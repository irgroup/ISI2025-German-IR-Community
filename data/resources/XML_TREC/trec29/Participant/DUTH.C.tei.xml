<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,231.17,116.95,153.02,12.62;1,193.52,134.89,228.31,12.62">DUTh at TREC 2020 Conversational Assistance Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,139.88,173.80,72.49,8.74"><forename type="first">Michalis</forename><surname>Fotiadis</surname></persName>
						</author>
						<author>
							<persName coords="1,219.83,173.80,67.13,8.74"><forename type="first">Georgios</forename><surname>Peikos</surname></persName>
						</author>
						<author role="corresp">
							<persName coords="1,294.63,173.80,84.45,8.74"><forename type="first">Symeon</forename><surname>Symeonidis</surname></persName>
							<email>ssymeoni@ee.duth.gr</email>
						</author>
						<author>
							<persName coords="1,406.48,173.80,69.00,8.74"><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Database &amp; Information Retrieval research unit</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical &amp; Computer Engineering</orgName>
								<orgName type="institution">Democritus University of Thrace</orgName>
								<address>
									<postCode>67100</postCode>
									<settlement>Xanthi</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,231.17,116.95,153.02,12.62;1,193.52,134.89,228.31,12.62">DUTh at TREC 2020 Conversational Assistance Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9162EF6CE389690B07E0383F89A57A75</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the DUTh's participation in the TREC 2020 Conversational Assistance Track (CAsT) track. Our approach incorporates linguistic analysis of the available queries along with query reformulation. The linguistic perspective of our approach implements the AllenNLP co-reference resolution model to every query of each conversational session. In addition, the SpaCy model was used for part-of-speech tagging and keyword extraction from the current and the previous turns. We reformulate the initial query into a weighted new query by keeping the keywords from the current turn and adding conversational context from previous turns. We argue that the conversational context of previous turns to have less impact than the keywords from the current turn while still adding some informational value. Finally, the new query was used for retrieval using Indri.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This is an overview of the Democritus University of Thrace (DUTh) retrieval runs submissions to the TREC 2020 Conversational Assistance Track(CAsT) <ref type="foot" coords="1,473.36,489.20,3.97,6.12" target="#foot_0">1</ref> , which focuses on conversational question answering. The system's main objective is to understand the information need in a conversational format and satisfy it. The primary task is to read the current dialogue to the given turn (context) and retrieve candidate responses (text passages) from a fixed text collection for the current turn.</p><p>Similarly to human-to-human conversations, human-to-assistant conversations are comprised of many turns and possibly more than one topic. An optimal system should distinguish possible topic drifts during the conversation and improve the relevance of the responses accordingly. In our case, the retrieval system's response is a ranking of short text responses suitable for voice-interface or a mobile screen (e.g., roughly 1-3 sentences in length). Summarizing, CAsT defines conversational search as a retrieval task in the conversational context.</p><p>Our approach consists of five basic steps: 1) co-reference resolution, 2) keyword and context extraction, 3) query reformulation, 4) passage retrieval, and 5) BERT passage re-ranking. Every step of our methodology is elaborated below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">AllenNLP Co-reference Resolution</head><p>Co-reference resolution is vital for question answering tasks in conversational contexts. In human-to-human conversations, the topic remains constant during the conversational turns, and usually, the subject is omitted or referenced by pronouns. We argue that this characteristic can be extended to human-to-assistants conversations too. The literature supports our argument that co-reference resolution is vital for question-answering tasks in a conversational context, see e.g. <ref type="bibr" coords="2,134.77,306.34,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="2,146.95,306.34,7.01,8.74" target="#b1">2]</ref>. In this direction, we applied AllenNLP's End-to-end Neural Coreference Resolution neural model <ref type="bibr" coords="2,245.65,318.30,10.52,8.74" target="#b2">[3]</ref> to replace the pronouns with their respective subjects.</p><p>In further detail, we iterated through every turn of every session and resolved the pronouns. There were no pronouns to resolve for the first turn as there were no previous turns. For the later turns, we concatenated the previous two turns and used them as an input to the AllenNLP neural model. The model determined the Part-Of-Speech (POS) for every token on the input (the concatenated sentences) and resolved the co-reference wherever possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">AllenNLP Named Entity Recognition</head><p>Besides co-reference resolution, we also used the AllenNLP named entity recognition model <ref type="bibr" coords="2,183.19,476.21,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="2,195.37,476.21,7.75,8.74" target="#b4">5]</ref> to identify named entities (people, locations, organizations, etc.) in the input text. The reasoning behind the usage of such a model is that in some cases the named entities were falsely replaced by pronouns. Such an example is visualized in Table <ref type="table" coords="2,218.08,512.08,3.87,8.74">1</ref>. We argue that such a feature will significantly improve the system's effectiveness, as it will eliminate the topic drift phenomenon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Without NER</head><p>With NER Describe Uranus.</p><p>Describe Uranus. What makes it so unusual?</p><p>What makes it so unusual? Tell me about its orbit.</p><p>Tell me about Uranus orbit. Why is it tilted?</p><p>Why is Uranus orbit tilted? How is its rotation different from other planets? How is Uranus rotation different from other planets? What is peculiar about its seasons?</p><p>What is peculiar about Uranus seasons? Are there any other planets similar to it?</p><p>Are there any other planets similar to Uranus seasons? Table <ref type="table" coords="2,169.22,656.02,4.13,7.89">1</ref>. Example of a conversational session where the use of NER was necessary</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Keyword and Context Extraction</head><p>We utilized the SpaCy model for English language<ref type="foot" coords="3,356.96,138.64,3.97,6.12" target="#foot_1">2</ref> to identify the POS tag of every token in the questions. After tokenization, SpaCy parses and creates a Doc object that contains useful information. From that object we extract the POS information that spaCy has predicted that fits best each token. In our experiment, we focus only on nouns, adjectives, adverbs, and verbs, based on previous studies, see e.g. <ref type="bibr" coords="3,261.88,199.99,10.52,8.74" target="#b5">[6,</ref><ref type="bibr" coords="3,274.06,199.99,7.01,8.74" target="#b6">7]</ref>. After tagging every token, we filtered them and kept only the aforementioned POS categories. We created a list of keywords for every turn of every session containing these tokens that were afterwards used as query terms. An example of the process is given in Table <ref type="table" coords="3,394.64,235.86,3.87,8.74" target="#tab_0">2</ref>. For each turn the query consists of the current query terms and former query terms. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Query Reformulation &amp; Passage Retrieval</head><p>Before retrieving the candidate passages, we reformulated each query to include context information from previous turns. We argue that as the conversation session proceeds, the former query terms are becoming less important. We used Indri's belief operator that allowed us to combine beliefs (scores) of terms, phrases, etc. With the weighted belief operator we assigned varying weights to certain expressions and we controlled how much of an impact each expression within our query had on the final score.</p><p>The query reformulation process will be further discussed in Section 3.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">BERT Re-ranking</head><p>After the initial retrieval, we tried to utilize BERT as a passage re-ranker to improve our results. We avoided using the pre-trained but not fine-tuned version version of BERT, as it would not had yielded better results according to last year's CAsT proceedings papers <ref type="bibr" coords="4,277.90,119.99,10.52,8.74" target="#b7">[8,</ref><ref type="bibr" coords="4,290.07,119.99,7.01,8.74" target="#b8">9]</ref>. As a result, it was necessary to fine-tune BERT on our dataset, a very computationally expensive task even on multiple TPUs. For that reason, we utilized the work of Nogueira et al. <ref type="bibr" coords="4,426.41,143.90,15.50,8.74" target="#b9">[10]</ref> who reimplemented BERT as a query-based passage re-ranker and achieved state-ofthe-art results on the TREC CAR dataset, topping the leaderboard of the MS MARCO passage retrieval task. They have published their code online<ref type="foot" coords="4,448.84,178.19,3.97,6.12" target="#foot_2">3</ref> along with the pre-trained and fine-tuned BERT models on the two datasets.</p><p>3 Experimental setup</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset &amp; Resources</head><p>As there are very few conversational datasets available, the CAsT's goal is to create a reusable benchmark dataset for further research in the conversational question answering domain. The data provided originates from multiple sources.</p><p>The dataset includes the passages collections, the conversational data provided for training and development, and finally, the Year 1 (Y1) training and evaluation sets. We employ the passages collection to retrieve our candidate passages for each query. The collections made available for the Year 2 (Y2) of this track were the MS MARCO Passage Ranking collection and the TREC CAR paragraph collection v2.0 <ref type="bibr" coords="4,228.48,380.89,14.61,8.74" target="#b10">[11]</ref>. In the current study, we focused on the Y1 train and evaluation data as we set out to thoroughly investigate the importance of query pre-processing and reformulation in the context of Conversational Information Seeking (CIS). At this point of our research, we design our approach based on Y1 data, so we exclude MS MARCO conversational session data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Collection Pre-processing</head><p>In order to set-up our approach, we had to process and parse the collections. We used the TREC-CAsT Tools<ref type="foot" coords="4,277.86,500.79,3.97,6.12" target="#foot_3">4</ref> to process and parse both of the collections, the MS MARCO Passage Ranking collection and the TREC CAR paragraph collection v2.0. For the TREC CAR paragraph collection v2.0 we also utilized the TREC CAR Tools<ref type="foot" coords="4,232.37,536.65,3.97,6.12" target="#foot_4">5</ref> that were made available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Linguistic Analysis</head><p>We submitted three runs, each of them using a different type of conversational utterances presented in Table <ref type="table" coords="4,266.66,611.87,3.87,8.74" target="#tab_1">3</ref>. We performed co-reference resolution and Named Entity Recognition for the duth run by using the AllenNLP tool, as described in Sections 2.1-2.2. For the duth arq and the duth manual runs, no co-reference resolution was needed. In these runs, we extracted the keywords similarly to create a list of keywords for every turn to be used as a context for future turns. The list of these extracted keywords was later used for the query reformulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">BERT Analysis</head><p>After CAsT's run submission deadline, we added another step in our experiments in order to improve our results even more, i.e. BERT passage re-ranking. As previously mentioned in Section 2.5, we utilized the work of Nogueira et al. <ref type="bibr" coords="5,134.77,354.35,14.61,8.74" target="#b9">[10]</ref>. More specifically, we used the large BERT model trained on MS MARCO. Nogueira et al. implemented the model in TensorFlow <ref type="foot" coords="5,368.71,364.73,3.97,6.12" target="#foot_5">6</ref> . We utilized the Tensor-Flow checkpoints and with some small code alterations we converted our run file, which contained the top-1000 candidate passages we retrieved for every query, to a tfrecord file, which was used as an input to the BERT model. Because we were focusing on the earlier positions we only used the top-100 candidate passages we retrieved as an input to the BERT model. Finally, the model returned a re-ranked run file of 100 candidate passages which was later evaluated using the TREC evaluation software. We performed BERT re-ranking for each and every run we submitted for CAsT Y2 and achieved significantly better results, which will be presented in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Retrieval Process</head><p>The Lemur Toolkit <ref type="bibr" coords="5,223.32,528.48,15.50,8.74" target="#b11">[12]</ref> was used to retrieve candidate passages from our collection. We assign a weight of 1 to the query terms of the current turn and kept the query terms of the former two turns-those query terms were downweighted-implementing the half-life decay model proposed by <ref type="bibr" coords="5,408.80,564.35,14.61,8.74" target="#b12">[13]</ref>. Specifically, we weighted the terms of the previous two conversational turns with weights of 0.5 and 0.25 respectively. Even though we believe that previous context could help Indri retrieve more relevant passages, weighing equally all history may lead to a rigid representation of the context, incapable of following a developing or drifting conversational topic. Weighting our previous context with a lower/decaying coefficient helped alleviating such effects.</p><p>For the reformulation of the queries we used the keywords extracted from the linguistic analysis we performed for both the current query (nouns, adjectives, adverbs and verbs) and the added context (nouns, adjectives and adverbs). We avoided using verbs from previous turns as context as it could lead to a potential topic drift that would lower the overall performance. In the cases where a term was found more than one time, both in the current turn and the context, we kept only the latest one. Both the MS MARCO Passage Ranking collection and the TREC CAR paragraph collection v2.0 were indexed, and the top-1000 passages with the highest score for each query were retrieved. No tuning of the Indri's search engine parameters was performed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Evaluation Measures</head><p>CAsT organizers' evaluated the ranking in two dimensions; the ranking depth and the turn depth. The ranking depth is the same as for adhoc search with focus on the early positions (P@1, P@3, P@5). The turn depth evaluates the ability of our system to perform on the n-th conversational turn. Performing well on deeper rounds indicates better ability to understand context.</p><p>In our study, we mainly used P@1, P@3, P@5, mean Average Precision (MAP), Reciprocal Rank, and NDCG@3, as our evaluation measures. Because the task is about conversational question answering, the passages in the earlier positions are our main interest. In a conversational setting there is only one opportunity to answer and it has to be correct.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results on the Y1 (2019) Dataset</head><p>For preparing our methods for CAsT Y2, we utilized the Y1 CAsT dataset for tuning and testing. We can see from Figure <ref type="figure" coords="6,337.56,573.43,4.98,8.74" target="#fig_0">1</ref> and Table <ref type="table" coords="6,396.33,573.43,4.98,8.74" target="#tab_2">4</ref> that our method significantly surpasses the baseline provided by the organizers of CAsT Y1. The baseline run consists only of AllenNLP co-reference resolution of the topics, stopwords removal and standard retrieval with Indri. It is expected that our method will perform better as it also includes the extra steps described in Sections 2-3. We can also see the impact of BERT re-ranking on our results with an increase in every evaluation metric. The latter highlights the importance of this extra step in our method overall.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results on the Y2 (2020) Dataset</head><p>Here we are going to present the results of our method on the Y2 evaluation dataset. In addition to the officially submitted runs we also include the postsubmission runs with the extra step of BERT passage re-ranking as described in Sections 2.5 and 3.4. The section is split in three parts, according to the evaluation topics' category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Raw Queries</head><p>In this category of runs we used the raw utterances of the evaluation dataset of Y2. The results of runs for raw queries are presented in Table <ref type="table" coords="7,399.24,657.11,4.98,8.74" target="#tab_3">5</ref> and Figure <ref type="figure" coords="7,456.35,657.11,3.87,8.74" target="#fig_1">2</ref>. We can see that our method performs slightly worse than the organizers' baseline run, which is expected as the organizers' baseline also includes BERT re-ranking along with BM25 retrieval. However, the 'duth BERT' run which includes the BERT re-ranking extra step performs significantly better. This is also expected as our method also includes co-reference resolution and linguistic analysis.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Automatically Rewritten Queries</head><p>In this category of runs we used the automatically rewritten utterances of the evaluation dataset of Y2. The results of the runs for automatically rewritten queries are presented in Table <ref type="table" coords="8,274.70,633.20,4.98,8.74" target="#tab_4">6</ref> and Figure <ref type="figure" coords="8,337.45,633.20,3.87,8.74" target="#fig_2">3</ref>. Our method performs significantly worse than the organizers' baseline run. Contrary to the raw utterances baseline run the baseline run of this category also includes co-reference resolution and query rewriting along with BERT re-ranking which explains why it outperforms our simpler method. By adding the BERT re-ranking step to our run, its performance significantly rises and is comparable to the baseline. However, even this run (duth arq BERT) fails to outperform the baseline which can be a result of a better BERT re-ranking model used by the baseline run.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Manually Resolved Queries</head><p>In this category of runs we used the manually resolved utterances of the evaluation dataset of Y2. Similarly to Section 4.2.2, our run performs significantly worse than the baseline run, which additionally includes a BERT re-ranking step.</p><p>However, even when we include such step in our method, we still cannot outperform the baseline run. This is an indication of a better, more suitable BERT re-ranking model used by the organizers. The results of the runs for manually resolved queries are presented in Table <ref type="table" coords="10,306.90,155.86,4.98,8.74">7</ref> and Figure <ref type="figure" coords="10,366.01,155.86,3.87,8.74" target="#fig_3">4</ref>.  <ref type="table" coords="10,164.82,525.99,4.13,7.89">7</ref>. Results of the Y2 (2020) evaluation dataset (for manually resolved queries) 1 Run that includes BERT passage re-ranking</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In our first participation to TREC's CAsT, we focused on pure Natural Language Processing (NLP) rules to incorporate conversational context in our queries, extracted from previous turns. We argued that the main characteristics of humanto-human conversations could be transferred to human-to-assistant conversations too. Following this direction, we used fast and effective tools to add extra informational value to each query.</p><p>There seem to be many possible improvements of the proposed method in several directions, one of which is the use of passage re-ranking with NLP neural models. Although (NLP) neural models are time-consuming to train, we firmly believe that it can yield better results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,213.37,353.00,185.55,7.89;7,134.77,229.65,172.91,106.84"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Performance on the Y1 (2019) dataset</figDesc><graphic coords="7,134.77,229.65,172.91,106.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="8,228.32,434.39,158.72,7.89;8,134.77,311.53,172.91,106.84"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Performance on the raw queries</figDesc><graphic coords="8,134.77,311.53,172.91,106.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="9,188.12,436.42,239.13,7.89;9,134.77,313.56,172.91,106.84"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Performance on the automatically rewritten queries</figDesc><graphic coords="9,134.77,313.56,172.91,106.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="10,199.49,421.43,216.37,7.89;10,134.77,298.58,172.91,106.84"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Performance on the manually resolved queries</figDesc><graphic coords="10,134.77,298.58,172.91,106.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,152.42,281.30,310.52,148.69"><head>Table 2 .</head><label>2</label><figDesc>Extracted tokens from initial queries based on SpaCy POS tagging</figDesc><table coords="3,176.69,281.30,261.98,132.80"><row><cell>Original user query</cell><cell>Final query terms</cell></row><row><cell>What are the main breeds of goat?</cell><cell>breeds, goat, main</cell></row><row><cell>Tell me about boer goats.</cell><cell>boer, goats</cell></row><row><cell>What breed is good for meat?</cell><cell>breed, good, meat</cell></row><row><cell>Are angora goats good for it?</cell><cell>angora, goats, good, meat</cell></row><row><cell>What about boer goats?</cell><cell>boer, goats</cell></row><row><cell>What are pygmies used for?</cell><cell>pygmies</cell></row><row><cell cols="2">What is the best for fiber production? best, fiber, production</cell></row><row><cell>How long do Angora goats live?</cell><cell>how, long, Angora, goats</cell></row><row><cell>Can you milk them?</cell><cell>milk, Angora, goats</cell></row><row><cell>How many can you have per acre?</cell><cell>how, many, acre</cell></row><row><cell>Are they profitable?</cell><cell>angora, goats, profitable</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,205.91,118.78,203.54,57.83"><head>Table 3 .</head><label>3</label><figDesc>Submitted runs</figDesc><table coords="5,205.91,118.78,203.54,41.94"><row><cell>Run ID</cell><cell>Type of utterances</cell><cell>Type of run</cell></row><row><cell>duth</cell><cell>Raw</cell><cell>Automatic</cell></row><row><cell>duth arq</cell><cell cols="2">Automatically rewritten Automatic</cell></row><row><cell cols="2">duth manual Manually rewritten</cell><cell>Manual</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,134.77,386.67,344.86,107.19"><head>Table 4 .</head><label>4</label><figDesc>Results of the Y1 (2019) evaluation dataset1 Run that uses the manually annotated evaluation topics 2 Run that includes BERT passage re-ranking</figDesc><table coords="7,473.02,386.67,6.60,7.86"><row><cell>3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,134.77,489.55,338.44,73.52"><head>Table 5 .</head><label>5</label><figDesc>Results of the Y2 (2020) evaluation dataset (for raw queries)1 Run that includes BERT passage re-ranking</figDesc><table coords="8,466.60,489.55,6.60,7.86"><row><cell>3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,134.77,494.89,345.83,84.48"><head>Table 6 .</head><label>6</label><figDesc>Results of the Y2 (2020) evaluation dataset (for automatically rewritten queries)</figDesc><table coords="9,469.33,494.89,6.60,7.86"><row><cell>3</cell></row></table><note coords="9,134.77,569.73,3.65,5.24;9,140.76,571.50,178.62,7.86"><p><p>1 </p>Run that includes BERT passage re-ranking</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,657.79,97.09,7.86"><p>http://www.treccast.ai/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,144.73,657.79,166.16,7.86"><p>https://spacy.io/usage/linguistic-features</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,144.73,635.88,168.79,7.86"><p>https://github.com/nyu-dl/dl4marco-bert</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,144.73,646.84,174.52,7.86"><p>https://github.com/grill-lab/trec-cast-tools</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,144.73,657.79,198.53,7.86"><p>https://github.com/TREMA-UNH/trec-car-tools</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="5,144.73,657.79,78.68,7.86"><p>www.tensorflow.org</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="11,142.96,224.79,337.63,7.86;11,151.52,235.75,329.07,7.86;11,151.52,246.71,329.07,7.86;11,151.52,257.66,174.93,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,422.28,224.79,58.31,7.86;11,151.52,235.75,256.05,7.86">Importance of pronominal anaphora resolution in question answering systems</title>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Luis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vicedo</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>Ferrández</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rodríguez</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,430.46,235.75,50.13,7.86;11,151.52,246.71,227.32,7.86">38th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2000">October 1-8, 2000. 2000</date>
			<biblScope unit="page" from="555" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,269.25,337.63,7.86;11,151.52,280.21,329.07,7.86;11,151.52,291.16,92.75,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,329.71,269.25,150.87,7.86;11,151.52,280.21,280.85,7.86">Erik Cambria, and Ramkumar Thirunavukarasu. Anaphora and coreference resolution: A review</title>
		<author>
			<persName coords=""><forename type="first">Rhea</forename><surname>Sukthanker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,447.30,280.21,33.29,7.86;11,151.52,291.16,15.22,7.86">Inf. Fusion</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="139" to="162" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,302.75,337.64,7.86;11,151.52,313.71,329.07,7.86;11,151.52,324.66,329.07,7.86;11,151.52,335.62,329.07,7.86;11,151.52,346.58,259.71,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,406.57,302.75,74.02,7.86;11,151.52,313.71,86.53,7.86">End-to-end neural coreference resolution</title>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,184.03,324.66,296.56,7.86;11,151.52,335.62,67.09,7.86">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rebecca</forename><surname>Hwa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</editor>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-09-09">2017. September 9-11, 2017. 2017</date>
			<biblScope unit="page" from="188" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,358.16,337.64,7.86;11,151.52,369.12,329.07,7.86;11,151.52,380.08,329.07,7.86;11,151.52,391.04,329.07,7.86;11,151.52,402.00,196.69,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,428.52,369.12,52.06,7.86;11,151.52,380.08,208.56,7.86">AllenNLP: A deep semantic natural language processing platform</title>
		<author>
			<persName coords=""><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joel</forename><surname>Grus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nelson</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,380.43,380.08,100.16,7.86;11,151.52,391.04,170.23,7.86">Proceedings of Workshop for NLP Open Source Software (NLP-OSS)</title>
		<meeting>Workshop for NLP Open Source Software (NLP-OSS)<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07">July 2018</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,413.58,337.63,7.86;11,151.52,424.54,329.07,7.86;11,151.52,435.50,329.07,7.86;11,151.52,446.46,329.07,7.86;11,151.52,457.42,329.07,7.86;11,151.52,468.38,133.34,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,151.52,424.54,279.80,7.86">Semi-supervised sequence tagging with bidirectional language models</title>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Russell</forename><surname>Power</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,304.18,435.50,176.41,7.86;11,151.52,446.46,188.78,7.86">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</editor>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-07-30">2017. July 30 -August 4. 2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1756" to="1765" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,479.96,337.63,7.86;11,151.52,490.92,316.86,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,151.52,490.92,138.07,7.86">Phrase-based information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tsoris</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Cornelis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Theo</forename><forename type="middle">P</forename><surname>Koster</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Van Der Weide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,297.24,490.92,81.01,7.86">Inf. Process. Manag</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="693" to="707" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,502.50,337.64,7.86;11,151.52,513.46,329.07,7.86;11,151.52,524.42,261.89,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,468.56,502.50,12.03,7.86;11,151.52,513.46,217.43,7.86">An evaluation of linguistically-motivated indexing schemes</title>
		<author>
			<persName coords=""><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Th</forename><forename type="middle">P</forename><surname>Van Der Weide</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H A</forename><surname>Koster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Van Bommel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,387.49,513.46,93.11,7.86;11,151.52,524.42,156.01,7.86">Proceedings of the 22nd BCS-IRSG Colloquium on IR Research</title>
		<meeting>the 22nd BCS-IRSG Colloquium on IR Research</meeting>
		<imprint>
			<date type="published" when="2000-04">April 2000</date>
			<biblScope unit="page" from="34" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,536.00,337.64,7.86;11,151.52,546.96,329.07,7.86;11,151.52,557.92,329.07,7.86;11,151.52,568.88,329.07,7.86;11,151.52,579.84,251.50,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,443.86,536.00,36.73,7.86;11,151.52,546.96,98.65,7.86">Radboud university at TREC 2019</title>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Kamphuis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Faegheh</forename><surname>Hasibi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Arjen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tanja</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Crijns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,447.41,546.96,33.18,7.86;11,151.52,557.92,212.97,7.86">Proceedings of the Twenty-Eighth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Angela</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>the Twenty-Eighth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11-13">2019. November 13-15, 2019. 2019</date>
			<biblScope unit="volume">1250</biblScope>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
	<note>TREC</note>
</biblStruct>

<biblStruct coords="11,142.96,591.42,337.63,7.86;11,151.52,602.38,329.07,7.86;11,151.52,613.34,329.07,7.86;11,151.52,624.29,329.07,7.86;11,151.52,635.25,329.07,7.86;11,151.52,646.21,251.50,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,182.22,602.38,298.37,7.86;11,151.52,613.34,84.66,7.86">Predicting relevant conversation turns for improved retrieval in multi-turn conversational search</title>
		<author>
			<persName coords=""><forename type="first">Esteban</forename><forename type="middle">A</forename><surname>Ríssola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manajit</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohammad</forename><surname>Aliannejadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,447.41,613.34,33.18,7.86;11,151.52,624.29,212.97,7.86">Proceedings of the Twenty-Eighth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Angela</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>the Twenty-Eighth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11-13">2019. November 13-15, 2019. 2019</date>
			<biblScope unit="volume">1250</biblScope>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
	<note>TREC</note>
</biblStruct>

<biblStruct coords="11,142.61,657.79,317.06,7.86" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="11,316.79,657.79,114.98,7.86">Passage re-ranking with bert</title>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,120.67,337.98,7.86;12,151.52,131.63,329.07,7.86;12,151.52,142.59,217.39,7.86" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="12,265.15,131.63,215.45,7.86;12,151.52,142.59,90.36,7.86">MS MARCO: A human generated machine reading comprehension dataset</title>
		<author>
			<persName coords=""><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<idno>CoRR, abs/1611.09268</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,153.55,337.98,7.86;12,151.52,164.51,329.07,7.86;12,151.52,175.46,329.07,7.86;12,151.52,186.42,20.99,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,458.30,153.55,22.29,7.86;12,151.52,164.51,245.56,7.86">Indri: A language model-based search engine for complex queries</title>
		<author>
			<persName coords=""><forename type="first">Trevor</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Howard</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,422.51,164.51,58.09,7.86;12,151.52,175.46,201.50,7.86">Proceedings of the international conference on intelligent analysis</title>
		<meeting>the international conference on intelligent analysis</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,197.38,337.98,7.86;12,151.52,208.34,329.07,7.86;12,151.52,219.30,329.07,7.86;12,151.52,230.26,329.07,7.86;12,151.52,241.22,301.95,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,151.52,208.34,329.07,7.86;12,151.52,219.30,11.14,7.86">Incrementality, half-life, and threshold optimization for adaptive document filtering</title>
		<author>
			<persName coords=""><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean</forename><surname>Beney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Cornelis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Theo</forename><forename type="middle">P</forename><surname>Koster</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Van Der Weide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,403.10,219.30,77.49,7.86;12,151.52,230.26,188.91,7.86">Proceedings of The Ninth Text REtrieval Conference, TREC 2000</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Donna</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>The Ninth Text REtrieval Conference, TREC 2000</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">500</biblScope>
		</imprint>
		<respStmt>
			<orgName>NIST Special Publication. National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
