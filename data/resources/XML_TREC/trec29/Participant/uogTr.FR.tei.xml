<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,98.13,84.23,415.73,15.44;1,231.07,104.15,150.36,15.44">University of Glasgow Terrier Team at the TREC 2020 Fair Ranking Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,136.82,134.31,93.13,10.59"><forename type="first">Graham</forename><surname>Mcdonald</surname></persName>
							<email>graham.mcdonald@glasgow.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Glasgow Glasgow</orgName>
								<address>
									<country key="GB">Scotland, UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,402.81,134.31,53.61,10.59"><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
							<email>iadh.ounis@glasgow.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Glasgow Glasgow</orgName>
								<address>
									<country key="GB">Scotland, UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,98.13,84.23,415.73,15.44;1,231.07,104.15,150.36,15.44">University of Glasgow Terrier Team at the TREC 2020 Fair Ranking Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A25B901871977A7E252CF6917D7660C0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In our participation to the TREC 2020 Fair Ranking Track, the University of Glasgow Terrier Team investigated a new approach for organically uncovering latent communities of authors that we wish to be fair to. Our deployed approach leverages a co-embedding model to jointly model a document's attributes, such as the document's authors, and the citation link graph of the documents in a collection, within a single embedding space. This network coembedding is then used as input to a community detection approach that automatically updates the identified communities for each instance of a repeated query. Moreover, we experiment with two different ranking strategies to provide a fair exposure to different communities, and the authors within the communities, over time. Our first ranking strategy is inspired by the concepts of coverage and novelty from search results diversification, while our second ranking strategy leverages a data fusion approach for prioritising different communities over time.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Building on last year's participation, for the TREC 2020 Fair Ranking Track re-ranking task, the University of Glasgow Terrier Team aimed to build upon their Terrier.org Information Retrieval (IR) platform <ref type="bibr" coords="1,73.45,438.35,9.24,7.94" target="#b6">[7,</ref><ref type="bibr" coords="1,84.93,438.35,11.48,7.94" target="#b9">10]</ref> to investigate another approach for organically uncovering the latent communities of authors that we wish to be fair to.</p><p>Our approach jointly models a document's attributes, such as co-authorship, and the document collection's citation link graph within a single embedding space, before leveraging a community detection approach to organically uncover latent communities of authors. Such latent author communities are likely to, for example, work on a particular problem or within a particular field of research. Moreover, our approach automatically updates the membership of the identified communities for each instance of a repeated query to try to ensure fairness for unknown, or arbitrary, protected groups.</p><p>To evaluate the effectiveness of our community detection approach for generating fair rankings, we experiment with two distinct ranking strategies. Our proposed strategies aim to provide a fair exposure to authors within a particular community, and to provide a fair exposure to each of the communities over time. The first ranking strategy that we deploy is inspired by search results diversification <ref type="bibr" coords="1,108.79,624.65,14.79,7.94" target="#b11">[12]</ref> while the second ranking strategy that we deploy leverages a well-known data fusion <ref type="bibr" coords="1,202.68,635.61,10.50,7.94" target="#b2">[3]</ref> approach to prioritise different communities over time.</p><p>In the following, we first describe our community detection fairness approach. Next we discuss the two ranking strategies that we deploy, before discussing the relevance-focused component of our approaches and providing details of our submitted runs. We then present an analysis of our obtained results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">COMMUNITY DETECTION FOR FAIR RANKING</head><p>Our participation in the Fair Ranking Track 2020 builds upon a novel community detection approach for identifying groups of documents that share common attributes, such as authors, and that are related to each other, for example through citations. Our intuition is that to be fair to unknown, or arbitrary, groups of authors when generating rankings we need a way of automatically uncovering the latent author groups, or communities, that exist within the collection of documents that are to be ranked. Our deployed community detection approach for fair ranking constructs a co-embedding attribute network <ref type="bibr" coords="1,486.49,317.39,10.60,7.94" target="#b8">[9]</ref> to jointly model the documents' attributes and the links that exist between the documents in the collection. Our approach has three stages, as follows:</p><p>• Stage 1: Constructs a directed network multigraph representing the document collection where a node in the graph is a document in the collection, represented by a set of attributes of the document. The edges of the graph are the citation links between documents. • Stage 2: Learns a co-embedding of the constructed graph, which jointly models the documents' attributes and the links between documents within a single embedding space. • Stage 3: Deploys a clustering-based community detection approach to identify communities within the learned embeddings.</p><p>For our participation in the Fair Ranking Track 2020, in Stage 1 of our community detection approach, we leverage a document's authors as attributes for the nodes of the graph and citation links as the graph edges. We note however, that the proposed approach is not restricted to modelling nodes and links in such a way. For example, the document's attributes can easily be updated to also include the terms of the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">FAIR RANKING STRATEGIES</head><p>We experiment with two strategies for generating fair rankings that aim to provide a fair exposure to our organically identified latent communities, and the authors within those communities, over time. Both of our approaches combine a community fairness score with a relevance score (we will discuss our approach for ranking the documents with respect to relevance in Section 4) for each document on a query-by-query basis to provide a fair exposure over multiple repeated queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Ranking Approach 1: Community Representativeness</head><p>Our first fair ranking strategy is loosely inspired by search results diversification <ref type="bibr" coords="2,106.69,125.40,13.22,7.94" target="#b11">[12]</ref>. Specifically, we take inspiration from the search results diversification concepts of novelty (that selects documents to include in a ranking if they discuss sub-topics of an ambiguous query that are not yet discussed by the documents that have previously been selected for the ranking) and coverage (where documents that represent many potential sub-topics of an ambiguous query are promoted in the ranking). However, differently from search results diversification, we aim to promote documents in the ranking that are (a) highly representative of the community that they belong to and, (b) highly dis-similar to the documents that are in the other communities. Importantly, for this approach, we consider that each document is a member of a single community and we generate new communities (varying the size and membership of the communities) for each instance of a repeated query, to try to ensure a fair exposure for communities and authors over time.</p><p>Our community representativeness fair ranking strategy combines the scores of two components. The first component, namely Community Coverage, scores documents based on their similarity to the other documents within the document's own community. The Community Coverage component prioritises the documents that are the most representative of the community that the documents belong to. The second component, namely Community Novelty, scores a document based on its dis-similarity to the documents that are members of the communities that the current document does not belong to. This component promotes documents if they are different from the documents that are in the other communities, i.e., the communities that the candidate document does not belong to.</p><p>For our experiments, we deploy two variants of our community representativeness fair ranking strategy to combine the communitybased scores with the predicted relevance of a document to generate the final ranking for a particular instance of a query. We provide details of the different variants that we deploy in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Ranking Approach 2: Data Fusion for Community Prioritisation</head><p>For our second community-based fair ranking strategy, we leverage a data fusion (rank aggregation) technique, CombSUM <ref type="bibr" coords="2,250.95,543.90,9.27,7.94" target="#b2">[3]</ref>, that has previously been shown to be an effective component for diversification <ref type="bibr" coords="2,84.24,565.82,9.52,7.94" target="#b5">[6]</ref>. To leverage data fusion to provide a fair exposure to individual communities, we assign prioritisation scores to each of the identified communities and generate multiple rankings. Each of the generated rankings prioritises the documents in a particular community, based on the community's assigned prioritisation score. The generated rankings are then aggregated to construct the final ranking.</p><p>For each instance of a repeated query, our data fusion community prioritisation ranking strategy has the following four stages:</p><p>• Stage 1: Define 𝑛 communities, where each document in the collection of documents that is to be ranked is a member of exactly one community.</p><p>• Stage 2: Deploy a stochastic process to assign a priority score to each of the communities, so that the communities are ranked 1..𝑛. • Stage 3: Generate n rankings of documents where the rank score for a document is calculated as the document's relevance score multiplied by the priority score of the community that the document is a member of. • Stage 4: Deploy a data fusion technique to aggregate the rank scores of each of the 𝑛 rankings to generate the final ranking for the query instance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">INDEXING &amp; RETRIEVAL</head><p>We indexed the semantic scholar <ref type="bibr" coords="2,443.18,222.75,10.68,7.94" target="#b1">[2]</ref> corpus using Terrier <ref type="bibr" coords="2,534.76,222.75,9.44,7.94" target="#b6">[7,</ref><ref type="bibr" coords="2,546.61,222.75,11.59,7.94" target="#b9">10]</ref> v5.2. We transformed the JSON representation of the corpus into traditional TREC documents, where each JSON attribute is represented as a separate field in the TREC document, before indexing the collection. When indexing the collection, we recorded the 'TITLE', 'PAPERABSTRACT' and 'OTHER' fields, where 'OTHER' contains the text from all of the remaining fields in a TREC document. We removed stopwords using Terrier's standard stopword list and applied Terrier's implementation of Porter stemmer <ref type="bibr" coords="2,500.91,310.42,13.36,7.94" target="#b10">[11]</ref>. This index was used in all our TREC submitted runs.</p><p>We investigated a number of retrieval strategies to form a base ranking that provides the document relevance scores for each of our community detection fair ranking approaches. We found that combining the DPH <ref type="bibr" coords="2,391.41,365.22,10.42,7.94" target="#b3">[4]</ref> parameter-free document weighting model from the Divergence from Randomness (DFR) framework <ref type="bibr" coords="2,528.77,376.18,10.51,7.94" target="#b0">[1]</ref> with the PyTerrier <ref type="bibr" coords="2,369.76,387.14,10.68,7.94" target="#b7">[8]</ref> implementation of ColBERT <ref type="bibr" coords="2,491.01,387.14,10.68,7.94" target="#b4">[5]</ref> resulted in the most effective retrieval performance. We use the relevance scores from this configuration for four of our five submitted runs. As a comparison benchmark, to evaluate the relative improvements that are the result of integrating ColBERT into the retrieval process, we also submitted a run where the relevance scores are generated using DPH alone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SUBMITTED RUNS</head><p>We submitted five runs to the TREC 2020 Fair Ranking Track:</p><p>• UoGTrBComRel: This run is a linear combination of the DPH+ColBERT relevance scores from PyTerrier and the (dis)similarity scores from each of the two components of our community representativeness fair ranking strategy, as follows: Relevance+Community Coverage+Community Novelty.</p><p>The relevance component and both of the components of our community representativeness fair ranking strategy are weighted equally in this variant. In practice, this means that, for documents that have a relatively high relevance score, the relevance component in this variant dominates the community representativeness components. This ensures that documents that are predicted to be relevant remain close to the top of the final ranking. • UoGTrBComPro: This run combines the DPH+ColBERT relevance scores from PyTerrier with the (dis)similarity scores from each of the two components of our community representativeness fair ranking strategy. Differently from UoGTr-BComRel, this run linearly combines a document's relevance score with the product of the (dis)similarity scores from each . This approach puts relatively more emphasis on the scores generated by the community representativeness ranking strategy. In particular, the more a document is dissimilar to the documents that are in other communities, the more the document's own community representativeness score (Community Coverage) is boosted. This can promote a document higher up a ranking than is likely to happen in the UoGTrBComRel variant. If a document is completely similar to the documents that are in other communities, then this approach reduces to a linear combination of the document's relevance score plus the document's own community representativeness score. • UoGTrBComFu: This run is a linear combination of the DPH+ColBERT relevance scores from PyTerrier with the scores from our data fusion community prioritisation ranking strategy. The run deploys data fusion to promote different communities over time. • UoGTrBRel: This run simply consists in ranking, for each instance of a query in the sequence, the documents according to their DPH+ColBERT relevance scores from PyTerrier. No fairness component is explicitly enforced. • UoGTrComRel: This run is the same as 𝑈 𝑜𝐺𝑇𝑟𝐵𝐶𝑜𝑚𝑅𝑒𝑙, except that the documents' relevance scores are generated by DPH alone (i.e., there is no ColBERT integration deployed when generating the relevance scores for this run).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS</head><p>In this section, we provide a concise analysis of the performances of our five submitted runs as reported by the official track metric, the difference in expected exposure from the target exposure. For the fairness ground-truth, each document is assigned to one of three fairness groups based on the International Monetary Fund (IMF) economic development status of the country of each author's affiliation, either advanced, developing, or mixed.  <ref type="table" coords="3,372.94,305.76,4.25,7.94" target="#tab_0">1</ref> also presents the mean values of the per-query TREC min, TREC mean, TREC median and TREC max differences in expected and target exposures (lower scores are better). From Table <ref type="table" coords="3,339.91,338.64,3.10,7.94" target="#tab_0">1</ref>, we can see that 𝑈 𝑜𝐺𝑇𝑟𝐵𝐶𝑜𝑚𝐹𝑢 achieves a smaller difference in expected and target exposures than the TREC mean and TREC Median (mean scores over the 200 queries).</p><p>Table <ref type="table" coords="3,349.18,371.52,4.09,7.94" target="#tab_1">2</ref> presents how each of our approaches performed on a perquery basis, in terms on the number of queries where an approach achieved the smallest difference in expected and target exposures (denoted as = 𝑀𝑖𝑛 𝑒𝑒 ), less than the TREC mean difference (denoted as &lt; 𝑀𝑒𝑎𝑛 𝑒𝑒 ), less than the TREC median difference (denoted as &lt; 𝑀𝑒𝑑𝑖𝑎𝑛 𝑒𝑒 ) or less than the TREC Max difference (denoted as &lt; 𝑀𝑎𝑥 𝑒𝑒 ). We can see from Table <ref type="table" coords="3,439.07,437.27,4.09,7.94" target="#tab_1">2</ref> that our data fusion community prioritisation ranking strategy (𝑈 𝑜𝐺𝑇𝑟𝐵𝐶𝑜𝑚𝐹𝑢) performed best from all of the runs submitted to TREC for 15 of the 200 queries (7.5%). Moreover, this approach resulted in a smaller difference between expected and target exposure than the TREC Mean for 70% of the queries (140) and a smaller difference than the TREC Median for 77.5% of the queries (155). Furthermore, our 𝑈 𝑜𝐺𝑇 𝑟𝐵𝐶𝑜𝑚𝐹𝑢 performed better than at least one of the other systems submitted to TREC for all of the queries. Overall, these results are promising and we will further investigate developing our proposed approach as future work.</p><p>Turning our attention to the performance of our community representativeness fair ranking strategy, we can see from Table <ref type="table" coords="3,554.16,568.78,4.25,7.94" target="#tab_0">1</ref> that, in terms of mean performance over the 200 queries, our 𝑈 𝑜𝐺𝑇𝑟𝐵𝐶𝑜𝑚𝑅𝑒𝑙 variant (a linear combination of relevance and the (dis)similarity scores from our community representativeness fair ranking strategy), performs better than our 𝑈 𝑜𝐺𝑇 𝑟 𝐵𝐶𝑜𝑚𝑃𝑟𝑜 variant (which puts relatively more weight on the scores generated by the community representativeness components than the relevance component). Indeed, from Table <ref type="table" coords="3,491.87,645.49,3.13,7.94" target="#tab_1">2</ref>, we can see that 𝑈 𝑜𝐺𝑇𝑟𝐵𝐶𝑜𝑚𝑅𝑒𝑙 performs better than 𝑈 𝑜𝐺𝑇𝑟𝐵𝐶𝑜𝑚𝑃𝑟𝑜 in terms of = 𝑀𝑖𝑛 𝑒𝑒 , &lt; 𝑀𝑒𝑎𝑛 𝑒𝑒 , &lt; 𝑀𝑒𝑑𝑖𝑎𝑛 𝑒𝑒 and &lt; 𝑀𝑎𝑥 𝑒𝑒 . This shows that relevance is an important component for minimising the difference between expected and target exposures when deploying our community representativeness ranking strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS</head><p>For our participation to the TREC 2020 Fair Ranking Track, we investigated a new approach for organically uncovering latent communities of authors that we wish to be fair to. Our approach firstly jointly models, within a single embedding space, a document's attributes (e.g., the document's authors) along with the citation link graph of the document collection. Secondly, our approach leverages a community detection approach for organically generating author communities. We also experimented with two different fair ranking strategies to provide a fair exposure to our identified author communities over time. Our first ranking strategy is inspired by search results diversification while our second ranking strategy leverages a data fusion technique. We found that our data fusion-based ranking strategy was particularly effective for providing a fair exposure to authors over time, resulting in the least difference between the expected and target exposures for 7.5% of queries, better than the TREC Mean for 70% of queries and better than the TREC Median for 77.5% of queries.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,53.50,85.73,242.15,254.78"><head>Table 1 :</head><label>1</label><figDesc>Run results in terms of the Mean (per-query) difference in expected exposure from the target exposure over 200 queries. The table also shows the variance (Var) and standard deviation (Std.) of each of our approaches and the TREC Min, Mean, Median and Max. The best Mean score is highlighted in bold.</figDesc><table coords="3,75.48,168.88,218.57,171.63"><row><cell></cell><cell>Mean</cell><cell>Var</cell><cell>Std.</cell></row><row><cell>𝑈 𝑜𝐺𝑇 𝑟𝐵𝐶𝑜𝑚𝑅𝑒𝑙</cell><cell cols="3">0.7966 0.1973 0.4442</cell></row><row><cell>𝑈 𝑜𝐺𝑇 𝑟𝐵𝐶𝑜𝑚𝑃𝑟𝑜</cell><cell cols="3">0.8087 0.1971 0.4439</cell></row><row><cell>𝑈 𝑜𝐺𝑇 𝑟𝐵𝐶𝑜𝑚𝐹𝑢</cell><cell cols="3">0.6078 0.1053 0.3245</cell></row><row><cell>𝑈 𝑜𝐺𝑇 𝑟𝐵𝑅𝑒𝑙</cell><cell cols="3">0.8251 0.2045 0.4523</cell></row><row><cell>𝑈 𝑜𝐺𝑇 𝑟𝐶𝑜𝑚𝑅𝑒𝑙</cell><cell cols="3">0.7966 0.1973 0.4442</cell></row><row><cell>TREC (per-query) Min</cell><cell cols="3">0.2931 0.0329 0.1814</cell></row><row><cell>TREC (per-query) Mean</cell><cell cols="3">0.7566 0.0653 0.2555</cell></row><row><cell cols="4">TREC (per-query) Median 0.7147 0.0789 0.2809</cell></row><row><cell>TREC (per-query) Max</cell><cell cols="3">1.4304 0.1649 0.4062</cell></row><row><cell cols="4">of the two components of our community representativeness</cell></row><row><cell cols="4">fair ranking strategy, as follows: Relevance+(Community</cell></row><row><cell cols="2">Coverage * Community Novelty)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,317.66,85.73,249.78,168.21"><head>Table 2 :</head><label>2</label><figDesc>Per-query analysis. Number of queries (out of 200 queries) for which each approach achieved the lowest difference in expected exposure from the target exposure (i.e. the best performing system for a particular query) (= 𝑀𝑖𝑛 𝑒𝑒 ), less than the mean difference (&lt; 𝑀𝑒𝑎𝑛 𝑒𝑒 ), less than the median difference (&lt; 𝑀𝑒𝑑𝑖𝑎𝑛 𝑒𝑒 ) and less than the max difference (&lt; 𝑀𝑎𝑥 𝑒𝑒 ) in expected exposure from the target exposure. Best values are highlighted in bold.= 𝑀𝑖𝑛 𝑒𝑒 &lt; 𝑀𝑒𝑎𝑛 𝑒𝑒 &lt; 𝑀𝑒𝑑𝑖𝑎𝑛 𝑒𝑒 &lt; 𝑀𝑎𝑥 𝑒𝑒</figDesc><table coords="3,322.40,202.15,236.65,51.78"><row><cell>𝑈 𝑜𝐺𝑇𝑟𝐵𝐶𝑜𝑚𝑅𝑒𝑙</cell><cell>11</cell><cell>71</cell><cell>87</cell><cell>194</cell></row><row><cell>𝑈 𝑜𝐺𝑇𝑟𝐵𝐶𝑜𝑚𝑃𝑟𝑜</cell><cell>10</cell><cell>67</cell><cell>83</cell><cell>193</cell></row><row><cell>𝑈 𝑜𝐺𝑇𝑟𝐵𝐶𝑜𝑚𝐹𝑢</cell><cell>15</cell><cell>140</cell><cell>155</cell><cell>200</cell></row><row><cell>𝑈 𝑜𝐺𝑇𝑟𝐵𝑅𝑒𝑙</cell><cell>8</cell><cell>66</cell><cell>80</cell><cell>191</cell></row><row><cell>𝑈 𝑜𝐺𝑇𝑟𝐶𝑜𝑚𝑅𝑒𝑙</cell><cell>2</cell><cell>82</cell><cell>92</cell><cell>196</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,317.96,283.85,240.25,29.86"><head>Table 1</head><label>1</label><figDesc>presents the mean difference in expected exposure and target exposure for each of our submitted runs, averaged over 200 queries. Table</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="8">ACKNOWLEDGEMENTS</head><p>We would like to thank <rs type="person">Alberto Ueda</rs>, <rs type="person">Craig Macdonald</rs> and <rs type="person">Zaiqiao Meng</rs> for their inputs during the course of our participation.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="4,333.39,99.76,225.51,6.23;4,333.39,107.73,225.57,6.23;4,333.39,115.75,64.78,6.18" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,391.38,99.76,167.52,6.23;4,333.39,107.73,64.48,6.23">Probabilistic Models for Information Retrieval based on Divergence from Randomness</title>
		<author>
			<persName coords=""><forename type="first">Gianni</forename><surname>Amati</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computing Science, University of Glasgow</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. Dissertation.</note>
</biblStruct>

<biblStruct coords="4,333.39,123.72,225.99,6.18;4,333.39,131.69,224.81,6.18;4,333.39,139.66,225.58,6.18;4,333.39,147.63,225.57,6.18;4,333.39,155.60,224.81,6.18;4,333.39,163.52,161.86,6.23" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,503.61,155.60,54.59,6.18;4,333.39,163.57,104.45,6.18">Construction of the Literature Graph in Semantic Scholar</title>
		<author>
			<persName coords=""><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dirk</forename><surname>Groeneveld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miles</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jason</forename><surname>Dunkelberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ahmed</forename><surname>Elgohary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sergey</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vu</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rodney</forename><surname>Kinney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Kohlmeier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tyler</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Hsu-Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><surname>Ooi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joanna</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sam</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lucy</forename><forename type="middle">Lu</forename><surname>Skjonsberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zheng</forename><surname>Wilhelm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Madeleine</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oren</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,449.97,163.52,41.41,6.23">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,333.39,171.49,224.81,6.23;4,333.39,179.46,92.23,6.23" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,447.36,171.54,92.49,6.18">Combination of multiple searches</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,544.92,171.49,13.29,6.23;4,333.39,179.46,59.83,6.23">NIST special publication SP</title>
		<imprint>
			<biblScope unit="volume">243</biblScope>
			<date type="published" when="1994">1994. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,333.39,187.48,225.99,6.18;4,333.22,195.45,224.98,6.18;4,333.39,203.37,137.20,6.23" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,547.00,187.48,12.38,6.18;4,333.22,195.45,224.98,6.18;4,333.39,203.42,78.91,6.18">University of Glasgow at TREC 2008: Experiments in blog, enterprise, and relevance feedback tracks with Terrier</title>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jie</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rodrygo L</forename><surname>Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,424.23,203.37,30.69,6.23">Proc. TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,333.39,211.39,224.81,6.18;4,333.39,219.31,202.93,6.23" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,445.10,211.39,113.09,6.18;4,333.39,219.36,150.90,6.18">ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT</title>
		<author>
			<persName coords=""><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,497.10,219.31,36.37,6.23">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,333.39,227.33,224.81,6.18;4,333.39,235.25,92.07,6.23" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,519.93,227.33,38.27,6.18;4,333.39,235.30,40.79,6.18">Fusion Helps Diversification</title>
		<author>
			<persName coords=""><forename type="first">Shangsong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,386.24,235.25,36.37,6.23">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,333.39,243.27,224.81,6.18;4,333.39,251.19,222.49,6.23" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,542.96,243.27,15.24,6.18;4,333.39,251.24,148.86,6.18">From puppy to maturity: Experiences in developing terrier</title>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iadh</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,493.99,251.19,59.03,6.23">Proc. of OSIR at SIGIR</title>
		<meeting>of OSIR at SIGIR</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,333.39,259.21,224.81,6.18;4,333.39,267.13,153.99,6.23" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,468.01,259.21,90.19,6.18;4,333.39,267.18,102.50,6.18">Declarative experimentation in information retrieval using pyterrier</title>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicola</forename><surname>Tonellotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,447.87,267.13,36.61,6.23">Proc. of ICTIR</title>
		<meeting>of ICTIR</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,333.39,275.15,225.88,6.18;4,333.39,283.07,150.14,6.23" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="4,333.39,283.12,101.19,6.18">Co-embedding Attributed Networks</title>
		<author>
			<persName coords=""><forename type="first">Zaiqiao</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shangsong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hongyan</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiangliang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,447.17,283.07,32.10,6.23">Proc. WSDM</title>
		<meeting>WSDM</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,333.39,291.09,224.81,6.18;4,333.39,299.06,224.81,6.18;4,333.39,306.98,117.78,6.23" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="4,400.80,299.06,157.40,6.18;4,333.39,307.03,50.67,6.18">Terrier: A High Performance and Scalable Information Retrieval Platform</title>
		<author>
			<persName coords=""><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gianni</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassilis</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christina</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,396.34,306.98,51.98,6.23">Proc. OSIR at SIGIR</title>
		<meeting>OSIR at SIGIR</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,333.39,314.95,224.81,6.23;4,333.18,322.97,45.22,6.18" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="4,416.29,315.00,95.30,6.18">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,518.28,314.95,24.17,6.23">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980. 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,333.39,330.94,224.81,6.18;4,333.39,338.86,186.14,6.23" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="4,536.16,330.94,22.03,6.18;4,333.39,338.91,136.50,6.18">Explicit search result diversification through sub-queries</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">T</forename><surname>Rodrygo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jie</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iadh</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,482.09,338.86,34.37,6.23">Proc. of ECIR</title>
		<meeting>of ECIR</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
