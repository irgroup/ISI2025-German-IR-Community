<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,172.80,76.21,266.51,12.64">HIT_LTRC at TREC 2011 Microblog Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,238.08,115.12,27.18,8.96"><forename type="first">Yun</forename><surname>Li</surname></persName>
							<email>nicyun@gmail.com</email>
						</author>
						<author>
							<persName coords="1,271.56,115.12,60.67,8.96"><forename type="first">Xishuang</forename><surname>Dong</surname></persName>
							<email>dongxishuang@gmail.com</email>
						</author>
						<author>
							<persName coords="1,339.71,115.12,34.14,8.96"><forename type="first">Yi</forename><surname>Guan</surname></persName>
							<email>guanyi@hit.edu.cn</email>
						</author>
						<title level="a" type="main" coord="1,172.80,76.21,266.51,12.64">HIT_LTRC at TREC 2011 Microblog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">518A63999A0F48577EC9C692593B6079</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our entry into the TREC 2011 Microblog track. We submitted two runs in this year's track, both in real-time fashion and without any external resources. The runs were generated through a three-step procedure, including scoring, threshold selection and re-ranking. The evaluation results of our submitted runs significantly outperform the disjunctive baseline run. We conducted additional runs to show our score decay and threshold selection strategies to be exceptionally effective.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper describes our participation in the TREC 2011 Microblog track. We submitted two runs, hitWIt and hitWId, that all operated in a strict real-time fashion, and had no external resources involved, even for the web pages linked by URLs in the tweet's text.</p><p>We satisfied the real-time search constraints by dynamically indexing the tweets. For a specific query, the retrieval process was performed based on the repository that only indexed the tweets whose creation times were earlier than the query's timestamp, therefore the words' statistics like IDF were calculated without any future evidences.</p><p>We deployed a three-step method to meet this year's Microblog search requirement that the retrieved results should be ranked reverse-chronologically. Firstly, we gave each tweet a score according to its relevance to the assumed query. The run hitWIt was scored with solely language modeling approach <ref type="bibr" coords="1,175.44,410.39,11.18,9.50" target="#b0">[1]</ref>, and the run hitWId with the case of score decay <ref type="bibr" coords="1,405.02,410.39,12.28,9.50" target="#b1">[2]</ref> considered additionally. This is the only difference between these two runs. In the second step, we calculated a score threshold for each query based on the score distribution of relevant and non-relevant tweets retrieved in the previous step, by modeling the relevant tweets' scores as the Gaussian distribution and the nonrelevant tweets' scores as the Exponential distribution. Finally, the retrieved tweets with scores higher than the threshold were re-ranked according to their timestamp and returned.</p><p>Our submitted runs both outperform the disjunctive baseline run with statistically significant improvements. We presented extra experimental results to demonstrate the effectiveness of our score decay and threshold selection method. The runs with score decay factor perform better than the runs without it if the appropriate value of decay parameter is chosen, and the runs with adaptive threshold selection algorithm beat the runs with threshold fixed manually.</p><p>The next section describes the methods we employed to generate our submissions in detail. Section 3 describes the experimental methodology and results. Finally, section 4 gives conclusion and outlook of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>We used a three-step process to generate our results. At first, we used a scoring function to give each tweet a relevance score with respect to one specific query. Secondly, we selected a threshold score for each query according to the distribution of the relevant and non-relevant tweets retrieved. Finally, the tweets with score higher than the threshold were re-ranked reverse chronologically according to their creation time.</p><p>Section 2.1 describes the scoring function we used to score a tweet-query pair, and section 2.2 describes the approach how the re-ranking threshold was determined. Other procedures like dynamic indexing and re-ranking are straightforward thus unnecessary to be represented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Tweet Scoring</head><p>Our two submissions differ only in the scoring process. The run hitWIt used the basic language modeling scoring function, and the run hitWId taken the score decay circumstance into consideration. We will describe these two scoring functions in detail in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Basic Score.</head><p>Our basic scoring function adopted Indri's <ref type="bibr" coords="2,290.14,158.50,12.28,9.50" target="#b2">[3]</ref> language modeling approach. In this approach, documents (or tweets) are scored by the likelihood the query was generated by the document's model. Specifically, documents are modeled by multiple-Bernoulli distribution <ref type="bibr" coords="2,395.88,182.62,12.28,9.50" target="#b3">[4]</ref> with Dirichlet prior as the Bayesian smoothing approach <ref type="bibr" coords="2,219.23,194.75,11.18,9.50" target="#b4">[5]</ref>.</p><p>Given a tweet 𝑇𝑇 and a query 𝑄𝑄, the probability that the query was generated by the tweet's model is calculated as follows, according to Indri's retrieval model</p><formula xml:id="formula_0" coords="2,236.52,246.76,242.20,30.26">P(Q|T) = � � tf r,T + μP(r|C) |T| + μ r∈Q |Q|<label>(1)</label></formula><p>Where 𝑡𝑡𝑡𝑡 𝑟𝑟,𝑇𝑇 is the term frequency of query's term 𝑟𝑟 in tweet 𝑇𝑇 , and 𝜇𝜇 is the tunable smoothing parameter.</p><p>The collection frequency of a term is calculated as 𝑃𝑃(𝑟𝑟|𝐶𝐶) = 𝑐𝑐𝑡𝑡 𝑟𝑟 |𝐶𝐶| ⁄ , and it is independent of the query.</p><p>We also employed pseudo relevance feedback <ref type="bibr" coords="2,310.56,340.79,16.13,9.50" target="#b12">[13]</ref>, which has been shown to be an effective strategy to improve the performance of retrieval systems. PRF assumes the top fbDocs documents in the original ranked list to be relevant to the query, and then uses these documents to select some meaningful terms to expand the original query. Finally, the result retrieved by the expanded query would be better than the previous one. For simplicity, we just adopted Indri's Relevance Model <ref type="bibr" coords="2,494.72,389.02,12.29,9.50" target="#b5">[6]</ref> for expansion term selection. In this model, all terms in the feedback documents are ranked according to the probability 𝑃𝑃(𝑟𝑟|𝐼𝐼), which means how likely the term 𝑟𝑟 would be generated from the query 𝑄𝑄. Then the top ranked fbTerms terms will be selected to expand the original query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P(r|Q) =</head><p>∑ P(r|T)P(Q|T)P(T)</p><formula xml:id="formula_1" coords="2,288.24,450.23,190.48,22.66">D P(Q)<label>(2)</label></formula><p>Score decay. Considering tweet's real time characteristic, the longer the time after its creation, the less importance it should have. We added a decay factor with half-life ℎ to each score calculated, the half-life means for how long time the score will be decayed with only one half of the initial score left. The decay factor was modeled exponentially.</p><formula xml:id="formula_2" coords="2,245.40,562.72,233.32,12.50">Score(t) = Score 0 • e -(t-t 0 ) τ ⁄<label>(3)</label></formula><p>Where 𝑆𝑆𝑐𝑐𝑆𝑆𝑟𝑟𝑆𝑆 0 and 𝑡𝑡 𝑆𝑆 are the initial score and time, 𝜏𝜏 is a model parameter related to half time ℎ as equation 4</p><formula xml:id="formula_3" coords="2,284.04,624.35,194.68,10.70">h = τ • ln2<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Threshold Selection.</head><p>After giving each tweet a score, the second step is aimed at picking out those most relevant tweets whose scores are above a meticulously calculated threshold. We will describe our techniques used for threshold adaptation in this section.</p><p>In adaptive filtering systems, the method of score distribution for dissemination threshold selection has shown exceptional effectiveness <ref type="bibr" coords="3,251.73,98.39,11.43,9.50" target="#b1">[2,</ref><ref type="bibr" coords="3,267.47,98.39,12.51,9.50" target="#b9">10]</ref>. This method assumed a Gaussian distribution for the scores of relevant documents and an exponential distribution for the scores of non-relevant documents. Figure <ref type="figure" coords="3,120.85,122.51,5.28,9.50">1</ref> illustrates how the Gaussian distribution fits relevant documents' scores of Topic 24 in this year's track, and figure <ref type="figure" coords="3,189.86,134.63,5.28,9.50">2</ref> illustrates the non-relevant documents' case. We can't estimate the parameters of these two distributions directly because unlike adaptive filtering, we have no relevance judgments when generating the result of Microblog search. There is a solution for this problem in <ref type="bibr" coords="3,173.41,381.95,12.27,9.50" target="#b6">[7]</ref> in the context of distributed retrieval. The Gaussian-Exponential score density model without relevance judgments can considered as mixture model and resolved by standard Expectation Maximization (EM) <ref type="bibr" coords="3,229.81,406.07,12.26,9.50" target="#b7">[8]</ref> algorithm. Equation 5 and 6 give the distribution densities of relevant and non-relevant documents' scores. Where 𝑥𝑥 is the document's score and 𝑅𝑅 is the judgment of the document's relevance to the query.</p><formula xml:id="formula_4" coords="3,243.60,453.20,235.12,30.02">P(x|R = 1) = 1 √2πσ e - (x-μ) 2 2σ 2<label>(5)</label></formula><formula xml:id="formula_5" coords="3,262.44,493.56,216.28,13.69">P(x|R = 0) = λe -λx<label>(6)</label></formula><p>Then the E-step and M-step of the EM algorithm could be described as follows E-step:</p><formula xml:id="formula_6" coords="3,216.96,555.40,261.76,27.05">P(R = 1|x i ) = P(R = 1)P(x i |R = 1) ∑ P(R = r)P(x i |R = r) 1 r=0<label>(7)</label></formula><formula xml:id="formula_7" coords="3,216.96,594.76,261.76,27.05">P(R = 0|x i ) = P(R = 0)P(x i |R = 0) ∑ P(R = r)P(x i |R = r) 1 r=0<label>(8)</label></formula><p>M-step:</p><formula xml:id="formula_8" coords="3,251.88,657.48,226.84,33.57">μ = ∑ P(R = 1|x i ) • x i |x| i=1 ∑ P(R = 1|x i ) |x| i=1<label>(9)</label></formula><formula xml:id="formula_9" coords="4,233.52,79.56,250.47,33.57">σ 2 = ∑ P(R = 1|x i ) • (x i -μ) 2 |x| i=1 ∑ P(R = 1|x i ) |x| i=1<label>(10)</label></formula><formula xml:id="formula_10" coords="4,252.12,124.96,231.87,30.05">λ = P(R = 0|x i ) ∑ P(R = 0|x i ) • x i |x| i=1<label>(11)</label></formula><formula xml:id="formula_11" coords="4,243.60,166.80,240.39,28.32">P(R = r) = ∑ P(R = r|x i ) |x| i=1 |x|<label>(12)</label></formula><p>We can get the posterior probability 𝑃𝑃(𝑅𝑅 = 𝑟𝑟|𝑥𝑥 𝑖𝑖 ) for each document's score when the parameters of the mixture model have been estimated. Intuitively speaking, the relevant documents tend to have a score with posterior probability 𝑃𝑃(𝑅𝑅 = 1|𝑥𝑥 𝑖𝑖 ) &gt; 𝑃𝑃(𝑅𝑅 = 0|𝑥𝑥 𝑖𝑖 ), together with equations above and a series of mathematic derivation, we could get 𝑥𝑥 𝑖𝑖 &gt; 𝜃𝜃 where</p><formula xml:id="formula_12" coords="4,258.72,273.28,225.27,131.82">θ = � b -√∆ a if ∆&gt; 0 +∞ if ∆&lt; 0 (13) ∆= b 2 -ac (14) a = 1 σ 2 (15) b = μ σ 2 + λ<label>(16)</label></formula><formula xml:id="formula_13" coords="4,255.00,415.24,228.99,66.90">ρ = P(R = 1) P(R = 0) (17) c = μ 2 σ 2 -2log ( ρ λ√2πσ )<label>(18)</label></formula><p>Recent work shows that Gamma distribution would be a more proper fit of the non-relevant documents' scores <ref type="bibr" coords="4,170.50,505.67,11.18,9.50" target="#b8">[9]</ref>. However, there is no closed form solution for parameter estimation of Gamma distribution so numerical method is needed. We kept Exponential distribution for simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In this section, we briefly describe the experimental environment we used to produce our submissions at first, and then we presented the evaluation results of our submitted runs. Finally, we will discuss more about our methods and results by conducting more experimental runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data.</head><p>We downloaded about 1.16 million tweets but the number of tweets used for indexing was only about 6 million. Those types of tweets considered as noise and thus filtered are described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>The null tweets are tweets without any content, and will be judged as non-relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>The tweets downloaded with a redirected HTTP code 302 are considered as retweets and removed as they would be judged as non-relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>There is another type of retweet with sign "RT" in their contents. Although the description before "RT" is considered as the tweet's novel information, it is so little that we consider them as noise.  This year's track is focused on English, so all the non-English tweets are judged as noise. Table <ref type="table" coords="5,117.58,134.63,5.28,9.50" target="#tab_0">1</ref> gives the number of each type of noise. Note that the number of each type of noise was calculated after the previous type of noise was filtered. For example, the number of 302-Retweets was calculated in the residual collection after the Null Tweets were removed. We did a quick and dirty preprocessing to the collection after the noisy tweets were removed, including stem and stopword removing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Measure.</head><p>The standard measure in this year's track is the precision of the top 30 results for each query, i.e. P@30. We also provided Mean Average Precision (MAP) and R-Precision for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Constraints.</head><p>We didn't use any future or external resources in our experiments, even for the web pages linked by the URLs in the tweets' content. All of our experiments satisfied the strict real-time search conditions. Tweets were dynamically indexed so all the retrieved tweets were guaranteed to be created before the incoming of the query, and the words' statistics like IDF were calculated without any future evidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results and discussion</head><p>We submitted two runs in this year's track. These two runs only differed in the scoring step, with one run (hitWIt) used the basic language model scoring function and the other run (hitWId) had the score decay factor incorporated.</p><p>We retrieved at most 2,000 tweets for each query in the scoring step, and then the EM algorithm was executed with the scores of these tweets in order to determine the re-ranking threshold. We will discuss more about the effectiveness of the threshold automatically selected later.</p><p>The number of pseudo feedback documents fbDocs was 20, number of terms selected from the feedback documents for query expansion fbTerms was 10. The smoothing parameter 𝜇𝜇 in language model was 20. The parameter 𝜏𝜏 in the score decay model was 7 days.</p><p>Table <ref type="table" coords="5,127.12,560.60,5.28,9.50" target="#tab_1">2</ref> gives the evaluation results of our submissions compared with the disjunctive baseline run provided on the track's page1. But unexpectedly, our run with score decay factor performs worse than the run without it. We considered the reason of the inferior result of hitWId as an inappropriate selection of decay parameter 𝜏𝜏 and conducted more runs to justify the effect of score decay factor. We kept other parameters constant and obtained several results based on different values of 𝜏𝜏.</p><p>From figure <ref type="figure" coords="6,155.05,135.21,5.28,9.50">3</ref> we can easily find out that our choice of 𝜏𝜏 in the run hitWId was far away from the optimal value. The performance of runs with score decay are able to outperform or at least equal to the run without score decay (hitWIt) when 𝜏𝜏 is greater than 40 days. The optimal performance is achieved when 𝜏𝜏 is equal to 90 days (the run BestDecay), and it outperforms the run hitWIt, as shown in table <ref type="table" coords="6,512.17,171.92,3.96,9.50" target="#tab_2">3</ref>.</p><p>We will also investigate the effectiveness of our threshold selection method deeper. We conducted runs with threshold fixed manually that gives exact 𝑡𝑡 documents for each query, i.e. we use a top-t manner threshold. We compare the performances of these runs with the automatically selected threshold run hitWId.</p><p>The comparison result is show in figure <ref type="figure" coords="6,286.75,232.51,3.96,9.50">4</ref>. The run with adaptive threshold selection method constantly outperforms other runs in both MAP and R-Precisio. Obviously, the maximal value of P@30 is achieved when 𝑡𝑡 is set as 30, but the other two measurements (MAP and R-Precision) are not optimal in this situation.</p><p>The average number of documents returned for each query of hitWIt is 95. But the performance of the run Fixedt95 with a fixed number of 95 documents returned for each query is apparently worse than hitWIt, as shown in table <ref type="table" coords="6,220.44,305.10,3.96,9.50" target="#tab_2">3</ref>. It means that when the same number of documents for the query set is returned, the result generated with adaptive threshold selection algorithm is significantly better than the one with threshold set as a fixed value for all queries.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Outlook</head><p>We described our participation in TREC 2011 Microblog track. We submitted two runs both generated through a three-step procedure including scoring, threshold selection and re-ranking. These two runs differed only in the first step that documents in one run were scored by the basic language modeling approach, and the other incorporated a score decay factor. We computed a re-ranking threshold for each query with the documents scored in the first step, through the score distribution method. It models the relevant documents' scores as Gaussian distribution and the non-relevant documents' scores as Exponential distribution, and then the threshold is calculated as the intersection of the curves of these two distributions. Finally, we re-rank the documents with scores higher than the threshold reverse chronologically, as required by this year's track. Both of our submissions greatly outperform the disjunctive baseline run. With a meticulously tuned decay parameter, the performance of our run with score decay factor could be better than the basic language model run. We also demonstrated the effectiveness of our adaptive threshold selection method by comparing our automatically selected threshold run to those runs with threshold set manually as an identical value to each query. The comparison result shows that the performance of the run with the adaptive threshold selection method is constantly superior in both MAP and R-Precision to those runs with manually set threshold. It also demonstrates that the threshold selection method significantly outperforms fixing threshold manually in all three measurements when the number of documents returned for all queries is the same.</p><p>We also tried a document prior before we submitted our runs. The prior was calculated by the information in the collection <ref type="bibr" coords="7,213.79,267.47,15.84,9.50" target="#b10">[11]</ref>, like the number the tweet was retweeted, the number the tweet was replied and the influence of the tweet's user <ref type="bibr" coords="7,279.20,279.47,16.33,9.50" target="#b10">[11,</ref><ref type="bibr" coords="7,298.53,279.47,12.51,9.50" target="#b11">12]</ref>. But unfortunately this prior brought nothing but huge noise made the performance inferior. We abandoned this run in our submission. We didn't investigate too much about the reason of this prior's poor performance, so an attempt to advance this idea may be an interesting future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,90.00,335.13,164.39,8.10;3,337.81,335.13,181.83,8.10;3,94.71,156.65,211.25,170.08"><head>Fig. 1 . 2 .</head><label>12</label><figDesc>Fig. 1. Density of relevant document scores Fig. 2. Density of non-relevant document scores</figDesc><graphic coords="3,94.71,156.65,211.25,170.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,90.00,621.81,195.39,8.10;6,337.80,621.81,150.57,8.10;6,94.71,443.34,211.25,170.08"><head>Fig. 3 . 4 .</head><label>34</label><figDesc>Fig. 3. Comparison with different decay parameter Fig.4. Comparison with fixed threshold</figDesc><graphic coords="6,94.71,443.34,211.25,170.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,90.00,183.21,407.28,51.28"><head>Table 1 . Number of different type of tweets</head><label>1</label><figDesc></figDesc><table coords="5,90.00,200.39,407.28,34.10"><row><cell>#Total</cell><cell>#Null</cell><cell>#302-</cell><cell>#RT-</cell><cell>#Non-English</cell><cell>#Indexed</cell></row><row><cell>Tweets</cell><cell>Tweets</cell><cell>Retweets</cell><cell>Retweets</cell><cell>Tweets</cell><cell>Tweets</cell></row><row><cell>16,141,812</cell><cell>1,204,053</cell><cell>1,068,257</cell><cell>1,528,385</cell><cell>6,368,274</cell><cell>5,952,843</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,148.08,597.93,315.83,76.72"><head>Table 2 . Result of submitted runs and the disjunctive baseline run</head><label>2</label><figDesc>Both of our submitted runs have statistical significant improvements over the disjunctive baseline run.</figDesc><table coords="5,148.08,615.23,315.83,59.42"><row><cell cols="3">Measure All Relevance Judgments</cell><cell cols="2">High Relevance Judgments</cell></row><row><cell>Run</cell><cell>P@30 MAP</cell><cell cols="2">R-Precision P@30 MAP</cell><cell>R-Precision</cell></row><row><cell>hitWIt</cell><cell cols="2">0.3973 0.3189 0.3777</cell><cell cols="2">0.1354 0.2405 0.2551</cell></row><row><cell>hitWId</cell><cell cols="2">0.3340 0.2727 0.3395</cell><cell cols="2">0.1263 0.2259 0.2392</cell></row><row><cell cols="3">Baseline 0.0986 0.1411 0.1486</cell><cell cols="2">0.0384 0.1616 0.1419</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,137.76,353.73,336.52,76.84"><head>Table 3 . Comparison with runs of best decay paramter τ = 90 and fixed threshold 𝐭𝐭 = 95</head><label>3</label><figDesc></figDesc><table coords="6,213.36,371.03,185.39,59.54"><row><cell>Measure</cell><cell cols="2">All Relevance Judgments</cell></row><row><cell>Run</cell><cell>P@30 MAP</cell><cell>R-Precision</cell></row><row><cell cols="3">BestDecay 0.3993 0.3194 0.3783</cell></row><row><cell>hitWIt</cell><cell cols="2">0.3973 0.3189 0.3777</cell></row><row><cell>Fixedt95</cell><cell cols="2">0.3429 0.2878 0.3538</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,95.28,711.57,166.43,8.10"><p>http://trec.nist.gov/act_part/tracks.new11.html</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,103.44,372.21,418.65,8.10;7,101.38,383.13,393.56,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,212.16,372.21,210.64,8.10">A Language Modeling Approach to Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,439.54,372.21,82.55,8.10;7,101.38,383.13,367.49,8.10">Proceeding of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>eeding of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,102.81,394.17,419.28,8.10;7,101.37,405.22,420.65,8.10;7,101.38,416.13,20.38,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,313.97,394.17,208.12,8.10;7,101.37,405.22,105.72,8.10">Incrementality, Half-life, and Threshold Optimization, for Adaptive Document Filtering</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Koster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Van Der Weide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,223.06,405.22,222.22,8.10">Proceeding of the Nineth Text Retrieval Conference (TREC-9</title>
		<meeting>eeding of the Nineth Text Retrieval Conference (TREC-9</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="12" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,103.41,427.18,418.63,8.10;7,101.37,438.22,208.53,8.10" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,298.15,427.18,223.88,8.10;7,101.37,438.22,96.28,8.10">Indri: A Language-Model Based Search Engine for Complex Queries (extended version)</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>CIIR Technical Report</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.56,449.14,416.49,8.10;7,101.37,460.18,420.72,8.10;7,101.38,471.22,54.80,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,280.65,449.14,224.93,8.10">Formal Multiple-Bernoulli Models for Language Modeling</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,101.37,460.18,420.72,8.10;7,101.38,471.22,28.91,8.10">Proceeding of the 27th annual international ACM SIGIR Conference on Research and Development in information retrieval</title>
		<meeting>eeding of the 27th annual international ACM SIGIR Conference on Research and Development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,104.13,482.14,417.93,8.10;7,101.38,493.18,420.68,8.10;7,101.37,504.23,103.04,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,196.16,482.14,325.90,8.10;7,101.38,493.18,31.61,8.10">A Study of Smoothing Methods for Language Models Applied to Ad Hoc Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,148.64,493.18,373.41,8.10;7,101.37,504.23,76.97,8.10">Proceeding of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>eeding of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,103.28,515.14,418.76,8.10;7,101.35,526.19,317.01,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,214.76,515.14,128.38,8.10">Relevance Based Language Models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,360.42,515.14,161.62,8.10;7,101.35,526.19,290.81,8.10">Proceeding of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>eeding of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,102.91,537.23,419.18,8.10;7,101.35,548.15,420.72,8.10;7,101.35,559.19,57.81,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,234.56,537.23,273.80,8.10">Modeling Score Distributions for Combining the Outputs of Search Engines</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rath</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,101.35,548.15,420.72,8.10;7,101.35,559.19,31.61,8.10">Proceeding of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>eeding of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,102.91,570.23,419.01,8.10;7,101.35,581.15,170.61,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,274.03,570.23,243.93,8.10">Maximum Likelihood from Incomplete Data Via the EM Algorithm</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,101.35,581.15,111.53,8.10">Journal of Royal Statist. Soc. B</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,102.92,592.19,419.07,8.10;7,101.36,603.23,191.47,8.10;7,292.92,601.30,5.04,5.40;7,303.36,603.21,218.62,8.10;7,101.40,614.13,163.05,8.10" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,277.88,592.19,244.11,8.10;7,101.36,603.23,85.23,8.10">Score Distribution Models: Assumptions, Intuition, and Robustness to Score Manipulation</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pavlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,208.65,603.23,84.19,8.10;7,292.92,601.30,5.04,5.40;7,303.36,603.21,218.62,8.10;7,101.40,614.13,136.86,8.10">Proceeding of the 33 rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>eeding of the 33 rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,108.96,625.17,408.43,8.10;7,517.32,623.26,4.80,5.40;7,101.40,636.22,393.60,8.10" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,203.40,625.17,215.39,8.10">Maximum Likelihood Estimation for Filtering Thresholds</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,437.79,625.17,79.60,8.10;7,517.32,623.26,4.80,5.40;7,101.40,636.22,367.53,8.10">Proceeding of the 24 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>eeding of the 24 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.76,647.13,414.29,8.10;7,101.40,658.18,54.81,8.10" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,269.84,647.13,156.72,8.10">Ranking Approaches for Microblog Search</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nagmoti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Teredesai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Cock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,443.96,647.13,60.37,8.10">Web Intelligence</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="153" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.52,669.22,414.74,8.10;7,101.40,680.14,291.69,8.10" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,242.06,669.22,213.91,8.10">TwitterRank: Finding Topic-Sensitive Influential Twitterers</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,471.74,669.22,50.53,8.10;7,101.40,680.14,265.03,8.10">Proceeding of the Third ACM International Conference on Web Search and Data Mining</title>
		<meeting>eeding of the Third ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,109.08,691.18,412.98,8.10;7,101.40,702.22,266.61,8.10" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,155.05,691.18,169.39,8.10">Relevance Feedback in Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rocchio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,343.58,691.18,178.49,8.10;7,101.40,702.22,117.54,8.10">The SMART Retrieval System: Experiments in Automatic Document Processing</title>
		<imprint>
			<publisher>Prentice-Hall Inc</publisher>
			<date type="published" when="1971">1971</date>
			<biblScope unit="page" from="313" to="323" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
