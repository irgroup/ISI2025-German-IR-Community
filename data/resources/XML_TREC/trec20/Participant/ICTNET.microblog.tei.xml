<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,189.53,81.89,211.85,14.04;1,401.35,79.17,4.48,9.00">ICTNET at Microblog Track TREC 2011 ‚Ä†</title>
				<funder ref="#_3jrCfWj #_t6n9Ka4">
					<orgName type="full">NSF of China</orgName>
				</funder>
				<funder ref="#_bCVpKjc #_Y8GmB4a">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,142.22,105.35,37.38,9.96"><forename type="first">Peng</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,192.77,105.35,44.54,9.96"><forename type="first">Jinhua</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,250.37,105.35,36.88,9.96"><forename type="first">Yubao</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,300.17,105.35,54.13,9.96"><forename type="first">Shenghua</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,362.47,105.35,28.60,9.96"><forename type="first">Yue</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,399.15,105.35,50.40,9.96"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,189.53,81.89,211.85,14.04;1,401.35,79.17,4.48,9.00">ICTNET at Microblog Track TREC 2011 ‚Ä†</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CB2634F98F5C44479AC9E127DD5D1BC3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The ICTNET group has participated in the Microblog track of TREC 2011. The main task is to search the messy tweets for those about a topic that is represented by a query. There are 50 queries, i.e. topics given for the track totally. Besides the topic description, a query time is also given for each query, indicating the exact time of the query issuance. The search is supposed to be conducted onsite, and those tweets later than the query time should not be returned. Furthermore, the issuers wishes to see the most recent but relevant information to the query. Hence, our system should answer a query by providing a list of relevant tweets ordered from newest to oldest, starting from the time the query was issued.</p><p>The existing related work about microblog is mainly focused on users <ref type="bibr" coords="1,386.35,291.93,7.51,8.96" target="#b0">[1]</ref><ref type="bibr" coords="1,397.62,291.93,7.51,8.96" target="#b1">[2]</ref>, information flow <ref type="bibr" coords="1,482.98,291.93,7.51,8.96" target="#b2">[3]</ref><ref type="bibr" coords="1,494.25,291.93,7.51,8.96" target="#b3">[4]</ref>, and tweets' content <ref type="bibr" coords="1,173.18,307.53,7.52,8.96" target="#b4">[5]</ref><ref type="bibr" coords="1,184.46,307.53,7.52,8.96" target="#b5">[6]</ref>. Our work is to query the tweets' content to find relevant, interesting, and fresh tweets. With exploring the features of tweets' content, hashtags, urls, post time etc., we employ SVM ranking model to rank our query results. The model is trained on pair-wise labeled data. Query extension both within tweets and external Wikipedia articles and Google search results are conducted by pseudo relevance feedback method and keywords extracting. In our experiment, 4 running results of 50 queries are collected on more than 5.6 million English tweets. There are 64.6% relevant tweets retrieved in less than 1000 returned results, and 449 relevant tweets are retrieved in top 30 according our ranking scores.</p><p>The rest of the report is organized as follows. Section 2 introduces the data preprocessing. Section 3 describes our main method to rank the search results namely the learning to rank. Section 4 shows the experiment results, and section 5 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Data preprocess</head><p>Only English tweets are considered in our work. With estimating the post time of the retweeted and removing those tweets in other languages, we then do the word stemming and stop word removing.</p><p>Besides, consecutively repeating one letter of a word becomes popular in tweets to express some emotions, such as "goooood", "tooooold", and etc. al. In such case, we simply reduce the times of the repeatness into 2 to map such expressions, and get "good", "toold" as their stems. Afterwards, urls and hashtags of a tweet are extracted out as another two features for the tweet. The "@" links in a tweet are not considered in our model, so "@" links are removed from the tweet content.</p><p>One of the most distinguishing features of tweets is that there are quite a bit of slangs and sloppiness words in them, which results in vocabulary mismatch problem. It is obvious that the mismatch problem may affect the query result, since a misspelled word cannot be hit by a correct query word. To solve this problem, we introduce a misspelling list which consists of the mappings from correct words to their commonly misspelled forms. We then extend each query with such a list, so tweets containing misspelled words can be hit in the search result. A Bayes-based model is used for building the misspelling list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Learning to Rank</head><p>The SVM rank is employed to train our ranking model. A query for tweets is described as a topic, which is more than a list of query words. So it becomes more important to mine the additional words around the topic, i.e. query extension. Afterwards, we proposed 6 features, including enhanced BM25, the times of retweetness, freshness, tweet length, the number of urls, and hashtags. With the 6 features and query extension, we train a SVM ranking model based on the labeled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Query extension</head><p>There are two ways for the query extension, internal extension and external extension. The internal extension indicates that we only use the corpus itself to extend our query, while the external extension can use the other web resources. If we query with the original query words, the top tweets that have the most ranking scores are more relevant to the topic described by the query. Therefore, the top-K tweets from the original query are used for extracting extension words. When viewing the top-K tweets as a document, the TF-IDF weight is employed to measure the extension words. For each query, we use Wikipedia and search engine such as Google to extent the query words. For each original description of query, we extract the keywords of the search results with TFIDF weight as the query extension. It is worth to mention that most of the words extended from the Wikipedia articles are the same to that from Google search. Besides, the misspelling list are also applied to the query extension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Features</head><p>We investigate 6 features to model the relevance, interestingness, and freshness. The elapsed time from posting to querying intuitively reflects the freshness. The length of a tweet is generally defined as the number of words after content cleansing and decomposition. Furthermore, the length of tweets must reflect the increment, so that the length of the left part after removing the original tweet is calculated for the retweeted ones. The other 4 features are described in the following, and the distributions of the features are studied as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Enhanced BM25</head><p>As for measuring the content relevance, we proposed a scoring method for tweets based on BM25.</p><p>Let Q be a query that consists of query words q 1 , q 2 , q 3 , ‚Ä¶ . In the BM25 model, the socre B(T i , Q) for tweet T i is calculated in the following way.</p><formula xml:id="formula_0" coords="2,204.91,504.70,191.12,31.06">1 1 1 ( , ) ( 1) ( , ) ( ) ( , )<label>(1 )</label></formula><formula xml:id="formula_1" coords="2,198.85,502.66,192.69,38.82">Q j i i j j i j i f q T k B T Q IDF q T f q T k b b avgtl ÔÄΩ ÔÄ´ ÔÄΩ ÔÄ´ ÔÄ≠ ÔÄ´ ÔÉ• ÔÅß ÔÅß ÔÅß ÔÅß</formula><p>where q j is the jth query word, |Q| is the total number of query words, avgtl is the average tweet length, and |T i | is the length of tweet T i . The function f(q j , T i ) indicates the frequency of the query word q j in tweet T i . The model parameters k 1 and b are 2.0 and 0.75 separately. IDF(q j ) is defined as follows.</p><p>ùêºùê∑ùêπ(ùëû ùëó ) = log ùëÅ -ùëõ ùëû ùëó + 0.5 ùëõ ùëû ùëó + 0.5</p><p>where ùëõ ùëû ùëó is the number of tweets that contain query word q j . It is seen that the score of a tweet matching two different words is the same to that of another matching the same word twice, if the two query words has the same IDF value. Since tweets are extremely short, the word frequency actually does not count much, and matching different query words makes much more sense. Therefore, we need a way to boost such a case. The enhanced BM25 finally defines as follows with boosting.</p><formula xml:id="formula_2" coords="2,202.69,715.72,191.47,25.05">1 , 1 1 1 ( , ) ( 1) ( , ) ( ) ( , )<label>(1 )</label></formula><formula xml:id="formula_3" coords="2,197.77,704.02,198.68,42.93">Q Q j i i j j i j j j i j i f q T k B T Q w IDF q h T f q T k b b avgtl ÔÄΩ ÔÄΩ ÔÉ¶ ÔÉ∂ ÔÉß ÔÉ∑ ÔÄ´ ÔÉß ÔÉ∑ ÔÄΩ ÔÉß ÔÉ∑ ÔÄ´ ÔÄ≠ ÔÄ´ ÔÉß ÔÉ∑ ÔÉ® ÔÉ∏ ÔÉ• ÔÉ• ÔÅß ÔÅß ÔÅß ÔÅß ÔÅß ÔÅß</formula><p>where w j is the weight of query word q j , and h j,i is a 0-1 binary that indicates whether query word q j hits tweet i. w j is used to measure the confidence that the extension query word q j belongs to the query topic. As for the misspelling extension, the edit distance divides the weight of the correct one. Simply, we give those original query words weight to be 5, and extension query word 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">The times of retweetness</head><p>In Twitter, the times of retweetness reflect the popularity of a tweet. We include those tweets that are exactly the same to the tweet, and contain "RT" followed by the tweet as a substring for the estimation of retweetness. It shows that the ratio of the tweets that have never been retweeted is about 94.96% in the corpus. Thus we only consider the tweets that are retweeted in the distribution. There are a large number of tweets that are retweeted once, while only a few have been retweeted more than 20 times.</p><p>The distribution for those retweeted follows the power law. And the retweetness feature is calculated as the following formula. ln (</p><formula xml:id="formula_4" coords="3,292.13,254.22,27.16,9.77">r i + 1 )</formula><p>where r i is the times of retweetness of tweet i. r i equals zero if it is not retweeted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Urls and hashtags</head><p>With the data preprocess, we got urls and hashtags extracted from the original tweet content. Since crawling the content of urls is not available, and may bring in the spam link content, we use the number of urls in each tweet as a feature. A tweet with urls usually contains more information than others. Thus the number of urls reflects the value of a tweet in our ranking model.</p><p>Hashtags are designed to reflect the topic of a tweet, so they are given much weight in the ranking model. Since a hashtag maybe a combination of several words, we simply use substring match, instead of whole word match as a query hits a hashtag. Similarly as the way we boost content match, the score is also boosted by multiplying the number of different query words got matched. Thus the feature score H i of hashtags for tweet i is calculated as follows.</p><p>, ,</p><p>)</p><formula xml:id="formula_6" coords="3,227.30,450.83,139.45,16.12">Q Q i j j i j i j j H IDF q h h ÔÄΩ ÔÄΩ</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ÔÄΩ ÔÉ• ÔÉ• ÔÅßÔÅß</head><p>where h j,i is a 0-1 binary that indicates whether query word q j hits the hashtages in tweet i. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Labeling</head><p>To train our ranking model, we need some acknowledged rank list for some queries which reflects the target of the Ad Hoc search. Unfortunately, the TREC committee does not provide such criteria. We then organized 8 well-trained graduate students in our lab to label the ranking list of several queries that are randomly picked from the 50 ones. As shown in Fig. <ref type="figure" coords="3,336.43,720.38,3.77,8.96" target="#fig_0">1</ref>, we build a labeling system to let people compare in pairs, and use the method of quick sort to form the final ranking list. So if we want to label a ranking list of length n, it costs O(logn) comparisons on average.</p><p>The labeling system looks like Fig 1 . For each query we ask volunteers to decide the 2 tweets namely T1 and T2, which one is better than anther. And we accumulate the result and rank the tweets to train a model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Evaluations</head><p>There are totally 16,141,812 tweets crawled according to the official seeds of TREC2011, and 5,650,490 English tweets are selected as the benchmark. 49 topics are tested. We submitted 4 different runs. In the 1 st run, ICTNET11MBR1, we only use internal query extension and misspelling list. The 2 nd run, ICTNET11MBR2, use takes logarithm of enhanced BM25 and different query weight, compare to the first one. The 3 rd run extends the queries with the keywords from related wiki articles and google search results, based on the first one. And the last run, ICTNET11MBR4, uses both future tweets and articles for query extension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table I. Experimental Results</head><p>Total Relevant retrieve @1000 -the total number of retrieved relevant tweets in the 1000 returned results. Total Relevant retrieve @30 -the total number of retrieved relevant tweets in the top 30 returned results of the labeled relevant tweets in the corpus. The column "best" gives the total number of the best retrieved tweets among all the team. And the column "submit" is our submission. It is need to mention that we misunderstood the real meaning returned results, and thought that it evaluates according to score sequence, instead of post time sequence. It is quite different in our ranking model. Thus we also evaluate the top 30 ranked tweets in our submission by ourselves, shown in column "submit@30". Nevertheless, the total number of retrieved tweets is 1850 while there is 2864 totally. In the "submit@30", the total number of retrieved tweets in top 30 is 449, while the total best is 899.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We propose 6 features to build the SVM Rank model, and by training on user labeled data, 4 runs are submitted with different query extensions and enhanced BM25 models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,245.93,634.58,103.57,8.96;3,139.92,494.62,316.87,130.31"><head>Figure 1</head><label>1</label><figDesc>Figure 1 Labeling System</figDesc><graphic coords="3,139.92,494.62,316.87,130.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,93.50,288.59,411.86,112.88"><head></head><label></label><figDesc>Table I illustrate the experimental results of our submission. The column "Official" gives the total number</figDesc><table coords="4,93.50,288.59,408.35,88.47"><row><cell cols="3">Total Relevant retrieve @1000</cell><cell cols="3">Total Relevant retrieve @30</cell><cell></cell><cell>MAP</cell><cell></cell><cell></cell><cell cols="2">R-precision</cell></row><row><cell>Official</cell><cell>submit</cell><cell>submit@30</cell><cell>best</cell><cell>submit</cell><cell>submit@30</cell><cell>best</cell><cell>submit</cell><cell>submit@30</cell><cell>best</cell><cell>submit</cell><cell>submit@30</cell></row><row><cell cols="2">Run1 2864 1839</cell><cell>--</cell><cell>899</cell><cell>67</cell><cell>440</cell><cell cols="2">0.51 0.10</cell><cell>0.15</cell><cell cols="2">0.61 0.10</cell><cell>0.20</cell></row><row><cell cols="2">Run2 2864 1593</cell><cell>--</cell><cell>899</cell><cell>63</cell><cell>348</cell><cell cols="2">0.51 0.09</cell><cell>0.12</cell><cell cols="2">0.61 0.08</cell><cell>0.17</cell></row><row><cell cols="2">Run3 2864 1845</cell><cell>--</cell><cell>899</cell><cell>67</cell><cell>449</cell><cell cols="2">0.51 0.10</cell><cell>0.14</cell><cell cols="2">0.61 0.09</cell><cell>0.20</cell></row><row><cell cols="2">Run4 2864 1850</cell><cell>--</cell><cell>899</cell><cell>59</cell><cell>416</cell><cell cols="2">0.51 0.10</cell><cell>0.14</cell><cell cols="2">0.61 0.08</cell><cell>0.19</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>‚Ä† This work is sponsored by <rs type="funder">NSF of China</rs> Grants No. <rs type="grantNumber">60903139</rs> and No. <rs type="grantNumber">60873243</rs>, and by <rs type="programName">863 Program</rs> of China Grants No. <rs type="grantNumber">2010AA012502</rs> and No. <rs type="grantNumber">2010AA012503</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_3jrCfWj">
					<idno type="grant-number">60903139</idno>
				</org>
				<org type="funding" xml:id="_t6n9Ka4">
					<idno type="grant-number">60873243</idno>
					<orgName type="program" subtype="full">863 Program</orgName>
				</org>
				<org type="funding" xml:id="_bCVpKjc">
					<idno type="grant-number">2010AA012502</idno>
				</org>
				<org type="funding" xml:id="_Y8GmB4a">
					<idno type="grant-number">2010AA012503</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,105.36,571.67,399.98,8.96;4,90.02,583.67,115.33,8.96" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,105.36,571.67,288.88,8.96">What is Twitter, a Social Network or a News Media? Haewoon Kwak</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<pubPlace>Changhyun Lee, Hosung Park, Sue Moon WWW</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,104.88,595.67,400.39,8.96;4,90.02,607.67,77.58,8.96" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="4,160.63,595.67,340.70,8.96">Finding Topic-sensitive Influential Twitters Jianshu Weng, Ee-Peng Lim, Jing Jiang</title>
		<author>
			<persName coords=""><surname>Twitterrank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Qi He WSDM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.14,619.70,399.61,8.96;4,90.02,631.70,402.10,8.96" xml:id="b2">
	<monogr>
		<title level="m" coord="4,105.14,619.70,399.61,8.96;4,90.02,631.70,288.23,8.96">Differences in the Mechanics of Information Diffusion Across Topics: Idioms, Political Hashtags, and Complex Contagion on Twitter Daniel M. Romero, Brendan Meeder</title>
		<imprint>
			<date type="published" when="2011">Jon Kleinberg WWW2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.12,643.70,400.27,8.96;4,90.02,655.70,72.85,8.96" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Jake</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Winter</forename><forename type="middle">A</forename><surname>Hofman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Duncan</forename><forename type="middle">J</forename><surname>Maso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Www</forename><surname>Watts</surname></persName>
		</author>
		<title level="m" coord="4,105.12,643.70,192.51,8.96">Who Says What to Whom on Twitter Shaomei</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,108.74,667.70,396.69,8.96;4,90.02,679.70,210.15,8.96" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="4,108.74,667.70,396.69,8.96;4,90.02,679.70,27.99,8.96">Earthquake Shakes Twitter Users: Real-time Event Detection by Social Sensors Takeshi Sakaki</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<pubPlace>Makoto Okazaki,Yutaka Matsuo WWW</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.00,691.70,400.48,8.96;4,90.02,703.70,44.61,8.96" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="4,105.00,691.70,173.00,8.96">Predicting the Future with Social Media[J]</title>
		<idno type="arXiv">arXiv:1003.5699</idno>
		<editor>S. Asur, B. A. Huberman</editor>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="report_type">Arxiv preprint</note>
</biblStruct>

<biblStruct coords="4,106.32,715.70,398.92,8.96;4,90.02,727.70,215.73,8.96" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<title level="m" coord="4,333.60,715.70,171.65,8.96;4,90.02,727.70,187.98,8.96">Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>the ACM Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>Training Linear SVMs in Linear Time</note>
</biblStruct>

<biblStruct coords="4,106.82,739.69,398.33,8.96;4,90.02,751.69,303.85,8.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,164.54,739.69,223.83,8.96">Optimizing Search Engines Using Clickthrough Data</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,397.86,739.69,107.29,8.96;4,90.02,751.69,220.78,8.96">Proceedings of the ACM Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the ACM Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
