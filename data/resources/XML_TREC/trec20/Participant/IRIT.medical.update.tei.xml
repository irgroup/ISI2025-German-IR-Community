<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,161.64,118.02,292.06,11.81;1,141.12,135.90,332.98,11.81;1,282.12,153.90,51.11,11.81">IRIT at TREC 2011: Evaluation of query reformulation techniques for retrieving medical records</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,251.40,192.67,41.01,9.13"><forename type="first">Duy</forename><surname>Dinh</surname></persName>
							<email>duy.dinh@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">IRIT laboratory -Paul Sabatier University</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>31062</postCode>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,300.72,192.67,63.22,9.13"><forename type="first">Lynda</forename><surname>Tamine</surname></persName>
							<email>lynda.tamine@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">IRIT laboratory -Paul Sabatier University</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>31062</postCode>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,161.64,118.02,292.06,11.81;1,141.12,135.90,332.98,11.81;1,282.12,153.90,51.11,11.81">IRIT at TREC 2011: Evaluation of query reformulation techniques for retrieving medical records</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B92D8BCB308355392B1CF8670151E0DD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Term Weighting Models</term>
					<term>Query Expansion</term>
					<term>Query Removal</term>
					<term>Medical Record Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In TREC 2011, we are motivated to participate in the medical record retrieval task, namely TRECMed. Our research focused on the evaluation of term weighting models and query expansion techniques within the medical record retrieval task. We compared the performance of different state-of-the-art term weighting models for retrieving patient records that might best suit the clinical information need. Afterwards, we evaluate different state-of-the-art query expansion (QE) techniques within an IR framework. We describe the IR system architecture and how we carried out the TREC experiments, and we present effectiveness results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In TREC 2011, we focused on two main features of information retrieval (IR), especially for biomedical IR: (1) term weighting, and (2) query reformulation. We first investigate the effectiveness of three different state-of-the-art term weighting models that have been shown to work well in the past: the well-established BM25 model <ref type="bibr" coords="1,196.92,547.86,9.99,9.13" target="#b0">[1]</ref>, the Divergence From Randomness model namely In expB2 (Inverse Expected Document Frequency model with the Bernoulli ratio normalisation) <ref type="bibr" coords="1,171.72,571.75,10.56,9.13" target="#b1">[2]</ref> and the log-logistic model namely LGD (a log logistic model) <ref type="bibr" coords="1,467.28,571.75,9.99,9.13" target="#b2">[3]</ref>. Next, we experiment with three different state-of-the-art query expansion algorithms implemented in the Terrier IR platform <ref type="bibr" coords="1,342.12,595.75,9.99,9.13" target="#b3">[4]</ref>.</p><p>The remainder of this paper is organized as follows: Section 2 describes our indexing and retrieval framework. Experimental results will be presented and discussed in section 3. Section 4 gives a conclusion of our participation in TRECMed 2011.</p><p>2 Indexing and retrieval framework Our indexing and retrieval framework is based on an open source search engine, which has been widely used for research in IR. More specifically, we used the Terrier IR platform <ref type="bibr" coords="2,223.92,168.30,10.56,9.13" target="#b3">[4]</ref> for indexing and retrieving documents in the collection of patients' visits. Each visit contains a set of reports related to a particular patient. In the pre-processing stage, we combined all reports of each patient into a single TREC-like document to obtain a single patient record as the unit of the retrieval.</p><p>The indexing aims to organize, structure and store statistical and/or linguistic information about terms and documents in the collection allowing a rapid and efficient search. During the indexing stage, stop-words are removed from documents before stemming using the Porter algorithm <ref type="bibr" coords="2,379.56,263.95,9.99,9.13" target="#b4">[5]</ref>.</p><p>The document retrieval aims to match the user query and document representations in order to retrieve a list of results that may satisfy the user information need. In our work, a document D containing terms used for formulating query Q is weighted by summing the score of each term figuring in document D:</p><formula xml:id="formula_0" coords="2,239.76,335.35,240.86,19.94">RSV (D, Q) = t∈Q score(t ∈ D)<label>( 1 )</label></formula><p>where score(t ∈ D) is the query term weight calculated using a particular term weighting model. For evaluating the performance of current state-of-the-art weighting models, we chose three different term weighting models used in our experiments, namely BM25 <ref type="bibr" coords="2,246.12,403.99,9.99,9.13" target="#b0">[1]</ref>, In expB2 <ref type="bibr" coords="2,305.04,403.98,10.56,9.13" target="#b1">[2]</ref> and LGD <ref type="bibr" coords="2,361.80,403.98,9.99,9.13" target="#b5">[6]</ref>. We then applied several state-of-the-art pseudo-relevance feedback techniques using statistical measures such as the Bose-Einstein (Bo) statistics <ref type="bibr" coords="2,323.52,427.87,10.56,9.13" target="#b1">[2]</ref> and the Kullback-Leibler divergence <ref type="bibr" coords="2,161.88,439.87,10.56,9.13" target="#b6">[7]</ref> in order to select most related terms for enriching the original query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The BM25 model</head><p>In the BM25 weighting model, the RSV of a document D for a query Q is:</p><formula xml:id="formula_1" coords="2,186.96,509.05,293.62,23.45">RSVBM25(D, Q) = t∈Q (k1 + 1) * tf n K + tf n * (k3 + 1) * qtf k3 + qtf * w (1)<label>(2)</label></formula><p>where</p><p>• tf n is the normalized within-document term frequency given by:</p><formula xml:id="formula_2" coords="2,258.12,583.38,218.26,25.82">tf n = tf (1 + b) + b * dl avg dl , (<label>3</label></formula><formula xml:id="formula_3" coords="2,476.38,590.10,4.25,9.13">)</formula><p>where tf is the within-document term frequency, dl and avg dl are respectively the document length and average document length, • k 1 , k 3 and b are tuning parameters, for which the default values are k 1 = 1.2, k 3 = 8.0, b = 0.75,</p><formula xml:id="formula_4" coords="3,141.72,120.30,157.92,9.81">• K is k 1 * ((1 -b) + b * dl/avg dl),</formula><p>• qtf is the within-query term frequency,</p><p>• w (1) is the idf (inverse document frequency) factor computed as:</p><formula xml:id="formula_5" coords="3,261.84,165.67,214.54,23.06">w (1) = log 2 N -N t + 0.5 N t + 0.5 (<label>4</label></formula><formula xml:id="formula_6" coords="3,476.38,172.38,4.25,9.13">)</formula><p>where N is the total number of documents (or cardinality) in the collection, and N t is the number of documents containing term t (also called as document frequency).</p><p>In the BM25 model, if N &lt; 2N t , i.e., term t is quite frequent in the collection, then t is assigned with a negative score in a particular document D because w (1) &lt; 0. In order not to penalize such terms, we just ignored them by giving a zero score when calculating the RSV(D, Q).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The In expB2 model</head><p>For the In expB2 model, query terms are weighted using the Inverse Expected Document Frequency model with Bernoulli after-effect and term frequency normalisation <ref type="bibr" coords="3,183.00,350.10,9.99,9.13" target="#b1">[2]</ref>. Formally, the RSV of a document D for a query Q is:</p><formula xml:id="formula_7" coords="3,197.28,370.22,283.35,32.67">RSV In expB2 (D, Q) = t∈D qtf × (tf +1)×tf n2 Nt×(tf n2+1)×ln2 × log 2 N +1 N ×(1-e -tf N )+0.5<label>(5)</label></formula><p>where t is a query term occurring in document D, -N t is the document frequency, -N is the total number of documents in the collection, -qtf is the query term frequency, -tf is the within-document term frequency, -tf n 2 is the normalised within-document term frequency, given by:</p><formula xml:id="formula_8" coords="3,237.84,507.78,242.79,22.69">tf n 2 = tf ln2 × log 2 1 + c × avg dl dl<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">The LGD model</head><p>In the LGD model, query terms are weighted using the log logistic distribution <ref type="bibr" coords="3,134.76,580.50,9.99,9.13" target="#b5">[6]</ref>. Formally, the RSV of a document D for a query Q is:</p><formula xml:id="formula_9" coords="3,181.44,600.90,299.19,26.66">RSV LGD (D, Q) = t∈D qtf × log 2 ( N t N + tf n ) -log 2 ( N t N )<label>(7)</label></formula><p>where t is a query term occurring in document D, -N t is the document frequency (i.e., number of documents containing term t), -N is the total number of documents in the collection, -qtf is the query term frequency, -tf n is the normalised within-document term frequency, given by:</p><formula xml:id="formula_10" coords="4,247.44,188.94,229.26,22.69">tf n = tf × log 2 (1 + c × avg dl dl ) (<label>8</label></formula><formula xml:id="formula_11" coords="4,476.76,195.67,3.87,9.13">)</formula><p>where avg dl is the average document length (in tokens), dl is the document length (in tokens) and c is a multiplying factor or tuning parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Query expansion</head><p>The DFR framework employs a query expansion (QE) mechanism that is a generalisation of Rocchio's method <ref type="bibr" coords="4,272.64,297.30,9.99,9.13" target="#b7">[8]</ref>: terms in the top-ranked documents retrieved in the first stage are weighted using a particular DFR term weighting model. In general, the weight of a term of the expanded query q * derived from the original query q is obtained as follows:</p><formula xml:id="formula_12" coords="4,222.60,353.47,258.03,22.68">weight(t ∈ q * ) = qtf n + β * Inf o DF R M axInf o<label>(9)</label></formula><p>where qtf n is the normalised within-query term frequency,</p><formula xml:id="formula_13" coords="4,141.00,420.18,164.52,21.62">-M axInf o = arg t∈q * max Inf o DF R , -Inf o DF R</formula><p>is the term frequency in the expanded query induced by using a DFR model, that is:</p><formula xml:id="formula_14" coords="4,210.12,466.62,266.06,10.89">Inf o DF R = -log 2 P rob(F req(w|K)|F req(w|C)) (<label>10</label></formula><formula xml:id="formula_15" coords="4,476.18,466.62,4.45,9.13">)</formula><p>where Prob is the probability of obtaining a given within-query term frequency from the top-ranked documents retrieved in the first stage. In the DFR framework, several measures are used to compute this probability such as: Bose-Einstein (Bo) statistics and Kullback-Leibler (KL) measure <ref type="bibr" coords="4,447.48,524.82,9.99,9.13" target="#b1">[2]</ref>. The former gives the following term frequency normalisation: , where TotalFreq(X) is the total frequency of term t in X documents (e.g., top-ranked documents, or the whole collection).</p><formula xml:id="formula_16" coords="4,215.64,558.54,264.99,24.09">Info Bo = -log 2 Prob(Freq(w|K)|Freq(w|C)) = -log 2 ( 1 1+λ ) -Freq(w|K) * log 2 ( λ 1+λ )<label>(11)</label></formula><p>• β = 0.4 is the Rocchio's parameter. while the latter gives the following term frequency normalisation:</p><formula xml:id="formula_17" coords="5,206.52,164.70,88.31,12.46">Info KL = F req(w|K)</formula><p>T otalF req(K) * log 2 F req(w|K) * T otalF req(C) F req(w|C) * T otalF req(K)</p><p>We used the default settings in Terrier for indexing and retrieval, for example the parameter b = 0.75 for term weighting using the BM25 model, c = 1.0 for the In expB2 <ref type="bibr" coords="5,178.56,214.26,10.56,9.13" target="#b1">[2]</ref> and LGD <ref type="bibr" coords="5,238.44,214.26,10.56,9.13" target="#b5">[6]</ref> models. For query expansion, we extracted 20 most representative terms from the top 20 ranked documents returned by the system from the first retrieval stage.</p><p>3 TRECMed submissions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Run description</head><p>We submitted four official runs to the TREC medical retrieval track. Our submitted runs are divided into two groups: the first one (2 runs) includes automatic runs and the second one (2 runs) includes manual runs. For each group of runs, we aim to evaluate the performance of state-of-the-art indexing and retrieval approaches compared to the performance of those enhanced with query expansion techniques. The description of the four submitted runs are as follows:</p><p>• IRIT a1 -This run scored documents w.r.t a query using the In expB2 model <ref type="bibr" coords="5,182.28,408.18,9.99,9.13" target="#b1">[2]</ref>, with c set to 5.0. The purpose of this run was to evaluate the performance of a state-of-the-art IR approach • IRIT a1QE1 -This run scored documents w.r.t a query using the In expB2 model <ref type="bibr" coords="5,180.36,444.06,10.56,9.13" target="#b1">[2]</ref> (c = 5.0) and enhanced with a Rocchio's query expansion technique using the Bo1 model <ref type="bibr" coords="5,244.32,455.95,9.99,9.13" target="#b1">[2]</ref>. The purpose of this run was to evaluate the utility of query expansion for IR. • IRIT m1 -This run was similar to the first run with the exception that some "redundant terms" such as "patient", "who" (which of course are not present in the stop-word list) are manually removed from the query. The purpose of this run was to evaluate the impact of redundant terms in the query on the IR performance. • IRIT m1QE1 -The last run was similar to the second run but with the exception that some "redundant terms" are removed from the query. In addition, we employed the Bo1 model <ref type="bibr" coords="5,319.92,563.58,10.56,9.13" target="#b1">[2]</ref> for query expansion. The purpose of this run was to evaluate the impact of query expansion and query removal on the IR performance.</p><p>For automatic runs, we use the default term processing pipeline in Terrier: stop-words are removed from documents and queries before stemming using the Porter algorithm <ref type="bibr" coords="5,210.60,633.42,9.99,9.13" target="#b4">[5]</ref>. For manual runs, we further removed query terms that are not present in the stop-word list but that we believe are not quite informative. For example, in the query "Patients with hearing loss", the term "with" is recognized as a stop-word and is therefore automatically removed from documents/queries. However, the term "patients" is not a stop-word term but is not quite informative because the main subject matter of the query is "hearing loss" which includes "patients" as the retrieval unit. Therefore, the term "patients" is considered as redundant information, which can be a reason of the query drift problem in IR. Therefore, it should be removed from the query. In this section, we will demonstrate the reason why such redundant terms should be removed from the query while representative terms should be used to enrich the semantics of the query.</p><p>In what follows, we present the results of our official runs submitted to TRECMed 2011. Afterwards, we present the results obtained by experimenting with several state-of-the-art weighting models across different query expansion algorithms in the Terrier IR platform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Official results</head><p>Table <ref type="table" coords="6,162.00,310.50,4.98,9.13" target="#tab_0">1</ref> shows the official results of our runs submitted to TRECMed 2011. According to the results, we observe that no significant performance gain is achieved in terms of MAP and P@X(x=10, 20) for both the automatic and manual runs with/without query expansion. Such obtained results may be influenced by the performance of the In expB2 model and the Bo1 query expansion model implemented in Terrier on the collection of medical records. Each of the record is composed of a set of single reports related to a particular patient. Using the same scenarios like runs submitted to TRECMed 2011 with the exception that the default configuration in Terrier is used (e.g., b=0.75, c=1.0), we further carried out the experiments with the two other state-of-the-art models namely BM25 <ref type="bibr" coords="6,163.68,430.03,10.56,9.13" target="#b0">[1]</ref> and LGD <ref type="bibr" coords="6,220.32,430.03,10.56,9.13" target="#b5">[6]</ref> across three query expansion models namely Bo1, Bo2 <ref type="bibr" coords="6,470.04,430.03,10.56,9.13" target="#b1">[2]</ref> and KL <ref type="bibr" coords="6,171.48,442.03,9.99,9.13" target="#b6">[7]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Unofficial results</head><p>First of all, we study the impact of removing non-informative terms from the query. Then, we aim to show the effectiveness of three query expansion models (Bo1, Bo2 and KL) on the TRECMed 2011 collection. Finally, we aim to show the utility of combining query removal and query expansion for IR.</p><p>Effectiveness of query removal for IR. As can be seen in table 2, the MAP results of the LGD model are slightly different from the BM25 model (0.3058 vs. 0.3182) without query removal (QR). However, the results in terms of P@x(x=10, 20) of the LGD model are dramatically better than the BM25 model (0.5118 vs. 0.4324 and 0.4103 vs. 0.3721). For query removal (QR), the conclusion is similar to the In expB2 model: no improvement is achieved when using the BM25 model. However, when applying the LGD model along with QR, we obtained an improvement of +10.76 % in terms of MAP, +1.72 % in terms of P@10 and +5.39 % in terms of P@20 over the baseline LGD (QR). The results in terms of MAP and P@x(x=10, 20) are even better than those obtained by the BM25 model with or without QR. Note that the LGD model is an informationbased model based on the log-logistic and smoothed power law <ref type="bibr" coords="7,408.96,251.83,9.99,9.13" target="#b2">[3]</ref>. This method has shown high performances by focusing on modeling the notion of "burtiness" in IR <ref type="bibr" coords="7,161.28,275.70,9.99,9.13" target="#b5">[6]</ref>. This notion describes the behavior of words which tend to appear in bursts, i.e., once they appear in a document, they are more likely to appear again. For this reason, we retained the LGD model for the next experiments. Utility of combining query removal and query expansion for IR. Table <ref type="table" coords="7,475.56,478.02,4.98,9.13" target="#tab_2">3</ref> depicts the results obtained by the LGD model with and without query removal across three query expansion models on the TRECMed 2011. As we can see, the LGD model performs well when solely applying query removal (see table 2, run QR + LGD) or solely applying query expansion (cf. table 3, run QR + LGD + QE, where QE stands for Bo1, or Bo2 or KL). When combining QR and QE, the performance in terms of MAP and P@x(x=10, 20) are even better than solely applying QR as well as than solely applying QE. Indeed, the best MAP obtained by run QR+LGD +Bo1 is achieved at 0.3944. The best value of P@10 (resp. P@20) is obtained at 0.4794 (resp. 0.4912). Therefore, we conclude that combining QR and QE within an appropriate weighting model allows to improve the IR performance. QR aims at focusing on the main subject matters of the query while QE aims at enriching the modified query with more related terms which better describe the semantics of the query. The intuition underlying QR is that the more the subject matters of the query are determined (by removing non-informative terms), the more the returned documents are close to the query.</p><p>In addition, the combination of QR and QE aims at retrieving more relevant documents w.r.t a given query without losing the recall and the precision. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In TREC 2011, we participated in the TRECMed track, which is a medical record retrieval adhoc task. The underlying IR platform of our experiments is the Terrier search system. Our participation focused on the use of several IR models for term weighting as well as state-of-the-art query expansion models. The best results of our runs attest the effectiveness of combining query removal and query expansion for IR using a particular term weighing model, especially the most recent IR information-based model namely LGD.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,151.68,593.46,25.54,9.13;4,158.64,606.06,321.97,9.13;4,168.60,618.06,172.47,9.13;4,158.64,631.75,40.38,9.81;4,202.92,628.94,35.51,6.38;4,217.68,637.22,5.88,6.38;4,244.08,631.75,50.94,9.81;4,299.04,628.94,85.79,6.38;4,318.96,637.22,45.72,6.38"><head></head><label></label><figDesc>where• F req(w|K) (resp. F req(w|C)) is the the term frequency within the top ranked documents (resp. the collection) • λ Bo1 = Freq(w|C) N and λ Bo2 = TotalFreq(K) * Freq(w|C) TotalFreq(C)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,134.76,473.35,345.96,87.12"><head>Table 1 .</head><label>1</label><figDesc>IR effectiveness obtained by each run on the TRECMed 2011 collection.</figDesc><table coords="6,191.76,493.42,227.42,67.04"><row><cell>P P P P P P P Run Measure</cell><cell>bpref</cell><cell>MAP</cell><cell>P@10</cell><cell>P@20</cell></row><row><cell>IRIT a1</cell><cell>0.4283</cell><cell>0.3323</cell><cell cols="2">0.4824 0.4132</cell></row><row><cell>IRIT a1QE1</cell><cell>0.4283</cell><cell cols="3">0.3344 0.4882 0.3912</cell></row><row><cell>IRIT m1</cell><cell cols="2">0.4619 0.3323</cell><cell cols="2">0.4824 0.4132</cell></row><row><cell>IRIT m1QE1</cell><cell cols="4">0.4619 0.3344 0.4882 0.3912</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,134.76,333.66,345.85,89.04"><head>Table 2 .</head><label>2</label><figDesc>IR effectiveness obtained by using the BM25 and LGD models on TRECMed 2011 collection with/without query removal (QR)</figDesc><table coords="7,171.60,370.36,272.18,52.34"><row><cell cols="2">bpref</cell><cell cols="2">MAP</cell><cell cols="2">P@10</cell><cell cols="2">P@20</cell></row><row><cell>QR</cell><cell>QR</cell><cell>QR</cell><cell>QR</cell><cell>QR</cell><cell>QR</cell><cell>QR</cell><cell>QR</cell></row><row><cell cols="8">BM25 0.4301 0.4301 0.3182 0.3182 0.4324 0.4324 0.3721 0.3721</cell></row><row><cell cols="8">LGD 0.4329 0.4607 0.3058 0.3387 0.5118 0.5206 0.4103 0.4324</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,134.76,161.83,345.88,148.56"><head>Table 3 .</head><label>3</label><figDesc>bpref, MAP and P@10 results obtained by the LGD model across 3 query expansion (QE) models (Bo1, Bo2, KL) with/without query removal (QR) on TRECMed 2011 collection LGD 0.4954 0.3902 0.4779 0.3534 0.2323 0.3432 0.5441 0.4265 0.5265 QR + LGD 0.5311 0.4058 0.5086 0.3944 0.2496 0.3852 0.5794 0.4441 0.5676</figDesc><table coords="8,144.36,208.00,320.52,102.38"><row><cell></cell><cell>bpref</cell><cell></cell><cell></cell><cell>MAP</cell><cell></cell><cell></cell><cell>P@10</cell><cell></cell></row><row><cell>Bo1</cell><cell>Bo2</cell><cell>KL</cell><cell>Bo1</cell><cell>Bo2</cell><cell>KL</cell><cell>Bo1</cell><cell>Bo2</cell><cell>KL</cell></row><row><cell>QR + TREC-best</cell><cell>0.5520</cell><cell></cell><cell></cell><cell>N/A</cell><cell></cell><cell></cell><cell>0.6560</cell><cell></cell></row><row><cell>TREC-second</cell><cell>0.5520</cell><cell></cell><cell></cell><cell>N/A</cell><cell></cell><cell></cell><cell>0.6030</cell><cell></cell></row><row><cell>TREC-third</cell><cell>0.5450</cell><cell></cell><cell></cell><cell>N/A</cell><cell></cell><cell></cell><cell>0.6030</cell><cell></cell></row><row><cell>TREC-fourth</cell><cell>0.5220</cell><cell></cell><cell></cell><cell>N/A</cell><cell></cell><cell></cell><cell>0.5440</cell><cell></cell></row><row><cell>TREC-median</cell><cell>0.4120</cell><cell></cell><cell></cell><cell>N/A</cell><cell></cell><cell></cell><cell>0.4760</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,138.32,492.97,342.22,8.21;8,146.88,503.89,244.72,8.21" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="8,358.27,492.97,122.28,8.21;8,146.88,503.89,130.18,8.21">Okapi at trec-7: Automatic ad hoc, filtering, vlc and interactive</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<editor>TREC.</editor>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="199" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.32,513.85,342.15,8.21;8,146.88,524.89,223.97,8.21" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,192.59,513.85,287.88,8.21;8,146.88,524.89,48.17,8.21">Probabilistic models for Information Retrieval based on Divergence from Randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>University of Glasgow</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="8,138.32,532.57,342.49,10.49;8,146.88,545.77,60.63,8.21" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,264.24,534.85,163.10,8.21">Information-based models for ad hoc IR</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clinchant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">É</forename><surname>Gaussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,452.32,534.85,28.48,8.21">SIGIR</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.32,555.85,342.32,8.21;8,146.88,566.77,333.77,8.21;8,146.88,577.69,52.16,8.21" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,249.70,555.85,230.94,8.21;8,146.88,566.77,154.09,8.21">Research directions in terrier. Novatica/UPGRADE Special Issue on Web Information Access</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C V</forename><surname>Lioma</surname></persName>
		</author>
		<editor>Ricardo Baeza-Yates et al.</editor>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>Invited Paper</note>
</biblStruct>

<biblStruct coords="8,138.32,587.77,342.19,8.21;8,146.88,598.69,183.77,8.21" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="8,218.51,587.77,132.39,8.21">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<biblScope unit="page" from="313" to="316" />
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.32,606.37,342.31,10.49;8,146.88,619.69,270.51,8.21" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,260.76,608.65,219.88,8.21;8,146.88,619.69,101.03,8.21">Retrieval constraints and word frequency distributions a log-logistic model for ir</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clinchant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">É</forename><surname>Gaussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,254.97,619.69,87.01,8.21">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="25" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.32,629.65,342.32,8.21;8,146.88,640.57,230.63,8.21" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="8,324.22,629.65,152.53,8.21">Introduction to Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schtze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.32,650.65,318.41,8.21" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rocchio</surname></persName>
		</author>
		<title level="m" coord="8,209.87,650.65,179.28,8.21">Relevance Feedback in Information Retrieval</title>
		<imprint>
			<date type="published" when="1971">1971</date>
			<biblScope unit="page" from="313" to="323" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
