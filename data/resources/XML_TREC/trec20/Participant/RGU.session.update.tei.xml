<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.77,116.95,327.82,12.62">RGU-ISTI-Essex at TREC 2011 Session Track</title>
				<funder ref="#_CKNT7Ke #_tKTwTne">
					<orgName type="full">EPSRC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,136.43,154.62,79.45,8.74"><forename type="first">Ibrahim</forename><surname>Adeyanju</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IDEAS Research Institute</orgName>
								<orgName type="institution" key="instit2">The Robert Gordon University</orgName>
								<address>
									<postCode>AB25 1HG</postCode>
									<settlement>Aberdeen</settlement>
									<country key="GB">Scotland, UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,226.44,154.62,94.87,8.74"><forename type="first">Franco</forename><forename type="middle">Maria</forename><surname>Nardini</surname></persName>
							<email>francomaria.nardini@isti.cnr.it</email>
							<affiliation key="aff1">
								<orgName type="department">Istituto di Scienza e Tecnologie dell&apos;Informazione &quot;A. Faedo&quot;</orgName>
								<orgName type="institution">Consiglio Nazionale delle Ricerche</orgName>
								<address>
									<addrLine>Via G. Moruzzi, 1</addrLine>
									<postCode>56124</postCode>
									<settlement>Pisa</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,331.86,154.62,78.49,8.74"><forename type="first">M-Dyaa</forename><surname>Albakour</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science and Electronic Engineering</orgName>
								<orgName type="institution">University of Essex</orgName>
								<address>
									<addrLine>Wivenhoe Park</addrLine>
									<postCode>CO4 3SQ</postCode>
									<settlement>Colchester</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,420.90,154.62,50.78,8.74"><forename type="first">Dawei</forename><surname>Song</surname></persName>
							<email>d.song]@rgu.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IDEAS Research Institute</orgName>
								<orgName type="institution" key="instit2">The Robert Gordon University</orgName>
								<address>
									<postCode>AB25 1HG</postCode>
									<settlement>Aberdeen</settlement>
									<country key="GB">Scotland, UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.08,166.58,70.10,8.74"><forename type="first">Udo</forename><surname>Kruschwitz</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science and Electronic Engineering</orgName>
								<orgName type="institution">University of Essex</orgName>
								<address>
									<addrLine>Wivenhoe Park</addrLine>
									<postCode>CO4 3SQ</postCode>
									<settlement>Colchester</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.77,116.95,327.82,12.62">RGU-ISTI-Essex at TREC 2011 Session Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">98DA3BE4194052953149B5D4B48815EA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Search shortcuts</term>
					<term>Session track</term>
					<term>TREC 2011</term>
					<term>Query logs</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Mining query recommendation from query logs has attracted a lot of attention in recent years. We propose to use query recommendations extracted from the logs of a web search engine to solve the session track tasks. The runs are obtained by using the Search Shortcuts recommender system. The Search Shortcuts technique uses an inverted index and the concept of "successful sessions" present in a web search engine's query log to produce effective recommendations for both frequent and rare/unseen queries. We adapt the above technique as a query expansion tool and use it to expand the given queries for Session Track at TREC 2011. The expansion is generated by using a method which aims to consider all past queries in the session. The expansion terms obtained are then used to build a global, uniformly weighted, representation of the user session (RL2). Furthermore, the expansion terms are then combined with a ranked list of results in order to boost terms appearing more frequently in the final results lists (RL3). Finally, we also integrate dwell times and the weighting method obtained taking both result lists and clicks into account for assigning weights to the terms to expand the final query of the session. In addition to that, we submitted a baseline run. It is based on the observation that using the term "wikipedia" to expand the query resulted in a better retrieval performance for the tasks at last year's session track at TREC 2010.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Session Track, introduced at the Text REtrieval Conference (TREC) 2010, aims to evaluate the ability of search engines to use previous user interactions in order to provide better results for subsequent queries in a user session thereby guiding a user to find relevant information faster. Last year participants were given query sessions containing only two queries and no interaction data. This year, the session track provided more interactive data to the participants. Query sessions were collected from real users and contained a variable number of queries and interaction data such as the documents displayed to the user, the clicked documents and dwelling times.</p><p>Session track 2011 provided another opportunity for us to propose a couple of techniques to improve the retrieval performance over user sessions. We submitted one baseline run and two other runs that make use of the Search Shortcuts (SS) <ref type="bibr" coords="2,157.45,227.84,10.52,8.74" target="#b1">[2]</ref> query recommendation technique. The two runs (apart from baseline) exploit the effectiveness of SS in producing query recommendations. SS is a query recommendation technique that make use of successful sessions (i.e., sessions ending with at least a click on the last query) present in a query log to produce suggestions. The technique is not only generally efficient and very effective but also works well for queries in the long tail of the distribution <ref type="bibr" coords="2,402.98,287.62,9.96,8.74" target="#b1">[2]</ref>.</p><p>The SS technique is able to use "session" information to devise recommendations for a given query. This is practically due to the organization of the knowledge model which makes use of an inverted index for computing recommendations. For each current query of the given sessions, we produce its relative recommendations. Furthermore, we use them to expand the current query with the terms composing them. We study different ways of expand the query with the terms obtained. First, we combine the current query with the terms produced by the SS recommender system by uniformly weighting them (RL2). Second, we use the ranked lists of results provided for each session as a way to boost terms that appears more frequently in the result lists (RL3). The last list (RL4) of the two runs makes use of dwelling time and available clicks on the result lists for assigning weights to the terms to expand the current query of the session.</p><p>The rest of the paper is structured as follows. Section 2 gives a brief description of the Session Track tasks for this year. We introduce the methodology used in building our runs in Section 3 and discuss the dataset and the resources used in our runs in Section 4. Details of our experiments and runs submitted to TREC appear in Section 5 with the evaluation results are discussed in Section 6. Finally, a brief conclusion is given in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Session Track 2011 Tasks</head><p>The main difference in this year task compared to the last year is that more interactive data is provided to the participants. Participants are provided with a set of query sessions. Each session consists of the current query q m and the user interactive data prior to the current query. These data includes: (a) the set of past queries in the session q 1 , q 2 , . . ., q m-1 , (b) the ranked list of URLs for each past query, (c) the set of clicked URLs/snippets and the time spent by the user reading the corresponding to each clicked url webpage.</p><p>Participants are tasked to run their retrieval system over the current query using the four criteria enumerated below.</p><p>1. ignoring the session data prior to the current query (RL1), 2. considering only the item (a) above, i.e. the queries prior to the current query (RL2), 3. considering only the items (a) and (b) above, i.e. the queries prior to the current along with the ranked lists of URLs and the corresponding web pages (RL3), 4. considering only the items (a), (b) and (c) above, i.e the queries prior to the current, the ranked lists of URLs and the corresponding web pages and the clicked URLs and the time spent on the corresponding web pages (RL4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Search Shortcuts Recommender System</head><p>A search session is an interactive process where users continuously refine their search query in order to better specify their information need. Sometimes, the successful query is not known in advance, but users might adopt concepts and terminologies on the basis of the results pages visited. The SS model we used was firstly proposed in <ref type="bibr" coords="3,236.98,344.81,10.52,8.74" target="#b0">[1]</ref> and then effectively designed in <ref type="bibr" coords="3,392.10,344.81,9.96,8.74" target="#b1">[2]</ref>. Let U be the set of users of a Web search engine whose activities are recorded in a query log QL, and Q be the set of queries in QL. We suppose QL is preprocessed by using some session splitting methods (e.g. <ref type="bibr" coords="3,299.41,380.68,10.52,8.74" target="#b4">[5,</ref><ref type="bibr" coords="3,311.59,380.68,7.75,8.74" target="#b7">8]</ref>) in order to extract query sessions, i.e., sequences of queries which are related to the same user search task. We say that a session σ is successful if and only if the user has clicked on at least one link shown in the result page returned by the search engine for the final query σ n and unsuccessful otherwise. The SS algorithm <ref type="bibr" coords="3,228.13,440.46,10.52,8.74" target="#b1">[2]</ref> works by efficiently computing similarities between partial user sessions (the one currently being performed) and historical successful sessions recorded in a query log. Final queries of most similar successful sessions are suggested to users as search shortcuts. Let σ be the current session performed by the user, and let the sequence τ be the concatenation of all terms with possible repetitions appearing in σ t| , i.e. the head of length t of session σ . Then, the algorithm computes the value of a scoring function δ (τ, σ s ), which for each successful session measures the similarity between its queries and the set of terms τ . Intuitively, this similarity measures how much a previously seen session overlaps with the user need expressed so far (the concatenation of terms τ serves as a bag-of-words model of user need). Sessions are ranked according to δ scores and from the subset of the top ranked sessions, it is possible to suggest their final queries. It is obvious that depending on how the function δ is chosen the algorithm provides different recommendation. In the original paper, authors opted for δ to be the similarity computed as in the BM25 metrics <ref type="bibr" coords="3,462.33,609.29,14.61,8.74" target="#b11">[12]</ref>. An IR-like metric takes care of words that are discriminant in the context of the session to which we are comparing. BM25, and other IR-related metrics, have been designed specifically to account for that property in the context of query/documents similarity.  Here, a previous user whose final query was "caesars palace" had a successful session; that is, the user clicked on at least one of the results returned by the search engine for the final query. We can therefore reduce search/ refinement duration of a new user by suggesting the final query from the previous successful session with identical queries. As shown in the figure, rather than allowing the user to refine the initial query to "hotels pool" and "las vegas hotel", "caesars palace" is more likely to direct the user to a landing page with more relevant results thereby creating another successful session.</p><p>The idea described above is translated into the following process. For each unique final query q f contained in successful sessions authors define a virtual document identified by its title and its content. The title, i.e., the identifier of the document, is exactly the query string q f . The content of the virtual document is instead composed of all the terms that have appeared in queries of all the successful sessions ending with q f . At the end of this procedure, a set of virtual documents is obtained; one for each distinct final query occurring in some successful sessions. All virtual documents are indexed with the preferred Information Retrieval system, and generating shortcuts for a given user session σ is simply a matter of processing the query σ t| over the inverted file indexing of such virtual documents. The processing of queries over inverted indexes is very fast and scalable, and these important characteristics are inherited by our query suggestion technique as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>The ClueWeb09 dataset 1 is a web crawl of more than a billion pages that was first used in TREC 2009 Web track. The ClueWeb09 category B dataset is a subset of the larger ClueWeb09 crawl and it consists of 50 million English pages. In this year Session Track's tasks, participants were permitted to use either one of the two datasets. An existing Indri<ref type="foot" coords="5,293.55,142.33,3.97,6.12" target="#foot_1">2</ref> index of the ClueWeb09 dataset is already available and searchable via a public web service <ref type="foot" coords="5,342.50,154.28,3.97,6.12" target="#foot_2">3</ref> . The web service enabled us to issue queries and retrieve the top documents returned by the search engine, thus removing the burden of indexing the data internally. The Indri search engine <ref type="bibr" coords="5,470.08,179.77,10.52,8.74" target="#b6">[7,</ref><ref type="bibr" coords="5,134.77,191.72,12.73,8.74" target="#b9">10]</ref> uses language modelling probabilities and supports query expansion.</p><p>The expanded representations of queries are obtained by using the Microsoft RFP 2006 query log which was preliminarily preprocessed by converting all queries to lower-case, and removing stop-words and punctuation/control characters. The queries in the log were then sorted by user and time-stamp, and segmented into sessions on the basis of a splitting algorithm which simply groups in the same session all the queries issued by the same users in a time span of 30 minutes <ref type="bibr" coords="5,171.89,275.41,14.61,8.74" target="#b10">[11]</ref>. Noisy sessions, likely performed by software robots, were removed. The remaining entries correspond to approximately nine million (9M) sessions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Our Runs</head><p>Each group participating in the session track can submit a maximum of three different runs to TREC based on the tasks described in Section 2. Each submission file of the TREC Session Track 2011 consists of four different ranked lists, namely RL1, RL2, RL3, and RL4.</p><p>The current query q m was processed to produce q m following these steps:</p><p>1. removing the following punctuation marks ( ) , ? 2. removing stop words from a common list of English stop words that do not fall within quoted text. 3. replacing quotes with the corresponding Indri syntax #1(&lt;quoted text&gt;) e.g. "event planning" becomes #1(event planning) 4. replacing site specification with the corresponding Indri format, e.g. "female winemakers site:.com.au" becomes "female winemakers com.url au.url"</p><p>The maximum number of returned documents in the list has been limited to 1000. We also used the Waterloo Spam Rankings<ref type="foot" coords="5,346.00,497.08,3.97,6.12" target="#foot_3">4</ref> for the ClueWeb09 dataset to filter the spam documents from the returned ranked lists. We consider documents with scores of 70% or less as spam which is recommended by the creators of those rankings <ref type="bibr" coords="5,174.97,534.52,9.96,8.74" target="#b3">[4]</ref>.</p><p>In all the runs, we generate RL1 by simply submitting a preprocessed version of the current query q m to the Indri index, i.e. RL1 is equivalent to D q m . Generating RL2 this year is a similar task to generating RL3 in the previous year's task <ref type="bibr" coords="5,156.77,582.34,9.96,8.74" target="#b5">[6]</ref>. In our runs, we generate RL2 in different ways. The major challenge resides in generating RL3 and RL4. The sections below describe the techniques used for determining the other three runs of each submission, namely: RL2, RL3, RL4. All the runs are obtained by means of the Indri query language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">System 1 -Baseline (rguBase)</head><p>The first system we propose is the rguBase baseline. This baseline has been produced by expanding the current query of each session with the term "wikipedia". The rationale for this is that by doing so in Session Track 2010 <ref type="bibr" coords="6,420.57,163.87,9.96,8.74" target="#b8">[9]</ref>, we obtain better retrieval performance. This submission file thus contains only two runs: RL1, and RL2 as we would like to assess only how the term "wikipedia" affect the overall retrieval performances of the given current query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">System 2 -Search Shortcuts (rguPisaSS)</head><p>The Search Shortcuts query recommender has been used as a query expansion technique. We build RL2 by using an expansion of the current query made by the terms composing the first three recommendations provided by the method and by uniformly weighting them after performing a stopword removal step. Furthermore, RL3 has been built starting by the first ten recommendations generated for each current query of the sessions provided. We use the terms composing them to produce an expanded query representation. In particular, after removing stopwords, we develop a term weighting scheme based on how many times any given expansion term appears in the snippets of the documents returned within the session. The final weight is thus computed by dividing the frequency of the single expansion term with the sum of the frequencies of the expansion terms over all the returned documents.</p><p>More formally, let E be the set of the expansion terms obtained by the recommendations produced by Search Shortcuts. Furthermore, let D be the set of documents returned for all the queries of the current user session. Let f D (t) be a function measuring the frequency of the term t ∈ E in the set of the snippets returned for the documents in D. The expansion weights of the term t used within RL3 is thus derived using Equation <ref type="formula" coords="6,324.42,452.87,3.87,8.74" target="#formula_0">1</ref>.</p><formula xml:id="formula_0" coords="6,258.73,473.32,221.86,24.72">w RL3 t = f D (t) ∀x∈E f D (x)<label>(1)</label></formula><p>#weight( 0.7 #combine(event planning college) 0.3 #weight(0.16 #combine(college) 0.01 #combine(fashion) 0.36 #combine(event) 0.4 #combine(planning) 0.01 #combine(conference) 0.05 #combine(online) 0.01 #combine(management)) )</p><p>Fig. <ref type="figure" coords="6,195.42,613.46,4.13,7.89">2</ref>. An example of an expanded query with Search Shortcuts.</p><p>To illustrate the expansion process, Figure <ref type="figure" coords="6,332.28,645.16,4.98,8.74">2</ref> shows a generated Indri query for session 2 (RL3). Note that for all the sessions and each ranked list we arbitrarily chose the values 0.7 and 0.3 for both components of the expansion, i.e., the original query and the weighted expansion set of terms produced by the Search Shortcuts method.</p><p>RL4 has been produced starting from the weights obtained for RL3 and by adding to the terms appearing in the snippets of the clicked documents a boosting factor. This boosting factor depends on the frequency (with repetitions) of the given term in the set of the clicked documents divided by the total frequency of the expansion terms that are present in the set of the clicked documents. More formally, let C be the set of the clicked documents for all the queries of the current user session. Clearly, C ⊆ D. w RL4 t can be thus computed by applying Equation <ref type="formula" coords="7,177.80,239.89,3.87,8.74" target="#formula_1">2</ref>.</p><formula xml:id="formula_1" coords="7,233.88,261.92,246.71,24.72">w RL4 t = w RL3 t + f C (t) ∀x∈E f C (x)<label>(2)</label></formula><p>Figure <ref type="figure" coords="7,180.59,294.27,4.98,8.74" target="#fig_1">3</ref> compares the expansion weights for session 63 across RL3 and RL4. It can be observed that the boosting factor increases the weights of some expansion terms while reducing the weights of others with respect to their RL3 weights after normalisation. Thus, in this example the RL4 weights of "court" and "judge" are boosted due to their frequency in the set of clicked documents. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">System 3 -Search Shortcuts with Time (rguPisaSST)</head><p>In the rguPisaSST run, we build RL2 by using an expansion of the current query made by the terms composing the first three recommendations provided by the method and by uniformly weighting them after performing a stopwords removal step. Furthermore, RL3 has been built starting by the first ten recommendations generated for each current query of the sessions provided. We use the terms composing them to produce an expanded query representation. In particular, we remove stopwords and we develop a term weighting scheme based on how much any given expansion term appears in the snippets of the documents returned within the session. As in the previous case, RL3 can be computed by applying Equation <ref type="formula" coords="7,177.80,657.11,3.87,8.74" target="#formula_0">1</ref>.</p><p>This run differs from the previous one on how we build the RL4 query. We produce RL4 by adding to the weights produced for RL3 a new weight obtained by exploiting the dwell time of each clicked document. The new weight measures how much a clicked document has been visualized by the user. We do this on a term basis. We thus select a candidate expansion term, we check if it is part of the snippet of one or more clicked documents and we compute its weight as a sum of its dwelling time within the session divided by the total dwelling time of all the documents within the session. We then sum the weights obtained to the weights referring to RL3. Finally, we normalize over all the expansion terms to obtain a set of weights that sum to one. More formally, let T be the set of documents that have been visualized for all the queries of the current user session. Clearly, T ⊆ C. In addition, let f T (t) be a function measuring the total dwelling time of the term t ∈ E. f T (t) works by computing the sum of the dwelling time of the documents in T for the term t (i.e. containing t in their snippets). Each f T (t) is then normalized by using the sum over all the terms x ∈ E as shown in Equation <ref type="formula" coords="8,134.77,299.32,3.87,8.74" target="#formula_2">3</ref>.</p><formula xml:id="formula_2" coords="8,234.10,321.45,246.50,24.72">w RL4 t = w RL3 t + f T (t) ∀x∈E f T (x)<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Discussion</head><p>Tables <ref type="table" coords="8,166.27,393.36,4.98,8.74" target="#tab_1">1</ref> and<ref type="table" coords="8,194.31,393.36,4.98,8.74" target="#tab_2">2</ref> summarize the nDCG and nDCG@10 results for our three runs with significant test data as well as the maximum, median and minimum across all the session track participants. These results (for nDCG@10) are also charted without significance test in the graphs in Figures <ref type="figure" coords="8,353.87,429.23,4.98,8.74" target="#fig_2">4</ref> and<ref type="figure" coords="8,382.04,429.23,3.87,8.74" target="#fig_3">5</ref>. This year, NIST assessors provided relevance assessments on two different criteria; thus, the results in Table <ref type="table" coords="8,173.59,453.14,4.98,8.74" target="#tab_1">1</ref> take into account the subtopics for all queries, whereas the results in Table <ref type="table" coords="8,162.16,465.09,4.98,8.74" target="#tab_2">2</ref> only reflect the current (last) query's subtopics. Each of the table columns represent the normalised discounted cumulative gain (nDCG) for each result list submitted. Despite receiving a variety of eight relevance metrics which includes Expected Reciprocal Rank (ERR) <ref type="bibr" coords="8,438.93,501.33,9.96,8.74" target="#b2">[3]</ref>, Average Precision <ref type="bibr" coords="8,195.70,513.28,15.50,8.74" target="#b13">[14]</ref> and Graded Average Precision (GAP) <ref type="bibr" coords="8,385.02,513.28,15.50,8.74" target="#b12">[13]</ref> among others, we will focus our results analysis on the nDCG results, as they relate to the established metrics from last year's TREC session track. The tables are split in two, the top half using the nDCG metric for all the documents submitted and the bottom showing the nDCG score using only the first ten returned documents (nDCG@10).</p><p>The arrows in the RL2, RL3 and RL4 columns represent the relative improvement or decline in the nDCG scores between the results lists for a given system (row), with a double arrow up (⇑) or down (⇓) indicating that a two tail t-test has supported the result as significantly better or worse. We use the horizontal double edge arrow (↔) to indicate equivalence of results. For instance an upward arrow (↑) in the RL2 column indicates that RL2 improves on RL1, and the first and second arrows in the RL3 column compare RL3 to RL1 and  RL3 to RL2 respectively. The following two sections outline the results obtained for baseline and SS systems, in cases where we do not explicitly refer to a result as significant it can be assumed that the comparison has returned a t-test value p &gt; 0.05.  The retrieval performance of RL2 is worse than RL1 for both evaluation with the last subtopic (Table <ref type="table" coords="10,226.16,633.20,4.43,8.74" target="#tab_2">2</ref>) and nDCG with all subtopics but improves slightly for nDCG@10 (see Table <ref type="table" coords="10,231.63,645.16,3.87,8.74" target="#tab_1">1</ref>). However, these results are better than those from the SS systems when a comparison is made across the column in both tables. This</p><p>shows that a lot of relevant documents were from the Wikipedia website and thus reinforces our previous results from last year's session track. Our baseline results are above the median results from all participants (see Figures <ref type="figure" coords="11,410.47,143.90,4.98,8.74" target="#fig_2">4</ref> and<ref type="figure" coords="11,437.99,143.90,4.43,8.74" target="#fig_3">5</ref>) despite the simplicity of this technique. The values of RL3 and RL4 are not applicable for this system because we did not submit any results for these criteria using Wikipedia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Expansion with Search Shortcuts (rguPisaSS &amp; rguPisaSST)</head><p>There is no significant difference when assessing with all subtopics or last query subtopics for both nDCG and nDCG@10 across RL1, RL2, RL3 and RL4. However considering all subtopics, RL4 was generally better than RL2 and RL3 but worse than RL1. Evaluation with nDCG@10 gave us better performance than nDCG for all subtopics as further interactive data are added (RL1 → RL4).</p><p>The only results that met our expectation, albeit slightly, was nDCG@10 for rguPisaSS and rguPisaSST using all subtopics. In this case, there were improvement in performance as more interactive data was incorporated into the systems. The SS systems were also above the median when compared to other systems as shown in Figures <ref type="figure" coords="11,220.19,337.18,4.98,8.74" target="#fig_2">4</ref> and<ref type="figure" coords="11,245.84,337.18,4.98,8.74" target="#fig_3">5</ref> when evaluated with nDCG@10. We only had a slight improvement from rguPisaSS to rguPisaSST at RL4 for both evaluations with the last and all subtopics. This indicates that incorporating the time did not really make a big difference, at least for our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper provided an overview of the experiments we carried out at the TREC 2011 Session Track. We proposed three different approaches to deal with the tasks introduced this year. While the first one is a pure baseline based on expanding the current query with the term "wikipedia", the last two approaches rely on expanding the current query with the recommendations produced by Search Shortcuts <ref type="bibr" coords="11,210.75,488.61,9.96,8.74" target="#b1">[2]</ref>, an effective query suggestion technique. The two runs with search shortcuts use different weighting schemes for expansion terms in different ways and depending on the type of available information (document snippets, dwell time, clicks, etc). We intend to improve the last two approaches further by optimising the weight of the expansion terms recommended by the Search shortcuts system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,204.31,289.41,206.74,7.89"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustration of the Search Shortcuts method</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,149.71,322.17,330.88,8.74;4,134.77,334.12,345.83,8.74;4,134.77,346.08,345.82,8.74;4,134.77,358.03,345.83,8.74;4,134.77,369.99,345.83,8.74;4,134.77,381.94,345.83,8.74;4,134.77,393.90,345.83,8.74;4,134.77,405.85,345.82,8.74;4,134.77,417.81,257.67,8.74;4,149.71,429.76,330.89,8.74;4,134.77,441.72,345.83,9.65;4,134.77,453.67,345.83,8.74;4,134.77,465.63,345.82,9.65;4,134.77,477.58,345.83,8.74;4,134.77,489.54,345.83,9.65;4,134.77,501.49,345.82,8.74;4,134.77,513.45,345.83,8.74;4,134.77,525.40,345.82,8.74;4,134.77,537.36,199.25,8.74;4,334.01,542.61,5.38,6.12;4,342.57,537.36,138.02,8.74;4,134.77,549.31,345.83,8.74;4,134.77,561.27,345.83,8.74;4,134.77,573.22,124.97,8.74"><head>Figure 3</head><label>3</label><figDesc>Figure3illustrates how the search shortcuts are utilized for query recommendation. Here, a previous user whose final query was "caesars palace" had a successful session; that is, the user clicked on at least one of the results returned by the search engine for the final query. We can therefore reduce search/ refinement duration of a new user by suggesting the final query from the previous successful session with identical queries. As shown in the figure, rather than allowing the user to refine the initial query to "hotels pool" and "las vegas hotel", "caesars palace" is more likely to direct the user to a landing page with more relevant results thereby creating another successful session.The idea described above is translated into the following process. For each unique final query q f contained in successful sessions authors define a virtual document identified by its title and its content. The title, i.e., the identifier of the document, is exactly the query string q f . The content of the virtual document is instead composed of all the terms that have appeared in queries of all the successful sessions ending with q f . At the end of this procedure, a set of virtual documents is obtained; one for each distinct final query occurring in some successful sessions. All virtual documents are indexed with the preferred Information Retrieval system, and generating shortcuts for a given user session σ is simply a matter of processing the query σ t| over the inverted file indexing of such virtual documents. The processing of queries over inverted indexes is very fast and scalable, and these important characteristics are inherited by our query suggestion technique as well.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="9,170.87,579.90,273.62,7.89;9,134.77,373.77,345.84,191.36"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Graphs showing nDCG@10 for evaluation with all subtopics</figDesc><graphic coords="9,134.77,373.77,345.84,191.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="10,155.73,565.16,303.91,7.89;10,134.77,366.84,345.84,183.55"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Graphs showing nDCG@10 for evaluation with last query subtopics</figDesc><graphic coords="10,134.77,366.84,345.84,183.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,134.77,116.91,345.95,224.38"><head>Table 1 .</head><label>1</label><figDesc>nDCG values when assessing over all subtopics; arrows indicate improvement(↑), decline (↓) or identical (↔) against previous results lists, first arrow in a cell relates to RL1, second arrow to RL2 and so on. Double arrows (⇑ / ⇓) indicates the comparison is statistically significant returning a two tailed t-test value &lt; 0.05.</figDesc><table coords="9,139.70,179.80,341.02,161.49"><row><cell>System</cell><cell>RL1.nDCG</cell><cell>RL2.nDCG</cell><cell>RL3.nDCG</cell><cell>RL4.nDCG</cell></row><row><cell>max</cell><cell>0.3433</cell><cell>0.3353</cell><cell>0.3993</cell><cell>0.4118</cell></row><row><cell>median</cell><cell>0.2804</cell><cell>0.2918</cell><cell>0.2363</cell><cell>0.2577</cell></row><row><cell>min</cell><cell>0.0937</cell><cell>0.0852</cell><cell>0.0000</cell><cell>0.0000</cell></row><row><cell>rguBase</cell><cell>0.2669</cell><cell>↓ 0.2594</cell><cell cols="2">Not Applicable Not Applicable</cell></row><row><cell>rguPisaSS</cell><cell>0.2669</cell><cell>↓ 0.2528</cell><cell>↓ ↑ 0.2561</cell><cell>↓ ↑ ↑ 0.2577</cell></row><row><cell>rguPisaSST</cell><cell>0.2669</cell><cell>↓ 0.2528</cell><cell>↓ ↑ 0.2561</cell><cell>↓ ↑ ↑ 0.2592</cell></row><row><cell></cell><cell cols="4">RL1.nDCG@10 RL2.nDCG@10 RL3.nDCG@10 RL4.nDCG@10</cell></row><row><cell>max</cell><cell>0.3789</cell><cell>0.4281</cell><cell>0.4307</cell><cell>0.4540</cell></row><row><cell>median</cell><cell>0.3232</cell><cell>0.3215</cell><cell>0.3259</cell><cell>0.3407</cell></row><row><cell>min</cell><cell>0.1510</cell><cell>0.1432</cell><cell>0.0000</cell><cell>0.0000</cell></row><row><cell>rguBase</cell><cell>0.3634</cell><cell>↑ 0.3763</cell><cell cols="2">Not Applicable Not Applicable</cell></row><row><cell>rguPisaSS</cell><cell>0.3634</cell><cell>↓ 0.3578</cell><cell>↑ ↑ 0.3735</cell><cell>↑ ↑ ↑ 0.3759</cell></row><row><cell>rguPisaSST</cell><cell>0.3634</cell><cell>↓ 0.3578</cell><cell>↑ ↑ 0.3735</cell><cell>↑ ↑ ↑ 0.3773</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,134.77,116.91,345.95,224.38"><head>Table 2 .</head><label>2</label><figDesc>NDCG values when assessing the last subtopic; arrows indicate improvement(↑), decline (↓) or identical (↔) against previous results lists, first arrow in a cell relates to RL1, second arrow to RL2 and so on. Double arrows (⇑ / ⇓) indicates the comparison is statistically significant returning a two tailed t-test value &lt; 0.05.</figDesc><table coords="10,139.70,179.80,341.02,161.49"><row><cell>System</cell><cell>RL1.nDCG</cell><cell>RL2.nDCG</cell><cell>RL3.nDCG</cell><cell>RL4.nDCG</cell></row><row><cell>max</cell><cell>0.3249</cell><cell>0.3170</cell><cell>0.34611</cell><cell>0.3565</cell></row><row><cell>median</cell><cell>0.2562</cell><cell>0.2463</cell><cell>0.2077</cell><cell>0.2169</cell></row><row><cell>min</cell><cell>0.0828</cell><cell>0.0737</cell><cell>0.0000</cell><cell>0.0000</cell></row><row><cell>rguBase</cell><cell>0.2432</cell><cell>↓ 0.2347</cell><cell cols="2">Not Applicable Not Applicable</cell></row><row><cell>rguPisaSS</cell><cell>0.2432</cell><cell>↓ 0.2244</cell><cell>↓ ↓ 0.2223</cell><cell>↓ ↑ ↑ 0.2248</cell></row><row><cell>rguPisaSST</cell><cell>0.2432</cell><cell>↓ 0.2244</cell><cell>↓ ↓ 0.2223</cell><cell>↓ ↑ ↑ 0.2260</cell></row><row><cell></cell><cell cols="4">RL1.nDCG@10 RL2.nDCG@10 RL3.nDCG@10 RL4.nDCG@10</cell></row><row><cell>max</cell><cell>0.2685</cell><cell>0.2954</cell><cell>0.2981</cell><cell>0.2971</cell></row><row><cell>median</cell><cell>0.2187</cell><cell>0.1888</cell><cell>0.1859</cell><cell>0.1927</cell></row><row><cell>min</cell><cell>0.0781</cell><cell>0.0631</cell><cell>0.0000</cell><cell>0.0000</cell></row><row><cell>rguBase</cell><cell>0.2301</cell><cell>↓ 0.2259</cell><cell cols="2">Not Applicable Not Applicable</cell></row><row><cell>rguPisaSS</cell><cell>0.2301</cell><cell>↓ 0.2117</cell><cell>↓ ↓ 0.2064</cell><cell>↓ ↓ ↑ 0.2079</cell></row><row><cell>rguPisaSST</cell><cell>0.2301</cell><cell>↓ 0.2117</cell><cell>↓ ↓ 0.2064</cell><cell>↓ ↓ ↑ 0.2109</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,144.73,657.79,187.87,7.86"><p>http://boston.lti.cs.cmu.edu/Data/clueweb09/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,144.73,635.88,137.04,7.86"><p>http://lemurproject.org/indri.php</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,144.73,646.84,299.77,7.86"><p>http://boston.lti.cs.cmu.edu:8085/clueweb09/search/cataenglish/lemur.cgi</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,144.73,657.79,184.16,7.86"><p>http://durum0.uwaterloo.ca/clueweb09spam/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This research is part of the AutoAdapt research project. AutoAdapt is funded by <rs type="funder">EPSRC</rs> grants <rs type="grantNumber">EP/F035357/1</rs> and <rs type="grantNumber">EP/F035705/1</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_CKNT7Ke">
					<idno type="grant-number">EP/F035357/1</idno>
				</org>
				<org type="funding" xml:id="_tKTwTne">
					<idno type="grant-number">EP/F035705/1</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="12,142.96,143.58,337.63,7.86;12,151.52,154.54,329.07,7.86;12,151.52,165.50,329.07,7.86;12,151.52,176.46,219.19,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,203.81,154.54,272.97,7.86">Search shortcuts: a new approach to the recommendation of queries</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Baraglia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Cacheda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Formoso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Perego</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Silvestri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,167.21,165.50,313.38,7.86;12,151.52,176.46,27.60,7.86">Proceedings of the third ACM conference on Recommender systems (Rec-Sys&apos;09)</title>
		<meeting>the third ACM conference on Recommender systems (Rec-Sys&apos;09)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="77" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,187.42,337.63,7.86;12,151.52,198.38,329.07,7.86;12,151.52,209.34,146.04,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,416.64,187.42,63.95,7.86;12,151.52,198.38,229.41,7.86">Generating suggestions for queries in the long tail with an inverted index</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Broccolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Marcon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Nardini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Perego</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Silvestri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,387.73,198.38,92.86,7.86;12,151.52,209.34,69.63,7.86">Information Processing and Management</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>IPM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,220.30,337.64,7.86;12,151.52,231.26,326.44,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,364.25,220.30,116.34,7.86;12,151.52,231.26,65.50,7.86">Expected reciprocal rank for graded relevance</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metlzer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Grinspan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,238.09,231.26,39.42,7.86">CIKM &apos;09</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="621" to="630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,242.21,337.64,7.86;12,151.52,253.17,329.07,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,336.70,242.21,143.89,7.86;12,151.52,253.17,146.79,7.86">Efficient and effective spam filtering and re-ranking for large web datasets</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,304.86,253.17,86.49,7.86">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="441" to="465" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,264.13,337.64,7.86;12,151.52,275.09,329.07,7.86;12,151.52,286.05,329.07,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,257.61,264.13,222.98,7.86;12,151.52,275.09,153.76,7.86">Beyond the session timeout: automatic hierarchical segmentation of search topics in query logs</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Klinkner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,324.06,275.09,156.53,7.86;12,151.52,286.05,219.45,7.86">Proceeding of the 17th ACM conference on Information and knowledge management (CIKM&apos;08)</title>
		<meeting>eeding of the 17th ACM conference on Information and knowledge management (CIKM&apos;08)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="699" to="708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,297.01,337.64,7.86;12,151.52,307.97,314.75,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,386.65,297.01,89.78,7.86">Session track overview</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,165.60,307.97,267.59,7.86">Proceedings of Nineteenth Text Retrieval Conference (TREC 2010</title>
		<meeting>Nineteenth Text Retrieval Conference (TREC 2010</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,318.93,337.63,7.86;12,151.52,329.89,158.47,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,265.74,318.93,135.23,7.86">Relevance based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,423.89,318.93,35.66,7.86">SIGIR&apos;01</title>
		<meeting><address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,340.84,337.63,7.86;12,151.52,351.80,329.07,7.86;12,151.52,362.76,329.07,7.86;12,151.52,373.72,140.03,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,414.07,340.84,66.52,7.86;12,151.52,351.80,170.12,7.86">Identifying taskbased sessions in search engine query logs</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lucchese</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Orlando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Perego</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Silvestri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Tolomei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,343.40,351.80,137.19,7.86;12,151.52,362.76,269.17,7.86">Proceedings of Third ACM International Conference on Web Search and Data Mining (WSDM&apos;11)</title>
		<meeting>Third ACM International Conference on Web Search and Data Mining (WSDM&apos;11)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="277" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,384.68,337.63,7.86;12,151.52,395.64,329.07,7.86;12,151.52,406.60,247.02,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,338.40,384.68,142.18,7.86;12,151.52,395.64,155.90,7.86">The use of domain modeling to improve performance over a query session</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lungely</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Albakour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Kruschwitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,327.95,395.64,152.65,7.86;12,151.52,406.60,184.39,7.86">Proceedings of the ECIR&apos;11 workshop on Information Retrieval Over Query Sessions</title>
		<meeting>the ECIR&apos;11 workshop on Information Retrieval Over Query Sessions</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,417.56,337.97,7.86;12,151.52,428.52,329.07,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,253.27,417.56,227.32,7.86;12,151.52,428.52,80.30,7.86">Combining the language model and inference network approaches to retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">W</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,238.08,428.52,164.79,7.86">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="735" to="750" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,439.47,337.98,7.86;12,151.52,450.43,329.07,7.86;12,151.52,461.39,329.07,7.86;12,151.52,472.35,213.25,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,264.66,439.47,211.81,7.86">Query chains: learning to rank from implicit feedback</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<idno type="DOI">10.1145/1081870.1081899</idno>
		<ptr target="http://doi.acm.org/10.1145/1081870.1081899" />
	</analytic>
	<monogr>
		<title level="m" coord="12,165.15,450.43,315.45,7.86;12,151.52,461.39,117.47,7.86;12,329.25,461.39,34.77,7.86">Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining</title>
		<meeting>the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="239" to="248" />
		</imprint>
	</monogr>
	<note>KDD &apos;05</note>
</biblStruct>

<biblStruct coords="12,142.62,483.31,337.98,7.86;12,151.52,494.27,319.13,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,273.82,483.31,206.77,7.86;12,151.52,494.27,26.99,7.86">The probabilistic relevance framework: Bm25 and beyond</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,186.09,494.27,198.56,7.86">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,505.23,337.98,7.86;12,151.52,516.19,329.07,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,326.43,505.23,154.16,7.86;12,151.52,516.19,78.58,7.86">Extending average precision to graded relevance judgments</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,250.05,516.19,35.66,7.86">SIGIR&apos;10</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="603" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,527.15,337.98,7.86;12,151.52,538.10,264.93,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,308.67,527.15,171.92,7.86;12,151.52,538.10,93.02,7.86">A simple and efficient sampling method for estimating ap and ndcg</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,266.00,538.10,39.61,7.86">SIGIR &apos;08</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="603" to="610" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
