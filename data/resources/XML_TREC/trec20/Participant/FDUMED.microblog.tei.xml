<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,206.51,81.18,198.96,12.64">Microblog TRACK 2011 of FDU</title>
				<funder ref="#_g9Fswpv #_a39E6QS">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_W3zrwZa #_qT69gEH">
					<orgName type="full">Doctoral Fund of Ministry of Education of China</orgName>
				</funder>
				<funder ref="#_KXMUwvE">
					<orgName type="full">Shanghai Science and Technology Development Funds</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,164.36,129.37,79.28,10.53"><forename type="first">Bingqing</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Fudan University Shanghai</orgName>
								<address>
									<postCode>200433</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,365.31,129.37,85.37,10.53"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
							<email>xjhuang@fudan.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Fudan University Shanghai</orgName>
								<address>
									<postCode>200433</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,206.51,81.18,198.96,12.64">Microblog TRACK 2011 of FDU</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C4B5E893D4E965DB49424B8B4354ECA0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Twitter provides huge amount of short messages, raises challenge problems to the research community. The Microblog Track of TREC detects the special behavior of the twitter dataset in the "real-time" retrieval task. This paper reports our participation in the Microblog Track task. Given the query topics, each participants are required to conduct a "real-time" retrieval task, which seeks for the most recent and interesting tweets for each query topic. Our focus in this task includes two aspects: (1)data preprocessing to remove non-English tweets, and (2)feature extraction for clustering the tweets into two categories. Given the huge interest in the microblog, there is lot of work to apply different linguist analysis techniques and data analysis methods to explore the behavior and special features in the Microblog sphere.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As a social network basically relied on text messages, Twitter, the microblog platform, produces millions of short messages and delivers those messages among the network interweaved by friends, colleagues, family members and many others. These short messages (or sometimes referred as status) provide updated news, offer useful information from coupon to job opportunities, express the blog holders' opinion and etc. Some special features such as "hash tag", "retweet" has attracted lots of attention from the research community. Research work are focused on different aspects such as how to normalize the tweet-language, label POS-tags for each word, identify Named Entities, analyze the opinions, explore the user graph, use the virtual social network data to predicate real-world events, etc.</p><p>With a strong interest in the microblog and social network, we took part in the TREC 2011 Microblog TRACK, so that we can explore and exploit some special features of the twitter.</p><p>This year, the Microblog Track proposed a "realtime" retrieval task, which requires the participants to seek for the most recent and interesting tweets for a query. The dataset Twitter2011 covers two-weeks tweets from Jan 23rd to Feb. 8th 2011. This task is aimed to stimulate the scenario when the users look for some tweets for the given query within that twoweek. Then, each test query topic is given a timestamp indicating what exact time that query is supposed to be submitted in that two weeks. The participants should only return the tweets posted before the query timestamp. The participants can use the external resources such as Wikipedia, the webpages, and the url in the tweets, but future information is not allowed in the "real-time" task, which including the whole dataset information such as IDF and other future evidence such as the Wikipedia explaining what the query is, but posted after the query timestamp.</p><p>This paper reports our participation into the Microblog track. To accomplish this task, we should face some problems such as identifying the language of the tweets, normalizing the tweets-language, and filter out irrelevant tweets and finding the "interesting" tweets.</p><p>We used multiple virtual machine instance to crawl all the dataset with the HTML crawler pro-vided by TREC. The job was accomplished within one day, which brings us a lot of benefit. Since the Twitter website would change their links to the tweets, it is better to collect the dataset in an early age. To identify the language of the tweets, we extracted the language tag from the HTML web pages, and used opensource language identification tool "TextCat" to identify the language. Normalizing the tweet-language is a lot of work. We tried some opensource dictionary-based tool such as "Jazzy" 1 , but got a limited normalization effect, which droves us to empirically normalize the tweets by rules. In the "real-time" scenario, we first find out all the tweets before the query timestamp, then generate two features from each tweets. One feature is the BM25 <ref type="bibr" coords="2,119.51,278.98,113.47,9.59" target="#b18">(Robertson, et al., 1999)</ref> weight formula, but in the "real-time" scenario, we calculate the "real-time" IDF value for each query word. The other feature is calculated by the SVD decomposition as the conventional collaborative filtering. Finally use kmeans++ to cluster these tweets, and retain those tweets that have higher BM25 score. In this way, we filter out some more tweets.</p><p>This paper is structured as follows. Section 2 gives an overview of the twitter dataset and data download process . Section 3 introduces the language identification process and the preprocessing steps. Section 4 introduces the method to find the relevant tweets. Section 5 reports the experiment results and give some discussion. And the conclusion is made in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Research work on the Microblog dataset are versatile, which we would like to classify them into the following categories. (1)Data Collection, which collect the data for a long period and gives an overview on the dataset, such as <ref type="bibr" coords="2,251.40,583.68,47.41,9.59;2,72.00,597.23,44.09,9.59">(Perovic,et al., 2010)</ref> <ref type="bibr" coords="2,116.09,597.23,93.81,9.59">(Yang, et al., 2011)</ref> (2) Elemetary linguistic analysis, such as lexical form normalization <ref type="bibr" coords="2,91.39,624.33,37.91,9.59" target="#b2">(Han and</ref><ref type="bibr" coords="2,132.09,624.33,117.38,9.59">Baldwin, 2011)(Brody and</ref><ref type="bibr" coords="2,252.25,624.33,41.39,9.59;2,72.00,637.88,44.60,9.59">Diakopoulos, 2011)</ref>, part-of-speech tagging <ref type="bibr" coords="2,228.54,637.88,70.25,9.59;2,72.00,651.43,23.48,9.59">(Gimpel, et al., 2011)</ref>, keyphrase extraction <ref type="bibr" coords="2,193.92,651.43,78.78,9.59">(Zhao, et al., 2011)</ref>. One obvious feature of Twitter is all kinds of out-ofvocabulary words such as initials, abbreviation, and other irregular form, to help the user express their 1 http://jazzy.sourceforge.net/ meaning within the 140 character limit. That is why the current research work focus on these elementary linguistic analysis work. (3) Linguistic application: such as sentiment analysis <ref type="bibr" coords="2,495.86,116.39,44.14,9.59;2,313.20,129.94,35.52,9.59">(Jiang, et al., 2011</ref><ref type="bibr" coords="2,348.72,129.94,135.17,9.59">)(Gonzalez-lbanez, et al., 2011</ref><ref type="bibr" coords="2,483.89,129.94,52.14,9.59;2,313.20,143.48,116.92,9.59">), classification(Qazvinian, et al., 2011</ref><ref type="bibr" coords="2,430.12,143.48,105.18,9.59" target="#b9">)(Zanzotto, et al., 2011)</ref>. Twitter contains lots of comments on the news, products, tv shows, movies, which provides a rich source for the researcher to analyze the users' opinions. (4) Social Graph <ref type="bibr" coords="2,403.55,197.68,102.71,9.59" target="#b10">(Meeder, et al., 2011)</ref> <ref type="bibr" coords="2,506.26,197.68,33.74,9.59;2,313.20,211.23,41.36,9.59" target="#b11">(Wu, et al., 2011)</ref>: researchers focus on the following and followed relation among the users. (5) Prediction: people use the data in the virtual microblog sphere to predict what will happen in the real world, for example, predicting the epidemics <ref type="bibr" coords="2,466.45,265.43,73.54,9.59;2,313.20,278.98,23.48,9.59" target="#b12">(Aramaki, et al., 2011)</ref>, predicting the gender of the user <ref type="bibr" coords="2,491.97,278.98,48.03,9.59;2,313.20,292.53,39.83,9.59" target="#b13">(Burger, et al., 2011)</ref>, predicting the investors( <ref type="bibr" coords="2,470.86,292.53,69.14,9.59;2,313.20,306.08,23.48,9.59" target="#b14">Bar-Haim, et al., 2011)</ref>, predicting the information credibility <ref type="bibr" coords="2,503.59,306.08,36.41,9.59;2,313.20,319.62,50.13,9.59">(Catillo, et al., 2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Twitter2011 Dataset</head><p>The dataset Twitter2011 is collected by each participant. The organizer provides the links in "Seed File", the participants restore these dataset from these seed files. One thing important for the participant is to download the dataset as soon as possible since the links in the website will not exist permanently. We collected the dataset using parallel virtual machine instances.</p><p>Seed File: each seed file contains about 10 thousand lines, each line contains the twitter users' name, the encoded tweet id, and the hashcode to verify that tweet. A url pointing to a real tweet can be recovered from these information, which can be used to download the tweet. There are 1670 seed files scattering in 17 days from Jan.23rd 2011 to Feb. 8th 2011.</p><p>Download Tool: The download tools provided by TREC have two versions, the JSCON version and the HTML version. The JSCON version require the user to have a registered twitter API on Twitter's whitepaper list, which allow the registered user to crawl 20000 tweets each hour. The JSCON version can provide complete information for each tweet, including the tweet content, the language, the following and followed information for that tweet, which is surely a good benefit for the researchers.</p><p>The HTML version could only extract the content and the posted timestamp for each tweet. However, the HTML version did not have a limit on the crawling speed. And the crawled html version tweets have the same html structure which makes it quite easy to clean the html tags and extract the meta data according to your needs. Another point should be noted is that the TREC download tool has a function to check the downloaded tweets and re-download those missing ones, which is quite helpful for us. We chose the HTML version of the download tool.</p><p>Crawler Setup: We setup 9 virtual instances to download the whole Twitter dataset, and let them work parallelly. Totally, for the 17 day's tweets and 9 virtual instances, we deployed 2 days tweets download work for 1 virtual instance, which would cost about 20 minutes to download the tweets for one seed file. Each instance would work about 24 hours. The original html downloaded data is kept in hadoop's sequence file format, which can be extracted easily with the TREC's download tools.</p><p>Data Statistics:</p><p>After downloading and amending the dataset, we got 16,141,812 Tweets, with 14081863 tweets for html response code 200, 1123076 tweets for response code 302, 243979 for response code 403, and 692894 tweets for response code 404. Finally, 15204939 tweets contain the real content, 936873 tweets are missing. The missing rate is 5.8%. This crawling job was done on June. 1st.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Language identification and Preprocessing</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Language Identification</head><p>Since we used the HTML crawling tool, we can not get the language information of each tweet. However, in the HTML web page, there is an html element which contains a feature indicating the language of this tweet. The element has the pattern "¡class= 'tweet-url screen-name" hreflang=", where the hreflang feature will show the language of the tweet user. This feature is not a precise one, but it can filter out some obvious non-English tweets, especially for Asia language such as Japanese, Korean. The statistics of the language tag is shown in Tab 1. English tweets is the majority of the Twitter2011 dataset. The second place goes to the Japanese lan- guage, followed by Spanish, whose amount seems to be less than half of the Japanese. But we doubt that Spanish's ratio should be higher, since many Spanish users would use English as the default language in the Twitter platform. About 67% twitter user's screen-name language is English, which we noted as Twitter2011Eng. In this filtered dataset, there are still a lot of non-English tweets. We used TextCat<ref type="foot" coords="3,466.78,392.37,3.99,7.01" target="#foot_0">2</ref> to identify the language of each tweet. TextCat has been reported showing good performance on the conventional news dataset <ref type="bibr" coords="3,371.85,435.04,120.12,9.59" target="#b19">(Cavnar and Trenkle, 1994)</ref>. It builds the character-level language model for each word, and calculate the score of each sentence by heauristic method. The user can control how many languages would this tool guess for one sentence. Since it is based on the language model, the user can select the models empirically or even train his own model. We used the default model attached in the toolkit and tuned the language the tool can output.</p><p>In order to evaluate the performance of this tool, we sampled some sentences from the filtered Twit-ter2011Eng dataset. 5000 tweets were sampled, and 250 tweets were annotated as English and non-English. The result is shown in Table . 2, which shows the balancing of the precision value and the recall value. Finally we set the parameter to be "a=30" and "u=1.07". And according to the 250 annotated tweets, 131 tweets are labeled as English, the ratio is 52.4%, which shows that there are still lots of non-English tweets after the first round </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Heauristic Preprocessing</head><p>Preprocessing of the Tweets include some problems:</p><p>(1) how to handle the user's tag such as "@Sophia", and the hash tag such as "#job", "#SocialMedia". (2) how to recognize the internet slang in the twitter language such as "lol"(laugh it loudly), "lmao"(laughing my ass off). ( <ref type="formula" coords="4,207.18,341.62,4.24,9.59">3</ref>) how to cope with those irregular long word such as "cccooooolll", ".......aha", "hahahaha".</p><p>We converted the user tag "@Sophia" to "-user-", remove the "#" symbol of the hashtag, recognize the url in tweets and converted it to "-url-". For those irregular words, at first we tried some dictionarybased tools to clean the data, for example Jazzy<ref type="foot" coords="4,291.59,437.57,3.99,7.01" target="#foot_1">3</ref> , Some simple spell corrector<ref type="foot" coords="4,194.88,451.12,3.99,7.01" target="#foot_2">4</ref> . For each OOV, Jazzy would rely on the morphology and the pronounciation of the OOV to generate top k most possible candidate word. However, such method is heavily relied on the dictionary you used, and the normalizing effect is far from satisfaction. For example, common words such as "haha" would be normalized to "here", "I" is normalized to "ii", "wknds"(weekends) is normalized to "winds", "iTumes" is normalized to "tunes", people's name such as "Louis" would be normalized to "Lousy", internet initials such as "u"(you) would be recognized as "us". proper name such as "INXS"(an Australia band) would be normalized to "ins". All these drove us to normalize the twitter dataset heauristically. We cleaned those sequential dots ".....", break the long connected words, and keep the rest unchanged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Retrieving Tweets</head><p>We build our system based on the Lucene<ref type="foot" coords="4,500.72,95.39,3.99,7.01" target="#foot_3">5</ref> toolkit. The whole process is given in Fig. <ref type="figure" coords="4,465.29,110.96,4.09,9.59">5</ref>. After identifying the English tweets, empirically normalizing the tweets, each tweet is given two features for clustering. The first feature real-time "BM25" represents the tweets score using the BM25 with the real-time inverse document frequency information, the second feature comes from SVD decomposition. Both the short query and the long tweets are casted onto the same reduced space, so that we can get the similarity of the query and the tweet on this reduced space. Both features are extracted in the strictly "real-time" scenario. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Query Processing</head><p>The high efficiency of Lucene allowed us to retrieve and collect the document for many query words.</p><p>Filtering those documents that is behind the query timestamp, we can get the "real-time" document frequency for the input query word, and input query phrase. TREC also gives a queryTweetTime element for each query topic, which actually is the latest tweet id for that query topic. This can be used to collect the "real-time" corpus size. After collecting the document frequency and the corpus size, it is easy to use the conventional scoring function to evaluate each tweet. Empirical method is used to segment the input query, by observing the "real-time" document frequency of the query phrase. Given a long query, in each iteration, we would remove one query word and check the rest query phrase's document frequency. If the document frequency could meet the requirement, a query phrase would be cut off from the original query, and the process would continue with the rest of the query words. For example, the query "mexico drug war" would be segmented as "mexico drug", "mexico", "drug war", "drug", "war".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Real-Time BM25</head><p>As stated above, the "real-time" BM25 is easily implemented, when we get the necessary document frequency with the help of Lucene's high running efficiency. The conventional BM25 formula is given as follows,</p><formula xml:id="formula_0" coords="5,72.00,276.96,221.74,36.23">BM25(Q, D) = ∑ n i=1 IDF rt (q i ) • (k 1 +1)•tf (q i ,D) k 1 •(1-b+b Len(D) avgdl )</formula><p>(1)</p><formula xml:id="formula_1" coords="5,73.31,317.72,231.59,17.09">IDF rt (q i ) = log Nrt-dfrt(q i )+0.5 dfrt(q i )+0.5<label>(2)</label></formula><p>Suppose the query Q has n query word, noted as q i , where k 1 and b are parameters, typically set as k 1 = 1 and b = 0.75. tf (q i , D) is the raw term frequency of query word q i in the document(tweet) D, df (q i , D) is the "real-time" document frequency of query word q i , N is the "real-time" corpus size.</p><p>Lucene is famous for its high performance. However, the ranking modular in Lucene is a little complicated, and some information such as the average document length is not directedly stored in Lucene, and the document length in Lucene is encoded in the Lucene system which is not so straightforward as term frequency. Although there are existing B-M25 implementaion on Lucene, we used our own implementation.</p><p>So each tweet could be ranked according to this "real-time" BM25 score. However, the "real-time" retrieval is a set retrieval task, which requires the participants to remove those irrelevant documents. That is why we resort to the SVD decomposition and finally clustering on the retrieved tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">SVD Decomposition</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SVD(Singular Value Decomposition</head><p>) is a common technique used in collaborative filtering and the recommendation system. Given the Word-Tweet Matrix built from the retrieved "real-time" tweet collection, this technique fits the problem, and it provides another view on the tweet other than the BM25 formula.</p><p>Given the Word-Tweet Matrix M , where each row represents a word, each column represents a tweet. The SVD tries to decompose this matrix into</p><formula xml:id="formula_2" coords="5,397.49,161.01,142.51,12.31">M = U ΣV T (3)</formula><p>where Σ is a diagonal matrix with non-negative singular values on the diagonal, the left matrix U is composed of the eigenvectors of M M T , the right matrix V is composed of the eigenvectors of M T M We used the SVD implementation in LingPipe<ref type="foot" coords="5,532.79,243.30,3.99,7.01" target="#foot_4">6</ref> , which also offer a comprehensive and hands-on tutorial on the SVD. The SVD decomposition process follows the work of <ref type="bibr" coords="5,423.80,285.96,111.51,9.59" target="#b20">(Gorrell and Webb, 2005)</ref>, which is a Generalized Hebbian Algorithm(GHA) for singular value decomposition in natural language processing. Since in NLP, we would face with huge sparse matrix, the GHA algorithm would calculate the eigen vectors based on the single observation of the input matrix, which also use limited space.</p><p>The parameters used in the SVD based on GHA algorithm include the number of the singular value, which is set to 20 in our experiment, the learning rate and the iteration steps which control the decomposition speed. A practical issue in the SVD is to fight with the sparse Word-Tweet Matrix. We empirically remove those words that only occur once in the returned "real-time" collection for the input query topic.</p><p>We first return the top 1000 tweets ranked by the "real-time" BM25 formula, then build the word-Tweet matrix, after decompose the matrix, we would get the left singular matrix which represents the projected vector for each word, and the right singular matrix which represents the projected vector for each tweet. Given the input query, each query word q i corresponds to a vector v q i in the projected vector space. Each tweet is projected as v t . So the similarity of the input query and the tweet would be</p><formula xml:id="formula_3" coords="5,352.88,653.58,187.12,33.71">SimSV D(Q, D) = ( n ∑ i=1 v q i ) • v t (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Clustering</head><p>After generating the features for each tweet, we would use KMeans++ to cluster on the returned result, which choose the initials to enhance the robust of the clustering algorithm. Some examples of the clustering result for the query topic is shown in Fig. <ref type="figure" coords="6,72.00,161.64,4.09,9.59">5</ref>.4. We use the first 2 topics as an example to show the effect of the clustering. The x-axis represents the BM25 feature, while the y-axis represents the SVD feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiment Result</head><p>We submitted 2 runs. Tab 5.4 show the evaluation result provided by TREC, which has removed the retweets by empirical method. Given the query judgement files, we re-evaluate the four runs, and report the result in Tab 5.4. All the tweets were evaluated by as "relevant" or "highly-relevant". Given the 50 testing query topics, totally, 49 topics have tweets judged as relevant, 33 topics have tweets judged as "highly-relevant". We both report the evaluation result by "relevance" and "high relevance".</p><p>From the table above, we could find that the "high relevance" tweets are scare, and there is a lot of space to improve it, which could be a research focus in the future.</p><p>Comparing the result, we could find that the English identification tool which could work fine in the newswire field, would not work so well as in the microblog sphere. In the Twitter dataset, removing the English tweets would make the MAP drop. We think that is because the MAP value is strongly affected by the "recall" value of the retrieval result. Removing the non-English tweets would surely decrease the "recall" value a lot. But the precision would not be affected too much, which can be observed by comparing the P30 and P10 value of these different runs. We should use more sophisticated techniques to handle the Term-Tweet Matrix, which could have improved the overall performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We report our method and evaluation result for participating the TREC 2011, Microblog Track. We used virtual machine instances to download the dataset parallelly in order to speed up the download speed, removed the non-English tweets, extracted features from each tweet and used clustering method to remove the uninteresting tweets. The result shows that there is still a lot of work in the future to improve the recall value of the retrieval performance. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,371.02,420.03,111.17,8.76"><head></head><label></label><figDesc>Figure 1: Process Overview</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,328.31,82.16,196.58,177.41"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the Language Tag in HTML</figDesc><table coords="3,329.74,94.57,193.72,165.01"><row><cell cols="2">hreflang language</cell><cell>amount</cell><cell>ratio</cell></row><row><cell>en</cell><cell cols="3">English 10894469 67.492%</cell></row><row><cell>ja</cell><cell>Japanese</cell><cell cols="2">2753207 17.056%</cell></row><row><cell>es</cell><cell>Spanish</cell><cell>1205837</cell><cell>7.470%</cell></row><row><cell>ko</cell><cell>Korean</cell><cell>84273</cell><cell>0.522%</cell></row><row><cell>fr</cell><cell>French</cell><cell>83432</cell><cell>0.517%</cell></row><row><cell>de</cell><cell>German</cell><cell>80551</cell><cell>0.499%</cell></row><row><cell>it</cell><cell>Italian</cell><cell>37670</cell><cell>0.233%</cell></row><row><cell>ru</cell><cell>Russia</cell><cell>19087</cell><cell>0.118%</cell></row><row><cell>tr</cell><cell>Turkish</cell><cell>10045</cell><cell>0.062%</cell></row><row><cell>NA</cell><cell>NA</cell><cell>973240</cell><cell>6.029%</cell></row><row><cell>total</cell><cell></cell><cell>16141812</cell><cell>100%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,72.00,82.16,226.80,144.45"><head>Table 2 :</head><label>2</label><figDesc>Performance of TextCat on Twitter</figDesc><table coords="4,72.00,92.56,226.80,134.06"><row><cell>a</cell><cell>u</cell><cell cols="3">Precision Recall F1-Measure</cell></row><row><cell cols="2">10 1.05</cell><cell cols="2">0.95 0.725</cell><cell>0.822</cell></row><row><cell cols="2">20 1.05</cell><cell>0.918</cell><cell>0.77</cell><cell>0.838</cell></row><row><cell cols="2">30 1.05</cell><cell>0.87</cell><cell>0.82</cell><cell>0.844</cell></row><row><cell cols="2">30 1.07</cell><cell>0.85</cell><cell>0.85</cell><cell>0.85</cell></row><row><cell cols="5">coarse filtering. After the second round filtering by</cell></row><row><cell cols="5">TextCat, 5304401 tweets are left, which are noted as</cell></row><row><cell cols="3">"Twitter2011EngClean".</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,147.51,82.16,316.99,265.44"><head>Table 3 :</head><label>3</label><figDesc>Evaluation Result: Evaluated by TREC, remove the duplicated retweet</figDesc><table coords="7,159.30,94.57,293.40,253.04"><row><cell>"Relevant"</cell><cell>MAP R-prec bpref</cell><cell>P10</cell><cell>P30</cell></row><row><cell>filter</cell><cell cols="3">0.1425 0.1821 0.2094 0.1857 0.1510</cell></row><row><cell>clean.filter</cell><cell cols="3">0.1000 0.1410 0.1702 0.1673 0.1340</cell></row><row><cell cols="2">"high Relevant" MAP R-prec bpref</cell><cell>P10</cell><cell>P30</cell></row><row><cell>filter</cell><cell cols="3">0.1707 0.1740 0.5024 0.0879 0.0677</cell></row><row><cell>clean.filter</cell><cell cols="3">0.1017 0.1249 0.3403 0.0606 0.0545</cell></row><row><cell cols="3">Table 4: Evaluation Result: not remove the retweet</cell><cell></cell></row><row><cell>"Relevant"</cell><cell>MAP R-prec bpref</cell><cell>P10</cell><cell>P30</cell></row><row><cell>rtBM25</cell><cell cols="3">0.2458 0.3063 0.3250 0.3367 0.2925</cell></row><row><cell>rtBM25.clean</cell><cell cols="3">0.2127 0.2737 0.2961 0.3204 0.2789</cell></row><row><cell>rtBM25.filter</cell><cell cols="3">0.1990 0.2718 0.2794 0.2959 0.2367</cell></row><row><cell cols="4">rtBM25.clean.filter 0.1298 0.1881 0.1958 0.2755 0.2245</cell></row><row><cell>"high Relevant"</cell><cell>MAP R-prec bpref</cell><cell>P10</cell><cell>P30</cell></row><row><cell>rtBM25</cell><cell cols="3">0.1358 0.1422 0.1557 0.0735 0.0544</cell></row><row><cell>rtBM25.clean</cell><cell cols="3">0.1110 0.1233 0.1321 0.0571 0.0503</cell></row><row><cell>rtBM25.filter</cell><cell cols="3">0.1265 0.1423 0.1480 0.0612 0.0517</cell></row><row><cell cols="4">rtBM25.clean.filter 0.0674 0.0784 0.0921 0.0469 0.0463</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="3,329.34,714.06,144.13,7.88"><p>http://www.let.rug.nl/vannoord/TextCat/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="4,88.14,702.89,99.85,7.88"><p>http://jazzy.sourceforge.net/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="4,88.14,714.06,128.51,7.88"><p>http://norvig.com/spell-correct.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="4,329.34,714.06,162.91,7.88"><p>http://lucene.apache.org/java/docs/index.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4" coords="5,329.34,703.10,183.06,7.88;5,313.20,714.06,29.64,7.88"><p>http://alias-i.com/lingpipe/demos/tutorial/svd/readme.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p>The author wishes to thank the anonymous reviewers for their helpful comments. This work was partially funded by <rs type="funder">National Natural Science Foundation of China</rs> ( <rs type="grantNumber">61003092</rs>, <rs type="grantNumber">61073069</rs>), <rs type="funder">Shanghai Science and Technology Development Funds</rs>(<rs type="grantNumber">10dz1500104</rs>), <rs type="funder">Doctoral Fund of Ministry of Education of China</rs> (<rs type="grantNumber">200802460066</rs>), and <rs type="person">Key Projects</rs> in the National Science &amp; <rs type="programName">Technology Pillar Program</rs>(<rs type="grantNumber">2009BAH40B04</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_g9Fswpv">
					<idno type="grant-number">61003092</idno>
				</org>
				<org type="funding" xml:id="_a39E6QS">
					<idno type="grant-number">61073069</idno>
				</org>
				<org type="funding" xml:id="_KXMUwvE">
					<idno type="grant-number">10dz1500104</idno>
				</org>
				<org type="funding" xml:id="_W3zrwZa">
					<idno type="grant-number">200802460066</idno>
					<orgName type="program" subtype="full">Technology Pillar Program</orgName>
				</org>
				<org type="funding" xml:id="_qT69gEH">
					<idno type="grant-number">2009BAH40B04</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,313.20,467.86,226.82,8.76;6,324.11,479.82,215.90,8.76;6,324.11,491.77,173.89,8.76" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,324.11,479.82,215.90,8.76;6,324.11,491.77,26.67,8.76">Streaming First Story Detection with application to Twitter</title>
		<author>
			<persName coords=""><forename type="first">Sasa</forename><surname>Petrovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Victor</forename><surname>Lavrenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,357.07,491.77,30.06,8.76">NAACL</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<pubPlace>Los Angeles, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,505.02,226.81,8.76;6,324.11,516.97,215.91,8.76;6,324.11,528.93,180.40,8.76" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,451.09,505.02,88.92,8.76;6,324.11,516.97,52.69,8.76">Temporal Variation in Online Media</title>
		<author>
			<persName coords=""><forename type="first">Jaewon</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,383.75,516.97,156.27,8.76;6,324.11,528.93,151.67,8.76">ACM International Conference on Web Search and Data Mining (WSDM &apos;11)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,542.17,226.81,8.76;6,324.11,554.12,215.90,8.76;6,313.20,567.37,29.89,8.76;6,360.31,567.37,24.91,8.76;6,402.44,567.37,14.39,8.76;6,434.05,567.37,35.42,8.76;6,486.70,567.37,53.32,8.76" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<title level="m" coord="6,439.56,542.17,100.45,8.76;6,324.11,554.12,215.90,8.76;6,313.20,567.37,29.89,8.76;6,360.31,567.37,24.91,8.76;6,402.44,567.37,14.39,8.76;6,434.05,567.37,35.42,8.76;6,486.70,567.37,48.88,8.76">Lexical Normalisation of Short Text Messages: Makn Sens a #twitter, ACL 2011 Samuel Brody and Nicholas Diakopoulos</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,324.11,591.28,215.90,8.76;6,324.11,603.23,56.17,8.76" xml:id="b3">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j" coord="6,324.11,591.28,211.50,8.76">Word Lengthening to Detect Sentiment in Microblogs</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,616.47,226.82,8.76;6,324.11,628.43,215.90,8.76;6,324.11,640.38,215.90,8.76;6,324.11,652.34,215.91,8.76;6,324.11,664.29,215.90,8.76;6,324.11,676.25,80.68,8.76" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="6,364.04,652.34,175.98,8.76;6,324.11,664.29,210.44,8.76">PART-OF-SPEECH TAGGING FOR TWIT-TER: ANNOTATION, FEATURES, AND EXPERI</title>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brendan O'</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Mills</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno>MENTS. ACL 2011</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,689.49,226.82,8.76;6,324.11,701.44,215.91,8.76;6,324.11,713.40,185.45,8.76" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="6,510.37,701.44,29.65,8.76;6,324.11,713.40,137.21,8.76">Topical Keyphrase Extraction from Twitter</title>
		<author>
			<persName coords=""><forename type="first">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jing</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Palakorn</forename><surname>Achanauparp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ee-Peng</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaoming</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,373.99,226.82,8.76;7,82.91,385.94,215.90,8.76;7,82.91,397.90,62.42,8.76" xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Long</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tiejun</forename><surname>Zhao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="report_type">Target-dependent Twitter Sentiment Classification</note>
</biblStruct>

<biblStruct coords="7,72.00,411.93,226.81,8.76;7,82.91,423.89,215.91,8.76;7,82.91,435.84,149.04,8.76" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Roberto</forename><surname>Gonzalez-Lbanez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nina</forename><surname>Wacholder</surname></persName>
		</author>
		<title level="m" coord="7,142.29,423.89,156.53,8.76;7,82.91,435.84,149.04,8.76">IDENTIFYING SARCASM IN TWIT-TER: A CLOSER LOOK. ACL 2011</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,449.87,226.82,8.76;7,82.91,461.83,215.91,8.76;7,82.91,473.78,147.50,8.76" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Emily</forename><surname>Vahed Qazvinian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Rosengren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qiaozhu</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Mei</surname></persName>
		</author>
		<title level="m" coord="7,156.91,461.83,141.91,8.76;7,82.91,473.78,84.43,8.76">Rumor has it: Identifying Misinformation in Microblogs</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,487.82,226.81,8.76;7,82.91,499.77,215.90,8.76;7,82.91,511.73,89.14,8.76" xml:id="b9">
	<analytic>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Massimo Zanzotto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marco</forename><surname>Pennaccchiotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kostas</forename><surname>Tsioutsiouliklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,188.08,499.77,110.73,8.76;7,82.91,511.73,26.67,8.76">Linguistic Redundancy in Twitter</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,525.76,226.82,8.76;7,82.91,537.72,215.91,8.76;7,82.91,549.67,215.90,8.76;7,82.91,561.63,143.85,8.76" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="7,223.03,537.72,75.79,8.76;7,82.91,549.67,215.90,8.76;7,82.91,561.63,86.92,8.76">We Know Who You Followed Last Summer: Inferring Social Link Creation Times In Twitter</title>
		<author>
			<persName coords=""><forename type="first">Brendan</forename><surname>Meeder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brian</forename><surname>Karrer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amin</forename><surname>Sayedi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Borgs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jennifer</forename><surname>Chayes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,575.66,226.81,8.76;7,82.91,587.61,215.90,8.76;7,82.91,599.57,19.93,8.76" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Shaomei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jake</forename><forename type="middle">M</forename><surname>Hofman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Winter</forename><surname>Mason</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Duncan</forename><forename type="middle">J</forename><surname>Watts</surname></persName>
		</author>
		<title level="m" coord="7,118.97,587.61,145.45,8.76">Who Says What to Whom on Twitter</title>
		<imprint>
			<publisher>WWW</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,613.60,226.81,8.76;7,82.91,625.56,215.90,8.76;7,82.91,637.51,143.94,8.76" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Eiji</forename><surname>Aramaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sachiko</forename><surname>Maskawa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mizuki</forename><surname>Morita</surname></persName>
		</author>
		<title level="m" coord="7,82.91,625.56,215.90,8.76;7,82.91,637.51,81.46,8.76">Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,651.55,226.81,8.76;7,82.91,663.50,215.90,8.76;7,82.91,675.46,19.93,8.76" xml:id="b13">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">George</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guido</forename><surname>Zarrella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,120.88,663.50,136.71,8.76">Discriminating Gender on Twitter</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,689.49,226.81,8.76;7,82.91,701.44,215.91,8.76;7,82.91,713.40,169.11,8.76" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Roy</forename><surname>Bar-Haim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Elad</forename><surname>Dinur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ronen</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Moshe</forename><surname>Fresko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guy</forename><surname>Goldstein</surname></persName>
		</author>
		<title level="m" coord="7,193.95,701.44,104.87,8.76;7,82.91,713.40,106.64,8.76">Identifying and Following Expert Investors on Twitter</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,313.20,373.99,226.81,8.76;7,324.11,385.94,183.50,8.76" xml:id="b15">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marcelo</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Barbara</forename><surname>Poblete</surname></persName>
		</author>
		<title level="m" coord="7,536.13,373.99,3.87,8.76;7,324.11,385.94,126.57,8.76">formation Credibility on Twitter</title>
		<imprint>
			<publisher>WWW</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,313.20,398.64,226.81,8.76;7,324.11,410.60,215.90,8.76;7,324.11,422.56,215.90,8.76;7,324.11,434.51,46.48,8.76" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,364.44,410.60,175.57,8.76;7,324.11,422.56,107.24,8.76">A cluster-based resampling method for pseudo-relevance feedback</title>
		<author>
			<persName coords=""><forename type="first">Kyung</forename><surname>Soon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lee</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,451.66,422.56,41.71,8.76">SIGIR &apos;08</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="235" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,313.20,447.21,226.81,8.76;7,324.11,459.17,215.90,8.76;7,324.11,471.12,46.48,8.76" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m" coord="7,418.72,447.21,121.29,8.76;7,324.11,459.17,59.32,8.76">Pattern Recognition and Machine Learning</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="page" from="179" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,313.20,483.83,226.81,8.76;7,324.11,495.78,215.90,8.76;7,324.11,507.74,215.90,8.76;7,324.11,519.69,155.55,8.76" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="7,505.04,483.83,34.97,8.76;7,324.11,495.78,215.90,8.76;7,324.11,507.74,36.24,8.76">Okapi at TREC7: automatic ad hoc, filtering, VLC and interactive track</title>
		<author>
			<persName coords=""><surname>Se</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,367.11,507.74,172.90,8.76">NIST SPECIAL PUBLICATION SP</title>
		<imprint>
			<biblScope unit="volume">500</biblScope>
			<biblScope unit="page" from="253" to="264" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>Issue</note>
</biblStruct>

<biblStruct coords="7,313.20,532.39,226.82,8.76;7,324.11,544.35,215.90,8.76;7,324.11,556.30,215.90,8.76;7,324.11,568.26,197.70,8.76" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="7,457.75,532.39,82.26,8.76;7,324.11,544.35,56.94,8.76">N-Gram-Based Text Categorization</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Cavnar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Trenkle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,398.96,544.35,141.05,8.76;7,324.11,556.30,215.90,8.76;7,324.11,568.26,24.02,8.76">Proceedings of Third Annual Symposium on Document Analysis and Information Retrieval</title>
		<meeting>Third Annual Symposium on Document Analysis and Information Retrieval<address><addrLine>Las Vegas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-04">April 1994</date>
			<biblScope unit="page" from="11" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,313.20,580.96,226.81,8.76;7,324.11,592.92,215.90,8.76;7,324.11,604.87,62.52,8.76" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="7,416.70,580.96,123.31,8.76;7,324.11,592.92,124.97,8.76">Generalized Hebbian Algorithm for Latent Semantic Analysis</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gorrell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Webb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,466.46,592.92,73.55,8.76;7,324.11,604.87,37.62,8.76">Proceedings of Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
