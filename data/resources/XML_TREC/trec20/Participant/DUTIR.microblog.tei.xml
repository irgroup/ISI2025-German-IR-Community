<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,168.98,82.60,274.20,14.36">DUTIR at TREC 2011 Microblog Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,189.17,107.53,46.11,9.50"><forename type="first">Cunhui</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<postCode>116024</postCode>
									<settlement>Dalian</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,242.09,107.53,52.79,9.50"><forename type="first">Kejiang</forename><surname>Ren</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<postCode>116024</postCode>
									<settlement>Dalian</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,302.71,107.53,49.86,9.50"><forename type="first">Hongfei</forename><surname>Lin</surname></persName>
							<email>hflin@dlut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<postCode>116024</postCode>
									<settlement>Dalian</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,359.47,107.53,63.49,9.50"><forename type="first">Shaowu</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<postCode>116024</postCode>
									<settlement>Dalian</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,168.98,82.60,274.20,14.36">DUTIR at TREC 2011 Microblog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">547EED558AEDF20E024E023274DBF907</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Microblog retrieval</term>
					<term>Language Model</term>
					<term>VSM</term>
					<term>Feedback</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In TREC 2011 Microblog Track, we explore the use of pseudo relevance feedback to expand original query terms in topics. Hyperlink is used to enhance the performance of the retrieval results. And we set a threshold of entropy to filter retrieval results. Microblog is a Realtime Adhoc Task, so we make use of average querytweettime that comes from pseudo relevance feedback to change retrieval score. We combine two models to improve retrieval results. The results show that our model is effective at realtime relevance retrieval.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In this work, we investigated a strategy of pseudo relevance feedback to expand original query terms in topics, as well as the combining two models of LM and VSM to improve the quality of a search result list. Our experiments mainly focus on the following three aspects: (1) how does the traditional retrieval models perform in microblogging environments? (2) How does the traditional retrieval models combining with pseudo relevance feedback and other microblog feature, such as entropy, hyperlink, perform in microblog information retrieval. (3) Due to the short text feature of microblog, can combining two retrieval models improve the quality of a search result list?</p><p>The Microblog track examines search tasks and evaluation methodologies for information seeking behaviors in microblogging environments. The goal of the task is to return a ranking of the documents in the collection in the order of querytweettime of relevance. The results are assessed mainly by P@30 <ref type="bibr" coords="1,155.36,513.18,15.44,9.50">[1]</ref>.</p><p>The rest of this paper is organized as follows: In Section 2, we describe the traditional retrieval models and relevance feedback model used in this paper. In section 3, we present the experimental for Microblog Track task. In section 4, we present our official results in microblog track. In section 5, we conclude the paper and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Retrieval Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Vector Space model (VSM)</head><p>In VSM, documents and queries are assumed to be part of a t-dimensional vector space, where t is the number of index terms. The typical form of document term weighting in the VSM <ref type="bibr" coords="1,454.24,653.61,17.62,9.50" target="#b1">[2]</ref> are:</p><formula xml:id="formula_0" coords="1,158.67,671.37,291.51,42.22">2 1 (lg 1.0) [(lg 1.0) ] ij j ij t ij j j tf idf w tf idf      , log j j N idf n  , 1 ij ij t ik k f tf f   </formula><p>Where idf j is the inverse document frequency weight for term j and tf ij is the term frequency weight of term j in document I, w ij is the weight of a term j in document i. N is the total number of documents in the collection, and n j is the number of documents in which term k occurs. In our experiments, we take advantage of Lucene toolkit[3] to implement VSM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Language model (LM)</head><p>A language model, which first used in information retrieval by Ponte and Croft <ref type="bibr" coords="2,443.35,154.33,12.35,9.50" target="#b2">[4]</ref>, representation of a document can be used to generate the query by sampling terms according to the probability distribution. The probability of producing the query for a given document model as follows:</p><formula xml:id="formula_1" coords="2,198.34,201.98,216.80,22.17">ˆˆ( | ) ( | ) 1.0 ( | ) d d d t Q t Q p Q M p t M p t M     </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>Where t is a term in query Q, the function ˆ( | ) </p><formula xml:id="formula_2" coords="2,176.46,239.44,260.69,48.92">d p t M is as follows: ˆ(1.0 ) , ,<label>( . ) ( , ) ( ) 0 ˆ</label></formula><formula xml:id="formula_3" coords="2,238.00,266.35,193.89,37.63">          </formula><p>Where cf t is the count of term t in the collection and cs is the collection size or the total number of tokens in the collection, tf (t,d) is the raw term frequency of term t in document d. The other functions calculate as follows:</p><formula xml:id="formula_4" coords="2,92.39,359.12,393.06,36.10">( , ) , 1.0 ˆ( ) ( ) 1.0 1.0 td tf t td t f R f f     , () ( ( | )) ˆ() td ml d d avg t p t M pt df    ,<label>( , ) ˆ( |</label></formula><p>)</p><formula xml:id="formula_5" coords="2,404.77,372.90,77.40,21.88">td ml d d tf P t M dl </formula><p>Where f is the mean term frequency of term t in documents where t occurs, df t is the document frequency of t, dl d is the total number of tokens in document d.  Q for query and the other is LM  D for document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Zhai et al.[9]</head><p>proposed a more universal language model which known as the Kullback-Leibler divergence retrieval model. Assume that a query q is obtained as a sample from a generative model  Q and a document d is generated by a model D . The distance value of d with respect to q can be measured by KL divergence:</p><formula xml:id="formula_6" coords="2,189.20,514.21,234.20,22.14">( | ) ( | ) log ( | ) ( ) Q D Q D w D P w P w cons q        </formula><p>The cons(q) is dropped because of no affecting ranking of document. Therefore the final ranking is based on the cross entropy of the query language model with respect to the document language model. The language model is based on the Indri Retrieval Toolkit[5].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Rocchio Query expansion</head><p>Rocchio's <ref type="bibr" coords="2,150.92,606.81,13.30,9.50" target="#b3">[6]</ref> approach which used the VSM to rank document provides a general framework for implementing relevance feedback. Rocchio feedback model can also be used for pseudo relevance based on query expansion. The terms weight of expanded query is calculated as follows:</p><formula xml:id="formula_7" coords="2,227.89,652.79,153.93,26.11">' i i rel non rel Q Q R S         </formula><p>Where Q ' and Q represent the expanded and original query vectors, R i and S i are individual terms of the relevant set of R and non-relevant set of S. The weights ,  and  are weights.</p><p>In our experiments, the parameters  and  are set constant value 1 and 0, the parameter  is a variable value changing with the document score which calculate from VSM or LM in the initial retrieval. The first ten documents which initial retrieval are considered relevance. The terms which are in the first ten retrieval document leaved for the count greater than two. The terms weight of the set R is calculated by TF-IDF, in which the collection size is set ten of the pseudo relevance documents.</p><p>3．Experiments</p><p>This section introduces our experiments in detail. The structure of the retrieval system is shown in Figure <ref type="figure" coords="3,130.82,201.13,3.96,9.50">1</ref>.</p><p>Figure <ref type="figure" coords="3,216.30,388.38,3.96,9.50">1</ref>. The framework of the microblog retrieval system. The preprocessing phase is designed to extract the English tweets from the raw corpus for the reason that the non-English tweets are judged non-relevant. The future evidence does not used in the system in order to meet the real-time retrieval. Consequently before the first retrieval, we built index for each query respectively in which the tweet querytweettime is less than query querytweettime. Also the external evidence did not used in the system.</p><p>Owing to the final retrieval results are ranked by the mean of tweets' querytweettime, the parameter t is used to decrease the score of the result which the querytweettim is greater but non-relevance. It is calculated as follows: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>     </head><p>Where t i is the querytweettime of tweet in result, t avg and t max are the average querytweettime and the maximum querytweettime of pseudo relevance feedback result list of ten respectively.</p><p>Since microblog is a short text containing no more than 140 characters, whether microblog has a hyperlink is important feature that imply the microblog has more information. It is used to enhance the final score of the retrieval results. The final score SC ' (q,d) of ranking is calculated as follows: ' </p><formula xml:id="formula_8" coords="3,123.26,281.56,304.07,422.80">( , ) ( , ) (1 * * ) SC q d SC q d a t b L     Corpus Processing Index</formula><p>Query Ranking</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feedback</head><p>New query Ranking Reranking Filter Where SC(q,d) is the score of query q and document d calculated by VSM or LM combing with pseudo relevance feedback, if the tweet contains a link, L is assigned a value of positive one, otherwise L is zero, the weights a and b are used to adjust the weight of t and L. In VSM, we set the weights a and b are both 0.5. In LM, they are set 0.5 and 0.1 respectively.</p><p>Entropy is another important characteristic of information in microblog that the more the number of words differently the greater the entropy. The calculation function is as follows:</p><formula xml:id="formula_9" coords="4,272.09,179.61,88.07,25.87">2 1 log n i i i E p p   </formula><p>Where p i is the frequency within the document, and n is the total independent term's size of the document. We set a threshold of entropy to filter retrieval results. The result which entropy is more than 2 is withheld. Relevance score is also used to filter the final results. The retrieval results which score less than 0.15 are discarded. And then the results are re-ranking using the querytweettime.</p><p>Different relevance ranking model in information retrieval are likely to retrieval new documents which are not shared between them. We combine the LM and VSM in a linear:</p><formula xml:id="formula_10" coords="4,223.78,315.62,159.28,12.45">( , ) ( , )<label>(1 )</label></formula><p>( , )</p><formula xml:id="formula_11" coords="4,185.82,314.92,259.81,14.71">LM VSM MixSC q d SC q d SC q d     </formula><p>Where MixSC(q,d) is the score after combination, SC(q,d) LM and SC(q,d) VSM are score of LM and VSM respectively. In our experiments  is set 0.7.</p><p>In all the considered approaches, we did a topic-based normalization before combination on the score of different methods, in order to normalize the positive values into values in the range [0, 1]. The normalized value of the score SC(q, d i ) between query q and document d i is calculated as follows:</p><p>( , ) min{ ( , )} ( , ) max{ ( , )} min{ ( , )}</p><formula xml:id="formula_12" coords="4,206.55,422.79,207.66,33.18">ii ii i ii SC q d SC q d SC q d SC q d SC q d   </formula><p>Where the max{SC(q, d i )} and min{SC(q, d i )} are the maximum and minimum value of SC(q, d i ) respectively for all the documents in the collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4．Results</head><p>There are four runs submitted. Table1shows our official runs considering all relevant and highly relevant tweets as relevant being over 49 topics for Microblog Track. The runs dutirTfidfFb and dutirLmFb take account of VSM and LM respectively combining with pseudo relevance feedback. The other two runs dutirMixSp and dutirMixFb are combination of two retrieval models LM and VSM, but the latter run used the pseudo relevance feedback. From Table1 and Table2, the performance of runs using the pseudo relevance feedback is significantly better than runs do not use feedback. And different relevance ranking model in information retrieval are retrieval new documents which are not shared between them. Since we filter the results taking advantage of entropy and final score, the result which has little terms of difference and low relevant score are discarded. And also enhance score of document having hyperlink, in general it usually include more information. In realtime task, the retrieval results which the querytweettime is huge have greater impact on the final ranking, so we decrease the score of those documents and increase the score of results of small querytweettime using the average querytweettime calculating from pseudo relevance feedback results. The effectiveness is obvious using querttweettime feature to improve results of ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5．Conclusion</head><p>In this paper, we present our methods and experiments in Microblog track 2011. We evaluate traditional IR models VSM and LM in our experiments, combining with pseudo relevance feedback and other microblog feature, such as entropy and hyperlink. Taking account of the microblog track is a Realtime Adhoc Task, we use entropy to filter the tweets containing fewer information. And also we set a threshold discarding the results which the relevance score is small.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,171.74,606.81,274.88,88.46"><head>Table 1</head><label>1</label><figDesc></figDesc><table coords="4,171.74,606.81,274.88,88.46"><row><cell></cell><cell cols="3">: MAP and P@30 of 4 runs for all relevance</cell></row><row><cell>Run id</cell><cell>MAP</cell><cell>R-prec</cell><cell>P@30</cell></row><row><cell>dutirTfidfFb</cell><cell>0.2219</cell><cell>0.3100</cell><cell>0.2939</cell></row><row><cell>dutirLmFb</cell><cell>.0.2851</cell><cell>0.3483</cell><cell>0.3224</cell></row><row><cell>dutirMixSp</cell><cell>0.2674</cell><cell>0.3426</cell><cell>0.3129</cell></row><row><cell>dutirMixFb</cell><cell>0.2936</cell><cell>0.3633</cell><cell>0.3408</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,171.74,91.93,274.88,88.46"><head>Table 2 :</head><label>2</label><figDesc>MAP and P@30 of 4 runs for highly relevance</figDesc><table coords="5,171.74,108.01,274.88,72.38"><row><cell>Run id</cell><cell>MAP</cell><cell>R-prec</cell><cell>P@30</cell></row><row><cell>dutirTfidfFb</cell><cell>0.1684</cell><cell>0.1980</cell><cell>0.0949</cell></row><row><cell>dutirLmFb</cell><cell>0.2375</cell><cell>0.2262</cell><cell>0.1071</cell></row><row><cell>dutirMixSp</cell><cell>0.2177</cell><cell>0.2137</cell><cell>0.1020</cell></row><row><cell>dutirMixFb</cell><cell>0.2352</cell><cell>0.2374</cell><cell>0.1162</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,127.94,483.42,260.76,9.50" xml:id="b0">
	<monogr>
		<ptr target="http://sites.google.com/site/microblogtrack/" />
		<title level="m" coord="5,127.94,483.42,70.64,9.50">Track Guidelines</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,106.83,499.02,415.26,9.50;5,105.74,514.62,214.49,9.50" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,226.88,499.02,236.73,9.50">Term-weighting approaches in automatic text retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,472.05,499.02,50.03,9.50;5,105.74,514.62,117.05,9.50">Information Processing and management</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="513" to="523" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.86,545.74,416.20,9.61;5,105.74,561.45,91.95,9.50" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,234.65,545.85,235.95,9.50">A language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,477.94,545.74,39.22,9.60">SIGIR&apos;93</title>
		<meeting><address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,104.90,592.65,336.65,9.50" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="5,154.45,592.65,189.74,9.50">Relevance Feedback in Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rocchio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971">1971</date>
			<biblScope unit="page" from="313" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.98,608.25,416.12,9.50;5,105.74,623.85,96.60,9.50" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="5,245.79,608.25,272.12,9.50">Information retrieval: algorithms and heuristics, second Edition</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="96" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.86,639.45,416.31,9.50;5,105.74,655.05,416.24,9.50;5,105.74,670.65,171.87,9.50" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,205.99,639.45,316.18,9.50;5,105.74,655.05,40.11,9.50">Model-based feedback in the language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,150.31,655.05,371.67,9.50;5,105.74,670.65,99.90,9.50">CIKM&apos;01: Proceedings of the tenth international conference on Information and knowledge management</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
