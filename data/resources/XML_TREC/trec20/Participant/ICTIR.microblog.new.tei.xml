<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,147.69,171.96,314.87,18.14;1,132.62,196.87,345.00,18.14">Author Model and Negative Feedback Methods on TREC 2011 Microblog Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,177.79,236.67,39.40,12.58"><forename type="first">Rui</forename><surname>Li</surname></persName>
							<email>lirui@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Graduate University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,239.00,236.67,71.60,12.58"><forename type="first">Bingjie</forename><surname>Wei</surname></persName>
							<email>weibingjie@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Graduate University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,332.41,236.67,43.12,12.58"><forename type="first">Kai</forename><surname>Lu</surname></persName>
							<email>lukai@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Graduate University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,397.33,236.67,61.45,12.58"><forename type="first">Bin</forename><surname>Wang</surname></persName>
							<email>wangbin@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,147.69,171.96,314.87,18.14;1,132.62,196.87,345.00,18.14">Author Model and Negative Feedback Methods on TREC 2011 Microblog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">49E7B886F4CA79B9E26C6170DF13E5A8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Microblog Retrieval</term>
					<term>twitter</term>
					<term>short text</term>
					<term>topic modeling</term>
					<term>negative feedback</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper gives an overview of our work (the ICTIR group) in microblog track of TREC 2011 for tweets retrieval. The basic query likelihood model with smoothing is the fundamental method in our approaches, we also consider other factors: the author information and the negative feedback. Firstly, we classify all queries into three categories, construct refined feedback in different ways to reform them; Secondly, extremely short tweets lead to poor clustering performance, the author topic models are trained for tweets expansion and smoothing. Finally, we train negative feedback model to reduce noise impacts in our microblog search task. Experimental results show that our methods could improve the retrieval performance greatly.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Lots of people spend more and more time on microblog in the daily lives, many of us obviously like to use this convenient way to share our lives and communicate with our friends. The dataset published in the microblog track is from twitter.com. Microblog is different from traditional web pages, social media and social networks. For example, in twitter, the tweets that user commonly write are extremely short, the average length is about 11. That is to say, if we use the traditional methods and technique in information retrieval directly, it would be suffered from severe problem of sparse. Moreover, microblogs usually contain some interesting features. You can "mention" other users in your tweets by adding their user names. "Retweet" are also supported to simply reproduce other users' tweets you like on your own page. User can add URLs in their tweets, which are then redirected by twitter.com. Hashtag, as a kind of tag, can be regarded as topics that user might be interested in and discussed in the tweets. That means user might tag the tweets himself by using hashtags. How to incorporate all these features to improve our retrieval results is a considerable problem. In addition, informal texts are found in vast majority of tweets. Tweets in twitter.com are filled with abbreviation, deformation, even emotions. It brings great natural language processing problems.</p><p>The microblog track has a defined task: to improve p@30 performance for all retrieval results of all the given queries. Each query is represented as "topics" that contains query id as primary key, query submission time, query content and the last tweet id before the query submitted. "Interesting" but "newer" relevant tweets should be ranked higher in rank list.</p><p>In our work, we first reform the query by feedback words which are gathered and extracted by several ways. Then, all tweets published by the same author are collected together to form a new dataset. After that, We could train topic models of authors/users <ref type="bibr" coords="2,296.74,461.84,11.71,10.48" target="#b0">[1]</ref>. At the last, we train negative feedback models with different parameters for different kinds of queries.</p><p>The rest of the paper is organized as follows: Section 2 shows our preparation for retrieval task and the baseline we use to get the initial retrieval sets. The main author model we used is presented in section 3. Section 4 introduces the negative feedback model. Section 5 describe our experiments, including the parameters we use and the details of the experimental results, and finally our conclusions and future work are given in section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preparation</head><p>The microblog dataset, released by TREC 2011, needs to be preprocessed before we use it. That is because it contains many informal and non-English texts. Furthermore, the "mention", "retweet", hashtag and URL in tweets should be processed before we index them. The main steps are as follows:</p><p>1. If the tweet starts with "RT" or the tweet status code equals to a specific number, it is a reproduced tweet from another and is repetitive. In that case, we just ignore this tweet. If the tweet contains "RT", we only keep the words before "RT".</p><p>2. User's name that tweets mentioned, hashtags and URLs that tweets contained are all extracted as useful features.</p><p>3. Emotions and stop words are filtered. 4. Some transformational lexicons are restored, such as "gooooood!!!" changed by "good".</p><p>5. Tweets written in non-English language are filtered. 6. Porter stemmer is used for stemming.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Baseline</head><p>Because some models which are used to rerank the tweets have high computation complexity, we only sort a subset of the corpus. All the queries are used to run a simply retrieval model (bm25) to get the initial result sets.</p><p>Each query contributes about top 10, 000 relevant tweets at most, we collect 471, 830 tweets (50 queries) in total at the end. First, we collect feedback documents for each search topic returned by search engines; There are some restrictions when we search, such as we only retrieve the documents whose released time is closed to the query submission time (but before 2011.2.8). The number of the feedback documents is about 10∼20. Second, key words are extracted automatically (TextRank), then participants are invited to choose manually about 10 key words for each query; In details, all the key words are selected by 3 people respectively. Third, the baseline result sets are obtained by running a simple search task with the expanded queries. The rank list for each query retrieved by probability model (BM25) and kl divergence (KL) model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Author Information Extraction</head><p>The baseline is a common retrieval method. As we mentioned that, it suffers from serious noise problem caused by the short text and irregular expression of words. The tweets are presented arbitrary and the average length is about 11. For example, a tweet which talks about "world cup" should be considered relevant to the query "soccer fifa", although there are no common words between them.</p><p>In our dataset, we find that, the twitterer always publish more than several tweets that are all have similar meaning. If a user is interested in a specific topic, he may write or retweet many relevant messages on his microblogs. For this basic reason, we can estimate the author's model and then use it to improve the recall rate. The users who published more than five tweets, are considered as containing useful information. To estimate the author's model, we considered all tweets issued by the same author (user) as one document. There are totally about 3.6 million authors in our dataset. We then could get a distribution over words for each author. Recently, topic models are found especially useful to measure documents' semantic relations. In topic model, topics are distributions on words. Similarities between author and query can be computed by the distance ( query likelihood, KL divergence and so on ) between their distributions over words and topics. So in our method, we train topic models for each author, and then compute their ranking scores on given query by the author model in section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Feedback Construction</head><p>According to paper <ref type="bibr" coords="4,215.24,417.55,17.17,10.48" target="#b12">[13]</ref>, queries can be classified as: celebrity, social event and common queries. For different types of queries, we adopt different expansion strategies to reconstruct it. For celebrity query, its motivation is mainly to find the breaking news about a particular person or a public institution (such as "Oprah Winfrey" and "White Stripes"), rather than to learn more about a particular aspect of that person. So the feedback documents and key words we choose for celebrity query expansion contain more "breaking news" words. These words can represent the event's different part and something the searcher wants to find, such as: people's name in the event, when and where the event broke out and so on. We achieve this by selecting key words by experienced participants and adding them into initial query. For social event query, its motivation is different from the celebrity query's, what to find has been to a certain extent settled and the scope is narrower. The feedback documents could contain more kinds of statements or comments, and synonym words could be expanded. For the third type query, which is searching for specific topics, for example: "organic farming requirements"? Even we find that it occupies a small percentage in all queries, we do query expansion by extracting useful information from wikipedia and wordnet. Examples of </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Author Model</head><p>With the feedback documents and expanded queries we constructed before, we introduce a retrieval model that could integrate the author information in this section. Because there is no user profile in the corpus, we just compute the similarities between authors' tweets and queries, the similarity can also be called the author's ranking score. It contains two parts: model of tweets and model of topics. Latent Dirichlet Allocation (LDA) are used to train the author's topic model. The score then can be computed according to the query likelihood retrieval model. All of these can be seen in formula 1 ∼ 4:</p><formula xml:id="formula_0" coords="5,140.12,584.73,359.28,11.50">S(A, Q) = (1 -λ)S tweet (A, Q) + λS topic (A, Q)<label>(1)</label></formula><formula xml:id="formula_1" coords="5,142.11,608.73,357.29,67.80">S tweet (A, Q) = 1 |A| tw∈A S(t w , q) = 1 |A| tw∈A w∈V C(w, q) log p(w|t w )<label>(2)</label></formula><formula xml:id="formula_2" coords="6,140.12,127.00,359.28,71.01">S topic (A, Q) = K i=1 p(θ i |A)S θ (Q, θ i ) (3) S θ (Q, θ i ) = w∈V C(w, q) log p(w|θ i ) (<label>4</label></formula><formula xml:id="formula_3" coords="6,494.42,174.28,4.99,10.48">)</formula><p>Where S denotes the ranking scores, A denotes author, |A| denotes the number of author's tweets , Q is the query, t w is the tweet, K is the topic number, C(w, q) is the count of word w in query q; S tweet , S topic and S θ mean the author's scores on tweets, the author's scores on topics, and the scores of each topic respectively. As we see, language modeling approaches are used by us to compute the ranking scores. One things need to notice is p(w|t w ) in formula 2 are estimated using Dirichlet Prior smoothing (DIR) and Jelinek-Mercer smoothing (JM) for comparison. The parameters after selected are 8∼20 (DIR) and 0.5 (JM). The author model is then used in our experiment as a smoothing model (the smoothing parameter is 0.2) for tweet expansion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Negative Feedback</head><p>We use negative feedback to improve the ranking effects. The main reason is that the model we used before is mainly used for common query retrieval tasks. However, in our dataset, some of queries are difficult. That means if the query is processed by the same method used before, the result will not so good. One of the reason is that the queries or the feedback documents contain noise words which could influence the results greatly. One query example is "Kubica crash", the expanded query after feedback contains the word "burn". According to this, in the result we find that lots of tweets that contain "crash crash burn" are recalled. Unfortunately, "crash crash burn" is the lyrics of a popular song, with a large number of tweets related to it. Thus, the relevant tweets are crowded out from the retrieval list. In this section, we represent our negative feedback method to cope with this problem.</p><p>After ranking methods we mentioned in section 3, we then collect negative feedback document sets for each query. The negative feedback model is trained from the non-relevant tweets, the corresponding negative feedback score can be computed as formula 5: </p><p>Where θ N is the negative feedback model, p(w|θ N ) is the non-relevant words probabilities. The negative feedback model could punish the words in non-relevant tweets. Notice that p(w|θ N ) is estimated by the partly selected words from non-relevant tweets but all the non-relevant tweets to avoid excessive negative feedback. So our methods could take advantage of the author model for tweets, the feedback model and negative feedback model for queries. In table 2, we see that the author model works well, both the baseline and author model improves greatly after feedback. This means the author's information is useful, the improvement might come from two parts: First, the author's other tweets are used to expand the tweets longer, to some extent work around the sparse issue. Second, adding author's topic aims at dealing with the words mismatch problem, some semantically related tweets maybe written by same author.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Negative Feedback</head><p>Non-relevant tweets labeled by 3 group participants (for training, cross validation and test dataset) in the rank list are used to predict the query difficulty. Each query's top 15 tweets in retrieval list are labeled. In our experiment, if the number of non-relevant tweets is no less than 5, 9 and 12, we considered the query as a common query, difficult query and highly difficult query respectively. After that, we train the negative feedback model we described before, and for the three kinds of queries we trained different parameters respectively. In table <ref type="table" coords="8,310.35,545.77,4.55,10.48" target="#tab_2">3</ref>, this baseline run we submitted is different from "BL" we mentioned before, because at that time there is no labeled data for training parameters, the run1 and run1fix in our submitted runs both make use of author model and relevance feedback, but with different parameters. Run2 have considered the negative feedback method we described before. So in table 2 and 3, we could see that, negative feedback could improve the result we retrieved before. That means the tweets suffers from too severe noise problem to make a simple query expansion directly. Our negative feedback method works better than other methods we have implemented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>As some papers mentioned <ref type="bibr" coords="9,254.27,195.81,12.36,10.48" target="#b2">[3]</ref> [4] <ref type="bibr" coords="9,287.99,195.81,11.71,10.48" target="#b4">[5]</ref>, there are some features we could use to improve the performance of retrieval: user information, hashtag, URL. Need to say, user profile and user's friends are both extraordinary useful information. We have not use these features, partly because the dataset released does not include them.</p><p>However, more importantly, the word co-occurrence in tweets is still extremely sparse; Sparsity and noise should be solved by using better methods. Moreover, it is reasonable to believe that several kinds of external resources could enhance the effectiveness of retrieval model. Our future work will lay emphasis on training receiver's model and using external resources to improve the retrieval effects; The structure of microblog is considerable contents that is worthy of research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,110.85,135.90,369.45,251.13"><head>Table 1 :</head><label>1</label><figDesc>The words selected from relevant documents Toyota Recall Mexico drug war Thorpe return in 2012 Olympics</figDesc><table coords="5,110.85,169.62,321.49,217.41"><row><cell>lexus</cell><cell>cartels</cell><cell>comeback</cell></row><row><cell>safety</cell><cell>violence</cell><cell>London</cell></row><row><cell>pedal</cell><cell>border</cell><cell>swimming</cell></row><row><cell>tundra</cell><cell>police</cell><cell>Ian Thorpe</cell></row><row><cell>fuel</cell><cell>tijuana</cell><cell>gold medal</cell></row><row><cell>pipe</cell><cell>fight</cell><cell>world</cell></row><row><cell>crack</cell><cell>traffick</cell><cell>championship</cell></row><row><cell>leak</cell><cell>conflict</cell><cell>welcome</cell></row><row><cell>avensis</cell><cell>government</cell><cell>Phelps</cell></row><row><cell>defect</cell><cell>calderon</cell><cell>australia</cell></row><row><cell cols="2">selected words can be seen in table 1.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,140.12,135.90,302.05,143.26"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table coords="7,140.12,135.90,302.05,143.26"><row><cell></cell><cell></cell><cell cols="3">Average P@30 and MAP</cell></row><row><cell></cell><cell>BL</cell><cell cols="3">BL+FB AT+FB AT+FB+NFB</cell></row><row><cell cols="2">P@30 0.2025</cell><cell>0.2654</cell><cell>0.3986</cell><cell>0.4075</cell></row><row><cell cols="2">MAP 0.1233</cell><cell>0.1632</cell><cell>0.2469</cell><cell>0.2986</cell></row><row><cell>S(D, Q) =</cell><cell cols="3">[p(w|θ q ) -αp(w|θ N )] log p(w|t w )</cell></row><row><cell>w∈V</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,110.85,136.56,388.54,137.15"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table coords="8,110.85,136.56,388.54,137.15"><row><cell cols="3">Average P@30, MAP and R-prec over all submitted runs(under the</cell></row><row><cell cols="2">two relevance criteria)</cell></row><row><cell></cell><cell>All</cell><cell>High</cell></row><row><cell>Runs</cell><cell cols="2">P@30 MAP R-prec P@30 MAP R-prec</cell></row><row><cell cols="3">baseline 0.0769 0.0722 0.0959 0.0182 0.0351 0.0271</cell></row><row><cell>run1</cell><cell cols="2">0.3823 0.1747 0.2352 0.1202 0.1043 0.1323</cell></row><row><cell cols="3">run1fix 0.3986 0.2469 0.3019 0.1354 0.2353 0.2517</cell></row><row><cell>run2</cell><cell cols="2">0.4075 0.2986 0.3571 0.1414 0.2598 0.2622</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_0" coords="7,139.91,416.03,214.00,15.15;7,110.85,445.96,388.55,10.48;7,110.85,460.40,388.54,10.48;7,110.85,474.85,388.55,10.48;7,110.85,489.29,151.27,10.48"><p>Experiment and AnalysisConsistent with the official method, our main evaluation indicators are P@30 and MAP. The experiments are designed to answer two questions: How useful the author's information is in the retrieval task? How does the noise problem could be alleviated or solved?</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Author Information</head><p>In our experiment, there are 3, 673, 968 authors in total, and we just keep the author who publish no less than 5 tweets to train topic model. That is, the users who published more than five tweets are thought as containing useful information. The toolkit we used to run our baseline method is lemur. The comparison of author model and baseline method can be seen at table 2, more detailed information can be seen in Table <ref type="table" coords="7,354.87,618.35,4.55,10.48">3</ref>. Where BL is the baseline method, F B denotes feedback, N F B denotes the negative feedback, and AT means the author topic model.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,134.92,420.93,364.48,10.48;9,134.92,435.37,225.79,10.48" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,403.14,420.93,96.27,10.48;9,134.92,435.37,134.98,10.48">Characterizing microblogs with topic models</title>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Susan</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dan</forename><surname>Liebling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,284.95,435.37,37.65,10.48">ICWSM</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,134.92,459.78,364.48,10.48;9,134.92,474.23,364.48,10.48;9,134.92,488.67,364.48,10.48;9,134.92,503.12,364.48,10.48;9,134.92,517.57,26.66,10.48" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,255.44,474.23,243.95,10.48;9,134.92,488.67,108.74,10.48">Short Text Classification in Twitter to Improve Information Filtering</title>
		<author>
			<persName coords=""><forename type="first">Bharath</forename><surname>Sriram</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dave</forename><surname>Fuhry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Engin</forename><surname>Demir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hakan</forename><surname>Ferhatosmanoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Murat</forename><surname>Demirbas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,258.30,488.67,241.09,10.48;9,134.92,503.12,359.96,10.48">Proceeding of the 33rd international ACM SI-GIR conference on Research and development in information retrieval</title>
		<meeting>eeding of the 33rd international ACM SI-GIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,134.92,541.97,364.47,10.48;9,134.92,556.42,364.48,10.48;9,134.92,570.87,364.48,10.48;9,134.92,585.31,102.10,10.48" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,456.86,541.97,42.54,10.48;9,134.92,556.42,164.07,10.48">Ranking Approaches for Microblog Search</title>
		<author>
			<persName coords=""><forename type="first">Rinkesh</forename><surname>Nagmoti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ankur</forename><surname>Teredesai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martine</forename><forename type="middle">De</forename><surname>Cock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,312.26,556.42,187.14,10.48;9,134.92,570.87,336.19,10.48">2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="153" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,134.92,609.72,364.48,10.48;9,134.92,624.17,364.48,10.48;9,134.92,638.61,292.27,10.48" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="9,201.45,624.17,297.94,10.48;9,134.92,638.61,133.94,10.48">Incorporating Query Expansion and Quality Indicators in Searching Microblog Posts</title>
		<author>
			<persName coords=""><forename type="first">Kamran</forename><surname>Massoudi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manos</forename><surname>Tsagkias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wouter</forename><surname>Weerkamp</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011-04">April 2011</date>
			<biblScope unit="page" from="19" to="21" />
		</imprint>
		<respStmt>
			<orgName>ECIR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,134.92,129.59,364.47,10.48;10,134.92,144.03,364.48,10.48;10,134.92,158.48,243.55,10.48" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,206.30,129.59,255.84,10.48">Hashtag Retrieval in a Microblogging Environment</title>
		<author>
			<persName coords=""><forename type="first">Miles</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,477.12,129.59,22.27,10.48;10,134.92,144.03,364.48,10.48;10,134.92,158.48,208.46,10.48">Proceeding of the 33rd international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>eeding of the 33rd international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,134.92,182.89,61.55,10.48;10,212.68,182.89,208.54,10.48;10,437.45,182.89,61.95,10.48;10,134.92,197.33,48.19,10.48;10,198.58,197.33,102.48,10.48;10,316.53,197.33,182.87,10.48;10,134.92,211.78,184.43,10.48" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="10,217.46,182.89,194.30,10.48">Statistical data mining tutorials</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moore</surname></persName>
		</author>
		<ptr target="http://www.autonlab.org/tutorials/" />
		<imprint>
			<date type="published" when="2000-05">May 2000</date>
			<pubPlace>Pittsburgh</pubPlace>
		</imprint>
		<respStmt>
			<orgName>CMU</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct coords="10,134.92,236.19,364.48,10.48;10,134.92,250.63,364.48,10.48;10,134.92,265.08,229.61,10.48" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,338.73,236.19,160.67,10.48;10,134.92,250.63,78.21,10.48">Empirical Study of Topic Modeling in Twitter</title>
		<author>
			<persName coords=""><forename type="first">Liangjie</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brian</forename><forename type="middle">D</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,227.40,250.63,267.12,10.48">1st Workshop on Social Media Analytics (SOMA 10)</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010-07-25">July 25, 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,134.92,289.49,364.47,10.48;10,134.92,303.93,364.48,10.48;10,134.92,318.38,364.48,10.48;10,134.92,332.83,364.48,10.48;10,134.92,347.27,142.26,10.48" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,453.34,289.49,46.05,10.48;10,134.92,303.93,364.48,10.48;10,134.92,318.38,103.36,10.48">A Generative Blog Post Retrieval Model that Uses Query Expansion based on External Collections</title>
		<author>
			<persName coords=""><forename type="first">Wouter</forename><surname>Weerkamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,252.59,318.38,246.81,10.48;10,134.92,332.83,364.48,10.48;10,134.92,347.27,105.88,10.48">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,134.92,371.68,364.48,10.48;10,134.92,386.13,364.48,10.48;10,134.92,400.57,232.15,10.48" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,438.59,371.68,60.80,10.48;10,134.92,386.13,109.73,10.48">Information Credibility on Twitter</title>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marcelo</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Barbara</forename><surname>Poblete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,258.26,386.13,241.13,10.48;10,134.92,400.57,96.00,10.48">Proceedings of the 20th international conference on World wide web</title>
		<meeting>the 20th international conference on World wide web</meeting>
		<imprint>
			<date type="published" when="2011">March 28CApril 1, 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,134.92,424.98,364.47,10.48;10,134.92,439.43,364.48,10.48;10,134.92,453.87,362.84,10.48" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,141.96,439.43,266.89,10.48">An Empirical Study on Learning to Rank of Tweets</title>
		<author>
			<persName coords=""><forename type="first">Yajuan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Long</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heung-Yeung</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,424.61,439.43,74.79,10.48;10,134.92,453.87,327.43,10.48">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,134.92,478.28,364.48,10.48;10,134.92,492.73,364.48,10.48;10,134.92,507.17,364.48,10.48" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,337.88,478.28,161.53,10.48;10,134.92,492.73,94.33,10.48">User context as a source of topic retrieval in twitter</title>
		<author>
			<persName coords=""><forename type="first">Ravali</forename><surname>Pochampally</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,243.33,492.73,256.06,10.48;10,134.92,507.17,329.56,10.48">Proceeding of the 34rd international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>eeding of the 34rd international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,134.92,531.58,364.48,10.48;10,134.92,546.03,364.49,10.48;10,134.92,560.47,364.48,10.48;10,134.92,574.92,26.66,10.48" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,141.81,546.03,166.66,10.48">Spam filtering for short messages</title>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jos</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mara</forename><surname>Gmez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Enrique</forename><forename type="middle">Puertas</forename><surname>Hidalgo</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Snz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,323.31,546.03,176.09,10.48;10,134.92,560.47,358.30,10.48">Proceedings of the sixteenth ACM conference on Conference on information and knowledge management</title>
		<meeting>the sixteenth ACM conference on Conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,134.92,599.33,364.48,10.48;10,134.92,613.77,364.48,10.48;10,134.92,628.22,364.48,10.48;10,134.92,642.66,61.13,10.48" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,470.67,599.33,28.72,10.48;10,134.92,613.77,305.88,10.48">Twit-terSearch: a comparison of microblog search and web search</title>
		<author>
			<persName coords=""><forename type="first">Jaime</forename><surname>Teevan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Merredith</forename><surname>Ringel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Morris</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,454.69,613.77,44.71,10.48;10,134.92,628.22,337.42,10.48">Proceedings of the fourth ACM international conference on Web search</title>
		<meeting>the fourth ACM international conference on Web search</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="35" to="44" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
