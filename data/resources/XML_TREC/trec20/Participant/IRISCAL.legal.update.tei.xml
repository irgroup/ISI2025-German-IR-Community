<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,112.53,61.77,370.25,15.55">Cluster-based Relevance Feedback : Legal Track 2011</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,164.20,97.00,75.10,7.68"><forename type="first">Kripabandhu</forename><surname>Ghosh</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Indian Statistical Institute</orgName>
								<address>
									<settlement>Kolkata</settlement>
									<region>West Bengal</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,248.66,97.00,74.72,7.68"><forename type="first">Prasenjit</forename><surname>Majumder</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Dhirubhai Ambani Institute of Information and Communication Technology</orgName>
								<address>
									<settlement>Gandhinagar</settlement>
									<region>Gujarat</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,346.83,97.00,80.08,7.68"><forename type="first">Swapan</forename><forename type="middle">Kumar</forename><surname>Parui</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Indian Statistical Institute</orgName>
								<address>
									<settlement>Kolkata</settlement>
									<region>West Bengal</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,112.53,61.77,370.25,15.55">Cluster-based Relevance Feedback : Legal Track 2011</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">16E43020F2AA638C86FF7CED5B736EDE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is our second participation in the TREC Legal Track. The TREC Legal Track 2011 featured only the Learning Task. We participated in Topics 401 and 403. We used Lemur 4.11 1 for Boolean retrieval and followed it with a clustering technique, where we chose members from each cluster (which we called seeds) for relevance judgement by the TA and assumed all other members of the cluster whose seeds are assessed as relevant to be relevant. Based on the relevance information from seeds and their clusters, we applied Rocchio relevance feedback technique implemented in Terrier 3.0 2 . Then, we used the feedback terms for the expansion of both the text queries and the Boolean queries. Finally, we used Z-fusion[4], a data fusion technique, on two of our runs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This year, TREC Legal Track comprised of a single task -Learning Task, which was similar to the 2010 Learning Task except that this year the participants would start with "zero knowledge" (no training documents were available). Three topics -nos 401, 402 and 403, were given for the task. For each topic, the assigned Topic Authorities (TAs) provided "coding guidelines" and conducted a "kick-off" call, which was the only opportunity for the teams to interact with the TAs. Our team participated only in topics 401 and 403. The participants had to submit interim runs on the basis of the number of documents submitted for assessment, before the final submission. They could ask for relevance assessments of maximum 1000 documents per topic, at most 100 documents each time. After the final submission, the relevance judgements of all the documents requested for determination to the TA by all the teams were made available. The participants could use these determinations and make mop-up submissions. The data set this year was the same as that used in the last year -the EDRM Enron v2 dataset which consisted of Enron emails and their native attachments separately provided. There were two formats of the data on offer, viz., XML and PST. Later on deduplicated text-only version was also available which we chose for our experiment. The data was available at http://durum0.uwaterloo.ca/trec/legal10/. The emails were of 596MB (compressed) and the native attachments were of 6GB (compressed). The collection contained 685592 documents. We used Indri search engine of Lemur 4.11 toolkit for Boolean retrieval and Terrier 3.0 for Rocchio relevance feedback using DFR <ref type="bibr" coords="1,327.92,525.71,14.99,9.96">[2]</ref>-BM25 <ref type="bibr" coords="1,371.23,525.71,10.52,9.96">[3]</ref> model.</p><p>We describe our approach in section 2, present our results in section 3 and conclude in section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Approach</head><p>In our last year's participation in the Legal Interactive Task <ref type="bibr" coords="1,327.36,592.43,12.68,9.96">[1]</ref>, we found that Indri search tool of Lemur 4.11, with its rich Boolean query language, is a very effective tool in utilizing the important keywords of a topic and retrieving a set of useful documents. So, we continued to use Indri for Boolean retrieval. To suit the nature of the Learning Task, we decided to use Terrier 3.0 to use its built-in relevant feedback support. In addition, we used our clustering algorithm (described in the following section) to maximize assessor feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Clustering Algorithm</head><p>Let G(V, E) be an undirected graph, where V (the set of vertices) is the set of all documents in a given collection C. There is an edge e ∈ E between vertices v 1 (d 1 ), v 1 (d 2 ) ∈ V , d 1 , d 2 being documents of C, if the normalised cosine similarity between d 1 and d 2 is greater than threshold (In our experiments, threshold is chosen as 0.3). Next, the connected components of G are found out. These components are our clusters. This is basically a single-linkage clustering which we thought would be appropriate for our experiment.</p><p>A cluster containing one or more judged relevant document(s) is considered as a "relevant cluster". In other words, each document of the cluster is assumed to be relevant. For a cluster not containing a judged relevant document, we send an arbitrarily chosen document as the representative (or seed) of the cluster for TA judgement. Such a cluster will be deemed relevant or nonrelevant according as its seed is judged as relevant or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Topic 401</head><p>The production request of topic 401 read as follows:</p><p>All documents or communications that describe, discuss, refer to, report on, or relate to the design, development, operation, or marketing of enrononline, or any other online service offered, provided, or used by the Company (or any of its subsidiaries, predecessors, or successors-in-interest), for the purchase, sale, trading, or exchange of financial or other instruments or products, including but not limited to, derivative instruments, commodities, futures, and swaps.</p><p>The coding instructions and the kick-off call provided crucial information about the notion of relevance of the topic. Based on this, we formed nine Indri queries: We submitted our first interim run -ISICLUT1 (prior to any assessment request) based on the documents retrieved by queries 1 and 2. We clustered all the documents returned by Indri queries 1 and 2 and manually inspected seeds from the clusters formed. All the seeds and their clusters deemed relevant were ranked above all other documents in the collection. We then sent the same seeds for assessor judgement. We continued our clustering exercise for the outputs of queries 3, 4, 5 and 6. By this time, we had finished our first 100 assessments. So, we submitted our second interim run -ISICLUT2. But now we had relevant document expanded from judged relevant seeds for queries 1 to 6. In this run, we arbitrarily ranked these documents and followed them with all other documents in the collection. Next we assessed all the seeds of 7, 8 and 9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Relevance Feedback and Boolean Query Expansion</head><p>We had achieved the relevance judgements of the seeds generated by the nine Indri queries discussed shortly. Next we decided to use Rocchio relevance feedback technique implemented in Terrier 3.0. Using this technique, we applied query expansion based on the relevance information received hitherto. At this stage, we tried out expansion of Boolean Indri queries. We could have done this kind of expansion in two ways. One, we could have expanded each of the nine Indri queries constructed initially. Another variant is that, we could expand the basic query of 401 as a whole. We tried both the approaches.</p><p>Using only the relevant assessments of Indri query 1, we obtained eight Rocchio feedback terms, viz. contact, user, product, password, launch, gosalia, screen and amita. Here, the Terrier query contained the terms enrononline and contact. So, the expanded Indri query for query 1 is as follows:</p><p>#band(enrononline contact #syn(user product password launch gosalia screen amita))</p><p>Similarly, we obtained the following expanded version of query 3: #band(enrononline #1(trade agreement) #syn(user ngpl product password screen click transact online offer))</p><p>We made only two querywise expansions, for queries 1 and 3, since they had high number of relevant documents which is necessary to generate good expansion terms.</p><p>We selected the new documents in top 100 of the ranked-list returned by Terrier after query expansion and sent them for TA assessment. For the new documents obtained by Indri expanded queries, we applied clustering and sent the seeds for assessment.</p><p>Next, we used all the relevant terms for 401 and obtained the following expanded Indri query:</p><p>#band(#syn(enrononline eol) #syn(tagg jarnold orig dollar bankruptcy may01 kiodex active nature)), where the basic Terrier query had the terms enrononline and eol.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Final Submission</head><p>At this stage, we had the relevant assessments of all the nine Indri queries and also those obtained through relevance feedback. We submitted the following three runs as the final submissions :</p><p>1. ISIROTTF : In this run, we placed the relevant documents in arbitrary order followed by all other documents in the collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">ISITRFTF :</head><p>We used Rocchio relevance feedback using all the relevant documents, the Terrier query containing the terms enrononline and eol 3. ISILRFTF : Here, the expansion terms returned by Rocchio feedback are used to expand the Indri query #band(#syn(enrononline eol)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Mop-up Submission</head><p>Before the mop-up submission, the relevance judgements of the documents submitted to the TA for assessment were released. We submitted the following runs, based on this relevance information :</p><p>1. ISIRoTAM : We placed the relevant documents in arbitrary order followed by all other documents in the collection.</p><p>2. ISITrFAM : We used Rocchio relevance feedback using all the relevant documents, the Terrier query containing the terms enrononline and eol 3. ISIFuSAM : this was the Z-fusion of the above two runs, with equal weight on each</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Final Submission</head><p>Our final submission for Topic 403 consisted in three runs:</p><p>1. ISIROTTF : We placed the relevant documents in arbitrary order followed by all other documents in the collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">ISITRFTF :</head><p>We used Rocchio relevance feedback using all the relevant documents, the Terrier query containing the terms -oil, gas, enron and environment 3. ISILRFTF : Here, the expansion terms returned by Rocchio feedback are used to expand the Indri query for the entire topic</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Mop-up Submission</head><p>Before the mop-up submission, the relevance judgements of the documents submitted to the TA for assessment were released. We submitted the following runs, based on this relevance information :</p><p>1. ISIROTAM : We placed the relevant documents in arbitrary order followed by all other documents in the collection.</p><p>2. ISITRFAM : We used Rocchio relevance feedback using all the relevant documents, the Terrier query containing the terms -oil, gas, enron and environment 3. ISIFUSAM : this was the Z-fusion of the above two runs, with equal weight on each</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>The results presented in this section were declared as "Preliminary evaluation results". The evaluation measure used was "hypothetical F1".  <ref type="table" coords="6,383.63,133.97,4.98,9.96" target="#tab_2">3</ref> shows the overall performance of all the submitted runs. As expected, the performance got better as more relevant documents were received. Relevance feedback proved to be a very effective tool in capturing new relevant documents from smaller number of judged relevant ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run type</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Future work</head><p>In our last year's participation, we learned that our clustering technique was quite effective in retrieving relevant documents. This yielded us very high precision but at the expense of recall and consequently, F-measure too. This led us to believe that restricting to relevant clusters would not serve the basic purpose of legal retrieval, which hinges on high recall. We had to use the initial relevance information to seek for more relevant documents from the entire corpus. We thought that relevance feedback and query expansion would suit our goal. In addition to the state-of-the-art text query expansion techniques, we made a humble attempt in Boolean query expansion, which produced promising results. In our mop-up submission, we also used data fusion in the hope of boosting couple of our runs. On the whole, as compared to our previous year's performance, we found that we have managed to strike a balance between precision and recall (reflected by F-measure).</p><p>In our clustering technique, we have basically implemented the single-linkage clustering algorithm. We are looking to implement the other type of hierarchical clustering -complete-linkage clustering. Also, in our technique we have chosen a representative document from a cluster (i.e., a seed ) arbitrarily. Instead of doing so, we will like to devise a method of choosing the best representative seed of a cluster.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,84.18,344.20,135.91,9.96;2,84.18,364.12,186.75,9.96;2,84.18,384.05,195.74,9.96;2,84.18,403.98,213.17,9.96;2,84.18,423.90,201.29,9.96;2,84.18,443.83,199.07,9.96;2,84.18,463.76,193.55,9.96;2,84.18,483.68,329.93,9.96;2,84.18,503.61,242.62,9.96"><head></head><label></label><figDesc>1. #band(enrononline contact) 2. #band(enrononline guest access emails) 3. #band(enrononline #1(trade agreement)) 4. #band(enrononline #syn(press news) release) 5. #band(enrononline #1(license agreement)) 6. #band(enrononline #1(financial product)) 7. #band(enrononline #5(trade derivative)) 8. #band(enrononline financial #syn(instrument product derivative swap)) 9. #band(enrononline #syn(marketing advertisement))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,202.38,371.81,190.53,270.08"><head>Table 1 :</head><label>1</label><figDesc>Topic 401 -Performance of runs</figDesc><table coords="5,202.38,371.81,190.53,270.08"><row><cell></cell><cell>Run id</cell><cell>Hypothetical F1</cell></row><row><cell cols="2">INTERIM ISICLUT1</cell><cell>8.8%</cell></row><row><cell>RUNS</cell><cell>ISICLUT2</cell><cell>8.8%</cell></row><row><cell>FINAL</cell><cell>ISIROTTF</cell><cell>12.2%</cell></row><row><cell>RUNS</cell><cell>ISITRFTF</cell><cell>50.5%</cell></row><row><cell></cell><cell>ISILRFTF</cell><cell>17.6%</cell></row><row><cell>MOP</cell><cell>ISIRoTAM</cell><cell>8.8%</cell></row><row><cell>UP</cell><cell>ISITrFAM</cell><cell>57.8%</cell></row><row><cell>RUNS</cell><cell>ISIFuSAM</cell><cell>14.1%</cell></row><row><cell>Run type</cell><cell>Run id</cell><cell>Hypothetical F1</cell></row><row><cell>INTERIM</cell><cell>ISICLST1</cell><cell>11.0%</cell></row><row><cell>RUNS</cell><cell>ISIRFCT2</cell><cell>7.2%</cell></row><row><cell>FINAL</cell><cell>ISIRoTTF</cell><cell>9.0%</cell></row><row><cell>RUNS</cell><cell>ISITrFTF</cell><cell>13.9%</cell></row><row><cell></cell><cell>ISILrFTF</cell><cell>4.6%</cell></row><row><cell>MOP</cell><cell>ISIROTAM</cell><cell>32.5%</cell></row><row><cell>UP</cell><cell>ISITRFAM</cell><cell>24.9%</cell></row><row><cell>RUNS</cell><cell>ISIFUSAM</cell><cell>34.0%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,207.69,663.75,179.90,9.96"><head>Table 2 :</head><label>2</label><figDesc>Topic 403 -Performance of runs</figDesc><table coords="6,192.63,22.90,210.02,57.78"><row><cell></cell><cell></cell><cell cols="2">Hypothetical F1</cell><cell></cell></row><row><cell>Topic no</cell><cell>Best</cell><cell cols="3">Median Worst Our Best</cell></row><row><cell>401</cell><cell>58.8%</cell><cell>28.0%</cell><cell>8.8%</cell><cell>57.8%</cell></row><row><cell>402</cell><cell>58.8%</cell><cell>13.1%</cell><cell>2.3%</cell><cell>-</cell></row><row><cell>403</cell><cell>72.0%</cell><cell>14.2%</cell><cell>3.1%</cell><cell>34.0%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,86.94,92.18,322.09,51.75"><head>Table 3 :</head><label>3</label><figDesc>Overall performance of all submitted runs Table 1 and 2 show our performance for Topics 401 and 403. Table</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,87.25,669.62,112.65,7.68"><p>http://www.lemurproject.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,87.25,679.12,67.97,7.68"><p>http://terrier.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,72.00,42.88,371.51,9.96;4,72.00,66.07,413.19,8.49;4,72.00,78.02,502.11,8.49;4,72.00,89.97,465.50,8.49;4,72.00,101.93,470.72,8.49;4,72.00,113.88,517.79,8.49;4,72.00,125.84,313.81,8.49;4,86.94,146.49,405.04,9.96" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,72.00,42.88,371.51,9.96;4,72.00,66.07,413.19,8.49;4,72.00,78.02,502.11,8.49;4,72.00,89.97,465.50,8.49;4,72.00,101.93,470.72,8.49;4,72.00,113.88,517.79,8.49;4,72.00,125.84,308.58,8.49">We used similar techniques for Topic 403. The production request for Topic 403 was: The pertinent request for production seeks All documents or communications that describe, discuss, refer to, report on, or relate to the environmental impact of any activity or activities undertaken by the Company including, but not limited to, any measures taken to conform to, comply with, avoid, circumvent, or influence any existing or proposed rule(s), regulation(s), law(s), standard(s), or other proscription(s), such as those governing environmental emissions, spills, pollution, noise, and/or animal habitats</title>
		<imprint/>
	</monogr>
	<note>Based on the kick-off call and coding guidelines, we formed the following seven Indri queries</note>
</biblStruct>

<biblStruct coords="4,88.05,168.41,211.12,9.96" xml:id="b1">
	<monogr>
		<title level="m" coord="4,96.91,168.41,197.44,9.96">#band(#syn(oil gas) enron spill environment</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,88.05,188.34,281.72,9.96" xml:id="b2">
	<monogr>
		<title level="m" coord="4,127.40,188.34,133.84,9.96">#syn(oil gas) enron spill #syn</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,88.05,208.26,374.40,9.96" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="4,127.40,208.26,335.04,9.96">#syn(oil gas) #syn(leak spill) #syn(environment atmosphere surrounding))</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,88.05,228.19,435.23,9.96;4,96.90,240.14,111.27,9.96" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="4,127.40,228.19,395.88,9.96;4,96.90,240.14,25.76,9.96">#syn(oil gas) #syn(spill emission) #syn(violation negligence) #syn(rule law regulation) #uw25</title>
		<imprint/>
	</monogr>
	<note>prevent damage</note>
</biblStruct>

<biblStruct coords="4,88.05,260.07,435.23,9.96;4,96.90,272.02,187.61,9.96" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="4,127.40,260.07,395.88,9.96;4,96.90,272.02,187.61,9.96">#syn(oil gas) pollution #syn(damage hazard harmful) #syn(environment atmosphere surrounding) #syn(air water sea river ocean))</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,88.05,311.87,248.66,9.96" xml:id="b6">
	<monogr>
		<title level="m" coord="4,96.91,311.87,151.07,9.96">#band(enron animal habitat #syn</title>
		<imprint/>
	</monogr>
	<note>harm damage kill</note>
</biblStruct>

<biblStruct coords="4,86.94,333.78,436.32,9.96;4,72.00,345.75,451.27,9.96;4,72.00,357.70,215.54,9.96" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="4,86.94,333.78,436.32,9.96;4,72.00,345.75,451.27,9.96;4,72.00,357.70,212.32,9.96">We made our first interim submission ISICLST1 using the documents retrieved by all the above queries. We clustered them, manually judged the seeds and placed the judged relevant clusters in the ranked list above the other documents in the list</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,76.71,384.12,286.49,8.94;4,72.00,401.99,451.28,9.96;4,72.00,413.94,204.33,9.96;4,86.94,437.85,436.31,9.96;4,72.00,449.80,119.33,9.96" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="4,107.00,384.12,256.19,8.94;4,72.00,401.99,451.28,9.96;4,72.00,413.94,204.33,9.96;4,86.94,437.85,220.73,9.96">Relevance Feedback and Boolean Query Expansion Like Topic 401, here also we used Rocchio relevance feedback and expanded the Boolean Indri queries. We expanded query 1 into the following query: #band(#syn(oil gas) enron spill environment #syn</title>
		<imprint/>
	</monogr>
	<note>transrede tg plaintiff bbpl approximate mmcmd pipelin gtb court bolivian</note>
</biblStruct>

<biblStruct coords="4,86.94,473.72,436.33,9.96;4,72.00,485.67,451.28,9.96;4,72.00,497.63,205.74,9.96;4,86.94,521.53,436.34,9.96;4,72.00,533.49,164.03,9.96" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="4,86.94,473.72,436.33,9.96;4,72.00,485.67,451.28,9.96;4,72.00,497.63,205.74,9.96;4,86.94,521.53,295.23,9.96">Here Terrier query contained the terms oil, gas, enron, spill and environment. Rocchio feedback yielded the terms -transrede, tg, plaintiff, bbpl, approximate, mmcmd, pipelin, gtb, court and bolivia. Similarly, query 2 was expanded into following: #band(#syn(oil gas) enron spill #syn(cleanup #1(clean up)) #syn</title>
		<imprint/>
	</monogr>
	<note>elektro court transrede appeal teixeira silva serec freire dpc tozzini</note>
</biblStruct>

<biblStruct coords="4,86.94,557.40,436.31,9.96;4,72.00,569.36,90.86,9.96;4,86.94,593.26,436.34,9.96;4,72.00,605.22,96.63,9.96" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="4,122.85,557.40,400.40,9.96;4,72.00,569.36,90.86,9.96;4,86.94,593.26,203.58,9.96">we did expansion for the entire topic (using the whole set of relevance assessments) and the expanded query was: #band(#syn(oil gas) enron environment #syn</title>
		<author>
			<persName coords=""><surname>Finally</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>transrede court cuiab tg plaintiff pipelin approxim bolivian gtb elektro</note>
</biblStruct>

<biblStruct coords="6,72.00,410.40,75.49,12.93" xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.50,434.78,252.87,9.96;6,372.19,434.78,77.06,9.96;6,472.07,434.78,51.18,9.96;6,87.50,446.74,187.96,9.96" xml:id="b12">
	<monogr>
		<ptr target="http://trec-legal.umiacs.umd.edu/itg10final.pdf" />
		<title level="m" coord="6,87.50,434.78,248.74,9.96">Trec2010 legal track interactive task guidelines</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.50,466.67,435.80,9.96;6,87.50,478.62,402.61,9.96" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="6,305.34,466.67,217.97,9.96;6,87.50,478.62,199.90,9.96">Probabilistic models of information retrieval based on measuring the divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">Gianni</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cornelis Joost</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,296.70,478.96,97.04,9.18">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="389" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.50,498.55,435.79,9.96;6,87.50,510.50,305.77,9.96" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="6,272.84,498.55,245.59,9.96">The probabilistic relevance framework: Bm25 and beyond</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,87.50,510.84,214.17,9.18">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.50,530.43,435.75,9.96;6,87.50,542.38,160.04,9.96" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="6,155.73,530.43,294.79,9.96">Data fusion for effective european monolingual information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,99.96,542.38,111.57,9.96">Proceedings of CLEF&apos;2004</title>
		<meeting>CLEF&apos;2004</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="233" to="244" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
