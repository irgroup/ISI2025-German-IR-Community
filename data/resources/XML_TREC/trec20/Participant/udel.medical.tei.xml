<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,64.32,72.54,481.00,16.59">Using Multiple External Collections for Query Expansion</title>
				<funder>
					<orgName type="full">National Institutes of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,220.32,118.12,75.05,11.06"><forename type="first">Dongqing</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer &amp; Information Sciences University of Delaware Newark</orgName>
								<address>
									<postCode>19716</postCode>
									<region>DE</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,321.96,118.12,78.17,11.06"><forename type="first">Ben</forename><surname>Carterette</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer &amp; Information Sciences University of Delaware Newark</orgName>
								<address>
									<postCode>19716</postCode>
									<region>DE</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,64.32,72.54,481.00,16.59">Using Multiple External Collections for Query Expansion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B9C20FC83B7A782795FEDF0EAD177D9D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>For the 2011 Medical Records Track, we used several external collections for query expansion and mainly explored three research questions:</p><p>First, we investigated the possibility of using query sessions from PubMed query logs for improving the estimation of a relevance model. In a typical search scenario, a user may submit multiple queries before she actually finds satisfactory search results. These closely related queries form a single query session which represents a single information need. By finding relevant query sessions with regard to a Medical Track topic we can incorporate into our relevance model useful query terms which reflect real information needs that are more or less related to the Medical Track topic.</p><p>Second, we explored how the size and quality of external collections would impact the effectiveness of query expansion.</p><p>More specifically, we used TREC 2007 Genomics Track data and ImageCLEF 2009 Medical Retrieval data. The former collection is more genomics-related and is larger while the latter one is more medical-related and is much smaller. Intuitively, it is more likely for a larger external collection to contain more good expansion terms. However, the quality (in terms of the overlapping concepts between the target collection and an external collection) can be an important factor as well. This allowed us to carry out a pilot study on the relationship between collection quality, size, and the effect on query expansion. Third, we used a mixture of external collections for query expansion. In particular, we explored methods that can adaptively combine evidence from multiple collections for different topics. Usually, the weights for a mixture relevance model are determined via training on a test collection, and thus are fixed across all topics. If we could estimate the concept overlapping of a topic with external collections and assign weights for the mixture model accordingly, the system can be adaptive to topics and may achieve a better performance. That is the motivation for this third research direction.</p><p>We first describe our retrieval models and systems in Sections 2 and 3. Then in Section 4 we show and compare the official TREC evaluation results of our submissions, and further analyze our retrieval system performance based on the test collection. Following that, we discuss the above research questions in Section 5. We conclude in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RETRIEVAL MODEL</head><p>We used a language modeling-based approach of applying a mixture of relevance models for query expansion as described by Diaz and Metzler <ref type="bibr" coords="1,438.36,348.93,9.12,8.97" target="#b3">[3]</ref>. The expanded relevance model estimate based on the original query and an external collection was implemented in the Indri<ref type="foot" coords="1,477.84,368.84,3.65,5.47" target="#foot_0">1</ref> system by formulating a query in the following format:</p><formula xml:id="formula_0" coords="1,316.80,401.25,238.61,19.53">#weight( λ #combine(w1 w2 ... w |Q| ) (1 -λ) #weight( p1 e1 p2 e2 ... pm em ) ),</formula><p>where λ is the weight assigned to the original query language model, w's are terms from the original query, and e's are the m expanded terms with the highest probabilities p's which are computed by the formula:</p><formula xml:id="formula_1" coords="1,361.20,480.45,190.83,27.03">pi = p(ei| θQ) = k j=1 p(ei|θ d j )p(Q|θ d j ), (<label>1</label></formula><formula xml:id="formula_2" coords="1,552.03,489.09,3.91,8.97">)</formula><p>where θQ is the estimate of relevance model based on an external collection, dj's are top-ranked k documents retrieved from the external collection, and θ d j is the document language model of dj. An expanded query looks like the following:</p><p>#weight( 0.7 #combine(female breast cancer mastectomies admission) 0.3 #weight( 0.225 mastectomy 0.145 women 0.110 risk 0.107 prophylactic 0.101 bct 0.074 radiate 0.068 therapy 0.062 radiotherapy 0.058 surgery 0.050 adjuvant ) )</p><p>This Indri query format can be extended to use multiple external collections for query expansion by formulating a #weight expression for each collection separately, then including them in the Indri query with a new weight parameter (such that weight parameters always sum to 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">RETRIEVAL SYSTEMS</head><p>This section describes six systems. We submitted 4 runs based on these systems. The first system used the target collection (i.e., medical records collection) only. The rest all used external information. We implemented all systems using Indri and trained them on the TREC sample test collection which contains 4 sample queries and 27 relevant visits.</p><p>In addition to the standard stopwords, we also removed 'patient' and 'patients' in the topics because they are common words in the medical records.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baseline</head><p>The baseline system used the target collection only. However, before indexing we merged multiple reports from the same visit into one single visit file based on the report-tovisit mapping information provided by NIST, which converted 100,866 reports to 17,198 visit files. In the retrieval process, the Dirichlet smoothing parameter µ of the language model was the only free parameter for this baseline system and was trained on the sample test collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Using Diagnosis Description</head><p>For this system, we further expanded all visit files by replacing the admission and discharge diagnosis codes with their corresponding descriptions<ref type="foot" coords="2,183.12,312.56,3.65,5.47" target="#foot_1">2</ref> (note that this procedure was taken before indexing for all the following systems as well). In addition, since the patient de-identifying procedure marked the age entities in a systematic way across all reports, we also extracted the age information, if there was in the report, and made it as a new field. The retrieval process was exactly the same as the previous system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Using Genomics Data</head><p>This system used the TREC 2007 Genomics Track dataset for relevance model estimation. This dataset contains 162,259 full-text articles in HTML format from 49 genomics-related journals <ref type="bibr" coords="2,90.12,441.57,9.12,8.97" target="#b4">[4]</ref>. We did not pre-process this dataset and we used Indri's default setting for retrieving documents from Genomics data. The expanded query model was computed according to Equation <ref type="formula" coords="2,150.84,472.89,3.56,8.97" target="#formula_1">1</ref>. Parameters λ, m, and k were trained by sweeping them over their parameter spaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Using ImageCLEF Data</head><p>Another external collection is the ImageCLEF 2009 medical image retrieval dataset which contains 74,902 images from two radiology journals, Radiology and Radiographics. Each image has a corresponding XML file containing its caption and article title <ref type="bibr" coords="2,117.96,559.05,9.12,8.97" target="#b7">[7]</ref>. The file also contains a URL of the article in which the image appears. This allowed us to crawl an additional 5,704 full-text articles as another external collection. We followed the same procedure as the previous system for estimating the query model. In this paper, we denote the collection containing captions and titles as CLEF-CT and the one containing full-text articles as CLEF-A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Using PubMed Query Log</head><p>In this system, a one-day PubMed query log was used. The users in the log are de-identified by the NLM to protect their privacy <ref type="bibr" coords="2,109.20,676.53,9.12,8.97" target="#b5">[5]</ref>. The content of the log file looks like the following:</p><p>YAAAAI|63|alzheimer's disease inhibition kva2Y4IOFlsAAAx3xiYAAAAM|63|RNA interference plymerase ... 4AAAAH|103|breast cancer and insulin resistance jFnDXYIOFpIAAEAb0QAAAAAH|103|Trpm5 insulin ... 08AAAAF|252|intracerebral hemorrhage 2ZK4IOFkQAABdJCyAAAAAJ|252|carotid artery track 3JNvrYIOFl0AAHs3MNoAAAAJ|252|papain AND teeth</p><p>Each line in the log file contains three parts, namely an anonymized user ID, seconds since midnight EST, and an query issued by that user, which are separated by vertical bars. There are 2,996,301 queries submitted by 627,455 unique users within a day, from midnight to midnight, and there is no click-through information associated with these queries.</p><p>After excluding users who are considered as 'bots' (who submitted over 50 queries per day) and all the null queries, we had 2,657,316 queries from 611,083 users. Figure <ref type="figure" coords="2,524.04,273.45,4.60,8.97" target="#fig_1">1</ref> shows the percentage distribution of number of users who issued a specific number of queries within a day. About 66% of the users submitted more than 5 queries. We further removed all special symbols, punctuations, and logical operators such as AND and OR from each query.</p><p>According to our hypothesis aforementioned, it is desired that query sessions could be identified from each user session (which contains all the queries submitted by a single user). However, finding query session boundaries is itself an open research question. Usually a time window of 30 minutes is used to separate sessions. There are other methods proposed specifically for query session segmentation in this one-day PubMed query log, such as using semantic and contextual information <ref type="bibr" coords="2,365.88,430.41,9.64,8.97" target="#b5">[5,</ref><ref type="bibr" coords="2,377.88,430.41,6.42,8.97" target="#b6">6]</ref>. For simplicity, we used a similar approach based on time for identifying query session boundaries as described below:</p><p>1. Treat each PubMed query (made italic in all the following steps to disambiguate it from the original medical records queries) as a document and index the query log.</p><p>2. For each of the k top-ranked queries, assign 1.0 as the weight for all query terms.</p><p>3. Obtain the corresponding user session of each topranked query (denoted as Q). All other queries in that user session are considered as relevant to the topic as well. However, the query term weights for those queries decay exponentially as a function of how far (in seconds) they are away from Q in that user session. If there are multiple queries found relevant within a single user session, the weights of other queries in that session will be computed according to their closest Q's. The assumption behind the above approach is that it is more likely for a user to submit two related queries if those two queries are close in time. Thus, we were essentially determining relevant query sessions by using a soft boundary, which was implemented as a decaying function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Using Two External Collections</head><p>Results on the sample test collection indicated that the Genomics data and PubMed query Log improved the baseline result by 20% to 30%. However, the ImageCLEF data did not show improvement. Thus, we used a mixture of the two promising datasets for our last system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RESULTS AND ANALYSIS</head><p>We submitted four runs to TREC based on the experimental results on the sample test collection. We summarize and analyze the results in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">TREC Results</head><p>Table <ref type="table" coords="3,79.68,495.34,4.60,8.97" target="#tab_0">1</ref> gives a summary of the runs from the six systems described in Section 3. We selected four runs for TREC submission as indicated in the last column. Table <ref type="table" coords="3,261.36,516.34,4.60,8.97" target="#tab_1">2</ref> shows the official evaluation results of the 4 submissions on four major evaluation measures. Results are based on the top 1000 retrieved visits for each run. udelgn has the best overall performance among the four runs.</p><p>All our four runs were in the second round of TREC submissions and thus they were not pooled and judged. Thus, we only compare our runs with the unjudged group. udelgn and udelbl are above the median for majority of topics on all three official evaluation measures (P@10, bpref, R-prec), while udelgn and udelbl are below the median for about half of the topics. Figure <ref type="figure" coords="3,142.08,641.85,4.60,8.97" target="#fig_2">2</ref> shows the result comparison for Rprec.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Analysis</head><p>Based on the evaluation results and our initial motivation of using external collections, we want to address several questions as listed below:</p><p>No 1) How much improvement over the baseline did we actually get after replacing the diagnosis codes with the description?</p><p>2) Are ImageCLEF data useful though we did not use them for TREC submission?</p><p>3) Why are the results of udelpm and udelmx worse than the other two runs? Does that mean the one-day PubMed query log is not applicable for our retrieval model?</p><p>To answer these questions, we re-evaluated all the systems described in Section 3 using cross-validation. The reason for using cross-validation is that we previously trained our systems on a very small sample test collection which might not reveal the true system performance well. Thus, we used 5-fold cross-validation on the official test collection. In each iteration, the retrieval model was trained on 28 queries to obtain the parameter setting for the best mean average precision (MAP) by sweeping over the parameter spaces according to Table <ref type="table" coords="3,366.72,479.37,3.56,8.97" target="#tab_3">3</ref>. Then the trained model was used to generate a rank list for the remaining 7 queries. After this process, we could get five separate rank lists which were further merged into one containing results for all the 35 topics (Topics 130 was dropped by TREC and actually not used for training here). Finally, we evaluated the merged results.   If we compare udelcf and udelcfa with udelbl, udelcf is just slightly better than udelbl on bpref. Thus, using CLEF-CT actually hurts the system performance. However, udelcfa consistently improves the baseline by more than 10% across all evaluation measures. This indicates that CLEF-A is better than CLEF-CT for query expansion. Furthermore, cross-validation results of systems udelpm and udelbl are quite different from their official TREC evaluation results. We think it was simply because the retrieval models of udelpm and udelmx overfitted the small sample test collections at that time. However, it seems that using the PubMed query log for query expansion has little effect on the system performance. We suspect that it is because the PubMed query log is quite different from the other external collections. For instance, queries are short but vary in length and format across different users. Typos are common in the log. Also, the log contains many navigational queries (e.g. author names, years, PMIDs) that are not useful. In fact, all these factors may prevent us from selecting the good expansion terms in the log. Moreover, the query log is just a one-day log, which means it may not cover all Medical Track topics well. That might be the reason that we observed improvements over a few topics but for the other topics PubMed log degraded the system performance (Figure <ref type="figure" coords="4,333.48,225.93,4.60,8.97" target="#fig_3">3</ref> explains this situation). As a result, the method of using query session for query expansion appeared to be less effective than the other methods. Thus, we need to find a better way to analyze this query log and extract useful information from it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">FURTHER EXPLORATION</head><p>In this section we describe some pilot studies. Based on the analysis in Section 4.2 we want to further explore two problems: 1) How the quality and size of the external collection may impact the performance of our retrieval systems; 2) How to effectively combine multiple external collections for query expansion. Some pilot studies are describe below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Quality vs. Size</head><p>The Genomics corpus is more genomics-related and is larger while the ImageCLEF corpus is more medical-related and is much smaller. It is more likely for a larger external collection which has overlapping concepts with the target collection to retrieve good expansion terms than a smaller one <ref type="bibr" coords="4,535.20,434.01,9.64,8.97" target="#b2">[2,</ref><ref type="bibr" coords="4,548.76,434.01,7.12,8.97">8,</ref><ref type="bibr" coords="4,316.80,444.45,6.42,8.97" target="#b3">3]</ref>. However, the quality of collections, in terms of their similarity with the target collection, is also an important factor <ref type="bibr" coords="4,343.56,465.45,9.12,8.97" target="#b3">[3]</ref>. For comparison, we summarizes the statistics of all external collections in Table <ref type="table" coords="4,445.68,475.89,3.56,8.97" target="#tab_5">5</ref>.</p><p>The CLEF-A collection is a superset of the CLEF-CT and thus is better in quality and size. Though Genomics collection may not be as good as both ImageCLEF collections in terms of quality, it is magnitudes larger than both Image-CLEF collections. That might be the reason that system udelgn outperformed udelcf and is only slightly inferior to udelcfa as shown in Table <ref type="table" coords="4,423.84,559.53,3.56,8.97" target="#tab_2">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Using Multiple Collections</head><p>Different external collections may all improve an initial ranking for a specific query but in different ways (e.g., Topics 129, 132, and 135 in Figure <ref type="figure" coords="4,432.12,616.53,3.57,8.97" target="#fig_0">4</ref>). Also, some external collections may improve an initial ranking while others may hurt the same initial ranking (e.g., Topics 124, 125, and 128 in Figure <ref type="figure" coords="4,346.32,647.97,3.57,8.97" target="#fig_0">4</ref>). That explains why system udelmx has the best MAP performance. However, the training time of this kind of systems grows exponentially as the number of external collection increases. If we can combine different external collections in a way that they are adaptive to specific queries, we can not only obtain better results than using a single external collection, but also improve the extensibility of the The CORI algorithm is mainly used in distributed information retrieval for resource selection and results merging. The algorithm first obtains information and statistics about individual collections via a query-based sampling approach and builds a set of resource descriptions that can accurately represent the contents of those collections. Then given a query, each collection will get a score based on the resource descriptions. Thus, CORI can select the top-ranked resources to search. Results from multiple resource will then be merged in a new ranking according to both the resource scores and original document scores.</p><p>We use CORI to build the resource descriptions for the medical records, Genomics, CLEF-A, and PubMed query log. Then, CORI assigns a different set of collection scores for each topic. We take those scores as collection weights in our relevance model. These scores could be thought of as the 'similarity' measure between a topic and a collection. A collection with high similarity scores may have more overlapping concepts with the topic and thus better expansion terms. We train k (number of top-ranked documents) and m (number of most frequent terms) using 5-fold crossvalidation. For simplicity, we use the same set of k and m for all external collections during each iteration of training. The CORI algorithm is already implemented in Indri and we use all the default settings.</p><p>We denote this CORI-based system as udelcori. The last row of Table <ref type="table" coords="5,88.20,625.89,4.60,8.97" target="#tab_2">4</ref> shows cross-validation results of udelcori. Though udelcori is not the top performing system, the results indicate that this weight assigning method is quite promising since it dynamically and automatically determines weights for each expansion clause for each query. Because it is unclear for now how the parameters of CORI will impact the results, we still need to do more exploration in the future. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>We have shown that using medical-related external collections for query expansion can effectively improve the baseline system. In addition, the size and quality of the expansion collection are two key factors of expansion effectiveness, and one can compensate the other. Moreover, the CORI resource selection algorithms can adaptively assign a set of weights to multiple expansion collections as well as the target collection. This query-adaptive resource weighting scheme has shown promising results and is worth further exploration.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,327.60,659.73,228.31,8.97;2,339.24,670.17,97.43,9.02;2,437.16,670.17,6.83,15.31;2,444.00,670.17,74.79,9.02"><head>4 .</head><label>4</label><figDesc>Aggregate term weights to get the top weighted m terms and compute p(e k |θ d )'s in Equation 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,53.76,257.86,239.21,8.97;3,53.76,268.42,141.06,8.97;3,53.80,54.08,238.86,189.58"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Distribution of number of users over number of queries they submitted.</figDesc><graphic coords="3,53.80,54.08,238.86,189.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,53.76,154.54,502.10,8.97;4,53.76,164.98,502.09,8.97;4,53.76,175.41,493.98,8.97;4,53.81,202.06,238.81,135.43"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: Difference between each system and median of TREC R-prec of the 80 unjudged runs for all 34 topics. Systems udelgn and udelbl are above the median for the majority of topics, while systems udelgn and udelbl are below the median for about half of the topics. Results of P@10 and bpref are similar to R-prec.</figDesc><graphic coords="4,53.81,202.06,238.81,135.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,53.76,351.70,239.06,8.97;4,53.76,362.26,239.10,8.97;4,53.76,372.70,115.48,8.97;4,174.00,372.70,7.16,15.31;4,186.00,372.70,107.24,8.97;4,53.76,383.14,239.10,8.97;4,53.76,393.58,239.11,8.97;4,53.76,404.02,105.66,8.97"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: MAP improvement of udelpm relative to udelbl. System udelpm performs relatively better than system udelbl on 7 ∼ 8 topics and relatively worse on about the same number of topics. For the majority of topics, these two system have roughly the same performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,316.80,380.26,239.10,8.97;5,316.80,390.82,173.94,8.97;5,316.84,288.10,238.89,77.96"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: MAP improvement of systems udelpm, udelgn, and udelcfa, relative to udelbl.</figDesc><graphic coords="5,316.84,288.10,238.89,77.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,323.28,54.45,227.23,169.77"><head>Table 1 :</head><label>1</label><figDesc>Run Summary</figDesc><table coords="3,323.28,54.45,227.23,169.77"><row><cell></cell><cell cols="2">. External Resource</cell><cell>RunID Submitted</cell></row><row><cell>1 2 3</cell><cell cols="3">none DCD (Diagnosis Code Desc.) udelbl udelba DCD + Genomics udelgn</cell><cell>√ √</cell></row><row><cell cols="3">4.a DCD + CLEF-CT</cell><cell>udelcf</cell></row><row><cell cols="4">4.b DCD + CLEF-A 5 DCD + Query Log 6 DCD + Genomics + Log</cell><cell>udelcfa udelpm udelmx</cell><cell>√ √</cell></row><row><cell></cell><cell cols="2">SystemID P@10</cell><cell>bpref R-prec MAP</cell></row><row><cell></cell><cell>udelbl</cell><cell cols="2">0.5324 0.5073 0.3907 0.3780</cell></row><row><cell></cell><cell>udelgn</cell><cell cols="2">0.5441 0.5217 0.4068 0.3924</cell></row><row><cell></cell><cell>udelpm</cell><cell cols="2">0.4206 0.4201 0.3085 0.2729</cell></row><row><cell></cell><cell>udelmx</cell><cell cols="2">0.4382 0.4545 0.3240 0.2827</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,316.80,237.10,239.34,19.41"><head>Table 2 :</head><label>2</label><figDesc>Official Evaluation Results (averaged over 34 topics)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,316.80,552.57,239.20,112.65"><head>Table 4</head><label>4</label><figDesc></figDesc><table coords="3,316.80,552.57,239.20,112.65"><row><cell cols="4">shows results of cross-validation. By comparing</cell></row><row><cell cols="4">udelba and udelbl, we can see that replacing diagnosis codes</cell></row><row><cell cols="4">with their descriptions improves the baseline by 4% to 6%</cell></row><row><cell cols="4">across all 4 evaluation measures. Using the Genomics data</cell></row><row><cell cols="4">Parameter From To (Exclusive) Step Size</cell></row><row><cell>µ</cell><cell>1000</cell><cell>30000</cell><cell>1000</cell></row><row><cell>λ</cell><cell>0.0</cell><cell>1.0</cell><cell>0.1</cell></row><row><cell>k</cell><cell>5</cell><cell>60</cell><cell>5</cell></row><row><cell>m</cell><cell>10</cell><cell>50</cell><cell>10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,316.80,677.62,239.17,40.29"><head>Table 3 :</head><label>3</label><figDesc>Parameter space for training. µ is the Dirichlet smoothing parameter, λ is the collection weight, k is the number of top-ranked documents, and m is the number of expansion terms.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,53.76,54.94,503.14,196.05"><head>Table 4 :</head><label>4</label><figDesc>Results by cross-validation. udelba is the baseline system. By using the description of diagnosis codes, system udelbl improves the baseline by 4 ∼ 6% on all 4 evaluation measures. udelcf and udelpm perform roughly the same as udelbl, while the other systems further improves the baseline. System udelmx has the best MAP.</figDesc><table coords="5,59.64,54.94,497.26,196.05"><row><cell cols="2">System ID External Resource</cell><cell></cell><cell>MAP</cell><cell>P@10</cell><cell>bpref</cell><cell>R-prec</cell></row><row><cell>udelba</cell><cell>none</cell><cell></cell><cell>0.3527</cell><cell>0.5059</cell><cell>0.4694</cell><cell>0.3654</cell></row><row><cell>udelbl</cell><cell>DCD</cell><cell></cell><cell cols="4">0.3741 (+ 6.1%) 0.5265 (+ 4.1%) 0.5004 (+ 6.6%) 0.3901 (+ 6.8%)</cell></row><row><cell>udelgn</cell><cell>DCD+Genomics</cell><cell></cell><cell cols="4">0.3907 (+10.8%) 0.5500 (+ 8.7%) 0.5057 (+ 7.7%) 0.3931 (+ 7.6%)</cell></row><row><cell>udelcf</cell><cell>DCD+CLEF-CT</cell><cell></cell><cell cols="4">0.3684 (+ 4.5%) 0.5176 (+ 2.3%) 0.5066 (+ 7.9%) 0.3891 (+ 6.5%)</cell></row><row><cell>udelcfa</cell><cell>DCD+CLEF-A</cell><cell></cell><cell cols="4">0.3920 (+11.1%) 0.5647 (+11.6%) 0.5188 (+10.5%) 0.4180 (+14.5%)</cell></row><row><cell>udelpm</cell><cell>DCD+Query Log</cell><cell></cell><cell cols="4">0.3740 (+ 6.0%) 0.5176 (+ 2.3%) 0.5054 (+ 7.7%) 0.3904 (+ 6.8%)</cell></row><row><cell>udelmx</cell><cell cols="2">DCD+Genomics+Log</cell><cell cols="2">0.4007 (+13.6%) 0.5382 (+6.4%)</cell><cell cols="2">0.5289 (+12.8%) 0.4146 (+13.5%)</cell></row><row><cell>udelcori</cell><cell cols="6">DCD+Genomics+CLEF-A+Log 0.3863 (+ 9.5%) 0.5588 (+10.5%) 0.5198 (+10.7%) 0.3981 (+ 8.9%)</cell></row><row><cell></cell><cell cols="3">Collection Documents Unique Terms</cell><cell cols="2">Total Terms Average Document Length</cell></row><row><cell></cell><cell>Genomics</cell><cell>162,259</cell><cell cols="2">2,143,156 1,070,113,111</cell><cell>6595</cell></row><row><cell></cell><cell>CLEF-A</cell><cell>5,704</cell><cell>162,032</cell><cell>37,050,614</cell><cell>6495</cell></row><row><cell></cell><cell>CLEF-CT</cell><cell>74,902</cell><cell>107,482</cell><cell>10,962,310</cell><cell>146</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,53.76,263.26,318.22,57.81"><head>Table 5 :</head><label>5</label><figDesc>Collection Statistics</figDesc><table /><note coords="5,53.76,291.22,239.06,8.97;5,53.76,301.66,239.20,8.97;5,53.76,312.10,161.55,8.97"><p><p><p>system. Thus, we borrow the idea of the CORI</p><ref type="bibr" coords="5,247.32,291.22,9.64,8.97" target="#b1">[1]</ref> </p>resource selection algorithm to assign a different set of weights to multiple collections for different queries.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,321.36,710.74,123.40,8.97"><p>http://lemurproject.org/indri/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,58.44,701.74,234.39,8.97;2,53.76,711.86,182.55,7.65"><p>We crawled diagnosis code descriptions from https:// drchrono.com/public_billing_code_search</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7.">ACKNOWLEDGMENTS</head><p>The authors would like to thank <rs type="person">Dr. Zhiyong Lu</rs> from <rs type="funder">NIH</rs>, <rs type="person">Dr. Jorge R. Herskovic</rs> and <rs type="person">Dr. Elmer V. Bernstam</rs> from <rs type="affiliation">University of Texas School of Health Information Sciences at Houston</rs>, for providing the one-day PubMed query log.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,321.29,613.05,96.59,10.76" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,330.96,625.05,188.11,8.97;5,330.96,635.49,203.80,8.97;5,330.96,645.93,142.12,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,373.08,625.05,130.88,8.97">Distributed information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,330.96,635.80,137.22,8.65">Advances in Information Retrieval</title>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="127" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,330.96,657.33,192.04,8.97;5,330.96,667.89,196.87,8.97;5,330.96,678.33,199.59,8.97;5,330.96,688.77,130.96,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,416.16,667.89,111.67,8.97;5,330.96,678.33,31.30,8.97">INQUERY does battle with TREC-6</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Swan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,382.08,678.64,148.47,8.65;5,330.96,689.08,39.18,8.65">The Sixth Text REtrieval Conference (TREC-6)</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="169" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,330.96,700.17,212.22,8.97;5,330.96,710.73,197.47,8.97;6,68.04,57.40,202.53,8.65;6,68.04,67.96,203.89,8.65;6,68.04,78.10,215.93,8.97;6,68.04,88.54,117.03,8.97" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,430.56,700.17,112.62,8.97;5,330.96,710.73,181.68,8.97">Improving the estimation of relevance models using large external corpora</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,68.04,57.40,202.53,8.65;6,68.04,67.96,203.89,8.65;6,68.04,78.10,128.61,8.97">Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;06</title>
		<meeting>the 29th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;06<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="154" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,68.04,99.94,198.40,8.97;6,68.04,110.50,199.99,8.97;6,68.04,120.94,52.48,8.97" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,105.24,110.50,147.09,8.97">TREC 2007 genomics track overview</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ruslen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">M</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,68.04,121.24,22.97,8.65">TREC</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,68.04,132.34,221.44,8.97;6,68.04,142.77,216.64,8.97;6,68.04,153.34,214.72,8.97" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,112.44,142.77,172.24,8.97;6,68.04,153.34,89.97,8.97">A day in the life of PubMed: Analysis of a typical day&apos;s query log</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Herskovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">Y</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">V</forename><surname>Bernstam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,164.76,153.64,27.43,8.65">JAMIA</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="212" to="220" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,68.04,164.74,195.72,8.97;6,68.04,175.17,210.79,8.97;6,68.04,185.61,182.43,8.97;6,68.04,196.05,82.11,8.97" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,170.52,164.74,93.24,8.97;6,68.04,175.17,210.79,8.97;6,68.04,185.61,34.80,8.97">Improving accuracy for identifying related PubMed queries by an integrated approach</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Wilbur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,110.16,185.92,136.25,8.65">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="831" to="838" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,68.04,207.57,211.59,8.97;6,68.04,218.01,224.91,8.97;6,68.04,228.45,209.55,8.97;6,68.04,238.89,157.83,8.97" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,68.04,228.45,209.55,8.97;6,68.04,238.89,19.23,8.97">Overview of the CLEF 2009 medical image retrieval track</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Eggel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Radhouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Bakke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,94.08,238.89,36.13,8.97">In CLEF</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="72" to="84" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,68.04,250.41,212.91,8.97;6,68.04,260.85,218.41,8.97;6,68.04,271.29,216.16,8.97;6,68.04,281.73,83.68,8.97" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,165.00,260.85,121.45,8.97;6,68.04,271.29,167.31,8.97">Okapi at TREC-6: Automatic ad hoc, VLC, routing, filtering and QSDR</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Boughanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,255.48,271.60,22.97,8.65">TREC</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="125" to="136" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
