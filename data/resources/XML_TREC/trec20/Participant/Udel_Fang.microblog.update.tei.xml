<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,120.36,59.78,371.04,15.00">Time-sensitive Weighting for Microblog Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,258.84,80.11,33.95,8.59"><forename type="first">Hao</forename><surname>Wu</surname></persName>
							<email>haowu@ece.udel.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<postCode>19716</postCode>
									<settlement>Newark</settlement>
									<region>DE</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,313.44,80.11,39.75,8.59"><forename type="first">Hui</forename><surname>Fang</surname></persName>
							<email>hfang@ece.udel.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<postCode>19716</postCode>
									<settlement>Newark</settlement>
									<region>DE</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,120.36,59.78,371.04,15.00">Time-sensitive Weighting for Microblog Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">81B75570AE84E038185501B2EC1D5C17</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We report our system and experiments for the realtime Adhoc task in the 2011 MicroBlog track. Our goal is to develop effective technique to retrieve relevant tweets that have been posted recently. In particular, we propose a time-sensitive term weighting strategy that can favor tweets in hot-discussed time and a document length related weighting method that can favor long tweets which are more likely to be interesting. Query expansion technique is also used to further improve the retrieval performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction:</head><p>In this year's realtime Adhoc task, Tweets2011 corpus is used. It contains about 16 millions tweets over the period from Jan. 24 th , 2011 to Feb. 8 th , 2011. Every topic contains not only a query but also the time when the query is submitted. Retrieval Systems are required to return tweets that are posted before the query was submitted, and the tweets need to be sorted based on the post time.</p><p>The problem set up and the characteristics of tweets make it necessary to consider the following three components: relevance, interestingness and the recency. Intuitively, relevant tweets should satisfy the following three properties. (1) tweets containing more query terms are more likely to be relevant. (2) tweets containing query terms with higher IDF values are more likely to be relevant. (3) tweets appearing in hot-discussed time period are more likely to be relevant and interesting. The first two properties are similar to traditional TF-IDF method and they lead to our baseline directly. The third property is a unique feature of microblog search and it leads to our time-sensitive weighting approach. Moreover, we also propose a document length-based weighting strategy to favor long tweets that contain more important content. Finally, we explore a query expansion method based on Web search results to better infer user intention.</p><p>The rest of the paper is organized as follows. We first explained the pre-processing procedure in Section 2, and then describe our methods as well as the submitted runs in Section 3. Experiment results are showed in Section 4 and we conclude in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preprocessing and Index Building</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document Downloading</head><p>We used "official twitter-corpus-tools corpus downloader" to download tweets with html output form. We totally crawl 15052875 available tweets (13938553 with response code 200 and 1114322 with response code 302).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preprocessing</head><p>Twitter is widely used all over the world and a large number of twitters are written in or include non-English characters, e.g. Chinese, Japanese, French and Arabic. Filtering out such non-English tweets will help us improve the retrieval performance and increase retrieval speed.</p><p>Most non-English text will apply characters which ASCII code is greater than 127 (128-255), e.g. Chinese, Japanese, Korean and Arabic. Thus simply removing tweets with characters which ASCII code over 127 will help filtering out non-English content. We apply this strategy and successfully remove most of non-English tweets from the database. However this strategy cannot guarantee all non-English content removed and it may mistakenly delete a few English tweets with special expression characters.</p><p>Another choice may be applying some comprehensive English dictionary to remove tweets with term not in the term list. However, regarding that micro blog is casual and informal, it will be a difficult task to category widely appeared misspelled terms from non-English characters. And more important, applying dictionary will against the constraint "not to use external resource".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Index Building</head><p>We built the index with the Lemur toolkit from UMass. Porter stammer is applied and none stop words are removed. Tweets are treated as documents and they are sorted by their post time from old to new.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview</head><p>Microblog search is a special kind of text search. It has some similarity with traditional text search, but it also has some features that are different from normal text search. For example: a tweet often contains at most 140 characters and it mostly only contains one aspect. As a consequence, traditional text-search method may not be the best choice for microblog search. Specifically, term frequency and document length normalization are important term weighting strategies in traditional retrieval models. However, they may not be very useful for microblog search because tweets are usually very short and contain only one aspect. On the other hand, IDF should still contribute to filter out non-sense terms. Based on this analysis, we simply design the following retrieval function:</p><formula xml:id="formula_0" coords="2,283.95,631.36,52.34,11.77">= ( )</formula><p>where W(t) is the time-sensitive term weighting of term t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Time-sensitive term weighting</head><p>Query term weight is also important in tweets search since tweets are also constituted with common non-sense terms and rare but important terms. Traditional methods calculate term weights by their occur frequency in documents which is widely known as inverse document frequency (IDF). However in our opinion, microBlog search is a dynamic rather than a static process. Thus term weight is determined by not only the background language model (IDF), but also tweet post time. In our assumption, terms occur in their popular discussed time should receive higher term weight than those in rare-discussed period. Take query "Kubica crash" as an example: term "Kubica", "crash" around Feb.6 when they are hot-discussed should receive higher term weight than "Kubica", "crash" which appear in other time.</p><p>To implement such idea, for each query term in each tweet, beside calculate its IDF in the whole collection, we also calculate its IDFs in three window sizes: 6 hours, 1 day and 3.5 days. For example, to get the term weight of a tweet posted at 12:00pm on Feb. 6. We will calculate IDFs based on tweets posted "9:00am -3:00pm Feb. 6", "12:00am Feb.6 -12:00am Feb.7" and "6:00pm Feb.4 -6:00am Feb. 8".</p><p>Then we design the following term weight function:</p><p>( , ) = log ( ( ) + 1 ( , ) )</p><p>In which docN(w) is total number of documents in time window w while DF is number of documents contain term t in time window w.</p><formula xml:id="formula_1" coords="3,162.36,431.31,297.99,27.62">( ) = ( ) 1 4 (6 , ) 1 16 (1 , ) 1 64 (3.5 , )</formula><p>To simplify the computational process, we choose window size by documents number rather than accurate time with negligible difference. (1/4 docN as 3.5 days, 1/16 docN as 1 day, 1/64 docN as 6 hours given the whole collection across two weeks)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document length</head><p>Since micro blog may contain much spam or senseless information, filtering out these spam tweets may help us improve both the interestingness and relevant of our results. In our assumption, such spam tweets are more likely to be short and contain many low IDF terms. Hence we design the following document length favor strategy to favor long tweets with high IDF terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>= + ( )</head><p>In experiments, we set = 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pseudo Feedback and query expansion with external search results</head><p>Query term match alone is not enough and in order to further improve system performance, latent information should be applied to expanse original queries.We designed two methods to dig out such latent information from two different sources: internal and external.</p><p>For internal source, pseudo feedback is applied: we chose all the terms of top 10 tweets as candidate and sum their TF-IDF scores in the top 10 tweets. Then 30 candidate terms with highest scores are chosen to expanse the original query with normalized weight calculated by their scores.</p><p>For external source, top search results from Yahoo are used and the expansion process is similar to the pseudo feedback we mentioned before.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment and Results</head><p>Based on the methods we mentioned before, we submit the following 4 runs: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Conclusion:</head><p>Comparing UDMicroIDF with Static-IDF, we notice a significant improvement on both MAP and r-precise scores. It shows that our time-sensitive strategy can help us improve the system performance for most queries especially some time-sensitive queries. For example, for query MB011 "Kubica crash" which is very time sensitive, the MAP score of our time-sensitive system is 0.77 comparing to 0.28 of static-IDF. It will be very interesting to do more research about the time-sensitive approach and other application of it.</p><p>Document-length-favor seems not to be a good strategy in this year's micro blog track and it hurts the performance a lot. Our unofficial runs "Comb1-no-length" and "Comb2-no-length" show some significant improvement to runs "UDMicroComb1" and "UDMicroComb2" which apply documentlength-favor. The strategy seems too aggressive, but it should be interesting to discuss its usage in other collections.</p><p>Pseudo Feedback and external source query expansion help us dig out some latent information from original query. For example, both "UDMicroComb1" and "UDMicroComb2" show a good improvement (0.31, 0.26vs0.14) for query MB002 "2022 FIFA soccer", because they dig out the important latent information "Qatar". However the query expansion of both methods are not always safe, they may hurt the performance for some queries. We would do more research to improve their stability.</p></div>		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
