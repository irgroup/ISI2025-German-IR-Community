<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,178.46,75.74,255.11,13.50;1,183.56,92.96,244.95,13.50">NUSIS at TREC 2011 Microblog Track: Refining Query Results with Hashtags</title>
				<funder ref="#_FPZsPNS">
					<orgName type="full">Singapore National Research Foundation &amp; Interactive Digital Media R&amp;D Program Office, MDA</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,109.46,123.18,50.30,9.88"><forename type="first">Hadi</forename><surname>Amiri</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<postCode>117543</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,174.11,123.18,44.27,9.88"><forename type="first">Yang</forename><surname>Bao</surname></persName>
							<email>baoyang@comp.nus.edu.sg</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Information Systems</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<postCode>117543</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,232.69,123.18,40.65,9.88"><forename type="first">Anqi</forename><surname>Cui</surname></persName>
							<email>cuianqi@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Information Systems</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<postCode>117543</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">State Key Lab of Intelligent Technology &amp; Systems</orgName>
								<orgName type="department" key="dep2">Tsinghua National Lab for Information Science &amp; Technology</orgName>
								<orgName type="department" key="dep3">Dept. of Computer Science &amp; Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,292.87,123.18,64.45,9.88"><forename type="first">Anindya</forename><surname>Datta</surname></persName>
							<email>datta@comp.nus.edu.sg</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Information Systems</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<postCode>117543</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,432.61,123.18,57.04,9.88"><forename type="first">Xiaoying</forename><surname>Xu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Information Systems</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<postCode>117543</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,178.46,75.74,255.11,13.50;1,183.56,92.96,244.95,13.50">NUSIS at TREC 2011 Microblog Track: Refining Query Results with Hashtags</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C14F39DA9F95CA7AF3FBDFF8B86FB0DF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe our submission to the TREC 2011 Microblog track. We first use URLs as a clue to discover and remove the spam tweets. Then we use both Lucene and Indri to generate a ranked list of results for each query, together with their relevance scores. After that, we use the scores to find out useful hashtags relevant to the query, therefore some previously lower-ranked tweets can be discovered and are re-ranked higher. Query reformulation is considered in two of the four runs in our submissions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The NUSIS team participated in the Realtime Adhoc task component of the TREC 2011 Microblog track. The team comprises members from the National University of Singapore and Tsinghua University. We analyzed the task and evaluation methods carefully, and submitted results based on our best understanding.</p><p>The task required at least one run with no external and future evidence involved. To achieve this, we first filtered out the "past" tweets according to the timestamp of each of the 50 query topics. Then we ran our algorithm 50 times, generating results for these topics. We provide a broad overview of our approach.</p><p>We start off by removing spam tweets. Tweets are usually in short texts; hence most spam tweets contain URLs of their own websites, so that users will visit the "den" from this link. Therefore, presence of URLs in a tweet provides strong evidence of it being spam. We find that many popular URLs are spam URLs <ref type="bibr" coords="1,226.32,566.20,11.71,9.88" target="#b0">[1]</ref>, and conduct a simple method to remove these tweets.</p><p>We constructed indices with Lucene <ref type="bibr" coords="1,263.49,592.78,12.89,9.88" target="#b1">[2]</ref> and Indri (for query reformulation) <ref type="bibr" coords="1,449.63,592.78,11.91,9.88" target="#b2">[3]</ref>, obtaining a relevance score of each tweet in the process. Instead of directly submitting the first 30 results, we adopt an algorithm that generates modified scores for these tweets, which, in turn, re-ranks the current list. Since some tweets may be ranked higher after this modification, the submitted results can be different. In the end, the tweets are sorted by these refined scores (for the adhoc evaluation) or by a combination of both their time and their modified scores (for the balanced evaluation).</p><p>The basic idea is to discover relevant hashtags for a query topic. We believe that, when generating results with traditional text information, the hashtags mentioned in these tweets are also of interest. Therefore, other tweets containing these hashtags but less relevant texts are also relevant to this topic. In this way, more tweets of interest are discovered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset and Preprocessing</head><p>The tweet dataset is downloaded using the twitter-corpus-download-tool <ref type="bibr" coords="2,448.27,156.68,11.64,9.88" target="#b3">[4]</ref>. A total of 13,660,436 tweets are downloaded with status code 200. Tweets with status code 302 (1,093,549 tweets), as well as tweets with code 200 but start with "RT", are retweets, which are defined as non-relevant, thus are removed. Some other tweets (1,378,120 tweets) are removed (with code 404) or are protected (with code 403), preventing us from accessing them.</p><p>According to the task description, all non-English tweets are considered as non-relevant. Similar as the preprocessing step in a previous work <ref type="bibr" coords="2,290.45,246.62,11.59,9.88" target="#b4">[5]</ref>, we remove these tweets based on the characters in the text, i.e. tweets containing characters other than Basic Latin and symbols are removed. Many tweets are too short which result in little information. Tweets with less than five words are discarded.</p><p>As mentioned before, tweets with spam URLs are removed. The spam URLs are determined from the following two aspects:</p><p>(1) For each URL u which appears more than five times in the corpus, it is considered as a spam URL if n u / N u ≤ 0.4, where n u is the number of unique users who have posted tweets containing u, and N u is the total number of times u has appeared.</p><p>(2) We also examine the dataset and find some popular domains with high occurrences. Therefore, we manually identified a set of spam domain including: "tinychat", "twittascope", "twitcam", and "twitcast". All URLs in these spam domain are considered as spam URLs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Indexing and Query Reformulations</head><p>The indices and relevance scores are generated by Lucene <ref type="bibr" coords="2,351.41,498.52,12.82,9.88" target="#b1">[2]</ref> and Indri <ref type="bibr" coords="2,410.98,498.52,13.14,9.88" target="#b2">[3]</ref> retrieval systems. We use the default implementation of the popular vector-space model in Lucene. Indri provides a robust query language that both accept keyword queries and complex queries. This language model provides many features like complex phrase matching, weighted expressions, and Boolean filtering, etc. We utilize these features to formulate the queries for the task. In particular for each query we first extract its N-Grams (N = 2, 3). We then construct some weighted expressions using the query and its N-grams. The reason that we use weighted expressions is because of the fact that it allows controlling the impact of each expression (e.g. by varying weights).</p><p>Let the query q = t 1 , t 2 , …, t n , where t i indicates the i-th term of the query. Using the Indri's query language we construct the following sub-queries:</p><p>(1) The whole query with weight 2.0 (2) Its 3-Grams with weight 1.5 (3) Its 2-Grams with weight 1.0, and (4) All the query terms with weight 0.5.</p><p>The following query is then obtained:</p><formula xml:id="formula_0" coords="3,89.88,101.17,317.32,60.65">Weight ( 2.0 #M (t 1 t 2 … t n ) 1.5 #N (t 1 t 2 t 3 ) 1.5 #N (t 2 t 3 t 4 ) … 1.5 #N (t n-2 t n-1 t n ) 1.0 #N (t 1 t 2 ) 1.0 #N(t 2 t 3 ) … 1.0 #N (t n-1 t n ) 0.5 t 1 0.5 t 2 … 0.5 t n ),</formula><p>where #X indicates that the terms should be in order with the max distance of X-1. We set M and N to 30 and 5 respectively in our experiments. We then perform the retrieval using the above reformulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Refining with Hashtags</head><p>The hashtag (word starts with a hash symbol #) is a specific feature in tweets. They usually denote the category or topic of the tweets, to provide a useful annotation. Hashtags are provided by the original author of the tweet; we believe them much relevant to the content, thus can be used to improve the query results.</p><p>Formally, let the results without refining be {r n }, where each r i consists of the tweet t i and its relevance score s i . Let {h i, m } be the hashtags in t i .</p><p>Since the first 30 results are more important in the evaluation, we scan the first 30 tweets to assign scores to the hashtags. For each of these tweets, denote s i as the score of the hastag h i, m . Therefore, hashtags that appear earlier in the result list (in the tweet ranked higher) have higher scores. Note a same hashtag may occur more than once in the tweets (or even in the tweet t i itself); the hashtag will be assigned scores multiple times.</p><p>Then, for each unique hashtag h k , we add up all the scores it has been assigned. Hence, hashtags that occur more times will have a higher final score, namely S(h k ).</p><p>The final score of a tweet is combined with both the original relevance score s i and the scores from the hashtags it contains, Σ k S(h i, k ), controlled by two weight factors w 1 and w 2 :</p><formula xml:id="formula_1" coords="3,168.80,520.31,274.58,10.63">finalscore(t i ) = w 1 • s i + (1 -w 1 ) • Σ k S(h i, k ) + w 2 • s i • Σ k S(h i, k )</formula><p>In practice, we set w 1 = 0.85 and w 2 = 0.07.</p><p>Finally, all the retrieved tweets (mostly more than 30) are re-ranked by the final score. Then the first 30 results are submitted for the first evaluation.</p><p>For the balanced evaluation, we consider both the time a tweet is created and its refined final score. We sort the result list by the time and score separately, thus for each tweet we have two ranks. Then we add the two ranks together to get a new index for the tweet, and sort the list again by this index. Finally, the first 30 results from this newly sorted list are submitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>According to the judgments, the evaluation includes scores from all 49 topics (topic 50 is dropped) and from 33 topics which have highly relevant tweets. The primary measure is P@30.</p><p>We submit four runs, two with Lucene indexing and two with Indri (query reformulation). For each indexing type, we submit a relevance result and a balanced result.</p><p>Our performances are shown in Fig. <ref type="figure" coords="4,255.72,140.60,4.59,9.88" target="#fig_0">1</ref> -Fig. <ref type="figure" coords="4,295.14,140.60,4.12,9.88">3</ref>. The solid lines ("balance" and "relevance") are generated from Lucene, while the dashed lines ("refBal" and "refRel") are from Indri with query reformulation. We compare the results (of these four runs) with the median performance of the participants, together with the baseline provided by TREC. Note that the baseline is based on Lucene without any further post-processing. Compared with the "relevance" line (Lucene + post-processing), we find that our post-processing methods improve the performance most of the time. However, in the cases baseline is better, it may due to the noises in the hashtags.</p><p>Another finding is that ranking with relevance is better than the balanced one. Although the task itself announced that the evaluation is from two aspects, we find the provided judgment (the official evaluation) considers the tweet IDs (represents the time a tweet is posted) retrieved in descending order as the rank order of the run. Under this consideration, our strategy may be designed differently to achieve a better performance.</p><p>For the comparison between with and without query reformulation, there is no significant difference in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we describe our efforts in the participation of the TREC 2011 Microblog track. We design some specific methods both in preprocessing and post-processing, to fully utilize the feature of tweets, i.e. spam URLs and hashtags. Although the query model is simple, we find that these methods are helpful to discover relevant tweets.</p><p>For the future work, we expect to examine the provided judgment in detail to find out the features that bring a tweet to be relevant. Although tweet texts are short, there will be some specific characteristics that are helpful for tweets retrieval.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,190.58,487.42,230.78,9.88;4,89.85,202.54,432.30,282.15"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 Mean average precision on each query topic</figDesc><graphic coords="4,89.85,202.54,432.30,282.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="5,89.85,72.00,432.30,282.15"><head></head><label></label><figDesc></figDesc><graphic coords="5,89.85,72.00,432.30,282.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="5,89.85,380.80,432.30,282.15"><head></head><label></label><figDesc></figDesc><graphic coords="5,89.85,380.80,432.30,282.15" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0" coords="1,89.88,709.78,3.00,5.40;1,92.88,711.75,288.22,8.10"><p>* This work has been done by the support of Tsinghua-NUS NExT Search Center.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>The <rs type="projectName">NExT Search Centre</rs> is supported by the <rs type="funder">Singapore National Research Foundation &amp; Interactive Digital Media R&amp;D Program Office, MDA</rs> under research grant (WBS: <rs type="grantNumber">R-252-300-001-490</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_FPZsPNS">
					<idno type="grant-number">R-252-300-001-490</idno>
					<orgName type="project" subtype="full">NExT Search Centre</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,105.79,500.69,416.03,9.98;6,89.88,513.35,432.06,9.99;6,89.88,526.18,212.42,9.88" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,329.59,500.69,192.23,9.98;6,89.88,513.35,45.22,9.98">Are the URLs Really Popular in Microblog Messages?</title>
		<author>
			<persName coords=""><forename type="first">Anqi</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,149.18,513.46,372.76,9.88;6,89.88,526.18,137.39,9.88">Proceedings of the 2011 IEEE International Conference on Cloud Computing and Intelligence Systems (CCIS2011</title>
		<meeting>the 2011 IEEE International Conference on Cloud Computing and Intelligence Systems (CCIS2011<address><addrLine>Beijing</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,104.80,552.82,336.66,9.88" xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Apache</forename><surname>Lucene</surname></persName>
		</author>
		<ptr target="http://lucene.apache.org/java/docs/" />
		<imprint>
			<date type="published" when="2011-08-01">1 Aug, 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,106.88,579.29,415.29,9.99;6,89.88,591.95,432.16,9.99;6,89.88,604.78,261.24,9.88" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,266.63,579.29,255.54,9.99;6,89.88,591.95,107.93,9.98">Combining the Language Model and Inference Network Approaches to Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,210.44,592.06,311.60,9.88;6,89.88,604.78,157.58,9.88">Information Processing and Management: Special Issue on Bayesian Networks and Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="735" to="750" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,106.95,631.36,415.11,9.88;6,89.88,644.08,46.02,9.88" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="https://github.com/lintool/twitter-corpus-tools" />
		<title level="m" coord="6,163.52,631.36,85.11,9.88">twitter-corpus-tools</title>
		<imprint>
			<date type="published" when="2011-08-01">1 Aug 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.82,670.55,416.20,9.99;6,89.88,683.21,432.07,9.99;6,89.88,696.00,208.27,9.88" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,330.07,670.55,191.95,9.99;6,89.88,683.21,183.55,9.98">Emotion Tokens: Bridging the Gap Among Multilingual Twitter Sentiment Analysis</title>
		<author>
			<persName coords=""><forename type="first">Anqi</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,287.98,683.32,233.97,9.88;6,89.88,696.00,92.06,9.88">Proceedings of the 7th Asia Information Retrieval Societies Conference</title>
		<meeting>the 7th Asia Information Retrieval Societies Conference<address><addrLine>Dubai</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
