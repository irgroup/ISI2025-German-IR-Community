<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,168.92,82.36,257.60,14.42">PRIS at TREC2011 Micro-blog Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,120.50,107.06,30.88,10.80"><forename type="first">Yan</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,158.96,107.06,73.05,10.80"><forename type="first">Zhenhua</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,240.44,107.06,56.37,10.80"><forename type="first">Wenlong</forename><surname>Lv</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,305.02,107.06,62.89,10.80"><forename type="first">Qianlong</forename><surname>Xie</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,375.58,107.06,54.35,10.80"><forename type="first">Yuhang</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,437.85,107.06,37.00,10.80"><forename type="first">Rao</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,215.36,122.66,49.13,10.80"><forename type="first">Weiran</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,273.38,122.66,57.61,10.80"><forename type="first">Guang</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,339.66,122.66,40.33,10.80"><forename type="first">Jun</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,168.92,82.36,257.60,14.42">PRIS at TREC2011 Micro-blog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2CC040799C173C79DC5308229780A9B1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our system to Micro-blog Track at TREC2011 is described in this paper, which includes data obtaining and preprocessing, index building and query expansion. There"re two methods of query expansion introduced in this report: Word Activation Force algorithm (WAF) and Electric Resistance Network. We also show the evaluation results for our team and the comparison with the best and median evaluations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1．Introduction</head><p>The Micro-blog Track examines search tasks and evaluation methodologies for information seeking behaviors in micro-blogging environments. This year is the first year of the Micro-blog Track, which aims at addressing a search task whereby a user's information need is represented by a query at a specific time. In particular, it is a real-time search task, where the user wishes to see the most recent but relevant information to the query. Hence, the system should answer a query by providing a list of relevant tweets ordered chronologically. It is expected that when selecting tweets to include in the list, the "interesting" but "newer" relevant tweets should be paid more attention to. Interestingness is subjective, but the issuer of a query might interpret it as providing somehow added value with respect to the query topic. For this year, the "novelty" between tweets is not considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Dataset and Preprocessing</head><p>In Micro-blog Track at TREC 2011, theTweets2011 corpus is provided officially, and we also downloaded the web pages linked from the tweets as extra corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Tweet2011 Corpus</head><p>The Tweet2011 corpus is obtainable with the official downloader, provided that the network environment guarantees a stable access to Twitter.com. When a tweet is finished, a status code is generated as a result. There"re five types of codes in the corpus, 200, 302, 403, 404 and null, which means ok, found, forbidden, not found and nothing respectively. In practice, the number and status of the tweets differs according to the network environment, downloading time and other possible reasons. In our case, the statistics of the corpus fetched via the corpus downloader are shown as follow: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Web Pages Linked from the Tweets</head><p>Due to the limited length of the tweet text, it fails to provide adequate information. We downloaded the URL links extracted from tweets to obtain extended content. The total number of tweets with one or more URLs was 2,768,878, in which 65109 were non-English. Even though there were considerable numbers of tweets that share the same URLs, especially in the case of "re-tweet", we reserved the duplicate links considering that it might indicate the popularity or other properties of relate tweets. Eventually, 1,659,097 web documents were successfully crawled from the internet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Tweets Pre-Processing</head><p>Two pre-processing tasks were performed in our system: RT tweets removal and non-English tweets removal.</p><p>We first extracted user remarks and remove the label "RT". The "new style" re-tweets to which the HTTP crawler returned 302 were all removed.</p><p>When URLs and punctuation were removed, each tweet was judged to be English or non-English with the help of an English vocabulary word list, Alan Beale's Core Vocabulary. A tweet with more than a half English words would be left and used for retrieval task while tweets with any non-English content were rejected in the query expansion task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Retrieval Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">System Introduction</head><p>To build a real-time system for this year"s Micro-blog Track search task, the system we implemented was designed based on the structure of an information retrieval system as the Fig. <ref type="figure" coords="3,500.96,154.37,4.36,9.45" target="#fig_0">1</ref> shows.</p><p>As shown in Fig. <ref type="figure" coords="3,177.43,185.57,4.09,9.45" target="#fig_0">1</ref>, the corpus of tweets was downloaded by official crawler while another dataset of web pages, whose links are provided in tweets, are fetched by a self-designed crawler. Then we extracted the relevant tweets according to the relevance score between tweets and the queries calculated based on the title of the topics. In the third part of our system, query expansion were applied for every topic. Finally, we re-evaluated the relevance between the tweets retrieved in the second step and the expanded topics, filtering out the tweets under the relevance threshold, and then re-sorted the tweets in chronological order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Baseline: Relevant Documents Retrieval</head><p>As the tweets corpus contains almost all the tweets posted from Jan 24 to Feb 8, most of the tweets are not relevant to the topics.</p><p>Firstly, we filtered out the re-tweets from the original tweet corpus, creating a new corpus NO302-Dataset, and building indexes for both the NO302-Dataset and the original corpus With302-Dataset.</p><p>Secondly, we manually extracted query words of each topic by filtering out stop words and expanded them using their synonyms. For example, the word US was expanded by USA and America.</p><p>Finally, the Xapian and Indri Toolsets were applied as our indexing toolsets. Tweets in No302-Dataset containing any of the keywords of a topic and posted before the query timestamp were treated relevant to the topic and would be retrieved for re-ranking later. While tweets in With302-Dataset containing all of the keywords of a topic were treated highly relevant to it and would be retrieved for expansion later.</p><p>In practice, we found that tweets ranked after 1000 in the ranking list were irrelevant to the topics though containing some keywords, so we made 1000 as the threshold of the number of results.</p><p>As to the webpage dataset, the process was similar and the difference was that only Indri Toolset was used and the threshold was set to 500.</p><p>We regarded the retrieval results as our baselines of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Query Expansion</head><p>In this stage, we are expected to mine the words that have strong connection with a given topic so as to improve document retrieval performance with more adequate information. Two algorithms were applied in this stage: the Word Activation Force algorithm and Term Similarity Metric method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Word Activation Force Algorithm</head><p>The Word Activation Force algorithm (WAF) is based on the assumption that there"s a special force in documents helping human brains activate associates of a word, such as "hospital" activates strongly "doctor" or "nurse". It believes that there are latent structures of word network in documents. The WAF proposes an effective approach mapping syntactical and semantic information into sparse directed networks, comprehensively highlighting the features of individual word. Based on the directed networks, sensible word clusters and hierarchies can be efficiently discovered.</p><p>For the Micro-blog TREC, WAF was applied to unearth extra keywords of a given topic to improve outcomes. To begin with, the top 500 most relevant web documents in the baseline were selected for each topic. Note that, the set of ranked documents for each topic is independent and we name it basic set.</p><p>The documents were stemmed and turned into lower-case letters in the first place. Then words occurrence and co-occurrence were calculated in the basic set. We use the follow annotations:</p><p>• f i ,the frequency of word i in the basic set;</p><p>• f ij ,the co-occurrence of word i to word j in the basic set, which indicates the frequencies of pairs (i,j) where i precedes j by up to L words(L =4 in our study); • d ij , the average word distance between word i and word j.</p><p>Then the word activation force of word i to word j, or waf ij , can be calculated as follows:</p><formula xml:id="formula_0" coords="4,263.68,343.03,244.60,20.79">waf ij = f ij f ji f i f j (1)</formula><p>It is obvious that all the element values in the WAF matrix is between 0 and 1. Zero means that word i is never followed by word j within our word window in the basic set, while one means that word i and j are always adjacent like a compound( f ij =f j =f i , d ij =1)</p><p>With the WAF Matrix above, we can calculate the closeness of word i and j, namely affinity, as follows:</p><formula xml:id="formula_1" coords="4,144.38,452.13,176.03,20.19">A ij waf = [ 1 |K ij | OR(waf ki , waf kj ) • 1 |L ij |</formula><p>OR(waf il , waf jl )</p><formula xml:id="formula_2" coords="4,205.40,454.47,226.55,14.73">l∈L ij k∈K ij ] 1/2</formula><p>(2)</p><p>where K ij = {k|waf ki &gt;0 or waf kj &gt;0} and Lij = {l|waf il &gt;0 or waf jl &gt;0}. And OR(x,y) = min(x,y)/max(x,y). The Affinity Matrix enables us to discover the association between words in the basic set. We define Q, W, S as the set of all words in basic set, the set of keywords, and the set of stop words respectively, where stop words were not taken into account in the first two sets. For each word i in Q, and word j in W but not in S, we selected valuable expansion keywords by the Aijwaf measure, assuming that high relevant words would have larger affinity value.</p><p>Apart from the affinity measure, we implied "topic frequency" to eliminate bad expansion words based on the assumption that words with high topic frequency is usually less discriminating. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2. Illustration of association network</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Term Similarity Metric Based on Electric Resistance Network</head><p>Besides WAF, the term similarity metric derived from the electric resistance network was also applied to query expansion. The distances between vertices were calculated through an undirected weighted graph. And we used the tweets retrieved from Indri as the corpus.</p><p>Step 1: Building an association network from related tweets We built an undirected weighed graph G = (V;E;w) where nodes V represent terms in tweets, edges E represent the associated pair, and weight w on the edges measures the strength of association between two connected nodes.</p><p>If two terms co-occur in one tweet, a direct link is built between them. If these two terms co-occur in n (n&gt;0) different tweets, the weight w is n, as is shown in Fig. <ref type="figure" coords="5,401.72,372.77,4.09,9.45">2</ref>.</p><p>The association between any two terms is calculated considering all association paths and cumulative weights connecting them.</p><p>Step 2: Calculating the effective resistances The electric resistance network can be used to calculate the effective resistances between any two nodes in the association network built in step 2. The weight w jk between node j and node k was calculated according to the electric conductance c jk defined in the original weighted graph: r jk = 1/c jk = 1/w jk .</p><p>Fig. <ref type="figure" coords="5,118.06,497.59,4.39,9.45" target="#fig_1">3</ref> illustrates the resistance network obtained from the weighted association network. For all possible pairs, we calculated the resistances with the help of Laplacian Graph L and L = A-D, where A is the adjacency matrix and D is the degree matrix of the graph. Then the effective resistance between node v j and node v k can be calculated as follows:</p><p>r jk = L + jj + L + kk -L + jk -L + kj (3) where L + represents the pseudo-inverse of L.</p><p>Step 3: Query expansion with the distance metric We extend the Effective Resistances calculation to the term space to define the distance in between a target term t and a set of terms S.</p><p>The definition of the distance between a target term t and a term set S is as follows:</p><formula xml:id="formula_3" coords="5,249.76,655.59,258.52,18.96">r S,t = 1 |S| r s i ,t s i ∈S<label>(4)</label></formula><p>where r ij is the effective resistance of node i and node j.</p><p>As for the query, we define Q and X as query term set and corpus term set respectively. And for a target term x, its normalized distance to Q can be calculated as follows:</p><formula xml:id="formula_4" coords="5,240.02,730.85,268.26,23.55">r Q,x norm = r Q ,x 1 |X -Q | r x ,y y ∈X -Q (5)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4. An example of query expansion</head><p>With the above metric, all relevant terms to the original queries can be found. And we selected the top 20 terms as highly relevant expansion terms for the next scoring step. Fig. <ref type="figure" coords="6,456.33,247.97,4.37,9.45">4</ref> shows an example of our query expansion result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5．Scoring and Ranking</head><p>The relevance of a tweet to a certain topic is evaluated separately. For each topic, the score of a tweet t can be calculated as follows:</p><formula xml:id="formula_5" coords="6,177.92,342.91,330.36,20.73">score t = a • N q L q + b • N e L eq + c • N s L + d • L L max + HasURL N s (6)</formula><p>where N q is the number of words which are contained both in the topic and t, L q is the number of key words in topic. Similarly, N e is the number of extension words that contained in t, L eq is the number of words in the expanded terms. L and N s represent the number of words in t with and without stop words respectively. Lmax is the maximum number of words of tweets for the current topic, and HasURL is a boolean variable indicating whether t contains URLs (used only in our run1 and run3). In addition, a, b, c and d are parameters, which were set to 3, 1, 0.3 and 0.5 respectively.</p><p>Obviously, a tweet containing more keywords in the topic is more likely a relevant tweet and should be given a higher score. The score of Ns/L and L/Lmax shows how informative a tweet is, while HasURL/Ns represents the potential information.</p><p>Then we ranked tweets for each topic according to the score in the descending order. Finally, we chose top n tweets in the ranking list as the relevant tweets. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,214.52,748.83,166.37,9.45"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The structure of our system</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,201.92,201.29,191.57,9.45;5,186.65,77.12,230.75,114.54"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Illustration of resistance network</figDesc><graphic coords="5,186.65,77.12,230.75,114.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,99.56,404.09,396.22,9.45;8,91.50,244.13,443.17,155.14"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Comparison with the best and median on MAP and R-Prec for PRISrun2.allrel</figDesc><graphic coords="8,91.50,244.13,443.17,155.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,116.82,75.52,384.50,133.47"><head></head><label></label><figDesc></figDesc><graphic coords="6,116.82,75.52,384.50,133.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,97.34,92.07,400.62,41.48"><head>Table 1 . The statistics of our team's corpus 200</head><label>1</label><figDesc></figDesc><table coords="2,97.34,107.39,400.62,26.16"><row><cell></cell><cell>302</cell><cell>403</cell><cell>404</cell><cell>Null</cell><cell>total</cell></row><row><cell>13,979,849</cell><cell>1,114,483</cell><cell>239,935</cell><cell>700,435</cell><cell>1,006,050</cell><cell>16,034,705</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6．Evaluation Results</head><p>In this year"s TREC Micro-blog Track, we submitted 4 versions of runs. And each run is different from another in three aspects as shown in Tab.2. For each run, the using of future and external evidence affected the range of mining corpus and the expanded words. All retrieved tweets were evaluated by relevance scores and a threshold was set to select highly relevant tweets. We can fix the threshold value manually or automatically. The manual way means that we set the cut-off value by observation, while for the automatic way, the value are worked out by some parameters that were configured automatically according to the features of expanded words. In addition, the runs using external evidences combined scored relevant tweets with tweets that offer highly relevant web pages even if the tweet itself may be irrelevant to the query. All the returned tweets for each run were sorted chronologically.</p><p>Tab.3 shows the evaluation results of the four runs. The topic 50 was dropped from the evaluation for it did not have any relevant tweets. The "allrel" is the evaluation for the remaining 49 topics, while the "highrel" is for the 33 topics having highly relevant tweets. We also list the baseline result provided by TREC, and it is obvious that all our four runs outweigh over the baseline significantly. It can also be concluded that the PRISrun2 is our best run.</p><p>We also compare our results of PRISrun2 with the best and median results of the track in Fig. <ref type="figure" coords="7,501.03,472.87,4.36,9.45">5</ref> and Fig. <ref type="figure" coords="7,124.44,488.47,4.08,9.45">6</ref>. In both "allrel" set and "highrel" set, it is obvious that our results outperform the median almost on every topic and even reach the best on some topics.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="7,111.02,597.67,370.89,9.45;7,111.02,613.27,294.22,9.45" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,233.64,597.67,248.27,9.45;7,111.02,613.27,79.72,9.45">An Activation Force-based Affinity Measure for Analyzing Complex Networks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1038/srep00113</idno>
	</analytic>
	<monogr>
		<title level="j" coord="7,198.19,613.27,44.73,9.45">Sci. Rep. 1</title>
		<imprint>
			<biblScope unit="page">113</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.02,628.87,367.54,9.45;7,111.02,644.47,387.42,9.45;7,111.02,660.07,119.00,9.45" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,280.30,628.87,198.26,9.45;7,111.02,644.47,163.02,9.45">Effective Query Expansion with the Resistance Distance Based Term Similarity Metric</title>
		<author>
			<persName coords=""><forename type="first">Shuguang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Milos</forename><surname>Hauskrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,292.38,644.47,201.64,9.45">proceedings of the 33th ACM SIGIR conference</title>
		<meeting>the 33th ACM SIGIR conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="715" to="716" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
