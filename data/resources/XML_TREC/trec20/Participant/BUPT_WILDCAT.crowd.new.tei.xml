<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,122.11,95.07,350.97,14.26;1,157.06,137.93,281.06,14.26">BUPT_WILDCAT at TREC Crowdsourcing Track: Crowdsourcing for Relevance Evaluation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,202.08,181.58,31.28,9.40"><forename type="first">Tao</forename><surname>Xia</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligent System Lab</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<country key="CN">P.R.China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,240.56,181.58,62.02,9.40"><forename type="first">Chuang</forename><surname>Zhang</surname></persName>
							<email>zhangchuang@bupt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligent System Lab</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<country key="CN">P.R.China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,311.22,181.58,23.82,9.40"><forename type="first">Tai</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligent System Lab</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<country key="CN">P.R.China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,341.79,181.58,51.39,9.40"><forename type="first">Jingjing</forename><surname>Xie</surname></persName>
							<email>xiejingjing113@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligent System Lab</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<country key="CN">P.R.China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,122.11,95.07,350.97,14.26;1,157.06,137.93,281.06,14.26">BUPT_WILDCAT at TREC Crowdsourcing Track: Crowdsourcing for Relevance Evaluation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C6C2215570EFC8D7EEC8F9873D7E09C3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In recent years, crowdsourcing has become an effective method in many fields, such as relecance evaluation. Based on our experiment carried out in Beijing University of Posts and Telecommunications for the TREC 2011 Crowdsourcing track, in this paper we introduce our strategies in recruiting workers, obtaining their relevance and rank juegements and quality control. Then we explain the improved EM algorithm and Gaussian model that we make use of to calculate the consensus of labels. The result shows that our stategies and algorithms are effective.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.44" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.44" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.44" lry="842.04"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.44" lry="842.04"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.44" lry="842.04"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.44" lry="842.04"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.44" lry="842.04"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.44" lry="842.04"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.44" lry="842.04"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.44" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In information retrieval, the accuracy of search engine in retrieving relevant documents is often evaluated by comparing with human judgements. The judges used to be experts, who have profound understanding in that field. However, with the ever-increasing scale of data sets to be labeled, we need a new approach to reduce the cost, time, effort and bias brought by the traditional methods, and promotes efficiency.</p><p>Recently, researches have revealed the effectiveness of crowdsourcing in dealing with the enormous data by distributing the work to a large group of "workers" or community through the Internet. In 2011 TREC crowdsourcing track, the application of crowdsourcing in search engine evaluation is addressed. The goal of this year includes:</p><p>1. How to obtain hogh-quality relevance judgements from individual crowd workers;</p><p>2. How to effectively compute consensus judgments from individual judgments; 3. Interaction between these (i.e., worker accuracy vs. subsequent consensus accuracy). <ref type="bibr" coords="1,483.84,654.84,12.74,9.40" target="#b0">[1]</ref> Aimed at the issues above, we divide our work into two tasks. In the first part of the paper, we will explain the design and strategies of task 1(assessment). We make use of a qualification test to screen workers, and take some quality control methods to guarantee that only eligible labels are submitted. We also provide workers the opportunity to calibrate their judgements of relevance. As for the second part, we will focus on the task 2 that calculate the consensus over a set of individual worker labels. First we will review the past improvements in EM algorithm, and then introduce the algorithm we adopted, together with the detailed process and program structure. Second, we make use of the Gaussian model to estimate the workers' judgements. At the end of the notebook, we will list the result measured in a series of criteria, and compare them with the average level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Asscessment</head><p>In this task, we aimed at obtaining relevance and rank judgements from workers. To guarantee the quality of labeling, we designed a qualification test on CrowdFlower to screen bad workers. Workers who passed the test are qualified to take the formal test on AMT, in which the test set data are used. All of the labels submitted by workers will be collected for further processing. Figure <ref type="figure" coords="2,169.97,258.67,5.22,9.40">1</ref> shows the overall workflow.  The jobs are published on CrowdFlower, only for AMT workers. In each job, workers have two tasks to finish. Firstly, they need to judge the relevance between the topic and documents, label them as "relevant" or "irrelevant" (binary judge). And then they need to rank the 5 documents in descending order.</p><p>CrowdFlower will automatically gather the labels, compare them with the gold answers and help evaluate the ability of workers. If the worker is marked as "trust" by CrowdFlower, we will treat them as excellent workers and collect their AMT ID. Then we will invite them to take part in the HIT on AMT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Test on AMT</head><p>In test on AMT, we scrambled the order of sets and organized the test set data into 76 HITs. Each HIT contains 6 sets. A gold set appears randomly among the 6 sets for quality control. We have set the qualification threshold to ensure only qualified workers can take the HITs. Workers Qualified workers are redirected to our HIT by clicking the URL provided in our email. In AMT, our HITs are shown using external webpages. This website can capture the worker ID, assignment ID and the HIT Number passed to it, shows corresponding topic-document pairs and record data. By using Flexpaper, documents are visually displayed in the webpage. Zoom and search function also provide conveniences for workers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.2">Accept a HIT</head><p>If the worker is interested in the HIT, he or she can accept the HIT and begin labeling. We have provided the query, description and instructions in the page to help them set up the judgement standard. Like the job in CrowdFlower, task 1 asks worker to judge the relevance. Mark "relevant" if the document is relevant to the query, otherwise mark "irrelevant". And task 2 is to rank the documents based on the relevance level. Among the 5 documents, the one with highest relevance ranks "1". And the others should be ranked in the descending order. Figure <ref type="figure" coords="3,500.28,364.49,5.22,1.00" target="#fig_2">4</ref> shows the user interface of a HIT. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.3">Auto Review</head><p>After the workers finish all the 6 topics, they can review the wrongly labelled documents in the gold set. Document, query and other detailed information will be shown, and the corresponding correct relevance labels are highlighted. In this way, workers can get some training, and have a deeper understanding about the relevance judge standard. We believe that it will be helpful for future labeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.4">Submit or Return</head><p>At the end of auto review page is the submit button. Sometimes it becomes a gery bar, prompting that the worker is not allowed to submit the HIT. That is because the labels provided by the worker do not meet our expection. When the worker finished the 6 topics, we will do some calculation using the labels and the time cost, and compare with our quality control threshold. If the quality meets the requirements, workers are able to submit the HIT to AMT. If it is not, the submit button will be disabled, and tell worker to return the HIT. The criteria considered will be introduced in 1.2.5. Considering some labels with very poor quality are meaningless for us, we choose to refuse them now. This stategy can effectively improve the overall quality of the judgements submitted to AMT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.5">Quality control method</head><p>We have taken some measures to control the quality of labels. When a worker is labeling, we check the compatibility of relevance and rank; when a worker finish all the topics, we calculate the binary score,NDCG score and time spent in each topic, and determine whether the worker are allowed to submit the HIT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Compatibility check -Relevance and rank</head><p>The relevance and rank judgements should be valid and compatible. First, to the 5 documents of each topic, their rank value should vary from 1 to 5, and be different each other. Otherwise, a window will pop up and prompt the error. Second, the documents that are irrelevant with the query should have a lower rank value than the relevant documents. For example, document A is marked as "relevant", while document B is marked as "irrelevant". If the worker assign 3 to A's rank, the rank of B should be larger than 3. If not, when "next" is pressed, a window will also tell worker about the error. Only when the relevance and rank judgements becomes compatible can the worker do the next topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Binary score</head><p>To evaluate the quality of worker's binary judgements (relevance) dynamically, we designed a criterion -binary score. Based on the trinary label (0, 1, 2) provided by NIST, we grade workers' binary judgements, and then normalize the sum. When worker's judgement is correct, he or she will obtain a higher score if the judgement is wrong, a lower score is given. We hold the view that the documents with NIST answer=2 are easier to judge than the ones with NIST answer=1 or NIST answer=0. So to the docuemts NIST answer=2, if the worker mark it with 1, he or she will get fewer score; if the worker mark it with 0, he or she will get 0. Through experiments, we set the parameters as following: The assignment whose binary score lower than 0.85 will be rejected to submit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) NDCG score</head><p>As for rank judgement, we use the NDCG score to control the quality. We refered to the NDCG algorithm in Computing Information Retrieval Performance Measures Efficiently in the Presence of Tied Scores, and altered details to meet TREC's requirements.</p><p>Since the reference answers provided by NIST are trinary, for example, the relevance judgements by NIST of a gold set is 1, 2, 2, 0, 1, then the correct rank should be 2, 1, 1, 3, 2. If the worker's rank lables are 1, 2, 3, 4, 5 , the NDCG score is calculated as following: () label v is the relevance label from NIST, i.e. 1, 2, 2, 0, 1; Through the experiments in the training phase, we assign the threshold of NDCG score 0.62. The assignment whose NDCG score lower than 0.62 will be rejected to submit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) topic time</head><p>We recorded the time worker spent on each topic when the worker is labeling. For a document, we think the judgements made in less than 6 seconds are not trustworthy. As a result, the whole assignment is not allowed to submit to AMT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Consensus</head><p>In this task, a set of labels contributed by individual workers were provided. We need to calculate the consensus labels from them. Both the binary judgement and rank value are required. Some of topic document pairs have NIST gold truth juegements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">EM Algorithm</head><p>Before the emerging of crowdsourcing theory, Expectation-maximization (EM) algorithm has been widely used in consensus computation. EM algorithm is an iterative approach for finding maximum likelihood estimates of parameters in statistical models, where the model depends on unobserved latent variables. In the expectation (E) step, we obtain the binary label by doing the majority decision; while in the maximization (M) step, we compute the propability of workers giving a correct label. Through sufficient iterations, the binary label approaches convergence. That is the output of EM algorithm.</p><p>Considering the workers' biases, an improved version of EM algorithm is to estimate both probabilities of givinging a correct judgement for each possible answer in the M step. This method efficiently rectifies workers' tendency to a specified label and improves the quality of output.</p><p>Another version takes the difficulty level of juegements into consideration. The correct rate of workers' labels is influenced by not only the ablity of worker, but also the difficulty level of current document. So involving the two parameters into EM algorithm is a good idea.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Process of algorithm</head><p>The EM algorithm we used is proposed by Dawid A.P and Skene A.M. EM algorithm works as follows:</p><p>1. Given L binary labels of M topic-document pairs from N workers, for each pair D i , initialize the correct label L i using majority vote and save it.</p><p>2. For each worker W j , calculate P cj -the probability of labeling a pair correctly, P ej -the probability of labeling incorrectly, and save them. Then set the vote weight V j of worker W j .</p><p>3. For each topic-document pair D i , recalculate the correct label L i using the vote weight of workers who have labeled the pair.</p><p>4. Repeat the step 2-3 until all the correct labels are stable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Vote Weight Set</head><p>In our experiment, the worker vote weight is set as follows:</p><formula xml:id="formula_0" coords="6,267.81,690.94,59.18,31.59">         ej cj j P P V log</formula><p>Where P cj is the labeling correctly probability of worker and P ej is the labeling incorrectly probability.</p><p>The vote weight comes from the following model: For each topic-document pair D i , the probability of correctly labeling L i =1 is:</p><formula xml:id="formula_1" coords="7,266.56,111.50,61.48,16.03">      0 1 1 ij ij L ej L cj i P P P</formula><p>And P i0 can be obtained in the same way. Then:</p><p>If the result of the expression above is larger than 0, i.e. P i1 &gt;P i0 , the correct label L i tend to be 1. The equation also expresses the vote result with weight V j . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Program</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">EM Algorithm with Gaussian Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Gaussian Model</head><p>There are M topic-document pairs, annotated with L binary labels by N workers. For each pair D i , it has a relevant degree B i (0&lt;B i &lt;1), and a relevant binary label L i (L i =1 when B i &gt;0.5, or L i =0). Each worker W j has an ability level 1/A j (A j &gt;0, its inverse is proportional to work quality of W j ), and a relevant label threshold T j (0&lt;T j &lt;1, in this experiment, T j =0.5).</p><p>In this model, when W j is in the annotation, he will obtain a relevant value B ij first. B ij is consistent with Gaussian distribution whose expectation is B i and variance is A j . Second, W j will compare B ij and his relevant label threshold T j . If B ij &gt;T j , W j will label L ij =1 to D i . Otherwise W j will label L ij =0. </p><formula xml:id="formula_2" coords="7,229.02,48.13,137.91,2258.24">                                                                                 0 1 0 1 0 1 0 1 0 1 0 1 log log log log log log ij ij ij ij ij ij ij ij ij ij L</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Process of Algorithm</head><p>The process of the EM algorithm is as follows:</p><p>1. Given L binary labels of M topic-document pairs annotated with by N workers, for each Worker W j , initialize his ability value 1/A j and save it.</p><p>2. E Step: For each pair D i with N i labels, calculate the expectation of its relevant value B emi using the above Gaussian model and then save B emi . B emi is:</p><formula xml:id="formula_3" coords="8,110.95,303.89,245.20,7246.52">        1 0 1 1 0 1 i i N j i ij N j i ij i emi dB p dB p B B 3. M</formula><p>Step: For each worker W j , estimate his ability value 1/A j with maximum likelihood estimation and then save A j . 4. Repeat the step 2-3 until all B emi are stable or iterated enough times. 5. For each pair D i , if B emi &gt;0.5, output label 1. Otherwise output label 0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Program</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Result</head><p>The preliminary results are shown below, both task 1 and task 2. And in each task, results of both relevance and rank are given. This is the result of binary judgement in task <ref type="bibr" coords="9,280.25,167.54,51.95,9.40">1, compared</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion and Future Work</head><p>In TREC, we made some adjustment in the strategies and algorithms, and the preliminary result shows that two-third of the criteria are high above the average level, especially in task 2. Our work provides an effective algorithm of consensus computing and a ne w method of assessment for the other researchers to refer. In future study, we will continue focus on improving the strategies and obtain a better result.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,208.92,436.83,177.36,9.07"><head>Figure 2</head><label>2</label><figDesc>Figure 2 the workflow of qualification test</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,238.46,123.24,26.92,9.40;3,268.37,130.37,88.06,1.00"><head></head><label></label><figDesc>Figure 3 Workflow on AMT</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,242.06,739.03,111.58,1.00;3,141.63,385.85,333.16,339.75"><head>Figure 4</head><label>4</label><figDesc>Figure 4 the HIT on AMT</figDesc><graphic coords="3,141.63,385.85,333.16,339.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,90.05,77.71,5.65,7.38;5,110.95,76.41,394.11,9.40;5,110.95,91.92,18.80,9.40;5,90.05,109.06,5.65,7.38;5,110.95,107.76,389.29,9.40;5,90.05,124.54,5.65,7.38;5,110.95,123.24,383.76,9.40;5,110.95,153.50,232.72,9.40;5,384.93,143.99,3.52,6.22;5,388.12,167.49,3.52,6.22;5,405.93,152.69,11.73,10.76;5,382.20,167.49,1.95,6.22;5,351.91,152.69,14.73,10.76;5,394.31,152.69,18.92,10.76;5,384.64,167.42,3.86,6.28;5,371.01,152.57,6.68,10.87;5,380.28,151.18,13.02,16.32;5,419.64,153.50,30.54,9.40;5,469.01,152.72,11.79,10.70;5,457.36,160.85,18.98,1.00;5,483.05,153.50,22.27,9.40;5,90.05,185.44,102.82,9.49;5,193.08,182.96,5.58,6.16;5,203.16,185.54,301.28,9.40;5,90.05,216.17,151.29,9.40;5,282.95,206.64,3.52,6.22;5,286.15,230.11,3.52,6.22;5,304.91,215.34,11.76,10.76;5,280.21,234.84,1.96,1.00;5,248.57,223.51,16.09,1.00;5,293.31,223.51,18.94,1.00;5,282.66,230.05,3.87,6.28;5,269.02,215.22,6.70,10.87;5,278.28,213.83,13.04,16.30;5,319.15,216.17,30.88,9.40;5,369.74,215.37,11.68,10.70;5,358.23,223.50,18.78,1.00;5,388.68,216.07,116.05,9.49;5,90.05,252.91,2.90,9.40;5,92.93,250.33,5.22,6.16;5,100.87,252.91,162.15,9.40;5,336.16,254.50,13.46,1.00;5,270.40,261.28,53.44,1.00;5,335.24,269.66,14.67,1.00;5,326.20,253.84,6.12,9.75;5,353.74,264.79,2.61,9.40;5,110.95,279.19,393.79,9.40"><head></head><label></label><figDesc>When NIST answer=0: if worker judgement=0, score +15; if worker judgement=1, score +10.When NIST answer=1: if worker judgement=0, score +5; if worker judgement=1, score +12.When NIST answer=2: if worker judgement=0, score +0; if worker judgement=1, score +9.The sum of the scores of 5 documents in the gold set is score of the i th topic-document pair. Suppose all binary judgements are correct, the worker can obtain the highest score i is the worker's score of the i th topic-document pair. Hence, we define BV binaryScore GV  . Through the experiments in the training phase, we assign the threshold of binary score 0.85.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,110.95,444.72,5.65,7.38;5,132.19,443.42,248.86,9.40;5,476.93,440.47,8.87,6.24;5,397.49,442.40,4.19,10.79;5,426.24,442.40,36.13,10.79;5,496.26,442.40,6.29,10.79;5,462.20,445.21,20.71,1.00;5,388.26,450.59,47.66,1.00;5,446.74,442.28,59.10,10.90"><head></head><label></label><figDesc>Calculate the Gain function based on the NIST answer:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="5,110.95,504.51,5.65,7.38;5,132.19,503.11,263.88,9.49;5,459.61,496.73,5.68,10.02;5,417.96,503.76,19.97,10.02;5,443.23,512.45,38.43,10.02;5,411.78,514.23,4.74,1.00;5,404.32,511.36,20.48,1.00;5,474.42,520.05,3.16,1.00;5,484.13,503.21,2.61,9.40;5,493.35,510.30,3.09,1.00;5,498.89,503.21,6.96,9.40;5,132.19,529.15,152.59,9.40;5,110.95,550.61,5.65,7.38;5,132.19,549.31,242.34,9.40;5,435.82,544.14,5.48,9.54;5,395.42,550.83,19.44,9.54;5,419.94,559.11,37.22,9.54;5,389.45,560.81,3.87,1.00;5,382.65,558.07,19.33,1.00;5,450.04,566.35,3.05,1.00;5,464.69,549.31,2.61,9.40;5,476.46,556.40,3.16,1.00;5,482.33,549.31,22.97,9.40;5,132.19,575.85,307.84,9.49;5,110.95,597.79,5.65,7.38;5,132.19,596.49,67.03,9.40;5,244.73,590.39,3.16,5.49;5,247.58,611.14,3.16,5.49;5,261.28,598.07,3.64,9.51;5,286.79,598.07,18.36,9.51;5,326.92,598.07,10.48,9.51;5,294.92,608.02,1.75,1.00;5,321.03,608.02,4.56,1.00;5,242.30,615.31,1.75,1.00;5,206.97,605.29,22.73,1.00;5,253.08,605.29,42.20,1.00;5,313.84,605.29,19.59,1.00;5,244.50,611.08,3.47,5.55;5,232.32,597.97,6.00,9.60;5,306.19,597.97,6.00,9.60;5,240.60,596.74,11.69,14.41;5,344.38,596.49,119.94,9.40;5,110.95,628.39,5.65,7.38;5,132.19,627.09,66.22,9.40;5,243.23,621.37,3.13,5.47;5,246.75,641.98,3.13,5.47;5,259.59,629.01,3.59,9.44;5,284.84,629.01,19.60,9.44;5,325.60,629.01,12.82,9.44;5,294.21,638.89,1.74,1.00;5,319.77,638.89,3.82,1.00;5,241.41,646.13,1.74,1.00;5,205.85,636.18,21.30,1.00;5,251.50,636.18,41.78,1.00;5,313.08,636.18,21.32,1.00;5,243.70,641.92,3.43,5.52;5,230.96,628.91,5.93,9.54;5,305.50,628.91,5.93,9.54;5,239.13,627.66,11.56,14.32;5,340.39,627.09,140.52,9.40;5,110.95,660.10,5.65,7.38;5,132.19,658.80,74.50,9.40;5,253.61,661.56,21.09,1.00;5,214.55,667.81,27.75,1.00;5,253.61,675.54,19.96,1.00;5,244.78,660.95,5.55,8.99;5,282.05,658.80,155.27,9.40"><head>.</head><label></label><figDesc>Calculate the discount function based on the worker's answer: j is the standard rank obtained by NIST's relevance gold answer, i.e. 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="7,224.06,451.23,147.46,9.07"><head>Figure 5</head><label>5</label><figDesc>Figure 5 program of EM algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="8,258.98,638.53,77.70,9.07"><head></head><label></label><figDesc>Figure 6 program</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,90.05,283.00,391.90,135.71"><head>Qualification Test on CrowdFlower</head><label></label><figDesc></figDesc><table coords="2,90.05,283.00,391.90,135.71"><row><cell cols="2">Qualification Test on CrowdFlower</cell><cell>Test on AMT</cell><cell>Data processing</cell></row><row><cell></cell><cell cols="2">Figure 1 overall workflow</cell><cell></cell></row><row><cell>1.1 Qualification test</cell><cell>Get Qualified Worker ID</cell><cell>Assign Qualification</cell><cell>Notify Workers</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,90.05,167.54,401.02,308.11"><head></head><label></label><figDesc>with the average level of all teams: This is the result of rank judgement in task 1, compared with the average level of all teams: This is the result of binary judgement in task 2, compared with the average level of all teams: This is the result of rank judgement in task 2, compared with the average level of all teams:</figDesc><table coords="9,90.05,183.25,401.02,292.40"><row><cell>team</cell><cell>Accuracy</cell><cell>Recall</cell><cell>Precision</cell><cell>Specificity</cell></row><row><cell>BUPT-WILDCAT</cell><cell>75.7%</cell><cell>83.8%</cell><cell>76.3%</cell><cell>64.2%</cell></row><row><cell>average</cell><cell>74.0%</cell><cell>75.4%</cell><cell>79.1%</cell><cell>70.4%</cell></row><row><cell>team</cell><cell>MAP</cell><cell>NDCG</cell><cell></cell><cell></cell></row><row><cell>BUPT-WILDCAT</cell><cell>78.3%</cell><cell>82.0%</cell><cell></cell><cell></cell></row><row><cell>average</cell><cell>79.8%</cell><cell>83.1%</cell><cell></cell><cell></cell></row><row><cell>team</cell><cell>Accuracy</cell><cell>Recall</cell><cell>Precision</cell><cell>Specificity</cell></row><row><cell>BUPT-WILDCAT</cell><cell>94.1%</cell><cell>92.3%</cell><cell>98.3%</cell><cell>97.2%</cell></row><row><cell>average</cell><cell>76.9%</cell><cell>80.0%</cell><cell>82.5%</cell><cell>71.6%</cell></row><row><cell>team</cell><cell>MAP</cell><cell>NDCG</cell><cell></cell><cell></cell></row><row><cell>BUPT-WILDCAT</cell><cell>81.6%</cell><cell>92.8%</cell><cell></cell><cell></cell></row><row><cell>average</cell><cell>81.6%</cell><cell>92.1%</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>Thanks to the organizer for all the work and efficient communication. Thanks to Amazon.com and crowdflower.com for the generous financial and technical support. And we appreciate the help from other researchers in <rs type="institution">PRIS Laboratory of BUPT</rs>.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="10,108.07,120.72,255.45,9.40" xml:id="b0">
	<monogr>
		<title level="m" coord="10,108.07,120.72,235.80,9.40">TREC2011CrowdsourcingTrack-FinalGuidelines081811</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.07,140.18,393.08,9.40;10,108.07,156.02,264.48,9.40" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,243.32,140.18,257.83,9.40;10,108.07,156.02,72.72,9.40">Maximum likelihood estimation of observer error-rates using the EM algorithm</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Dawid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Skene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,187.89,156.02,73.86,9.40">Applied Statistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="20" to="28" />
			<date type="published" when="1979-09">Sept. 1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.07,175.46,355.82,9.40;10,108.07,190.87,219.26,9.50" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,323.81,175.46,140.07,9.40;10,108.07,190.97,69.54,9.40">Quality Management on Amazon Mechanical Turk</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Panagiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Foster</forename><surname>Ipeirotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jing</forename><surname>Provost</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,185.37,190.97,55.22,9.40">KDD-HCOMP</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2010-07-25">July 25, 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.07,210.77,374.01,9.40;10,108.07,226.25,399.79,9.40;10,108.07,241.73,311.46,9.40" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,452.64,210.77,29.44,9.40;10,108.07,226.25,395.54,9.40">Whose Vote Should Count More: Optimal Integration of Labels from Labelers of Unknown Expertise</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Whitehill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Ruvolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tingfan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Javier</forename><surname>Movellan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,108.07,241.73,280.84,9.40">Advances in Neural Information Processing Systems (forthcoming)</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
