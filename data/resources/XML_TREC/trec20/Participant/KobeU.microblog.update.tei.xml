<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,118.22,93.45,358.84,15.15;1,216.37,113.17,162.53,15.15">TREC 2011 Microblog Track Experiments at Kobe University</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,65.28,149.29,79.73,10.48"><forename type="first">Taiki</forename><surname>Miyanishi</surname></persName>
							<email>miyanishi@ai.cs.kobe-u.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department">Kuniaki Uehara Graduate School of System Informatics</orgName>
								<orgName type="institution">Kobe University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,169.11,149.29,81.62,10.48"><forename type="first">Naoto</forename><surname>Okamura</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Kuniaki Uehara Graduate School of System Informatics</orgName>
								<orgName type="institution">Kobe University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,274.83,149.29,53.81,10.48"><forename type="first">Xiaoxi</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Kuniaki Uehara Graduate School of System Informatics</orgName>
								<orgName type="institution">Kobe University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,352.74,149.29,71.87,10.48"><forename type="first">Kazuhiro</forename><surname>Seki</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Kuniaki Uehara Graduate School of System Informatics</orgName>
								<orgName type="institution">Kobe University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,118.22,93.45,358.84,15.15;1,216.37,113.17,162.53,15.15">TREC 2011 Microblog Track Experiments at Kobe University</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">53A5D6AB1BE2D621F772479EAB6EA473</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our approach to real-time microblog search that returns tweets for a given query in reverse chronological order. The approach utilizes a learning-to-rank (L2R) algorithm that has been increasingly used for information retrieval (IR). Generally, L2R algorithms require features which represent the associations between a user query and a document (tweet in this case). However, it is more difficult for microblog search to obtain rich features than traditional document search because the contents of microblog are too short: limited to only 140 characters. In addition, there is no standard, publicly available training data for learning to rank microblogs. To solve these problems, we generate new features by clustering large microblog data (the Tweets2011 corpus). The features are defined for triplets ⟨user query, tweet, cluster⟩ and represent the relevance of the tweet with respect to both the query and its topic (cluster). An L2R model is learned using the generated features as well as other features on labeled training data manually created by our research group. The effectiveness of the proposed approach is demonstrated by comparative experiments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Microblog, most notably Twitter 1 , is becoming increasingly popular and has been used world-wide, where real-time search is an important function to have a grasp of latest development or others' thoughts of a topic in which a user is interested. Such information play an important role in the field of event detection <ref type="bibr" coords="1,90.71,478.42,14.61,8.74" target="#b9">[10]</ref>, real-time web search <ref type="bibr" coords="1,208.32,478.42,9.96,8.74" target="#b3">[4]</ref>, or even safety information mining <ref type="bibr" coords="1,144.98,489.18,9.96,8.74" target="#b8">[9]</ref>. The difference between general web search and real-time search is that the former would return the results ranked by topical relevance to a user query, while the latter considers time sequence as well and presents relevant results in reverse chronological order (i.e., from the latest to the earliest).</p><p>The first year of the Microblog track addresses the real-time adhoc task. The following is the excerpt defining the task from the Microblog track guideline:</p><p>In the first run of the Microblog track, we will be addressing a search task whereby a user's information need will be represented by a query at a specific time. In particular, we address a real-time search task, where the user wishes to see the most recent but relevant information to the query. Hence, the system should answer a query by providing a list of relevant tweets ordered from newest to oldest, starting from the time the query was issued. When selecting tweets to include in the list, sys-1 http://twitter.com tems should favor "interesting" but "newer" relevant tweets. Interestingness is subjective, but the issuer of a query might interpret it as providing somehow added value with respect to the query topic. For this year, the "novelty" between tweets will not be considered.</p><p>Our approach to this task consists of three steps: initial search, reranking, and filtering described in Figure <ref type="figure" coords="1,340.61,498.04,3.87,8.74" target="#fig_0">1</ref>. First, we index tweets and search them using the Indri search engine <ref type="bibr" coords="1,437.18,508.80,9.96,8.74" target="#b7">[8]</ref>. Second, in order to remove irrelevant tweets to this task, we filter them by http status codes and their languages according to the track guideline in this year. After filtering, we collect features for the retrieved tweets. Also, we generate another type of features, called semantic features, based on user clusters identified in the tweets corpus. Using these features, we train a Ranking SVM which was used for reranking the initial set of retrieved tweets to produce the final tweet list. Inside our system, we mainly focus on a feature generation for a learning to rank (L2R) algorithm which exploits tweet contents and authority features following the related work. Note that, it is important to have good features to be effective for L2R and, unlike other targets such as web pages, it is difficult to define such features from the contents of microblogs (tweets) as each post is limited to only 140 characters. We tackle this problem by generating new contentbased features to represent the relevance of a tweet to a given query. To do this, we first cluster a large tweet corpus (Tweets2011) and then calculate a trigonal area for each triplet ⟨query, tweet, cluster⟩ in a ... In this representation, the relevance of a tweet to a given query is represented via each topically formed cluster. In addition, to learn a L2R model, small training data are manually created using the 12 example topics that the track organizers assembled and provided to the participants. The rest of this paper is organized as follows: Section 2 describes how we collected our data, including Tweets2011, to be used in this work. Section 3 presents the detail of our approach. We report on our experiments and the results in Section 4. Finally, Section 5 concludes this paper with a summary of findings and possible future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Tweet Corpus, Indexing, and Initial Search</head><p>We built the Tweets2011 corpus using the twittercorpus-tools 2 based on the 16,141,812 tweet seeds provided by the track organizers. We created the following two types of indices based on the resulting HTML files using the Indri retrieval engine 3 with default settings. Neither stemming nor stop-word removal was employed.</p><p>1. Index containing entire corpus (I 1 ).  The former index I 1 used the entire corpus disregarding the timestamp associated with each query. In other words, this index contains future tweets that did not exist when a query was issued. Strictly speaking, this is not appropriate for real-time search because using this index means we are using future information for term weights, such as IDF values. Conversely, the latter index I 2 was created to simulate a realistic real-time search setting, where no future information is available when a query is issued. We made the same number of indices as the number of queries having different timestamps, separately. Using these indices, we obtained three different initial search results T example , T topic1 , and T topic2 as follows:</p><p>1. T example : Queried the 12 example topics against I 1 and retained top 300 tweets posted before the given topic time.</p><p>2. T topic1 : Queried the 50 test topics against I 1 and retained top 1000 tweets posted before the given topic time.</p><p>3. T topic2 : Queried the 50 test topics against I 2 and retained top 1000 tweets (tweets posted before the given topic time do not exist).</p><p>The aforementioned 12 example topics (summarized in Table <ref type="table" coords="2,347.28,597.05,4.43,8.74" target="#tab_3">2</ref>) were distributed in advance by the track organizers. For tweets contained in T example and T topic1 , we additionally obtained their JSON files as auxiliary data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Approach</head><p>Our approach uses an L2R algorithm and is similar to Duan et al. <ref type="bibr" coords="2,371.20,691.72,10.52,8.74" target="#b4">[5]</ref> except that we employ filtering and propose semantic feature generation. L2R model requires training data which consists of a set of queries (q's) and, for each query, a list of tweets (t's) from the tweet corpus manually judged in relevance order. We trained Ranking SVM as an L2R model and ranked  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Feature Definitions</head><p>For L2R, it is quite important to choose good features. Considering the related work, we arbitrarily chose four types (called scopes) of features as shown in Table <ref type="table" coords="3,94.11,526.30,4.98,8.74" target="#tab_4">3</ref> for tweet representation. These scope types are: "Retrieval" being search scores produced by different IR models, "Message" concerning tweet itself, such as the number of characters or words and the number of URLs in the contents, "User" concerning user who posted a tweet, such as the number of followers and friends, and "Semantic" indicating the conceptual difference among a query, a tweet and a user cluster. These scopes, except for the last scope, were used for judgment of tweet credibility <ref type="bibr" coords="3,223.96,623.13,9.96,8.74" target="#b1">[2]</ref>. For binary features (i.e., true or false), their values are represented as 1 and 0. For numerical features, they are converted to z-scores. Missing values are filled with the mean of the normalized values of the other features in the same scope.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Feature Generation</head><p>Generally, L2R requires features representing the relationship between a user query and a tweet to generalize the model to unseen queries. A commonly used feature in this regard is to specify whether the query appears in a document (tweet). However, since each tweet is limited to 140 characters and there may be synonyms and polysemous words, simply looking at surface matches may not be sufficient to generate a reliable feature. For these reasons, we use K-means to identify semantic clusters representing topics such as politics, sport, science, etc. and calculate the semantic similarity among query, tweet, and a semantic cluster to create semantic features. To calculate the similarity between query and tweet in a latent concept space by the word vector projection, we use the view of Latent Semantic Indexing (LSI) <ref type="bibr" coords="3,462.48,405.79,9.96,8.74" target="#b2">[3]</ref>. As the latent semantic space divides multiple topics into respective clusters, we can calculate semantic similarities corresponding to each topic. An example of the semantic feature generation is shown in Figure3.</p><p>As the first step of making semantic clusters, we build a user-word matrix with the tf.idf<ref type="foot" coords="3,476.66,468.77,3.97,6.12" target="#foot_0">4</ref> term weighting <ref type="bibr" coords="3,323.07,481.11,10.52,8.74" target="#b6">[7]</ref> using the entire Tweets2011 corpus. We remove infrequent words (less than three) and non-ASCII characters and apply stemming by Snowball<ref type="foot" coords="3,479.27,501.05,3.97,6.12" target="#foot_1">5</ref> . The resulting matrix has n=4,654,678 rows (users) and m=879,192 columns (words). We apply singular value decomposition (SVD) to perform dimensionality reduction and noise reduction on the high-dimensional user-word matrix. Specifically, we use redsvd <ref type="foot" coords="3,446.90,554.85,3.97,6.12" target="#foot_2">6</ref> to perform SVD to reduce it to p dimensional space.</p><p>For clustering, we use the mini-batch K-means <ref type="bibr" coords="3,523.08,577.94,15.50,8.74" target="#b10">[11]</ref> implemented as sofia-kmeans<ref type="foot" coords="3,432.39,587.13,3.97,6.12" target="#foot_3">7</ref> using the reduced usertopic matrix U n×p as input. Specifically, we initialize the matrix by K-means++ <ref type="bibr" coords="3,432.34,610.22,10.52,8.74" target="#b0">[1]</ref> with mini-batches of size 1000 and 10000 iterations and cluster the data into k clusters. The centroid of each cluster ⃗ c p can be seen as a representative vector for the cluster. We call this centroid a topic vector.</p><p>Thus, we calculate a trigonal area among the topic vector ⃗ c p determined by clustering tweets, the query vector ⃗ q p and the tweet vector ⃗ t p (the latter two are obtained by projecting their original word vectors on the latent semantic space). The resulting area represents the relevance of the tweet with respect to both the query and its topic (cluster), and is used as a feature. The area is computed by Heron's formula shown as follow:</p><formula xml:id="formula_0" coords="4,105.27,596.85,178.21,18.97">S = √ s(s -a)(s -b)(s -c) (<label>1</label></formula><formula xml:id="formula_1" coords="4,283.48,606.53,4.24,8.74">)</formula><p>where</p><formula xml:id="formula_2" coords="4,84.99,627.15,183.77,11.50">a = ||⃗ q p -⃗ c p ||, b = || ⃗ t p -⃗ c p ||, c = ||⃗ q p -⃗ t p ||,</formula><p>and s is defined as 1/2(a + b + c). This area is computed for each topic cluster, resulting in k different features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Filtering</head><p>For the real-time adhoc task, non-English tweets are not considered relevant even if they contain relevant information in foreign languages. Retweets are not considered relevant, either. Thus, it is expected to improve search performance, specifically precision, to filter out all non-English tweets or retweets. In addition, low-ranked tweets are removed because the official performance metric is precision at 30 (P@30) and retrieved tweets are ordered in reverse chronological order, where it is important to retain only (deemed) highly relevant tweets. To this end, we apply the filtering procedure as follows:</p><p>1. Remove all the tweets starting with "RT" or those with the HTTP status code 302.</p><p>2. Remove all the tweets containing non-ASCII characters more than 15 percentages of their length.</p><p>3. Remove all the tweets whose lang element, extracted from their JSON format, is non-en &amp; which are determined as non-English by Google Language Detection API <ref type="foot" coords="4,440.53,717.73,3.97,6.12" target="#foot_4">8</ref>4. Remove low-ranked tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Relevance Assessment</head><p>After defining features for L2R, we need training data to train a learning to rank model. As there was no available training data we could find, we created a small amount of training data by ourselves using the 12 example topics distributed by the track organizers.</p><p>For each example topic, we obtained top 300 tweets from T example (see Section 2) retrieved by Indri with default settings. Then, a non-native English speaker annotated all retrieved tweets according to two criteria: relevance and interestingness each on a scale of 1 to 3 corresponding to 'bad', 'neutral', and 'good', respectively. More relevant/interesting tweets were assigned higher scores. Table <ref type="table" coords="5,116.80,270.06,4.98,8.74" target="#tab_5">4</ref> shows some example tweets and their scores (labels).</p><p>We defined relevance as containing user query words or their synonyms in a tweet, and interestingness as containing informative information (which is subjective). The final tweet score was defined as a product of these scores. With the training data, a ranking model was learned using Ranking SVM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>To learn a ranking function (ranker) which provides tweets' ranking in relevance order, we prepared the training data based on the features as described in Sections 3.1 and 3.2. We use SVM rank as a ranker, an implementation of Ranking SVM <ref type="bibr" coords="5,206.43,459.18,9.96,8.74" target="#b5">[6]</ref>. No kernel was used in order to speed up the learning process and to reduce the number of parameters to be optimized. After learning, we performed the leave-one-out crossvalidation on the 12 example topics to determine the optimum parameter C of Ranking SVM, which controls the trade-off between empirical loss and regularization. We tested 0.001, 0.003, 0.005, 0.008, and 0.01.</p><p>With the optimum parameters (C = 0.001), we reranked both search results T topic1 and T topic2 for the 50 test queries. As the output, we considered only top 30 tweets after reranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation</head><p>The assessors at NIST judged the relevance of pooled tweets from the 184 runs submitted by the total of 58 participating groups. Among the 50 test topics, it was reported that the 50th topic had no relevant tweets. Among the rest, 33 topics was reported to have highly relevant tweets. We separately report their results in Table <ref type="table" coords="5,83.91,696.54,3.87,8.74" target="#tab_6">5</ref>, where "all" are results for the 49 topics, and "high" for the 33 topics.</p><p>The primary evaluation measure for this task is the average of Precision at 30 (P@30). R-Precision (R-prec) and Mean Average Precision (MAP) are also shown in the table for reference. The run names in the first column corresponds to particular experimental setting as follows:</p><p>• Lucene-1000<ref type="foot" coords="5,386.29,125.17,3.97,6.12" target="#foot_5">9</ref> : Top 1000 ranked results by a disjunctive baseline run using Lucene<ref type="foot" coords="5,487.93,135.93,7.94,6.12" target="#foot_6">10</ref> provided by the organizers.</p><p>• Lucene-30: Top 30 ranked results of Lucene-1000.</p><p>• Indri 1 -1000: Top 1000 ranked results retrieved by Indri search with index I 1 (i.e., T topic1 ).</p><p>• Indri 2 -1000: Top 1000 ranked results retrieved by Indri search with index I 2 (i.e., T topic2 ).</p><p>• Indri 2 -1000-rt: Top 1000 tweets of T topic2 after retweet filtering (see Section 3.3).</p><p>• Indri 2 -1000-rtlang: Top 1000 tweets of T topic2 after retweet and language filtering.</p><p>• Indri 2 -30: An official run submitted as "normal". Top 30 tweets of T topic2 .</p><p>• Indri 1 -30-rtlang: Top 30 tweets of T topic1 after retweet and language filtering.</p><p>• Indri 1 -30-lr-rtlang: Another official run submitted as "ri". Top 30 of T topic1 after reranking and filtering. In this case, we set reduced dimension with p = 100 due to the restriction of computational resources and the number of clusters with k = 12 because the 12 example topics exist.</p><p>We used the two types of indexes I 1 and I 2 to obtain the results Indri 1 -1000 and Indri 2 -1000, respectively. Both results were obtained from Indri search engine and were evaluated for the top 1000 tweets against the official relevance judgment. Indri 1 -1000 is the results for the index using the entire corpus, and Indri 2 -1000 is for the indexes built for individual topics. Our expectation was that the index for the entire corpus would produce better results as it contains more information but clearly it did not in this case. Individual indexes were found to be better despite of less information. This result means that future information distorted statistics such as term weights, resulting in the inferior performance for realtime search.</p><p>Comparing Indri 2 -1000 to Indri 2 -1000-rt, Indri 2 -1000-rtlang, and Indri 2 -30, we can see how much improvement we gained through the three filters (i.e. retweet, non-English, and low-ranked filters). In P@30, retweet filter and non-English filter improved the performance by 26% and 33%, respectively. Also, filtering low-ranked tweets, Indri 2 -30, dramatically improved the performance by 227%. The same result holds for a different search engine, Lucene. Lucene-30 (the top 30 tweets taken from Lucene-1000) improved the performance by 225% comparing to Lucene-1000. This result suggests that topical relevance of tweets is much more important than when they were posted, which is counter-intuitive for real-time search. The improvement is presumably due to the fact that the corpus contains tweets only for 17 days from Jan. 23 to Feb. 7, 2011. As a whole, these filters are simple but essential on this year's rule. Lastly, the result of the proposed approach (filtering after reranking), indri 1 -30-lr-rtlang, performed better than indri 2 -30-rtlang. Reranking further improved P@30 by about 7%, and this is the best result among our official submissions.</p><p>We summarize the results of our experiments as follows:</p><p>1. Different indexes resulted in different results; future statistics of word distribution had harmful effects for IR precision.</p><p>2. Simple retweet and non-English filters significantly improved retrieval performance. This result also indicates that there are many retweets and some non-English tweets in search results.</p><p>3. Focusing on highly ranked tweets resulted in a striking boost in performance, suggesting that temporal closeness between a query and them seems to play an unimportant role in the Tweets2011 corpus.</p><p>4. The learning to rank model is effective for improving the performance for real-time twitter search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future work</head><p>Through the real-time adhoc task of TREC 2011 Microblog track, we developed a two-step approach: reranking and filtering. Filtering step identifies and removes retweets and non-English tweets, which was found crucial for this task. After filtering, we reranked tweets based on an L2R model learned using five types of features. The reranking step further improved the search performance, achieving the best overall result.</p><p>For future work, we plan to analyze effective features for learning to rank and develop a feature selection method suited for real-time search. Besides, we will use query expansion based on time-sensitive features and algorithm to improve IR performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,90.52,208.66,163.38,8.74"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overall system architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,370.34,206.76,105.46,8.74"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Ranking SVM</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,93.10,365.50,158.21,8.74"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Feature generation system</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,56.69,468.99,231.03,180.95"><head>Table 1</head><label>1</label><figDesc></figDesc><table coords="2,56.69,468.99,231.03,180.95"><row><cell></cell><cell>shows the dis-</cell></row><row><cell cols="2">tribution of the HTTP status codes of the results.</cell></row><row><cell cols="2">These tweets were posted by 5,356,842 distinct users</cell></row><row><cell cols="2">in total, of which 5,194,623 (97.0%) correspond to the</cell></row><row><cell cols="2">status codes 200 (OK) or 302 (Found). Unlike tra-</cell></row><row><cell cols="2">ditional test collections, each participant's corpus is</cell></row><row><cell cols="2">slightly different from the other participants due to</cell></row><row><cell cols="2">the self-archiving process. It is not clear how it af-</cell></row><row><cell cols="2">fects the final results but supposedly negligible.</cell></row><row><cell cols="2">Table 1: Number of fetched tweets</cell></row><row><cell>Status code</cell><cell># of tweets (%)</cell></row><row><cell>200 (OK)</cell><cell>14,230,073 (88.1)</cell></row><row><cell>302 (Found)</cell><cell>1,131,329 (7.00)</cell></row><row><cell>403 (Forbidden)</cell><cell>207,373 (1.28)</cell></row><row><cell>404 (Not Found)</cell><cell>573,034 (3.54)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,65.75,93.42,452.42,306.40"><head>Table 2 :</head><label>2</label><figDesc>Example queries.</figDesc><table coords="3,65.75,107.27,452.42,292.55"><row><cell cols="2">Number</cell><cell cols="2">Querytime</cell><cell></cell><cell></cell><cell>Title</cell><cell>Querytweettime</cell></row><row><cell cols="7">Example001 Thu Feb 03 22:06:42 2011 Chavez expropriate property</cell><cell>33285274087723010</cell></row><row><cell cols="7">Example002 Mon Feb 07 19:29:22 2011 Jintao visit US</cell><cell>34695232985645056</cell></row><row><cell cols="6">Example003 Fri Feb 04 20:03:25 2011</cell><cell>Saleh Yemen overthrow</cell><cell>33616636950880256</cell></row><row><cell cols="7">Example004 Mon Feb 07 13:53:01 2011 Sudan independence vote</cell><cell>34610585857433600</cell></row><row><cell cols="7">Example005 Mon Feb 07 17:37:44 2011 natural disasters Australia</cell><cell>34667136454631424</cell></row><row><cell cols="7">Example006 Wed Feb 02 22:09:28 2011 Kepler discovers new planets</cell><cell>32923583248338944</cell></row><row><cell cols="7">Example007 Wed Feb 02 15:47:04 2011 Texas school robot</cell><cell>32827348227198976</cell></row><row><cell cols="7">Example008 Wed Jan 26 03:25:35 2011 State of the Union and social media 30104034627031041</cell></row><row><cell cols="7">Example009 Tue Jan 25 03:05:55 2011 Example010 Mon Jan 24 00:40:20 2011 Sian Massey comments Cavaliers record Semantic Features</cell><cell>29736694160826368 29337669070749696</cell></row><row><cell cols="6">Example011 Fri Jan 28 22:55:25 2011</cell><cell>Mets, Madoff victims lawsuit</cell><cell>31123207859740672</cell></row><row><cell cols="6">Example012 Sun Feb 06 14:13:31 2011</cell><cell>Bjorn Qatar Masters</cell><cell>34253356427911168</cell></row><row><cell>Normal Space User_2 User_1</cell><cell>User_3</cell><cell>User_N</cell><cell>User_1</cell><cell>User_2</cell><cell cols="2">Latent Space User_3 User_N ...</cell></row><row><cell>Query</cell><cell>Tweet</cell><cell></cell><cell></cell><cell cols="2">K-means</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Cluster1</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Cluster2</cell><cell>Cluster3</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Query</cell><cell>Tweet</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell></row></table><note coords="3,155.91,318.65,14.36,6.92;3,67.51,341.94,102.70,5.90;3,71.15,329.09,71.17,8.58;3,133.56,281.78,7.55,11.26"><p><p>SVD</p>Feature : area among query, tweet, cluster (q, t) = {0.7, 0.5, 0.2} ...</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,103.24,93.42,385.49,250.14"><head>Table 3 :</head><label>3</label><figDesc>Five scopes of features representing a tweet.</figDesc><table coords="4,103.24,107.27,385.49,236.29"><row><cell>Scope</cell><cell>Feature</cell></row><row><cell cols="2">Retrieval Cosine similarity between query and topic</cell></row><row><cell></cell><cell>TFIDF</cell></row><row><cell></cell><cell>Okapi</cell></row><row><cell></cell><cell>Language Model with Dirichlet Smoothing</cell></row><row><cell></cell><cell>Language Model with Jelinek-Mercer Smoothing</cell></row><row><cell cols="2">Message Length of the text of the tweet in characters</cell></row><row><cell></cell><cell>Length of the text of the tweet in number of words</cell></row><row><cell></cell><cell>Contains a question mark "?" or exclamation mark "!"</cell></row><row><cell></cell><cell>Contains a personal pronoun in 1st, 2nd, or 3rd person. (Three features)</cell></row><row><cell></cell><cell>Fraction of capital letters in the tweet</cell></row><row><cell></cell><cell>Number of URLs contained on the tweet</cell></row><row><cell></cell><cell>Tweet contains "RT"</cell></row><row><cell></cell><cell>Day of the week in which this tweet was written</cell></row><row><cell>User</cell><cell>Time passed since the author registered his/her account in days</cell></row><row><cell></cell><cell>Number of people following this author at posting time</cell></row><row><cell></cell><cell>Number of people this author is following at posting time</cell></row><row><cell></cell><cell>Whether or not the author has a verified account at posting time</cell></row><row><cell></cell><cell>Whether or not the author has a non-empty bio at posting time</cell></row><row><cell></cell><cell>Whether or not the author has a non-empty homepage URL at posting time</cell></row><row><cell></cell><cell>Fraction of tweets containing more than 30% of characters in uppercase</cell></row><row><cell cols="2">Semantic Area among query, tweet, and cluster in a semantic space</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="4,71.49,367.28,449.23,150.78"><head>Table 4 :</head><label>4</label><figDesc>Examples of the manually created training data.</figDesc><table coords="4,71.49,381.18,449.23,136.88"><row><cell>Query</cell><cell cols="3">Relevance Interestingness Tweet</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Chavez expropriate property</cell><cell>3</cell><cell>3</cell><cell cols="2">Venezuela's</cell><cell>Chavez</cell><cell>threatens</cell><cell>to</cell><cell>seize</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="6">bank:/EFE)President Hugo Chavez threat-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>ened</cell><cell>to</cell><cell>expropriate</cell><cell>the</cell><cell cols="2">Venezuelan...</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">http://bit.ly/dQJFZT</cell><cell></cell><cell></cell></row><row><cell></cell><cell>1</cell><cell>2</cell><cell cols="6">INTERVIEW -Venezuela's "sweetheart" champi-</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="6">ons Chavez: Venezuelan President Hugo Chavez</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">during a meeting</cell><cell></cell><cell></cell></row><row><cell>Jintao visit US</cell><cell>3</cell><cell>3</cell><cell cols="6">U.S., China diplomats to meet in Beijing: Less</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="6">than a week after Chinese President Hu Jintao</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">visited Washington,... http://bit.ly/fAz91q</cell></row><row><cell></cell><cell>1</cell><cell>3</cell><cell cols="6">Has China really saved American con-</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="6">sumers $600 billion, as Hu Jintao claims?</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">http://econ.st/hMCeCb</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="6,62.67,93.42,477.21,120.74"><head>Table 5 :</head><label>5</label><figDesc>Results comparing different settings.</figDesc><table coords="6,62.67,107.27,477.21,106.89"><row><cell>Run</cell><cell cols="6">P@30 (all) R-prec (all) MAP (all) P@30 (high) R-prec (high) MAP (high)</cell></row><row><cell>Lucene-1000</cell><cell>0.0986</cell><cell>0.1486</cell><cell>0.1411</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Lucene-30</cell><cell>0.3204</cell><cell>0.2130</cell><cell>0.1645</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Indri 1 -1000</cell><cell>0.0728</cell><cell>0.0710</cell><cell>0.0723</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Indri 2 -1000</cell><cell>0.0959</cell><cell>0.1505</cell><cell>0.1403</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Indri 2 -1000-rt</cell><cell>0.1204</cell><cell>0.1784</cell><cell>0.1620</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Indri 2 -1000-rtlang</cell><cell>0.1272</cell><cell>0.1907</cell><cell>0.1699</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Indri 2 -30 (normal)</cell><cell>0.3136</cell><cell>0.2123</cell><cell>0.1608</cell><cell>0.0869</cell><cell>0.1767</cell><cell>0.1582</cell></row><row><cell>Indri 1 -30-rtlang</cell><cell>0.3871</cell><cell>0.1950</cell><cell>0.1526</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Indri 1 -30-lr-rtlang (ri)</cell><cell>0.4265</cell><cell>0.2635</cell><cell>0.2227</cell><cell>0.1303</cell><cell>0.2232</cell><cell>0.2079</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="3,322.80,719.21,189.22,6.99"><p>A user is regarded as a document d in terms of idf.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="3,322.80,729.00,122.80,6.64"><p>http://snowball.tartarus.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="3,322.80,738.22,135.50,6.64"><p>http://code.google.com/p/redsvd/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3" coords="3,322.80,747.44,211.72,6.64"><p>http://code.google.com/p/sofia-ml/wiki/SofiaKMeans</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4" coords="4,322.80,738.93,211.72,6.64;4,307.56,747.44,83.50,6.64"><p>http://code.google.com/apis/language/translate/v2/ getting started.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5" coords="5,322.80,738.22,197.83,6.64"><p>http://trec.nist.gov/act part/tracks.new11.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_6" coords="5,322.80,747.44,105.86,6.64"><p>http://lucene.apache.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,328.04,259.64,210.56,8.74;6,328.04,270.40,210.54,8.74;6,328.04,281.16,210.55,8.74;6,328.04,291.92,176.38,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,463.13,259.64,75.46,8.74;6,328.04,270.40,126.02,8.74">k-means++: The advantages of careful seeding</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vassilvitskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,476.84,270.40,61.74,8.74;6,328.04,281.16,210.55,8.74;6,328.04,291.92,67.91,8.74">Proceedings of the 18th annual ACM-SIAM symposium on discrete algorithms</title>
		<meeting>the 18th annual ACM-SIAM symposium on discrete algorithms</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1027" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,328.04,310.65,210.56,8.74;6,328.04,321.41,210.54,8.74;6,328.04,332.17,210.55,8.74;6,328.04,342.93,116.03,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,514.21,310.65,24.38,8.74;6,328.04,321.41,125.02,8.74">Information credibility on twitter</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Poblete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,476.61,321.41,61.97,8.74;6,328.04,332.17,210.55,8.74;6,328.04,342.93,16.42,8.74">Proceedings of the 20th international conference on World Wide Web</title>
		<meeting>the 20th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="675" to="684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,328.04,361.66,210.55,8.74;6,328.04,372.42,210.54,8.74;6,328.04,383.18,210.56,8.74;6,328.04,393.94,196.53,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,443.45,372.42,95.14,8.74;6,328.04,383.18,65.25,8.74">Indexing by latent semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Harshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,400.99,383.18,137.61,8.74;6,328.04,393.94,99.93,8.74">Journal of the American society for information science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="391" to="407" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,328.04,412.67,210.55,8.74;6,328.04,423.43,210.55,8.74;6,328.04,434.19,210.54,8.74;6,328.04,444.95,210.54,8.74;6,328.04,455.71,210.54,8.74;6,328.04,466.47,22.69,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,477.40,423.43,61.19,8.74;6,328.04,434.19,210.54,8.74;6,328.04,444.95,32.72,8.74">Time is of the essence: improving recency ranking using Twitter data</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kolari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,380.70,444.95,157.88,8.74;6,328.04,455.71,136.53,8.74">Proceedings of the 19th international conference on World Wide Web</title>
		<meeting>the 19th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="331" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,328.04,485.20,210.55,8.74;6,328.04,495.95,210.55,8.74;6,328.04,506.71,210.55,8.74;6,328.04,517.47,210.55,8.74;6,328.04,528.23,90.82,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,381.07,495.95,157.52,8.74;6,328.04,506.71,59.51,8.74">An empirical study on learning to rank of tweets</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,408.04,506.71,130.55,8.74;6,328.04,517.47,206.71,8.74">Proceedings of the 23rd; international conference on computational linguistics</title>
		<meeting>the 23rd; international conference on computational linguistics</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="295" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,328.04,546.96,210.55,8.74;6,328.04,557.72,210.55,8.74;6,328.04,568.48,210.56,8.74;6,328.04,579.24,210.54,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,394.17,546.96,144.42,8.74;6,328.04,557.72,73.75,8.74">Optimizing search engines using clickthrough data</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,420.48,557.72,118.11,8.74;6,328.04,568.48,210.56,8.74;6,328.04,579.24,112.23,8.74">Proceedings of the 8th ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 8th ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,328.04,597.97,210.55,8.74;6,328.04,608.73,210.55,8.74;6,328.04,619.49,177.14,8.74" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="6,380.01,597.97,158.58,8.74;6,328.04,608.73,210.55,8.74;6,328.04,619.49,89.95,8.74">A statistical interpretation of term specificity and its application in retrieval</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Jones</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972">1972</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="11" to="21" />
		</imprint>
	</monogr>
	<note>Journal of documentation</note>
</biblStruct>

<biblStruct coords="6,328.04,638.22,210.55,8.74;6,328.04,648.98,210.55,8.74;6,328.04,659.74,210.55,8.74;6,328.04,670.50,116.84,8.74" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="6,451.89,638.22,86.70,8.74;6,328.04,648.98,210.55,8.74;6,328.04,659.74,210.55,8.74;6,328.04,670.50,19.53,8.74">Combining the language model and inference network approaches to retrieval. Information processing &amp; management</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Croft</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="735" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,328.04,689.23,210.55,8.74;6,328.04,699.99,210.55,8.74;6,328.04,710.75,210.54,8.74;6,328.04,721.51,210.55,8.74;6,328.04,732.27,210.55,8.74;6,328.04,743.03,22.69,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,393.21,699.99,145.38,8.74;6,328.04,710.75,113.92,8.74">Safety information mining -what can NLP do in a disaster</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Matsubayashi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagiwara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Murakami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,461.16,710.75,77.42,8.74;6,328.04,721.51,210.55,8.74;6,328.04,732.27,116.74,8.74">Proceedings of the 5th international joint conference on natural language processing (IJCNLP)</title>
		<meeting>the 5th international joint conference on natural language processing (IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2011-11">Nov 2011</date>
			<biblScope unit="page" from="965" to="973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,77.17,86.50,210.56,8.74;7,77.17,97.26,210.55,8.74;7,77.17,108.02,210.55,8.74;7,77.17,118.78,210.55,8.74;7,77.17,129.54,90.82,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,259.33,86.50,28.40,8.74;7,77.17,97.26,210.55,8.74;7,77.17,108.02,90.44,8.74">Earthquake shakes twitter users: real-time event detection by social sensors</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,188.16,108.02,99.56,8.74;7,77.17,118.78,205.08,8.74">Proceedings of the 19th international conference on World Wide Web</title>
		<meeting>the 19th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="851" to="860" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,77.17,148.27,210.55,8.74;7,77.17,159.03,210.54,8.74;7,77.17,169.79,182.69,8.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,125.50,148.27,124.60,8.74">Web-scale k-means clustering</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,268.61,148.27,19.11,8.74;7,77.17,159.03,210.54,8.74;7,77.17,169.79,73.11,8.74">Proceedings of the 19th international conference on World Wide Web</title>
		<meeting>the 19th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1177" to="1178" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
