<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,73.99,83.76,461.73,15.48">The University of Amsterdam at the TREC 2011 Session Track</title>
				<funder ref="#_8JHq4bu">
					<orgName type="full">Netherlands Organisation for Scientific Research (NWO)</orgName>
				</funder>
				<funder ref="#_bjZH5uQ">
					<orgName type="full">Service Innovation &amp; ICT program</orgName>
				</funder>
				<funder ref="#_vdgDhuE">
					<orgName type="full">CLARIN-nl program</orgName>
				</funder>
				<funder>
					<orgName type="full">CIP ICT-PSP</orgName>
				</funder>
				<funder ref="#_PTGh7ud">
					<orgName type="full">PROMISE Network of Excellence</orgName>
				</funder>
				<funder ref="#_mM7xQsh #_NTEWDmU #_v72vVV4 #_sP3RmNA">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_eCwR7Uv">
					<orgName type="full">European Commission</orgName>
				</funder>
				<funder ref="#_phTfv4v">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_vxRzdGN">
					<orgName type="full">Hyperlocal Service Platform</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,158.65,116.28,86.41,10.75"><forename type="first">Bouke</forename><surname>Huurnink</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,260.00,116.28,98.42,10.75"><forename type="first">Richard</forename><surname>Berendsen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,373.36,116.28,80.70,10.75"><forename type="first">Katja</forename><surname>Hofmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,224.40,136.69,58.77,10.75"><forename type="first">Edgar</forename><surname>Meij</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,298.11,136.69,90.19,10.75"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,73.99,83.76,461.73,15.48">The University of Amsterdam at the TREC 2011 Session Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1873BE9AE31914A573789A3B75693AF5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe the participation of the University of Amsterdam's ILPS group in the Session track at TREC 2011.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The stream of interactions created by a user engaging with a search system contains a wealth of information. For retrieval purposes, previous interactions can help inform us about a user's current information need. Building on this intuition, our contribution to this TREC year's session track focuses on session modeling and learning to rank using session information. In this paper, we present and compare three complementary strategies that we designed for improving retrieval for a current query using previous queries and clicked results: probabilistic session modeling, semantic query modeling, and implicit feedback.</p><p>The rest of this paper is structured as follows: we detail our approach in Section 2, followed by our retrieval setup in Section 3. We describe our results in Section 4 and end with a concluding section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Modeling Sessions and Queries, and</head><p>Learning from Feedback</p><p>Here we describe our three strategies for session-based search: probabilistic session modeling, semantic query modeling, and implicit feedback. Before we start, we fix our notation and terminology. We use q m to denote the current query and I = {i 1 , i 2 , . . . , i m-1 } to denote the set of past interactions, where each interaction i n is associated with a query q n , a set of displayed result snippets R n and a set of clicked result snippets C n .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Probabilistic Session Modeling</head><p>Our probabilistic session modeling strategy uses interpolation to combine results from the current query with results from previously issued queries and with results from previously displayed or clicked snippets. Our experiments use progressively increasing amounts of session information: first previously issued queries, then previously displayed result snippets, and then previously clicked result snippets.</p><p>They are aimed at answering the following research questions:</p><p>• Does incorporating results from previously issued queries improve performance for the current query?</p><p>• Does incorporating results from previously displayed result snippets improve performance for the current query?</p><p>• Does incorporating results from previously clicked result snippets improve performance for the current query?</p><p>To form a query from a set of displayed or clicked result snippets, we apply RM-1 <ref type="bibr" coords="1,419.48,388.64,10.58,8.64" target="#b5">[6]</ref>.</p><p>Our session modeling approach is based on the FixInt approach of Shen et al. <ref type="bibr" coords="1,401.14,412.55,15.27,8.64" target="#b9">[10]</ref>. However, instead of creating new query models, we model the sessions at the document level. We calculate P(q m |d), the probability of q m given a document d, and P(i n |d), the probability of each prior interaction given d. We calculate P(N |d), the probability of the current information need N , by combining these probabilities using an interpolation parameter α such that:</p><formula xml:id="formula_0" coords="1,340.20,500.68,215.72,24.83">P(N |d) = α • P(q m |d) + (1 -α) • ∑ m-1 n=1 P(i n |d) |I| .<label>(1)</label></formula><p>As α increases, previous interactions are given less weight. When α = 1, only the results from the current query are taken into account. All previous interactions are given equal weight, normalizing by the number of previous interactions. Further, we model an interaction as a combination of a past query q n issued by the user, and a feedback query f n formed from either R n or C n , depending on the experimental condition. We interpolate these results again, using a second parameter β:</p><formula xml:id="formula_1" coords="1,355.52,647.18,200.40,9.72">P(i n |d) = β • P(q n |d) + (1 -β) • P( f n |d).<label>(2)</label></formula><p>Substituting Eq. 2 into Eq. 1, we obtain</p><formula xml:id="formula_2" coords="1,331.85,682.62,224.07,9.72">P(N |d) = α • P(q m |d)<label>(3)</label></formula><formula xml:id="formula_3" coords="1,351.77,696.90,189.12,24.83">+ (1 -α) • ∑ m-1 n=1 β • P(q n |d) + (1 -β) • P( f n |d) |I| .</formula><p>When β = 1, only the results from the user-issued query are taken into account, and conversely, when β = 0, only results from the feedback query are taken into account. We determine α and β by optimizing on the training data as described in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Semantic Query Modeling</head><p>Wikipedia provides a rich and extensive source of information, not only in terms of content but also in terms of more structural information, such as the hyperlinks between articles. We implemented a novel algorithm that leverages the anchor texts of incoming hyperlinks to Wikipedia articles, including not only "normal" hyperlinks, but also redirects and alternative titles of pages. It does so in two steps. First, the anchor texts are used to identify and score relevant Wikipedia articles for all possible term n-grams in a query <ref type="bibr" coords="2,79.53,259.73,10.79,8.64" target="#b6">[7,</ref><ref type="bibr" coords="2,93.37,259.73,7.19,8.64" target="#b7">8]</ref>. Then, for each of these articles, we again use the incoming anchor texts. In this step, however, we use them to determine the parameters of a language model for each article. The language models are subsequently combined for all n-grams in the query, yielding as end result a semantically-informed language model of the query, i.e., a semantic query model (SQM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Learning from Implicit Feedback</head><p>Our implicit feedback strategy uses machine learning to combine different ranking features, building on previous work in the area of online learning to rank from implicit feedback <ref type="bibr" coords="2,91.95,414.37,10.79,8.64" target="#b2">[3,</ref><ref type="bibr" coords="2,104.95,414.37,7.19,8.64" target="#b3">4]</ref>. We experiment with two learning strategies:</p><p>(1) learning from explicit relevance judgments on an external collection, and (2) learning from previous result clicks on previous results in the same session and other sessions.</p><p>Our experiments compare these two strategies to address the following research questions:</p><p>• Do weights tuned on an external collections carry over to the TREC session task?</p><p>• Do the clicks included with the TREC session data provide enough information for effective learning to rank?</p><p>• How do weights tuned using learning to rank from implicit feedback compare to those tuned on an external collection?</p><p>For both learning strategies we use the same implementation of an online learning to rank algorithm. Training data is constructed from either the external collection or click data observed on previous user interactions. The data is then used to learn weights for linear weighted combinations of the ranking features. To generate the final result list to be presented to the user, we apply the learned weight vector to the current query. Below, we detail the methods used to construct training data, the learning algorithm, features, and research questions.</p><p>Constructing training data In runs using an external collection, we constructed training instances from the data provided for the TREC 2009 Million Query track <ref type="bibr" coords="2,504.21,81.19,10.58,8.64" target="#b0">[1]</ref>. We used relevance assessments from the last queries of training sessions we constructed, see Section 3.3. In preliminary experiments, we found that best results were obtained when using all pairs of documents where one document was judged somewhat relevant (relevance grade 1), and the other document was judged highly relevant (grade 2). We extracted all such document pairs and trained our learning algorithm on all resulting data. As the algorithm is stochastic, we ran it repeatedly and selected the best weight vector to generate the results.</p><p>For the run using click data, we extract pair-wise preference relations, following <ref type="bibr" coords="2,419.20,224.65,10.58,8.64" target="#b4">[5]</ref>. In this approach, result documents that were clicked and presented at a lower rank than other, non-clicked documents, can be inferred to be more relevant than these non-clicked documents. Here, we extract all pairs that can be constructed in this way from all sessions.</p><p>Thus, given a document result list that was presented to a user in response to a query, and for which one or more clicks on documents were observed, we construct all possible ordered document pairs X, and infer labels Y (x) ∈ {-1, +1} for those pairs for which one document was clicked while the other was not (pairs for which neither, or both documents were clicked are discarded).</p><p>During learning, we use two sets of training data. Global training instances X G include all pair-wise preference relations inferred for all but the current target session (similar to leave-one-out). Local training instances X L include all training instances extracted for the current session (if available).</p><p>Features To facilitate learning that can generalize over documents and queries, we use a feature φ(d|q) representation that encodes the relationship between queries q and documents d. To apply pair-wise learning to rank we then represent pairs of documents by the difference of their feature vectors, such that x i = φ(d i 1 |q)φ(d i 2 |q). As the amount of training data is fairly limited, we limited ourselves to the following three features:</p><p>• standard retrieval scores for the current query on the anchor text,</p><p>• scores returned by the run UvAmodeling.RL <ref type="bibr" coords="2,507.29,577.58,9.23,8.59" target="#b0">[1]</ref><ref type="bibr" coords="2,516.52,577.58,4.61,8.59" target="#b1">[2]</ref><ref type="bibr" coords="2,521.13,577.58,9.23,8.59" target="#b2">[3]</ref>, and</p><p>• scores returned by the run UvAsemantic.RL <ref type="bibr" coords="2,506.23,597.45,9.08,8.59" target="#b0">[1]</ref><ref type="bibr" coords="2,515.31,597.45,4.54,8.59" target="#b1">[2]</ref><ref type="bibr" coords="2,519.84,597.45,9.08,8.59" target="#b2">[3]</ref>.</p><p>Learning to rank Given a set of observed data (X, Y) for P document pairs, we apply the stochastic gradient descent (SGD) algorithm defined by Zhang <ref type="bibr" coords="2,493.75,648.04,15.77,8.64" target="#b10">[11,</ref><ref type="bibr" coords="2,514.40,648.04,41.51,8.64;2,316.81,660.00,14.61,8.64">Algorithm 2.1]</ref>. This algorithm finds a weight vector ŵ that minimizes the empirical loss:</p><formula xml:id="formula_4" coords="2,352.34,694.27,203.58,27.27">ŵ = arg min w 1 P P ∑ i=0 L(w, x i , y i ) + λ 2 ||w|| 2 2 ,<label>(4)</label></formula><p>where L(w, x, y) is a loss function, in this case the hinge loss, and the last term is a regularization term. The algorithm was shown to perform competitvely on standard learning to rank datasets <ref type="bibr" coords="3,88.50,93.14,10.58,8.64" target="#b8">[9]</ref>. Here, we follow the implementation provided in sofia-ml. 1 For each observed training sample (x t , y t ), this algorithm updates the weight vector w t using the update rule w t+1 = w t + ηy t x tηλw. We use the unregularized version of this algorithm (by setting λ = 0) and use a small constant η = 0.0005. Finally, a given weight vector w is applied directly to the extracted feature vectors for given document-query pairs to compute ranking scores S = wφ(D|q). Documents are sorted by this score to obtain a result ranking <ref type="bibr" coords="3,208.76,200.74,10.58,8.64" target="#b4">[5]</ref>.</p><p>3 Experimental Setup</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Retrieval Framework</head><p>For retrieval we use a standard KL-divergence approach, with Bayesian smoothing using a Dirichlet prior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Collection</head><p>We made use of the English portion of the Clueweb A document collection. We did not use any form of stemming and removed a conservative list of 588 stopwords. We removed the 70% of the documents most likely to be spam according to the Waterloo fused spam scores <ref type="bibr" coords="3,208.78,395.67,10.58,8.64" target="#b1">[2]</ref>. Some Wikipedia pages were classified as spam using this algorithm, however, we kept these pages in the collection as we consider Wikipedia to be valuable knowledge resource.</p><p>We created two indexes. For the first index, the content index, we stripped all html from the documents and indexed the resulting plain text using the Indri retrieval engine. For the second index, the anchor-text index, we represented each document by the anchor text of URLs pointing to that document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training Data</head><p>To create training sessions, we worked backwards from queries for which we had relevance assessments. We selected queries from the Million Query Track 2009. For each query, we wrote an information need for which the querywould be a reasonable last query q m . Then we performed search sessions in Clueweb09 2 based on that information need and we recorded the result pages and our clicks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Runs</head><p>All submitted runs were Category A runs. 1 Provided online at http://code.google.com/p/sofia-ml/. UvAlearning Runs combine several ranking features using learning to rank on an external collection (RL1-3) or from implicit feedback (RL4) as described in §2.3.</p><p>RL1 Learn weights using the external collection; features: anchor text, UvAmodeling.RL1, UvAsemantic.RL1</p><p>RL2 Learn weights using the external collection; features: anchor text, UvAmodeling.RL2, UvAsemantic.RL2</p><p>RL3 Learn weights using the external collection; features: anchor text, UvAmodeling.RL3, UvAsemantic.RL3</p><p>RL4 Uses the same features as UvAlearning.RL3, but learns weights using implicit feedback, as described in §2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Result overviews for our submissions are shown in Table <ref type="table" coords="3,550.93,627.14,4.98,8.64" target="#tab_0">1</ref> and Table <ref type="table" coords="3,359.76,639.09,3.74,8.64" target="#tab_1">2</ref>. We show results according to nDCG@10, as this gives a good indication of the quality of the top 10 search results.</p><p>The best run type overall was UvAmodeling. For this run, we did not use query expansion or implicit learning, but linearly interpolated results from the current query with results from previous queries and result clicks. This approach Looking in more detail at the UvAmodeling run set, we see that performance did not increase between RL1 and RL2; this was due to a a bug in the system. This means that we cannot conclusively state whether incorporating results from previously issued queries improves performance for the current query in this setting. However, when we add information from previously displayed results (RL3), we see that performance goes down when evaluating with only the documents relevant to only the last subtopic. However, when evaluating with documents relevant to the whole topic of the session, performance increases. Finally, performance increases for both types of evaluation when we add information from previously clicked result snippets under RL4, and indeed this is where we attain the best performance.</p><p>Regarding our learning approaches, where weights for linear weighted combinations of runs were learned from either external data, or implicit feedback, we find few improvements over individual runs. The runs UvAlearning.RL <ref type="bibr" coords="4,270.15,437.53,9.10,8.59" target="#b0">[1]</ref><ref type="bibr" coords="4,283.80,437.53,9.10,8.59" target="#b1">[2]</ref> outperform the UvAsemantic runs, but score lower than the UvAmodeling runs. The reason may be that semantic modeling performs better on the external collection than on the TREC session track data, so that weights for this run are over estimated by the learning approach. In the RL3 series, where scores for UvAsemantic are higher, the benefit of combining weights increases, so that UvAlearning.RL3 outperforms all other runs in this series.</p><p>Moving to the run UvAlearning.RL4, we see that scores are substantially lower than for UvAlearning.RL3, which uses the same features and learning algorithm, but training data extracted from implicit feedback. We conclude that the click data associated with the current sessions does not contain enough information to provide useful feedback for learning to rank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have described the participation of the University of Amsterdam's ILPS group in the session track at TREC 2011. In our experiments we examined three complementary strategies for improving retrieval for a current query. Our first Our second strategy, based on semantic query modeling, did less well than we expected, likely due to topic drift from excessively aggressive query expansion. We expect that performance of this strategy would improve by limiting the number of terms and/or improving the probability estimates.</p><p>With respect to our third strategy, based on learning from feedback, we found that learning weights for linear weighted combinations of features from an external collection can be beneficial, if characteristics of the collection are similar to the current data. Feedback available in the form of user clicks appeared to be less beneficial. Our run learning from implicit feedback did perform substantially lower than a run where weights were learned from an external collection with explicit feedback using the same learning algorithm and set of features.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,64.66,710.53,186.96,8.51;3,316.81,56.89,239.10,9.03;3,336.74,69.23,219.18,8.64;3,336.74,81.19,161.32,8.64;3,336.74,100.44,144.67,9.15;3,336.74,116.10,219.18,9.03;3,358.66,128.12,120.81,9.08;3,336.74,143.71,219.18,9.03;3,358.66,155.73,137.95,9.08;3,336.74,171.32,219.18,9.03;3,358.66,183.35,128.44,9.08;3,316.81,202.92,239.10,9.03;3,336.74,215.26,219.18,8.64;3,336.74,227.22,219.18,8.64;3,336.74,239.17,141.41,8.64;3,336.74,258.43,182.86,9.15;3,336.74,274.09,219.18,9.03;3,358.66,286.11,148.28,9.08;3,336.74,301.70,219.18,9.03;3,358.66,314.04,197.26,8.64;3,358.66,325.68,145.95,9.08;3,336.74,341.27,219.18,9.03;3,358.66,353.61,197.26,8.64;3,358.66,365.25,125.19,9.08"><head>2 1 RL2 1 RL3 9 RL4 1 UvAsemantic 1 RL2 1 RL3 5 RL4</head><label>21191115</label><figDesc>We used http://boston.lti.cs.cmu.edu/Services/ UvAmodeling Run based on explicit modeling. All runs are created according to Equation 3. Weight parameters are determined using the training collection. RL1 Use current query only: α = Use current query and previous queries, but no result snippets: α = 0.6, β = Use current query, previous queries, and previous displayed results: α = 0.6, β = 0.Use current query, previous queries, and previous clicked results: α = 0.4, β = 0.Run based on semantic query modeling (SQM). All runs are created using SQM, in combination with Equation 3. Weight parameters are determined using the training collection.RL1 Use SQM for current query only: α = Use SQM for current query and previous queries, but no result snippets: α = 0.6, β = Use SQM for current query and previous queries, and create query from previously displayed results without SQM: α = 0.5, β = 0.Use SQM for current query and previous queries, and create query from previously clicked results without SQM: α = 0.5, β = 0.8</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,53.80,64.07,239.10,167.08"><head>Table 1 :</head><label>1</label><figDesc>Result overview for all runs in terms of nDCG@10, considering only those documents relevant to the subtopics of the last query as relevant. The highest score pfr each experimental condition is indicated in bold.</figDesc><table coords="4,53.80,115.65,239.10,115.50"><row><cell>Run type</cell><cell>RL1</cell><cell>RL2</cell><cell>RL3</cell><cell>RL4</cell></row><row><cell>UvAmodeling</cell><cell cols="4">0.238 0.238 0.232 0.254</cell></row><row><cell>UvAsemantic</cell><cell cols="4">0.186 0.181 0.208 0.192</cell></row><row><cell>UvAlearning</cell><cell cols="4">0.211 0.199 0.233 0.173</cell></row><row><cell cols="5">gained the highest performance under experimental condi-</cell></row><row><cell cols="5">tions RL1, RL2, and RL4. It also achieved the highest over-</cell></row><row><cell cols="5">all score. The highest performing run type under condition</cell></row><row><cell>RL3 was UvAlearning.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,316.81,64.07,239.10,141.74"><head>Table 2 :</head><label>2</label><figDesc>Result overview for all runs in terms of nDCG@10, considering those documents relevant to the whole topic of the session. The highest score for each experimental condition is indicated in bold.</figDesc><table coords="4,316.81,113.61,239.10,92.20"><row><cell>Run</cell><cell>RL1</cell><cell>RL2</cell><cell>RL3</cell><cell>RL4</cell></row><row><cell>UvAmodeling</cell><cell cols="4">0.337 0.337 0.349 0.412</cell></row><row><cell>UvAsemantic</cell><cell cols="4">0.285 0.305 0.355 0.329</cell></row><row><cell>UvAlearning</cell><cell cols="4">0.321 0.324 0.400 0.293</cell></row><row><cell cols="5">strategy, based on probabilistic session modeling, was the</cell></row><row><cell>best performing strategy.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research was partially supported by the <rs type="funder">European Union</rs>'s <rs type="programName">ICT Policy Support Programme as part of the Competitiveness and Innovation Framework Programme</rs>, <rs type="funder">CIP ICT-PSP</rs> under grant agreement nr 250430, the <rs type="funder">PROMISE Network of Excellence</rs> co-funded by the 7th <rs type="programName">Framework Programme</rs> of the <rs type="funder">European Commission</rs> under grant agreement nr 258191, the <rs type="projectName">LiMoSINe</rs> project co-funded by the 7th <rs type="programName">Framework Programme</rs> of the <rs type="funder">European Commission</rs> under grant agreement nr 288024, the <rs type="funder">Netherlands Organisation for Scientific Research (NWO)</rs> under project nrs <rs type="grantNumber">612.061.-814</rs>, <rs type="grantNumber">612.061.815</rs>, <rs type="grantNumber">640.004.802</rs>, <rs type="grantNumber">380-70-011</rs>, <rs type="grantNumber">727.011.005</rs>, the <rs type="institution">Center for Creation, Content and Technology (CCCT)</rs>, the <rs type="funder">Hyperlocal Service Platform</rs> project funded by the <rs type="funder">Service Innovation &amp; ICT program</rs>, the <rs type="projectName">WAHSP</rs> project funded by the <rs type="funder">CLARIN-nl program</rs>, under <rs type="projectName">COMMIT</rs> project <rs type="projectName">Infiniti</rs> and by the <rs type="programName">ESF Research Network Program ELIAS</rs>. 6 References</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_phTfv4v">
					<orgName type="program" subtype="full">ICT Policy Support Programme as part of the Competitiveness and Innovation Framework Programme</orgName>
				</org>
				<org type="funding" xml:id="_PTGh7ud">
					<orgName type="program" subtype="full">Framework Programme</orgName>
				</org>
				<org type="funded-project" xml:id="_eCwR7Uv">
					<orgName type="project" subtype="full">LiMoSINe</orgName>
					<orgName type="program" subtype="full">Framework Programme</orgName>
				</org>
				<org type="funding" xml:id="_8JHq4bu">
					<idno type="grant-number">612.061.-814</idno>
				</org>
				<org type="funding" xml:id="_mM7xQsh">
					<idno type="grant-number">612.061.815</idno>
				</org>
				<org type="funding" xml:id="_NTEWDmU">
					<idno type="grant-number">640.004.802</idno>
				</org>
				<org type="funding" xml:id="_v72vVV4">
					<idno type="grant-number">380-70-011</idno>
				</org>
				<org type="funding" xml:id="_vxRzdGN">
					<idno type="grant-number">727.011.005</idno>
				</org>
				<org type="funded-project" xml:id="_bjZH5uQ">
					<orgName type="project" subtype="full">WAHSP</orgName>
				</org>
				<org type="funded-project" xml:id="_vdgDhuE">
					<orgName type="project" subtype="full">COMMIT</orgName>
				</org>
				<org type="funded-project" xml:id="_sP3RmNA">
					<orgName type="project" subtype="full">Infiniti</orgName>
					<orgName type="program" subtype="full">ESF Research Network Program ELIAS</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,333.41,674.96,222.50,8.64;4,328.43,686.74,227.48,8.82;4,328.43,698.69,227.49,8.59;4,328.43,710.65,135.40,8.82" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,361.11,686.91,136.54,8.64">Million query track 2009 overview</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pavlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,516.33,686.74,39.58,8.59;4,328.43,698.69,194.18,8.59">The Eighteenth Text Retrieval Conference Proceedings</title>
		<imprint>
			<publisher>NIST. Special Publication</publisher>
			<date type="published" when="2009">2010. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.40,57.28,222.50,8.64;5,65.42,69.23,227.49,8.64;5,65.42,81.01,227.49,8.82;5,65.42,93.14,47.59,8.64" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,104.74,69.23,188.16,8.64;5,65.42,81.19,124.73,8.64">Efficient and effective spam filtering and reranking for large web datasets</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,202.41,81.01,86.60,8.59">Information Retrieval</title>
		<imprint>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.40,113.07,222.50,8.64;5,65.42,125.02,227.49,8.64;5,65.42,136.80,227.48,8.82;5,65.42,148.75,88.95,8.59" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,65.42,125.02,227.49,8.64;5,65.42,136.98,23.48,8.64">Balancing exploration and exploitation in learning to rank online</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Whiteson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,113.15,136.80,179.75,8.59;5,65.42,148.75,85.07,8.59">ECIR 2011: 33rd European Conference on Information Retrieval</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.40,168.86,222.50,8.64;5,65.42,180.81,227.49,8.64;5,65.42,192.59,227.48,8.82;5,65.42,204.54,157.98,8.59" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,65.42,180.81,227.49,8.64;5,65.42,192.77,22.06,8.64">A probabilistic method for inferring preferences from clicks</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Whiteson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,113.93,192.59,178.97,8.59;5,65.42,204.54,99.04,8.59">20th ACM Conference on Information and Knowledge Management</title>
		<imprint>
			<publisher>CIKM</publisher>
			<date type="published" when="2011">2011b. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.40,224.65,222.50,8.64;5,65.42,236.42,190.63,8.82" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,160.04,224.65,132.86,8.64;5,65.42,236.60,68.12,8.64">Optimizing search engines using clickthrough data</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,151.73,236.42,35.35,8.59">KDD &apos;02</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.40,256.53,222.50,8.64;5,65.42,268.30,227.48,8.82;5,65.42,280.26,227.49,8.59;5,65.42,292.21,166.19,8.59" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,226.55,256.53,66.35,8.64;5,65.42,268.48,65.42,8.64">Relevance based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,150.38,268.30,142.52,8.59;5,65.42,280.26,227.49,8.59;5,65.42,292.21,162.57,8.59">SIGIR &apos;01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.40,312.32,222.50,8.64;5,65.42,324.10,227.49,8.82;5,65.42,336.05,227.49,8.59;5,65.42,348.01,194.73,8.59" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,221.92,312.32,70.98,8.64;5,65.42,324.27,105.38,8.64">Supervised query modeling using Wikipedia</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,193.58,324.10,99.33,8.59;5,65.42,336.05,227.49,8.59;5,65.42,348.01,191.10,8.59">SIGIR &apos;10: Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.40,368.11,222.50,8.64;5,65.42,379.89,227.48,8.82;5,65.42,391.84,227.49,8.59;5,65.42,403.80,110.68,8.59" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,65.42,380.07,148.16,8.64">Adding semantics to microblog posts</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Weerkamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,233.01,379.89,59.88,8.59;5,65.42,391.84,227.49,8.59;5,65.42,403.80,47.88,8.59">Proceedings of the fifth ACM international conference on Web search and data mining</title>
		<meeting>the fifth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<publisher>WSDM</publisher>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.40,423.72,222.51,8.82;5,65.42,435.68,163.45,8.59" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,147.39,423.90,107.58,8.64">Large scale learning to rank</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,271.87,423.72,21.03,8.59;5,65.42,435.68,158.98,8.59">NIPS 2009 Workshop on Advances in Ranking</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,75.38,455.78,217.52,8.64;5,65.42,467.74,227.49,8.64;5,65.42,479.51,109.73,8.82" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,258.18,455.78,34.72,8.64;5,65.42,467.74,211.97,8.64">Contextsensitive information retrieval using implicit feedback</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,65.42,479.51,22.82,8.59">SIGIR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,75.38,499.62,217.52,8.64;5,65.42,511.57,227.49,8.64;5,65.42,523.35,120.06,8.82" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,149.02,499.62,143.88,8.64;5,65.42,511.57,212.24,8.64">Solving large scale linear prediction problems using stochastic gradient descent algorithms</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,65.42,523.35,38.12,8.59">ICML &apos;04</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">116</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
