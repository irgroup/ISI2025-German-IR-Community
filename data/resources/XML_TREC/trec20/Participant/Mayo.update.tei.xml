<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,147.05,101.81,317.59,15.55">Empirical Ontologies for Cohort Identification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,91.96,134.31,58.74,10.87"><forename type="first">Stephen</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName coords="1,161.54,134.31,112.55,10.87"><forename type="first">Kavishwar</forename><surname>Wagholikar</surname></persName>
						</author>
						<author>
							<persName coords="1,283.54,134.31,78.81,10.87"><forename type="first">Sunghwan</forename><surname>Sohn</surname></persName>
						</author>
						<author>
							<persName coords="1,371.98,134.31,68.54,10.87"><forename type="first">Vinod</forename><surname>Kaggal</surname></persName>
						</author>
						<author>
							<persName coords="1,450.01,134.31,69.73,10.87"><forename type="first">Hongfang</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName coords="1,232.91,148.26,60.28,10.87"><forename type="first">Mayo</forename><surname>Clinic</surname></persName>
						</author>
						<title level="a" type="main" coord="1,147.05,101.81,317.59,15.55">Empirical Ontologies for Cohort Identification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3CCE7DD23C10295666312A74FFB06266</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The growth of patient data stored in Electronic Medical Records (EMR) has greatly expanded the potential for the evidence-based improvement of clinical practice. The proper re-use of this clinical information, however, does not replace basic research techniques -it augments them. The Text REtrieval Conference 2011 Medical Records Track explored how information retrieval may support clinical research by providing an efficient means to identify cohorts for clinical studies.</p><p>Mayo Clinic NLP's submission to the TREC Medical Records track attempts information retrieval at a semantic level, combining two disparate means of computing clinical semantics. Substantial effort has gone into the development of precise semantic specification of concepts in medical ontologies and terminologies <ref type="bibr" coords="1,127.38,403.25,22.81,9.62">[1, ?]</ref>. But human clinicians do not generate clinical text by referring to such resources, and ontology creators do not base their terminology design on clinical text -so the distribution of ontology concepts in actual clinical texts may differ greatly.</p><p>Therefore, in representing clinical reports for cohort identification, we advocate for a model that makes use of expert knowledge, is empirically validated, and considers context. This is accomplished through a new framework: empirical ontologies. Patient cohort identification is thus a practical use case for the techniques in our recent work on clinical concept frequency comparisons <ref type="bibr" coords="1,188.84,547.25,13.67,9.62" target="#b1">[2,</ref><ref type="bibr" coords="1,205.83,547.25,7.01,9.62" target="#b2">3]</ref>.</p><p>The rest of this paper describes the TREC 2011 Medical Records task, describes Mayo Clinic's run submissions, and reports evaluation results with subsequent discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>The inaugural TREC 2011 Medical Records track was arranged as follows. The data to be retrieved lay in the University of Pittsburgh's BLU repository, which includes only the free text portions of medical records. Each patient at the University of Pittsburgh would have one or more medical records (documents) associated with him or herself. Each record was given in XML format, and included both structured data and the unstructured text. Records are uniquely identified by their checksum. Note that each record contains a note type and subtype; in the example, the note comes from an Emergency Room/Department. The chief complaint section is a helpful textual summary of what the record is about from the patient's perspective, and is not present for every record. The admit diagnosis and discharge diagnosis serve a similar function but are also not always present. They are given as ICD-9 codes, a medical terminology frequently used for billing purposes. Finally, notice that the notes were de-identified, so that any protected health information has been replaced with surrogates.</p><p>The records were grouped into visits -a physical visit to the hospital. The unit of retrieval was defined as a patient visit. In total, there were 95,702 records that corresponded to 17,198 visits. The largest visit was 418 records, but the mean visit was 5.56 records.</p><p>Participants from 29 institutions were given a set of 35 hypothetical topics developed by experts at the Oregon Health Sciences University (OHSU). These topics defined patient profiles that might be involved in a clinical trial. For each topic, participants retrieved a list of patient visits in order of relevance to the topic.</p><p>For evaluation and ranking, there were two evaluation rounds. In the judged round, retrieved records from participants' runs were given to assessors at OHSU. These assessors rendered relevance judgments on a stratified pool of visits -the top 10 of each submitted run, and decreasing percentages of lowerranked visits from each run.</p><p>Although there was a fairly consistent pool depth (number of adjudged visits for each topic), the nature of each topic and its correspondence with the given dataset varied greatly. For example, topic 130 was discarded for purposes of evaluation because no records were assessed as being relevant to the query topic; on the other hand, other topics likely had many relevant visits that were never assessed.</p><p>Thus, the primary evaluation metric chosen for rankings was bpref, since it only penalizes systems for placing irrelevant documents ahead of relevant documents. Other evaluation metrics such as P@10 will be presented where they illustrate something about the data, system outputs, or evaluation procedure.</p><p>In the unjudged round of evaluations, bpref and other metrics were calculated based on the relevance judgment pools from the first round. Thus, a metric like P@10 for an unjudged round is an approximation, unlike that for a judged round.</p><p>Mayo Clinic NLP submitted runs to both the judged and unjudged rounds, but we report only the latter (the former contained significant bugs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>In our empirical ontologies approach, each query is predominantly represented at the semantic concept level, rather than at a textual level. Similarly, each document is represented as a set of semantic concepts. Query concepts and document concepts are weighted, aggregated, and compared to produce a ranking of the most similar topic-visit pairs. Below, we describe Mayo Clinic's baseline unjudged run and then detail the innovations introduced in the other runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baseline</head><p>Each topic query is given in a form such as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number: 108 Patients treated for vascular claudication surgically</head><p>From the text of this query, we manually assigned semantic concepts to important semantic concepts. As a baseline configuration (outside the dotted line of Figure <ref type="figure" coords="2,354.81,192.58,3.87,9.62" target="#fig_0">1</ref>), the weights for each query were specified manually. Three medical experts were asked the following questions:</p><p>1. What are essential concepts in the query?</p><p>2. What procedures, medication, or surgeries treat this (if not in the topic description)?</p><p>3. What distinction is being drawn (things that are NOT wanted)?</p><p>4. What is a typical patient with this condition like? Common comorbidities?</p><p>5. What types of notes will this be found in? NOT found in? (e.g., discharge diagnosis, operative note)</p><p>6. Are there other terms that express what they are looking for better?</p><p>The answers to these questions were at first manually written as term lists by the experts. We normalized these terms to concept unique identifiers (CUIs) from the the Unified Medical Language System (UMLS) Metathesaurus <ref type="bibr" coords="2,371.43,474.90,13.98,9.62" target="#b0">[1]</ref> via the UMLS Terminology Services. We augmented these CUIs with pseudo-CUIs for age and gender terms, as well as terms from the last question that might be in text but might not be capturable by dictionary lookup algorithms.</p><p>Weights for each of the concepts were given a weight according to which question they were answering: 1.0, 0.75, 0.5, and 0.25 for the first 4 questions, respectively. CUIs for item 3 were marked as negated. The second-to-last question was unused for the baseline method, but, for use in later methods, weights were given to note types for each topic. Beyond the questions we asked experts, weights were also given to sections within a medical record upon analysis of the topics; these were also unused in the baseline method.</p><p>We then view each topic query as a vector, where each index indicates the weight of a concepts. For the baseline model, the query processing ends here, and we have produced a query 'mask.'</p><p>Figure <ref type="figure" coords="2,351.50,702.05,4.98,9.62" target="#fig_1">2</ref> shows the methodology for processing and retrieving reports, where again, the baseline method  is outside the dotted line. First, we automatically extract concepts from reports in the Pittsburgh repository using standard clinical NLP tools. In the baseline method, this mapping from text to UMLS concepts was accomplished with an Aho-Corasick <ref type="bibr" coords="3,287.07,405.89,13.80,9.62" target="#b3">[4]</ref> dictionary lookup on normalized tokens, using the UMLS 2011AA as the dictionary.</p><p>For report-side processing, we again had a few special cases, where we automatically assigned CUIs according to rules. ICD-9 diagnosis codes were translated into CUIs via the Metathesaurus, and were included. Special pseudo-CUIs were created for age and gender groups. Also, the same pseudo-CUIs from the query side (age, gender, terms from the last question) were included.</p><p>For each report, we count the frequency of all concepts (CUIs) that are present. Our previous work shows that this is relatively similar to tf-idf in the medical domain <ref type="bibr" coords="3,137.82,595.35,13.61,9.62" target="#b2">[3]</ref>. Then, for each hospital visit, weights are summed across reports to obtain a vectorial representation. This allows us to represent the patient's visit in vectorial form, just as we had represented the query.</p><p>We can then rank query-visit pairs by comparing the vectors. The simplest method for doing this, cosine similarity, was used as our baseline. The 1,000 visits closest to each query topic vector were ranked and retained as our run submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Propagation</head><p>The idea of empirical ontologies, while present in the baseline system, is implemented most fully with the idea of propagation. Because we are viewing each query and each report as a collection of weighted semantic concepts, we can make additional inferences at a semantic level. These are illustrated in Figure <ref type="figure" coords="3,531.97,436.42,3.87,9.62" target="#fig_2">3</ref>.</p><p>Ontological propagation. The UMLS Metathesaurus contains CUIs that arise from source ontologies, which maintain hierarchical relationships between concepts. For example, an "colon structure" (CUI: C0009368) has an 'isa' relationship with its ontological parent, "large intestine structure" (CUI: C1709915). Ontological propagation takes a set of weighted concepts (i.e., directly from the queries, or from frequency counts in the reports) and propagates those weights to hierarchically related concepts.</p><p>If a concept "colon structure" is mentioned, the presence of its parent "large intestine structure" is entailed. Thus, we propagate weights from a concept to its parents (see Figure <ref type="figure" coords="3,499.21,630.32,4.98,9.62" target="#fig_2">3</ref> for the corresponding example). However, if a concept "colonoscopy" is negated "no colonoscopy," it does not imply that no procedures were done. However, it may imply that "no virtual colonoscopy" was done. Therefore, for negated concepts, we propagate weights from a concept to its children. Of course, it is not always meaningful to execute this kind of propagation fully. For example, it is may not be helpful to say that there is an instance of a "anatomical site" when the concept "colon structure" is discovered. Therefore, we implement two kinds of decay and allow an optional cutoff. First, we included a constant multiplier (less than 1) to make any propagated concept count less than an originally-discovered concept. Second, we implement a geometric decay based on path distance (number of hierarchical nodes separating the original weighted concept and the concept that will receive additional weighting). Finally, we give the option to cut off upwards or downwards propagation at defined path distances.</p><p>Figures <ref type="figure" coords="4,127.72,524.86,4.98,9.62" target="#fig_0">1</ref> and<ref type="figure" coords="4,156.25,524.86,4.98,9.62" target="#fig_1">2</ref> show where Ontological propagation takes place in our system.</p><p>Co-occurrence propagation. Ontological semantic relationships, as coded by experts, sometimes ignore the empirical realities of how concepts are distributed. We also investigated distributional relationships between concepts, so that concepts occurring in the same document would have relationships between them with some weight defined by how many times they co-occurred. This is shown on the right of Figure <ref type="figure" coords="4,241.24,650.96,4.98,9.62" target="#fig_2">3</ref> by the size of the arrows between "colon structure" and "colonoscopy" and between "colon structure" and "ascending colon structure."</p><p>We created two large tables storing the frequency of CUI occurrences in each document, based on a random sample of 50 million Mayo Clinic clinical notes. The smaller had 79,597,219 relationships, and the larger had 282,712,288. These tables excluded the most common concepts in the clinical documents due to computational constraints. The intuition was that common concepts are unlikely to be highly discriminative, since previous work shows they are fairly general terms <ref type="bibr" coords="4,504.14,414.00,12.57,9.62" target="#b2">[3]</ref>.</p><p>These tables were queried in SQL to retrieve cooccurrences, as follows: where cutoff was the fewest co-occurrences that would be reported as a valid relationship. Because searching for the co-occurrences of a concept is time-consuming, we limited this search to only the query expansion section, i.e., to concepts that were present in the query.</p><formula xml:id="formula_0" coords="4,352.68,465.91,62.76,8.49">SELECT a.cui</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Variants</head><p>Mayo Clinic NLP submitted 4 system configurations:</p><p>1. mayo2noprop (Section 3.1): Baseline configuration with manually-assigned query concepts and weights; report weights are based on Aho-Corasick string matching. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Expansion and weighting (mayolbrst)</head><p>The configuration of the mayolbrst run is as follows:</p><p>• Query-side ontological propagation. Weights of query concepts are extended to UMLS 'isa' relationships (ontological neighbors). The initial downweighting of ontologically propagated concepts was set at 0.9 for positive concepts and 0.7 for negative concepts. The geometric decay parameter based on the path was set at 0.125.</p><p>• Query-side co-occurrence propagation. Weights of query concepts are extended to co-occurring concepts from Mayo's NLP-processed corpus of 50 million-plus clinical notes.</p><p>• Report-side ontological propagation. Weights of report concepts are extended to UMLS 'isa' relationships (ontological neighbors). The same decay parameters were used as the query-side ontological propagation above, but additionally cut off propagation towards parents at a path distance of 3, and towards children at a path distance of 2.</p><p>• Type weights. A multiplier is included on the report side for what type of note each concept is from, since a visit may have reports of different types. For example, for Topic 108 (see Section 3.1), concepts found in Operative notes were deemed 1.5× more useful than those found in other note types.</p><p>• Section weights. A multiplier is included on the report side for what section of a note each concept is from, e.g., DIAGNOSIS might be higher weighted than FAMILY HISTORY. Sections are automatically tagged using SecTagger, as per Figure <ref type="figure" coords="5,123.36,712.07,3.87,9.62" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Automatic query-side concept extraction (mayolbra)</head><p>This run, mayolbra, differed from the other 3 in the means by which it interpreted the query topic. The others used manual CUI assignments and weights, whereas mayolbra assigned these CUIs and weights automatically. The same baseline dictionary lookup procedure (based on the Aho-Corasick algorithm) that was used on the reports was also used on the raw text of the query. This implied that query processing had no special weighting, since the concept extraction had methodology used frequency, and the concept frequency in the queries was not necessarily tied to importance. However, this also meant that the same CUI(s) would be found from both the queries and the reports for a given text string.</p><p>The propagation configuration of this run was identical to that of mayolbrst. No type weights or section weights were used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">UIMA-based report-side concept extraction (mayoubr)</head><p>This run, mayoubr, differed from the other 3 in the means by which concepts were found in the reports. Report processing was carried out using Mayo Clinic's clinical Text Analysis and Knowledge Extraction System, cTAKES <ref type="bibr" coords="5,400.34,416.36,15.48,9.62" target="#b4">[5]</ref>. The query-side processing was manual, consistent with the baseline. This alternative report-processing pipeline was used out-ofthe-box, and no tuning was added for age, gender, special terms, or ICD-9 diagnostic codes. The propagation configuration of this run was again identical to that of mayolbrst. No type weights or section weights were used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Development Evaluation</head><p>During development, we evaluated which of our algorithms might be useful by performing case-insensitive string matching of terms from each query, and then examining the top N reports. We then counted the percentage of records that contained matches. This metric was averaged across queries for each of our submitted runs, yielding a % accuracy measure similar to P@N that tests our methods against unweighted string matching. It is a rough measure, since there is no test to ensure that all the conditions of the query are met. The accuracy for the top 10, 20, 50, and 100 reports are: The 4 runs were chosen based on the development evaluations. Preliminary results showed that expanding queries and reports based on ontologies and cooccurrences did not make a significant difference in the accuracy. This is not unexpected; extending the weights to related concepts would not necessarily increase the number of exact string matches (which were used to define the metric). The official results showed that this was not the case on a real relevance judgment task.</p><p>Other variations were tested, but unsubmitted for final runs. Using the developmental evaluation, we made a few additional observations. First, we varied the size of co-occurrence tables used. Recall that we stored to tables from which we calculated cooccurrence relationships; the smaller co-occurrence corpus surprisingly did not impact accuracy greatly. Additionally, we manually tested a few parameter settings for coefficient, decay, and cutoff in the propagation steps. The final configuration submitted in mayolbrst, mayolbra, and mayoubr performed the best on the development evaluation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>Official TREC results on the baseline and variants are as follows: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>It is evident that there was a significant effect of including the more sophisticated query expansion features. Interestingly, the automatic system receieved the best score on all metrics. This is especially interesting because our accuracy metric used for development did found the opposite result. This is likely due to the fact that when the query was processed with the same dictionary lookup algorithm as the reports, and the exact same CUIs were used for both, but this did not necessarily correspond to exact string matches in the development metric. It is also clear from comparing mayoubr to mayolbrst that what goes into the report processing makes a significant difference, though the fact that metadata was unused in mayoubr makes the result inconclusive for the UIMA-based concept extraction approaches in general. Future versions with cTAKES could increase in accuracy considerably.</p><p>It should be noted that these were in the "unjudged" competition, and a large proportion of the returned reports were therefore unjudged. Some of the metrics (especially P@10) are dominated by the fact that these were unjudged runs. In each of the 4 systems, less than 50% of the top 10 visits were judged. Thus, the reported values of P@10 were close to the lowest possible values (if all the unjudged visits turned out to be irrelevant). This metric is particularly susceptible to the lack of judged visits; indeed, a meta-analysis of all submitted TREC runs showed that the P@10 for our systems were abnormally low compared to others with similar bpref scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The TREC 2011 Medical Records track competition provided an opportunity to use the semanticallyoriented empirical ontologies for a practical information retrieval task, cohort identification. We obtained competitive results that illustrated the usefulness of advanced features like propagating weights between related concepts. Additionally, we found that the match between query-side and report-side algorithms had the most significant effect on performance.</p><p>Future work includes viewing the information retrieval task from a text-centric perspective without losing some of the gains that are possible from semantic reasoning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,90.68,220.54,430.35,9.62"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Block diagram for query expansion. Dotted line separates baseline and other techniques.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,82.90,326.24,445.90,9.62"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Block diagram for visit summarization. Dotted line separates baseline and other techniques.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,72.00,252.60,467.72,9.62;4,72.00,264.55,467.70,9.62;4,72.00,276.51,467.70,9.62;4,72.00,288.46,467.71,9.62;4,72.00,300.42,78.77,9.62"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Left: Hierarchically-arranged concepts with weights represented by circle sizes. 'x' denotes a missing concept. Right: Propagation of a concept ("colon structure") to hierarchically related concepts ("large intestine structure") and co-occurrence related concepts ("colonoscopy"). The red (shaded) circles indicate weights added by the propagation. The strength of co-occurrence relationships are shown as the size of red arrows.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,79.19,74.83,221.68,9.62;5,91.93,86.78,208.94,9.62;5,91.93,98.74,56.53,9.62;5,79.19,122.76,61.07,9.62;5,155.87,122.76,35.40,9.62;5,206.91,122.76,27.09,9.62;5,263.04,122.76,37.82,9.62;5,91.93,134.72,208.93,9.62;5,91.93,146.68,208.95,9.62;5,91.93,158.63,150.02,9.62;5,79.19,182.66,221.67,9.62;5,91.93,194.62,208.95,9.62;5,91.93,206.57,25.26,9.62"><head>2 .</head><label>2</label><figDesc>mayolbrst (Section 3.3.1): Includes the additional processing from the dotted boxes of Figures maual query weights with automatic weights from Aho-Corasick string matching on the text of the query. 4. mayoubr (Section 3.3.3): Uses cTAKES instead of Aho-Corasick for Dictionary Lookup on reports.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,326.34,578.77,213.38,9.62;6,326.34,590.73,213.37,9.62;6,326.34,602.68,210.34,9.62" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,352.04,590.73,154.83,9.62">The unified medical language system</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Lindberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">L</forename><surname>Humphreys</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Mc-Cray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,514.23,590.73,25.48,9.18;6,326.34,602.68,133.20,9.18">Methods of information in Medicine</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">281</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,326.34,622.48,213.37,9.62;6,326.34,634.43,213.35,9.62;6,326.34,646.38,213.34,9.62;6,326.34,658.34,91.99,9.62" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,471.49,622.48,68.22,9.62;6,326.34,634.43,213.35,9.62;6,326.34,646.38,139.43,9.62">Semantic Characteristics of NLP-extracted Concepts in Clinical Notes vs. Biomedical Literature</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hongfang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,490.06,646.38,49.62,9.18;6,326.34,658.34,61.37,9.18">Proceedings of AMIA 2011</title>
		<meeting>AMIA 2011</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,326.34,678.14,213.37,9.62;6,326.34,690.09,213.35,9.62;6,326.34,702.05,213.36,9.62;6,326.34,714.00,213.34,9.62;7,87.50,74.83,213.37,9.18;7,87.50,86.78,78.81,9.62" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,353.87,702.05,185.83,9.62;6,326.34,714.00,136.43,9.62">UMLS Term Occurrences in Clinical Notes: A Large-scale Corpus Analysis</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hongfang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dingcheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cui</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Musen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Chute</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nigam</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,490.06,714.00,49.62,9.18;7,87.50,74.83,213.37,9.18;7,87.50,86.78,48.41,9.18">Proceedings of the AMIA Joint Summit on Clinical Research Informatics</title>
		<meeting>the AMIA Joint Summit on Clinical Research Informatics</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,87.50,106.71,213.37,9.62;7,87.50,118.67,213.35,9.62;7,87.50,130.62,213.34,9.62;7,87.50,142.57,43.70,9.62" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,287.73,106.71,13.14,9.62;7,87.50,118.67,213.35,9.62;7,87.50,130.62,25.45,9.62">Efficient string matching: an aid to bibliographic search</title>
		<author>
			<persName coords=""><forename type="first">Alfred</forename><forename type="middle">V</forename><surname>Aho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Margaret</forename><forename type="middle">J</forename><surname>Corasick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,121.59,130.62,124.09,9.18">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="333" to="340" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,87.50,162.50,213.36,9.62;7,87.50,174.46,213.36,9.62;7,87.50,186.41,213.37,9.62;7,87.50,198.36,213.37,9.62;7,87.50,210.32,213.38,9.62;7,87.50,222.28,213.37,9.18;7,87.50,234.23,69.16,9.62" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,87.50,186.41,213.37,9.62;7,87.50,198.36,213.37,9.62;7,87.50,210.32,154.90,9.62">Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Savova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Masanz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">V</forename><surname>Ogren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">C</forename><surname>Kipper-Schuler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">G</forename><surname>Chute</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,254.88,210.32,46.00,9.18;7,87.50,222.28,208.98,9.18">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">507</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
