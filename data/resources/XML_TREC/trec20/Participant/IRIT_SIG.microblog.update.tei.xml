<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,193.19,87.86,219.93,12.93">IRIT at TREC Microblog 2011</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,128.14,125.06,95.13,9.96"><roleName>Lamjed</roleName><forename type="first">Firas</forename><surname>Damak</surname></persName>
							<email>damak@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">IRIT/SIG-RFI</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,226.61,125.06,48.23,9.96"><forename type="first">Ben</forename><surname>Jabeur</surname></persName>
							<email>jabeur@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">IRIT/SIG-RFI</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,282.82,125.06,83.55,9.96"><forename type="first">Guillaume</forename><surname>Cabanac</surname></persName>
							<email>cabanac@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">IRIT/SIG-RFI</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,374.76,125.06,98.76,9.96"><forename type="first">Karen</forename><surname>Pinel-Sauvagnat</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IRIT/SIG-RFI</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,213.62,137.01,60.96,9.96"><forename type="first">Lynda</forename><surname>Tamine</surname></persName>
							<email>tamine@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">IRIT/SIG-RFI</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,302.32,137.01,90.33,9.96"><forename type="first">Mohand</forename><surname>Boughanem</surname></persName>
							<email>boughanem@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">IRIT/SIG-RFI</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,193.19,87.86,219.93,12.93">IRIT at TREC Microblog 2011</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">920F56D0A7696F46001FCAE3A15EA700</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of the IRIT lab, university of Toulouse, France, to the Microblog Track of TREC 2011. Two different approaches were experimented by our team, which are described in the two main parts of the paper.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Microblogging consists in sharing short messages (microblogs) through a social network platform. Twitter, the most popular microblogging service to date, has experienced exponential growth in recent years. Launched in October 2006, Twitter's number of users has increased from 94,000 <ref type="bibr" coords="1,153.18,342.08,3.97,6.97" target="#b0">1</ref> in April 2007 to 200 millions in 2010 <ref type="bibr" coords="1,321.45,342.08,3.97,6.97" target="#b1">2</ref> . It takes now one week for users to send a billion of tweets <ref type="bibr" coords="1,179.14,354.03,3.97,6.97" target="#b2">3</ref> . Having this important microblogging activity, users are overwhelmed by the enormous quantity of new tweets and difficulty accessing to their interesting topics. A new retrieval task consisting on tweet search is therefore necessary. This task is triggered by social and timely motivations in addition to the topically motivations characterizing the traditional Web search. Users are searching over microblogs for short, concise and real-time information which is not already indexed by Web search engines.</p><p>Among the works having addressed tweet search task, we identify two categories of approaches. The first one considers various topically, microblogging and social indicators as input parameters for machine-learned ranking system, one can fo example cite the approach in [1]. The second category of model-based approaches defines relevance as a multidimensional component and represents the different relevance factors into an integrated model [2-4]. In this paper, we present two model-based approaches to rank tweets given a topic: the first approach use three factors to evaluate relevance. Each factor is computed through a set of feature scores. These factors are named content features, Twitter features and author features. The second approach proposes a Bayesian network model that integrates textual similarity, the influence of microblogger in the network and the time magnitude of the tweet.</p><p>The remainder of this paper is organized as follows: the first approach and relative results are described in section 2, while the second approach and relative results are given in section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Combining specific features for microblog search</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Method</head><p>TREC Microblog Track organizers defined external evidence as evidence outside the Tweets 2011 corpus. Future evidence are information that would not have been available to the system at the time the query was submited. They decided that runs created using external or future evidence will be ranked separately from runs that do not. Besides future evidence, we believe that a system using external evidence runs in strict real-time sense: concretely, there is no meaning for future evidence. Moreover, external resources are commonly used in IR. For this reason, we tried to avoid future evidences in our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Design of our approach</head><p>The first step in our approach is to index and retrieve the top-N relevant tweets for each topic using an usual plain-text search engine. The second step consists in processing these results to evaluate the feature scores (i.e., content, Twitter and author features). The final score is computed by combining the search engine score with the set of the feature scores. The top tweets are then sorted in a reverse chronological order. Before displaying results, we processed the resulting tweets with a language filter so as only those tweets written in English would be considered (see figure <ref type="figure" coords="2,211.92,260.47,3.87,9.96" target="#fig_0">1</ref>).</p><p>Our approach is designed to handle multiple search options: first of all, we had the choice between either indexing all the collection or making an index for each topic. The tweets indexed in the second case are only those published before the topic's timestamp. As we did not want to use future evidence, we only worked with this second version of index.</p><p>We also had the possibility to choose between using the topic as it was given by Track organizers, or adding keywords from our topic expansion module (formulate topic in the figure). Then, when calculating the score, we had the possibility to use only the search engine score, or to combine it with feature scores. Finally, we designed a set of refinement parameters:</p><p>-MIN: minimum score of the tweets to be displayed in the results.</p><p>-MT: the number of terms added to the topic.</p><p>-MN: supplies parameter (i.e., the number of results returned by the search engine that will be processed by the features module) since the feature processing of 1500 tweets took too much time on our platform (more than 30 min on a dual core machine at 2,8 GHz). We choose to use the Lucene platform 4 in our approach. This open source software is a highperformance, full-featured text search engine library written entirely in Java. In addition, it provides access to powerful term boosting, indexing and predefined searching features. The tokenizer was modified by organizers to preserve hashtags and mentions (i.e., words starting with the specific characters of Twitter: #,@). Nevertheless, they specified a field in the index for the HTTPSTATUSCODE of the tweets. The reason behind doing that is to be able to specify which type of tweets would be retrieved. Since it was announced that retweets will not be considered as relevant this year, we retained only the original tweets with HTTPSTATUSCODE equals to 200. Thus, we dropped out all other type of tweets (HTTPSTATUSCODE equals to 302, 403, and 404). However, we did not process the data to remove the implicit retweets (HTTPSTATUSCODE equals to 202 and starting with RT) since they could contain extra information. Besides using the configuration aforementioned, we used term-boosting for expanding topics with keywords. We exploited it to give more importance to the topic terms and to avoid losing the initial purpose of the topic.</p><p>In the rest of the paper, the relevance score obtained by the Lucene search engine for a tweet t and a query q is denoted by Lucene(t, q). The corpus of top-N relevant tweets obtained by the Lucene search engine regarding a topic q is denoted by T q . Finally, C q denotes the corpus of all tweets published before timestamp of a topic q. (T q ⊆ C q ). Finally, apart from indexing and retrieving, we used the Lucene search engine to calculate some feature scores. We address this in more details when explaining features in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Factor descriptions</head><p>In the context of microblog search, there is a set of new criteria of the new media that are imposed into the issue of retrieval. Relevance surely depends on which task the user is trying to complete. Considering that, it seems crucial to us to find and add new factors such as authority, quality, informativeness, temporality, and so on.</p><p>In our approach, we use three factors: the content factor, the Twitter factor and the author factor. Each factor is computed through a set of associated feature scores.</p><p>Content features. We used 3 content-specific features which are relative to some microblogs specificities: the wide variety of topics discussed by authors (1), the shortness of microblogs (2), and the wide variety of expressions used by authors (3).</p><p>-Tweet popularity: this feature estimates the popularity of a current tweet in T q . We made the assumption that a tweet is popular if we find the same content in many other tweets. The similarity between a pair of tweets is calculated using the Lucene content-based similarity sim(t i , t j ). We denote the current tweet by t i . The resulting formula to evaluate this feature is:</p><formula xml:id="formula_0" coords="3,241.07,537.70,263.32,26.06">f 1 (t i , q) = tj ∈Tq,i =j sim(t i , t j ) |T q | -1<label>(1)</label></formula><p>-Tweet length: instinctively, the lengthier a sentence is, the more information it contains. We calculate this feature by counting the number of words it contains. We denote l(t i ) as the number of words a tweet t i in T q contains. This feature is defined as:</p><formula xml:id="formula_1" coords="3,257.32,608.16,247.07,24.28">f 2 (t i , q) = l(t i ) max tj ∈Tq l(t j )<label>(2)</label></formula><p>-Exact term matching: this feature is used to promote tweets that contain terms of the topic q. nb(t i , q) denotes the number of times a term of the tweet t i exist in the topic q:</p><formula xml:id="formula_2" coords="3,249.16,667.55,255.24,23.94">f 3 (t i , q) = nb(t i , q) max tj ∈Tq nb(t j , q)<label>(3)</label></formula><p>Twitter features. We consider 3 additional Twitter-specific features that may indicate the quality of the information shared through tweets.</p><p>-URL presence: by sharing an URL, an author would confirm the information published in his/her tweet or draw the attention of his/her followers to contents on the web. Thus, we believe that it could indicate informativeness. It is a binary feature:</p><formula xml:id="formula_3" coords="4,238.44,164.14,265.95,21.91">f 4 (t i , q) = 1 if t i contains url 0 if not<label>(4)</label></formula><p>-URL frequency: this feature aims to calculate how popular the URLs published in a tweet in the corpus C q . f rq(url) denotes the number of time the url appear in the corpus C q .</p><formula xml:id="formula_4" coords="4,262.32,230.10,242.07,20.88">f 5 (t i ) = url∈ti f rq(url)<label>(5)</label></formula><p>-Hashtag: The # symbol, called a hashtag, is used to mark keyword or topic in a Tweet. Any Twitter user can categorize or follow topics with hashtags. It gives information to link tweets describing the same event or place to a group. f req(h) denotes the frequency of a hashtag in the corpus C q :</p><formula xml:id="formula_5" coords="4,265.58,318.41,238.81,20.87">f 6 (t i ) = h∈ti f rq(url)<label>(6)</label></formula><p>Author features. To include the authority of the tweet author in the score function, we consider two author-specific features:</p><p>-Number of tweets: The purpose of this feature is to promote tweets published by active authors compared to tweets published by someone less active. a(t i ) denotes the author of the tweet t i . N (a(t i )) is the number of tweets published by the author of the tweet t i in the corpus</p><formula xml:id="formula_6" coords="4,167.61,416.99,336.78,22.66">C q . f 7 (t i ) = N (a(t i ))<label>(7)</label></formula><p>-Mention: the more an author has been mentioned, the more popular he/she is.M (a(t i )) denotes how many time the author of the tweet t i has been mentioned in the corpus C q .</p><formula xml:id="formula_7" coords="4,273.75,477.74,230.64,10.70">f 8 (t i ) = M (a(t i )) (8)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.4">Formulate topics</head><p>Since microblogs are too short to express clearly their subjects, and queries are too simple to give the best representation of the information need, we found the idea of expanding topics a good solution to improve our chances of retrieving relevant tweets while containing different words from the topic. The idea is to extract keywords from news articles published before the timestamps of a given topic. To do that, we used two APIs in which we could specify the topic and time period of the articles to extract: NYTimes API <ref type="bibr" coords="4,310.57,595.23,3.97,6.97" target="#b4">5</ref> and Guardian API<ref type="foot" coords="4,403.13,595.23,3.97,6.97" target="#foot_2">6</ref> . Since the articles are chronologically retrieved by the APIs, for each topic we took the 2 first articles from each source to produce a mega-document [5]. Then we used the Alchemy API<ref type="foot" coords="4,413.41,619.15,3.97,6.97" target="#foot_3">7</ref> to extract the top-5 keywords. Alchemy API uses deep linguistic parsing, statistical natural language processing, and machine learning to analyze the content and extract semantic metadata.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.5">Scoring</head><p>Our scoring function is evaluated in two steps. The first step consists in evaluating the score of each feature (9) and the second step involves the computation of the final score (10). All the feature scores are normalized to lie between 0 and 1. We adopted a linear function for</p><formula xml:id="formula_8" coords="5,106.87,156.55,397.53,10.70">f eatures(t i , q) = f 1 (t i , q) + f 2 (t i , q) + f 3 (t i , q) + f 4 (t i ) + f 5 (t i ) + f 6 (t i ) + f 7 (t i ) + f 8 (t i ) (9)</formula><p>After normalizing the feature scores, the final score is calculated as: score(t i , q) = lucene(t i , q) + f eatures(t i , q)</p><p>(10)</p><p>with score(t i , q) ∈ [0, 2]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Results</head><p>We submitted 2 runs to TREC Microblog Track 2011: iritfd1 and iritfd2. The only difference between our two runs is that in iritfd1 we expanded topics with keywords from news articles, while in iritfd2 we did not. Thus, Run iritfd2 is thus without future or external evidence, contrary to run irifd1 that is with external but not future evidence. The same function (10) was used to evaluate the score of tweets in both runs.</p><p>To assess the contribution of the features used in our approach, we also created a post-hoc baseline run (iritfd0) where relevance is based only on scores obtained by the Lucene search engine.</p><p>For iritfd1 and iritfd2, we set our parameters as follows:</p><p>-MIN (minimum score of the tweets): 0.7; -T (the number of terms added to the topic in iritfd1): 5; -N (the number of results returned by the search engine that will be processed by the features module): 1,500.</p><p>For each topic, the system provides a chronologically ranked list of tweets (up to 1,000). The number of proposed topics was 50 but only 49 were judged. Two types of relevance judgments were calculated by organizers: allrel and highrel. The difference between them is that in highrel only the highly relevant tweets have been considered. Consequently, the number of topics in this case was only 33.</p><p>Table <ref type="table" coords="5,143.58,504.76,4.98,9.96" target="#tab_0">1</ref> summarizes our results. We present scores of MAP and P@30 for the both types of relevance judgements (i.e., allrel and highrel), the improvement of iritfd2 compared to iritfd0 (improvement iritfd2/iritfd0), and the improvement of iritfd1 compared to iritfd2 (improvement iritfd1/iritfd2).</p><p>We recall that iritfd2 uses features scores and thus can be directly compared with iritfd0 which did not, and that iritfd1 uses query expansion as well as features scores and thus can be directly compared to iritfd2.</p><p>Regarding the evaluation of iritfd0 and iritfd2, features clearly help to retrieve relevant tweets: the P@30 is improved by 90,49% and the MAP by 24,51% (difference statistically significant for the two cases).</p><p>Compared to iritfd2, The MAP of iritfd1 has improved by 10,20% in allrel and 19,29% in highrel. However we could not justify this improvement with the topic expansion since the difference between the two runs was not statistically significant (i.e., p &gt; 0.05 with a paired Students t-test). More experiments are needed to fully understand the effect of expansion. Note that the degradation of the P@30 in highrel judgments compared to allrel judgments is more important than the MAP degradation for the same considered judgments. This observation is valuable for the majority of the systems (the average of median P@30 is decreased from 0.2591 in allrel to 0.0686 in highrel). It could be explained by the fact that MAP is less sensitive to the number of relevant documents than the P@n.</p><p>Compared with the median across all runs submitted by any team, iritfd1 outperformed the P@30 for 27 out of 49 and the median AP for 38 out of 49 topics. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Discussion and future works</head><p>We proposed in this section an approach that combines a set of features to rank real time microblogs. The specificity of our work is that we calculate the tweet scores by keeping in mind 3 important factors which are content features, Twitter features, and author features. These factors were calculated by combining a set of features linearly. We also proposed a topic expansion approach. However, we could not conclude about its effectiveness. There is still a lot of room for improvement. We need to evaluate the influence of each feature independently. We will test the effect of the number of keywords added to the topic, which may be detected with a more suitable topic expansion approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A Bayesian network retrieval model for tweet search</head><p>We present in this section a second tweet search approach based on Bayesian networks that integrates several relevance features namely hashtags, tweet time magnitude, tweet length and the social influence of microbloggers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Tweet Search Model</head><p>We propose to model tweets using Bayesian networks. Such representation allows to model influenceable sources of evidence though conditional probabilities. We present in what follows the Bayesian network topology then we focus on query evaluation precess.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Network topology</head><p>The Bayesian network for tweet search is represented by a graph G = (X, E), where nodes X = Q ∪ K ∪ T ∪ U corresponds to the set of random variables and the set of edges E = X × X represents conditional dependencies between them. Q, K, T and U correspond respectively to the sets of queries, terms, tweets and microbloggers. -The query layer Q includes the query node q which is associated to a binary random variable q ∈ {0, 1}. The short representation of q = 1 is noted q and denotes "the query q is observed". Conversely, q = 0 is noted q and denotes "the query q is not observed". We notice that the same notation q is used to refer to the query, the associated random variable and the query node. The same notation is used for other nodes in the network. -The terms layer K includes nodes of terms present in the tweet index. A binary random variable k i ∈ {0, 1} is associated to each term k i . -The tweets layer T includes tweet nodes. A binary random variable t j ∈ {0, 1} is associated to each tweet t j . -The microbloggers layer U includes microblogger nodes. A binary random variable u k ∈ {0, 1} is associated to each microblogger u k .</p><p>Information edges. Each edge in the network express a conditional dependency between nodes. Edges connecting the query q ∈ Q with parent terms k i ∈ K represent the chance of generating the query from connected term. Each term k i is connected to parent tweets t j ∈ T that it indexes. Edges from tweets to terms express that the event of observing a particular tweet impacts the observation of the connected term. Finally, a tweet node t i ∈ is connected to a single parent node corresponding to the microblogger u k ∈ U having published t j . This edge shows that the event of observing a tweet t j depends on the observation event of the corresponding microblogger u k . To avoid cycles in the graph, we assume that tweets and microbloggers are mutually independent between each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query evaluation</head><p>The relevance of a tweet t j considering a query q is assimilated to the joint probability that both events t j = 1 and q = 1 appear. This probability is computed as:</p><formula xml:id="formula_9" coords="7,153.09,548.13,351.29,24.22">P (q ∧ t j ) = ∀k P (q|k)P (u k ) ∀i|on(i,k)=1 P (k i |t j ) × ∀i|on(i,k)=0 P ( ki |t j )<label>(11)</label></formula><p>k is a query parent configurations defined by a vector of random variables k</p><formula xml:id="formula_10" coords="7,101.89,581.40,402.52,46.25">= (k 1 , k 2 , ..., k m ), k i ∈ {0, 1}. Considering a query q = {k 1 , k 2 } composed of two terms k 1 and k 2 , the set of query parent configurations is represented by {(k 1 , k 2 ), (k 1 , k2 ), ( k1 , k 2 ), ( k1 , k2 )}. on(i, k) = 1 if k i = 1 according to the query configuration k and on(i, k) = 0 if k i = 0.</formula><p>Computing probability P (q|k). The probability P (q|k) of observing the query q having the configuration k helps to weight the different combinations of the query terms as follows:</p><formula xml:id="formula_11" coords="7,258.70,671.27,245.68,21.19">P (q|k) = ∀i on(i, k)<label>(12)</label></formula><p>Computing probability P (k i |t j ). The probability P (k i |t j ) of observing a term k i in the tweet t j depends, on the one hand, on the term's occurrence and on the other hand on the tweet properties. This probability is computed using the term frequency F (k i , t j ), the hashtag presence H (k i , t j ), the time magnitude T (k i , t j ) and the tweet length L(t j ):</p><formula xml:id="formula_12" coords="8,183.41,143.92,320.97,10.39">P (k i |t j ) = (1 -µ)F (k i , t j ) H (k i , t j ) + µ T (k i , t j ) L(t j )<label>(13)</label></formula><formula xml:id="formula_13" coords="8,253.33,158.92,251.05,13.02">P ( ki |t j ) = 1 -P (k i |t j )<label>(14)</label></formula><p>with µ ∈ [0..1] is a smoothing parameter.</p><p>-Term frequency F (k i , t j ) replaces the common tf measure with a graduated function F (k i , t j ) that map high frequencies into a small interval:</p><formula xml:id="formula_14" coords="8,217.78,222.91,286.60,28.43">F (k i , t j ) 1 -a tf k i ,t j , if k i is present in t j 0, otherwise<label>(15)</label></formula><p>with a ∈ [0..1] and tf ki,tj is the frequency of the term k i in the tweet t j . -Hashtag score H (k i , t j ) leverages the importance of hashtagged terms as follows:</p><formula xml:id="formula_15" coords="8,210.29,289.11,294.09,28.43">H (k i , t j ) 1 - b tf #k i ,t j , if #k i is present in t j b, otherwise<label>(16)</label></formula><p>b ∈ [0..0.5] is the default hashtag score. tf #ki,tj is the frequency of the hashtag #k i in t j . -Time magnitude T (k i , t j ) of tweet t j depends on its submission time. This probability would be more important when term k i is frequently used at tweet submission period. The time magnitude is estimated as follows:</p><formula xml:id="formula_16" coords="8,272.33,376.89,232.05,24.23">T (k i , t j ) = df ki,Γj |Γ j |<label>(17)</label></formula><p>Γ j = t k , |θ tjθ t k | ≤ ∆t is the set of temporal neighbors of t j within the 2∆t time window. df ki,Γj is the number of tweets in Γ j containing k i . -Tweet length L(t j ) score highlights tweets closer to the average tweets length avg tl . The tweet length score of a tweet t j with a length tl tj is computed as follows:</p><formula xml:id="formula_17" coords="8,257.36,460.27,247.03,24.50">L(t j ) = 1 1 + avg tl -tl tj<label>(18)</label></formula><p>Computing probability P (t j |u k ). The probability P (t j |u k ) of observing a tweet t j knowing the corresponding microblogger u k is computed as follows:</p><formula xml:id="formula_18" coords="8,266.70,521.83,237.69,24.62">P (t j |u k ) = 1 |T u k |<label>(19)</label></formula><p>T u k is the set of tweets published by the microblogger u k</p><p>Computing probability P (u k ). The probability P (u k ) is interpreted as the influence of microblogger u k on the retweet social network. This network is modeled by a graph G = (U, R) where U is the set of microbloggers having published at least one tweet that contains a query term and R = U × U denotes the set of retweet relationships. A retweet relationship (u i , u j ) ∈ R is defined from u i to u j if u i retweeted a tweet of u j . The influence of a microblogger u i is estimated by applying PageRank algorithm on the retweet network as follows:</p><formula xml:id="formula_19" coords="8,189.49,647.46,314.90,28.91">Inf p (u i ) = d |U | + (1 -d) uj ∈U,uj →ui w i,j Inf p-1 (u j ) O(u j )<label>(20)</label></formula><p>O(u j ) is the outdegree of node u j . d is the random walk parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Corpus indexing and tweet filtering</head><p>Tweets are indexed using NESTOR microblogging retrieval platform developed by our team. Indexing process separates URLS from tweet message and indexes only textual content. This system supports multi-language tokenisation and uses the Porter stemming algorithm for recognized English text. Moreover, the tweeting features such as retweets, mentions and hashtags are extracted and integrated as meta-data. Finally, conventional retweets starting with "RT @username" are detected and used in addition to Twitter native retweets. The retrieval process is conducted with respect to the requirements of the realtime adhoc task. In fact, posterior tweets to query time are discarded by applying a time constraint when extracting tweet from inverted-index. We note also that the social retweet network is built from posterior tweets and no future information is used in the query evaluation process. avg tl , Γ j and T (u k ) consider only posterior tweets to the query time. After computing relevance score P (q ∧ t j ), the tweet results is filtered as follows:</p><p>-We remove all retweets -We remove non English tweets expect mixed-language tweets where English is the principal language. Tweet language is detected using the text processing library MorphAdorner<ref type="foot" coords="9,498.35,285.00,3.97,6.97" target="#foot_4">8</ref> . -We remove tweet including less than |q| 2 terms. |q| is the query length. This helps to reduce noise in the final result set ranked by tweeting time.   Comparing overall results, the proposed model shows low performances compared to TREC median. However, we can draw some primary conclusion form obtained results. In comparison to the similar p@30 values shown by Nestor and Nestor-S models with tweet time ranking, we note a slight decline of Nestor-S, where social feature is disabled, compared to Nestor model in the case where tweets are ranked by score. We conclude that the social context impacts the tweet relevance. Moreover, we note through the decline of Nestor-T performances observed with score ranking, that the time feature can improve the retrieval effectiveness. However, opposite behavior observed with time ranking shows that the time magnitude may affect top list ranking with some irrelevant tweets. Finally, best p@30 values presented by Nestor-L allow to conclude that average tweet length is not an appropriate feature for tweet search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results and discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Conclusion and future work</head><p>We proposed in this work a tweet search model that integrates several features within a Bayesian network model namely the time magnitude, hashtags, tweet length and the social influence of microbloggers. Obtained results show that some features are useful for tweet search. Other ones show promising performances that need to be improved. In future work, we plan to conduct extended experiments analyzing the impact of each feature and also to model the temporal aspects of tweets within the Bayesian network.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,182.73,581.71,240.85,8.97;2,133.07,465.31,340.10,102.20"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. UML activity diagram summing up of our approach</figDesc><graphic coords="2,133.07,465.31,340.10,102.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,211.37,173.18,183.56,8.97"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The Bayesian network of tweet search</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="9,101.89,361.81,331.66,9.96;9,108.12,381.98,232.86,9.96;9,108.12,393.99,293.49,9.96;9,108.12,406.02,283.94,9.96;9,392.06,406.35,14.63,10.05;9,407.60,406.02,24.89,9.96;9,108.12,418.03,326.33,10.39;9,435.35,418.03,2.76,9.96;9,101.89,438.14,402.49,9.96;9,101.89,450.09,97.52,9.96"><head>Tables 2</head><label>2</label><figDesc>compares results obtained by different configurations of our model: -Nestor: Proposed model with all features included. -Nestor-S: Proposed model with social feature disabled P (u) = 1. -Nestor-T: Proposed model with temporal feature disabled T (k i , t j ) = 1. -Nestor-L: Proposed model with tweet length feature is disable L(u) = t j . Experiments are conducted with the next parameters values: µ = 0.25,a = 0.25, b = 0.4, ∆t = 1h and d = 0.15.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,266.40,484.89,30.33,8.97"><head>Ranked</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,101.89,175.11,402.51,109.87"><head>Table 1 .</head><label>1</label><figDesc>Summary of the results. * indicates a significant improvement (p ≤ 0.05 with a paired two-tailed Students t-test)</figDesc><table coords="6,136.22,175.11,333.87,79.72"><row><cell></cell><cell></cell><cell>allrel</cell><cell cols="2">highrel</cell></row><row><cell></cell><cell>P@30</cell><cell>MAP</cell><cell>P@30</cell><cell>MAP</cell></row><row><cell>Iritfd0(baseline)</cell><cell>0,1346</cell><cell>0,1558</cell><cell>0,041</cell><cell>0,1179</cell></row><row><cell>Iritfd2</cell><cell>0,2564</cell><cell>0,1940</cell><cell>0,0960</cell><cell>0,1622</cell></row><row><cell>Improvement iritfd2/iritfd0</cell><cell cols="4">90,49% * 24,51% * 134,14% * 37,57% *</cell></row><row><cell>iritfd1(topic expansion)</cell><cell>0,2605</cell><cell>0,2138</cell><cell>0,0970</cell><cell>0,1935</cell></row><row><cell>Improvement iritfd1/iritfd2</cell><cell>1,59%</cell><cell>10,20%</cell><cell>1.04%</cell><cell>19,29%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,145.92,484.89,314.46,119.88"><head>Table 2 .</head><label>2</label><figDesc>Comparison of model configurations. * Official run</figDesc><table coords="9,145.92,484.89,314.46,100.69"><row><cell></cell><cell></cell><cell></cell><cell>by time</cell><cell></cell><cell cols="2">Ranked by score</cell></row><row><cell></cell><cell cols="2">All rel</cell><cell cols="2">High rel</cell><cell cols="2">All rel</cell></row><row><cell></cell><cell>p@30</cell><cell>MAP</cell><cell>p@30</cell><cell>MAP</cell><cell>p@30</cell><cell>MAP</cell></row><row><cell>Nestor*</cell><cell>0.2027</cell><cell>0.1305</cell><cell>0.0838</cell><cell>0.1287</cell><cell>0.2218</cell><cell>0.1384</cell></row><row><cell>Nestor-S*</cell><cell>0.2027</cell><cell>0.1305</cell><cell>0.0838</cell><cell>0.1286</cell><cell>0.2184</cell><cell>0.1360</cell></row><row><cell>Nestor-T</cell><cell>0.2082</cell><cell>0.1343</cell><cell>0.0585</cell><cell>0.0912</cell><cell>0.1912</cell><cell>0.1196</cell></row><row><cell>Nestor-L</cell><cell>0.2048</cell><cell>0.1306</cell><cell>0.0565</cell><cell>0.0867</cell><cell>0.2293</cell><cell>0.1426</cell></row><row><cell>TREC median</cell><cell>0.2592</cell><cell>0.1433</cell><cell>0.2646</cell><cell>0.1381</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="2,111.85,685.00,142.39,8.97"><p>http://lucene.apache.org/java/docs</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="4,111.85,663.07,119.85,8.97"><p>http://developer.nytimes.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="4,111.85,674.04,172.06,8.97"><p>http://www.guardian.co.uk/open-platform</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3" coords="4,111.85,685.00,114.94,8.97"><p>http://www.alchemyapi.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4" coords="9,111.85,685.00,162.22,8.97"><p>http://morphadorner.northwestern.edu/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,105.47,339.24,398.93,8.97;10,114.04,350.21,390.37,8.97;10,114.04,361.17,390.37,8.97;10,114.04,372.12,109.26,8.97" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,425.68,339.24,78.72,8.97;10,114.04,350.21,118.59,8.97">An empirical study on learning to rank of tweets</title>
		<author>
			<persName coords=""><forename type="first">Yajuan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Long</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heung-Yeung</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,255.12,350.51,249.29,8.66;10,114.04,361.17,135.13,8.97">Proceedings of the 23rd International Conference on Computational Linguistics, COLING &apos;10</title>
		<meeting>the 23rd International Conference on Computational Linguistics, COLING &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="295" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.47,383.08,398.93,8.97;10,114.04,394.05,390.35,8.97;10,114.04,405.00,390.37,8.97;10,114.04,415.96,123.52,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,364.08,383.08,140.32,8.97;10,114.04,394.05,23.54,8.97">Ranking approaches for microblog search</title>
		<author>
			<persName coords=""><forename type="first">Rinkesh</forename><surname>Nagmoti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ankur</forename><surname>Teredesai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martine</forename><forename type="middle">De</forename><surname>Cock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,154.90,394.35,349.49,8.66;10,114.04,405.30,129.94,8.66;10,299.28,405.00,45.06,8.97">Proceedings of the 2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology</title>
		<meeting>the 2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">01</biblScope>
			<biblScope unit="page" from="153" to="157" />
		</imprint>
	</monogr>
	<note>WI-IAT &apos;10</note>
</biblStruct>

<biblStruct coords="10,105.47,426.92,398.93,8.97;10,114.04,437.88,390.36,8.97;10,114.04,448.84,341.95,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,443.33,426.92,61.07,8.97;10,114.04,437.88,114.91,8.97">Ranking mechanisms in twitter-like forums</title>
		<author>
			<persName coords=""><forename type="first">Anish</forename><surname>Das Sarma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Atish</forename><forename type="middle">Das</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sreenivas</forename><surname>Gollapudi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rina</forename><surname>Panigrahy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,249.80,438.18,254.59,8.66;10,114.04,448.84,143.50,8.97">Proceedings of the third ACM international conference on Web search and data mining, WSDM &apos;10</title>
		<meeting>the third ACM international conference on Web search and data mining, WSDM &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.47,459.80,398.94,8.97;10,114.04,470.75,390.36,8.97;10,114.04,481.71,205.80,8.97" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,276.88,459.80,223.60,8.97">A weighted multi-factor algorithm for microblog search</title>
		<author>
			<persName coords=""><forename type="first">Lulin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yi</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ning</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,126.58,470.75,346.46,8.97">Proceedings of the 7th international conference on Active media technology, AMT&apos;11</title>
		<meeting>the 7th international conference on Active media technology, AMT&apos;11<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="153" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.47,492.68,398.92,8.97;10,114.04,503.63,315.34,8.97" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,261.75,492.68,237.90,8.97">A new Effective Approach for Categorizing Web Documents</title>
		<author>
			<persName coords=""><forename type="first">Claus-Peter</forename><surname>Klas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Norbert</forename><surname>Fuhr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,125.56,503.93,251.75,8.66">Proceedings of the 22th BCS-IRSG Colloquium on IR Research</title>
		<meeting>the 22th BCS-IRSG Colloquium on IR Research</meeting>
		<imprint>
			<date type="published" when="2000-04">April 2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
