<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,105.47,71.79,386.60,12.90;1,142.01,87.73,313.52,12.90">LIA at TREC 2012 Web Track: Unsupervised Search Concepts Identification from General Sources of Information</title>
				<funder ref="#_TvHxmyZ">
					<orgName type="full">French Agency for Scientific Research (Agence Nationale de la Recherche)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,105.54,130.63,87.70,10.75"><forename type="first">Romain</forename><surname>Deveaud</surname></persName>
							<email>romain.deveaud@univ-avignon.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">LIA -University of Avignon</orgName>
								<address>
									<settlement>Avignon</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,264.15,130.63,69.24,10.75"><forename type="first">Eric</forename><surname>Sanjuan</surname></persName>
							<email>eric.sanjuan@univ-avignon.fr</email>
							<affiliation key="aff1">
								<orgName type="institution">LIA -University of Avignon</orgName>
								<address>
									<settlement>Avignon</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,413.52,130.63,69.27,10.75"><forename type="first">Patrice</forename><surname>Bellot</surname></persName>
							<email>patrice.bellot@lsis.org</email>
							<affiliation key="aff2">
								<orgName type="institution">LSIS -Aix-Marseille University</orgName>
								<address>
									<settlement>Marseille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,105.47,71.79,386.60,12.90;1,142.01,87.73,313.52,12.90">LIA at TREC 2012 Web Track: Unsupervised Search Concepts Identification from General Sources of Information</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9933329EF7605DA0FF7162A56F723F77</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we report the experiments we conducted for our participation to the TREC 2012 Web Track. We experimented a brand new system that models the latent concepts underlying a query. We use Latent Dirichlet Allocation (LDA), a generative probabilistic topic model, to exhibit highly-specific query-related topics from pseudo-relevant feedback documents. We define these topics as the latent concepts of the user query. Our approach automatically estimates the number of latent concepts as well as the needed amount of feedback documents, without any prior training step. These concepts are incorporated into the ranking function with the aim of promoting documents that refer to many different query-related thematics. We also explored the use of different types of sources of information for modeling the latent concepts. For this purpose, we use four general sources of information of various nature (web, news, encyclopedic) from which the feedback documents are extracted.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>When searching for a specific information, users query the retrieval system with a list of keywords, a question, a declarative sentence or maybe a long description of the search topic. However, this often does not fully describe the user information need, which may harm retrieval performance. One way to better outline the topic of the search without the help of the user is to enrich the query with additional information. Such query expansion techniques have shown to significantly improve the effectiveness of retrieval systems in many TREC tracks before.</p><p>The goal of the work presented in this paper is to accurately represent the underlying core concepts involved in a search process, hence indirectly improving the contextual information surrounding this search. For this purpose, we introduce an unsupervised framework that allows to track the implicit concepts related to a given query and improve document retrieval effectiveness by incorporating these concepts to the initial query. For each query, latent concepts are extracted from a reduced set of feedback documents initially retrieved by the system. These feedback documents can come from the target collection or from any other textual source of information.</p><p>The main strength of our approach is that it is entirely unsupervised and does not require any training step. The number of needed feedback documents as well as the optimal number of concepts are automatically estimated at query time. We emphasize that the algorithms have no prior information about these concepts. The method is also entirely independent of the source of information used for concept modeling. Queries are not labelled with topics or keywords and we do not manually fix any parameter at any time, except the number of words composing the concepts.</p><p>2 Query-Oriented LDA</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Latent Dirichlet Allocation</head><p>Latent Dirichlet Allocation is a generative probabilistic topic model <ref type="bibr" coords="1,394.42,715.22,74.87,9.46" target="#b3">(Blei et al., 2003)</ref>. The underlying intuition is that documents exhibit multiple topics, where a topic is a multinomial distribution over a fixed vocabulary W . The goal of LDA is thus to automatically discover the topics from a collection of documents. The documents of the collection are modeled as mixtures over K topics each of which is a multinomial distribution over W . Each topic multinomial distribution φ k is generated by a conjugate Dirichlet prior with parameter β, while each document multinomial distribution θ d is generated by a conjugate Dirichlet prior with parameter α. Thus, the topic proportions for document d are θ d , and the word distributions for topic k are φ k . In other words, θ d,k is the probability of topic k occurring in document d (i.e. P (k|d)). Respectively, φ k,w is the probability of word w belonging to topic k (i.e. P (w|k)). Exact LDA estimation was found to be intractable and several approximations have been developed <ref type="bibr" coords="2,268.45,269.90,21.82,9.46;2,72.00,283.45,51.58,9.46" target="#b3">(Blei et al., 2003;</ref><ref type="bibr" coords="2,126.35,283.45,124.18,9.46" target="#b8">Griffiths and Steyvers, 2004)</ref>. We use in this work the variational approximation algorithm implemented and distributed by Pr. Blei<ref type="foot" coords="2,272.75,308.51,3.99,6.91" target="#foot_0">1</ref> .</p><p>Each learned multinomial distribution φ k is traditionally presented as list of the top words with the higher probabilities for topic k. Topics can then be easily identified by their most representative words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Estimating the number of concepts</head><p>There can be a numerous amount of concepts underlying an information need. Latent Dirichlet Allocation allows to model the topic distribution of a given collection, but the number of topics is a fixed parameter. However we can not know in advance the number of concepts that are related to a given query. We propose a method that automatically estimates the number of latent concepts based on their word distributions.</p><p>Considering LDA's topics are constituted of the n words with highest probabilities, we define an argmax <ref type="bibr" coords="2,104.16,571.29,16.08,9.57">[n]</ref> operator which produces the top-n arguments that obtain the n largest values for a given function. Using this operator, we obtain the set W k of the n words that have the highest probabilities P (w|k) = φ k,w in topic k:</p><formula xml:id="formula_0" coords="2,129.77,651.78,102.01,17.66">W k = argmax w [n] φ k,w</formula><p>Latent Dirichlet Allocation needs a given number of topics in order to estimate topic and word distributions. Several approaches has been studied for automatically finding the right number of LDA's topics contained in a set of documents <ref type="bibr" coords="2,336.53,80.21,81.83,9.46" target="#b2">(Arun et al., 2010;</ref><ref type="bibr" coords="2,421.81,80.21,71.98,9.46" target="#b4">Cao et al., 2009)</ref>. Even though they differ at some point, they follow the same idea of computing similarities (or distances) between pairs of topics over several instances of the model, while varying the number of topics. It comes down to a clustering approach which delineates the different clusters. Here the clusters are the topics and the objective is to maximize the dissimilarity between topics. Iterations are done by varying the number of topics of the LDA model, then estimating again the Dirichlet distributions. The optimal amount of topics of a given collection is reached when the overall dissimilarity between topics achieves its maximum value.</p><p>We perform a simple heuristic that estimates the number of latent concepts of a user query by maximizing the information divergence D between all pairs (k i , k j ) of LDA's topics. The number of concepts K estimated by our method is given by the following formula:</p><formula xml:id="formula_1" coords="2,318.16,357.84,199.40,31.13">K = argmax K 1 K(K -1) (k i ,k j )∈T K D(k i ||k j )</formula><p>where K is the number of topics given as a parameter to LDA, and T K is the set of K topics. In other words, K is the number of topics for which LDA modeled the most scattered topics. The Kullback-Leibler divergence measures the information divergence between two probability distributions. It is used particularly by LDA in order to minimize topic variation between two expectationmaximization iterations <ref type="bibr" coords="2,414.52,509.83,76.62,9.46" target="#b3">(Blei et al., 2003)</ref>. It has also been widely used in a variety of fields to measure similarities (or dissimilarities) between word distributions <ref type="bibr" coords="2,364.54,550.48,98.98,9.46" target="#b0">(AlSumait et al., 2008)</ref>. Considering it is a non-symmetric measure we use the Jensen-Shannon divergence, which is the symmetric version of KL divergence, to avoid obvious problems when computing divergences between all pairs of topics:</p><formula xml:id="formula_2" coords="2,313.02,639.57,204.36,64.11">D(k i ||k j ) = 1 2 w∈W p(w|k i ) log p(w|k i ) p(w|k j ) + 1 2 w∈W p(w|k j ) log p(w|k j ) p(w|k i )</formula><p>The word probabilities for given topics are obtained from the multinomial distributions φ k .</p><p>Each word w of the vocabulary W has a probability of belonging to the topic k, which is expressed by p(w|k) = φ k,w . The final outcome is the optimal number of topics K and its associated topic model. The resulting T K,M set of topics is considered as the set of K latent concepts modeled from a set of M feedback documents. We will further refer to the T K,M set as a concept model.</p><p>The number of relevant documents can vary from one query to another, hence the number M of feedback documents used to model the latent concepts must also vary for each query. It is also highly dependent on the source of information from which the feedback documents are extracted. We propose in the following section a method for automatically choosing the right amount M of feedback documents based on concept models similarities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">How many feedback documents?</head><p>An obvious problem with pseudo-relevance feedback based approaches is that not-relevant documents can be included in the set of feedback documents. This problem is much more important with our approach since it could result with learned concepts that are not related to the initial query. We mainly tackle this difficulty by reducing the amount of feedback documents. Relevant documents concentration is higher in the top ranks of the list. Thus one simple way to reduce the probability of catching noisy feedback documents is to reduce their overall amount.</p><p>However an arbitrary number can not be fixed for all queries. Some information needs can be satisfied by only 2 or 3 documents, while others may require 15 or 20. Thus the choice of the feedback documents amount has to be automatic for each query. To this end, we compare the concept models generated from different amounts m of feedback documents. To avoid noise, we favor the concept models that contain concepts that are similar to others in other models. The underlying assumption is that all the feedback documents are essentially dealing with the same topics, no matter if they are 5 or 20. Concepts that are likely to appear in different models learned from various amounts of feedback documents are certainly related to query, while noisy concepts are not.</p><p>We estimate the similarity between two concept models by computing the similarities between all pairs of concepts of the two models. Considering that two concept models are generated based on different number of documents (i.e. different R Q collections), they do not share the same probabilistic space. Since their probability distribution are not comparable, computing their overall similarity can be done solely by taking the concepts word distributions into account. We treat the different concepts as bags of words and use a document frequency-based similarity measure:</p><formula xml:id="formula_3" coords="3,307.28,171.98,233.01,50.00">sim(T K,m , T K,n ) = k∈T K,m k ∈T K,n |k i ∩ k j | |k i | w∈W p(w|k)p(w|k ) log N df w</formula><p>where |k i ∩ k j | is the number of words the two concepts have in common, df w is the document frequency of w and N is the number of documents in the target collection. The initial purpose of this measure was to track novelty (i.e. minimize similarity) between two sentences <ref type="bibr" coords="3,487.99,305.22,37.56,9.46;3,307.28,318.77,52.55,9.46">(Metzler et al., 2005)</ref>, which is precisely our goal, except that we want to track redundancy (i.e. maximize similarity) while taking word probabilities inside the topics into account.</p><p>The final sum of similarities between each concept pairs produces an overall similarity score of the current concept model compared to all other models. Finally, the concept model that maximizes this overall similarity is considered as the best candidate for representing the implicit concepts of the query. In other words, we consider the top M feedback documents for modeling the concepts, where</p><formula xml:id="formula_4" coords="3,334.79,506.64,163.23,21.54">M = argmax m n sim(T K,m , T K,n )</formula><p>In other words, for each query, the concept model that is the most similar to all other learned concept models is considered as the final set of latent concepts related to the user query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Concept weighting</head><p>We previously detailed how we estimate the number of concepts and the number of feedback documents from which they are extracted. We face in this section the problem of appropriately weighting these concepts. User queries can be associated with a number of underlying concepts but these concepts do not have the same importance. For example, the previous method for selecting the right amount of feedback documents could still yield noisy concepts, and some concepts may also be barely rel-evant.Hence it is essential to emphasize appropriate concepts and to depreciate inappropriate ones. One effective way is to rank these concepts and weigh them accordingly: important concepts will be weighted higher, thus reflecting their importance.</p><p>Recent studies proposed different approaches to rank or score LDA topics <ref type="bibr" coords="4,189.55,161.59,100.72,9.46" target="#b1">(Alsumait et al., 2009;</ref><ref type="bibr" coords="4,72.00,175.14,96.02,9.46" target="#b12">Newman et al., 2010;</ref><ref type="bibr" coords="4,171.98,175.14,87.69,9.46" target="#b15">Wen and Lin, 2010)</ref>, however .</p><p>Finally, the score δ k of a concept k with respect to its overall coherence in the collection is given by:</p><formula xml:id="formula_5" coords="4,126.21,244.14,109.85,23.30">δ k = d∈R Q p(d|Q)p(k|d)</formula><p>where n is the number of words in each concept. The probability of a concept k appearing in document d is given by the multinomial distribution θ previously learned by LDA, hence p(k|d) = θ d,k . Each concept is weighted with respect to its coherence in the target collection, but the actual representation of the concept is still a bag of words. These words are the core components of the concepts and intrinsically do not have the same importance. The easier way of weighting them is to use their probability of belonging to a concept k which are learned by Latent Dirichlet Allocation and given by the multinomial distribution φ k . Probabilities are normalized across all words, the weight of word w in concept k is thus computed as follows:</p><formula xml:id="formula_6" coords="4,131.40,499.55,96.32,28.31">φk,w = φ k,w w ∈W k φ k,w</formula><p>Finally, a concept learned by our latent concept modeling approach is a set of weighted words representing a facet of the information need underlying a user query. The concept is itself weighted to reflect its relative importance with other concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Document ranking</head><p>The previous subsections were all about modeling consistent concepts from reliable documents and modeling their relative influence. Here we detail how these concepts can be integrated in a retrieval model in order to improve ad-hoc document ranking.</p><p>There are several ways of taking conceptual aspects into account when ranking documents. Here, the final score of a document d with respect to a given user query Q is determined by the linear combination of query word matches (standard retrieval) and latent concepts matches. It is formally written as follows:</p><formula xml:id="formula_7" coords="4,307.28,112.61,221.84,26.25">s(Q, d) = P (d|Q)+ k∈T K,M δk w∈W k φk,w •P (d|w)</formula><p>where T K,M is the concept model that holds the latent concepts of query Q (see Section 2.4) and δk is the normalized weight of concept k:</p><formula xml:id="formula_8" coords="4,372.12,197.55,84.49,28.11">δk = δ k k ∈T K,M δ k</formula><p>The P (d|Q) and P (d|w) probabilities are the likelihood of document d being observed given the initial query Q (respectively, word w). In this work we use a language modeling approach to retrieval <ref type="bibr" coords="4,359.79,291.96,122.78,9.46" target="#b9">(Lavrenko and Croft, 2001)</ref>, P (d|w) is thus the maximum likelihood estimate of word w in document d, computed using the language model of document d in the target collection C. Likewise, P (d|Q) is the basic language modeling retrieval model, also known as query likelihood, and can also be formally written as P (d|Q) = q∈Q P (d|q). We tackle the null probabilities problem with the standard Dirichlet smoothing since it is more convenient for keyword queries (as opposed to verbose queries) <ref type="bibr" coords="4,444.41,427.45,81.13,9.46;4,307.28,441.00,23.48,9.46" target="#b16">(Zhai and Lafferty, 2004)</ref>, which is the case here. We fix the Dirichlet prior parameter to 1500 and do not change it at any time during our experiments. However it is important to note that this model is generic, and that the word matching function could be entirely substituted by other state-of-the-art matching function (like BM25 <ref type="bibr" coords="4,420.38,522.30,105.16,9.46;4,307.28,535.85,25.45,9.46" target="#b13">(Robertson and Walker, 1994)</ref> or information-based models <ref type="bibr" coords="4,461.65,535.85,63.89,9.46;4,307.28,549.40,68.99,9.46" target="#b5">(Clinchant and Gaussier, 2010)</ref>) without changing the effects of our latent concept modeling approach on document ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">General Sources of Information</head><p>The approach described in the previous section requires a source of information from which the concepts could be extracted. This source of information can come from the target collection, like in traditional relevance feedback approaches, or from an external collection. In this work we use a set of different data sources that are large enough to deal with a broad range of topics. Then we can explore which effects does the nature, the size or the quality of the information source have over latent concept modeling. This set of data sources is composed of four general resources: Wikipedia as an encyclopedic source, the New York Times and GigaWord corpora as sources of news data and the category B of the ClueWeb09<ref type="foot" coords="5,155.31,118.82,3.99,6.91" target="#foot_1">2</ref> collection as a web source. The English GigaWord LDC corpus consists of 4,111,240 newswire articles collected from four distinct international sources including the New York Times <ref type="bibr" coords="5,129.38,175.06,105.15,9.46" target="#b7">(Graff and Cieri, 2003)</ref>. The New York Times LDC corpus contains 1,855,658 news articles published between <ref type="bibr" coords="5,192.03,202.16,21.82,9.46">1987</ref><ref type="bibr" coords="5,236.12,202.16,21.82,9.46">and 2007</ref><ref type="bibr" coords="5,99.94,215.71,23.48,9.46" target="#b14">(Sandhaus, 2008))</ref>. The Wikipedia collection is a recent dump from July 2011 of the online encyclopedia that contains 3,214,014 documents<ref type="foot" coords="5,250.37,240.76,3.99,6.91" target="#foot_2">3</ref> . We removed the spammed documents from the category B of the ClueWeb09 according to a standard list of spams for this collection<ref type="foot" coords="5,189.86,281.41,3.99,6.91" target="#foot_3">4</ref> . We followed authors recommendations <ref type="bibr" coords="5,153.28,297.00,101.67,9.46" target="#b6">(Cormack et al., 2011)</ref>  These four resources are heterogeneous in all possible ways. They vary in terms of vocabulary size, number of documents and, of course, type of information. We thus expect that latent concepts will be as diverse as the sources of information from which their are modeled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental setup</head><p>We used Indri<ref type="foot" coords="5,136.61,604.12,3.99,6.91" target="#foot_4">5</ref> for indexing and retrieval. The whole ClueWeb09 collection was stemmed during indexing with the well-known light Krovetz stemmer, and stopwords were removed using the standard english stoplist embedded within Indri. We also removed from our index all the documents that have a spam percentile lower than 70 according to Waterloo's list 4 . As seen in Section 2, concepts are composed of a fixed amount of weighted words For all our runs we fixed the number of words belonging to a given concept to n = 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Runs</head><p>We submitted four runs in which we explore the influence of the number of feedback documents used for concept modeling, the concept weights and combining the general sources of information.</p><p>lcm-web This is our reference run. It uses the complete concept modeling approach described in this paper, but the feedback documents from which the concepts are modeled are solely extracted from the Web source of information (see Section 3). lcm-web-noW This run is the same as above, except that we removed the concept weights (the δk s). The word weights (the φk s) are still present in the ranking function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>lcm-web-10p</head><p>This run is identical to lcm-web, except that we fix the number of feedback documents to M = 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>lcm-4res</head><p>This last run uses our concept modeling on the four general sources of information presented earlier. The concept models issued from the different sources are combined in the final document ranking function:</p><formula xml:id="formula_9" coords="5,313.84,503.88,205.14,46.27">s 4res (Q, d) = P (d|Q) + 1 |S| σ∈S k∈T K,M (σ) δk w∈W k φk,w • P (d|w)</formula><p>where S is the set of sources of information and T K,M (σ) is the concept model composed of K concepts modeled from M feedback documents which were extracted from a source σ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>We report in this section the results of our runs for both the Ad Hoc (Table <ref type="table" coords="5,437.03,661.02,4.54,9.46" target="#tab_2">2</ref>) and the diversity metrics (Table <ref type="table" coords="5,374.45,674.57,3.94,9.46" target="#tab_4">3</ref>). We also present the results of a standard competitive baseline, the Markov Random Field for IR <ref type="bibr" coords="5,386.63,701.67,113.15,9.46">(Metzler and Croft, 2005)</ref>, as a mean of comparison. We chose the Sequential Dependance Model instantiation of this model and set the various weights as recommended by the authors (λ T = 0.85, λ O = 0.1 and λ U = 0.05).</p><p>This baseline showed to be highly effective in previous TREC tracks, and especially in those involving web documents. For both  Although there is not much difference in averaged scores between our four runs, we see that lcm-4res achieves highly significant improvements over the MRF-IR baseline. More, the three other runs fail to retrieve any relevant document in the top 20 ranks (ERR@20 = nDCG@20 = 0) for 13 topics, while the lcm-4res approach only fails for 9 topics. It is however interesting to note that MRF-IR fails on the same topics as our Latent Concept Modeling (LCM) approaches. It may be an language modeling issue, and it may be interesting to compare with other participants that explored other retrieval models. The indexing of only non-spammed documents could also be an explanation and needs further exploration.</p><p>When looking at runs individually, fixing the number of feedback documents to 10 achieves better results on average than using an adaptive method. Despite improvements of lcm-web-10p over MRF-IR are less significant than lcm-web for nDCG@20, the gain in computation time seems to be worth fixing M .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>ERR-IA@20 α-nDCG@20 P-IA@20  As for the diversity, removing the concept weights seems to improve the results on average, however lcm-4res achieves again higher statistically significant improvements than the other runs. It also reduces the number of topic failures to only one compared to 4 for the other runs and 5 to MRF-IR.</p><p>Overall, the influence of concept weighting is rather low. When comparing results topic per topic between lcm-web and lcm-web-noW, we see no significant differences. This is certainly due to the fact that all the concepts refer to common thematics and share the same vocabulary. Plus, using a small amount of feedback documents leads to computing LDA in a reduced probabilistic space. Hence, some very important words w.r.t to the query are present in every concept, thus diminishing the effect and the interest of concept weighting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper detailed the run we submitted to the TREC 2012 Web track. Our approach was to model the latent concepts that are underlying an information need. The goal was to broaden the scope of the search and ultimately promoting retrieval diversity, without hurting topical relevance.</p><p>Official results suggest that our approach works quite well for both ad hoc and diversity metrics. The use of several sources of information (instead of sticking to the target collection) is found useful in this context.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,72.00,297.00,218.27,159.38"><head>Table 1 :</head><label>1</label><figDesc>and set the "spamminess" threshold parameter to 70. The resulting corpus is composed of 29,038,220 web pages. Information about the four general sources of information used in this work.</figDesc><table coords="5,74.11,364.84,214.05,53.79"><row><cell cols="3">Resource # documents # unique words</cell><cell># total words</cell></row><row><cell>NYT</cell><cell>1,855,658</cell><cell>1,086,233</cell><cell>1,378,897,246</cell></row><row><cell>Wiki</cell><cell>3,214,014</cell><cell>7,022,226</cell><cell>1,033,787,926</cell></row><row><cell>GW</cell><cell>4,111,240</cell><cell>1,288,389</cell><cell>1,397,727,483</cell></row><row><cell>Web</cell><cell>29,038,220</cell><cell cols="2">33,314,740 22,814,465,842</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,72.00,93.76,218.27,157.54"><head></head><label></label><figDesc>table of results, we use two sided paired wise t-test to determine statistically significant differences with MRF-IR ( * : p &lt; 0.1; * * : p &lt; 0.05; * * * : p &lt; 0.01).</figDesc><table coords="6,86.45,162.80,189.37,88.51"><row><cell>Run</cell><cell>ERR@20</cell><cell>nDCG@20</cell></row><row><cell>MRF-IR</cell><cell>0.1038</cell><cell>0.1041</cell></row><row><cell>lcm-web</cell><cell>0.1334  *  *</cell><cell>0.1306  *  *</cell></row><row><cell>lcm-web-noW</cell><cell>0.1352  *  *</cell><cell>0.1337  *</cell></row><row><cell>lcm-web-10p</cell><cell>0.1364  *  *  *</cell><cell>0.1339  *</cell></row><row><cell>lcm-4res</cell><cell>0.1428  *  *  *</cell><cell>0.1401  *  *  *</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,72.00,267.14,218.27,23.01"><head>Table 2 :</head><label>2</label><figDesc>Ad Hoc results for our four submitted runs.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,72.00,704.17,218.27,23.01"><head>Table 3 :</head><label>3</label><figDesc>Diversity results for our four submitted runs.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,88.14,748.01,182.91,8.03;2,72.00,757.97,27.40,6.31"><p>http://www.cs.princeton.edu/ ˜blei/ lda-c</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,88.14,695.46,156.01,6.31;5,72.00,705.42,53.80,6.31"><p>http://boston.lti.cs.cmu.edu/ clueweb09/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,88.14,716.30,182.91,6.31;5,72.00,726.26,48.42,6.31"><p>http://dumps.wikimedia.org/enwiki/ 20110722/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,88.14,737.13,182.91,8.03;5,72.00,747.10,75.32,6.31"><p>http://plg.uwaterloo.ca/ ˜gvcormac/ clueweb09spam/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,88.14,757.97,145.26,6.31"><p>http://www.lemurproject.org</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgments</head><p>This work was supported by the <rs type="funder">French Agency for Scientific Research (Agence Nationale de la Recherche)</rs> under <rs type="projectName">CAAS</rs> project (<rs type="grantNumber">ANR 2010 CORD 001 02</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_TvHxmyZ">
					<idno type="grant-number">ANR 2010 CORD 001 02</idno>
					<orgName type="project" subtype="full">CAAS</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,307.28,623.00,218.27,8.64;6,318.19,633.96,207.36,8.64;6,318.19,644.92,207.36,8.64;6,318.19,655.71,207.36,8.81;6,318.19,666.67,207.36,8.58;6,318.19,677.63,100.45,8.81" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,404.08,633.96,121.46,8.64;6,318.19,644.92,207.36,8.64;6,318.19,655.88,128.02,8.64">On-line LDA: Adaptive Topic Models for Mining Text Streams with Applications to Topic Detection and Tracking</title>
		<author>
			<persName coords=""><forename type="first">Loulwah</forename><surname>Alsumait</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Barbará</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlotta</forename><surname>Domeniconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,465.73,655.71,59.81,8.58;6,318.19,666.67,207.36,8.58;6,318.19,677.63,96.51,8.81">Proceedings of the 2008 Eighth IEEE International Conference on Data Mining, ICDM &apos;08</title>
		<meeting>the 2008 Eighth IEEE International Conference on Data Mining, ICDM &apos;08</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,307.28,701.69,218.26,8.64;6,318.19,712.64,207.36,8.64;6,318.19,723.43,207.36,8.81;6,318.19,734.39,207.36,8.58;6,318.19,745.35,207.35,8.81;6,318.19,756.48,45.38,8.64" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,449.30,712.64,76.24,8.64;6,318.19,723.60,147.61,8.64">Topic Significance Ranking of LDA Generative Models</title>
		<author>
			<persName coords=""><forename type="first">Loulwah</forename><surname>Alsumait</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Barbará</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Gentle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlotta</forename><surname>Domeniconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,489.48,723.43,36.06,8.58;6,318.19,734.39,207.36,8.58;6,318.19,745.35,207.35,8.81;6,318.19,756.48,41.44,8.64">Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases, ECML PKDD &apos;09</title>
		<meeting>the European Conference on Machine Learning and Knowledge Discovery in Databases, ECML PKDD &apos;09</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,67.28,218.27,8.64;7,82.91,78.24,207.36,8.64;7,82.91,89.20,207.36,8.64;7,82.91,99.99,207.36,8.81;7,82.91,110.95,207.36,8.81;7,82.91,121.91,143.24,8.58" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,208.14,78.24,82.13,8.64;7,82.91,89.20,207.36,8.64;7,82.91,100.16,106.82,8.64">On Finding the Natural Number of Topics with Latent Dirichlet Allocation: Some Observations</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Arun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Veni Madhavan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">Narasimha</forename><surname>Murthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,209.47,99.99,80.80,8.58;7,82.91,110.95,134.43,8.58">Advances in Knowledge Discovery and Data Mining</title>
		<title level="s" coord="7,82.91,121.91,139.13,8.58">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6118</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,140.89,218.27,8.64;7,82.91,151.68,207.36,8.81;7,82.91,162.64,111.95,8.81" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,111.15,151.85,107.76,8.64">Latent Dirichlet Allocation</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,228.79,151.68,61.48,8.58;7,82.91,162.64,97.65,8.58">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,181.63,218.27,8.64;7,82.91,192.59,207.36,8.64;7,82.91,203.38,207.36,8.81;7,82.91,214.51,32.37,8.64" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,174.34,192.59,115.94,8.64;7,82.91,203.55,125.26,8.64">A density-based method for adaptive LDA model selection</title>
		<author>
			<persName coords=""><forename type="first">Juan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tian</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jintao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sheng</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,221.26,203.38,64.41,8.58">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="7" to="9" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,233.33,174.82,8.64;7,267.85,233.33,22.42,8.64;7,82.91,244.12,207.36,8.81;7,82.91,255.08,207.36,8.58;7,82.91,266.03,207.36,8.58;7,82.91,276.99,83.05,8.81" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,82.91,244.29,165.32,8.64">Information-based models for ad hoc IR</title>
		<author>
			<persName coords=""><forename type="first">Stéphane</forename><surname>Clinchant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Gaussier</surname></persName>
		</author>
		<idno>SIGIR &apos;10</idno>
	</analytic>
	<monogr>
		<title level="m" coord="7,272.46,244.12,17.81,8.58;7,82.91,255.08,207.36,8.58;7,82.91,266.03,207.36,8.58;7,82.91,276.99,32.66,8.58">Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 33rd international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,295.98,218.27,8.64;7,82.91,306.94,207.36,8.64;7,82.91,317.73,207.36,8.81;7,82.91,328.69,28.35,8.58" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="7,110.90,306.94,179.37,8.64;7,82.91,317.90,127.12,8.64">Efficient and effective spam filtering and reranking for large web datasets</title>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Charles</forename><surname>Clarke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Information Retrieval</note>
</biblStruct>

<biblStruct coords="7,72.00,347.68,218.27,8.64;7,82.91,358.47,207.36,8.81;7,82.91,369.59,58.39,8.64" xml:id="b7">
	<analytic>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Cieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,243.78,347.68,46.50,8.64;7,82.91,358.47,202.85,8.81">English Gigaword. Philadelphia: Linguistic Data Consortium</title>
		<imprint>
			<date type="published" when="2003">2003. 2003T05</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,388.41,218.27,8.64;7,82.91,399.20,207.36,8.81;7,82.91,410.16,207.36,8.58;7,82.91,421.12,60.33,8.81" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,268.68,388.41,21.59,8.64;7,82.91,399.37,79.19,8.64">Finding scientific topics</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Steyvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,174.19,399.20,116.08,8.58;7,82.91,410.16,207.36,8.58;7,82.91,421.12,11.00,8.58">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">101</biblScope>
		</imprint>
	</monogr>
	<note>Suppl</note>
</biblStruct>

<biblStruct coords="7,72.00,440.11,218.27,8.64;7,82.91,450.90,207.36,8.81;7,82.91,461.86,207.36,8.58;7,82.91,472.82,207.36,8.81;7,82.91,483.94,35.42,8.64" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,249.27,440.11,41.00,8.64;7,82.91,451.07,91.22,8.64">Relevance based language models</title>
		<author>
			<persName coords=""><forename type="first">Victor</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<idno>SI- GIR &apos;01</idno>
	</analytic>
	<monogr>
		<title level="m" coord="7,194.62,450.90,95.64,8.58;7,82.91,461.86,207.36,8.58;7,82.91,472.82,189.35,8.58">Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 24th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,502.76,218.27,8.64;7,82.91,513.55,207.36,8.81;7,82.91,524.51,207.36,8.58;7,82.91,535.47,207.36,8.58;7,82.91,546.43,124.84,8.81" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,249.11,502.76,41.17,8.64;7,82.91,513.72,169.20,8.64">A Markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,272.45,513.55,17.81,8.58;7,82.91,524.51,207.36,8.58;7,82.91,535.47,207.36,8.58;7,82.91,546.43,120.90,8.81">Proceedings of the 28th annual international ACM SI-GIR conference on Research and development in information retrieval, SIGIR &apos;05</title>
		<meeting>the 28th annual international ACM SI-GIR conference on Research and development in information retrieval, SIGIR &apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,565.42,218.27,8.64;7,82.91,576.38,207.36,8.64;7,82.91,587.17,207.36,8.81;7,82.91,598.13,207.36,8.58;7,82.91,609.08,192.57,8.81" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,228.20,576.38,62.07,8.64;7,82.91,587.34,138.44,8.64">Similarity measures for tracking information flow</title>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yaniv</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alistair</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,240.91,587.17,49.35,8.58;7,82.91,598.13,207.36,8.58;7,82.91,609.08,188.62,8.81">Proceedings of the 14th ACM international conference on Information and knowledge management, CIKM &apos;05</title>
		<meeting>the 14th ACM international conference on Information and knowledge management, CIKM &apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,628.07,218.27,8.64;7,82.91,639.03,207.36,8.64;7,82.91,649.82,207.36,8.81;7,82.91,660.78,207.36,8.58;7,82.91,671.74,207.36,8.58;7,82.91,682.70,72.14,8.81" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,188.60,639.03,101.67,8.64;7,82.91,649.99,60.59,8.64">Automatic evaluation of topic coherence</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jey</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Han</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karl</forename><surname>Grieser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,161.83,649.82,128.44,8.58;7,82.91,660.78,207.36,8.58;7,82.91,671.74,207.36,8.58;7,82.91,682.70,68.20,8.81">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT &apos;10</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,701.69,218.27,8.64;7,82.91,712.64,207.36,8.64;7,82.91,723.43,207.36,8.81;7,82.91,734.39,207.36,8.58;7,82.91,745.35,207.36,8.58;7,82.91,756.31,83.05,8.81" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,237.37,701.69,52.90,8.64;7,82.91,712.64,207.36,8.64;7,82.91,723.60,124.90,8.64">Some simple effective approximations to the 2-Poisson model for probabilistic weighted retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,229.72,723.43,60.55,8.58;7,82.91,734.39,207.36,8.58;7,82.91,745.35,207.36,8.58;7,82.91,756.31,79.11,8.81">Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;94</title>
		<meeting>the 17th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;94</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,307.28,67.28,218.27,8.64;7,318.19,78.07,207.36,8.81;7,318.19,89.03,93.82,8.81" xml:id="b14">
	<analytic>
		<author>
			<persName coords=""><forename type="first">Evan</forename><surname>Sandhaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,407.97,67.28,117.58,8.64;7,318.19,78.07,207.36,8.81;7,318.19,89.03,28.82,8.58">The New York Times Annotated Corpus. Philadelphia: Linguistic Data Consortium</title>
		<imprint>
			<date type="published" when="2008">2008. 2008T19</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,307.28,109.12,218.27,8.64;7,318.19,119.91,207.36,8.81;7,318.19,130.87,203.30,8.81" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,467.48,109.12,58.06,8.64;7,318.19,120.08,76.70,8.64">Towards Finding Valuable Topics</title>
		<author>
			<persName coords=""><forename type="first">Zhen</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ching-Yung</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,413.14,119.91,112.41,8.58;7,318.19,130.87,199.36,8.81">Proceedings of the SIAM International Conference on Data Mining, SDM &apos;10</title>
		<meeting>the SIAM International Conference on Data Mining, SDM &apos;10</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,307.28,150.97,218.27,8.64;7,318.19,161.93,207.36,8.64;7,318.19,172.72,207.36,8.81;7,318.19,183.68,90.76,8.81" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,483.03,150.97,42.52,8.64;7,318.19,161.93,207.36,8.64;7,318.19,172.89,82.11,8.64">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,410.29,172.72,115.26,8.58;7,318.19,183.68,59.94,8.58">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
