<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,101.90,77.54,408.01,19.76">Query-Structure Based Web Page Indexing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,151.94,112.82,114.36,12.99"><forename type="first">Falah</forename><forename type="middle">H</forename><surname>Al-Akashi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">University of Ottawa Ottawa</orgName>
								<address>
									<postCode>K1N6N5</postCode>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,346.51,112.82,82.44,12.99"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">University of Ottawa Ottawa</orgName>
								<address>
									<postCode>K1N6N5</postCode>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,101.90,77.54,408.01,19.76">Query-Structure Based Web Page Indexing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8920869A69882146AE4BD9C621572F51</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Indexing is a crucial technique for dealing with the massive amount of data present on the web.</p><p>In our third participation in the web track at TREC 2012, we explore the idea of building an efficient query-based indexing system over Web page collection.</p><p>Our prototype explores the trends in user queries and consequently indexes texts using particular attributes available in the documents. This paper provides an in-depth description of our approach for indexing web documents efficiently; that is, topics available in the web documents are discovered with the assistance of knowledge available in Wikipedia. The welldefined articles in Wikipedia are shown to be valuable as a training set when indexing Webpages. Our complex index structure also records information from titles and urls, and pays attention to web domains.</p><p>Our approach is designed to close the gaps in our approaches from the previous two years, for some queries. Our framework is able to efficiently index the 50 million pages available in the subset B of the ClueWeb09 collection. Our preliminary experiments on the TREC 2012 testing queries showed that our indexing scheme is robust and efficient for both indexing and retrieving relevant web pages, for both the ad-hoc and diversity task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The rapid growth and massive quantities of data on the Internet have increased the importance and complexity of information retrieval systems. The amount and the diversity of the web data introduce shortcomings in the way search engines rank their results.</p><p>In this work, we propose to push search engine behaviour in a new direction, away from link analysis and toward actual content and topic analysis of web pages. Typically, the current</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>approach of content-based indexing does not scale well for phrasal queries, because the positions of the words need to be recorded, requiring a lot of storage space. On another hand, indexing without considering word location for proximity search causes two documents to seem similar if they have some words in common even when they are on different in topics. Term frequency is important for determining the topic of the documents; but this is not case for all document configurations, because documents may contain different topics located on different parts.</p><p>In order to experiment with a new intelligent search model for the web, we evaluate our algorithm by using the queries/topics made available by NIST in 2012, as part of TREC web search track. The advantage of using these queries is that NIST made available expected solutions, called relevance judgments, consisting of lists of documents that are relevant answers to each query; therefore we can evaluate our proposed model. In TREC 2012, we focused on two tasks: the classic text retrieval task called adhoc retrieval, and the diversity task.</p><p>The rest of our paper describes each component in our system. Section 2 describes our indexing approach. Section 3 describes the query processing steps. Section 4 describes query expansion. Section 5 explains the experimental results for our run. Finally, section 6 closes this paper with our conclusion regarding this approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">OUR APPROACH</head><p>Indexing is crucial for the task of finding relevant information on the Web. Various indexing methods are used in a wide range of applications, such as Home-page finding, Entity finding, and Web pages classification. The design of highly-scalable indexing algorithms is needed, especially with an estimate of one billion pages currently accessible on the web. Previous work classifies indexing of web documents in two types: word-based and phrase-based indexing <ref type="bibr" coords="2,509.85,538.95,12.87,10.80" target="#b5">[6]</ref>.</p><p>In our entry in TREC 2012, we built an index that handles phrases and concepts with different length using two references: Wikipedia articles and the Million Query Track 1 data. Our index is structured as a core distributed search files. It uses sub-trees of a fixed length; each internal node has one leaf that contains documents relevant to that node. The depth from the root to each leaf corresponds to the word or phrase which is two nodes for each word or phrase (we use the first term from each phrase for labelling the first level in the index; whereas the remaining terms are used for labelling the second level). The subsequent nodes from the root to the leaves map all index words or phrases. Each leaf in the index holds all indexed documents regarding a particular topic, and the path name from the root to each leaf corresponds to a possible query terms. Since our index from last year's system could not find relevant results for some queries, we addressed this drawback in this model.</p><p>We used a pool of five index classes. The index nodes in each class use a regular name instead of the coding names that we used in previous versions of our system. Each class contains a particular type of indexed data, as listed and shown in the figure <ref type="figure" coords="3,391.11,223.66,32.69,10.80">below:</ref> 1-Wiki: index class that holds all Wikipedia documents. 2-Domains: index class that holds all domain names; as well as all their titles and urls.</p><p>3-Title: index class that holds all documents that we indexed using phrases from their titles. 4-Words Combination Index: index class such that the nodes are labeled with keywords selected from urls and titles; the content of nodes holds vectors of significant terms. Figure <ref type="figure" coords="3,125.76,417.99,6.00,10.80" target="#fig_1">1</ref> shows the architecture of our system. In the following sections, we will describe each index class in more details. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Wikipedia Repository Index</head><p>Wikipedia contains approximately 5 million articles in English. The data in each article is structured into several fields, and sometimes it has a relationship with other articles using tags or links to expand a certain topic. Each document has a unique vocabulary name and identifier; each article has multi-faceted vocabulary terms to describe the same article's content. To efficiently index Wikipedia documents, we used three equivalent methods for grouping and indexing similar articles, in terms of reducing the index size and the time required for indexing and searching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Using Common Tags (Vocabularies)</head><p>Each document in Wikipedia has a unique vocabulary name and identifier. Sometimes, Wikipedia articles use different vocabulary terms to describe the same article. This means that some articles are repeated many times with different vocabulary names and the TREC identifiers used in the ClueWeb data. All similar articles must be grouped and bounded together in a cluster of similar articles. To accomplish this, our system scanned through the content of each article and gathered all the significant tags and vocabulary terms (those that were in bold fonts). Each article name is used for creating and titling the index node; whereas the significant tags are stored together in the content node. Overall, during the scanning all Wikipedia documents, documents that share the same tags must share the same contents. Thus, the content of any node in the index aggregates all the similar articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Using Terms' Impact</head><p>Not all Wikipedia articles are real articles. In our investigation, there are 50% of articles categorized as short; they contain only a few words. Also, some topics are covered more comprehensively than others. We propose to use term impact again rather than a term frequency.</p><p>We investigate new ways to compute term impact, as explained later on. After computing the weights/impact value for each term in the documents, the terms with high weights are selected to be representative to their documents. We used a strict cut-off (threshold) value of impact in the range of <ref type="bibr" coords="4,115.78,646.62,40.64,10.80">[2.5-5.5]</ref>. The candidate terms are built and used to label the index nodes (if they were not built previously), while the document identifiers are stored in the content of corresponding nodes. Therefore, each node in the index could store a cluster of documents that imply equal or close terms impact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Using the CRC-Dictionary</head><p>To save time for indexing and to reduce the size of the index, we used a checksum algorithm (CRC16) to group the documents that have high similarity (they are redundant). We also avoided repeating the computation of term frequency in similar documents. To do so, the system scanned through each document's content in the Wikipedia corpus and computed the CRC16 for the header paragraph. We selected the header paragraphs, because some articles have little changes in other paragraphs. The generated CRC16 values were used for represent the keys of a dictionary D (a hash table), whereas the values of the keys contain all the document identifiers (TREC identifiers). Overall, during the scanning all Wikipedia documents, documents that share the same contents must share the same CRC values. Thus, the content of any key in the dictionary aggregates all the similar articles. Finally, the dictionary D was transferred to the index pool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Home Pages Indexing</head><p>We used two complementary methods for indexing the Home Pages. The first method stores the indexed data at a high level stage in the index, whilst the second method stores the indexed data at a low level stage in the index. Both results are combined together in the class of home pages located in the index pool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Using Domain Names</head><p>Our system indexed all domain names and created a new class in the index pool for each home page. Each node in the index's class is named by the domain's name; additionally, all urls that belong to each site are stored as vectors in that node. Our system is built to index nodes from the domain names regardless of the type of extension. The contents of the nodes contain the documents' ids and their urls. However, we assigned a different ranked value for each extension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Using Wikipedia External Links</head><p>Wikipedia is often a good reference for most homepages. The external links in the Wikipedia repository are used for the homepage finding task and potentially work better than searching in anchor texts of web pages [14]. Our system scanned the content of each article and indexed the home page from the external link section. In general, Wikipedia writers used different terms for introducing a home page, i.e. "website", "homepage", "official", etc. To tackle this situation, we used regular expressions for extracting the home pages from Wikipedia documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Document Titles Index</head><p>We notices that phrases in the titles are often connected together by using conjunction words, i.e., "or" , "and" , "at" , "in" , "on" , "by" , "with" , "from" , or "for"; or punctuation characters, i.e., ":" , "|" , "(" , ")" , "-" , "," , or "&amp;". Thus, segmenting the titles of documents into phrases is essential to know the most important key-phrases that the document content focuses on. We used these characters and words for partitioning the titles into list of terms and phrases.</p><p>On the other side, not all these terms or phrases have equal impact in their document's content. To compute the impact of the extracted terms and phrases, our system computed the cosine similarity between a vector that represented each item (term or phrase) and a vector that represented the document's content. Finally, the extracted items were used for creating and labeling the nodes in the index class; whilst the contents of nodes include: the TREC identifiers, and the impact values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Terms Combination Index</head><p>Usually, queries refer to terms that are available in different positions in documents; for instance some terms are located in the urls; whereas the remaining terms are located in the content. A combination index class, however, focuses on this type of query.</p><p>To build the class, first, the frequency of each term in the documents collection was computed. Second, the three terms that were the most frequent in each document were selected.</p><p>Finally, for each keyword in the url and title of document, the index node was created and named as the name of that keyword; whereas the content of node held the three terms that most frequent.</p><p>An example for the link "http://www.opm.gov/oca/pay/HTML/02maxgs2.asp , the most frequent terms in this document's content are: "GS", "pay", and "rate"; the terms "opm", "oca", and "pay" extracted from the URL; and the terms "MAXIMUM", "GENERAL", "SCHEDULE", and "LIMITATIONS" extracted from the title were used for creating the index nodes. The content of each node holds a list of the most frequent terms ("GS", "pay", and "rate"), in addition to the document identifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Topical Dictionary-Based Index</head><p>Our final technique for building the phrasal index aims at detecting the main topics of documents. It is composed by three mutual hash tables, such that each hash table has a unique and specific topic. All hash tables are built on-the-fly before mapping them to the physical storage. We used two phases during the creating of this index:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head> Phase 1 -Document-topic investigation</head><p>The first step in this phase is investigating the most important topic in the document. We used three hash tables that work cooperatively. The topics of documents were turned out from the title of Wikipedia articles and from the list of queries available in the file "Million Query Track" 2 .</p><p>After scanning through the Web documents, each document was assigned to a particular topic. Thus, each node contains a set of documents that involved the same topic; as shown here as an example:["angular cheilitis", {document-1, url | .... |document-n,url}]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head> Phase 2 -Computing Topics' Weights</head><p>Usually, if a site focuses on a topic "civil right movement", all documents that belong to that site probably contain the phrase "civil right movement". As a consequence, the content of such index node should contain most documents that belong to that site. In this section, we will focus on computing the two impacting factors, in the document and in the site (domain), for computing the documents topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Document-Topic Weighting</head><p>This step checks the phrase distribution in the documents contents using an online "HTTP request" 3 . If the phrase is available in the correct distribution, the weight of document is computed using the cosine similarity between two vectors, the first vector represents the phrase in each node and the second vector represents the document's content. The result is stored in the memory as: [Document #, url, phrase-id, score].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Site-Topic Weighting</head><p>We applied a top-down traversal algorithm 4 for computing the weights of the sub-trees in each site. To make the content of the index nodes optimal for the number of documents, our system used an automatic cut-off value. The cut-off value is changeable and relies on the number of documents in each sub-tree; this means the value is low if the sub-tree holds a few numbers of indexed documents (children) and vice versa; however, the sub-trees that have little contributions are cut off from their parents. If the index node contains a large number of documents, the cut-off starts at 1 and grows up whenever the number of remaining documents in the final list is higher than 200. We chose a threshold of 200 to keep a balance between the precision and recall values. However, the remaining tree is compressed and bounded to a new tree.</p><p>After reducing the size of the tree, the total weight of each document is recomputed by using the following formula:</p><formula xml:id="formula_0" coords="8,108.02,327.13,334.30,10.80">Rank (D) = (Site-Topic Weighting * Document-Topic Weighting)/100</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">QUERY PROCESSING</head><p>Query processing is an essential step for any search engine. The query processor is the portion of server that accepts, parses, and executes the query syntax. A query processor has the following duties:</p><p> Query goals (detecting the type of query).  Distribute the queries over indexes.  Query execution.  Query optimization (query expansion and normalization).</p><p>In our experiments, we categorized queries into four types (each type processed by specific index classes):</p><p> Title: this means that relevant pages contain all the query terms in core positions, as full key-phrases, e.g.., "Ron Howard" or "Sore Throat".</p><p>• Domain: this means that relevant documents are located in a particular site or domain, e.g., "University of Phoenix" or "Churchill Downs".</p><p>• Occurrence: this means that relevant documents are weighted using the occurrence of query terms in documents content, e.g., "Fibromyalgia" or "Lipoma".</p><p>• Combining: this type of query is processed using primitive keywords from urls and/or titles that imply important weights in the documents content, e.g., "gs pay rate" or "brooks brother's clearance".</p><p>The first step of the query processor is looking for the query in the cached results available in the index repository. If such result is not available, the query will be forwarded to a pertinent index class. The forwarding relies on the class priority. Our system uses the following priorities for detecting the pertinent index class for each type of query:</p><p>• If the query length is one word, searching will occur in the home-page index and the dictionary-based index, because one word queries often refer to the home pages, e.g., "arkansas", or refer to the terms that are most frequent in document's contents, regardless the documents are home pages or not, e.g., "grilling".</p><p>• If the query length is two words or more, searching will occur in four index classes: o The home-page index class (domain name), e.g., the queries "churchill downs", "quit smoking", and "newyork hotels". The pre-processing removes the spaces before searching, i.e., www.churchilldowns.com, "www.newyorkhotel.com", or inserts dashes, i.e., "www.quit-smoking.com" or "www.newyork-hotel.com", respectively. A simple form of stemming is used, too. The home-page index class (Wikipedia external links) holds the home pages for other queries, too, e.g., "california franchise tax board".</p><p>o The term-combination-index class, e.g., a query like "becoming a paralegal". o The title-based index class, e.g., "old coins" in "www.ancientcoins.ca", or a query like "gs pay rate" in "www.gspay.com"; in which the term "rate" was extracted from the content; or it refers to the site www.opm.gov/oca/pay/; in which the terms "gs" and "rate" were processed from the content. Another example, for the query "brooks brothers clearance", refers to the site "brooksbrothers.com"; the term "clearance" was processed in the content.</p><p>o The dictionary-based index class, e.g., query like "black history", "septic system design", "dogs clean up bags" or "furniture for small spaces".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">QUERY EXPANSION</head><p>The previous section introduced a wide range of phrasal indexing mechanisms and established that phrasal indexing has the potential to improve retrieval effectiveness. Now we focus on query expansion, User's feedback is utilized implicitly by computing the behaviour of some users who adapted the preferences in the dynamic properties of Wikipedia collection. We used two algorithms for query expansion: the shared-links and the manner of titling similar articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Using Shared-Links</head><p>Wikipedia articles could expand the current articles to other articles by using shared links.</p><p>Usually, the target articles also point backward to the source articles. We assume that if an article (A) has a link that points to an article (B), and the article (B) has a link that points backward to the article (A), the two articles A and B are related. Therefore, our system gathered all links for each article and built a hash-table in which the articles names represent the keys of table and the gathered links are stored in the content of subsequent keys.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Using Titling Variation Aspect</head><p>As we mentioned earlier, Wikipedia articles often use term variants. Some similar articles have different titles, and these variants should be used to expand queries that match any title of article. For example, an article "lipoma" is titled by Wikipedia writers as: "fatty tumor", "fatty lipoma", "lypoma", "lipom at ousneoplasm", "lipomas", and "lipomatosis". These variations are gathered by our system during the indexing of the Wikipedia articles; that is, each title in the Wikipedia is a key in the dictionary, whilst the other titles were stored in the content of that key.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTAL RESULTS</head><p>We submitted the results of our model for two tasks, the adhoc and the diversity tasks of the web track. For some queries, our precision was zero because many documents retrieved for those queries were ranked as spam in the TREC relevance judgments. The spam detection for the TREC collection was done automatically by using the University of Waterloo IR system <ref type="bibr" coords="10,516.99,642.66,18.51,10.80" target="#b11">[12]</ref>.</p><p>We believe that some of the documents that are ranked as spam in the TREC collection are not really spam.</p><p>We present our results in comparison to the best results over all the 48 runs submitted by all the participants for the test queries (50). Despite the fact that we participated in TREC using only the subset B of the very large web collection, we compare with all the submissions. TREC uses general criterion for making comparison based on ERR values for all participants, regardless if the group used the subset A or B. The tables 1 and 2 below show our position in the top 8 runs in TREC 2012, according to the track`s overview paper <ref type="bibr" coords="11,400.51,178.18,18.55,10.80" target="#b12">[13]</ref>. If comparing only with the systems that used the subset B, we obtained the best results. If comparing with all systems, we were in the third position for the ad-hoc task and in second position for the diversity task.</p><p>Figure <ref type="figure" coords="11,106.21,240.37,6.00,10.80" target="#fig_1">1</ref> shows more details for the results of our system. Table <ref type="table" coords="11,125.78,427.11,4.67,10.80">1</ref>: Top adhoc task results ordered by ERR@20 for the best runs over 48 runs <ref type="bibr" coords="11,496.42,427.11,20.08,10.80" target="#b12">[13]</ref> Table <ref type="table" coords="11,110.66,608.94,4.67,10.80">2</ref>: Top diversity task results ordered by ERR-IA@20 for the best runs over 48 runs <ref type="bibr" coords="11,511.42,608.94,20.10,10.80" target="#b12">[13]</ref> Figure <ref type="figure" coords="12,164.66,358.09,4.67,10.80">2</ref>: Web Track 2012 diversity and adhoc summary results for our system</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>This paper described our system for the TREC 2012 web track. We explained how the query volume and phrase index can efficiently support the finding of relevant results with low disk overhead. Our method used our own custom indexing and ranking model based on topics identification in the documents' content through the investigation of query structures. This model provides a variety of analytic capabilities, including: phrase extraction, concept correlation, Web page topic finding, topics classification, documents grouping, and document/site weighting. This method is more sophisticated than our previous methods and more robust for processing all types of queries. We addressed some drawbacks of our methods from 2010 and 2011; for example, we kept the stop words in the key-phrase index. This allowed us to successfully process queries that contain stopwords, such as "becoming a paralegal" or "furniture for small spaces", by breaking him into phrases and giving them equal weights since they have the same importance in the query.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,90.02,351.85,449.71,10.80;3,90.02,372.49,449.69,10.80;3,90.02,393.25,225.40,10.80"><head>5 -</head><label>5</label><figDesc>Topical Index: index class that holds all other documents except Wikipedia pages and homepages. The documents in this class are indexed based on our collective phrases selected from Wikipedia and One Million Query Track.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,185.93,665.46,240.08,10.80;3,121.20,460.57,369.56,191.15"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The Architecture of Our Index Structure</figDesc><graphic coords="3,121.20,460.57,369.56,191.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="11,72.00,278.98,468.00,135.00"><head></head><label></label><figDesc></figDesc><graphic coords="11,72.00,278.98,468.00,135.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="11,72.00,465.73,468.00,133.50"><head></head><label></label><figDesc></figDesc><graphic coords="11,72.00,465.73,468.00,133.50" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,77.54,698.23,178.91,9.96"><p>http://trec.nist.gov/data/million.query.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1" coords="7,75.26,698.23,291.71,9.96"><p>http://msdn.microsoft.com/en-us/library/system.web.httprequest.aspx</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2" coords="8,75.26,698.23,225.56,9.96"><p>http://www.cs.umd.edu/~hjs/pubs/SametPAMI85b.pdf</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="13,93.26,104.38,446.79,10.92;13,93.38,118.30,178.40,10.80" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="13,159.17,104.38,189.94,10.91">An Inverted Index Generator for CINDI</title>
		<author>
			<persName coords=""><forename type="first">Hodong</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Computer Science, Concordia University, Canada</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s Thesis</note>
</biblStruct>

<biblStruct coords="13,92.54,132.10,447.50,10.80;13,93.38,145.90,378.12,10.80" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="13,319.79,132.10,173.78,10.80">Zeeker: A topic-based search engine</title>
		<author>
			<persName coords=""><forename type="first">Magnus</forename><surname>Sigurðsson Søren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Halling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Master of Science in Engineering, the Technical University of Denmark (DTU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="13,95.78,159.70,443.82,10.80;13,93.38,173.50,446.49,10.80;13,93.38,187.30,215.49,10.80" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,292.68,159.70,222.29,10.80">Compaction techniques for nextword indexes</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bahle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,93.38,173.50,446.49,10.80;13,93.38,187.30,25.80,10.80">Proc. 8th International Symposium on String Processing and Information Retrieval (SPIRE 2001)</title>
		<meeting>8th International Symposium on String essing and Information Retrieval (SPIRE 2001)<address><addrLine>San Rafael, Chile</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="33" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,94.46,201.10,445.54,10.80;13,93.38,214.90,446.70,10.80;13,93.38,228.70,382.28,10.80" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,321.03,201.10,218.98,10.80;13,93.38,214.90,25.10,10.80">Efficient Phrase Querying with an Auxiliary Index</title>
		<author>
			<persName coords=""><forename type="first">Dirk</forename><surname>Bahle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugh</forename><forename type="middle">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,232.01,228.70,178.18,10.80">The 28th European Conference on IR</title>
		<meeting><address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001. 2006</date>
		</imprint>
		<respStmt>
			<orgName>School of Computer Science and Information Technology, RMIT University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="13,93.59,242.53,446.12,10.80;13,93.38,256.33,433.74,10.80" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="13,303.56,242.53,236.15,10.80;13,93.38,256.33,25.10,10.80">Efficient Phrase Querying with Common Phrase Index</title>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chung</forename><surname>Keung Poon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer -Verlag</publisher>
			<pubPlace>China</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,93.26,270.01,446.79,10.92;13,93.38,283.93,178.40,10.80" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="13,159.16,270.01,189.94,10.91">An Inverted Index Generator for CINDI</title>
		<author>
			<persName coords=""><forename type="first">Hodong</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Computer Science, Concordia University, Canada</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s Thesis</note>
</biblStruct>

<biblStruct coords="13,91.68,297.73,448.40,10.80;13,93.38,311.41,446.50,10.91;13,93.38,325.33,446.36,10.80;13,93.38,339.13,122.19,10.80" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,100.22,311.41,206.16,10.91">ICTNET at Web Track 2011 Ad-hoc Task</title>
		<author>
			<persName coords=""><surname>Xu Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianguo</forename><surname>Zeyingpeng</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yue</forename><surname>Xiaomingyu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xueqi</forename><surname>Hongboxu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,321.23,311.41,170.30,10.91">Institute of Computing Technology</title>
		<meeting><address><addrLine>Beijing; Beijing, TREC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Chinese Academy of Sciences</note>
</biblStruct>

<biblStruct coords="13,92.42,352.93,447.48,10.80;13,93.38,366.73,446.76,10.80;13,93.38,380.53,235.25,10.80" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,334.15,352.93,205.75,10.80;13,93.38,366.73,33.04,10.80">Query-independent evidence in home page finding</title>
		<author>
			<persName coords=""><forename type="first">Trystan</forename><surname>Upstill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Hawking</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,409.90,366.73,130.25,10.80;13,93.38,380.53,100.19,10.80">CSIRO Mathematical and Information Sciences</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Canberra, Australia; Canberra, Australia</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Australian National University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="13,93.38,394.21,446.73,10.92;13,93.38,408.03,342.56,10.92" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,443.16,394.21,96.95,10.92;13,93.38,408.03,64.97,10.91">Purely-based Topic Classification</title>
		<author>
			<persName coords=""><forename type="first">Eda</forename><surname>Baykan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Monika</forename><surname>Henzinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ludmila</forename><surname>Marian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ingmar</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,170.66,408.15,229.82,10.80">18th International World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,95.28,421.95,444.68,10.80;13,93.38,435.75,446.70,10.80;13,93.38,449.55,148.71,10.80" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,446.80,421.95,93.16,10.80;13,93.38,435.75,115.13,10.80">Exploring URL Hit Priors for Web Search</title>
		<author>
			<persName coords=""><forename type="first">Ruihua</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shuming</forename><surname>Guomaoxin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ji-Rong</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei-Ying</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,441.10,435.75,98.99,10.80;13,93.38,449.55,83.25,10.80">The 28th European Conference on IR</title>
		<meeting><address><addrLine>Beijing China</addrLine></address></meeting>
		<imprint>
			<publisher>Microsoft Research Asia</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,98.18,463.35,441.81,10.80;13,93.38,477.15,432.12,10.80" xml:id="b10">
	<analytic>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kaptein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koolen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,283.25,463.35,256.74,10.80;13,93.38,477.15,172.98,10.80">Result Diversity and Entity Ranking Experiments: Anchors, Links, Text and Wikipedia</title>
		<meeting><address><addrLine>University of Amsterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,96.84,490.95,443.32,10.80;13,93.38,504.75,387.50,10.80" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="13,315.79,490.95,224.37,10.80;13,93.38,504.75,143.24,10.80">Efficient and effective spam filtering and reranking for large web datasets</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clarke</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1004.5168</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>University of Waterloo</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="13,95.06,518.55,441.35,10.80;13,94.58,532.35,199.47,10.80" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,398.75,518.55,137.66,10.80;13,94.58,532.35,51.22,10.80">Overview of the TREC 2012 Web Track</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="13,159.02,532.35,100.31,10.80">TREC working notes</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
