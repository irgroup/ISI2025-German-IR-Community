<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,133.36,114.94,345.69,15.12">IRIT at TREC 2012 Contextual Suggestion Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,198.91,148.65,69.08,10.68"><forename type="first">Gilles</forename><surname>Hubert</surname></persName>
							<email>gilles.hubert@univ-tlse3.fr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">UMR 5505</orgName>
								<orgName type="institution" key="instit1">University of Toulouse</orgName>
								<orgName type="institution" key="instit2">IRIT</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,312.20,148.65,100.89,10.68"><forename type="first">Guillaume</forename><surname>Cabanac</surname></persName>
							<email>guillaume.cabanac@univ-tlse3.fr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">UMR 5505</orgName>
								<orgName type="institution" key="instit1">University of Toulouse</orgName>
								<orgName type="institution" key="instit2">IRIT</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,133.36,114.94,345.69,15.12">IRIT at TREC 2012 Contextual Suggestion Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8E2A945AB3EA5BFF4C1757541FD6B61A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we give an overview of the participation of the IRIT lab, University of Toulouse, France, in the TREC 2012 Contextual Suggestion Track. We present our personalized contextual retrieval framework, an approach for context processing, and two approaches for user preference processing. The official evaluations of our two submitted runs are reported and compared to the four baselines defined for the track. Evaluation results show that one of our submitted run was ranked 1 st among the 27 runs of the 14 participants for the two official evaluation measures of the track.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In TREC 2012, the Contextual Suggestion Track was run for the first time. The track goal was to investigate search techniques considering context elements such as the user's location, weather, and time, as well as considering user interests via personal preferences and past history, for example. The original aspect of this new track is to tackle simultaneously two issues: 1) searching places according to a given spatial and temporal context and 2) personalizing search results according to user interests.</p><p>This track was an opportunity for us to extend previous works on user profiles [BHM02, HM07], geographic information retrieval [PCSH10a, PCSH10b, PSC + 12], and information retrieval <ref type="bibr" coords="1,504.37,480.37,37.15,9.63" target="#b5">[Hub05,</ref><ref type="bibr" coords="1,72.00,493.92,29.29,9.63" target="#b3">HM09]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Personalized Contextual Retrieval Framework</head><p>Our retrieval framework is based on a modular architecture as illustrated in Figure <ref type="figure" coords="1,454.48,552.64,4.16,9.63" target="#fig_0">1</ref>. It combines two modules: the first module is dedicated to context processing while the second module is dedicated to preference processing, i.e., to result personalization according to user interests.</p><p>The goal of the Contextual Suggestion Track 2012 was to recommend interesting places and activities from the open web. Rather than building an ad hoc web search engine we decided to establish our framework on the Google Places (https://developers.google.com/places) search engine. This choice is motivated by the fact that the Google Places API retrieves a list of places matching any query with geographic coordinates and searched place types. In addition, we defined several processes to process 1) the input data available to the track and 2) the data returned by the external search engines that we relied on. These processes are related to:</p><p>• The definition of queries submitted to the Google Places search engine from the contexts given for the track and the "accepted place types."</p><p>• The definition of search result descriptions; our framework uses the Bing (http://www.bing. com) and Google (http://www.google.com) search engines to collect snippets. These helped to build descriptions about the places returned by the Google Places search engine.</p><p>• The modeling of user preferences from the examples and profiles given for the track.</p><p>• The personalization of search results according to user preferences. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Context Processing</head><p>Since our retrieval framework relies on the Google Places API to get a set of places matching a given context, our module for context processing mainly consists in defining a query suited to this external search engine and corresponding to the context. Among the different tags constituting the contexts proposed in the track, we used the following ones: lat (i.e., latitude), long (i.e., longitude), day, time, and season. Geographic coordinates were directly processed by the Google Places API. We defined different sets of place types based on the list of place types accepted by the Google Places API. These place sets were defined intuitively to match the different combinations of temporal parts of the contexts of the track. The different place sets that we came up to were:</p><p>• PS 1: amusement park, aquarium, art gallery, bar, book store, bowling alley, cafe, movie theater, museum, park, restaurant, shopping mall, zoo.</p><p>• PS 2: aquarium, art gallery, bar, book store, bowling alley, cafe, movie theater, museum, park, restaurant, shopping mall.</p><p>• PS 3: bar, cafe, grocery or supermarket.</p><p>• PS 4: bar, cafe, restaurant, shopping mall.</p><p>• PS 5: bowling alley, cafe, casino, movie theater, night club, park, restaurant.</p><p>• PS 6: bowling alley, cafe, casino, movie theater, night club, restaurant.</p><p>For each context C, a place set was selected depending on the season, the day, and the time given. The association between each triple (season, time, day) and a place type set was achieved manually, as reported in Table <ref type="table" coords="3,221.52,102.54,4.24,9.63" target="#tab_0">1</ref>. Due to a limitation in the Google Places API output to 60 results per query, we split each query into 3 subqueries (i.e., 3 place type subsets with the same geographic coordinates) to retrieve more results (i.e., 3 × 60). The results returned for the three subqueries were then merged into a single result list. Considering the requirements of the track, we selected only results comprising a website URL to build each list of results corresponding to each context. The result list was then enriched with descriptions of results. For each result, we constituted a description by searching for and merging snippets from Bing (or Google when Bing failed to retrieve any result) based on its website URL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Preference Processing</head><p>In our framework, user preferences were processed after searching for the results according to contextual elements (cf. section 3). The list of results L obtained for any context C was personalized for each profile P of the TREC Contextual Suggestion Track.</p><p>Tying up with principles of content-based filtering <ref type="bibr" coords="3,327.57,461.17,32.44,9.63" target="#b0">[BC92]</ref> we built user preferences from ratings on the examples provided by the track (i.e., the track profiles) and the example contents. User preferences were classified into positive preferences and negative preferences <ref type="bibr" coords="3,438.05,488.27,44.71,9.63" target="#b4">[HMIH00]</ref>.</p><p>Ratings on example suggestions defining the track profiles were classified into initial ratings (i.e., based on the title and description of each example suggestion only) and final ratings (i.e., based on the content of the page and linked pages). For this year's participation, we considered positive ratings to build positive preferences and negative ratings to build negative preferences. To compare positive and negative preferences to contextual results we constructed compatible representations relying on the Vector Space Model <ref type="bibr" coords="3,312.82,569.56,31.40,9.63" target="#b9">[Sal79]</ref> widely used in information retrieval (IR). Based on previous works in IR <ref type="bibr" coords="3,225.11,583.11,37.38,9.63" target="#b5">[Hub05,</ref><ref type="bibr" coords="3,266.22,583.11,32.18,9.63" target="#b3">HM09]</ref> we performed an indexing process of profiles and contextual results by removing stopwords and keeping representative terms without stemming. We then computed a similarity score between each result vector and each preference vector based on the cosine measure.</p><p>We defined two approaches to build and use positive and negative preferences:</p><p>1. The coarse-grained approach consisted in defining positive and negative global preferences.</p><p>For each user profile, the positively rated example suggestions were indexed and merged to constitute a unique vector of terms representing the positive preferences of each user. In the same way, negatively rated suggestions were indexed and merged to constitute a unique vector of terms representing the negative preferences of each user. For each user profile P and each result r in L, the similarity score was then computed as follows:</p><formula xml:id="formula_0" coords="4,127.79,97.47,412.21,13.18">score cg (P, r) = cosine(P ref + (P ), r) -cosine(P ref -(P ), r), score ∈ [-1, 1]<label>(1)</label></formula><p>This method intended to promote the results most similar to global positive preferences and most dissimilar to global negative preferences.</p><p>2. The fine-grained approach consisted in defining positive and negative preferences as sets of positive and negative preference examples. For each user profile, the positively rated example suggestions were indexed to constitute a set of term vectors representing the positive preferences of each user (E + ). In the same way, negatively rated suggestions were indexed to constitute a set of term vectors representing the negative preferences of each user (E -). For each user profile P and each result r, the similarity score was then computed as follows:</p><formula xml:id="formula_1" coords="4,101.46,245.23,438.54,19.41">score f g (P, r) = max l∈E + (cosine(P ref + l (P ), r))-max m∈E - (cosine(P ref - m (P ), r)), score ∈ [-1, 1] (2)</formula><p>This method intended to promote the results most similar to one positive example and most dissimilar to one negative example.</p><p>Results were then ordered by decreasing order of scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Runs and Evaluation Results</head><p>We discuss in this section the features as well as the official evaluations of the two runs that we submitted to the TREC 2012 Contextual Suggestion Track and the features of the four baselines created by the organizers of the track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Submitted Runs</head><p>For this year's participation to the TREC Contextual Suggestion Track we submitted two runs labeled iritSplit3CPv1 and iritSplit3CPv2 based on both context and preference processing. We applied the following same principles for both runs:</p><p>• According to the submission guidelines, we selected the top 50 results from the result lists returned by our framework to populate the run.</p><p>• For this first participation, positive preferences were based on examples with initial and final ratings equal to 1, considering only examples of great interest for the users with regards to either their description or page contents. We indexed only description parts without considering the content of the page and linked pages. In a similar way, negative preferences were based on examples with initial and final ratings equal to -1.</p><p>The two runs differed from the approach applied for preference processing (cf. section 4):</p><p>• The first run iritSplit3CPv1 applied the coarse-grained approach of preference processing that uses global positive and negative user preferences.</p><p>• The second run iritSplit3CPv2 applied the fine-grained approach of preference processing that uses positive and negative preferences as sets of positive and negative preference examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Baselines</head><p>Four baselines were defined by the organizers of the track as follows:</p><p>• The baseline waterloo12a consisted of the top 50 attractions given by tripadvisor.com for the city of each context. This baseline took into account the geographical aspect only, thus ignoring the user profiles and temporal aspect of information needs.</p><p>• The baseline waterloo12b also consisted of the top 50 attractions given by tripadvisor.com. Contrary to waterloo12a it used the site's search tool with search terms manually generated based on the sample suggestions with a high rating in the user's profile.</p><p>• The baseline baselineA was output from the Google Places API. Each context was split into day, time, and location. The suggestions were taken from the top-rated results of the union of query results covering the context and sorted by Google's own ratings. This baseline did not rely on the use of user profiles.</p><p>• The baseline baselineB was created the same way as baselineA but suggestions were restricted to pubs, restaurants, and cafes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results</head><p>The evaluation results according to the P@5 measure over profiles and contexts for the different dimensions (i.e., W: Website, G: Geographical, T: Temporal, and D: Description) and combinations (i.e., WGT and GT) of these two runs and the four baselines are reported in Table <ref type="table" coords="5,470.69,354.71,4.24,9.63" target="#tab_1">2</ref>.  <ref type="table" coords="5,185.90,536.34,4.33,9.63" target="#tab_1">2</ref>, baselineA is a strong baseline for the official P@5 WGT measure (it is higher than the other baselines). Our runs outperformed this strong baseline and therefore all the four baselines. Our iritSplit3CPv1 run particularly yielded better results than the strong baseline according to all the dimensions and dimension combinations. In particular, it was largely higher (+81.33 %) than the strong baseline according to the official P@5 WGT measure as showed in Table <ref type="table" coords="5,101.54,604.09,4.23,9.63" target="#tab_2">3</ref>. This comparison is interesting since iritSplit3CPv1 and baselineA used the same external search engine. It shows that the modules we defined for context processing to result personalization provided a material improvement in effectiveness.</p><p>The evaluation results according to the MRR measure over profiles and contexts for the different dimensions and their combinations of these two runs and the four baselines are reported in Table <ref type="table" coords="5,533.63,658.29,4.17,9.63">4</ref>.</p><p>According to Table <ref type="table" coords="5,184.76,671.84,4.29,9.63">4</ref>, baselineB serves as strong baseline for the official MRR WGT measure, instead of baselineA. Our iritSplit3CPv1 run outperformed this strong baseline according to all the dimensions and dimension combinations, except for the temporal dimension. In particular, this run yielded greater effectiveness (+33.42 %) compared to the strong baseline according to the  <ref type="table" coords="6,297.58,330.04,4.16,9.63" target="#tab_3">5</ref>. Once again it is worth noting that iritSplit3CPv1 and baselineB used the same external search engine, which gives credit to our context processing and result personalization. In contrast, our second run (iritSplit3CPv2 ) yielded poorer evaluation results, except for the website dimension. On the one hand, evaluations reported in Table <ref type="table" coords="6,312.17,486.59,5.35,9.63" target="#tab_1">2</ref> and Table <ref type="table" coords="6,370.15,486.59,5.35,9.63">4</ref> show that our runs (iritSplit3CPv1 and iritSplit3CPv2 ) yielded better evaluations for the Geographical and Temporal dimensions than for the Website and Description dimensions. The poorer results for the Description dimension could be explained by the raw fusion of snippets that we applied to create suggestion descriptions.</p><p>On the other hand, evaluations show that iritSplit3CPv1 overcomes iritSplit3CPv2 regarding all the dimensions and dimension combinations. The superiority of iritSplit3CPv1 is particularly visible with regards to the Website and Description dimensions and the WGT combination (i.e., combination of the Website, Geographical, and Temporal dimensions). These results show that our coarse-grained approach returned more suitable suggestions than our fine-grained approach for preference processing. An explanation for that could be that the fine-grained approach alloted too much importance to two extreme examples only (i.e., the best matching positive example and the best matching negative example) leaving other examples aside.</p><p>In addition, our two runs obtained promising results compared to the statistics over the 27 submitted runs. iritSplit3CPv1 was ranked 1 st according to the two official measures (i.e., P@5 WGT and MRR WGT). iritSplit3CPv2 was ranked 14 th according to P@5 WGT and 12 th according to MRR WGT. Moreover, according to the WGT combination, iritSplit3CPv1 was greater or equal to the Median for 34/35 judged contexts over profiles and 8 times the best run. It was also greater or equal to the Median for 17/19 judged profiles over contexts and 6 times the best run. iritSplit3CPv2 was greater or equal to the Median for 30/35 judged contexts over profiles and 4 times the best run. It was also greater or equal to the Median for 15/19 judged profiles over contexts and 2 times the best run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>This paper introduced our personalized contextual framework based on a modular architecture combining two modules. A first module is dedicated to context processing. A second module is dedicated to result personalization according to user interests. This year's participation to the TREC Contextual Suggestion Track led to encouraging results since one of our submitted runs was ranked 1 st according to the two official evaluation measures. We checked that the effectiveness of our approach does not only depend on the data that we extracted from Google Places, since our run outperforms baselines that rely on these data by a margin of 81.33 % or more (for the official P@5 WGT measure).</p><p>Future work will tackle the temporal processing of queries (i.e., season, time, and day) to associate place type sets to contexts with higher accuracy. We will also tackle preference processing with regards to partial positive and negative ratings and with regards to similarity scoring between contextual results and user preferences.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,130.45,396.09,351.10,9.63"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Architecture of our personalized contextual retrieval framework</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,138.10,134.09,331.80,112.59"><head>Table 1 :</head><label>1</label><figDesc>Place type sets per triple Season-Time-Day</figDesc><table coords="3,138.10,150.16,331.80,96.52"><row><cell>Season</cell><cell></cell><cell></cell><cell>Time</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Morning</cell><cell cols="2">Afternoon</cell><cell cols="2">Evening</cell></row><row><cell></cell><cell cols="6">weekday weekend weekday weekend weekday weekend</cell></row><row><cell>Spring</cell><cell>PS 3</cell><cell>PS 3</cell><cell>PS 4</cell><cell>PS 1</cell><cell>PS 5</cell><cell>PS 5</cell></row><row><cell>Summer</cell><cell>PS 3</cell><cell>PS 3</cell><cell>PS 4</cell><cell>PS 1</cell><cell>PS 5</cell><cell>PS 5</cell></row><row><cell>Fall</cell><cell>PS 3</cell><cell>PS 3</cell><cell>PS 4</cell><cell>PS 1</cell><cell>PS 6</cell><cell>PS 6</cell></row><row><cell>Winter</cell><cell>PS 3</cell><cell>PS 3</cell><cell>PS 4</cell><cell>PS 2</cell><cell>PS 6</cell><cell>PS 6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,88.94,386.82,419.32,159.16"><head>Table 2</head><label>2</label><figDesc></figDesc><table coords="5,88.94,386.82,419.32,159.16"><row><cell></cell><cell></cell><cell cols="3">: Official results for the P@5 measure</cell><cell></cell><cell></cell></row><row><cell>Run</cell><cell></cell><cell cols="4">P@5 (Mean over all the profiles and contexts)</cell><cell></cell></row><row><cell></cell><cell>WGT</cell><cell>GT</cell><cell>G</cell><cell>T</cell><cell>W</cell><cell>D</cell></row><row><cell>baselineA (+)</cell><cell>0.1784</cell><cell>0.5114</cell><cell>0.7908</cell><cell>0.5694</cell><cell>0.4086</cell><cell>0.3031</cell></row><row><cell>baselineB</cell><cell>0.1704</cell><cell>0.5482</cell><cell>0.8060</cell><cell>0.5883</cell><cell>0.2654</cell><cell>0.2444</cell></row><row><cell>waterloo12a</cell><cell>0.1377</cell><cell>0.4229</cell><cell>0.8230</cell><cell>0.4451</cell><cell>0.3463</cell><cell>0.3272</cell></row><row><cell cols="2">waterloo12b (-) 0.0864</cell><cell>0.4065</cell><cell>0.6827</cell><cell>0.4988</cell><cell>0.1741</cell><cell>0.3117</cell></row><row><cell cols="2">iritSplit3CPv1 0.3235</cell><cell>0.6027</cell><cell>0.8930</cell><cell>0.6156</cell><cell>0.4599</cell><cell>0.3605</cell></row><row><cell>iritSplit3CPv2</cell><cell>0.1790</cell><cell>0.5486</cell><cell>0.8466</cell><cell>0.5580</cell><cell>0.3235</cell><cell>0.2593</cell></row><row><cell>According to Table</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,72.00,81.96,443.90,257.71"><head>Table 3 :</head><label>3</label><figDesc>Difference with the strong baseline for the P@5 measure</figDesc><table coords="6,72.00,98.49,443.90,241.19"><row><cell>Difference</cell><cell></cell><cell cols="4">P@5 (Mean over all the profiles and contexts)</cell><cell></cell></row><row><cell>iritSplit3CPv1</cell><cell>WGT</cell><cell>GT</cell><cell>G</cell><cell>T</cell><cell>W</cell><cell>D</cell></row><row><cell cols="7">vs BaselineA (+) +81.33 % +17.85 % +12.92 % +8.11 % +12.56 % +18.94 %</cell></row><row><cell></cell><cell cols="5">Table 4: Official results for the MRR measure</cell><cell></cell></row><row><cell>Run</cell><cell></cell><cell cols="4">MRR (Mean over all the profiles and contexts)</cell><cell></cell></row><row><cell></cell><cell>WGT</cell><cell>GT</cell><cell>G</cell><cell>T</cell><cell>W</cell><cell>D</cell></row><row><cell>baselineA</cell><cell>0.2993</cell><cell>0.6447</cell><cell>0.8906</cell><cell>0.7002</cell><cell>0.5366</cell><cell>0.4632</cell></row><row><cell>baselineB (+)</cell><cell>0.3504</cell><cell>0.7470</cell><cell>0.9274</cell><cell>0.7817</cell><cell>0.4384</cell><cell>0.3951</cell></row><row><cell>waterloo12a</cell><cell>0.2130</cell><cell>0.5703</cell><cell>0.8615</cell><cell>0.6119</cell><cell>0.3859</cell><cell>0.4183</cell></row><row><cell cols="2">waterloo12b (-) 0.1404</cell><cell>0.5304</cell><cell>0.7447</cell><cell>0.6149</cell><cell>0.2775</cell><cell>0.4467</cell></row><row><cell cols="2">iritSplit3CPv1 0.4675</cell><cell>0.7585</cell><cell>0.9480</cell><cell>0.7634</cell><cell>0.6493</cell><cell>0.5461</cell></row><row><cell>iritSplit3CPv2</cell><cell>0.3377</cell><cell>0.6795</cell><cell>0.9072</cell><cell>0.6853</cell><cell>0.4500</cell><cell>0.3841</cell></row><row><cell cols="3">official MRR WGT measure as showed in Table</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,83.64,402.24,437.70,63.78"><head>Table 5 :</head><label>5</label><figDesc>Difference with the strong baseline for the MRR measure</figDesc><table coords="6,83.64,418.77,437.70,47.25"><row><cell>Difference</cell><cell></cell><cell cols="4">MRR (Mean over all the profiles and contexts)</cell><cell></cell></row><row><cell>iritSplit3CPv1</cell><cell>WGT</cell><cell>GT</cell><cell>G</cell><cell>T</cell><cell>W</cell><cell>D</cell></row><row><cell cols="2">vs BaselineB (+) +33.42 %</cell><cell>+1.54 %</cell><cell>+2.22 %</cell><cell>-2.34 %</cell><cell cols="2">+48.11 % +38.22 %</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,130.03,381.81,411.50,9.63;7,130.03,395.36,310.32,9.63" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,321.28,381.81,220.25,9.63;7,130.03,395.36,129.88,9.63">Information filtering and information retrieval: two sides of the same coin?</title>
		<author>
			<persName coords=""><forename type="first">Nicholas</forename><forename type="middle">J</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,265.96,395.36,71.59,9.63">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="29" to="38" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,130.03,412.08,409.99,9.63;7,130.03,425.63,409.97,9.63;7,129.66,439.18,411.86,9.63;7,129.76,452.73,24.85,9.63" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,386.35,412.08,153.67,9.63;7,130.03,425.63,145.79,9.63">Automatic profile reformulation using a local document analysis</title>
		<author>
			<persName coords=""><forename type="first">Anis</forename><surname>Benammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gilles</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Josiane</forename><surname>Mothe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,297.72,425.63,242.28,9.63;7,129.66,439.18,284.88,9.63">Advances in Information Retrieval, 24th BCS-IRSG European Colloquium on IR Research, volume 2291 of LNCS</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="124" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,130.03,469.45,412.11,9.63;7,130.03,483.00,409.97,9.63;7,129.25,496.55,296.42,9.63" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,289.38,469.45,248.62,9.63">Reusing past queries to facilitate information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Gilles</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Josiane</forename><surname>Mothe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,143.30,483.00,396.70,9.63;7,129.25,496.55,57.61,9.63">ICSOFT &apos;07: Proceedings of the 2nd International Conference on Software and Data Technologies</title>
		<imprint>
			<publisher>INSTICC Press</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="166" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,130.03,513.28,409.99,9.63;7,130.03,526.82,304.83,9.63" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,286.49,513.28,253.54,9.63;7,130.03,526.82,37.96,9.63">An adaptable search engine for multimodal information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Gilles</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Josiane</forename><surname>Mothe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,177.05,526.82,140.92,9.63">J. Am. Soc. Inf. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1625" to="1634" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,130.03,543.55,410.28,9.63;7,130.03,557.10,409.97,9.63;7,130.03,570.65,409.97,9.63;7,130.03,584.19,343.74,9.63" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,492.35,543.55,47.96,9.63;7,130.03,557.10,261.33,9.63">Document filtering method using non-relevant information profile</title>
		<author>
			<persName coords=""><forename type="first">Keiichiro</forename><surname>Hoashi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kazunori</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Naomi</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kazuo</forename><surname>Hashimoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,414.05,557.10,125.95,9.63;7,130.03,570.65,409.97,9.63;7,130.03,584.19,97.93,9.63">SIGIR &apos;00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="176" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,130.03,600.92,409.97,9.63;7,129.63,614.47,410.37,9.63;7,129.63,628.02,412.49,9.63;7,130.03,641.56,71.57,9.63" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,202.34,600.92,168.18,9.63;7,180.27,614.47,359.73,9.63;7,129.63,628.02,221.55,9.63">Third International Workshop of the Initiative for the Evaluation of XML Retrieval, INEX 2004, Revised Selected Papers</title>
		<author>
			<persName coords=""><forename type="first">Gilles</forename><surname>Hubert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,393.23,600.92,146.77,9.63;7,129.63,614.47,41.99,9.63">Advances in XML Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3493</biblScope>
			<biblScope unit="page" from="183" to="196" />
		</imprint>
	</monogr>
	<note>A voting method for XML retrieval</note>
</biblStruct>

<biblStruct coords="7,130.03,658.29,409.99,9.63;7,130.03,671.84,409.98,9.63;7,130.03,685.39,409.97,9.63;7,130.03,698.93,412.09,9.63;7,130.03,712.48,71.57,9.63" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,491.52,658.29,48.50,9.63;7,130.03,671.84,409.98,9.63;7,130.03,685.39,52.94,9.63">Measuring Effectiveness of Geographic IR Systems in Digital Libraries: Evaluation Framework and Case Study</title>
		<author>
			<persName coords=""><forename type="first">Damien</forename><surname>Palacio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guillaume</forename><surname>Cabanac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Sallaberry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gilles</forename><surname>Hubert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,206.82,685.39,333.17,9.63;7,130.03,698.93,220.69,9.63">ECDL&apos;10: Proceedings of the 14th European Conference on Research and Advanced Technology for Digital Libraries</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6273</biblScope>
			<biblScope unit="page" from="340" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,130.03,75.44,409.99,9.63;8,130.03,88.99,409.99,9.63;8,130.03,102.54,222.21,9.63" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,506.79,75.44,33.23,9.63;8,130.03,88.99,409.99,9.63;8,130.03,102.54,23.79,9.63">On the evaluation of geographic information retrieval systems: Evaluation framework and case study</title>
		<author>
			<persName coords=""><forename type="first">Damien</forename><surname>Palacio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guillaume</forename><surname>Cabanac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Sallaberry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gilles</forename><surname>Hubert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,163.41,102.54,86.82,9.63">Int. J. Digit. Libr</title>
		<imprint>
			<biblScope unit="page" from="91" to="109" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,120.08,24.39,9.63;8,96.39,118.14,6.59,7.04;8,103.48,120.08,436.54,9.63;8,130.03,133.62,409.99,9.63;8,129.65,147.17,411.86,9.63;8,130.03,160.72,409.99,9.63;8,130.03,174.27,82.46,9.63" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,158.57,133.62,366.38,9.63">Do expressive geographic queries lead to improvement in retrieval effectiveness?</title>
		<author>
			<persName coords=""><surname>Psc + 12] Damien</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Palacio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guillaume</forename><surname>Sallaberry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gilles</forename><surname>Cabanac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mauro</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Gaio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,129.65,147.17,406.82,9.63">Bridging the Geographic Information Sciences, International AGILE&apos;2012 Conference</title>
		<title level="s" coord="8,130.03,160.72,247.64,9.63">Lecture Notes in Geoinformation and Cartography</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="267" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,130.03,191.81,390.32,9.63" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,205.31,191.81,183.52,9.63">Mathematics and information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Gerard</forename><surname>Salton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,397.87,191.81,32.69,9.63">J. Doc</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
