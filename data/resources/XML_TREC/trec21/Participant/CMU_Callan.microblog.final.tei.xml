<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,60.61,72.35,488.51,16.84">Overcoming Vocabulary Limitations in Twitter Microblogs</title>
				<funder ref="#_4qp5Mzu">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder>
					<orgName type="full">Singapore National Research Foundation</orgName>
				</funder>
				<funder>
					<orgName type="full">Center for the Future of Work</orgName>
				</funder>
				<funder>
					<orgName type="full">International Research Centre @ Singapore Funding Initiative</orgName>
				</funder>
				<funder>
					<orgName type="full">IDM Programme Office</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,132.02,118.05,53.16,11.06"><forename type="first">Yubin</forename><surname>Kim</surname></persName>
							<email>yubink@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,260.76,118.05,88.20,11.06"><forename type="first">Reyyan</forename><surname>Yeniterzi</surname></persName>
							<email>reyyan@cs.cmu.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,416.68,118.05,68.85,11.06"><forename type="first">Jamie</forename><surname>Callan</surname></persName>
							<email>callan@cs.cmu.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,60.61,72.35,488.51,16.84">Overcoming Vocabulary Limitations in Twitter Microblogs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2B24629C992427878DDF03CC028F14BC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Twitter</term>
					<term>document expansion</term>
					<term>query expansion</term>
					<term>pseudorelevance feedback</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>One major difficulty in performing ad-hoc search on microblogs such as Twitter is the limited vocabulary of each document due their short length. In this paper, two approaches to addressing this issue are presented. The first is query expansion through pseudo-relevance feedback and the other is document expansion of tweets using web documents linked from the body of the tweet. Tweets are expanded by concatenating the contents of the title tag and the meta descriptor tags of the document to the tweet itself. These two approaches gave additive gains in MAP and Precision at 30.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In recent years, a new form of publishing has become increasingly popular on the Internet; in addition to longer articles, users are now publishing short messages called microblogs. One of the most popular microblog platforms is Twitter 1 and its users alone generate 400 million "tweets" per day as of June 2012 2 . These microblog entries have different characteristics from a typical web document; the entries are shorter due to a 140 character limit, are often filled with accidental and deliberate spelling errors, and they are realtime with new entries being constantly created. Therefore, techniques to address vocabulary mismatch and a timely real-time indexer become important for microblogs.</p><p>In this paper, the first need is considered within the framework of the Microblog Track in the Text REtrieval Conference 3 (TREC) and document expansion of tweets and query expansion through pseudo-relevance feedback are proposed as solutions. Phrases such as proper nouns extracted from queries are also investigated due to their significance in the query.</p><p>The real-time ad-hoc task in Microblog Track specifies that given a query which is issued at a specific time point, tweets that contain relevant information up to the specified time should be returned. Any retweets or tweets from a later time than which the query was issued are considered nonrelevant.</p><p>To comply with Twitter's terms of use, the dataset for the Microblog Track was distributed as a list of tweet ids, which the participants used to fetch the actual tweet text from Twitter directly. However, because the full JSON form of tweets are not easily available without an API key, the following work was done on a corpus of tweets constructed by screen-scraping the tweet display HTML pages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>In the inaugural year of the Microblog Track at TREC, there were some common themes among participants. The first theme was query expansion. Tweets are short, thus there is often a vocabulary mismatch between a query and the content of the tweet. For example, the query "Detroit Auto Show" has a relevant tweet which contains "North American Car of the Year" but no direct mention of "auto". Although the exact implementation of their methods differed, all of the top 5 finishing runs included some form of query expansion <ref type="bibr" coords="1,316.81,543.81,9.72,7.86" target="#b8">[8,</ref><ref type="bibr" coords="1,329.22,543.81,7.16,7.86" target="#b1">1,</ref><ref type="bibr" coords="1,339.07,543.81,7.16,7.86" target="#b6">6,</ref><ref type="bibr" coords="1,348.92,543.81,7.16,7.86">9,</ref><ref type="bibr" coords="1,358.77,543.81,6.48,7.86" target="#b4">4]</ref>. Most reported that query expansion improved their results, although Louvan et al. saw that one of their query expansion methods hurt results for highly relevant tweets while a different method improved results for highly relevant tweets <ref type="bibr" coords="1,379.81,585.66,9.21,7.86" target="#b7">[7]</ref>.</p><p>Another popular theme was temporal distance or recency, either as a feature in a learning-to-rank algorithm <ref type="bibr" coords="1,514.00,617.04,9.72,7.86" target="#b8">[8]</ref> or used as a boosting factor to re-rank tweets <ref type="bibr" coords="1,468.60,627.50,9.71,7.86" target="#b1">[1,</ref><ref type="bibr" coords="1,481.10,627.50,7.16,7.86" target="#b4">4,</ref><ref type="bibr" coords="1,491.06,627.50,11.76,7.86" target="#b10">10,</ref><ref type="bibr" coords="1,505.61,627.50,6.47,7.86" target="#b7">7]</ref>. However, the results of these experiments were mixed. Metzler et al. reported that the time feature received a 0 weight after training <ref type="bibr" coords="1,332.68,658.88,9.71,7.86" target="#b8">[8]</ref> and Ferguson et al. saw a negative impact on runs judged against all relevant documents <ref type="bibr" coords="1,473.22,669.34,9.20,7.86" target="#b4">[4]</ref>. However, Ferguson mentioned that a temporal re-weighting helped when the run was judged against only highly relevant documents <ref type="bibr" coords="1,316.81,700.73,9.72,7.86" target="#b4">[4]</ref> and Roegiest et al. <ref type="bibr" coords="1,414.70,700.73,14.32,7.86" target="#b10">[10]</ref> and Amati et al. <ref type="bibr" coords="1,508.31,700.73,9.71,7.86" target="#b1">[1]</ref> reported small gains when a temporal element was used in ranking. Some groups also used custom text-scoring functions with parameters that would be unusual for an ad-hoc web task. For example, Ferguson et al. used the Okapi BM25 model with parameters k1 = b = 0, effectively using binary term weighting and eliminating document length normalization <ref type="bibr" coords="2,53.80,109.94,9.20,7.86" target="#b4">[4]</ref>. Louvan et al. also modified the built-in Lucene scoring function to use binary term weighting in conjunction to temporal boosting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">INITIAL DATA PROCESSING</head><p>The guidelines in TREC task indicate that any tweets that are retweets (a tweet originally written by a different author that was forwarded) or are non-English tweets are nonrelevant. Additionally, document expansion requires detecting and downloading the links included in the tweet. Thus, some pre-processing was necessary before the tweets could be indexed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Tweet Body Cleaning</head><p>Tweets have a loose structure that is used to represent information other than the text body. For example, the @ symbol is used with a username when a tweet is directed towards another user (e.g. @bob123 Your BBQ was awesome! ) and the # symbol is used to indicate keywords or topics in the tweet (e.g. A big hurrah for physics with existence of #Higgs confirmed ). Tweets may also contain links to external pages with more details about the subject of the tweet.</p><p>Although these details could be used to improve search results (e.g. using the external links for document expansion), indexing them along with the text body hurts results. Due to the 140 character limitation on tweets, these structural details become a large percentage of the content when left in. Indeed, when the @ username mentions and URLs were stripped from the tweets, search results improved in preliminary tests with the queries from last year's track. However, hash tags provide almost a keyword-like summary of the tweet and thus contains valuable content. Therefore, each tweet was stripped of @ username mentions and URLs, but the hash tags phrases were left in.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">URL Detection and Download</head><p>URLs were extracted from tweets using two simple regular expressions:</p><formula xml:id="formula_0" coords="2,67.12,556.99,215.83,25.90">• (\s|^)(www\.\w\S*[^[:punct:]\s])[[:punct:]]* • (http://\w\S*[^[:punct:]\s])[[:punct:]]*</formula><p>For each URL found in the tweet corpus, the webpage was downloaded and saved to disk annotated with the tweet ID the URL was extracted from. These webpages were then used later for document expansion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Retweet Detection</head><p>Ordinarily, retweets are marked by a field in the full JSON representation of tweets available with a Twiter API key. However, some retweets are "old-style" retweets where the author manually copies and pastes a tweet annotated with a RT. Also, in the case of the TREC dataset, only a limited, screen-scraped representation of tweets are available. After a few experiments, it was found that when the HTML page of a tweet returns a 302 status code it indicates that tweet is a (new-style) retweet. In order to detect old-style retweets, tweets that have the word "RT" near the beginning of the tweet (where "beginning" is heuristically determined to be the first 8 characters) were marked as retweets as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Language Identification</head><p>The Microblog Track guidelines stipulate that non-English tweets are non-relevant. Therefore, the tweets needed to be tagged with their language ID so that non-English tweets could be discarded.</p><p>The language of each tweet was identified using a C implementation of Textcat<ref type="foot" coords="2,414.40,217.34,3.65,5.24" target="#foot_0">4</ref> . The standard pre-packaged language models were used for Chinese, Japanese, Korean, Portuguese, Arabic, and Russian and their various encodings. The language models for English, Spanish, French, German, and Dutch were replaced with models specifically trained for Twitter created by Carter et al. <ref type="bibr" coords="2,449.37,271.41,9.71,7.86" target="#b2">[2]</ref> A tweet was first stripped of mentions of usernames and URL-like strings, then if it was too short it was replicated until it contained 25 characters. Note that any tweet with fewer than 8 characters was discarded for not having enough content; this was done because extremely short tweets in all likelihood cannot satisfy the informational needs of a query.</p><p>Afterwards, the cleaned tweet was passed to Textcat and any tweets that had English as one of the possible language ID tags (i.e. tweets that are maybe English) were included in the index. Experiments were also run using tweets that contained English as the only language tag (i.e. tweets that are certainly English), but using the looser, maybe-English approach yielded better results in the query set from last year. This is likely due to the fact that the stricter, certainly-English approach can miss actual English tweets, while non-English tweets allowed by the looser approach are likely filtered out by the query itself, which is in English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">PROPOSED APPROACH</head><p>Two approaches for overcoming vocabulary mismatch were attempted to create a competitive entry for the TREC Microblog Track.</p><p>The first method is the use of document expansion. The Microblog Track guidelines states that a tweet which links to a relevant webpage is considered relevant by the judgesthat is, a linked webpage is considered an extension of the tweet. Therefore, document expansion was used to expand the tweet with relevant terms from a document it links to.</p><p>In addition to document expansion, a query expansion method was tried to overcome the vocabulary mismatch problem. Pseudo-relevance feedback (PRF), a well-known and effective method of query expansion was used to expand the query with terms from the retrieved relevant documents.</p><p>Finally, a heuristic procedure was used to extract phrases from query topics, which were given additional weight in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Phrase Detection</head><p>In baseline query experiments with the 2011 topics, it was noticed that a few queries did extremely poorly despite having many documents that were judged relevant in the pool. One such query was query 14 release of "The Rite". Most tweets judged relevant for this query contained the phrase "The Rite" in contrast to the non-relevant tweets returned by the baseline system which often contained only the term "rite" without the "the".</p><p>One way to resolve similar issues is to include stopwords in the query and the indexed documents; however, this may not generalize well for phrases which do not contain stopwords yet still appear in quotes. Therefore, in addition to retaining stopwords, phrases were extracted from queries by using capitalization, quotation marks, or dashes. With the help of these heuristics, phrases such as proper names which are important keywords in queries could be extracted and searched as a phrase with additional weights. Furthermore, numbers in queries were also extracted and given additional weight due to their significance. For instance, in query 2 2022 FIFA soccer the 2022 year helps to filter out relevant tweets from any FIFA and soccer related tweets. Several example queries and the extracted phrases are given in Table <ref type="table" coords="3,53.80,571.11,3.58,7.86">1</ref>.</p><p>Once the phrases were extracted, they were given additional weight and were used to construct a query similar to Figure <ref type="figure" coords="3,53.80,612.95,3.58,7.86" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Document Expansion</head><p>It was observed that relevant, informational tweets often contain a URL link. This is usually because it is difficult to convey a lot of information in a 140 characters (which is the limit for tweets), so users often tweet a headline of a news article and link to the body of the article. Thus, the tweets were expanded with the content of the documents that it linked to in order to overcome the vocabulary mismatch. However, this produced terms that were very poor in quality; selected words were very rare terms such as usernames and misspelled words that occur a few times in a single document but nowhere else. Attempts at heuristically correcting the problem such as discarding words that only occur in a single document did not improve the results. Similar problems existed with using Kullback-Leibler divergence between a background language model and the HTML document as the term weights.</p><p>Therefore, instead of algorithmically trying to determine which terms are most representative of the webpage, the summarization efforts made by the creators of the HTML pages were leveraged by extracting the contents of the title tag, and the contents of the keywords and description type meta tags. The text from these sources were added to the tweet as expansion terms. Although simple, this method has the advantage of using keywords that humans have identified as being a good summary of the document.</p><p>A comparison of the three document expansion methods is presented in Table <ref type="table" coords="3,394.12,464.61,3.58,7.86" target="#tab_2">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Pseduo-Relevance Feedback</head><p>Pseudo-relevance feedback (PRF) is a typical query expansion method which assumes the top N retrieved documents are relevant, identifies discriminative terms from these documents and adds them to the original query as expanded terms. Indri has a built-in PRF method which is based on Lavrenko's Relevance Model <ref type="bibr" coords="3,434.01,551.53,9.20,7.86" target="#b5">[5]</ref>.</p><p>In this model, a language model is built from the top retrieved documents, and terms from that language model are ranked by their weights. A weighted unigram query is then built with those top terms, and this query is combined with the original query to retrieve the final set of documents.</p><p>Different sets of pseudo-relevance feedback parameters were tried and the best results were obtained with the top 5 retrieved documents, adding top 10 feedback terms to the query and using a weight of 0.2 on the original query and 0.8 on the expanded query. Example queries and their expanded terms are given in Table <ref type="table" coords="3,417.92,687.52,3.58,7.86" target="#tab_1">3</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTAL SETUP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Statistics</head><p>The tweet corpus was downloaded on October 13, 2011. However, the last ID file was incompletely processed and was re-crawled on March 20, 2012. The statistics for the downloaded tweets are presented in Table <ref type="table" coords="4,225.03,383.90,3.58,7.86" target="#tab_3">4</ref>.</p><p>HTML documents linked from non-retweet, English tweets were crawled over a few days with the majority being downloaded between March 14, 2011 to March 16, 2011. However, the webpages linked from the tweets from the last ID file which was not completely crawled initially, were downloaded on April 2, 2011. In total, 1,161,041 HTML documents were downloaded.</p><p>Of the tweets downloaded, many were found to be either retweets or non-English tweets. After these tweets were filtered out, only 5,776,034 tweets remained and were indexed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Document Format</head><p>The indices for the dataset were created using Indri, a search engine commonly used in the research community 5 .</p><p>With the initial data processing steps completed, each tweet was converted to a pseudo-XML "trectext" format suitable for indexing with Indri. Document expansion was done at this step; for each tweet to be converted to XML, the tweet ID was matched with the webpages previously downloaded as described in Section 3.2 and the related terms identified by the document expansion algorithm were added to the tweet content. An example of a trectext document can be seen in Figure <ref type="figure" coords="4,113.57,661.73,3.58,7.86">2</ref>.</p><p>The CLEANTWEET field is the original tweet cleaned as per Section 3.1. EXPAND contains the document expansion terms and ONLYENGLISH is true when a tweet is certainly-English, false if it is maybe-English (non-English tweets are not indexed).</p><p>For more details regarding language identification, refer to Section 3.4.</p><p>In order to comply with the track requirement that no future data is used (even for collection statistics), an index was created for each topic which only contains the tweets that are in the "past" relative to the query, so that the IDF values are unpolluted by "future" documents upon query time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Individual Component Results</head><p>To discern the individual effects of the different system components, the queries and relevance judgements from the 2011 Microblog Track were used to evaluate each component.</p><p>The official metric for the 2011 Microblog Track was Precision at 30. However, this year the track switched to the area under the receiver operating characteristic (ROC) curve.</p><p>The ROC curve is a plot of the false positive rate (nonrelevant retrieved) the true positive rate (relevant retrieved), and the area under the curve (AUC) is the probability that a classifier will rank a randomly chosen positive instance higher than a random negative instance <ref type="bibr" coords="4,482.62,690.26,9.20,7.86" target="#b3">[3]</ref>. In this paper, both metrics and Mean Average Precision (MAP) are reported.</p><p>A summary of the individual effects of the different components is shown in Table <ref type="table" coords="5,153.40,68.10,3.58,7.86" target="#tab_5">5</ref>. Also, a per-query Average Precision (AP) analysis for four of the runs is shown in Figure <ref type="figure" coords="5,53.80,89.02,3.58,7.86" target="#fig_2">3</ref>. In all experiments, unless otherwise indicated, stopwords are included in all queries and the Dirichlet smoothing parameter is set to µ = 400 as these settings produced the best results on training data. Each ranked list returns 1000 results.</p><p>As expected, pseudo-relevance feedback increases the average performance but with a higher variance in performance (compare standard deviations 0.2195 for baseline and 0.2568 for PRF). Document expansion also increased average performance to a lesser degree than PRF, but it decreased the standard deviation of the queries (0.2087). However, this effect may be incidental to the training query set, as the submitted runs did not exhibit similar effects.</p><p>When combined together, PRF and document expansion show statistically significant additive gains compared to running either PRF or document expansion alone.</p><p>Phrases did not produce any statistically significant results and the average gains are small. However, this is not surprising as stopwords are included these runs. In preliminary results, when phrase queries were compared with a stopped baseline, the gains for phrases were greatest in queries where important stopwords would have been removed from queries (such as release of "The Rite" or release of "The Known and Unknown"). The gains for these queries are less when compared to a baseline that includes stopwords.</p><p>Lastly, pre-processing of tweets is shown to significantly improve results; there is over a 10 point gain in both MAP and P@30 from an index of raw tweets to the CLEANTWEET index, which has non-English and retweets removed and the tweet body cleaned of URLs and user @ mentions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EXPERIMENTAL RESULTS</head><p>Although the official metric this year was ROC, there was no single summary number given for the metric. Therefore, the results of the 2012 track are presented with MAP and Precision at 30.</p><p>Again, similar to the individual component experiments, in all of the runs, unless otherwise indicated, stopwords are included in all queries and the Dirichlet smoothing parameter is set to µ = 400. Each ranked list returned 1000 results.</p><p>The following four configurations were chosen for the submitted runs.</p><p>1. cmuPhrE: Phrase query on document expansion field.</p><p>2. cmuPrfPhr: Phrase query linearly interpolated with PRF (on plain, cleaned tweets).</p><p>3. cmuPrfPhrE: Phrase query on document expansion field linearly interpolated with PRF performed on document expansion field.</p><p>4. cmuPrfPhrENo: Phrase query on document expansion field linearly interpolated with PRF performed on doc-ument expansion field where stopword PRF terms were removed.</p><p>The performance of the four runs in TREC 2012 are displayed in Table <ref type="table" coords="5,385.52,108.25,3.58,7.86" target="#tab_6">6</ref>. For comparison, a baseline run index containing all the tweets in their raw form is also shown in the table. A per-query AP analysis is presented in Figure <ref type="figure" coords="5,316.81,139.63,3.58,7.86" target="#fig_4">4</ref>. The best run submitted (ordered by MAP and P@30), cmuPrfPhrENo, contained 45 out 59 queries above the median. Another run, cmuPrfPhr, recorded 46 queries above the median.</p><p>PRF continued to perform well in the 2012 query set, bringing statistically significant gains in both P@30 and MAP.</p><p>Document expansion did not work as well in the 2012 results. The differences in in cmuPrfPhr and cmuPrfPhrE seem to indicate a small additive average gain when document expansion and PRF are combined, at the expense of a higher variance. However, this gain is not statistically significant. This explains the '# above Median' column of Table <ref type="table" coords="5,342.17,286.08,3.58,7.86" target="#tab_6">6</ref>, which shows that more queries were above median in cmuPrfPhr than cmuPrfPhrE. A possible cause for this may be the following.</p><p>The 2011 and 2012 query sets both had similar proportions of expanded relevant tweets over the total set of all relevant tweets, but the 2012 query set had a higher variance in the ratio of expanded tweets across different queries. That is, the 2011 query set had a more even distribution of relevant expanded tweets over different queries. This would make the effect of document expansion more variable over different queries in the 2012 query set, resulting in less statistically significant improvements.</p><p>The higher variance of the document expansion run compared to a run without expansion (cmuPrfPhr vs. cmuPrf-PhrE) also differs from the findings from the 2011 query set, where document expansion was seen to reduce query performance variance from the baseline and when combined with PRF.</p><p>Unlike in 2011, the run without stopwords (cmuPrfPhrENo) did slightly better on average than the equivalent run including stopwords (cmuPrfPhrE) in the 2012 query set. Previously in the 2011 query data, including stopwords had slightly improved results. This is likely due to the 2011 query set containing more queries that would be sensitive to stopword removal, such as MB014 'release of "The Rite"' and MB018 'William and Kate fax save-the-date'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS</head><p>To develop ad-hoc search techniques better suited for the new publishing medium of microblogs, two approaches were tried. The first approach performed document expansion using the webpages linked from the tweet in a pre-processing step. Two different methods of generating candidate expansion terms, TF-IDF and KL divergence, produced very similar and low-quality words. Using the title text and metadata from the webpages as the expansion terms offers an easy performance boost without delving into more complex natural language processing algorithms.      The second approach, in a run-time step, used pseudorelevance feedback to perform query expansion which significantly improved average results at the cost of a higher variance.</p><p>When used together document expansion and query expansion gave additive gains in both the 2011 and 2012 query sets, although the gain was not statistically significant in the 2012 query set due to a higher variability of expanded documents marked relevant in different queries. Pre-processing the corpus to remove retweets and non-English tweets and cleaning the tweet body also gave a significant boost in results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,126.75,263.71,93.19,7.86"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Phrase query</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,55.85,202.32,426.05,7.86;6,53.80,212.78,241.42,8.11;6,53.80,223.24,269.72,7.86"><head></head><label></label><figDesc>† indicates a significant (p &lt; 0.05) difference using the two-tailed paired t-test compared to the raw tweet. * indicates a significant difference compared to CLEANTWEET. ˆindicates a significant difference compared to PRF and Doc Exp.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,122.02,677.79,365.67,7.86;6,53.80,484.31,251.07,167.38"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Per query analysis of AP values for all relevant tweets from TREC 2011 dataset.</figDesc><graphic coords="6,53.80,484.31,251.07,167.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,92.92,450.60,172.82,6.99;7,346.93,450.60,179.17,6.99;7,87.33,667.38,183.99,6.99;7,338.77,667.38,195.50,6.99"><head></head><label></label><figDesc>(a) cmuPhrE run. Standard deviation: 0.1853. (b) cmuPrfPhr run. Standard deviation: 0.2083. (c) cmuPrfPhrE run. Standard deviation: 0.2237. (d) cmuPrfPhrENo run. Standard deviation: 0.2235.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="7,126.52,686.68,356.69,7.86;7,53.80,459.73,251.06,200.85"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Per query analysis of AP values for all relevant tweets on TREC 2012 dataset.</figDesc><graphic coords="7,53.80,459.73,251.06,200.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,316.81,55.49,239.12,186.84"><head>Table 3 :</head><label>3</label><figDesc>Example PRF expansion termsInitially, document expansion was attempted by selecting the top-k TF-IDF weighted terms in a HTML document.</figDesc><table coords="3,326.71,55.49,219.32,115.76"><row><cell>Original Query</cell><cell>Expanded Terms</cell></row><row><cell>2022 FIFA soccer</cell><cell>fifa, cup, 2022, world,</cell></row><row><cell></cell><cell>qatar, held, stadium, win-</cell></row><row><cell></cell><cell>ter, care, child</cell></row><row><cell>Egyptian curfew</cell><cell>curfew, egypt, defy, build,</cell></row><row><cell></cell><cell>besiege, govern, mubarak,</cell></row><row><cell></cell><cell>extend, street, demon-</cell></row><row><cell></cell><cell>strate</cell></row><row><cell cols="2">Moscow airport bombing moscow, bomb, airport,</cell></row><row><cell></cell><cell>suicide, terrorist, reuter,</cell></row><row><cell></cell><cell>busiest, kill, chechen, rebel</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,72.72,55.49,464.29,231.62"><head>Table 2 :</head><label>2</label><figDesc>Sample expansion terms for tweets</figDesc><table coords="4,72.72,55.49,464.29,231.62"><row><cell>Original Tweet</cell><cell></cell><cell></cell><cell>TF-IDF</cell><cell>KL Divergence</cell><cell>Metadata</cell></row><row><cell cols="3">Stanley Ho Gives Up SJM</cell><cell>shai parcele oster sjm oke-</cell><cell>parcele 1257 shai oster</cell><cell>Plans to divide nearly all of</cell></row><row><cell>Stake</cell><cell></cell><cell></cell><cell>effe 1257 tussle too568 rind</cell><cell>too568 rind santorum648</cell><cell>Macau gambling ....</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>tussle</cell></row><row><cell cols="3">I make about $30 a day via</cell><cell>1440 credite clickbank grav</cell><cell>1440 credite tid grav gen-</cell><cell>make money online, af-</cell></row><row><cell>twitter</cell><cell></cell><cell></cell><cell>tid generator xml referr re-</cell><cell>erator xml clickbank referr</cell><cell>filiate marketing, make</cell></row><row><cell></cell><cell></cell><cell></cell><cell>fresh</cell><cell>refresh</cell><cell>money on internet ....</cell></row><row><cell>jetsbuzztap:</cell><cell cols="2">Yahoo!</cell><cell>buzztap jetsbuzztap i5lx4</cell><cell>jetsbuzztap i5lx4 buzztap</cell><cell>By BARRY WILNER</cell></row><row><cell cols="3">Sports &gt; &gt; Jets silenced:</cell><cell>silenc retweete afc -19 si-</cell><cell>silenc retweete -19 afc si-</cell><cell>AP Pro Football Writer -</cell></row><row><cell cols="3">Steelers win AFC title</cell><cell>lence steeler</cell><cell>lence footer</cell><cell>National Football League</cell></row><row><cell>24-19 : jetsbuzzta..</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>news</cell></row><row><cell cols="2">Tweet Type</cell><cell cols="2">Number of Tweets</cell><cell></cell></row><row><cell>HTTP 200</cell><cell></cell><cell></cell><cell>11,796,107</cell><cell></cell></row><row><cell>HTTP 301</cell><cell></cell><cell></cell><cell>2,212,522</cell><cell></cell></row><row><cell cols="2">Non Retweets</cell><cell></cell><cell>11,286,497</cell><cell></cell></row><row><cell>English</cell><cell></cell><cell></cell><cell>6,578,488</cell><cell></cell></row><row><cell cols="2">Tweets Indexed</cell><cell></cell><cell>5,776,034</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,106.77,309.34,133.18,7.86"><head>Table 4 :</head><label>4</label><figDesc>Statistics of tweets used</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,53.80,85.75,412.22,124.43"><head>Table 5 :</head><label>5</label><figDesc>Effects of each individual component on TREC 2011 dataset.</figDesc><table coords="6,143.70,85.75,322.32,83.88"><row><cell></cell><cell></cell><cell>All relevant</cell><cell></cell><cell cols="3">Highly relevant</cell></row><row><cell>Method</cell><cell>AUC</cell><cell>P@30</cell><cell>MAP</cell><cell>AUC</cell><cell>P@30</cell><cell>MAP</cell></row><row><cell>Raw Tweet</cell><cell>0.8535</cell><cell>0.3524</cell><cell>0.2894</cell><cell>0.8859</cell><cell>0.0769</cell><cell>0.1372</cell></row><row><cell>CLEANTWEET</cell><cell>0.8606</cell><cell>0.4619 †</cell><cell>0.3945 †</cell><cell>0.8976</cell><cell cols="2">0.1102 † 0.1894 †</cell></row><row><cell>Phrase</cell><cell>0.8614</cell><cell>0.4639</cell><cell>0.4011</cell><cell>0.8981</cell><cell>0.1102</cell><cell>0.1888</cell></row><row><cell>Doc Exp</cell><cell cols="2">0.8767* 0.4837</cell><cell>0.4373*</cell><cell>0.9090</cell><cell cols="2">0.1265* 0.2200</cell></row><row><cell>PRF</cell><cell>0.8671</cell><cell>0.5088*</cell><cell>0.4547*</cell><cell>0.901</cell><cell>0.1197</cell><cell>0.2120</cell></row><row><cell cols="7">Doc Exp + PRF 0.8953* 0.5116*ˆ0.4906*ˆ0.9201* 0.1340* 0.2362*</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,53.80,76.86,502.12,113.96"><head>Table 6 :</head><label>6</label><figDesc>Performance of four submitted official runs on TREC 2012 dataset. * indicates statistically significant (p &lt; 0.05) difference between it and all previous configurations.</figDesc><table coords="7,317.86,76.86,46.83,7.86"><row><cell>All relevant</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="2,321.42,711.19,160.75,7.86"><p>http://software.wise-guys.nl/libtextcat/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="8.">ACKNOWLEDGEMENTS</head><p>This research was in part supported by the <rs type="funder">National Science Foundation (NSF)</rs> grant <rs type="grantNumber">IIS-0916553</rs> and the <rs type="funder">Singapore National Research Foundation</rs> under its <rs type="funder">International Research Centre @ Singapore Funding Initiative</rs> and administered by the <rs type="funder">IDM Programme Office</rs>. Furthermore this publication was made possible by the generous support of the iLab and the <rs type="funder">Center for the Future of Work</rs>. Any opinions, findings, conclusions, and recommendations expressed in this paper are the authors' and do not necessarily reflect those of the sponsors.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_4qp5Mzu">
					<idno type="grant-number">IIS-0916553</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,58.28,334.96,96.81,10.75" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.59,347.55,201.34,7.86;8,72.59,358.01,209.84,7.86;8,72.59,368.47,203.22,7.86;8,72.59,378.93,193.73,7.86;8,72.59,389.39,48.57,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,125.60,368.47,150.21,7.86;8,72.59,378.93,16.76,7.86">FUB, IASI-CNR, UNIVAQ at TREC 2011</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amodeo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Nicola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Flammini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gaibisso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gambosi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Marcone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,108.11,378.93,158.21,7.86;8,72.59,389.39,19.64,7.86">Text REtrieval Conference Proceedings. NIST</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.59,400.85,216.13,7.86;8,72.59,411.31,217.87,7.86;8,72.59,421.77,181.48,7.86;8,72.59,432.23,163.49,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,248.56,400.85,40.16,7.86;8,72.59,411.31,217.87,7.86;8,72.59,421.77,137.19,7.86">Microblog language identification: Overcoming the limitations of short, unedited and idiomatic text</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Weerkamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Tsagkias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,216.58,421.77,37.50,7.86;8,72.59,432.23,135.33,7.86">Language Resources and Evaluation Journal</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.59,443.69,179.87,7.86;8,72.59,454.15,213.04,7.86;8,72.59,464.61,165.41,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,121.82,443.69,130.64,7.86;8,72.59,454.15,168.25,7.86">Roc graphs: Notes and practical considerations for data mining researchers</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Fawcett</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>HP Laboratories Palo Alto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="8,72.59,476.07,189.16,7.86;8,72.59,486.53,204.56,7.86;8,72.59,496.99,198.89,7.86;8,72.59,507.45,48.57,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,112.98,486.53,164.17,7.86;8,72.59,496.99,21.77,7.86">CLARITY at the TREC 2011 Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>O'hare</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lanagan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F</forename><surname>Smeaton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,113.26,496.99,158.21,7.86;8,72.59,507.45,19.64,7.86">Text REtrieval Conference Proceedings. NIST</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.59,518.91,189.97,7.86;8,72.59,529.37,207.98,7.86;8,72.59,539.83,205.73,7.86;8,72.59,550.29,219.65,7.86;8,72.59,560.75,200.77,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,197.16,518.91,65.40,7.86;8,72.59,529.37,64.47,7.86">Relevance based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,155.97,529.37,124.60,7.86;8,72.59,539.83,205.73,7.86;8,72.59,550.29,216.07,7.86">Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;01</title>
		<meeting>the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;01<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.59,572.21,190.22,7.86;8,72.59,582.67,203.52,7.86;8,72.59,593.13,190.40,7.86;8,72.59,603.59,100.04,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,195.56,582.67,80.55,7.86;8,72.59,593.13,64.98,7.86">PRIS at TREC2011 Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,156.48,593.13,106.51,7.86;8,72.59,603.59,71.11,7.86">Text REtrieval Conference Proceedings. NIST</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.59,615.05,185.50,7.86;8,72.59,625.51,194.46,7.86;8,72.59,635.97,204.63,7.86;8,72.59,646.43,189.14,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,215.32,625.51,51.73,7.86;8,72.59,635.97,168.30,7.86">University of Indonesia at TREC 2011 Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Louvan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Adriani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Vania</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Distiawan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">Z</forename><surname>Wanagiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,259.81,635.97,17.41,7.86;8,72.59,646.43,160.21,7.86">Text REtrieval Conference Proceedings. NIST</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.59,657.89,195.48,7.86;8,72.59,668.35,190.40,7.86;8,72.59,678.81,100.04,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,168.37,657.89,99.70,7.86;8,72.59,668.35,64.98,7.86">USC/ISI at TREC 2011: Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,156.48,668.35,106.51,7.86;8,72.59,678.81,71.11,7.86">Text REtrieval Conference Proceedings. NIST</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.59,690.26,193.49,7.86;8,72.59,700.73,218.64,7.86;8,72.59,711.19,199.65,7.86;8,335.61,57.64,100.04,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,119.91,700.73,171.32,7.86;8,72.59,711.19,74.67,7.86">TREC 2011 Microblog Track Experiments at Kobe University</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miyanishi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Okamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Seki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Uehara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,165.73,711.19,106.51,7.86;8,335.61,57.64,71.11,7.86">Text REtrieval Conference Proceedings. NIST</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,335.60,69.09,186.23,7.86;8,335.61,79.55,207.42,7.86;8,335.61,90.02,189.14,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,470.10,69.09,51.73,7.86;8,335.61,79.55,171.10,7.86">University of Waterloo at TREC 2011: Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roegiest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,525.62,79.55,17.41,7.86;8,335.61,90.02,133.48,7.86">Text REtrieval Conference Proceedings</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
