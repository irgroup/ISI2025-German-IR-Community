<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,145.91,164.85,319.42,15.12;1,238.16,186.77,134.94,15.12;1,173.28,208.68,264.69,15.12">Retrieving Medical Records with &quot;sennamed&quot;: NEC Labs America at TREC 2012 Medical Records Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,202.60,241.17,53.00,10.48"><forename type="first">Yanjun</forename><surname>Qi</surname></persName>
							<email>yanjun@nec-labs.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Machine Learning</orgName>
								<orgName type="department" key="dep2">NEC Laboratories America</orgName>
								<address>
									<settlement>Princeton</settlement>
									<region>New Jersey</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,282.26,241.17,126.40,10.48"><forename type="first">Pierre-François</forename><surname>Laquerre</surname></persName>
							<email>pierre.francois@nec-labs.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Machine Learning</orgName>
								<orgName type="department" key="dep2">NEC Laboratories America</orgName>
								<address>
									<settlement>Princeton</settlement>
									<region>New Jersey</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,145.91,164.85,319.42,15.12;1,238.16,186.77,134.94,15.12;1,173.28,208.68,264.69,15.12">Retrieving Medical Records with &quot;sennamed&quot;: NEC Labs America at TREC 2012 Medical Records Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">83F991AB586CFBBEA945098930FF592F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this notebook, we describe the automatic retrieval runs from NEC Laboratories America (NECLA) for the Text REtrieval Conference (TREC) 2012 Medical Records track. Our approach is based on a combination of UMLS medical concept detection and a set of simple retrieval models. Our best run, sennamed2, has achieved the best inferred average precision (infAP) score on 5 of the 47 test topics, and obtained a higher score than the median of all submission runs on 27 other topics. Overall, sennamed2 ranks at the second place amongst all the 82 automatic runs submitted for this track, and obtains the third place amongst both automatic and manual submissions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The majority of medical information today is stored as an abundant combination of free, structured and semi-structured text. Electronic medical records (EMRs) document clinical information about a patient such as his/her medical history, current medical care, and current illnesses. This information can be leveraged by healthcare professionals to track the progress of patients, guide the diagnosis, and provide more personalized care to the patients. The urgent need for efficient processing and intelligent access of EMRs has led to a rapid increase in research efforts recently. As a notable example, the renowned TREC been holding a Medical Records track <ref type="bibr" coords="1,233.01,601.28,10.52,8.74" target="#b0">[1]</ref> since 2011, which has attracted many research groups from all over the world to participate and to evaluate the performance of their EMR retrieval algorithms.</p><p>The TREC Medical Records track includes a retrieval task aiming to find EMRs that are relevant to a given natural language query <ref type="bibr" coords="1,383.73,649.10,12.56,8.74" target="#b0">[1]</ref>. These EMRs are de-identified medical records, provided by the University of Pittsburgh BLU-Lab NLP Repository<ref type="foot" coords="2,230.20,138.34,3.97,6.12" target="#foot_0">1</ref> . There is a total of more than one hundred thousand medical reports from encounters with patients in various departments from multiple hospitals. This corpus contains nine types of reports, including radiology, emergency department, and radiology reports. These reports can be grouped into ∼17,000 distinct visits, each corresponding to a single patient's stay at the hospital. For the 2011 track, the participants were required to submit relevant records from the above EMR corpus for 35 topic queries (with one of the queries having no reports found in the end). For the 2012 track, submissions were evaluated by judging the relevance of their returned results on 50 given queries, of which 3 were later excluded by the organizers due to the lack of relevant visits for proper evaluation. Submissions were split in two different groups. Automatic submissions include those that do not require any human intervention, while manual submissions include everything else. Topics and relevance judgments were created by physicians who are also students in the bioinformatics program at Oregon Health and Science University.</p><p>The NECLA team submitted four automatic runs to the 2012 track. The main techniques used in our runs include medical concept detection, a vectorspace retrieval model, a probabilistic retrieval model, a supervised preference ranking model, unsupervised dimensionality reduction, and query expansion. The details of these techniques are given in the next section. Experimental results for each model are presented in Section 3 and are further analyzed in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>The basic task of the TREC Medical Records track is to return a ranked list of visits that are relevant to a given ad-hoc query such as "Patients taking atypical antipsychotics without a diagnosis schizophrenia or bipolar depression". We explored a number of classical Information Retrieval (IR) technologies for this task and also considered the special properties of medical record text, such as frequent usage of acronyms. We used relevance judgments from the 2011 track for parameter tuning and model selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preprocessing</head><p>We generated simple regular expressions to remove boilerplate text such as "My signature below is attestation that I have interpreted this/these examination(s) and agree with the findings as noted above.". To find such sentences, we searched for the most common substrings of several given lengths in the corpus.</p><p>The de-identification tags were converted to simple text to prevent downstream tools from interpreting the special syntax as punctuation. For example, "**DATE[Feb 01 06]" was converted to "Feb 01 06".</p><p>The patient denies any abdominal pain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C0030705 C0332319 negC0000737</head><p>Table <ref type="table" coords="3,207.74,176.83,3.87,8.74">1</ref>: Semantic concept extraction on raw text tokens.</p><p>In the provided EMR collection, reports associated with the same patient stay are grouped into visits. The content-based retrieval task expects to retrieve those visits that are semantically relevant to a given query. We have tested two types of indexing in our runs: visit-based and report-based. In visit-based indexing, a visit's reports are concatenated into a single document. In report-based indexing, individual reports are indexed, and the query results are transformed into unique visits before being returned. There was no significant difference between those two approaches on the 2011 topics. Therefore, we opted to use the visit-based approach for all submissions. Thus, in the rest of this report, we use "document" to refer to all medical reports related to a given visit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Term Representation Using Plain Text and/or UMLS Medical Concepts Transformation</head><p>Besides working on plain text tokens, we also utilized MetaMap <ref type="bibr" coords="3,399.69,376.47,15.77,8.74" target="#b1">[2]</ref> to convert the raw text into sequences of UMLS medical concepts. The UMLS metathesaurus <ref type="bibr" coords="3,133.77,400.38,10.52,8.74" target="#b2">[3]</ref> is the largest thesaurus in the biomedical domain, and tries to represent biomedical knowledge using semantic concepts and the relationships between them. MetaMap, a program developed by the National Library of Medicine (NLM), maps raw text tokens to corresponding Concept Unique Identifiers (CUIs), where each CUI belongs to a specific biomedical concept in the UMLS metathesaurus. Only top candidate CUIs were kept, and no limitation was put on the UMLS source. Negation detection was used to distinguish between concepts and their negated counterpart. Negated concepts were given unique ids so that downstream systems could tell them apart from the non-negated counterparts. The extraction on the full set of medical records led to a dictionary size of 62553, among which 7388 were negations. Table <ref type="table" coords="3,378.75,519.94,4.98,8.74">1</ref> provides a schematic example of the above procedure. In this table, C0030705 corresponds to "patient", C0332319 to "denies", and negC0000737 to the negation of "abdominal pain". The same process was applied to the query topics. Admission and discharge ICD codes were also converted to their UMLS equivalent and added to each visit. Other metadata from the XML was discarded. The end result is a representation of documents or topics containing a sequence of UMLS concept ids or their negation. In the following, we use "UMLS" to tag those retrieval runs using CUIs extracted from records and CUIs from queries as the basic term tokens. We use "raw text" to tag those retrieval runs using the plain text token (after preprocessing). We also test the combined representation of "UMLS + raw text" in our experiments, which uses the concatenation of plain text tokens and the extracted CUIs to represent records and query topics. See Table <ref type="table" coords="3,457.05,663.40,4.98,8.74">2</ref> for the different representations tried in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Indexing and Ranking</head><p>Generally speaking, the task at hand is a standard ad-hoc IR task, where documents that are topically relevant to a query must be returned. Thus, we explore (1) a classic vector space retrieval model, (2) a language model based retrieval approach, and (3) a supervised preference ranking model belonging to the "learning to rank" category. We also test several other classic IR techniques in our runs, including dimensionality reduction using Latent Semantic Indexing (LSI), and query expansion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Retrieval with a Vector-Space Model</head><p>In the vector space model, each document and query is represented as a vector of terms. In our experiments, the terms could be plain text tokens, detected CUIs, or both. Documents are then ranked by the similarity between the query vector and the document vector. Empirical studies of retrieval methods have found that good retrieval performance is closely related to the use of proper heuristics such as TF-IDF weighting <ref type="bibr" coords="4,300.71,350.03,9.96,8.74" target="#b3">[4]</ref>. We use one of the best performing vector space retrieval formula, BM25 <ref type="bibr" coords="4,298.18,361.99,9.96,8.74" target="#b4">[5]</ref>:</p><formula xml:id="formula_0" coords="4,176.20,382.91,301.28,27.30">ω∈q∩d ln( N -df(ω) + 0.5 df(ω) + 0.5 ) • tf(ω, d) • (k 1 + 1) tf(ω, d) + k 1 • (1 -b + b • |d| avgdl )<label>(1)</label></formula><p>Here tf(ω, d) represents the count of word ω in the document d, tf(ω, q) is the count of word ω in the query q, and N is the total number of documents in the collection. df(ω) is the number of documents which contain this term. |d| represents the length of the document. avdl is the average document length. k 1 and b are parameters that can be tuned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Retrieval with Language Model with Dirichlet Smoothing</head><p>Besides the vector space retrieval model, language model based retrieval has attracted a lot of attention recently <ref type="bibr" coords="4,297.57,526.47,10.52,8.74" target="#b5">[6,</ref><ref type="bibr" coords="4,312.31,526.47,7.01,8.74" target="#b6">7]</ref>. Thus we test one retrieval model belonging to this category. This type of model builds a probabilistic language model G d for each document d, and then ranks documents for a given query based on the likelihood that each document's language model could have generated the query: P (q|G d ). The retrieval function is:</p><formula xml:id="formula_1" coords="4,151.02,595.22,326.46,26.88">logP (q|G d ) = ω∈q∩d log p s (ω|d) α d * p(ω|C) + |q| * log(α d ) + ω∈q log(p(ω|C))<label>(2)</label></formula><p>Here |q| is the length of query, and p(ω|C) is the probability of the term given by the collection language model, which represents how popular the term is in the whole collection, i.e. playing a similar role to the well known IDF.</p><p>Language modeling based IR approaches typically employ a smoothing strategy to assign a non-zero probability to unseen terms, which can improve the accuracy of term probability estimation in general <ref type="bibr" coords="5,343.22,151.87,9.96,8.74" target="#b5">[6]</ref>. One of the best performing method is Dirichlet prior smoothing. When utilizing Dirichlet prior smoothing <ref type="bibr" coords="5,133.77,175.78,10.52,8.74" target="#b5">[6]</ref> to smooth the document language model, we have,</p><formula xml:id="formula_2" coords="5,237.46,193.78,240.02,22.31">p s (ω|d) = tf(ω, d) + µ * p(ω|C) |d| + µ<label>(3)</label></formula><formula xml:id="formula_3" coords="5,277.83,222.17,195.41,22.31">α d = µ |d| + µ (<label>4</label></formula><formula xml:id="formula_4" coords="5,473.24,228.91,4.24,8.74">)</formula><p>where |d| is the length of the document, and µ is a parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Retrieval with a supervised "Learning to Rank" Model</head><p>In addition, we study a retrieval model which is trained by supervised signals to rank a set of documents for given queries in the pairwise preference learning framework. This model belongs to the "learning to rank" category <ref type="bibr" coords="5,437.63,318.62,10.52,8.74" target="#b7">[8]</ref> which learns the preference or relevance function by assigning a real valued score to a feature vector describing a (query, object) pair. Specifically we utilize the so-called "supervised semantic indexing" (SSI) approach <ref type="bibr" coords="5,386.61,354.48,9.96,8.74" target="#b8">[9]</ref>. Given a query q and a document d, the relevance score between q and d is modeled as:</p><formula xml:id="formula_5" coords="5,228.65,386.87,248.83,19.91">f (q, d) = q W d = i,j W ij Φ(q i , d j ),<label>(5)</label></formula><p>where Φ(q i , d j ) = q i d j and W ij models the relationship/correlation between i th query feature q i and j th document feature d j . This is essentially a linear model with pairwise features Φ(•, •) and the parameter matrix W is learned from labeled data. Pairwise features describing relationships between two raw features (e.g. word synonymy or polysemy) have been shown to improve the retrieval precision before <ref type="bibr" coords="5,244.82,478.70,9.96,8.74" target="#b8">[9]</ref>. The training labels are based on the 2011 TREC Medical Records track test collection which contains 7100 visits judged not relevant and 1765 judged relevant across 34 query topics. We perform two-fold cross-validation on this reference set for parameter tuning, i.e. half as training and half as testing. Our experimental results showed that SSI does not improve the retrieval results over simple retrieval models. This is in part due to the low quantity of queries and corresponding relevance judgments available for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.4">Dimensionality Reduction using LSI</head><p>LSI <ref type="bibr" coords="5,152.66,594.21,15.50,8.74" target="#b9">[10]</ref> has been widely used for dimensionality reduction in IR. It is treated as one of the most successful tools for learning latent topics from text. Thus we also test this technique in our runs. We used Gensim <ref type="bibr" coords="5,362.57,618.12,19.31,8.74" target="#b10">[11]</ref> to train and obtain a model to project the document and query into a reduced space with m latent dimensions. Here m is a hyper-parameter to tune. Before applying LSI, the dictionary size was cut down to 44113 by filtering out tokens that appeared in too many visits (&gt; 99%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.5">Query Expansion with Pseudo-Relevance Feedback</head><p>We also test the classic pseudo-relevance feedback strategy, which has been found to improve performance of multiple TREC ad-hoc tasks before <ref type="bibr" coords="6,439.87,158.30,14.61,8.74" target="#b11">[12]</ref>. For a given query, pseudo-relevance feedback uses the designated retrieval model to retrieve the set of top-k ranked documents. It then expands the original query using the top ranked m candidate terms from this set of documents according to:</p><formula xml:id="formula_6" coords="6,237.97,216.01,239.51,21.98">q 1 = α • q 0 + (1 -α) • i=1..m q i rf<label>(6)</label></formula><p>Here, q 1 represents the revised query and q 0 is the original query. q i rf refers to the i-th candidate term from pseudo-relevance feedback. α, m and k are hyperparameters to tune. This pipeline is based on Lavrenko's relevance models <ref type="bibr" coords="6,461.98,268.72,15.50,8.74" target="#b12">[13]</ref> implemented in Indri <ref type="bibr" coords="6,228.99,280.67,9.96,8.74" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.6">Query and Document Expansion with UMLS</head><p>We also experimented with several approaches to query and document expansion using UMLS. UMLS provides a hierarchy between concepts through several relations including narrower than, synonymous to, and others. For query expansion, every concept was expanded by including concepts synonymous to or beneath them in the UMLS hierarchy. Negations were also propagated. For documents, the expansion was done upwards. On the 2011 test topics, we found out that this expansion strategy was detrimental to retrieval performance, regardless of the combination used (query only, document only, both). We thus excluded this strategy from the submitted runs. More intelligently targeted expansion, such as expansion limited to specific concept categories, would likely have been more successful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>Submissions to the TREC 2012 Medical Records track were evaluated by judging the relevance of their submitted results on 47 given queries. The main evaluation metric used is infAP. The inferred normalized discounted cumulative gain (infNDCG), R-precision and the precision at 10 (P@10) were also reported. Before the final submission, we used the 34 test queries and their associated relevance judgments from the 2011 track to perform hyper-parameter tuning, model selection and the evaluation of various possible configurations. Table <ref type="table" coords="6,161.17,582.26,4.98,8.74">2</ref> provides the list of our retrieval variants. Table <ref type="table" coords="6,175.66,594.21,4.98,8.74" target="#tab_0">3</ref> summarizes the retrieval performance of various configurations from Table <ref type="table" coords="6,160.65,606.17,4.98,8.74">2</ref> on the TREC 2011 medical test topics. For each retrieval configuration, we tuned the hyper-parameters to optimize the sum of the averaged bpref and R-prec metrics <ref type="bibr" coords="6,200.02,630.08,9.96,8.74" target="#b0">[1]</ref>. The value range tried for the hyper-parameters of the vector space retrieval (i.e. k 1 and b) and language model retrieval (i.e. µ) models are based on the suggestions by <ref type="bibr" coords="6,280.42,653.99,9.96,8.74" target="#b3">[4]</ref>. We can see that, in general, the UMLS concept based representation gives better retrieval performance, when compared</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Submitted runs Term Representation</head><p>Indexing &amp; Ranking sennamed1 UMLS concept language model retrieval, query expansion sennamed2 UMLS concept vector space retrieval, query expansion sennamed3 UMLS concept vector space retrieval sennamedlsi UMLS concept vector space retrieval, LSI Other runs sennamed-4 UMLS concept language model retrieval sennamed-5 UMLS concept + raw text language model retrieval, query expansion sennamed-6 UMLS concept + raw text vector space retrieval, query expansion sennamed-7</p><p>UMLS concept + raw text vector space retrieval sennamed-8 UMLS concept + raw text language model retrieval sennamed-9 raw text vector space retrieval sennamed-A UMLS concept "learning to rank" retrieval Table <ref type="table" coords="7,224.55,345.09,3.87,8.74">2</ref>: Various retrieval configurations we tried.</p><p>with "raw text" or "raw text + UMLS". Finally we selected four different runs (sennamed1, sennamed2, sennamed3 and sennamedlsi) which reflect the various techniques we tried. We use the best selected parameters of these models (based on 2011 track) to rank EMRs for 47 queries requested for the 2012 track. Table <ref type="table" coords="7,175.90,424.74,4.98,8.74" target="#tab_1">4</ref> provides an overview of the performance of our four submitted runs based on the relevance judgments for 47 test topics in 2012 medical track. We can see that the performance difference between these four runs on 2012 test queries are quite consistent with their relative differences on the 2011 test collection. Table <ref type="table" coords="7,196.81,472.56,4.98,8.74" target="#tab_3">6</ref> shows the number of topics in which our best run (sennamed2) was the best, above median, on par with the median, lower than the median, or the worst among all submitted runs, across the four main performance metrics. Finally, tables 7 and 8 compare our best run in terms of the infAP and P@10 for each topic versus the best, median and worst runs among all 2012 submissions. Table <ref type="table" coords="7,161.81,532.33,4.98,8.74" target="#tab_2">5</ref> lists the best five run among all submissions for 2012 TREC medical track. We can see that overall, sennamed2 ranks second amongst all automatic submissions, and third amongst all runs <ref type="bibr" coords="7,311.27,556.24,14.61,8.74" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>Overall, our submission sennamed2 obtained the best infAP score on 5 of the 47 test topics, and did better than the median on 27 others. This is rather surprising given the simplicity of the approach. To better understand the performance, we present in Table <ref type="table" coords="7,219.52,646.88,4.98,8.74" target="#tab_3">6</ref> the comparison of sennamed2 based on the number of topics in a given performance metric. In addition, Table <ref type="table" coords="7,366.52,658.83,4.98,8.74" target="#tab_4">7</ref>  The majority of the errors were due to a lack of higher level query understanding. Our system could not properly interpret constraints such as "[. . . ] developed disseminated intravascular coagulation in the hospital". Along similar lines, temporal aspects were also ignored, such as the one in topic 177: "Patients treated for depression after myocardial infarction".</p><p>While negation detection was useful, a more sophisticated approach that also takes uncertainty into account would have fared better. As is, our system cannot make the difference between "The patient was tested for disseminated intravascular coagulation" and an actual diagnosis of disseminated intravascular coagulation. Furthermore, the scope of negation detection was limited to a single sentence, whereas negations sometimes occur past sentence boundaries.</p><p>Finally, errors in MetaMap's concept detection also accounted for some of our errors. Despite its overall reliability, certain topics proved problematic. For instance, in topic 137, "TNF-inhibitor treatments" was converted to two concepts -"inhibitor" and "treatments" -discarding the "TNF" part. Another example is topic 179, where "atypical antipsychotics without a diagnosis schizophrenia" became "atypical schizophrenia (negated)" and "antipsychotics". In the end, it may be better to combine UMLS concepts with the original text, albeit with a more elaborate approach than simple concatenation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>The NECLA team submitted four runs to the Medical Records track at TREC 2012. We experimented with a set of techniques including dimensionality reduction, medical concept detection, query expansion and various document retrieval approaches for this task. Among our four submitted runs, the best results were achieved using a combination of medical concept detection, vector-space retrieval model and query expansion using pseudo-relevance feedback. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,374.64,658.83,102.85,8.74"><head>Table 3 :</head><label>3</label><figDesc>and Table8present the Performance of our retrieval runs on the 2011 test topics. The term representation and methods of ranking/indexing are listed in Table2.</figDesc><table coords="8,139.75,128.76,373.49,255.46"><row><cell cols="5">Run / Metric bpref R-prec P@10 infAP</cell><cell></cell></row><row><cell cols="2">sennamed1</cell><cell cols="3">0.5012 0.3755 0.5176 0.3322</cell><cell></cell></row><row><cell cols="2">sennamed2</cell><cell cols="3">0.5761 0.4196 0.5129 0.3912</cell><cell></cell></row><row><cell cols="2">sennamed3</cell><cell cols="3">0.5033 0.3839 0.4735 0.3314</cell><cell></cell></row><row><cell cols="2">sennamedlsi</cell><cell cols="3">0.5308 0.3327 0.4118 0.3108</cell><cell></cell></row><row><cell cols="2">sennamed-4</cell><cell cols="3">0.4619 0.3448 0.4706 0.2987</cell><cell></cell></row><row><cell cols="2">sennamed-5</cell><cell>0.4474</cell><cell>0.321</cell><cell>0.4794 0.2964</cell><cell></cell></row><row><cell cols="2">sennamed-6</cell><cell cols="3">0.5362 0.4026 0.5088 0.3954</cell><cell></cell></row><row><cell cols="2">sennamed-7</cell><cell>0.4886</cell><cell>0.384</cell><cell>0.4824 0.3697</cell><cell></cell></row><row><cell cols="2">sennamed-8</cell><cell cols="3">0.4444 0.3181 0.4706 0.2966</cell><cell></cell></row><row><cell cols="2">sennamed-9</cell><cell cols="3">0.4388 0.3384 0.4735 0.3157</cell><cell></cell></row><row><cell cols="5">sennamed-A 0.4782 0.3156 0.3912 0.2669</cell><cell></cell></row><row><cell cols="7">Metric / Run Name sennamed1 sennamed2 sennamed3 sennamedlsi median</cell></row><row><cell>infAP</cell><cell cols="2">0.2246</cell><cell>0.2745</cell><cell>0.2169</cell><cell>0.2151</cell><cell>0.1695</cell></row><row><cell>infNDCG</cell><cell cols="2">0.4780</cell><cell>0.5468</cell><cell>0.4688</cell><cell>0.4468</cell><cell>0.4243</cell></row><row><cell>R-prec</cell><cell cols="2">0.3457</cell><cell>0.3805</cell><cell>0.3298</cell><cell>0.2974</cell><cell>0.2935</cell></row><row><cell>P@10</cell><cell cols="2">0.5255</cell><cell>0.5574</cell><cell>0.5447</cell><cell>0.4468</cell><cell>0.4702</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,133.77,399.33,343.72,52.52"><head>Table 4 :</head><label>4</label><figDesc>Performance metrics for four submitted runs, compared with the median over all teams on the 2012 test topics.</figDesc><table coords="8,133.77,443.11,118.83,8.74"><row><cell>performance of sennamed2.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,133.77,128.76,353.26,196.88"><head>Table 5 :</head><label>5</label><figDesc>Performance metrics for our best run sennamed2, compared with the best four other runs among all teams on the 2012 test topics<ref type="bibr" coords="9,400.07,228.33,14.61,8.74" target="#b13">[14]</ref>. Manual runs are marked with a star(*).</figDesc><table coords="9,139.75,128.76,347.28,196.88"><row><cell cols="4">Run Name / Metric infNDCG infAP P@10</cell><cell></cell><cell></cell></row><row><cell>NLMManual*</cell><cell></cell><cell>0.680</cell><cell>0.366 0.749</cell><cell></cell><cell></cell></row><row><cell>udelSUM</cell><cell></cell><cell>0.578</cell><cell>0.286 0.592</cell><cell></cell><cell></cell></row><row><cell>sennamed2</cell><cell></cell><cell>0.547</cell><cell>0.275 0.557</cell><cell></cell><cell></cell></row><row><cell>ohsuManBool*</cell><cell></cell><cell>0.526</cell><cell>0.250 0.611</cell><cell></cell><cell></cell></row><row><cell>atigeo1</cell><cell></cell><cell>0.524</cell><cell>0.224 0.519</cell><cell></cell><cell></cell></row><row><cell cols="6">Metric / Number of topics Worst &lt; median = median &gt; median best</cell></row><row><cell>infAP</cell><cell>0</cell><cell>13</cell><cell>2</cell><cell>27</cell><cell>5</cell></row><row><cell>infNDCG</cell><cell>0</cell><cell>13</cell><cell>1</cell><cell>27</cell><cell>6</cell></row><row><cell>R-prec</cell><cell>2</cell><cell>10</cell><cell>6</cell><cell>24</cell><cell>5</cell></row><row><cell>P@10</cell><cell>4</cell><cell>7</cell><cell>12</cell><cell>13</cell><cell>11</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,133.77,340.75,343.71,20.69"><head>Table 6 :</head><label>6</label><figDesc>Comparison of sennamed2 based on the number of topics in a given performance metric.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,133.77,499.07,343.71,56.56"><head>Table 7 :</head><label>7</label><figDesc>This simple pipeline obtained a final infAP score of 0.2745, compared to the median infAP score 0.1695 of all automatic submissions. Our best run, sennamed2 ranks as the third over all 2012 TREC Medical track submissions, and second if we only take automatic runs into account.</figDesc><table coords="10,202.40,128.76,206.45,603.71"><row><cell>topic</cell><cell>best</cell><cell cols="3">median worst sennamed2</cell></row><row><cell>136</cell><cell cols="2">0.5724 0.0492</cell><cell>0</cell><cell>0.0494</cell></row><row><cell>137</cell><cell>0.0155</cell><cell>0</cell><cell>0</cell><cell>0.0113</cell></row><row><cell>139</cell><cell cols="2">0.6906 0.2046</cell><cell>0</cell><cell>0.6634</cell></row><row><cell>140</cell><cell cols="2">0.5122 0.2554</cell><cell>0</cell><cell>0.2387</cell></row><row><cell>141</cell><cell cols="2">0.4549 0.1307</cell><cell>0</cell><cell>0.22</cell></row><row><cell>142</cell><cell cols="2">0.3092 0.1492</cell><cell>0</cell><cell>0.1856</cell></row><row><cell>143</cell><cell>0.6229</cell><cell>0.458</cell><cell>0.0064</cell><cell>0.5253</cell></row><row><cell>144</cell><cell cols="2">0.1723 0.0804</cell><cell>0</cell><cell>0.1194</cell></row><row><cell>145</cell><cell cols="2">0.6206 0.4394</cell><cell>0</cell><cell>0.5948</cell></row><row><cell>146</cell><cell cols="2">0.4338 0.0132</cell><cell>0</cell><cell>0.4338</cell></row><row><cell>147</cell><cell cols="3">0.2012 0.0737 0.0027</cell><cell>0.1873</cell></row><row><cell>148</cell><cell cols="2">0.5584 0.3994</cell><cell>0</cell><cell>0.4839</cell></row><row><cell>149</cell><cell>0.092</cell><cell cols="2">0.0291 0.0004</cell><cell>0.0742</cell></row><row><cell>150</cell><cell cols="2">0.8196 0.5237</cell><cell>0</cell><cell>0.516</cell></row><row><cell>151</cell><cell cols="2">0.0552 0.0058</cell><cell>0</cell><cell>0.0026</cell></row><row><cell>152</cell><cell cols="2">0.1299 0.0475</cell><cell>0</cell><cell>0.028</cell></row><row><cell>153</cell><cell cols="2">0.5716 0.2226</cell><cell>0</cell><cell>0.3607</cell></row><row><cell>154</cell><cell cols="3">0.4681 0.0601 0.0002</cell><cell>0.0052</cell></row><row><cell>155</cell><cell cols="2">0.2033 0.0664</cell><cell>0</cell><cell>0.2033</cell></row><row><cell>156</cell><cell cols="3">0.1115 0.0548 0.0031</cell><cell>0.0469</cell></row><row><cell>157</cell><cell cols="2">0.4214 0.0493</cell><cell>0</cell><cell>0.1897</cell></row><row><cell>158</cell><cell cols="2">0.7885 0.2801</cell><cell>0</cell><cell>0.7237</cell></row><row><cell>160</cell><cell cols="3">0.2486 0.0624 0.0002</cell><cell>0.2486</cell></row><row><cell>161</cell><cell cols="2">0.8444 0.1152</cell><cell>0</cell><cell>0.754</cell></row><row><cell>162</cell><cell cols="3">0.0725 0.0463 0.0031</cell><cell>0.047</cell></row><row><cell>163</cell><cell>0.2402</cell><cell>0.098</cell><cell>0</cell><cell>0.2402</cell></row><row><cell>164</cell><cell cols="2">0.7426 0.4514</cell><cell>0</cell><cell>0.6468</cell></row><row><cell>165</cell><cell cols="2">0.4974 0.2518</cell><cell>0</cell><cell>0.3978</cell></row><row><cell>167</cell><cell>0.4324</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>168</cell><cell cols="3">0.1458 0.0355 0.0007</cell><cell>0.0274</cell></row><row><cell>169</cell><cell cols="3">0.5277 0.4435 0.0363</cell><cell>0.5069</cell></row><row><cell>170</cell><cell cols="2">0.8474 0.5386</cell><cell>0</cell><cell>0.6471</cell></row><row><cell>171</cell><cell cols="2">0.6934 0.2177</cell><cell>0</cell><cell>0.6202</cell></row><row><cell>172</cell><cell cols="3">0.2474 0.0699 0.0006</cell><cell>0.0606</cell></row><row><cell>173</cell><cell>0.358</cell><cell>0.0423</cell><cell>0</cell><cell>0.0099</cell></row><row><cell>174</cell><cell>0.2768</cell><cell>0.094</cell><cell>0</cell><cell>0.0555</cell></row><row><cell>175</cell><cell cols="2">0.7323 0.3622</cell><cell>0</cell><cell>0.4571</cell></row><row><cell>176</cell><cell cols="2">0.1819 0.0403</cell><cell>0</cell><cell>0.0697</cell></row><row><cell>177</cell><cell cols="3">0.4027 0.0385 0.0037</cell><cell>0.0349</cell></row><row><cell>178</cell><cell cols="2">0.9055 0.6168</cell><cell>0</cell><cell>0.7892</cell></row><row><cell>179</cell><cell>0.0674</cell><cell>0.001</cell><cell>0</cell><cell>0.028</cell></row><row><cell>180</cell><cell cols="2">0.5294 0.2877</cell><cell>0</cell><cell>0.3262</cell></row><row><cell>181</cell><cell cols="2">0.4044 0.0252</cell><cell>0</cell><cell>0.4044</cell></row><row><cell>182</cell><cell cols="3">0.1062 0.0761 0.0036</cell><cell>0.0657</cell></row><row><cell>183</cell><cell cols="2">0.3542 0.0903</cell><cell>0</cell><cell>0.0689</cell></row><row><cell>184</cell><cell cols="3">0.5762 0.2946 0.0041</cell><cell>0.2946</cell></row><row><cell>185</cell><cell cols="2">0.6571 0.0754</cell><cell>0</cell><cell>0.2375</cell></row><row><cell cols="4">Mean 0.4238 0.1695 0.0014</cell><cell>0.2745</cell></row></table><note coords="10,174.71,748.13,302.77,8.74;10,133.77,760.09,343.71,8.74;10,133.77,772.04,51.47,8.74"><p>Comparison of sennamed2 to best/median/worse of all teams on the 2012 test topics, in term of infAP for every topic. Number in bold when above the median.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,149.01,655.54,139.73,6.64"><p>http://www.dbmi.pitt.edu/nlpfront</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,154.25,601.66,323.23,8.74;9,154.25,613.62,323.23,8.74;9,154.25,625.57,22.69,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,277.22,601.66,200.26,8.74;9,154.25,613.62,20.78,8.74">Overview of the TREC 2011 medical records track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,200.65,613.62,270.62,8.74">The Twentieth Text REtrieval Conference Proceedings TREC</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,154.25,645.50,323.23,8.74;9,154.25,657.45,200.00,8.74" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="9,247.17,645.50,230.30,8.74;9,154.25,657.45,169.07,8.74">Effective mapping of biomedical text to the umls metathesaurus: The metamap program</title>
		<author>
			<persName coords=""><forename type="first">Alan</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.25,127.96,323.23,8.74;12,154.25,139.92,267.52,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,309.16,127.96,168.32,8.74;12,154.25,139.92,18.64,8.74">The representation of meaning in the umls</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Mccray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">J</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,181.97,139.92,154.43,8.74">Methods of information in medicine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page">193</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.25,158.81,323.23,8.74;12,154.25,170.76,323.23,8.74;12,154.25,182.72,323.23,8.74;12,154.25,194.67,83.30,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,304.56,158.81,172.92,8.74;12,154.25,170.76,39.88,8.74">A formal study of information retrieval heuristics</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">X</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,219.29,170.76,258.18,8.74;12,154.25,182.72,290.56,8.74">Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 27th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.25,213.57,323.23,8.74;12,154.25,225.52,244.35,8.74" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="12,306.18,213.57,171.30,8.74;12,154.25,225.52,76.51,8.74">The probabilistic relevance framework: BM25 and beyond</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Now Publishers Inc</publisher>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.25,244.41,323.23,8.74;12,154.25,256.37,323.24,8.74;12,154.25,268.32,323.23,8.74;12,154.25,280.28,208.38,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,257.29,244.41,220.18,8.74;12,154.25,256.37,168.68,8.74">A study of smoothing methods for language models applied to ad hoc information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,344.13,256.37,133.35,8.74;12,154.25,268.32,323.23,8.74;12,154.25,280.28,80.78,8.74">Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 24th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="334" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.25,299.17,323.23,8.74;12,154.25,311.13,323.23,8.74;12,154.25,323.08,323.23,8.74;12,154.25,335.04,65.42,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,154.25,311.13,288.20,8.74">Indri: a language-model based search engine for complex queries</title>
		<author>
			<persName coords=""><forename type="first">Trevor</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Howard</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,223.42,323.08,254.06,8.74;12,154.25,335.04,35.03,8.74">Proceedings of the International Conference on Intelligent Analysis</title>
		<meeting>the International Conference on Intelligent Analysis</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="12,154.25,353.93,323.24,8.74;12,154.25,365.88,229.77,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,204.59,353.93,187.17,8.74">Learning to rank for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,403.86,353.93,73.63,8.74;12,154.25,365.88,138.17,8.74">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="225" to="331" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.25,384.77,323.23,8.74;12,154.25,396.73,323.23,8.74;12,154.25,408.69,323.23,8.74;12,154.25,420.64,162.43,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,306.39,396.73,128.19,8.74">Supervised semantic indexing</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Sadamasa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,458.37,396.73,19.11,8.74;12,154.25,408.69,323.23,8.74;12,154.25,420.64,33.83,8.74">Proceeding of the 18th ACM conference on Information and knowledge management</title>
		<meeting>eeding of the 18th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="187" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.25,439.53,323.23,8.74;12,154.25,451.49,323.23,8.74;12,154.25,463.44,148.48,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,448.34,439.53,29.14,8.74;12,154.25,451.49,178.44,8.74">Harshman. Indexing by latent semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,339.77,451.49,137.70,8.74;12,154.25,463.44,102.05,8.74">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.25,479.82,323.23,11.26;12,154.25,494.29,323.24,8.74;12,154.25,506.25,323.23,8.74;12,154.25,518.20,241.75,9.02" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,299.04,482.34,178.44,8.74;12,154.25,494.29,84.45,8.74">Software Framework for Topic Modelling with Large Corpora</title>
		<author>
			<persName coords=""><forename type="first">Radim</forename><surname>Řehůřek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Petr</forename><surname>Sojka</surname></persName>
		</author>
		<ptr target="http://is.muni.cz/publication/884893/en" />
	</analytic>
	<monogr>
		<title level="m" coord="12,260.81,494.29,216.68,8.74;12,154.25,506.25,139.42,8.74">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</title>
		<meeting>the LREC 2010 Workshop on New Challenges for NLP Frameworks<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-05">May 2010</date>
			<biblScope unit="page" from="45" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.25,537.09,323.23,8.74;12,154.25,549.05,323.23,8.74;12,154.25,561.00,323.23,8.74;12,154.25,572.96,162.17,8.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,343.17,537.09,134.31,8.74;12,154.25,549.05,127.93,8.74">Selecting good expansion terms for pseudo-relevance feedback</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,305.13,549.05,172.34,8.74;12,154.25,561.00,323.23,8.74;12,154.25,572.96,34.57,8.74">Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 31st annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="243" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.25,591.85,323.23,8.74;12,154.25,603.81,323.23,8.74;12,154.25,615.76,305.39,8.74" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,281.48,591.85,141.02,8.74">Relevance based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,441.57,591.85,35.91,8.74;12,154.25,603.81,323.23,8.74;12,154.25,615.76,177.78,8.74">Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 24th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.25,634.65,323.23,8.74;12,154.25,646.61,323.23,8.74;12,154.25,658.56,22.69,8.74" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,280.14,634.65,197.34,8.74;12,154.25,646.61,20.78,8.74">Overview of the TREC 2012 medical records track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,195.32,646.61,275.95,8.74">The Twenty First Text REtrieval Conference Proceedings TREC</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
