<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,206.28,83.17,182.87,12.64">PRIS at 2012 Microblog Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,127.68,107.51,54.00,9.50"><forename type="first">Jiayue</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,189.23,107.51,41.81,9.50"><forename type="first">Sijia</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,238.20,107.51,31.75,9.50"><forename type="first">Yue</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,276.85,107.51,27.45,9.50"><forename type="first">Jie</forename><surname>Yin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,311.30,107.51,62.44,9.50"><forename type="first">Qianqian</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,381.49,107.51,43.05,9.50"><forename type="first">Weiran</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,432.26,107.51,35.41,9.50"><forename type="first">Jun</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,206.28,83.17,182.87,12.64">PRIS at 2012 Microblog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">116461208759204714885771AFB82D1C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Take account of that most tags are keyword rich and indicate the topic of tweets directly, but there was no space between two words. So Word Segmentation was used to separate the tags by space. This time we used the former max matching algorithm. The problem is that no dictionary is appropriate. Common words dictionary is partial and Oxford Dictionary doesn't distinguish plurality. Then we made a combination of Common words dictionary, Oxford Dictionary and D.A.B(Dictionary of American Biography).But due to abbreviation and unknown words, there is still some mistakes. To avoid undesirable influence from these mistakes, we remained both the original tags and separated tags.</p><p>Two pre-processing tasks were performed in our system: RT tweets removal and non-English tweets removal. We first extracted user remarks and remove the label "RT". The "new style" re-tweets to which the HTTP crawler returned 302 were all removed. When URLs and punctuation were removed, each tweet was judged to be English or non-English with the help of an English vocabulary word list, Alan Beale's Core Vocabulary. A tweet with more than a half English words would be left and used for retrieval task while tweets with any non-English content were rejected in the query expansion task. After pre-processing, tweets' and websites' index was built with Indri.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Query Expansion</head><p>In the retrieval process for the retrieval of a query, it is needed to return the most relevant microblog results. There is a kind of words is very much associated with the query, the kind of word is a synonym of the query. The synonym of the query in order to find the most important step is to find a reliable comprehensive thesaurus. This time we choose WordNet, a thesaurus. WordNet is a large lexical database of English. Nouns, verbs, adverbs and adjectives are organized by semantic relations into synonym sets (synsets), each representing one concept. We select all of the synonyms of each word in the query for each query depending on the part of speech. The result of the synonym expansion would be added to the former result of query expansion by other means.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Query Formulation 1 Analyzing tweets using electric resistance network</head><p>In this task, electric resistance network was applied to query expansion. We used the tweets retrieved from indri as the corpus and calculated the effective resistance and distance metrics.</p><p>(1)To building an association network from related tweets, We built an undirected weighed graph G = (V;E;w) where nodes V represent terms in tweets, edges E represent the associated pair, and weight w on the edges measures the strength of association between two connected nodes. If two terms co-occur in one tweet, a direct link is built between them. If these two terms co-occur in n (n&gt;0) different tweets, the weight w is n. (2) The weight wjk between node j and node k was calculated according to the electric conductance cjk defined in the original weighted graph: rjk = 1/cjk= 1/wjk. For all possible pairs, we calculated the resistances with the help of Laplacian Graph L and L = A-D, where A is the adjacency matrix and D is the degree matrix of the graph. Then the effective resistance between node vj and node vk can be calculated as follows: rjk = L+jj + L+kk -L+jk -L+kj (3) where L+ represents the pseudo-inverse of L.</p><p>(3) The definition of the distance between a target term t and a term set S is as follows:</p><p>where rij is the effective resistance of node i and node j. As for the query, we define Q and X as query term set and corpus term set respectively. And for a target term x, its normalized distance to Q can be calculated as follows:</p><p>2 Analyzing links using latent Dirichlet allocation There are 2 kinds of links we took into consideration, links of retrieved tweets and links retrieved from indri. We used LDA to analyze these 2 kinds of links separately, and then integrate the results. 3 Design of the adaptive threshold system As to the filtering task, we designed an adaptive threshold system to simulate actual situation. First we manually set the initial threshold for each query with the same value. Those tweets with score higher than threshold were labeled with 'yes' and we checked relevance of this tweet to adjust the threshold. If the yes-labeled tweet was indeed relevant, we labeled it with 'right'; on the other hand, we labeled it with it can help automatically tune parameters when combining multiple evidences (e.g., text relevance, local sensitivity, URL quality, spam score, etc.) and avoid over-fitting by means of regularization.</p><p>The overall tweet score was equal to ∑ 𝐹𝑒𝑎𝑡𝑢𝑟𝑒𝑊𝑒𝑖𝑔ℎ𝑡 𝑖 × 𝐹𝑒𝑎𝑡𝑢𝑟𝑒𝑆𝑐𝑜𝑟𝑒 𝑖 𝑁 𝑖 , where FeatureWeight i was a configurable parameter and ∑ FeatureWeight i N i = 1. Each FeatureScore i evaluated a field-specific relevance feature. N was the total number of features. There were five fields: keywords, expanded words, entity, URL, hash-tag. For each field, we used the following features:</p><p>1. keyword_score -the percentage of keywords which a tweet contained for the target topic. 2. expandword_score -the percentage of expanded words which a tweet contained for the target topic.</p><p>3. entity_score -Since a named entity (e.g., people, products, location, etc.) in a query indicated the main part of the topic, this feature was used to highlight the contribution of target entities in the queries. 4. URL_score -A URL represented the potential information of a tweet, and the relevance score of linked text would also be added to the score. 5. hashtag_score -The hash-tags indicated the key words of tweets. But a tweet made up of all hash-tags would be spam. So this feature was used for key-word emphasizing and spam detection.</p><p>Our approach trained learning to rank with 50 iterations on the TREC Micro-blog Ad-hoc Task Evaluation Data last year. Then we ranked tweets for each topic according to the score in the descending order. Finally, we chose top n tweets in the ranking list as the relevant tweets.</p><p>[1] Yan Li, Zhenhua Zhang, Wenlong Lv. PRIS at TREC2011 Micro-blog Track.</p><p>Proceedings of Text REtrieval Conference 2011.</p><p>[2] Massih Reza Amini, Tuong Vinh Truong, Cyril Goutte. A boosting algorithm for learning bipartite ranking functions with partially labeled data. Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, July 20-24, 2008, Singapore, Singapore.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0" coords="2,90.00,606.20,415.32,10.80;2,90.00,621.80,415.25,10.80;2,90.00,637.40,415.30,10.80;2,90.00,653.00,117.12,10.80;2,90.00,675.97,137.33,12.64;2,111.00,701.00,394.20,10.80;2,90.00,718.88,415.20,10.80;2,90.00,736.88,415.44,10.80;2,90.00,754.76,418.32,10.80"><p>'wrong'. If there were too many labeled-wrong tweets/too less labeled-right tweets, we raised/lowered the threshold and adjustment was determined by the average value of labeled-right/wrong tweets, threshold before adjusting and a constant coefficient which was set manually.4 Scoring and RankingLast year we used a formula [1] to evaluate the relevance of a tweet to a certain topic, which combined five factors with manually tuned parameters for weighting.However, this year we used a learning to rank algorithm which computed an optimized ranking using SEMI-SUPERVISED BIPARTITE RANKING[2]. Therefore,</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
