<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,157.22,92.96,280.82,15.96">ICTNET at Microblog Track TREC 2012</title>
				<funder ref="#_umSWzcy #_7b98hT4 #_T7xaKht">
					<orgName type="full">NSF of China</orgName>
				</funder>
				<funder ref="#_THbJ5cB">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder>
					<orgName type="full">NIST</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,100.82,121.70,48.03,10.56"><forename type="first">Bolong</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,162.62,121.70,52.01,10.56"><forename type="first">Jinghua</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,228.40,121.70,37.95,10.56"><forename type="first">Xiao</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.00,121.70,45.31,10.56"><forename type="first">Cunhui</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,333.79,121.70,57.05,10.56"><forename type="first">Shenghua</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,399.31,121.70,30.15,10.56"><forename type="first">Yue</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,437.94,121.70,53.12,10.56"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,157.22,92.96,280.82,15.96">ICTNET at Microblog Track TREC 2012</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E63892B536BC3ABC046798DE34C66EE9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>There are two search tasksin TREC2012 Microblog Track <ref type="bibr" coords="1,356.35,203.72,8.02,6.96" target="#b0">[1]</ref> , namely: Real-time Adhoc and Real-time Filtering.The Tweets2011 corpus is used again and last year's results can be used as first officiallylabeled data for any participants to traintheir models.In this year's track, the former task has60 new queriesgiven and the latter is first proposed.</p><p>In the Real-time Adhoc task, we use indri retrieval toolkit <ref type="bibr" coords="1,351.55,266.12,8.02,6.96" target="#b1">[2]</ref> to construct our retrieval system and propose a strategy of pseudo relevance feedback to expand original query,then we retrieved original tweets and their indri's scores as an important feature.Besides, we calculate lots of other features of these tweets, such abouturl, hash_tag, entropy, tfidf, bm25, language model <ref type="bibr" coords="1,477.70,312.95,8.02,6.96" target="#b2">[3]</ref> and proximity <ref type="bibr" coords="1,130.46,328.55,8.02,6.96" target="#b3">[4]</ref> .At last, we use two learning-to-rank methods, specifically RankSVM <ref type="bibr" coords="1,434.35,328.55,8.02,6.96" target="#b4">[5]</ref> and ListNet <ref type="bibr" coords="1,494.74,328.55,8.02,6.96" target="#b5">[6]</ref> , to combine all those featuresto sort them, returning the final ranked tweets to a specified query.</p><p>In the Real-time Filtering task, we assuming this task is similar with the topic tracking in Twitter Stream <ref type="bibr" coords="1,120.62,375.35,8.02,6.96" target="#b6">[7]</ref> , we build up two filtering modelsbased on language modeland Vector Space Modelrespectively. Each model is initialized by the start query and its relevant tweets. For each new coming tweet, the model will decide whether it is under thetopic. If it is, we update the model to keep up with the development of the topic.</p><p>The rest of this paper is organized as follows. In Section 2, we discuss the preprocessing of Tweets2011 corpus. In Section 3, the main method to rank the search results in Real-time Adhoc task is discussed. In Real-time Filtering task, we describe two filtering models in Section 4. Experiment resultsare reported in Section 5. And in the last section, we draw conclusions about our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Data preprocessing</head><p>We use our last year's preprocessed corpus <ref type="bibr" coords="1,294.41,553.33,8.02,6.96" target="#b7">[8]</ref> . As tweets can be deleted or protected after posting, we additionally use an updating tweet ids list to remove tweets deleted from the corpus recently.Besides, word stemming is reprocessed and stop word removing is not processed as this will cause a large portion of information in such short text lost.Finally, there are 7,443,387tweets in our data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Real-time Adhoc</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Query expansion</head><p>We leverage both internal and external expansions.In internal expansion, we assume the retrievedtop tweets which have themost ranking scores are more relevant to the topic.When viewing the top tweets as a document, we can estimate each word's new weight according to,</p><formula xml:id="formula_0" coords="2,163.82,79.98,267.71,31.39">Weight(T) = ğ‘–ğ‘‘ğ‘“(ğ‘‡) ğ‘†ğ‘¢ğ‘š_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’(ğ·(ğ¾)) * âˆ‘ ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘‘) * ğ‘¡ğ‘“(ğ‘‘, ğ‘‡) ğ‘‘ğœ–ğ·(ğ¾)</formula><p>whereD(K) indicates the top-K returned tweets from the original query, Sum_Score(D(K)) is the sum of top-K tweets' scores, tf(d, T) is the term frequency of T in tweet d and idf(T) is the global inverse document frequency of term T in the corpus. Besides, we use term concurrency frequency in the corpusas a second method to choose expansion words, their weights are estimated in following formula, where tc(T) indicates the frequency of term T concurrency with query terms, and it is normalized byâˆ‘ ğ‘¡ğ‘(ğ‘¡) ğ‘¡âˆˆğ‘‘ .</p><formula xml:id="formula_1" coords="2,159.38,220.40,276.71,31.37">Weight(T) = 1 ğ‘†ğ‘¢ğ‘š_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’(ğ·(ğ¾)) * âˆ‘ ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘‘) * ğ‘¡ğ‘(ğ‘‡) âˆ‘ ğ‘¡ğ‘(ğ‘¡) ğ‘¡âˆˆğ‘‘ ğ‘‘ğœ–ğ·(ğ¾)</formula><p>In external expansion, we use Google Search Engine to fetch result page of the original query. All wordsoccurred in top three links' titles are chosen to be the expansion words.</p><p>At last, we use Indri Retrieval Language to combine these expansion words and original query considering their new weights <ref type="bibr" coords="2,217.85,307.19,7.77,6.96" target="#b8">[9]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Features</head><p>We used two types of features, including static features (query independent) and dynamic features (query dependent, in both original and expanded queries, proximity features are only in original queries).For every result tweet, there are totally 51 features to be estimated (listing in the following tables). As the pages are limited, we can't describe every feature in details.Fortunately, lots of features can be described by their names, so we only choose some namelessfeatures to describe.</p><p>In static features, indri_score is returnedfrom our Indri Retrieval System, oov_ratio is the ratio of out-of-vocabulary words count over the total words count, unique_word_ratio is similar to oov_ratio.</p><p>In dynamic features, tf value is query term frequencyin a tweet,tf-idf value is the query termtf-idf weight in a tweet. boolean_model, vsm, bm25, lmir (language model for IR) are the scores of the query to a tweet under these retrieval models.In lmir, three smoothing methods are used respectively, including DirichletPrior(dir), Jelinek-Mercer(jm) and Absolute Discounting(abs). We also estimate query proximity in a tweet. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Learning to Rank Methods</head><p>We utilize a simple linear learning-to-rank model to combine all these aforementionedfeatures. Given a query Q and a tweet D, a relevance score s(Q,D) is computed according to:</p><formula xml:id="formula_2" coords="3,245.69,151.82,104.12,36.60">s(Q, D) = âˆ‘ ğœ† ğ‘– ğ‘“ ğ‘– (ğ‘„, ğ·) ğ‘ ğ‘–</formula><p>where N is the total number of features,ğ‘“ ğ‘– (ğ‘„, ğ·)is a feature value andğœ† ğ‘– is a model parameter. Given a query Q, tweets D are ranked in descending order of their relevance score. To estimate model parameters, we use two types of learning-to-rank approaches, specifically RankSVM <ref type="bibr" coords="3,482.14,224.96,8.02,6.96" target="#b4">[5]</ref> for Pairwise approach and ListNet <ref type="bibr" coords="3,222.05,240.56,8.02,6.96" target="#b5">[6]</ref> for Listwise approach. Last year's queries and results are used for training, and 5-fold cross-validation is utilized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Real-time Filtering</head><p>We assume this task is similar with the topic tracking in Twitter Stream <ref type="bibr" coords="3,407.71,309.35,8.02,6.96" target="#b6">[7]</ref> , however, there are some differences in our approach.</p><p>A quality score is defined as a static weight for each tweet. The quality score is used to measure the probability of whether a tweet's content is meaningful, and is treated as a global weight for each tweet. We adopted the logistic regression model to calculate the quality scores. The features consist of several static features extracted inAdhoc task. And the tweets of the given 10 training topics are used as learning samples.</p><p>Two different retrieval models are utilized to implement two filters respectively. In the filter based on language model, we choose stupid backoff as the smoothing technique and "queue" as the history retention technique <ref type="bibr" coords="3,224.57,449.75,8.02,6.96" target="#b6">[7]</ref> .In the filter based on vector space model, tf value is calculated in the "foreground" model and idf comes from the "background"model <ref type="bibr" coords="3,402.67,465.35,8.02,6.96" target="#b6">[7]</ref> , and we also use the "queue" strategy to retain history information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments and Results</head><p>In Real-time Adhoc task, 60 queries are tested and four runs are submitted with different query expansions and different learning-to-rank methods.Tfidf query expansion is used in ICTWDSERUN1, and concurrency frequency query expansion is used in ICTWDSERUN2. In both ICTWDSERUN3 and ICTWDSERUN4, we use google search results as query expansion. RankSVMmethod is used in both ICTWDSERUN1 and ICTWDSERUN3, while LiseNetmethod is used in both ICTWDSERUN2 and ICTWDSERUN4.For each topic we return 10000 tweets in ICTWDSERUN1, and 1000 in both ICTWDSERUN2 and ICTWDSERUN3, but in ICTWDSERUN4 the returned tweets' number is estimated by a k-means method. The following table shows our results.</p><p>Table <ref type="table" coords="3,205.01,676.60,2.82,10.56">I</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In Real-time Adhoc task, we propose 51 features and use them in two learning-to-rank models which are trained by last year's results of the task.Finally, four runs are submitted with different query expansions. In Real-time Filtering task, we construct two filtering models to track topic in the stream of tweets, two runs are submitted with different tracking models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,93.62,676.60,408.34,82.13"><head></head><label></label><figDesc>. Experiments Results in Real-time Adhoc Task Filtering task, 40 topics are tested and four runs are submitted with different retrieval models and initialized strategies.VSM is used in both ICTNETFTRUN1 and ICTNETFTRUN2, and Language Model is used in both ICTNETFTRUN3 and ICTNETFTRUN4. To initialize the original topic we only use data in the corpus in ICTNETTFRUN1 and ICTNETTFRUN3, while we use the top-3 Google search results as an external resource in ICTNETTFRUN2 and ICTNETTFRUN4. The following table shows our results.TableII. Experiments Results in Real-timeFiltering Task</figDesc><table coords="3,93.62,693.10,408.34,65.64"><row><cell cols="2">ICTWDSERUN4</cell><cell>ICTNET</cell><cell cols="2">0.2113 0.1650</cell><cell>automatic</cell><cell>yes</cell><cell>no</cell><cell>yes</cell></row><row><cell cols="2">In Real-time RUN group</cell><cell>Prec</cell><cell>Recl</cell><cell>F(0.5)</cell><cell>T11SU</cell><cell>manual?</cell><cell>RT?</cell><cell>docs?</cell><cell>extern?</cell></row><row><cell>ICTNETFTRUN1</cell><cell>ICTNET</cell><cell>0.1553</cell><cell cols="2">0.5020 0.1669</cell><cell>0.1265</cell><cell>automatic</cell><cell>yes</cell><cell>no</cell><cell>no</cell></row><row><cell>ICTNETFTRUN2</cell><cell>ICTNET</cell><cell>0.1513</cell><cell cols="2">0.5244 0.1630</cell><cell>0.1249</cell><cell>automatic</cell><cell>yes</cell><cell>no</cell><cell>yes</cell></row><row><cell>ICTNETFTRUN3</cell><cell>ICTNET</cell><cell>0.0000</cell><cell cols="2">0.3641 0.0000</cell><cell>0.0000</cell><cell>automatic</cell><cell>yes</cell><cell>no</cell><cell>no</cell></row><row><cell>ICTNETFTRUN4</cell><cell>ICTNET</cell><cell>0.0001</cell><cell cols="2">0.4933 0.0001</cell><cell>0.0000</cell><cell>automatic</cell><cell>yes</cell><cell>no</cell><cell>yes</cell></row><row><cell></cell><cell>RUN</cell><cell>group</cell><cell>P@30</cell><cell>MAP</cell><cell>manual?</cell><cell>RT?</cell><cell>docs?</cell><cell>extern?</cell></row><row><cell cols="2">ICTWDSERUN1</cell><cell>ICTNET</cell><cell cols="2">0.2384 0.2093</cell><cell>automatic</cell><cell>yes</cell><cell>no</cell><cell>no</cell></row><row><cell cols="2">ICTWDSERUN2</cell><cell>ICTNET</cell><cell cols="2">0.2339 0.1981</cell><cell>automatic</cell><cell>yes</cell><cell>no</cell><cell>no</cell></row><row><cell cols="2">ICTWDSERUN3</cell><cell>ICTNET</cell><cell cols="2">0.2113 0.1878</cell><cell>automatic</cell><cell>yes</cell><cell>no</cell><cell>yes</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank all organizers and assessors of <rs type="institution">TREC</rs> and <rs type="funder">NIST</rs>. This work is sponsored by <rs type="funder">NSF of China</rs> Grants No. <rs type="grantNumber">60933005</rs>, No. <rs type="grantNumber">61100083</rs> and No.<rs type="grantNumber">61173064</rs>, and by <rs type="programName">242 Program</rs> of China Grants No.<rs type="grantNumber">2011F65</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_umSWzcy">
					<idno type="grant-number">60933005</idno>
				</org>
				<org type="funding" xml:id="_7b98hT4">
					<idno type="grant-number">61100083</idno>
				</org>
				<org type="funding" xml:id="_T7xaKht">
					<idno type="grant-number">61173064</idno>
					<orgName type="program" subtype="full">242 Program</orgName>
				</org>
				<org type="funding" xml:id="_THbJ5cB">
					<idno type="grant-number">2011F65</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,104.18,511.15,325.23,10.56" xml:id="b0">
	<monogr>
		<ptr target="http://sites.google.com/site/trecmicroblogtrack/" />
		<title level="m" coord="4,104.18,511.15,90.74,10.56">TREC 2012 Microblog</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,104.29,526.75,251.48,10.56" xml:id="b1">
	<monogr>
		<ptr target="http://www.lemurproject.org/indri/" />
		<title level="m" coord="4,104.29,526.75,89.01,10.56">Indri Retrieval Toolkit</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.38,542.35,399.99,10.56;4,90.02,557.95,92.80,10.56" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,229.52,542.35,233.61,10.56">A language modeling approach to informationretrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,467.36,542.35,33.79,10.56">SIGIR&apos;93</title>
		<meeting><address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,107.54,573.55,397.78,10.56;4,90.02,589.15,192.11,10.56" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,204.65,573.55,263.17,10.56">An exploration of proximity measuresinformation retrieval</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,491.04,573.55,14.29,10.56;4,90.02,589.15,111.04,10.56">the Proceedings of SIGIR&apos;2007</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="295" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,106.70,604.75,398.71,10.56;4,90.02,620.35,307.12,10.56" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,164.40,604.75,227.44,10.56">Optimizing Search Engines Using Clickthrough Data</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,396.48,604.75,108.93,10.56;4,90.02,620.35,250.65,10.56">Proceedings of the ACM Conference on Knowledge Discovery andData Mining (KDD)</title>
		<meeting>the ACM Conference on Knowledge Discovery andData Mining (KDD)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,104.30,635.95,356.86,10.56" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="4,187.84,635.95,218.53,10.56">Learning to Rank: From PairwisetoListwiseApproach</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.38,651.55,399.95,10.56;4,90.02,667.18,190.22,10.56" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,246.93,651.55,258.40,10.56;4,90.02,667.18,127.32,10.56">Smoothingtechniques for adaptive online language models: Topictracking in tweet streams</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Morgan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,233.10,667.18,15.65,10.56">KDD</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,107.54,682.78,397.69,10.56;4,90.02,698.38,300.51,10.56" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,327.36,682.78,173.08,10.56">ICTNET at Microblog Track TREC 2011</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,90.02,698.38,269.71,10.56">Proceeddings of the 20th Text REtrieval Conference (TREC 2011)</title>
		<meeting>eeddings of the 20th Text REtrieval Conference (TREC 2011)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,106.22,713.98,399.15,10.56;4,90.02,729.58,171.42,10.56" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="4,191.87,713.98,170.63,10.56">USC/ISI at TREC 2011: Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,370.84,713.98,134.52,10.56;4,90.02,729.58,140.62,10.56">Proceeddings of the 20th Text REtrieval Conference (TREC 2011)</title>
		<meeting>eeddings of the 20th Text REtrieval Conference (TREC 2011)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
