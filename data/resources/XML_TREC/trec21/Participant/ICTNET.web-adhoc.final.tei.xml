<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,174.12,83.21,247.02,12.58">ICTNET at Web Track 2012 Ad-hoc Task</title>
				<funder ref="#_vCYVK47 #_ruTYVKB #_hhyzMXc">
					<orgName type="full">NSF of China</orgName>
				</funder>
				<funder ref="#_Cq9hYeV">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder>
					<orgName type="full">NIST</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,93.12,107.70,42.57,9.02"><forename type="first">Heyuan</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,149.98,107.70,51.99,9.02"><forename type="first">Yuanhai</forename><surname>Xue</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,216.70,107.70,54.19,9.02"><forename type="first">Shaohua</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,285.66,107.70,44.13,9.02"><forename type="first">Feng</forename><surname>Guan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,344.59,107.70,53.24,9.02"><forename type="first">Xiaoming</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,405.67,107.70,31.95,9.02"><forename type="first">Yue</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,445.84,107.70,53.08,9.02"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,174.12,83.21,247.02,12.58">ICTNET at Web Track 2012 Ad-hoc Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">694E98BCFDC00CF48B9382BBBDC31D0A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we report our experiments at Ad-hoc task, Web Track 2012. In this year, we attempt to use new web parser with noise elimination. The Conditional Boolean BM25 was used as major ranking function. We also introduce Learning-To-Rank to combine multiple features together for ranking, but the performance was poor due to the low quality of training data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Ad-hoc task investigates the performance of search over a static set of documents using previously-unseen topics. The ClueWeb09 Dataset <ref type="bibr" coords="1,296.28,261.61,7.62,5.83" target="#b0">[1]</ref> and its derived data were still used this year. The topic used this year was the same as NTCIR-10, which was shorter and more common than 2011's Ad-hoc task. This paper is organized as follows. In Section 2, we discuss the workflow of building index, including parser, data processing, and building. The retrieval models and Learning-To-Rank are described in Section 3. In Section 4, we report the evaluation results and discuss the performance this year. Finally, we conclude our work in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Building Index</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">New web parser with noise elimination</head><p>We use the new version of web parser to analysis the web page and extract the text. Many low-quality web pages in ClueWeb09 were filled with advertising and spam. Last year, we use na√Øve html parser that treat full page as content, which would bring in spam and noise <ref type="bibr" coords="1,371.40,417.61,7.62,5.83" target="#b1">[2]</ref> . The new parser proposed this year could remove the noise and spam parts in web page based on DOM characteristic. For example, many paragraphs (&lt;p&gt;) appear continuous trend to be the pure, non-spam text. On the other hand, advertisement and navigation usually consist of intensive hypertext references (&lt;a&gt; tag). We apply the new parser to extract TREC-ID, URL, title, pure content and anchor text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Anchor Text</head><p>As we discussed last year, search on reverse anchor text could significant improve the retrieval performance <ref type="bibr" coords="1,142.14,526.81,7.62,5.83" target="#b1">[2]</ref> . In year 2011, we use anchor text data by Dang <ref type="bibr" coords="1,347.76,526.81,7.62,5.83" target="#b2">[3]</ref> and treat each unique pair of &lt;URL, anchor text&gt; as individual document. This year, we use the same original data but employ a map/reduce workflow to merge the anchor text for the same URL. At the map side, we compute the hash value for URL and collect anchor text with count. For the reduce task, we joint the anchor text to form a bigger text for the same key (same URL) and repeat it for many times if the count value is bigger than 1. The reduced text value was seen as a document field for this URL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Index Building</head><p>This year, we use GolaxyDT2 <ref type="bibr" coords="1,221.40,636.01,7.62,5.83" target="#b4">[5]</ref> , a real-time distributed search platform. As the data was already generated, we select the distributed mode instead of real-time mode build to speed up the procedure.</p><p>Firstly, we combine all the fields to form a structured XML documents. The document was consist of 6 fields, including TREC-ID, URL, title, pure content, reverse anchor text and spam value <ref type="bibr" coords="1,453.12,682.81,7.62,5.83" target="#b3">[4]</ref> . Secondly, we setup a distributed file system on a 10-servers cluster and copy the structured data to DFS. Then, we deploy the GolaxyDT2 across the cluster. The master controller distributes the data list to each GolaxyDT2 index builder and start the building remotely. The whole building process takes 10 hours to finish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Retrieval Models and LTR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Conditional Boolean BM25 Model</head><p>Okapi BM25 is a widely used probabilistic retrieval model <ref type="bibr" coords="2,329.46,105.61,7.62,5.83" target="#b5">[6]</ref> , which is designed for non-structure text.</p><p>In order to apply this model to structured document with many fields, we combine Boolean model and BM25 Model this year. Firstly, we search on each field using Boolean operator and BM25 separately.</p><p>For the short fields, such as title and reverse anchor text, we apply OR operator before BM25 ranking.</p><p>After that, documents that any query words occurs at least once is selected and ranked. For the long fields, such as content, we perform the similar workflow, but use AND operator instead of OR.</p><p>Secondly, we combine different fields' document together by using AND operator. Documents that exist in all fields rank list would remain to form the final list. Also, we add all part's BM25 score together to obtain the final score and rank by score.</p><p>The short field, for instance, AND operator would lead to better accuracy. But for some topic, apply AND operator may cause very few matched documents. Therefore, we propose a modified model this year. For each topic, we use AND operator on title field. If the matching documents is less than threshold, we switch to OR operator. For content field, the operator is always AND. We call this Conditional Boolean BM25 Model and use it as baseline this year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning to rank</head><p>Learning to rank (LTR) introduces machine learning to retrieval ranking problem. It uses supervised or semi-supervised learning to automatically construct a ranking model from training data. LTR is an effective way to combine multiple ranking features together. We choose 11 features and classify them in three types. The Probabilistic Retrieval Model, which is the BM25 score for title, URL, content, reverse anchor fields. The Language Model, including query like-hood and KL-divergence model for title, URL, content and reverse anchor text fields. The content quality feature, such as the spam score and PageRank for document.</p><p>Because the lack of feature values that we proposed, we can't use public available training data such as LETOR <ref type="bibr" coords="2,123.66,464.41,7.62,5.83" target="#b7">[8]</ref> . Our training data is generated base on the relevance judgment for TREC 2009 and TREC 2010. As a matter of fact, this is a low quality training data, for there are only 98 topics in the dataset and very few relevance documents for each topic. We use RankBoost <ref type="bibr" coords="2,392.40,495.61,7.62,5.83" target="#b8">[9]</ref> algorithm this year. For training, we use 5-folds cross validation and the output model is used for ranking directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Boost Wikipedia Result</head><p>In many commercial search engines, such as Google, the high quality document is boosted to the first place. This year, we explore the feasibility of boost Wikipedia result. Two indexes are built separately. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The first one is INDEX_WIKI, built for pages in</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results and Discussion</head><p>In the first run, ICTNET12ADR1, we use Conditional Boolean BM25 Model described in Section 3.1.</p><p>Then the matching Wikipedia result is boosted to the first position as shown in Section 3.3. This run is the baseline and we use it to validate the effectiveness of other runs.</p><p>In the run ICTNET12ADR2, the workflow was nearly the same as ICTNET12ADR1. But we use the new web page parser described in Section 2.1. We submit this run to investigate the influence of noise elimination for Ad-hoc task.</p><p>The last run, ICTNET12ADR3, was generated by Learning-to-rank, as described in Section 3.2. Many features are combined together and a ranking model is automatic generated to form the final result. This is our first attempts that introduce Learning-to-rank for Ad-hoc task recent years.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>Rel. Docs. ERR@20 nDCG@20 P@10 P@20 MAP  <ref type="table" coords="3,114.61,221.88,5.01,9.02" target="#tab_0">1</ref> summarizes the performance of our ad-hoc submission this year. As shown in the chart, the first run is best on NDCG, P@5, P@20 and MAP, which is against our prediction. The second run with new parser performance best on ERR@20 but not good at other metrics, which means the noise elimination may optimize top result quality but reduce the recall rate. The third run, which uses Learning-to-rank, performs worst this year. As we point out in Section 3.2, the training data used was generated from relevance judgments in year 2009 and 2010, which is of low quality. We'll try to use other training data and continue to explore effective approach to use learning to rank in Ad-hoc task next year.</p><formula xml:id="formula_0" coords="3,95.10,156.64,68.75,9.61">ICTNET12ADR1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we described our experiment in Ad-hoc task. This year, we use new parser to eliminate the noise in web pages. It's good at optimize top result documents, but may lower the recall. Also, we introduce Conditional Boolean BM25 model to rank the result. To improve the quality of top ranks, we boost the matching Wikipedia page, which play a positive role in the submission compared with last year. Last, we use Learning-to-rank, combining multiple features together to form a rank model, but it performs badly due to the low quality of training data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,292.76,575.70,212.41,9.02;2,90.00,591.30,415.29,9.02;2,90.00,606.90,415.36,9.02;2,90.00,622.50,415.33,9.02;2,90.00,638.10,415.30,9.02;2,90.00,653.70,189.12,9.02"><head></head><label></label><figDesc>ClueWeb09 under the en.wikipedia.org domain. The other pages in ClueWeb09 are built in index INDEX_NORMAL. For INDEX_WIKI, we use Boolean Retrieval Model in URL field. For INDEX_NORMAL, the model described in Section 3.2 is used to rank the result. The final submission is a combination of the two indexes above. For each query, we search across INDEX_WIKI and choose the top one document if any matches. Then search across INDEX_NORMAL and fill the other positions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,90.00,156.64,409.68,74.26"><head>Table 1 : Result of ad-hoc task, TREC 2012 Table</head><label>1</label><figDesc></figDesc><table coords="3,95.10,156.64,404.58,42.85"><row><cell></cell><cell>1398</cell><cell>0.2075</cell><cell>0.1162</cell><cell>0.2860</cell><cell>0.2610</cell><cell>0.0908</cell></row><row><cell>ICTNET12ADR2</cell><cell>1337</cell><cell>0.2149</cell><cell>0.1101</cell><cell>0.2680</cell><cell>0.2570</cell><cell>0.0783</cell></row><row><cell>ICTNET12ADR3</cell><cell>1210</cell><cell>0.1983</cell><cell>0.0934</cell><cell>0.2280</cell><cell>0.2060</cell><cell>0.0612</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6.">Acknowledgements</head><p>We would like to thank all organizers and assessors of <rs type="institution">TREC</rs> and <rs type="funder">NIST</rs>. This work is sponsored by <rs type="funder">NSF of China</rs> Grants No. <rs type="grantNumber">60933005</rs>, No. <rs type="grantNumber">61100083</rs> and No.<rs type="grantNumber">61173064</rs>, and by <rs type="programName">242 Program</rs> of China Grants No.<rs type="grantNumber">2011F65</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_vCYVK47">
					<idno type="grant-number">60933005</idno>
				</org>
				<org type="funding" xml:id="_ruTYVKB">
					<idno type="grant-number">61100083</idno>
				</org>
				<org type="funding" xml:id="_hhyzMXc">
					<idno type="grant-number">61173064</idno>
					<orgName type="program" subtype="full">242 Program</orgName>
				</org>
				<org type="funding" xml:id="_Cq9hYeV">
					<idno type="grant-number">2011F65</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="3,103.50,518.74,245.28,8.77" xml:id="b0">
	<monogr>
		<title level="m" coord="3,217.02,518.74,97.32,8.77">The ClueWeb09 Dataset</title>
		<imprint/>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note>EB.OL</note>
</biblStruct>

<biblStruct coords="3,104.59,549.48,400.78,9.02;3,90.00,565.08,365.22,9.02" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,269.89,549.48,168.10,9.02">ICTNET at Web Track 2011 Ad-hoc Task</title>
		<author>
			<persName coords=""><forename type="first">Heyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuanhai</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Xu Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,445.19,549.48,60.18,9.02;3,90.00,565.08,216.34,9.02">Proceedings of the Twentieth Text REtrieval Conference (TREC 2010</title>
		<meeting>the Twentieth Text REtrieval Conference (TREC 2010<address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,104.16,580.68,252.38,9.02" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="3,156.36,580.68,159.69,9.02">Anchor Text Query Log for ClueWeb09</title>
		<author>
			<persName coords=""><forename type="first">Croft</forename><surname>Dang</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>EB/OL</note>
</biblStruct>

<biblStruct coords="3,104.81,611.76,400.45,9.35" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="3,147.04,611.76,217.03,9.02">Waterloo Spam Rankings for the ClueWeb09 Dataset</title>
		<author>
			<persName coords=""><surname>Cormack</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Waterloo Spam Rankings [EB/OL</note>
</biblStruct>

<biblStruct coords="3,104.22,643.42,277.27,9.19" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="3,137.28,643.42,107.64,9.19">Golaxy DTSearch 2 [EB/OL</title>
		<author>
			<persName coords=""><surname>Golaxy</surname></persName>
		</author>
		<ptr target="http://www.golaxy.cn/" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,107.04,659.02,398.27,9.19;3,89.99,674.62,234.79,9.19" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="3,230.88,659.02,82.28,9.19">OKAPI at TREC8[C]</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>S E Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Walkery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,322.98,659.02,182.34,9.19;3,89.99,674.62,100.66,9.19">Proceedings of the Eighth Text REtrieval Conference (TREC 1999)</title>
		<meeting>the Eighth Text REtrieval Conference (TREC 1999)<address><addrLine>Gaithersburg, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,104.21,690.22,385.64,9.19" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="3,152.33,690.22,67.44,9.19">Learning to rank</title>
		<author>
			<persName coords=""><surname>Wikipedia</surname></persName>
		</author>
		<ptr target="http://en.wikipedia.org/wiki/Learning_to_rank[EB/OL" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,109.56,705.82,395.77,9.19" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="3,219.06,705.82,243.14,9.19">LETOR: Learning to Rank for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>EB/OL</note>
</biblStruct>

<biblStruct coords="3,105.60,737.02,399.66,9.19;3,90.00,752.62,322.87,9.19" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="3,353.28,737.02,151.98,9.19;3,90.00,752.62,108.97,9.19">An efficient boosting algorithm for combining preferences [J]</title>
		<author>
			<persName coords=""><forename type="first">Yoav</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Raj</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,204.42,752.62,177.56,9.19">The Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
