<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,188.09,82.24,235.73,14.36">HIT at TREC 2012 Microblog Track</title>
				<funder ref="#_bUnbpsG">
					<orgName type="full">key project of National High Technology Research and Development Program of China</orgName>
				</funder>
				<funder ref="#_5wJFNaf">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder>
					<orgName type="full">Fundamental Research Funds for the Central Universities</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,120.38,122.92,71.17,9.94"><forename type="first">Zhongyuan</forename><surname>Han</surname></persName>
							<email>zyhan@mtlab.hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology Harbin</orgName>
								<address>
									<postCode>150001</postCode>
									<settlement>Heilongjiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Heilongjiang Institute of Technology Harbin</orgName>
								<address>
									<postCode>150050</postCode>
									<settlement>Heilongjiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,205.85,122.92,41.83,9.94"><forename type="first">Xuwei</forename><surname>Li</surname></persName>
							<email>xwli@mtlab.hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology Harbin</orgName>
								<address>
									<postCode>150001</postCode>
									<settlement>Heilongjiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,256.73,122.92,56.88,9.94"><forename type="first">Muyun</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology Harbin</orgName>
								<address>
									<postCode>150001</postCode>
									<settlement>Heilongjiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,322.51,122.92,53.92,9.94"><forename type="first">Haoliang</forename><surname>Qi</surname></persName>
							<email>haoliang.qi@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Heilongjiang Institute of Technology Harbin</orgName>
								<address>
									<postCode>150050</postCode>
									<settlement>Heilongjiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,385.51,122.92,40.05,9.94"><forename type="first">Sheng</forename><surname>Li</surname></persName>
							<email>lisheng@hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology Harbin</orgName>
								<address>
									<postCode>150001</postCode>
									<settlement>Heilongjiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,434.38,122.92,53.72,9.94"><forename type="first">Tiejun</forename><surname>Zhao</surname></persName>
							<email>tjzhao@hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology Harbin</orgName>
								<address>
									<postCode>150001</postCode>
									<settlement>Heilongjiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,188.09,82.24,235.73,14.36">HIT at TREC 2012 Microblog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9C7C3F763367D533D5B52E7A241A2490</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our approaches to the TREC 2012 Microblog Track. We explore the query expansion and document expansion techniques to address the retrieval of short tweet texts. Further, we examine the webpages linked by the URL in a tweet as an external source to improve the performance. Then learning to rank technique is adopted to combine all features for better performance. Finally, we accomplish the microblog filtering via comparing the new tweet against top m relevant tweet retrieved in the history.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Microblog, most notably Twitter, is becoming increasingly popular around the world. For users, the real-time search in microblog is an effective way to have a grasp of latest development or other's thoughts of a topic. However, the microblog retrieval challenges the classical retrieval technologies with its extremely short text, e.g. Twitter with no more than 140 characters. In TREC 2011 Microblog Track, the learning to rank technique are generally adopted to combine text-based features with non-text features such as URL, hashtag, time and so on <ref type="bibr" coords="1,448.18,501.48,5.54,6.26" target="#b1">[1]</ref><ref type="bibr" coords="1,453.72,501.48,2.77,6.26" target="#b2">[2]</ref><ref type="bibr" coords="1,456.48,501.48,5.54,6.26" target="#b3">[3]</ref> . In our view, the the current research is mainly focused on the application of non-text features, leaving the difficulty of modeling caused by microblog's short text less touched. In particular, the short document modeling is not well addressed. Therefore, we try to examine the document expansion and query expansion under the classical language model framework to accomplish the microblog retrieval in this year. Meanwhile, we also examine the webpage contents indicated by the URL in a tweet for its contribution to retrieval performance. In addition, we make use of learning to rank technique to combine other non-text features for better performance. At last, we accomplish the microblog filtering via comparing the new tweet against top m relevant tweet retrieved in the history.</p><p>TREC 2012 microblog track intends to fulfill two defined tasks: Real-time Adhoc Task and Real-time Filtering Pilot Task. The Remainder of this paper is arranged as follows: Section 2 introduces our approaches and results in Real-time Adhoc Task. Section 3 presents the way we accomplish the Real-time Filtering Pilot Task, and Section 4 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">REAL-TIME ADHOC TASK</head><p>We investigate the query expansion, the document expansion for tweet search, and apply learning to rank technique to adopt to combine all features for better performance. In other way, We incorporate the scores of the tweet texts and the scores of the URL in them to improve retrieval performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">KL-divergence Retrieval Model</head><p>The KL-divergence model is a classical language modeling approach for retrieval. It can support feedback more naturally. In this approach, a query and a document are assumed to be generated from a unigram query language model and a unigram document language model , respectively. Given a query Q and a document D, we would compute an estimate of the corresponding query model ( ) and document model ( ), and then KL-divergence of the two models is defined as :</p><formula xml:id="formula_0" coords="2,233.84,306.25,160.84,32.34">   V w D Q Q D Q ) θ | p(w ) θ | p(w log * ) θ | p(w ) θ || θ KL(</formula><p>where V is the set of all the words in vocabulary. The estimation of the query model is described in sub-section 2.2 and the estimation of the document model is often done through smoothing with the global collection language model , we used the Dirichlet smoothing with  =100:</p><formula xml:id="formula_1" coords="2,239.59,409.58,131.54,26.16">μ | D | ) θ | μP(w D) c(w, ) θ | P(w C D   </formula><p>Because of short text of tweet, document expansion is used for better estimation of the document language model as is described in sub-section 2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query Expansion</head><p>We applied the relevance feedback model <ref type="bibr" coords="2,293.93,502.92,8.10,6.26" target="#b4">[4]</ref> for query expansion. The relevance model deems that a query term is generated by a relevance model p(w|θ R ), which is derived by top-ranked feedback documents by assuming them to be samples from the relevance model as follows:</p><formula xml:id="formula_2" coords="2,236.76,553.01,143.28,22.36">   F d R R ) θ | d)P(d | P(w ) θ | P(w</formula><p>where F denotes the feedback documents, usually chosen as the top-ranked retrieval documents for the query (set as 20 in our experiment); p(w|d) is the probability that the term w appearing in the document d, and the relevance θ R is approximated by the original query, thus we can obtain:</p><formula xml:id="formula_3" coords="2,211.86,635.10,197.66,30.03">     m 1 i d i F d d d R ) θ | P(q ) )P(θ θ | P(w ) θ | P(w</formula><p>The above relevance model is used to enhance the original query model by the following interpolation:</p><formula xml:id="formula_4" coords="2,220.80,235.82,296.14,153.90">Q  D  Q  ˆD  Q  ˆC  ) θ | αP(w ) θ | α)P(w - 1 ( ) θ | P(w R q ' q  </formula><p>where α is the interpolation weight (set as 0.8 in our experiments).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Document Expansion</head><p>The use of a limited and very small number of characters by twitter's very definition (i.e. 140 characters) drastically reduces the length of the tweet text. In very short microblog messages, most terms occur only once, making statistical estimation less reliable. Meanwhile, the term mismatch in microblog search is also non-trivial issue. In this sense, how to best estimate the document language model P(w|D) is crucial.</p><p>Since |D| is small (about 12 terms in length in our experiments after tweet message preprocessing), the word count n(w,D) is frequently observed as 1. To enhance the classical the maximum likelihood estimation method, we applied DELM (Document Expansion Language Model) <ref type="bibr" coords="3,122.54,284.50,8.08,6.26" target="#b5">[5]</ref> to improve the representation of short tweet in microblog search. That is, the model for document D is smoothed with contents obtained from its k nearest neighbors D 1 ,…,D k , with each document's influence in the smoothed model being proportional to its cosine similarity with D.</p><p>The precise definition of neighborhood document (i.e. tweet) is measured by the cosine similarity between any two document models X and Y. Then it assigns a confidence value r d (b) to every document b in the collection to indicate the confidence we believe b is sampled from d's hidden model. The cosine similarity and confidence value are defined respectively as below:</p><formula xml:id="formula_5" coords="3,255.04,405.44,118.08,91.59">     i 2 i 2 i i i i y x y x Y) sim(X,     {d} C b' ) b' sim(d, b) sim(d, b) rd(d,</formula><p>In fact the confidence value r d (b) is set by normalizing the cosine similarity scores. Then a pseudo document d' is obtained with the following pseudo term count:</p><formula xml:id="formula_6" coords="3,206.64,537.23,217.87,22.84">       {d} C b d b)) c(w, (b) (r β) (1 d) βc(w, ) d' c(w,</formula><p>Here it uses a parameter β to control the degree of relying on neighborhood document. This technique is proved to be valid in improving search results in TREC texts by [5]. In our experiments, β=0.8 and the number of neighborhood documents is set 100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">URL</head><p>The research of TREC 2011 Microblog Track shows that whether containing a URL is an important feature for a tweet <ref type="bibr" coords="3,228.77,658.95,8.08,6.26" target="#b1">[1]</ref> . A tweet which contains a URL is more likely to contain substantial contents for a topic. We take advantage of a simple linear model to combine the score of tweet and the score of URL. Given a query Q and a tweet D, the relevance score(Q,D) is computed according to the following equation: in which Score_D(Q,D) is the relevance score for Q and D estimated by Kullback-Leibler (KL) divergence; Score_URL(Q,D) is the relevance score of Q and Webpage of URL in D, which is also estimated by KL divergence.</p><p>The λ is the parameter to control the effect of URL content to the retrieval process. We empirically set it as a constant of 0.8. The δ is a zoom ratio to enable the Score_URL(Q,D) to be comparable to Score_D(Q,D), which is decided as the ratio of the average of Score_D to the average of Score_URL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Learning to Rank</head><p>Previous works proved that microblog's non-text features are positive to retrieval performance. The learning to rank technique, which was successfully used by the several teams in TREC 2011 Microblog Track, is also adopted in this paper.</p><p>Specifically, we designed a ranking logistic regression model to learn a pair-wise ranking from twitter retrieval. The ranking logistic regression algorithm will be reported in the future. For a training sample consisting of a relevant tweet and an irrelevant tweet, the following features are applied to the modeling process:</p><p> Text-based features KL(Q,D): KL divergence of the original query and the original tweet; KL(EQ,D): KL divergence of the expanded query and the original tweet; KL(Q,ED): KL divergence of the original query and the expanded tweet; KL(EQ,ED): KL divergence of the expanded query and the expanded tweet;  Non-text features Has_URL: whether the tweet contain a URL (binary valued) Has_hashtag: whether the tweet contain a hashtag (binary valued) Retweet_count: frequency of the tweet re-posted  User features Followers_count: how many people are following this author Friends_count: how many people this author is following Listed_count: how many groups is the user in Note that to avoid using external source, the content of URL here is not used as in sub-section 2.4 in the ranking modeling process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Data setting</head><p>We download 10,397,336 tweets by twitter crawler provided by track organizers. After preprocessing, 3,754,077 tweets are indexed. The main steps are as follows:</p><p> The null tweets were removed.  The retweets without "RT" would be judged as non-relevant and thus were removed. The retweets with "RT" are removed if there is nothing contents in front of "RT". But</p><formula xml:id="formula_7" coords="4,156.27,86.72,258.63,9.74">δ * D) Q, Score_Url( * λ D) score_D(Q, * λ) - (1 D) Score(Q,  </formula><p>once there exists description in the beginning of their tweet text, we only keep the words before "RT".  We filtered out all the non-English tweets using language identifier tool provided by Nutch<ref type="foot" coords="5,158.90,120.67,3.48,6.26" target="#foot_0">1</ref> .  Porter stemmer is used for stemming and stop words are filtered. The statistics of dataset obtained by our group are shown in Table <ref type="table" coords="5,406.02,154.12,4.14,9.94">1</ref>. Moreover, we extracted URL links in tweets and downloaded them as an external resource. The number of successfully downloaded webpage is 814,817.</p><p>At last, we completed the real-time index. Actually, we indexed tweets which only posted before the timestamp for every query. We used TREC 2011 microblog task data to train the parameters as mentioned before and submitted four official runs as follows:</p><p> hitQryFBrun4: a baseline run uses KL divergence with query expansion only;  hitDELMrun2: both query expansion and document expansion are applied;  hitURLrun3: using external source: a linear combination of score in Run2 and the URL derived score as described in sub-section 2.4;  hitLRrun1: result from learning to rank technique as described in sub-section 2.5;</p><p>The formal results provided by TREC are listed in Table <ref type="table" coords="5,394.78,452.01,5.52,9.94" target="#tab_0">2</ref> and Table <ref type="table" coords="5,458.20,452.01,4.14,9.94" target="#tab_1">3</ref>. Comparing hitDELMrun2 with hitQryFBrun4, it indicates that the straight forward integration of the document expansion into the query expansion does not significantly improve the performance. The corresponding analysis is still under going now. Unsurprisingly, the learning to rank technique in hitLRrun1 brings about a better retrieval performance.</p><p>The result deserves further elaboration is that the hitURLrun3 achieves best performance. This fact indicates that the webpage of the URL in a tweet is a valid help to decide if the tweet is relevant to a topic. This is somewhat natural since a webpage content is more informative than 140 characters.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">REAL-TIME FILTERING PILOT TASK</head><p>The main measure of this sub-task is T11SU which is biased for precision. In TREC 2011 Microblog Track, we can observe many queries have a retrieval results over 0.4 at P@30 <ref type="bibr" coords="6,488.50,264.10,8.08,6.26">[6]</ref> . This fact motivates us to use information retrieval results for a good T11SU score. And the retrieval model adopted for this task is what we described at sub-section 2.5. The tweets prior to querytweettime are used as background training data for query expansion, document expansion and in Dirichlet smoothing method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Retrieval Score Based Filtering</head><p>The chief difference between the retrieval and filtering is that we have the whole document collection for retrieval, yet we have only partial documents preceding a give time T in filtering.</p><p>To apply the retrieval model, we treat the documents ahead of T as the collection, and then retrieve top m tweets as the relevant set. To tell whether a newly arrival tweet X is relevant to the topic, we simply compute its retrieval score and compare it with the m-th tweet. If X has smaller score, it is filtered as irrelevant otherwise it is updated into the relevant set.</p><p>We examine three strategies to determine the m as follows:</p><p>1) Fixed top-m method: the baseline method which always keeps most relevant m tweets in the relevant set. 2) Dynamic top-m method: to take advantage the observation that the relevant tweets tends to occurred at a close period, we extend k tweets in the relevance set; and an irrelevant tweet will result a decrease of |k/1000| in the number of relevant set. 3) Combined Dynamic top-m with tweet's content and Fixed top-m with URL: this method is designed specifically for tweets with URL: only the tweets both in dynamic top-m with tweets' content and fixed top-m with webpage of the URL are judged relevant, otherwise are judged irrelevant; and tweets without URL are all treated as irrelevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Results</head><p>We perform the same data processing as described in sub-section 2.6. At the starting point for a given topic, we used the entire corpus prior to querytweettime as background training data, and the query and querytweet as a positive training example.</p><p>Similarly, we submitted four official runs as follows:</p><p>C   window2run: results from fixed top-m method with m=2;  hitRSW: results from dynamic top-m method with m=2 and k=8;</p><p> hitUWT: results from a combined method of dynamic top-m with content and fixed top-m with URL , again m=2 and k=8 in dynamic method and m=1000 in fixed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>URLAllFB: all tweets are judged as positive to examine the recall of our data collection; TREC released results of the four runs are provided in Table <ref type="table" coords="7,383.23,169.72,4.14,9.94" target="#tab_2">4</ref>. From these summary results, the fixed top-m method(windows2run)gets a better T11SU but the recall is too low. The dynamic top-m method (hitRSW) improves the recall rate, but more irrelevant tweets are judged positive, which causes a better F_0.5 and a lower T11SU. The dynamic top-m with URL (hitUWT) achieves best T11SU and F_0.5 by introducing the webpage indicated by the URL as external resources. Also, it seems that we lost almost 10% of the relevant tweets in our data collections, which deserves further investigation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSION</head><p>In TREC 2012 microblog track, we explore the query expansion and document expansion approaches to tweet retrieval. It seems that current document expansion approach is still far from a perfect solution to tweet document modeling. Instead, we find that the webpage of the URL in a tweet can benefit the retrieval process significantly.</p><p>In the sub-task of Real-time Filtering Pilot Task, we developed a approach using information retrieval model to filter out the relevant tweet. The results show the approach works well.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,224.93,247.75,162.21,9.94;5,167.06,264.21,25.42,8.96;5,165.62,279.81,28.10,8.96;5,216.53,264.21,36.02,8.96;5,220.49,279.81,28.10,8.96;5,280.13,264.21,15.91,8.96;5,269.81,279.81,36.51,8.96;5,322.99,264.21,69.40,8.96;5,344.95,279.81,25.46,8.96;5,405.07,264.21,50.45,8.96;5,416.26,279.81,28.10,8.96;5,157.22,295.89,45.08,8.96;5,232.01,295.89,4.98,8.96;5,271.85,295.89,32.57,8.96;5,337.75,295.89,40.01,8.96;5,410.35,295.89,40.04,8.96;5,110.06,327.57,75.75,8.96"><head>Table1</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,141.02,592.44,283.15,89.86"><head>Table 2 .</head><label>2</label><figDesc>Results for Highly Relevant Tweets</figDesc><table coords="5,141.02,609.02,283.15,73.28"><row><cell></cell><cell>P@30</cell><cell>R-Precision</cell><cell>MAP</cell></row><row><cell>hitQryFBrun4</cell><cell>0.2345</cell><cell>0.2471</cell><cell>0.2302</cell></row><row><cell>hitDELMrun2</cell><cell>0.2350</cell><cell>0.2522</cell><cell>0.2257</cell></row><row><cell>hitURLrun3</cell><cell>0.2701</cell><cell>0.2872</cell><cell>0.2642</cell></row><row><cell>hitLRrun1</cell><cell>0.2446</cell><cell>0.2628</cell><cell>0.2411</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,141.02,91.72,283.15,89.86"><head>Table 3 .</head><label>3</label><figDesc>Results for All Relevant Tweets</figDesc><table coords="6,141.02,108.18,283.15,73.40"><row><cell></cell><cell>P@30</cell><cell>R-Precision</cell><cell>MAP</cell></row><row><cell>hitQryFBrun4</cell><cell>0.4424</cell><cell>0.3655</cell><cell>0.3186</cell></row><row><cell>hitDELMrun2</cell><cell>0.4345</cell><cell>0.3636</cell><cell>0.3197</cell></row><row><cell>hitURLrun3</cell><cell>0.4695</cell><cell>0.3751</cell><cell>0.3469</cell></row><row><cell>hitLRrun1</cell><cell>0.4379</cell><cell>0.3777</cell><cell>0.3355</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,190.37,294.55,229.00,89.86"><head>Table 4 .</head><label>4</label><figDesc>Results for Real-time Filtering Pilot Task</figDesc><table coords="7,190.37,311.01,229.00,73.40"><row><cell></cell><cell>T11SU</cell><cell cols="2">F_0. 5 Precision</cell><cell>Recall</cell></row><row><cell>window2run</cell><cell>0.3321</cell><cell>0.2055</cell><cell>0.3860</cell><cell>0.0987</cell></row><row><cell>hitRSW</cell><cell>0.2942</cell><cell>0.2699</cell><cell>0.2838</cell><cell>0.3440</cell></row><row><cell>hitUWT</cell><cell>0.4117</cell><cell>0.3338</cell><cell>0.6219</cell><cell>0.1740</cell></row><row><cell>URLAllFB</cell><cell>0</cell><cell>0.0001</cell><cell>0</cell><cell>0.9146</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,112.58,709.56,79.91,7.24"><p>http://nutch. apache. org/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5.">ACKNOWLEDGEMENTS</head><p>The work of this paper is supported by the <rs type="funder">key project of National High Technology Research and Development Program of China</rs> (<rs type="programName">863 Program</rs>, No. <rs type="grantNumber">2011AA01A207</rs>), the project of <rs type="funder">National Natural Science Foundation of China</rs> (Grant No. <rs type="grantNumber">61105072 &amp; 61272384</rs>) and the <rs type="funder">Fundamental Research Funds for the Central Universities</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_bUnbpsG">
					<idno type="grant-number">2011AA01A207</idno>
					<orgName type="program" subtype="full">863 Program</orgName>
				</org>
				<org type="funding" xml:id="_5wJFNaf">
					<idno type="grant-number">61105072 &amp; 61272384</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,95.31,631.91,96.60,12.64" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,106.09,656.40,416.13,9.94;7,106.94,672.00,114.75,9.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,194.13,656.40,184.06,9.94">USC/ISI at TREC 2011: Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,398.59,656.40,118.81,9.94">Proceedings of TREC 2011</title>
		<meeting>TREC 2011<address><addrLine>Gaithersburg, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,108.73,687.60,413.47,9.94;7,106.94,703.20,398.24,9.94" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,383.43,687.60,138.76,9.94;7,106.94,703.20,139.66,9.94">TREC 2011 Microblog Track Experiments at Kobe University</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miyanishi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Okamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Seki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Uehara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,265.61,703.20,117.37,9.94">Proceedings of TREC 2011</title>
		<meeting>TREC 2011<address><addrLine>Gaithersburg, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.84,76.10,416.30,9.94;8,106.94,91.72,417.92,9.94;8,106.94,107.32,85.32,9.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,340.01,76.10,182.14,9.94;8,106.94,91.72,41.09,9.94">An Empirical Study on Learning to Rank of Tweets</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H.-Y</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,167.90,91.72,352.70,9.94">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="295" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,106.20,122.92,415.93,9.94;8,106.94,138.52,415.22,9.94;8,106.94,154.12,129.27,9.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,240.72,122.92,154.95,9.94">Relevance-based Language Models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,416.38,122.92,105.75,9.94;8,106.94,138.52,415.22,9.94;8,106.94,154.12,38.88,9.94">Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.97,169.72,415.93,9.94;8,106.94,185.32,415.00,9.94;8,106.94,200.92,415.28,9.94;8,106.94,216.52,83.55,9.94" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,276.82,169.72,245.08,9.94;8,106.94,185.32,44.38,9.94">Language Model Information Retrieval with Document Expansion</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,179.33,185.32,342.61,9.94;8,106.94,200.92,194.86,9.94">Proceedings of the main Conference on Human Language Technology Conference of the North American Chapter</title>
		<meeting>the main Conference on Human Language Technology Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>the Association of Computational Linguistics</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="407" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,109.70,232.12,412.22,9.94;8,106.94,247.75,239.57,9.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,278.60,232.12,222.93,9.94">Overview of the TREC-2011 Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,106.94,247.75,117.38,9.94">Proceedings of TREC 2011</title>
		<meeting>TREC 2011<address><addrLine>Gaithersburg, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
