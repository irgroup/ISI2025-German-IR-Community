<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,170.28,115.96,274.80,12.62">UCAS at TREC-2012 Microblog Track</title>
				<funder ref="#_DuQ2KMa">
					<orgName type="full">President Fund of UCAS</orgName>
				</funder>
				<funder ref="#_srgBEsX">
					<orgName type="full">NSFC</orgName>
				</funder>
				<funder ref="#_Pa5Gdd8">
					<orgName type="full">National Key Technology R&amp;D Program of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,179.13,153.63,44.00,8.74"><forename type="first">Xin</forename><surname>Zhang</surname></persName>
							<email>zhangxin510@mails.ucas.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer and Control Engineering</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,231.44,153.63,29.06,8.74"><forename type="first">Sha</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer and Control Engineering</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,268.66,153.63,30.11,8.74"><forename type="first">Ben</forename><surname>He</surname></persName>
							<email>benhe@ucas.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer and Control Engineering</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,306.99,153.63,50.50,8.74"><forename type="first">Jungang</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer and Control Engineering</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,385.45,153.63,50.78,8.74"><forename type="first">Tiejian</forename><surname>Luo</surname></persName>
							<email>tjluo@ucas.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer and Control Engineering</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,170.28,115.96,274.80,12.62">UCAS at TREC-2012 Microblog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A7A88D6F1BC54534FAE1FD27D729F0C2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Two search tasks, i.e. real-time adhoc and real-time filtering are addressed in this year's Microblog track. The participation of (Graduate) University of Chinese Academy of Sciences (UCAS) in this track aims to evaluate the effectiveness of the query-biased learning to rank model, which was proposed in our previous work. To futher improve the retrieval effectiveness of learning to rank, we construct the query-biased learning to rank framework by taking the difference between queries into consideration. In particular, we learn a query-biased ranking model with a semi-supervised transductive learning algorithm so that the query-specific features, e.g. the unique expansion terms, are utilized to capture the characteristics of the target query. This query-biased ranking mode is combined with the general ranking model to produce the final ranked list of tweets in response to the given target query. Experiments on the standard TREC Tweets11 collection show that the query-biased learning to rank approach outperforms strong baselines when evaluated under MAP, namely the conventional application of the state-of-the-art learning to rank algorithm.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This year is the second year of the Microblog track and two search tasks, namely Real-time Adhoc and Real-time Filtering are addressed, whereby a user's information need is represented by a query at a specific time. Similar to last year's track, in the real-time adhoc task the systems are requested to produce a list of recent and relevant tweets starting from the query was issused. Different from the real-time adhoc task, the real-time filtering task which can be thought of as orthogonal to the real-time adhoc task, aims to decide whether the subsequently posted tweets are response to the query entered at the particular point in time. In the filtering task, the user is interested in the tweets after the querytweettime in order to keep up to date about a specific topic on Twitter.</p><p>Recently, quite a few research has attempted to apply learning to rank to Twitter search <ref type="bibr" coords="1,216.68,596.34,9.96,8.74" target="#b1">[2]</ref>, including supervised <ref type="bibr" coords="1,328.24,596.34,10.96,8.74" target="#b2">[3,</ref><ref type="bibr" coords="1,339.20,596.34,7.31,8.74" target="#b3">4]</ref> and semi-supervised methods <ref type="bibr" coords="1,134.77,608.30,10.79,8.74" target="#b5">[6,</ref><ref type="bibr" coords="1,145.56,608.30,7.20,8.74" target="#b6">7,</ref><ref type="bibr" coords="1,152.75,608.30,7.20,8.74" target="#b7">8]</ref>. By using learning to rank, multiple intrinsic features of Twitter, such as user authority, mentions, retweets, hashtags and recency can be combined to learn a ranking model <ref type="bibr" coords="1,233.89,632.21,9.96,8.74" target="#b0">[1]</ref>.</p><p>In our experiments, we adopt a query-biased learning to rank approach by integrating a general ranking model with the query-biased model that takes the query differences into account <ref type="bibr" coords="2,287.28,118.99,9.96,8.74" target="#b7">[8]</ref>. In the combined framework, the general ranking model is learned from the 2011 microblog queries by the conventional learning to rank approach. In addition, a query-biased ranking model is learned by a transductive learning algorithm based on the pseudo relevance information. Finally, the query-biased model is combined with the general model to produce the final tweet ranking for the target queries.</p><p>The rest of the paper is organized as follows. Section 2 introduces the data pre-processing, indexing strategy and the language filter. Sections 3 givens a detail introduction of the query-biased learning to rank framework. Section 4 presents the experimental results and analysis. Finally, Section 5 concludes our experiments and suggests future research directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Pre-processing and Indexing</head><p>The corpora used in our experiments is in the format of HTML. We experiment on the Tweets11 data collection, which spans over a period of two weeks from 24th January 2011 to 8th February 2011. We successfully download 13,401,964 tweets from Twitter.com using the feeds distributed by the track organizers in 2011. Our crawl of Tweets11 consists 10,443,773 tweets after removing the defacto irrelevant tweets that are not fetchable as of 7th May 2012, as the tweets may be deleted or protected after posting. Before using it, we first convert the corpora to the TREC format. In particular, in TREC-formatted files, documents are delimited by&lt;DOC&gt;&lt;/DOC&gt; tags, as in the following example: &lt;DOC&gt; &lt;DOCNO&gt; 28968126875963392 &lt;DOCNO&gt; &lt;AUTHOR&gt; TonyFranceOH &lt;/AUTHOR&gt; &lt;TIME&gt; Sun Jan 23 00:11:54 +0000 2011 &lt;/TIME&gt; &lt;AT&gt; &lt;/AT&gt; &lt;BODY&gt; Oh, my GOD &lt;/BODY&gt; &lt;RTAT&gt; &lt;/RTAT&gt; &lt;RT&gt; if today was a boring slop day &lt;/RT&gt; &lt;/DOC&gt; In the above example, DOCNO is the tweet id; AUTHOR is the author of the tweet; TIME is the posted time of the tweet; AT contains all the mentioned users in the tweet, except those occurring in RT tweet; RT is the reposted tweet; RTAT indicates the author from which the tweet is retweeted; BODY means the remaining tweet content after removing AT, RTAT, RT.</p><p>In our experiments, we build an indivdual index for each query using an inhouse version of Terrier <ref type="bibr" coords="2,243.60,608.26,9.96,8.74" target="#b4">[5]</ref>. Both direct index and inverted index are built to support retrieval and query expansion. Standard stopword removal and Porter's stemmer are applied.</p><p>For the language filter, the LC4j package is used to detect whether a tweet is in English or not. It is a language categorization library designed for the Java programming language. It has been designed to be a compact, fast and scalable Java library that implements the algorithms to identify languages using n-grams <ref type="bibr" coords="3,134.77,142.90,14.61,8.74">[16]</ref>. In our runs, the detected non-English tweets are removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Query-biased Learning to Rank</head><p>In this section, we will give a detail introduction to the query-biased learning to rank approach <ref type="bibr" coords="3,216.02,212.94,10.52,8.74" target="#b7">[8]</ref> that utilizes both the common features of Twitter messages and the query-specific aspects that differentiate between queries. More specially, the general ranking model is learned from the 2011 microblog queries and the query-biased model is learned from the query-specific features by a semi-supervised learning algorithm. Then the two models with a learning rate are linear combined to produce a final tweet list for each given topic.</p><formula xml:id="formula_0" coords="3,181.75,297.55,298.84,9.65">Score f inal (d, Q) = Score LT R (d, Q) + β • Score QLT R (d, Q)<label>(1)</label></formula><p>where Score f inal (d, Q) is the final score of tweet d for the given query Q; Score LT R (d, Q) is the score given by the general ranking model;</p><formula xml:id="formula_1" coords="3,407.44,328.35,74.52,9.65">Score QLT R (d, Q)</formula><p>is the score given by the query-biased model. The setting of the parameter β is obtained by training on the official queries of 2011 Microblog track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">General Ranking Model</head><p>The common features used to represent the tweets and the learning to rank algorithm will be described in this section.</p><p>It is of great importance to select the feature set to generate a good ranking function in the learning to rank systems. In our experiments, the features are organized around the basic entities for each query-tweet pair to distinguish between the relevant and irrelevant messages. More specially, five types of features are exploited, namely content-based relevance, content richness, authority, recency and Twitter specific features, which were used in our previous work <ref type="bibr" coords="3,467.31,488.29,9.96,8.74" target="#b5">[6]</ref>. For the content-based relevance features, we just use DFRee <ref type="bibr" coords="3,406.63,500.24,14.61,8.74" target="#b9">[10]</ref>, DirichletKL <ref type="bibr" coords="3,134.77,512.20,10.52,8.74" target="#b8">[9]</ref> with and without query expansion.</p><p>Many learning to rank approaches have been proposed in the literature, which can be applied for learning the general ranking model. In the experiments, we adopt the pair-wise learning to rank algorithm RankSVM <ref type="bibr" coords="3,388.19,548.29,15.50,8.74" target="#b10">[11,</ref><ref type="bibr" coords="3,403.69,548.29,11.62,8.74" target="#b11">12]</ref>, which applies the traditional formulation of the SVM optimization problem by taking the document pairs and their preferences as the learning instances.</p><p>In the learning process, after the positive and negative examples are appended to the labeled set by making use of the relevance assessments information, we empirically assign preference values according to the temporal distance between the timestamps of the tweet and the query. The larger the preference value is, the higher the tweet is relevant to the given query. This labeling strategy is mainly due to the fact that recency is a crucial factor of relevance in real-time Twitter search. The fresh tweets are favored over those outdated.</p><p>The target values of RankSVM define the order of the examples of each query. We arbitrarily reassign the target values of the relevant tweets with an interval of 0.5 <ref type="bibr" coords="4,163.25,142.90,9.96,8.74" target="#b5">[6]</ref>, according to the temporal distance in days between the timestamps of the tweet and the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query-biased Ranking Model</head><p>Query-specific Tweet Representation Since the purpose of the query-biased modeling is to utilize the query-specific characteristics to boost the retrieval performance, it is a challenging issue to select the appropriate features that are unique to the given queries to represent the tweets. We choose to represent the tweets by the most informative terms in the pseudo relevance set, namely the top-ranked tweets in the initial retrieval. As queries are different to each other in their topical concepts, it is a natural choice to represent the queryspecific aspects by the most weighted terms in the pseudo relevance set, which are usually assumed to be highly related to the query topics.</p><p>Figure <ref type="figure" coords="4,180.85,312.28,4.98,8.74" target="#fig_0">1</ref> provides the algorithm used for extracting the term features for the query-specific tweet representation. In particular, all the unique terms in the top-30 tweets are taken as candidate terms, and the 10 terms with highest KL divergence weights are chosen as the query-specific features. Thus, the selected words and their corresponding KL divergence weights are used as attributes and values to represent the given tweets. Our arbitrary choice of selecting the top-10 terms from the top-30 tweets is mainly due to the fact that this setting was found to provide the best query expansion effectiveness in the TREC 2011 Microblog track, as reported in <ref type="bibr" coords="4,225.17,407.92,14.61,8.74" target="#b9">[10]</ref>. The KL divergence weight of a candidate term t in the top-k ranked tweets in the initial retrieval is computed as follows:</p><formula xml:id="formula_2" coords="4,237.33,440.30,243.26,22.31">w(t, R k ) = P (t|R k ) log 2 P (t|R k ) P (t|C)<label>(2)</label></formula><p>where P (t|R k ) is the probability of generating the candidate term t from the set of top-k ranked tweets R k , and P (t|C) is the probability of generating t from the entire collection C. The algorithm for document representation is shown in Figure <ref type="figure" coords="4,425.23,506.68,3.87,8.74" target="#fig_0">1</ref>.</p><p>Transduction for Query-biased Modeling In <ref type="bibr" coords="4,356.43,536.57,9.96,8.74" target="#b7">[8]</ref>, a query-biased transductive learning algorithm is devised to boost the retrieval performance. Transductive learning <ref type="bibr" coords="4,208.86,560.48,15.49,8.74" target="#b12">[13]</ref> is a semi-supervised method for classification by utilizing limited data Using transduction, it is not necessary to generate a model to predict the label of any unobserved point during the process of learning. In our experiments, the query-biased transduction learning algorithm and retrieval are integrated into a learning to rank paradigm. A general description of the proposed method is given in Figure <ref type="figure" coords="4,276.22,620.25,3.87,8.74" target="#fig_1">2</ref>. The underlying idea of our proposed method is similar to that of pseudo relevance feedback <ref type="bibr" coords="4,336.12,632.21,14.61,8.74" target="#b13">[14]</ref>, which assumes a high degree of relevance of the top-ranked documents. Before training, it is only required to predict the labels of a given test set examples <ref type="bibr" coords="4,329.53,656.12,14.61,8.74" target="#b14">[15]</ref>. After the initial retrieval using the content-based model, we label, the top-ranked and bottom-ranked tweets are selected as the positive and negative examples, respectively, on the hypothesis that the top-ranked tweets are highly relevant to the given query topic. In contrast, the bottom-ranked are believed to some extent off-topic in their contents.</p><p>A model is learned to predict the ranking of the remaining unlabeled tweets, from which the very top-ranked and bottom-ranked tweets are appended to the labeled data set. Such a process repeats until the number of iterations exceeds a predefined threshold. Finally, a ranking of all the retrieved tweets are produced by the query-biased model learning by the above transduction process. All the parameters in the proposed query-biased transductive learning algorithm, for example the number of iterations (i.e. N in Figure <ref type="figure" coords="5,356.25,448.52,3.87,8.74" target="#fig_1">2</ref>, are obtained by tuning on training queries. We only apply RankSVM for learning a query-biased model in this paper. This is mainly due to the small amount of pseudo training data available, where the advantage of the listwise approaches such as LambdaMART is negated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Real-time Adhoc Task</head><p>We submitted four official runs as follows:</p><p>-gucasBasic: A baseline run using DFRee with query expansion.</p><p>-gucasGen: A run using the general learning to rank approach, namely RankSVM <ref type="bibr" coords="5,151.70,620.05,14.61,8.74" target="#b10">[11]</ref>. -gucasGenReg: A run using the general learning to rank approach and simple text matching. -gucasQuery: A run using the query-biased learning to rank approach <ref type="bibr" coords="5,454.39,656.12,9.96,8.74" target="#b7">[8]</ref>. In our submitted runs, we issuse a retrieval score for each returned tweet to represent the probability of relevance to the query. In the following, we will evaluate the runs at two levels.</p><p>-Comparison of the general learning to rank (gucasGen) with the contentbased retrieval models (gucasGen).</p><p>In our experiments, we carry out a grid seach to select the optimal query expansion setting by adding different numbers of expansion terms from the diverse top-k tweets to the original query. We examine if the general learning to rank model (gucasGen) is able to improve the retrieval effectiveness over the classical content-based weighting models. From Table <ref type="table" coords="6,259.84,572.18,3.87,8.74" target="#tab_0">1</ref>, we can see that, gucasGen have relatively weak performance when evaluated under MAP, while provide better precision at 30. We suggest that the minor error of the feature extraction of recency and the regularization parameter C for RankSVM, lead to the interesting phenomenon. -Comparison of the query-biased learning to rank (gucasQuery) with the the general learning to rank (gucasGen). We examine to which extent the querybiased learning to rank approach is able to improve the retrieval effectiveness by taking query differences into consideration in Table <ref type="table" coords="7,395.32,191.84,3.87,8.74" target="#tab_1">2</ref>. It turns out that the query-biased learning to rank outperforms the general learning to rank approach when evaluating under MAP, while the precision at 30 makes no difference. It is possibly due to the fact that the large size of the test set while conducting transduction learning is limited to the top-ranked tweets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Real-time Filtering Task</head><p>Three official runs are submitted as follows:</p><p>-gucasB: A baseline run using DFRee with query expansion.</p><p>-gucasL1: A run using the query-biased learning to rank approach <ref type="bibr" coords="7,439.12,408.98,9.96,8.74" target="#b7">[8]</ref>.</p><p>-gucasL2: A run using the query-biased learning to rank approach <ref type="bibr" coords="7,446.63,420.23,10.52,8.74" target="#b7">[8]</ref> with different parameter settings.</p><p>Surprisingly, the effectiveness of the above three runs shows no difference with F=0.1009, Presion=0.0848 and Recall=0.6656, which we will investigate the reasons in the next steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>we adopt a query-biased learning learning to rank approach that utilizes both the general and query-specific evidence of relevance for the real-time Twitter search.</p><p>In particular, a query-biased ranking model is learned by a semi-supervised transductive learning algorithm in order to better capture the characteristics of the given queries. Such a query-biased ranking model is combined with a general ranking model given by the conventional learning to rank approach to produce the final ranking of the Twitter messages, namely the tweets, in response to the user information need. Extensive experiments have been conducted on the standard Tweets11 dataset to evaluate the effectiveness of our proposed approach.</p><p>Results show that the our proposed combined learning to rank approach is able to outperform strong baseline, namely the state-of-the-art learning to rank algorithms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,219.56,285.08,176.24,7.89"><head>Input D: initialFig. 1 .</head><label>1</label><figDesc>Fig. 1. The tweet representation algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,190.98,396.66,233.39,7.89"><head>Input D: initialFig. 2 .</head><label>2</label><figDesc>Fig. 2. The query-biased transductive learning algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,200.83,115.91,210.62,50.98"><head>Table 1 .</head><label>1</label><figDesc>Comparison of gucasGen with gucasBasic.</figDesc><table coords="7,235.62,136.71,144.11,30.18"><row><cell cols="3">Metrics. gucasBasic gucasGen</cell></row><row><cell>MAP</cell><cell>0.1476</cell><cell>0.1344, -9.82%</cell></row><row><cell cols="2">P@30 0.1763</cell><cell>0.1876, +6.41%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,199.12,269.75,214.05,50.98"><head>Table 2 .</head><label>2</label><figDesc>Comparison of with gucasGen.</figDesc><table coords="7,235.81,290.54,143.75,30.18"><row><cell cols="3">Metrics. gucasGen gucasQuery</cell></row><row><cell>MAP</cell><cell>0.1344</cell><cell>0.1503, +11.83%</cell></row><row><cell cols="2">P@30 0.1876</cell><cell>0.1876, 0%</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work is supported in part by the <rs type="funder">NSFC</rs> Project <rs type="grantNumber">61103131/F020511</rs>, the <rs type="funder">President Fund of UCAS</rs> (<rs type="grantNumber">Y15101FY00</rs>), and the <rs type="funder">National Key Technology R&amp;D Program of China</rs> (<rs type="grantNumber">2012BAH23B03</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_srgBEsX">
					<idno type="grant-number">61103131/F020511</idno>
				</org>
				<org type="funding" xml:id="_DuQ2KMa">
					<idno type="grant-number">Y15101FY00</idno>
				</org>
				<org type="funding" xml:id="_Pa5Gdd8">
					<idno type="grant-number">2012BAH23B03</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,138.35,222.29,342.25,7.86;8,146.91,233.25,230.41,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,381.95,222.29,98.65,7.86;8,146.91,233.25,151.94,7.86">Measuring user influence in twitter: The million follower fallacy</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Haddadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Benevenuto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">P</forename><surname>Gummadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,317.95,233.25,29.43,7.86">ICWSM</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,244.21,342.24,7.86;8,146.91,255.17,131.37,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,359.73,244.21,120.86,7.86;8,146.91,255.17,61.73,7.86">Overview of the TREC 2011 microblog track</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,228.09,255.17,22.95,7.86">TREC</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,266.12,325.02,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,243.82,266.12,147.35,7.86">Usc/isi at trec 2011: Microblog track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,410.62,266.12,22.95,7.86">TREC</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,277.08,76.07,7.86;8,260.92,277.08,219.67,7.86;8,146.91,288.04,217.78,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,397.99,277.08,82.61,7.86;8,146.91,288.04,145.67,7.86">Trec 2011 microblog track experiments at kobe university</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miyanishi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Seki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Uehara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,311.94,288.04,22.95,7.86">TREC</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,299.00,342.24,7.86;8,146.91,309.96,333.68,7.86;8,146.91,320.92,20.99,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,450.57,299.00,30.02,7.86;8,146.91,309.96,257.49,7.86">Terrier: A high performance and scalable information retrieval platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,425.76,309.96,49.82,7.86">SIGIR OSIR</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,331.88,342.24,7.86;8,146.91,342.84,70.89,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,274.20,331.88,202.46,7.86">Transductive learning for real-time Twitter search</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,158.43,342.84,29.43,7.86">ICWSM</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,353.80,342.24,7.86;8,146.91,364.75,84.02,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,254.96,353.80,177.18,7.86">Learning to rank with partially-labeled data</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kirchhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,451.93,353.80,23.89,7.86">SIGIR</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="251" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,375.71,342.24,7.86;8,146.91,386.67,225.27,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,303.74,375.71,176.86,7.86;8,146.91,386.67,54.03,7.86">Query-biased learning to rank for real-time twitter search</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,220.47,386.67,22.42,7.86">CIKM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1915" to="1919" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,397.63,342.24,7.86;8,146.91,408.59,227.54,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,252.96,397.63,227.63,7.86;8,146.91,408.59,93.27,7.86">Model-based feedback in the language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,259.35,408.59,22.42,7.86">CIKM</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,419.55,337.98,7.86;8,146.91,430.51,333.68,7.86;8,146.91,441.47,20.99,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,275.41,430.51,155.24,7.86">Fub, iasi-cnr, UNIVAQ at TREC 2011</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amodeo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Nicola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Flammini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gaibisso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gambosi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Marcone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,451.90,430.51,22.95,7.86">TREC</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,452.43,337.98,7.86;8,146.91,463.38,86.26,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,208.18,452.43,202.85,7.86">Optimizing search engines using clickthrough data</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,431.68,452.43,17.65,7.86">KDD</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,474.34,337.98,7.86;8,146.91,485.30,210.06,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,342.83,474.34,98.22,7.86">Learning to order things</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,450.00,474.34,30.59,7.86;8,146.91,485.30,132.16,7.86">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="243" to="270" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,496.26,337.97,7.86;8,146.91,507.22,169.44,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,214.26,496.26,167.26,7.86">An overview of statistical learning theory</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,403.15,496.26,77.44,7.86;8,146.91,507.22,77.96,7.86">IEEE Transactions on Neural Networks</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="988" to="999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,518.18,337.98,7.86;8,146.91,529.14,47.79,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,197.81,518.18,169.34,7.86">Relevance feedback in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rocchio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,383.72,518.18,96.87,7.86;8,146.91,529.14,20.34,7.86">Prentice-Hall Englewood Cliffs</title>
		<imprint>
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,540.10,337.98,7.86;8,146.91,551.06,20.99,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,271.50,540.10,110.73,7.86">Stable transductive learning</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>El-Yaniv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Pechyony</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,400.13,540.10,22.29,7.86">COLT</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="35" to="49" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
