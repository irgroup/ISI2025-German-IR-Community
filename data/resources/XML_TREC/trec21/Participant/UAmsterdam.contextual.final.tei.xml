<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,157.95,83.76,293.81,15.48;1,151.33,105.68,307.05,15.48">Contextual Suggestion from Wikitravel: Exploiting Community-based Suggestions</title>
				<funder ref="#_Hcvxj9C #_m7jBEry #_xYEz5Fd">
					<orgName type="full">Netherlands Organization for Scientific Research (NWO</orgName>
				</funder>
				<funder ref="#_H2twCFS">
					<orgName type="full">European Communitys Seventh Framework Program</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,140.35,138.20,75.75,10.75"><forename type="first">Marijn</forename><surname>Koolen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Humanities</orgName>
								<orgName type="laboratory">Archives and Information Studies</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,258.44,138.20,63.92,10.75"><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Humanities</orgName>
								<orgName type="laboratory">Archives and Information Studies</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Informatics Institute</orgName>
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,371.29,138.20,93.33,10.75"><forename type="first">Hugo</forename><surname>Huurdeman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Humanities</orgName>
								<orgName type="laboratory">Archives and Information Studies</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,157.95,83.76,293.81,15.48;1,151.33,105.68,307.05,15.48">Contextual Suggestion from Wikitravel: Exploiting Community-based Suggestions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">61A3B52BE3F854C9C25FFB3896942FF2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation in the TREC 2012 Contextual Suggestion Track. The goal of the track is to evaluate systems that provide suggestions for activities to users in a specific location, at a specific time, taking into account their personal preferences. As a source for travel suggestions we use Wikitravel, which is a community-based travel guide for destinations all over the world. From pages dedicated to cities in the US we extract suggestions for sightseeing, shopping, eating and drinking. Descriptions from positive examples in the user profiles are used as queries to rank all suggestions in the US. Our baseline approach merges the per-query rankings of all positive examples of all users. Our userdependent approach merges the per-query rankings of the positive examples of a single user. The rankings suggestions are then filtered based on the location of the user. We ignore the temporal aspects of the context. The user-dependent rankings are more effective for contextual suggestion than user-independent rankings. The two systems show similar perform on the geographical dimension, but the user-dependent system provides more interesting suggestions. Our results show that information on user preferences is valuable for providing appropriate suggestions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Wikitravel 1 is a collaboratively created site for travel and tourist information, with lists of things to see and do in places all over the world. Locations are neatly structured in countries, states, regions, districts, cities and suburbs and have a dedicated page, and the places to visit within each location are presented in lists and tables in each page. This information provides travellers with easy access to a list of options for sightseeing, shopping, eating, drinking and sleeping. If you find yourself in a particular city, it is easy to browse this list. For larger cities, the number of options can 1 URL: http://wikitravel.org/ be very large and is often spread over multiple pages, making it hard to find options that you like. For smaller places the list can be very short and not contain anything of interest in the immediate area, but pages on nearby places may have better options. Our aim for the TREC 2012 Contextual Suggestion Track <ref type="bibr" coords="1,410.06,278.65,11.62,8.64" target="#b0">[1]</ref> is to use Wikitravel as a source for suggestions based on the user's current location, which are ranked by distance and how well they match the user's known preferences.</p><p>We use the descriptions of the suggestions as document representations and the descriptions of preferred items in the profiles as queries to retrieve and rank suggestions.</p><p>The rest of this paper is organised as follows. We first describe our experimental setup in Section 2. We discuss our results in Section 3 and provide a more detailed analysis in Section 4. We discuss some aspects of the relevance judgements in Section 5 and summarise our findings in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data collection</head><p>Wikitravel is an open platform where anyone can add, edit and delete travel information about places in the world. There are many pages, each dedicated to a specific city or town, with sections describing how to get there and things to see and do. Most pages are structured according to some general rules, to get a consistent travel guide, with clearly separated sections for transportation, sightseeing, shopping and accommodation. Activities, attractions, restaurants and bars are usually presented in lists or tables, with the name of the shop, museum, park, restaurant or hotel, a short description and often a hyperlink to the homepage of a dedicated site. These are provided by a community of travellers and locals and can be used as a source for contextual suggestions.</p><p>We crawled all Wiki Travel pages of locations within the US, starting with the page on the United States of America as the seed list. We extracted site-internal links from all the States, Regions, Cities, Districts and Burroughs sections. The pages within the Districts and Burroughs categories de-scribe neighbourhoods in large cities. While extracting links from each of these sections, a mapping is stored that identifies how the source is connected to the target page. For instance, in the Regions section of the page for the U.S. state Oregon we extract links for the regions Cascade Mountains, Central Oregon, Columbia Gorge and four other regions. With each link we store a mapping indicating that that region is a region in the state Oregon. This hierarchical mapping can be used as an indication of distance between the location of the user and other locations. When there are not enough suggestions in the city where the user is located, we can add suggestions from cities in the same region. From the City, District and Burrough pages we extracted suggestions from the sections Do, See, Buy, Eat, and Drink. Each suggestion is identified by either a paragraph, list item or table row in html markup. We only considered items that have an hyperlink to an external web page as suggestions and used the surrounding text in the list item or table row element as description. We extracted a total of 20,200 suggestions from 1587 cities and towns. For some locations there is only a single suggestion, the median (mean) number of suggestions 4 (13). The place with the highest number of suggestions is Chicago (816 suggestions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Retrieval</head><p>Each suggestion is a document with the description as representation, which we indexed with Indri <ref type="bibr" coords="2,208.75,378.58,10.58,8.64" target="#b1">[2]</ref>. We used Krovetz stemming and removed common stopwords. In the user profiles, the description of each positive example (where the user rated the suggestion positive both when reading the description and seeing the actual page) was used as a query, resulting in the set Q + u . We ranked suggestions per query (default language model with Dirichlet smoothing, µ = 2500) and scores are merged over all queries per profile using CombSUM. The score of each retrieved suggestion is the sum of all it's score for all queries q for user u. Formally, score S(d) for suggestion d is computed as:</p><formula xml:id="formula_0" coords="2,132.13,515.22,160.77,33.06">S(d) = |Q + u | i=1 P (d|q i )<label>(1)</label></formula><p>This produces a location-independent ranking of suggestions, which can be updated each time the user adds new information to her profile. When the user wants suggestions based on where she is, the ranking is filtered on distance to her location. All suggestions within the city where the user is located are ranked first, then suggestions within the same region, then within the same state, then the rest of the suggestions. The top 50 suggestions are returned to the user. For large cities this often means all suggestions are within the same city. For smaller locations, with only a small number of suggestions, this often means the suggestions further down the list require some travelling. In Section 4 we analyse the difference between suggestions for small and large cities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Official Runs</head><p>The topic set consists of 34 user profiles, 49 examples and 50 contexts. The examples are suggestions in Toronto and consist of a short description and a URL to a dedicated website. Each user profile contains judgements from a single user on all 49 examples, with an initial judgement based on the description of the example suggestion and a final judgement after visiting the website. The contexts contain a location (city and state in the US), time of day (morning, afternoon or evening) and season of the year (spring, summer, autumn, winter).</p><p>For this year's Contextual Suggestions Track, systems have to provide 50 suggestions for each pair of user and context. There are 34 • 50 = 1700 user/context pairs. We submitted two runs:</p><p>UAmsCS12wtSUMb : this is a baseline run that is userindependent. The ranking is the based on the positive examples of all user profiles.</p><p>UAmsCS12wtSUM : This is a location-dependent run, where suggestions in the user's location are ranked first, then suggestions in the same region, then suggestions in the same state, etc.</p><p>These runs allow us to investigate the value of individual user profiles. Is the profile of an individual user better for ranking suggestions than a general profile?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>Suggestions are judged on 4 aspects: the description (D) of the suggestion, the website (W), the geographical location (G) and the temporal aspect (T). Evaluation is focused on the W, G and T dimensions. All dimensions are judged on a 3 level scale: not appropriate/interesting (0), marginally appropriate/interesting (1) and appropriate/interesting <ref type="bibr" coords="2,523.27,495.17,10.58,8.64" target="#b1">(2)</ref>. The official evaluation reports on three measures: W, GT and WGT. To be relevant for the GT measure, a suggestion has to score both G=2 and T=2. For WGT it has to score 2 for W, G and T. Evaluation results for our two official runs are shown in Table <ref type="table" coords="2,340.62,567.13,3.74,8.64" target="#tab_0">1</ref>. Columns 2, 3 and 4 are averaged over all profiles per context. Columns 5, 6 and 7 are averaged over all contexts per profile. The Median is based on the median per topic score of all submitted runs, and is calculated as the average over all median per topic scores.</p><p>The user-independent baseline UAmsCS12wtSUMb generally scores below the Median except for the website dimension per context. The user-dependent run UAm-sCS12wtSUM scores above the Median on the website dimension, but well below the Median for the geo-temporal dimension. Our system ignores the temporal aspects of the context, so the higher Median scores suggests other participating systems did incorporate temporal aspects. When we compare our two runs to each other, it is clear that using the preferences of a single user improves performance on the website dimension. Interestingly, it also improves performance on the geo-temporal dimension, even though both runs use the same distance-based filtering method and both ignore the temporal aspects of the context. In the next section we analyse performance for the individual relevance dimensions and individual topics to try and find an explanation for this phenomenon.</p><p>For the context averages, the GT and WGT scores are higher than for the profile averages. For each profile, between 16 and 19 contexts have been judged. For each context, the number of profiles judged varies between 2 and 34. From this we expect the profile means to be more stable and show less variance. The mean per context scores range from 0.0 and 0.9 while the mean per profile scores range from 0.1556 to 0.3125. It is clear that our system fails for some contexts, regardless of which user it provides suggestions for. It seems the higher G and WGT scores for context averages are caused by high scoring outliers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Analysis</head><p>In this section we take a closer look at differences between users, the per topic performance of our two methods and the impact of user-dependent result merging on the final ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Suggestions per City</head><p>Is there a relation between the number of suggestions available in the context city and the number of suggestions that are geographically relevant? If suggestions from outside the context cities are geographically irrelevant, we should focus on finding other sources for suggestions in those cities where few are provided on Wikitravel.</p><p>Figure <ref type="figure" coords="3,92.17,698.87,4.98,8.64" target="#fig_0">1</ref> shows the relation between the number of suggestions in the context city and the fraction of geographically relevant suggestions in the top 5. The x axis represents the number of suggestions in the top 50 that are located in the context city. Data points below 50 represent contexts where there are fewer than 50 suggestions on Wikitravel for that city. For instance, the data points at x = 11 represent cities where only 11 suggestions were extracted from Wikitravel. The remaining 39 suggestions in the top 50 come from other cities in the region or state. The y axis represents the precision on the geographical dimension, P@5(G). The scores below 0.4 all represent contexts where fewer than 50 suggestions are available. Almost all scores above 0.4 represent contexts where all top 50 suggestions are in the context city.</p><p>There is a clear relation between the number of suggestions available in a city and the P@5(G) score. The back-off strategy to add suggestions from other cities in the same region seems ineffective. It might be more effective to search the web for other suggestions in the context city. To what extent do users judge the suggestions of our systems differently? The user-independent ranking (UAm-sCS12wtSUMb) gives the same suggestions in the same order for all users, which allows us to compute user agreement on the judged suggestions. These are shown in rows 4 and 5 of Table <ref type="table" coords="4,88.49,466.10,3.74,8.64" target="#tab_1">2</ref>. The agreement on the initial judgements are similar to those for the examples, with a lower minimum and a larger variance. This is probably due to the low number of data points per pair of users. Only the top 5 suggestions are judged by both users, compared to the 49 data points for the examples. The agreement on the final judgements has a slightly higher mean and median than for the examples, but this may again be due to the low number of pairs and the low number of data points per pair. However, in general the agreement for judged suggestions is similar to that of the examples. This indicates judgement behaviour is similar across suggestions and examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparing Methods</head><p>Recall that both our submissions use the descriptions of positively judged examples as queries to rank suggestions. The UAmsCS12wtSUMb run ignores individual users and merges the rankings from all these queries, while the UAm-sCS12wtSUM run merges the rankings for the positive examples of a single user. How different are these rank- ings? And are the performance differences stable and similar across all user profiles and contexts, or do the two systems perform differently on only a small number of profiles and contexts? We look at the overlap in the rankings of the two systems and the per topic differences in P@5 for the different relevance dimensions. The overlap between the two runs starts at 26% at rank 1-that is, on average 0.26 of the results of the top 1 results overlap. At rank 5 the overlap is still 26%, but then steadily grows to 38% overlap at rank 50. The top of the rankings are substantially different. The ranking is very sensitive to which queries are used in producing the locationindependent ranking. That the overlap increases further down the ranking is due to the decreasing number of different suggestions to choose from when creating the locationdependent ranking.</p><p>In Table <ref type="table" coords="4,363.19,495.09,4.98,8.64" target="#tab_2">3</ref> we show the number of topics for which the user-dependent method improves performance (row 2, ↑), decreases performance (row 4, ↓) and achieves the same performance (row 3, =) as the user-independent baseline, for five relevance dimensions: geographical (column 2, G), temporal (column 3, T), geo-temporal (column 4, GT), website (column 5, W) and geo-temporal and website (column 6, WGT). Here we see that the user-independent baseline more often outperforms the user-dependent system on geographical relevance than vice versa. This is perhaps due to the larger number of queries used per context. The baseline UAmsCS12wtSUMb run uses all positive examples from all users as queries, and may match with more suggestions in the context city than the user-dependent UAmsCS12wtSUM run. However, in the majority of cases, the two systems have the same score. This is not surprising, given that they use the same geographical filtering technique.</p><p>Although both systems ignore temporal aspects of the contexts and the suggestions, there is a large difference in per-formance on the temporal relevance dimension. The userdependent system scores higher than the baseline on 267 profile-context pairs, but lower on only 137 pairs. Although this can explain the difference in P@5(GT) in Table <ref type="table" coords="5,267.20,93.14,3.74,8.64" target="#tab_0">1</ref>, it is not clear why this performance difference on temporal relevance occurs.</p><p>Figure <ref type="figure" coords="5,93.84,129.23,4.98,8.64" target="#fig_2">2</ref> shows the per topic differences for P@5(G) (top), P@5(T) (centre) and P@5(W) (bottom). This further demonstrates that both methods perform similarly on the geographical dimension, but the user-dependent system performs better on the temporal and website dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Our analysis has brought up questions about the relevance dimensions. We are not able to explain how it is possible that when both systems ignore the temporal aspects, one still clearly outperforms the other on temporal relevance. More details on the relevance judgements criteria and procedures could be insightful. How is temporal relevance judged? Is the only necessary condition that a suggested attraction or activity is available at the specified time of day? That is, do judges only consider whether the time of day falls within the opening hours of a suggested attraction? If this is the case, perhaps the user-independent baseline offers suggestions that have more restricted opening hours than the userdependent system. The user-independent baseline probably focuses on suggestions that most users like, which may be mostly day time activities or only night time activities.</p><p>For geographical relevance, we would also like to know more about the relevance criteria. How should geographic relevance be treated? A suggestion for a bar to have a coffee that is 50 miles from the user's location is perhaps less relevant than a museum with famous paintings that the user likes. One is less likely to travel far for a coffee than for some famous site or a special concert. The uniqueness of what the suggestion offers plays a role in what the user considers an acceptable distance. The mood of the user may play a role as well (I don't feel like travelling far), but is not part of the provided context. But we argue that geographical relevance depends on how appropriate the travelling distance is for the provided suggestion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we detailed our official runs for the TREC 2012 Contextual Suggestion Track. We extracted a larger number of suggestions from Wikitravel pages on cities and towns in the US and created two systems that generate geographically independent rankings. One system also ignores individual user preferences, while the other tries to take those preferences into account when ranking suggestions. Geographical filtering is done per context city, providing fast query-time result selection. P@5 (G)  Our results show that ranking suggestions based on user preferences outperforms those of the user-independent baseline. Analysis shows that the two systems have little overlap in the top suggestions, showing that tailoring the results to specific user preferences has a large impact on the ranking. Since both systems use the same geographical filtering technique, they show similar performance on the geographical dimension.</p><p>Both systems ignore the temporal aspect of the context (time of day and season), but for some unknown reason, the user-dependent ranking performs better on the temporal dimension than the user-independent baseline.</p><p>For future work, we want to incorporate temporal aspects into retrieval model by taking the opening hours of suggestions and the time of day of the context into account. We also would like to expand the number of suggestions, especially for cities with a small number of available suggestions. Sources for these suggestions could be local travel sites or the results from specific queries to general purpose search engines.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,316.81,449.58,239.10,8.64;3,316.81,461.54,171.04,8.64"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Relation between the number of intra-city suggestions and geographical precision (P@5(G).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,316.81,644.80,239.10,8.64;5,316.81,656.76,239.10,8.64;5,316.81,668.71,237.47,8.64"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Improvement per topic of user-dependent run (UAmsCS12wtSUM) over user-independent run (UAm-sCS12wtSUMb) for MRR(W) (top) and P@5(W) (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,53.80,64.07,502.11,168.87"><head>Table 1 :</head><label>1</label><figDesc>Evaluation results for the official submissions, averaged per context (columns 2-4) and averaged per profile (columns 5-7). Best scores are in bold</figDesc><table coords="3,143.16,101.70,323.40,131.24"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>P@5</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Context</cell><cell></cell><cell></cell><cell>Profile</cell><cell></cell></row><row><cell>Run</cell><cell>WGT</cell><cell>W</cell><cell>GT</cell><cell>WGT</cell><cell>W</cell><cell>GT</cell></row><row><cell>Median</cell><cell cols="6">0.1456 0.3193 0.5214 0.0943 0.3400 0.4729</cell></row><row><cell>UAmsCS12wtSUM</cell><cell cols="6">0.1429 0.3743 0.2438 0.1211 0.3772 0.2253</cell></row><row><cell cols="7">UAmsCS12wtSUMb 0.0743 0.3286 0.2360 0.0632 0.3035 0.1971</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>MRR</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Context</cell><cell></cell><cell></cell><cell>Profile</cell><cell></cell></row><row><cell>UAmsCS12wtSUM</cell><cell cols="6">0.1781 0.5321 0.3174 0.1629 0.5471 0.3089</cell></row><row><cell cols="7">UAmsCS12wtSUMb 0.1109 0.5321 0.2813 0.0962 0.5015 0.2401</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,53.80,64.07,407.15,338.09"><head>Table 2 :</head><label>2</label><figDesc>Strict pairwise agreement of different users on the provided examples # Pairs Min Max Median Mean Std.dev To what extent do users judge the examples differently? We compare the overlap in examples and within those sets the overlap of the judgements. All 34 users provided initial judgements based on descriptions and final judgements based on websites for 49 examples. This allows us to compare the pairwise agreement for each pair of users. In Table2we show statistics on the strict pairwise agreement for the examples (rows 2 and 3), in which we consider user agreement only if two users choose the exact same level of interest (0 for not interested, 1 for marginally interested, or 2 for in-</figDesc><table coords="4,53.80,107.09,360.83,83.85"><row><cell cols="2">Initial 561</cell><cell>0.18 0.76</cell><cell>0.41</cell><cell>0.41</cell><cell>0.09</cell></row><row><cell>Final</cell><cell>561</cell><cell>0.20 0.69</cell><cell>0.41</cell><cell>0.42</cell><cell>0.08</cell></row><row><cell cols="2">Initial 9</cell><cell>0.00 0.80</cell><cell>0.40</cell><cell>0.44</cell><cell>0.25</cell></row><row><cell>Final</cell><cell>9</cell><cell>0.40 0.75</cell><cell>0.50</cell><cell>0.54</cell><cell>0.13</cell></row><row><cell>4.2 Comparing Users</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note coords="4,53.80,321.79,239.10,8.64;4,53.80,333.75,239.10,8.64;4,53.80,345.70,239.10,8.64;4,53.80,357.66,239.10,8.64;4,53.80,369.61,239.10,8.64;4,53.80,381.57,239.10,8.64;4,53.80,393.52,182.89,8.64"><p>terested). There is little difference between agreement levels for initial and final judgements. The mean (median) agreement for initial judgements is 0.41 (0.41) and 0.41 (0.42) for final judgements. The maximum agreement is 0.76 for initial judgements and 0.69 for final judgements. Clearly, users have different preferences, indicating there is value in adjusting suggestions to personal preferences.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,316.81,188.75,239.10,87.53"><head>Table 3 :</head><label>3</label><figDesc>Number of topics for which user preference improves performance</figDesc><table coords="4,352.52,226.77,167.69,49.50"><row><cell cols="2">Change G</cell><cell>T</cell><cell>GT W WGT</cell></row><row><cell>↑</cell><cell cols="3">124 267 155 19 14</cell></row><row><cell>=</cell><cell cols="3">339 201 357 15 29</cell></row><row><cell>↓</cell><cell cols="3">142 137 93</cell><cell>10 1</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments This research was supported by the <rs type="funder">Netherlands Organization for Scientific Research (NWO</rs> projects # <rs type="grantNumber">612.066.513</rs>, <rs type="grantNumber">639.072.601</rs>, and <rs type="grantNumber">640.005.001</rs>) and by the <rs type="funder">European Communitys Seventh Framework Program</rs> (<rs type="grantNumber">FP7 2007/2013</rs>, Grant Agreement 270404 ).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Hcvxj9C">
					<idno type="grant-number">612.066.513</idno>
				</org>
				<org type="funding" xml:id="_m7jBEry">
					<idno type="grant-number">639.072.601</idno>
				</org>
				<org type="funding" xml:id="_xYEz5Fd">
					<idno type="grant-number">640.005.001</idno>
				</org>
				<org type="funding" xml:id="_H2twCFS">
					<idno type="grant-number">FP7 2007/2013</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,70.40,414.66,222.50,8.64;6,70.40,426.62,222.50,8.64;6,70.40,438.57,97.05,8.64" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="6,127.95,426.62,164.95,8.64;6,70.40,438.57,67.92,8.64">Overview of the TREC 2012 Contextual Suggestion Track</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dean-Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,70.40,458.50,21.86,8.64;6,111.12,458.50,181.78,8.64;6,70.40,470.45,222.50,8.64;6,70.40,483.34,38.36,7.01" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="6,111.12,458.50,181.78,8.64;6,70.40,470.45,22.28,8.64">Language modeling meets inference networks</title>
		<author>
			<persName coords=""><surname>Indri</surname></persName>
		</author>
		<ptr target="http://www.lemurproject.org/indri/" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
