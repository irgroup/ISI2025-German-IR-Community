<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,79.42,72.35,450.88,16.84;1,185.05,92.27,239.62,16.84">TREC Microblog 2012 Track: Real-Time Algorithm for Microblog Ranking Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,136.28,137.97,111.19,11.06"><forename type="first">Davide</forename><forename type="middle">Feltoni</forename><surname>Gurini</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering Artificial Intelligence Laboratory</orgName>
								<address>
									<addrLine>Roma Tre University Via della Vasca Navale</addrLine>
									<postCode>79 -00146</postCode>
									<settlement>Rome</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,373.95,137.97,87.77,11.06"><forename type="first">Fabio</forename><surname>Gasparetti</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Engineering Artificial Intelligence Laboratory</orgName>
								<address>
									<addrLine>Roma Tre University Via della Vasca Navale</addrLine>
									<postCode>79 -00146</postCode>
									<settlement>Rome</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,79.42,72.35,450.88,16.84;1,185.05,92.27,239.62,16.84">TREC Microblog 2012 Track: Real-Time Algorithm for Microblog Ranking Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CAE3AFE0273077FCE8E2DEC233761DB8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As a matter of fact Twitter is becoming the new big data container, due to the deep increase of amount of users and its growing popularity. Moreover the huge amount of user profiles and rough text data, are providing continuosly new research challenges. This paper reports our contribution and results to the Trec 2012 Microblog Track. In this particular, challenge each participant is required to conduct a "real-time" retrieval task, which given a query topic seeks for the most recent and relevant tweets. We devised an effective real time ranking algorithm, avoiding heavy computational requirements. Our contribution is multifold: (1) adapting an existing ranking method BM25 to the microblogging purpose (2) enhancing traditional content-based features with knowledge extracted from Wikipedia, (3) employing Pseudo Relevance Feedback techniques for query expansion ( <ref type="formula" coords="1,184.62,392.36,3.92,7.86">4</ref>) performing text analysis such as ad-hoc text normalization and POS Tagging to limit noise data and better represent useful information.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In the last year the huge interest in the microblog platform Twitter has been leading to large amounts of short text messages sent between users everyday. These short messages called "'tweets"' provide information ranging from job opportunities, personal opinions, newspaper articles to simply author's sentiments. The research community is now focused on different aspects such as limiting irrilevant or noisy information, employing ad-hoc POS Taggers, Named Entity Recognition tools or employing predictive analysis. In June 2012 the traffic data reached a rate of 400 million tweet per day. Consequently in order to explore the behavior and relevant features in the microblog sphere is thus required a lot of work to apply different linguist analysis techniques and data analysis methods. Our interest in microblog and social networks allowed us to partecipate in Trec Microblog 2012 Track based on Twitter corpus. Twitter corpus cover 2 weeks from Jan 23rd to Feb. 8th 2011 where TREC identified 60 query topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">MICROBLOG AD-HOC TASK 2.1 Task</head><p>This year is the second time TREC conference releases a task in microblog track. The first challenge consists in finding and ranking relevant tweets given a query topic. This task is aimed to simulate user behaviours that want to retrieve some information on Twitter using few keywords. Basically, the goal is to retrieve the best relevant tweet pertinent to the given keyword and discard the irrilevant ones. In the evaluation, all retrieved document are ordered by recency and then evaluated by traditional metrics, such as Precision @30, R-precision, MAP and ROC curve. The judgment is based on 3-level scale: non-relevant, relevant and high-relevant. In Trec 2012, only high relevant tweets are taken into consideration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Dataset</head><p>The corpus available for testing correspond to the one used in 2011, which consist approximately in 16 million documents gathered in the period 24-1-2011 and 8-02-2011. However we were able to collect around 15 million tweets due to protected users or tweet deletion. Every document contains many information for research such as information about the tweet and the user profile. We collected those tweets by means of web crawler and extract several features from the raw html source such as the url, number of retweets, if the tweet is a reply part of conversation, the location and so on. At the end of retrieval phase, two English language recognizers have been employed: TextCat<ref type="foot" coords="1,465.88,561.15,3.65,5.24" target="#foot_0">1</ref> and Apache TIKA<ref type="foot" coords="1,549.21,561.15,3.65,5.24" target="#foot_1">2</ref> . All the retweeted data are also discarded according with the TREC Microblog guidelines. Finally, the final corpus consists of 5 million tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">THE RETRIEVAL SYSTEM</head><p>Our approach is based on the idea that actual ranking algorithm based on tf-idf weighting schema and keyword matching can be a baseline for a microblog ranking system. Nevertheless this approach has large chances to be improved considering the peculiar characteristics of the domain. We started building our system entirely using the open source Figure <ref type="figure" coords="2,86.81,247.27,4.12,7.89">1</ref>: The Proposed Retrieval and Ranking System information retrieval system Apache Lucene to store and index documents. As can be seen in the Figure <ref type="figure" coords="2,251.27,296.32,4.61,7.86">1</ref> the first processing step of our approach is a ranking system based on BM25 formula implemented into Java Lucene<ref type="foot" coords="2,247.40,315.47,3.65,5.24" target="#foot_2">3</ref> and a Microblog Scoring that will be explain in the next section. This first step is also used to retrieve the top-k relevant tweets and proceed with the query expansion process in order to improve accuracy of the ranking system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Revised-BM25</head><p>Our BM25 algorithm approach is a variant of the standard BM25 ranking function. The differences between our function and standard BM25 are in the computation of term weights and the normalization of length weight. In both of the calculations we use the inverse function instead of the normal weight. Thus given a query q composed by query terms {q1..qn} , the score assigned to the document D is obtained:</p><formula xml:id="formula_0" coords="2,53.80,487.41,239.31,36.62">BM 25(q, D) = n i=1 IDFrt(qi)• 1 tf (q i ,D) • (k + 1) 1 tf i ,D) • (1 -b + (b • (LEN )) (1)</formula><p>where k and b are weight parameters set to k = 2 and b = 0.67<ref type="foot" coords="2,88.81,535.32,3.65,5.24" target="#foot_3">4</ref> , avgl (collection) is the average document lenght in the collection. LEN is the length weight normalization adjusted for short text and consequently for Twitter. We are assigning an higher score to longer tweets:</p><formula xml:id="formula_1" coords="2,121.53,591.80,171.38,23.68">LEN = 1 LEN GT H(D) avgl(collection) )<label>(2)</label></formula><p>TF is the term-frequency and IDF is inverted document frequency calculated as follows: where docFreq is the document frequency of the query word. Although Lucene provides high perfomance for indexing and searching, was hard to adapt it to the new algorithm BM25 because document frequencies and further implied features are deeply encoded in the Lucene system. Further algorithms that analyze specific social features extracted from the tweets and combined with the revised-BM25 ranking function are to be discussed in the next sections.</p><formula xml:id="formula_2" coords="2,104.79,657.18,180.27,19.74">IDF (qi) = log N -docF req + 0.5 docF req + 0.5<label>(</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Micro-Score system</head><p>As a feature of microblogs, the limitation of text length forces users to write concisely. Sometimes this means that tweets do not directly include relevant content, but contain references or other microblog specific features to represent it. Table <ref type="table" coords="2,354.68,337.35,4.61,7.86" target="#tab_0">1</ref> summaries statistics of some relevant features in tweets judged non relevant, relevant or high relevant in 2011 Twitter Corpus.</p><p>It is clear that the average noise terms (of which we will discuss later) is inversely proportional to the relevance of the tweet while the urls occur more often in high relevant tweets. Based on that statistics we propose the generalized formula:</p><formula xml:id="formula_3" coords="2,316.81,438.74,239.10,18.32">M score(T ) = α • url + β • log(rt) + γ • reply + δ • log(noisetxt)<label>(4</label></formula><p>) where the presence of some features are linearly combined altering the traditional ranking function. The first element url regards the presence of urls in a tweet. By using urls users can include many extra information such as an images, videos or correlated newspaper articles. Nonetheless we argue that analyzing every url and the page included in it, is not suitable for a real time ranking. Thus we decided to include just the feature that shows the url presence in the tweet. Another microblog feature included in the formula is the number of retweets. Preliminary experiments on small corpus used to assign weights to each feature show how this is not a so reliable indicator.</p><p>In the next step we classify the tweets in two class:</p><p>• conversational tweets</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• direct tweets</head><p>Tweets are into the former category if they are a reply to another user tweet, or they are retweets. In this case we assign zero weight, 1 otherwise. The last feature called noise terms or noise text, indicates tweets that contain noisy information. Our hypothesis is that a relevant tweet contains well written text, e.g. syntactically correct.</p><p>Therefore we extracted a subset of tweets representing a noise text class: Repeated Letter: Ex. looovee, soooo much Alphanumeric Words: Ex. 2night, 4ever, str8</p><p>Strong presence of Smiley: Ex. O_O, ^_^, :-), :)</p><p>In order to recognize those dirty text, we employed regular expression techniques. An example is given below:</p><formula xml:id="formula_4" coords="3,53.80,202.90,242.13,36.11">Repeated Letter: .*([a-zA-Z])\\1{2}.* Alphanumeric Words: [0-9]{1}[a-zA-Z]+[a-zA-Z]+[0- 9]{1}[a-zA-Z]*</formula><p>The outcome is a value close to 1 if the tweet contains an high level of syntactically incorrect content. The outcome is a value close to 0 if the tweet does not contains (in our hypothesis) noise text. Afterwards that we calculated the Mscore formula placing a value for α , β , γ and δ parameter. The linear combination between Mscore and BM25-Revised is our baseline algorithm for ranking tweet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">QUERY EXPANSION</head><p>Subsequently to a deep analysis of the microblog dataset, we discovered that some query terms are not able to retrieve all the relevant tweets. Basically, the recall is negatively altered because of the mismatch between the query keywords and the terms in the tweets (e.g., see the well-known vocabulary problem <ref type="bibr" coords="3,105.92,412.49,12.28,7.86" target="#b6">[6]</ref>. In order to improve the retrieval recall we decided to set up a full automatic query expansion module. Starting from top-15 documents ranked by our system, we follow two query expansion steps:</p><p>1. Wikipedia Topic-Entity Expansion</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Noun-Adjective Pseudo Relevance Feedback</head><p>The following sections describe in details the steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Wikipedia Topic-Entity Expansion</head><p>In this first step of query expansion we used a service called Wikify Service<ref type="foot" coords="3,136.54,540.04,3.65,5.24" target="#foot_4">5</ref> included in the Wikipedia Miner project of the Waikato University. This service automatically detects the topics mentioned a the given document, and also provides the probability that detected topics are right. Hence, we extracted the topics with best likelihood from top-15 ranked tweets and built a vector representation for the semantic analysis.</p><p>Afterward we analyze the semantic relatedness between the extracted topics and the original query terms using the Compare Service<ref type="foot" coords="3,137.92,634.19,3.65,5.24" target="#foot_5">6</ref> of Wikipedia Miner. Figure <ref type="figure" coords="3,261.54,635.95,4.61,7.86" target="#fig_0">2</ref> shows an example of how semantic relation works in Wikimedia Miner. In few words the relatedness measures are calculated from the links going into and out of each page. Links that are common to both pages are used as evidence that they are related, while links that are unique to one or the other indicate the opposite. The page is the Wikipedia Page representing the term (if available). For the query expansion we suppose that if the extracted Wikipedia topic and the query term have an high semantic similarity, the topic can be quite good for the query expansion. The principal benefit of this approach is that, given ambiguous terms, such as NSA, we are able to obtain the potential meanings (e.g, National Security Agency, Information Security). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Noun-Adjective Pseudo Relevance Feedback</head><p>The second step of query expansion analyzes the lexicon contained in top-15 ranked tweet. In order to automatically extract the terms for expansion we used the Pseudo Relevance Feedback approach. Basically we selected the top-15 ranked documents and, using a Part of Speech Tagger 7 , we extracted the Proper Nouns (NNP) and Adjectives found in the documents. Finally, we ranked those terms with tfidf weight schema, to better represent relevant terms. The entire process can be summarized as follows:</p><p>1. Select top-15 documents from First Retrieval 2. Process all documents with POS Tagger 3. Extract Noun and Adjectives words 4. Weight extracted words with ft-idf formula</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Select top-3 extracted words for query expansion</head><p>At the end of Wikipedia and Pseudo Relevance Feedback processes, we combined both modules inserting the terms into the original query. If the terms -for some reasonsare not available, the following step is skipped. In order to assign a weigth for the expanded terms we used the Lucene boosting feature. Preliminary tests have led us to set to 1 the weight of the original query terms and 0.3 for the expanded terms. An example of expansion is:</p><p>• &lt;QUERY TOPIC&gt;: 108</p><p>• &lt;QUERY&gt;: &lt;identity theft protection&gt;</p><formula xml:id="formula_5" coords="4,67.12,57.64,227.77,18.32">• &lt;EXPANDED&gt;: &lt;identity theft protection Crime^0.3 Fraud^0.3 Service^0.3 &gt;</formula><p>where all the query terms are combined by the OR operator. Thus, a possible query term vector is identity theft fraud or identity protection service. Finally, the final query expanded is given in input to the Revised-BM25 and Mscore retrieval system, in order to rerank the documents. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EVALUATION</head><p>In this section we present the offical 2012 Trec evaluation for ad-hoc task. We submitted only one run to microblog challenge. Our run -"AIRUN1 "-uses no future evidence but employs external evidence such as Wikipedia Miner. Furthermore, we submitted a full automatic run without manual interation. Figure <ref type="figure" coords="4,82.95,471.66,4.61,7.86" target="#fig_1">3</ref> shows some statistics about our run such as MAP and R-Precision. Table <ref type="table" coords="4,149.43,482.12,4.61,7.86" target="#tab_1">2</ref> shows high relevant official results detected by TREC, and our self-made evaluation for all relevant results <ref type="foot" coords="4,104.56,501.27,3.65,5.24" target="#foot_6">8</ref> . Figure <ref type="figure" coords="4,84.35,513.50,4.61,7.86">4</ref> shows the difference between our median P@30 and median P@30 of all other runs, for each query topic. AIRUN1 outperforms the median in most of query-topics. However in few cases our system is quite under the median and our expectations. In detail we recognize the topics 81, 85, 89 in which our system has scored almost zero for P@30 and MAP. The query expansion activity process was not able to extract relevant adjectives and noun in the lexicon. Nevertheless our system is able to improve Lucene baseline score, in particular with query expansion and the MScore modules. In Table <ref type="table" coords="4,130.12,618.11,4.61,7.86" target="#tab_2">3</ref> we summarized the score of each module, from Lucene baseline to the full working system with BM25+Mscore+QueryExpansion modules. We achieved an improvement from 0.19 to 0.29 in Precision@5 using the combination of all the developed modules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>All Relevant</head><p>High Relevant P@5 P@30 MAP R-prec P@30 MAP 2012 AIRun 0.501 0.40 0.331 0.193 0.2 0.152 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSIONS</head><p>In this paper we described the approach for the TREC 2012 Microblog Track. We propose an effective and straighforward real-time algorithm for ranking tweets that is able to exploit traditional retrieval and semantic annotation tools. The evaluation confirms that the approach is able to rank high relevant tweets with 0.2 Precision@30 higher than the median of all approaches. It is interesting to take in consideration users interests, their older tweets and friends in order to create a basic user profiling. We are planning also to try some effective improvement in our query expansion system and in Microblog-Score. In particular we are studying techniques for identifying authoritative and influential users given a specific topic. In our opinion this combined approach can improve the ranking system, limiting issues related to spam documents. Finally we will investigate the improvement of discovering the dirty text class, and propose a Machine Learning approach to identify and automatically normalize this class of problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,320.05,309.27,232.48,7.89;3,316.81,171.54,246.22,123.46"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Wikipedia relation between cat and dog</figDesc><graphic coords="3,316.81,171.54,246.22,123.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,99.31,350.85,148.09,7.89;4,60.32,164.16,226.07,172.42"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Summary of AIRUN1</figDesc><graphic coords="4,60.32,164.16,226.07,172.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,285.07,55.49,277.10,615.34"><head>Table 1 :</head><label>1</label><figDesc>General statistic of Twitter features</figDesc><table coords="2,285.07,662.98,7.84,7.86"><row><cell>3)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,316.81,105.68,239.11,102.79"><head>Table 2 :</head><label>2</label><figDesc>2012 High Relevant Official Results and All</figDesc><table coords="4,316.81,116.14,198.37,92.32"><row><cell cols="2">Relevant Unofficial Results</cell><cell></cell><cell></cell></row><row><cell>AIRUN1</cell><cell cols="3">P@5 P@30 MAP</cell></row><row><cell cols="2">Lucene baseline 0.19</cell><cell>0.12</cell><cell>0.08</cell></row><row><cell>+ Bm25(Rev.)</cell><cell>0.23</cell><cell>0.14</cell><cell>0.10</cell></row><row><cell>+ Mscore</cell><cell>0.27</cell><cell>0.17</cell><cell>0.13</cell></row><row><cell>+ Q.E.</cell><cell cols="2">0.29 0.208</cell><cell>0.15</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,316.81,221.36,239.10,482.80"><head>Table 3 :</head><label>3</label><figDesc>High relevant score evaluated for every module of our approach</figDesc><table coords="4,316.81,456.65,239.10,18.35"><row><cell>Figure 4: Difference -for each query topic-between</cell></row><row><cell>median P@30 and AIRUN P@30</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,53.80,216.62,239.11,18.35"><head>Table 4 :</head><label>4</label><figDesc>List of groupID in the Ad-hoc task sorted by best P@30</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,321.42,700.86,124.61,7.86"><p>http://textcat.sourceforge.net/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,321.42,711.19,93.84,7.86"><p>http://tika.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,58.40,682.92,234.50,7.86;2,53.80,691.89,239.11,7.86;2,53.80,700.86,191.54,7.86"><p>The first version of our Java implementation of BM25 ranking algorithm for Lucene, is available for download at http://code.google.com/p/bm25-lucene-score/ .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,58.40,711.19,182.32,7.86"><p>This values are obtained by preliminary tests</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="3,58.40,682.92,143.81,7.86;3,222.61,682.92,70.30,7.86;3,53.80,691.89,165.65,7.86"><p>Live demo is available here: http://wikipediaminer.cms.waikato.ac.nz/services/?wikify</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="3,54.25,700.45,3.65,5.24;3,58.40,702.22,143.81,7.86;3,222.61,702.22,70.30,7.86;3,53.80,711.19,175.13,7.86"><p><ref type="bibr" coords="3,54.25,700.45,3.65,5.24" target="#b6">6</ref> Live demo is available here: http://wikipediaminer.cms.waikato.ac.nz/services/?compare</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6" coords="4,58.40,702.22,234.50,7.86;4,53.80,711.19,82.15,7.86"><p>The evaluation was performed using the same metrics released by the TREC</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,58.28,474.96,96.81,10.75" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.59,494.00,186.63,8.12" xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Apache</forename><surname>Lucene</surname></persName>
		</author>
		<ptr target="https://apache.lucene.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.59,505.46,89.32,7.86;5,72.59,516.56,213.98,7.47;5,72.59,526.38,20.96,7.86" xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Trec</forename><surname>Microblog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Track</forename></persName>
		</author>
		<ptr target="https://sites.google.com/site/microblogtrack/" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.59,537.84,206.97,7.86;5,72.59,548.30,20.96,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="5,165.26,537.84,110.41,7.86">Microblog track 2011 of fdu</title>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">H</forename><surname>Bingqing</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wang</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.59,559.75,203.82,7.86" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">Z</forename><surname>Charu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename></persName>
		</author>
		<title level="m" coord="5,177.97,559.75,70.02,7.86">Mining Text Data</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.59,571.21,199.42,7.86;5,72.59,581.67,220.31,7.86;5,72.59,592.13,74.03,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="5,118.61,571.21,153.40,7.86;5,72.59,581.67,108.57,7.86">Twittersa: un sistema per l&apos;analisi del sentimento nelle reti sociali</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Feltoni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>Roma Tre University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct coords="5,72.59,603.59,193.80,7.86;5,72.59,614.05,220.32,7.86;5,72.59,624.51,48.01,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,156.92,603.59,109.48,7.86;5,72.59,614.05,119.90,7.86">The vocabulary problem in human-system communication</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>George</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,199.92,614.05,92.98,7.86;5,72.59,624.51,17.99,7.86">Communications of the ACM</title>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.59,635.97,217.56,7.86;5,72.59,646.43,201.20,7.86;5,72.59,656.89,179.13,7.86;5,72.59,667.35,130.04,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,231.99,635.97,58.16,7.86;5,72.59,646.43,197.28,7.86">Twittersearch: a comparison of microblog search and web search</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Jaime Teevan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,72.59,656.89,179.13,7.86;5,72.59,667.35,102.14,7.86">Proceedings of the fourth ACM international conference on Web search</title>
		<meeting>the fourth ACM international conference on Web search</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.59,678.81,198.42,7.86;5,72.59,689.27,62.54,7.86" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="5,134.45,678.81,136.56,7.86;5,72.59,689.27,34.24,7.86">Syntactic normalization of twitter messages</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kaufmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.59,700.73,213.25,7.86;5,72.59,711.19,179.31,7.86" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="5,137.77,700.73,148.07,7.86;5,72.59,711.19,151.45,7.86">Author model and negative feedback methods on trec 2011 microblog track</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,335.60,57.64,210.15,7.86;5,335.61,68.10,203.10,7.86;5,335.61,78.56,209.86,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,401.69,57.64,144.06,7.86;5,335.61,68.10,96.78,7.86">Integrating the probabilistic models bm25/bm25f into lucene</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Prez-Iglesias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,439.40,68.10,99.31,7.86;5,335.61,78.56,181.96,7.86">Proceedings of the fourth ACM international conference on Web search</title>
		<meeting>the fourth ACM international conference on Web search</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,335.60,90.02,209.55,7.86;5,335.61,100.48,152.77,7.86" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="5,435.21,90.02,109.94,7.86;5,335.61,100.48,75.70,7.86">Ranking tweets considering trust and relevance</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ravikumar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,335.60,111.93,201.39,7.86;5,335.61,122.39,206.82,7.86;5,335.61,132.85,201.03,7.86;5,335.61,143.32,140.63,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="5,503.37,111.93,33.62,7.86;5,335.61,122.39,127.43,7.86">Ranking approaches for microblog search</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Rinkesh Nagmoti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Cock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,470.02,122.39,72.41,7.86;5,335.61,132.85,201.03,7.86;5,335.61,143.32,112.40,7.86">IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,335.60,154.77,213.26,7.86;5,335.61,165.23,192.14,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="5,466.45,154.77,82.42,7.86;5,335.61,165.23,59.34,7.86">Overview of the trec 2011 web track</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,401.85,165.23,77.24,7.86">Proceedings of Trec</title>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
