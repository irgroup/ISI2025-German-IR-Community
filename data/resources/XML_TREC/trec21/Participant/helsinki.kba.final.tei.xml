<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,201.19,115.96,212.96,12.62;1,224.64,133.89,166.09,12.62">Term Association Analysis for Named Entity Filtering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,188.54,171.86,53.15,8.74"><forename type="first">Oskar</forename><surname>Gross</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,252.24,171.86,68.50,8.74"><forename type="first">Antoine</forename><surname>Doucet</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory" key="lab1">Normandy University -UNICAEN GREYC</orgName>
								<orgName type="laboratory" key="lab2">UMR-6072</orgName>
								<orgName type="institution">CNRS</orgName>
								<address>
									<postCode>F-14032</postCode>
									<settlement>Caen Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,350.67,171.86,71.67,8.74"><forename type="first">Hannu</forename><surname>Toivonen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,201.19,115.96,212.96,12.62;1,224.64,133.89,166.09,12.62">Term Association Analysis for Named Entity Filtering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5E7AD88C8219955D0D1364C57987A25E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of the Universities of Helsinki and Caen in the first round of the TREC Knowledge Base Acceleration track 3 . The task focused on filtering a stream of documents relevant to a set of entities. Our approach uses word co-occurrence graphs for modelling the named entities. We submitted two runs that achieved an average F-measure superior to the mean of all submitted runs. The best of those runs ranked in the top 5 runs for both the central and relevant F-measures, out of a total of 43 runs submitted by 11 institutions. As our runs were the produce of a first implementation of our approach, these preliminary results are very supportive of our idea to use concept graphs for modelling named entity relations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge bases (e.g., Wikipedia) collect, structure and validate information about certain entities or events. At the moment articles in the knowledge bases are managed by humans and new information is added to articles with some delay. According to Frank et al. <ref type="bibr" coords="1,272.20,540.42,10.52,8.74" target="#b0">[1]</ref> the median delay of the updates in Wikipedia is 356 days. Automatically detecting news stories, which are novel and relevant to Wikipedia articles would considerably decrease the amount of human labour needed to perform this task. In addition to knowledge base acceleration, other potential applications include media monitoring, topic mining and advertising.</p><p>We propose a graph based method for relating documents to target named entities. The fundamental idea of the method is to model a named entity by analysing its co-occurring concepts. We provide a methodology for creating named entity specific graphs, which we use for filtering documents.</p><p>The rest of the paper is organized as follows: in the next section we will introduce the related work. In Section 3 we will introduce the method for generating concept graphs. How to filter the documents using the proposed method will be described in Section 4. We evaluate our method and compare its results to the state of art in Section 5. Finally, conclusions are drawn in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Named-entity filtering, from a stream of news data, is related to several fields where discovering and following-up on events concerning a given topic is especially valuable. In all these fields, the ability to identify named-entities is an essential performance enhancer.</p><p>Followingly, this task concerns diverse fields of information retrieval, such as news surveillance <ref type="bibr" coords="2,228.68,277.97,9.96,8.74" target="#b1">[2]</ref>, entity linking <ref type="bibr" coords="2,310.23,277.97,10.52,8.74" target="#b2">[3]</ref> and text categorization <ref type="bibr" coords="2,433.09,277.97,9.96,8.74" target="#b3">[4]</ref>. In this section, we will focus on the closest and most significant papers, notably on the approaches developed during the recent TREC KBA track, whose first round in 2012 <ref type="bibr" coords="2,158.01,313.83,10.52,8.74" target="#b0">[1]</ref> focused specifically on the task of named-entity filtering.</p><p>News Surveillance. The task of news surveillance is to give alerts for all the events related to a given domain of interest. For instance, health agencies (e.g., the World Health Organization) wish to be informed of every case of occurrence of a transmittable disease, as close as possible from the moment when it occurred <ref type="bibr" coords="2,166.03,383.36,9.96,8.74" target="#b1">[2]</ref>. Other typical fields of application lie in the field of intelligence, and in finance, where the era of high frequency trading turned the apprehension of news milliseconds earlier into a decisive advantage. However, most approaches are strongly domain-dependent, requiring thousands of syntactic patterns to detect relevant news alerts <ref type="bibr" coords="2,243.97,431.18,9.96,8.74" target="#b4">[5]</ref>.</p><p>Entity Linking. Entity Linking is the task of automatically linking phrases occurring in a document to entries in a knowledge base. Several comparative evaluation competitions have run in the recent past, testifying on the great progress achieved (INEX's Link-the-Wiki <ref type="bibr" coords="2,276.13,488.75,9.96,8.74" target="#b5">[6]</ref>, Text Analysis Conference's Knowledge Base Population (KBP) <ref type="bibr" coords="2,219.17,500.70,10.30,8.74" target="#b6">[7]</ref>). Entity linking is nowadays a well-understood problem, that paves one way leading towards named-entity filtering : once the namedentities are marked within a text, it "only" remains to compute the centrality and relevance of the named entity: is it the main topic of the document, or is it simply mentioned?</p><p>Many of the methods presented in the TREC KBA track follow up from entity linking. This is natural, since the corpus was provided with pre-extracted named-entities.</p><p>Liu and Fang <ref type="bibr" coords="2,209.01,596.34,10.52,8.74" target="#b7">[8]</ref> presented one of the best performing approaches of the KBA track, by building "entity profiles". By fetching a snapshot of the Wikipedia, and considering the anchor text of all internal Wikipedia links as related entities, they defined a wider representation of named entities. <ref type="bibr" coords="2,149.71,644.16,66.29,8.74">Araujo et al. [9]</ref> underlined that 4% of the Wikipedia citations do not mention the Wikipedia they are cited by. This motivates their focus on the detection of documents that do not mention a named entity that is yet central to it. To achieve this, they fed their model with the Google Cross-Lingual Dictionary (GCLD) <ref type="bibr" coords="3,175.66,142.90,14.61,8.74" target="#b9">[10]</ref>, a ready-made resource associating Wikipedia entries to strings. As the TREC KBA topics are named-entities for which a Wikipedia entry is defined, they could replace the topics with the strings returned by the GCLD. With adequate parameters, the technique obtained the best performance for centrality and relevance.</p><p>Text Categorization. Text categorization is the task of assigning categories to a text, given a training set of text-category assignments. Text filtering is the special case when there is only one category, and the classifier is only to decide whether a given text belongs to it, or not. Such a categorization is usually led based on word term features, and the best-performing technique in the state of the art is the well-known SVM <ref type="bibr" coords="3,272.38,275.73,14.61,8.74" target="#b10">[11]</ref>.</p><p>Kjersten and McNamee <ref type="bibr" coords="3,253.54,287.95,15.50,8.74" target="#b11">[12]</ref> hence proposed to filter the document sets, using the SVM classifier over a set of features composed of the named entities provided by the TREC KBA organizers. Positive examples from the training set were those marked as central. All the others were considered negative. The technique proved that this was achievable, and it obtained the best and second-best performance (out of 40 runs) for centrality.</p><p>Other approaches. The approaches presented at TREC KBA 2012 can essentially be split into two categories <ref type="bibr" coords="3,252.31,384.90,9.96,8.74" target="#b0">[1]</ref>: those that exploit rich features from a Knowledge Base (Wikipedia or Google Dictionary) and those that focus on machine learning techniques (such as SVM).</p><p>Unlike the approaches from the first category, our technique is endogenous, that is, it does not make use of any resources that are not present in the corpus. Hence, it can easily generalize accross domains and languages (even though, the latter was not yet verified).</p><p>To the best of our knowledge, no recent techniques have been proposed that would rely on the construction and exploitation of concept association graphs. The closest example was introduced by Gamon <ref type="bibr" coords="3,348.46,493.03,14.61,8.74" target="#b12">[13]</ref>. He adressed the problem of novelty detection by building an association graph connecting sentences and sentence fragments, and chose to exploit a number of graph-based features that were assumed to be good indicators of novelty. The method tied with the best techniques presented in the TREC novelty track 2 years earlier <ref type="bibr" coords="3,424.62,540.85,14.61,8.74" target="#b13">[14]</ref>, but the authors himself questioned the significance of the improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Named Entity Graphs</head><p>Our method is based on the idea, that a news item is related to a named entity when it is connected to concepts which are also connected to the named entity. Thus our approach consists of two steps:</p><p>1. Calculate which concepts are related to each topic item (named entity graphs); 2. Calculate, for each news story, the overlap between the concepts related to the named entity and those related to the news story.</p><p>In this report we present a very simple approach: due to time constraints, our runs were only meant to eavaluate the potential of our approach. The generalization of the method to graphs, is here to provide a foundation on which we can base our future work. Indeed, our TREC KBA 2012 experiments used only the 1st level associations of the named entity graphs.</p><p>Stanford NER processing. Before using the news stories, we processed the Stanford NER data as follows:</p><p>1. Concatenate named entity names with underscore (if the type (organization, person etc) of the previous word is the same as the current word, they are concatenated together) 2. Remove all words which are not nouns We extract nouns and named entities from the documents and discard everything else. In addition to simplicity, this choice is motivated by nouns and named entities being conceptually more basic than concepts referred to by verbs or prepositions <ref type="bibr" coords="4,190.53,359.80,14.61,8.74" target="#b14">[15]</ref>. We then lowercase and lemmatize all the words. Named entity graphs. The named entity graphs are calculated by using the annotation data and all the news stories before the cutoff period. The graph generation consists of two steps: (1) we calculate the co-occurrence graph using the documents; (2) we clean the graph, by removing unnecessary edges and nodes.</p><p>The first step is based on log-likelihood ratio calculation. Consider the set of documents, which are connected (by annotation) to named entity n, by d ∈ C n . We will consider a document d as bag of sentences S d and each sentence as bag of words T d ∈ S d . The set of all words is T = T d .</p><p>We analyze word co-occurrences on the granularity of sentences, since words which are in one sentence have a strong relation to each other <ref type="bibr" coords="4,408.40,509.24,14.61,8.74" target="#b15">[16]</ref>.</p><p>The named entity graph</p><formula xml:id="formula_0" coords="4,134.77,522.05,345.82,21.61">G n = (V n , E n , W n ) is a weighted, undirected graph with nodes V n , edges E n ⊂ V n × V n , and edge weights W n : V n × V n → R + .</formula><p>For notational convenience, we assume W (e 1 , e 2 ) = 0 if there is no edge between e 1 and e 2 .</p><p>The construction of the graph then starts, using all terms in the corpus C n as its nodes, i.e., V = T .</p><p>We use log-likelihood ratio (LLR) to measure the strength (or unexpectedness) of an association between two terms <ref type="bibr" coords="4,320.76,607.44,14.61,8.74" target="#b16">[17]</ref>.</p><p>LLR measures how much the observed joint distribution of terms x and y differs from their distribution under the null hypothesis of independence, i.e., how surprising is their association. Edges are constructed for each term pair {e 1 , e 2 } in T that has a high-enough LLR value.</p><p>In other words, we compute LLR for the union P of all the pairs of terms in all sentences of the corpus</p><formula xml:id="formula_1" coords="5,259.91,153.86,220.68,20.81">P = d∈Cn s d ∈d s d × s d .<label>(1)</label></formula><p>Cleaning the graphs. The goal of the graph cleaning process is to remove unncessary edges and nodes. We are interested in keeping only associations that are directly related to the named entity. In this aim, we first calculate the combinations N of the different parts of the named entity. Consider a named entity "Annie Laurie Gaylor". For this named entity the possible combinations are N = {"Annie Laurie Gaylor", "Annie Laurie", "Annie Gaylor", "Laurie Gaylor", "Annie", "Laurie", "Gaylor"}. In the next step we leave only such edges, for which e 1 ∈ N or e 2 ∈ N .</p><p>Our experiments showed, that there are nouns, which appear in all the named entity graphs. For overcoming this noisiness problem, we removed all nodes that appeared in every single named entity graph, since their discriminative power is subsequently very weak. Let the set of all topic graphs be G n ∈ Γ . We construct the set of nodes which are found in all the graphs as:</p><formula xml:id="formula_2" coords="5,276.89,353.79,61.58,20.06">U = GninΓ V n .</formula><p>The following nodes are hence removed from all the graphs:</p><formula xml:id="formula_3" coords="5,211.01,406.60,193.34,9.65">G n = (V \ U, {e ∈ E : e 1 / ∈ U ∧ e 2 / ∈ U }, W ).</formula><p>For demonstration purposes, we extracted the highest weighted edges and respectively adjacent nodes from two graphs -one is the graph of the pianist Boris Berezovsky, and another is for the businessman Boris Berezovsky. The resulting graphs can be seen on Figure <ref type="figure" coords="5,312.44,463.94,4.98,8.74" target="#fig_0">1</ref> for the pianist and Figure <ref type="figure" coords="5,441.57,463.94,4.98,8.74" target="#fig_1">2</ref> for the businessman.</p><p>In the next section we will show how we utilise these graphs for detecting the news stories which are related to a given topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Document Filtering</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Principles</head><p>To be able to rank documents with respect to the names entities of any given TREC KBA topic, consisting of one or more named entities, it remained to design a way to compute relevance scores based on our novelty model.</p><p>We did so by relying on the concept of word co-occurrence, with the following principles in mind, on what we expect a more interesting document to be like :</p><p>-the concepts in document should intersect with concepts related to NE; -the other (unrelated) neighbours should not be penalized for. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Document Relevance Evaluation</head><p>Following the preprocessing step described in the previous section, we use the weights in the named entity graph to calculate the relevance of documents as follows.</p><p>Our main idea is that document relevance is calculated by measuring how strongly words in the document are connected to the named entity. Let us consider the target document d t , containing the words w t .</p><p>For a given named entity n we calculate the relevance status value r between the document d t and the entity graph G n as:</p><formula xml:id="formula_4" coords="6,222.07,544.86,171.21,26.80">RSV (G n , d t ) = 1 |w t | w∈wt v∈Vn W (w, v),</formula><p>which is the average edge weight of the words in the named entity graph. To produce our 2 runs,we used two different thresholding methods:</p><p>1. For the first run, helsinki-disgraph50, we used a fixed, rule-of-thumb threshold of 30; 2. For the second run, helsinki-disgraph250, we used the mean value of the weights of the entity graph of the current entity. 5 Run Description</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Testing and Results</head><p>To get a first glimpse of the suitability of our methodology, we experimented with the training data provided, using the following procedure.</p><p>We first split the training data into a learning set and a test set, containing, respectively, 80% and 20% of the training documents. Splitting the data was done according to chronology: the news stories assigned to the training set occurred before those assigned to the test set.</p><p>To estimate the accuracy of our method, we first built the graphs for each target topic. Then, for each document d, we ran the following procedure through the test data: Followingly, we obtained a document sample containing all annotated documents, and all documents with a score higher than 0, that is, all those documents containing words that are directly related to the corresponding TREC KBA topic. We then split this dataset into two disjoint subsets named related and unrelated. The related set contained the documents for which the annotation decision was set to "are related", while all the other documents were thrown into the unrelated set. The corresponding prediction was encouraging, with an area under the ROC curve around 0.77.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Submitted Runs and Results</head><p>Using this methodology, we submitted two runs to the KBA track, disgraph and disgraph2. The main methodology for both of the methods was the same, and, as mentioned earlier, the only difference was in the threshold selection method. For disgraph the threshold was manually set to 30 and for disgraph2 the threshold was equal to the mean value of each named entity graph.</p><p>We calculated the named entity graphs on the whole training set, i.e., using all the data before the cutoff date, which was 31.12.2011 23:59:59. The named entity graphs were then used for scoring documents by using the two different thresholding methods.</p><p>The performance of our two runs, disgraph and disgraph2, are summarized in Table <ref type="table" coords="8,174.65,596.27,3.87,8.74">1</ref>. The detailed performance of both runs over different cut-off values is given respectively in Figures <ref type="figure" coords="8,272.11,608.22,4.98,8.74" target="#fig_3">3</ref> and<ref type="figure" coords="8,299.78,608.22,3.87,8.74" target="#fig_4">4</ref>.</p><p>The mean average F-measure for the KBA-track was 0.2066 and the best run's average F-measure was 0.4263. Taking into account documents in which topic named entities were marked both relevant and central, the run disgraph2 was ranked 3rd (out of 43) in terms of macro-averaged F-score, and 5th in terms </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper we proposed a method for filtering documents according to named entities. The method relies on finding the concepts, i.e., nouns and other named entities, which are related to the respective named entity.</p><p>The method was designed with the goal to be as language independent as possible. Another aspect we took into account was the interpretability and the possibility to generalize the method in the future.</p><p>The method works well, performing amongst the top 5 runs out of 43, in terms of F-measure over documents in which the topic was judged relevant and central. This is a very encouraging result for further exploring the idea of modeling named entity relations through concept association graphs.</p><p>Essential future work is to become able to update the named as the stream is analyzed. In our current implementation, the named entity graph is statically based on documents prior to the cutoff date of 31.12.2011 at 23:59:59, and we observed a clear and steady decrease in precision as the documents processed were getting farther from this date.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,134.77,367.02,345.83,7.89;6,134.77,378.00,140.66,7.86;6,134.77,115.83,345.83,236.41"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The graph for the pianist Boris Berezovsky. We have omitted the edge weights for the sake of clarity of the figure.</figDesc><graphic coords="6,134.77,115.83,345.83,236.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,134.77,367.02,345.83,7.89;7,134.77,378.00,173.48,7.86;7,134.77,115.83,345.83,236.41"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The graph for the businessman Boris Berezovsky. We have omitted the edge weights for the sake of clarity of the figure.</figDesc><graphic coords="7,134.77,115.83,345.83,236.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,138.97,558.58,330.05,8.74;7,150.93,568.92,329.66,8.74;7,168.64,580.88,98.66,8.74;7,150.37,592.03,147.22,9.65;7,151.48,603.17,159.51,8.74"><head>1 .</head><label>1</label><figDesc>Compute the relevance score of document d (as described in Section 4.2) (a) If the document was assessed by the annotators, store the annotator decision and the score; (b) If score d &gt; 0, store the value; (c) Otherwise, ignore the document.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,134.77,325.13,345.82,7.89;8,134.77,336.12,20.74,7.86;8,177.99,115.83,259.37,194.53"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Run "disgraph": Precision, Recall, F-measure and Scaled Utility w.r.t. cut-off value</figDesc><graphic coords="8,177.99,115.83,259.37,194.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="9,134.77,325.13,345.83,7.89;9,134.77,336.12,20.74,7.86;9,177.99,115.83,259.37,194.53"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Run "disgraph2": Precision, Recall, F-measure and Scaled Utility w.r.t. cut-off value</figDesc><graphic coords="9,177.99,115.83,259.37,194.53" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.96,202.02,337.64,7.86;10,151.52,212.98,329.07,7.86;10,151.52,223.94,39.41,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="10,187.39,212.98,293.21,7.86;10,151.52,223.94,16.79,7.86">Building an Entity-Centric Stream Filtering Test Collection for TREC 2012</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kleiman-Weiner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename></persName>
		</author>
		<imprint>
			<biblScope unit="volume">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,235.26,337.63,7.86;10,151.52,246.22,329.07,7.86;10,151.52,257.15,108.62,7.89" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,253.26,246.22,223.49,7.86">Internet surveillance systems for early alerting of threats</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Linge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Steinberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Yangarber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Van Der Goot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Al Khudhairy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Stilianakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,151.52,257.18,66.27,7.86">Eurosurveillance</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,268.50,337.64,7.86;10,151.52,279.46,329.07,7.86;10,151.52,290.42,235.48,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="10,259.66,268.50,216.53,7.86">Wikify!: linking documents to encyclopedic knowledge</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Csomai</surname></persName>
		</author>
		<editor>Silva, M.J., Laender, A.H.F., Baeza-Yates, R.A., McGuinness, D.L., Olstad, B., Olsen, .H., Falco, A.O.</editor>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>CIKM, ACM</publisher>
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,301.74,337.64,7.86;10,151.52,312.68,85.12,7.89" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,212.31,301.74,201.19,7.86">Machine learning in automated text categorization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,420.84,301.74,59.75,7.86;10,151.52,312.70,21.27,7.86">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,324.02,337.63,7.86;10,151.52,334.98,300.57,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,216.31,324.02,264.28,7.86;10,151.52,334.98,96.75,7.86">A survey of methods to ease the development of highly multilingual text mining applications</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Steinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,256.27,334.98,145.66,7.86">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,346.31,337.64,7.86;10,151.52,357.27,205.29,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="10,342.06,346.31,133.97,7.86">Focused access to xml documents</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Trotman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Geva</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page" from="373" to="387" />
			<pubPlace>Berlin, Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,368.59,337.63,7.86;10,151.52,379.55,329.07,7.86;10,151.52,390.51,329.07,7.86;10,151.52,401.47,309.98,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,239.49,368.59,241.10,7.86;10,151.52,379.55,22.87,7.86">Knowledge base population: successful approaches and challenges</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,195.51,379.55,285.08,7.86;10,151.52,390.51,206.19,7.86">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1148" to="1158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,412.79,337.63,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="10,223.42,412.79,252.96,7.86">Entity Profile based Approach in Automatic Knowledge Finding</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,435.07,337.63,7.86;10,151.52,446.03,167.16,7.86" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="10,420.00,435.07,60.59,7.86;10,151.52,446.03,144.51,7.86">CWI at TREC 2012, KBA Track and Session Track</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gebremeskel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bosscarino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>De Vries</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,457.35,337.98,7.86;10,151.52,468.31,329.07,7.86;10,151.52,479.27,329.07,7.86;10,151.52,490.23,329.07,7.86;10,151.52,501.19,237.03,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,285.03,457.35,195.56,7.86;10,151.52,468.31,32.82,7.86">A cross-lingual dictionary for english wikipedia concepts</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">I</forename><surname>Spitkovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">C C</forename><surname>Choukri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Declerck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Doan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">U</forename><surname>Maegaard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mariani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Odijk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,328.30,479.27,152.29,7.86;10,151.52,490.23,252.46,7.86">Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC&apos;12)</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Piperidis</surname></persName>
		</editor>
		<meeting>the Eight International Conference on Language Resources and Evaluation (LREC&apos;12)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct coords="10,142.61,512.51,337.98,7.86;10,151.52,523.47,60.92,7.86" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<title level="m" coord="10,213.62,512.51,113.88,7.86">Advances in kernel methods</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="169" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,534.79,337.98,7.86;10,151.52,545.75,43.78,7.86" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="10,272.25,534.79,208.34,7.86;10,151.52,545.75,21.14,7.86">The HLTCOE Approach to the TREC 2012 KBA Track</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kjersten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mcnamee</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,557.08,337.98,7.86;10,151.52,568.03,329.07,7.86;10,151.52,578.99,329.07,7.86;10,151.52,589.95,9.22,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,201.72,557.08,211.02,7.86">Graph-based text representation for novelty detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,432.52,557.08,48.07,7.86;10,151.52,568.03,329.07,7.86;10,151.52,578.99,40.95,7.86">Proceedings of TextGraphs: the First Workshop on Graph Based Methods for Natural Language Processing</title>
		<meeting>TextGraphs: the First Workshop on Graph Based Methods for Natural Language Processing<address><addrLine>New York City</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,601.28,337.98,7.86;10,151.52,612.23,328.60,7.86" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="10,201.46,601.28,154.79,7.86">Overview of the trec 2004 novelty track</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<editor>Voorhees, E.M., Buckland, L.P.</editor>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>TREC, National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,623.56,337.97,7.86;10,151.52,634.52,202.56,7.86" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="10,211.49,623.56,269.09,7.86;10,151.52,634.52,78.60,7.86">Why nouns are learned before verbs: Linguistic relativity versus natural partitioning</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gentner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<biblScope unit="page">4854</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">BBN report</note>
</biblStruct>

<biblStruct coords="10,142.61,645.84,337.98,7.86;10,151.52,656.77,65.39,7.89" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,197.72,645.84,155.98,7.86">Wordnet: a lexical database for english</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,361.79,645.84,118.80,7.86">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,119.67,337.98,7.86;11,151.52,130.61,171.98,7.89" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,213.35,119.67,263.23,7.86">Accurate methods for the statistics of surprise and coincidence</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Dunning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,151.52,130.63,103.52,7.86">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="61" to="74" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,141.59,337.98,7.86;11,151.52,152.55,329.07,7.86;11,151.52,163.51,215.92,7.86" xml:id="b17">
	<analytic>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">P</forename><surname>Buckland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,316.39,141.59,164.21,7.86;11,151.52,152.55,42.62,7.86">Proceedings of the 21st Text REtrieval Conference</title>
		<meeting>the 21st Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-11-06">2012. November 6-9, 2012. 2012</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
