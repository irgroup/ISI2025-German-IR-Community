<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,60.24,56.61,491.52,12.93">An Exploration of Ranking-based Strategy for Contextual Suggestion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,249.41,93.81,50.22,9.96"><forename type="first">Peilin</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,322.33,93.81,40.27,9.96"><forename type="first">Hui</forename><surname>Fang</surname></persName>
							<email>hfang@ece.udel.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,60.24,56.61,491.52,12.93">An Exploration of Ranking-based Strategy for Contextual Suggestion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C29AC9648B257901EB0E526C167521A4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe our efforts in TREC 2012 Contextual Suggestion Track. The task is to provide suggestions to users based on their personal interests as well as their contexts. To tackle the problem, we propose to rank candidate suggestions based on their similarity to the personal profile and that to the contexts (i.e., geographic and temporal information). The ranking function is computed based on the similarity between a suggestion and the places that the user like and the dis-similarity between the suggestion and the places disliked by the user. The similarities are computed based on the either the category or description of the suggestions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>TREC 2012 Contextual Suggestion Track provides a venue for evaluating the "zero query term problem" <ref type="bibr" coords="1,513.82,275.90,9.95,9.96" target="#b0">[1]</ref>, which aims to proactively provide user suggestions based on their contexts. Specifically, given a user's profile (i.e, the places that he/she likes and dislikes) and the user's context (i.e., location and time), the task is to return the user with suggestions that are relevant to either the profile or context.</p><p>The data set consists of two parts: (1) profiles of 34 users, i.e., their preferences on 49 example suggestions; (2) 50 contexts (i.e., geographical and temporal information). The problem set up is to retrieve 50 suggestions based on each pair of profile and context.</p><p>To solve the problem, we need to address three challenges:</p><p>-How to find candidate suggestions? -How to rank the suggestions based on the user profile? -How to rank the suggestions based on the contexts?</p><p>To address the first challenge, we retrieve candidate suggestions from multiple online sources based on the geographical information. For the second challenge, we propose to model the relevance of a suggestion based on its similarities with positive examples in the profile (i.e.,the places liked by the user) and the dis-similarities with the negative examples (i.e., the places disliked by the user). The similarity between a suggestion and a place can be measured based on their categories as well as their descriptions. Finally, to address the last challenge, we propose to post-process the results by filtering out the suggestions that do not satisfy the temporal requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Gathering Candidate Suggestions</head><p>To collect candidate suggestions, we crawl the information from multiple online sources such as Yelp and Foursquqre based on the geographical information from the 50 contexts. The collected candidate suggestions have different fields such as categories, web sites, business hours, etc. Moreover, we also crawl the web site for each candidate suggestion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Ranking based on User Profiles</head><p>We now describe how to rank candidate suggestions based on user profiles. The profile of each user consists of the user's preferences for 49 example locations. The locations that a user likes are referred to as "positive examples", and those disliked by the user are referred to as "negative examples". Intuitively, the relevance score of a candidate suggestion should be higher when it is similar to positive examples while different from the negative examples.</p><p>Formally, we denote U as a user and C as a candidate suggestion. Moreover, let P (U ) denote positive examples, i.e., a set of places that the user likes, and N (U ) denote negative examples, i.e., a set of places that the user dislikes. The relevance score of C with respect to U can then be computed as follows: where ϕ ∈ [0, 1] and it regularize the weights between the positive and negative examples. When ϕ = 1, the highly ranked suggestions would be those similar to the locations that the user likes. When ϕ = 0, the highly ranked suggestions would be those different from the locations that the user dislikes. S P (P (U ), C) measures the similarity between the positive user profile and the candidate suggestion, and we assume that it can be computed by averaging the similarity scores between each positive example and the candidate suggestion. |P (U )| corresponds to the number of positive examples in the user profile.</p><formula xml:id="formula_0" coords="1,152.34,700.93,402.95,39.37">S(U, C) = ϕ × S P (P (U ), C) + (1 -ϕ) × S N (N (U ), C) (1) = ϕ × p∈P (U ) SIM (p, C) |P (U )| + (1 -ϕ) × p∈N (U ) SIM (n, C) |N (U )| ,<label>(2)</label></formula><p>Thus, it is clear that the problem of computing the relevance score of a candidate suggestion with respect a user can be boiled down to the problem of computing the relevance score between a candidate suggestion and a place mentioned in the user profile, i.e., SIM (e, C), where e is an example from the user profile. We explore the following two types of information to compute SIM (e, C): (1) the category of a place; and (2) the description of a place.</p><p>Category-based similarity: Category is a very important factor that may greatly impact user preferences. The categories of the crawled suggestions are often hierarchical. Here is an example category, i.e., [History Museum→ Museum→Arts]. The categories becomes more general from the left to the right. In this example, Arts is the most general category while History Museum is the most specific category. Note that we represent the hierarchical categories as a set of categories in this paper.</p><p>We can compute SIM (e, C) based on the category similarities between e and C as follows:</p><formula xml:id="formula_1" coords="2,192.58,411.05,362.70,28.90">SIM C (e, C) = ci∈C(e) cj ∈C(C) |Intersection(ci,cj )| max(|ci|,|cj |) |C(e)| × |C(C)| ,<label>(3)</label></formula><p>where C(e) denotes the set of categories of location e and |Intersection(c i , c j )| is the number of common categories between c i and c j . Recall that we crawled the candidate suggestions from two online sources. Table <ref type="table" coords="2,522.71,460.27,4.98,9.96" target="#tab_0">1</ref> shows example categories from both sources. Thus, we combine the similarity scores computed based on the categories from them as follows:</p><formula xml:id="formula_2" coords="2,155.85,501.29,399.43,14.04">SIM C ′ (e, C) = φ × SIM Y elp C (e, C) + (1 -φ) × SIM F ourSquare C (e, C).<label>(4)</label></formula><p>In our experiments, we set φ as 0.5 which means the importance of category score of Yelp and FourSquare are the same.</p><p>Description-based similarity: In example suggestions, each suggestion has its unique description which typically is at a short length. We want to learn how the descriptions can affect people's decision on different places. By comparing the descriptions of training suggestions with textual web sites of testing suggestions we may find some interesting connections. We use textual web sites of testing suggestions because we believe that textual web sites are more reliable than descriptions especially when we rank candidate suggestions. The similarity used function is the F2EXP ranking function <ref type="bibr" coords="2,130.62,622.38,9.95,9.96" target="#b1">[2]</ref>. Thus, we compute the similarity scores as follows: SIM D (e, C) = F 2EXP (DES(e), DES(C)), where DES(e) is a description of the example place e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Ranking the candidates based on the contexts</head><p>There are two types of context: geographical and temporal information. All of the candidate suggestions crawled in the first step are related to the geographical requirement because they are retrieved based on it. To make sure the suggestions satisfying the temporal requirement, we collected the business hours from Yelp, and then assign the business hours for each cateogry if the majority suggestions in that category follow the same business hour. Candidate suggestions that do not meet the temporal requirement are then removed from the final ranking list.</p><p>We submitted two runs: UDInfoCSTc and UDInfoCSTdc.</p><p>-UDInfoCSTc: We use only category information to compute the similarities as shown in Equation (3).</p><p>-UDInfoCSTdc: We use both category and description information to compute the similarities as follows:</p><formula xml:id="formula_3" coords="3,180.38,129.45,374.91,10.71">SIM combine (e, C) = α × SIM C (e, C) + (1 -α) × SIM D (e, C)<label>(5)</label></formula><p>where α ∈ [0, 1] and it controls the weight for the two similarity methods.</p><p>In both runs, we post-process the results to meet the geographic and temporal requirements. All the parameters are trained based on the example suggestions. We tried all combinations of parameters mentioned in previous subsections. For each of them, we pick up their values from [0,1] with pace length 0.1. We get the parameters set that leads the best performance of each fold and average them.</p><p>For each suggestion, the assessor judges W (Website), D (Description), G (Geographical), T (Temporal), GT (combine G and T) and WGT (combine WGT). For combined measures, only all of them are appropriate then the score will be "1"; otherwise the score will be "0". Here we only show the P@5 WGT performance:  Table <ref type="table" coords="3,98.91,640.14,4.98,9.96">2</ref> shows the overall performance of two runs, i.e., the performance is for the corresponding measures over all judged profiles and contexts. It is clear that using only category information is more effective for WGT (i.e., website, geographical and temporal) while using description can help for using GT only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In TREC 2012 Contextual Suggestion Track, we submitted two runs. Our goal is to evaluate (1) an information gathering strategy that crawls and integrates the information about candidate suggestions from multiple sources, such as Yelp, Foursquare etc.; and (2) a ranking-based method that computes the similarity between a candidate suggestion and a user profile based on both descriptions and categories of the candidate and example suggestions.</p><p>In particular, the two runs are UDInfoCSTc and UDInfoCSTdc. In UDInfoCSTc, we use categories only to compute the similarities between each candidate suggestion/example suggestion pair. For each user, positive and negative similarities are combined using optimal coefficients learned from examples. Final ranking is based on combined similarities scores. In UDInfoCSTdc, we use the similar strategy with UDInfoCSTc but when computing similarities we use categories together with descriptions. For both runs, we post-process the results to meet the geographic and temporal requirements. The performance of our two submitted runs are in general better than the median performance. Moreover, using category only as the similarity function we get a overall better performance than using combined category and description scores.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,56.69,572.58,498.61,8.96;3,56.69,583.53,98.14,8.96"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. P@5 WGT Performance of UDInfoCSTc and UDInfoCSTdc (compare with median) on each context by averaging all profiles for that context.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,71.64,616.24,483.65,9.96;3,56.69,628.19,489.58,9.96;3,71.64,640.14,483.65,9.96;3,56.69,652.10,498.59,9.96;3,56.69,664.05,384.22,9.96"><head>Figure 1</head><label>1</label><figDesc>Figure1and 2 show the performance of our runs compared with median performance of the track based on context and profile, respectively. It is clear that our runs are better than the median performance in most cases.Table2shows the overall performance of two runs, i.e., the performance is for the corresponding measures over all judged profiles and contexts. It is clear that using only category information is more effective for WGT (i.e., website, geographical and temporal) while using description can help for using GT only.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,132.06,56.64,344.82,120.54"><head>Table 1 .</head><label>1</label><figDesc>Examples of Categories in Example Suggestions</figDesc><table coords="2,132.06,77.41,344.82,99.77"><row><cell>NAME</cell><cell>Yelp Categories</cell><cell>FourSquare Categories</cell></row><row><cell>HoSu Bistro</cell><cell>SushiRestaurant→Restaurants;</cell><cell>SushiRestaurant→Food</cell></row><row><cell></cell><cell>KoreanRestaurant→Restaurants;</cell><cell></cell></row><row><cell></cell><cell>JapaneseRestaurant→Restaurants</cell><cell></cell></row><row><cell>The Rex</cell><cell>JazzBlues→MusicVenues→Arts</cell><cell>JazzClub → MusicVenue →</cell></row><row><cell></cell><cell></cell><cell>ArtsEntertainment</cell></row><row><cell cols="2">St. Lawrence Market Grocery→Shopping;</cell><cell>FarmersMarket → Food-</cell></row><row><cell></cell><cell>FarmersMarket→Shopping</cell><cell>DrinkShop → ShopService</cell></row><row><cell>...</cell><cell>...</cell><cell>...</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,56.69,63.18,498.61,380.00"><head></head><label></label><figDesc>P@5 WGT Performance of UDInfoCSTc and UDInfoCSTdc (compare with median) on each profile by averaging all contexts for that profile.</figDesc><table coords="4,56.69,63.18,400.90,380.00"><row><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Median</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Tc</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Tdc</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.6 P@5 WGT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2</cell><cell>3</cell><cell>6</cell><cell>8</cell><cell>1 1</cell><cell>1 4</cell><cell>1 6</cell><cell>1 7</cell><cell>1 8</cell><cell>1 9</cell><cell>2 1</cell><cell>2 2</cell><cell>2 3</cell><cell>2 5</cell><cell>2 6</cell><cell>2 7</cell><cell>2 8</cell><cell>3 1</cell><cell>3 3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Profile</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="16">Fig. 2. Table 2. Overall Performance of Two Runs</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="10">P@5 WGT P@5 W P@5 GT</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="4">UDInfoCSTc</cell><cell></cell><cell cols="2">0.2481</cell><cell></cell><cell cols="2">0.3500</cell><cell></cell><cell cols="2">0.4950</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="5">UDInfoCSTdc</cell><cell cols="2">0.2210</cell><cell></cell><cell cols="5">0.3500 0.5442</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,60.27,642.90,495.03,8.96;4,68.84,653.87,476.46,8.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,265.79,642.90,255.27,8.96">Frontiers, challenges, and opportunities for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,527.26,642.90,28.05,8.96;4,68.84,653.87,317.88,8.96">Report from swirl 2012 the second strategic workshop on information retrieval in lorne</title>
		<imprint>
			<date type="published" when="2012-05">May 2012</date>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="2" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,60.27,664.83,495.04,8.96;4,68.84,675.78,486.47,8.96;4,68.84,686.74,137.99,8.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,158.09,664.83,256.03,8.96">An exploration of axiomatic approaches to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,432.97,665.13,122.34,8.26;4,68.84,675.78,419.28,8.96">Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;05</title>
		<meeting>the 28th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;05<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="480" to="487" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
