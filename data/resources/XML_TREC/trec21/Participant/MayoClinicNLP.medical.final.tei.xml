<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,121.07,101.81,369.56,15.39">Three Questions about Clinical Information Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,150.05,134.31,58.74,10.87"><forename type="first">Stephen</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName coords="1,219.64,134.31,71.34,10.87"><forename type="first">James</forename><surname>Masanz</surname></persName>
						</author>
						<author>
							<persName coords="1,391.92,134.31,69.73,10.87"><forename type="first">Hongfang</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName coords="1,232.91,148.26,60.28,10.87"><forename type="first">Mayo</forename><surname>Clinic</surname></persName>
						</author>
						<title level="a" type="main" coord="1,121.07,101.81,369.56,15.39">Three Questions about Clinical Information Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2F0BBA74F32039EDB8E872C95C2F4656</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Electronic Medical Records (EMRs) have greatly expanded the potential for the evidence-based improvement of clinical practice by providing a data source for computable medical information. The Text REtrieval Conference 2012 Medical Records Track (TREC-med) explored how information retrieval may support clinical research by providing an efficient means to identify cohorts for clinical studies. A shared task called participants to find cohorts of relevant patients for 50 different topic queries.</p><p>The users in TREC-med information retrieval systems would be medical experts who are searching for cohorts. In our previous work, we have collaborated with such experts on specific queries; the assortment of 50 queries makes this competition a standardized benchmark task. Thus, techniques that have shown case-by-case improvement can be tested against a much larger number of queries. We have taken this opportunity to investigate three core questions around which many of our algorithms are designed:</p><p>1. What is the relative value of structured data (e.g., fields in EMRs, or document metadata) compared to clinical text?</p><p>2. Are extensive information extraction (IE) efforts any benefit when we consider the applied question of information retrieval (IR)?</p><p>3. Can distributional semantics help supply missing information in a query?</p><p>For each of these three questions, we have extended Apache Lucene 1 with pre-existing techniques and tested on the TREC-med cohort identification task. In testing these independently, we aim to find generalizable principles for cohort identification in other documents collections and queries.</p><p>The rest of this paper describes the TREC 2012 Medical Records task, describes Mayo Clinic's run submissions in detail, and reports evaluation results with subsequent discussion. 1 See lucene.apache.org</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>The TREC 2012 Medical Records track was arranged as a follow-up to the 2011 track <ref type="bibr" coords="1,449.78,223.41,9.95,9.62" target="#b0">[1]</ref>, with nearly identical setup. The data to be retrieved lay in the University of Pittsburgh's BLU repository, which includes the free text portions of medical records (see report text below). Each patient at the University of Pittsburgh would have one or more medical records (documents) associated with him or herself. Each record was given in XML format, and included both structured data and the unstructured text. Records are uniquely identified by their checksum. Note that each record contains a note type and subtype; in the example, the note comes from an Emergency Room/Department. The chief complaint section is a helpful textual summary of what the record is about from the patient's perspective, but is not present for every record. The admit diagnosis and discharge diagnosis serve a similar function but are also not always present. They are given as ICD-9 codes, a medical terminology frequently used for billing purposes. Finally, notice that the notes were de-identified, so that any protected health information has been replaced with surrogates.</p><p>The records were grouped into visits -a physical visit to the hospital. The unit of retrieval was defined as a patient visit. In total, there were 95,702 records that corresponded to 17,198 visits. The largest visit was 418 records, but the mean visit was 5.56 records.</p><p>Participants from 24 institutions were given a set of 50 hypothetical topics (queries) developed by experts at the Oregon Health Sciences University (OHSU). Each query is given in a form such as Number: 143 Patients who have had a carotid endarterectomy These topics defined patient profiles that might be involved in a clinical trial. For each topic, participants retrieved a list of patient visits in order of relevance to the topic.</p><p>For evaluation and ranking, retrieved records from participants' runs were given to assessors at OHSU. These assessors rendered relevance judgments on a stratified pool of visits -the top 15 of each submitted run, and a random sample of the remaining top 100 in each run. The nature of each topic and its correspondence with the given dataset varied greatly. For example, 4 topics were discarded for purposes of evaluation because no records were assessed as being relevant to the query topic; on the other hand, other topics likely had many relevant visits that were never assessed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>We tested 3 focused questions that lay groundwork for future patient identification systems. We evaluated the usefulness of document metadata, contextually-aware information extraction results, and distributional semantic query expansion. As a baseline, we used a standard Lucene index, and each of the other runs was built directly on this baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baseline</head><p>Apache Lucene is perhaps the most widely used information retrieval framework. Lucene indexes a collection of documents for extremely efficient text search. Similar to rows in a database, documents are the granularity of a collection in Lucene; similar to columns, fields in Lucene contain values for each document that are considered strings by default. We took each medical record from the BLU repository and stored fields corresponding to 10 useful parts of the XML document: Document ID (checksum), Visit ID (stands in for Patient ID), Date (from checksum), Type, Subtype, Chief Complaint, Admit diagnosis (ICD-9 codes), Discharge diagnosis (ICD-9 codes), Year, and Content (the clinical text).</p><p>As mentioned, each of the fields in Lucene can be indexed. Behind the scenes, by default, Lucene uses an Analyzer pipeline for the text that includes tokenization, normalization, lowercasing words, and stop word removal; it then creates an inverted index for each token in each field. Unlike the mapping implied in the fields (from documents to tokens), an inverted index maps from tokens to documents, and this makes it easy to find terms that match a query. For our baseline methodology, we included variants of "patient" as a stop word, and only searched the Content field.</p><p>When searching for a term, Lucene effectively uses the following equation to rank which documents are most relevant:</p><formula xml:id="formula_0" coords="2,320.72,368.59,218.97,41.97">score(q, d) = coord(q, d) • qNorm(q) • t∈q tf(t) • idf(t) 2 • t.boost() • norm(t, d)<label>(1)</label></formula><p>where q is the query, d is a document in the collection, t is a term, and the following functions hold: In this baseline approach, we strictly used the text of the original TREC topic as the query, without any special weighting for t.boost(). It should be noted, however, that we used Lucene's same Standard Analyzer on both the query and the collection. Likewise, we searched within an unaltered Content field (i.e., the text itself), and thus norm() had no effect on the final weighting.</p><formula xml:id="formula_1" coords="2,316.82,458.22,25.30,8.83">score</formula><p>Since Lucene ranks top documents rather than top visits (i.e., patients), we consider the most relevant document to represent the whole visit. This maximum-document assumption for each patient is not neceessarily a good one, but we have focused on testing other aspects of the retrieval framework. We report the top 1,000 unique visits for each query.</p><p>Evaluations in TREC-med 2011 were on a smaller set of 35 topics, and reported results used bpref; the performance on TREC-med 2011 topics was bpref=0.4249.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Test 1:</head><p>Including Structured Metadata (MayoMetadata)</p><p>First, we performed a controlled test of the value of EMR structured data on retrieval. For practitioners and researchers who use EMR data, ICD-9 codes are the first line of defense in cohort identification. They are frequently used in lieu of more sophisticated cohort identification procedures. We accounted for these ICD-9 codes by mapping to their textual representations using the UMLS Metathesaurus. Term lists for each ICD-9 code were then stored in additional Lucene index fields: Admit Diagnosis Terms and Discharge Diagnosis Terms. This is not strictly the same as a boolean search for matching ICD-9 codes, which requires person or process to code the query into ICD-9 codes. However, in our experience, users of an IR system will typically think of terms of interest, then consult a reference material to find relevant codes, then search the structured data for codes. Indexing and searching the textual representations of ICD-9 codes is thus a reasonable automatic method for retrieving ICD-9 codes.</p><p>With the query unchanged from the baseline, we searched over 4 fields: the text of these two diagnoses terms, the Chief Complaint, and the Content field. Since we expected these coded representations to be highly relevant for retrieval, we weighted the structured data sections higher (in proportion to the much shorter field length) than the text itself, by using the norm() function. Performance on the 35 TREC 2011 topics improved significantly using this addition (bpref=0.4541).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Test 2: Weighting IE Output (MayoPayload)</head><p>Second, we performed a controlled test (i.e., ignoring metadata) of the value of using the results of information extraction to inform the scoring procedures. We used a recent Information Extraction (IE) system developed at Mayo Clinic, MedTagger, due to its speed. MedTagger uses a lexicon of terms and variants that have been attested in a large corpus of clinical text <ref type="bibr" coords="3,128.04,678.14,10.51,9.62" target="#b1">[2,</ref><ref type="bibr" coords="3,142.64,678.14,7.01,9.62" target="#b2">3]</ref>, and looks for these terms in the document collection (here, the BLU NLP repository) as its means of Named Entity Recognition. Additionally, MedTagger applies the NegEx <ref type="bibr" coords="3,229.40,714.00,10.51,9.62" target="#b3">[4]</ref> and ConText <ref type="bibr" coords="3,310.84,74.83,10.51,9.62" target="#b4">[5]</ref> algorithms, which discover whether these named entities were negated, hypothetical, historical, or experienced by someone other than the patient. After being found in the BLU text, these named entities and their attributes were brought into the Lucene index. For each named entity, the last token in that named entity carried a Payload -additional data attached to a token within Lucene. Our custom-defined payload included a normalized form of the named entity, the semantic group, status (any hedging of a statement), polarity (whether the statement was negated), and the experiencer (subject of a statement, typically the patient).</p><p>We used a simple heuristic to down-weight tokens if its attributes cast any doubt that the named entity was associated with the patient. Values were chosen by manually testing against the 2011 query topics: polarity = "negated" → .10w status = "history of" → .75w</p><p>"fam. history" → .10w</p><p>"probable" → .25w</p><formula xml:id="formula_2" coords="3,339.78,353.35,199.92,9.62">experiencer = not "patient" → .10w<label>(2)</label></formula><p>This weight w is an incremental part of the calculation for norm(t, d).</p><p>By augmenting the index with the ability to downweight on these mentions, query terms finding negated or hedged matches would be dispreferred. This simple NLP-driven addition improved performance from the baseline on TREC-med 2011 topics, with bpref=0.4730.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Test 3: Query Expansion with Semantic Vectors (MayoExpanded)</head><p>Finally, we performed a controlled test (i.e., ignoring metadata and negation) of the value of query expansion through distributional semantics. While the baseline and previous approaches directly used the text of the queries (with stop word removal) to search documents, here we modified the queries. We used Random Indexing <ref type="bibr" coords="3,447.04,606.41,10.51,9.62" target="#b5">[6]</ref> to build distributional semantic representations (i.e., vectors) of terms from a large corpus of Mayo Clinic clinical notes. Near-neighbor terms (often multiple tokens each) were selected for each topic. We constructed expanded queries whose terms had a t.boost() weighting based on the frequency of tokens in the near-neighbor synonymous term lists. We included it for diversity in the result pool, despite slightly decreased performance on TREC 2011 topics (bpref=0.4097). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>Official TREC results on the baseline and variants are shown in Table <ref type="table" coords="4,156.14,423.36,3.87,9.62">1</ref>. In 2011, bpref was used for the official evaluation rankings, due to problems in calculating the inferred measures. The inferred measures <ref type="bibr" coords="4,72.00,459.23,10.51,9.62" target="#b6">[7]</ref> are now available in 2012.</p><p>The baseline (MayoLucene) is improved upon by the IE-influenced retrieval (MayoPayload) across all metrics. Both ICD-9 codes (MayoMetaData) and semantic vector query expansion (MayoExpanded) actually decrease the performance across all metrics. For comparison, Table <ref type="table" coords="4,176.74,535.82,4.98,9.62" target="#tab_2">2</ref> shows the performance of these techniques on both the 35 topics from 2011 and the 50 topics from 2012. The ∆ columns highlight the % difference from baseline associated with each of the three techniques being tested.</p><p>Finally, in Table <ref type="table" coords="4,161.50,600.47,4.98,9.62" target="#tab_3">3</ref> we show the correlations between our baseline and 3 other runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>At the beginning, we set out to answer three questions, which we revisit here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Structured clinical data in IR?</head><p>(MayoMetaData)</p><p>The evaluation results for 2012 topics suggest that structured data does not uniformly improve performance. This is especially interesting given that performance did improve significantly for 2011 topics when structured data was added, and given that the median R-precision scores for 2011 and 2012 were very similar.</p><p>In 2012, 32 of the 47 topics (68%) were hurt by including ICD-9 codes, showing that the detrimental effects of the structured data were relatively widespread. MayoMetaData had the highest standard deviation (0.2125) among the three tested systems.</p><p>All this may indicate that topics vary widely, and structured data is not always a good match for what an end user is looking for. Alternatively, a possible explanation is that the 2012 topics are harder to encapsulate in diagnosis codes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">IE results in IR? (MayoPayload)</head><p>Here, we find a clear indication that Information Extraction methods do benefit Information Retrieval. This is shown with positive results across both 2011 and 2012 topic sets.</p><p>For 2012 topics, 35 of 47 topics (74%) were im-proved by including this type of contextual information. This is an encouraging result, showing that extensive IE research has practical benefit in IR systems. MayoPayload also has the smallest standard deviation (0.0634), showing the consistency of the approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Distributional semantic query expansion? (MayoExpanded)</head><p>The flavor of query expansion that we have proposed shows an overall drop in performance, showing that query expansion through distributional means cannot necessarily be relied upon. There are indeed cases where query expansion outperforms plain queries (25 of 47, or 53% of cases), but the opposite is also true (22 of 47, or 47%). One contributing factor could be that the semantic vectors were trained on a different distribution of data (Mayo EDT) than the test data (Pittsburgh BLU). Since most TREC 2012 topics had few relevant visits and the goal of query expansion is to aid in increasing recall, it seems that increases in performance due to recall are more than balanced out by the cost in precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Other questions</head><p>As shown in Table <ref type="table" coords="5,153.97,398.79,3.87,9.62" target="#tab_3">3</ref>, the correlative relationships between the different approaches confirm existing findings. Overall, MayoLucene is a strong baseline, and large deviations from it tended to come from lowerperforming runs. In particular, Because MayoMeta-Data searches (and highly weights) fields that are not present in the other approaches, it is the least correlated with the others. Two related, untested questions are whether interactive user input and structured (or faceted) queries would be of benefit. This is part of our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The TREC 2012 Medical Records track competition provided an opportunity to test three focused questions about Information Retrieval in the clinical domain. Structured data and query expansion can sometimes be helpful, but information extraction results can be used effectively to greatly increase IR performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,136.28,72.25,335.83,270.45"><head>Table 2 :</head><label>2</label><figDesc>Comparison of methods on 2011 topics vs. 2012 topics.</figDesc><table coords="4,136.28,72.25,335.83,270.45"><row><cell cols="4">infNDCG σ 2 infNDCG</cell><cell>infAP</cell><cell>bpref R-prec</cell><cell>P@10</cell></row><row><cell>MayoLucene</cell><cell>0.3694</cell><cell cols="4">0.2310 0.1359 0.2771 0.2583 0.4043</cell></row><row><cell>MayoMetaData</cell><cell>0.3222</cell><cell cols="4">0.2125 0.1175 0.2474 0.2072 0.3553</cell></row><row><cell>MayoPayload</cell><cell>0.4119</cell><cell cols="4">0.0634 0.1590 0.2981 0.2807 0.4319</cell></row><row><cell>MayoExpanded</cell><cell>0.3587</cell><cell cols="4">0.1422 0.1239 0.2652 0.2321 0.4043</cell></row><row><cell cols="6">Table 1: MayoClinicNLP results for TREC-med 2012</cell></row><row><cell></cell><cell></cell><cell cols="2">2011 topics</cell><cell></cell><cell>2012 topics</cell></row><row><cell></cell><cell></cell><cell>bpref</cell><cell></cell><cell>∆</cell><cell>bpref</cell><cell>∆</cell></row><row><cell cols="2">MayoLucene</cell><cell>0.4249</cell><cell></cell><cell cols="2">-0.2771</cell><cell>-</cell></row><row><cell cols="3">MayoMetaData 0.4541</cell><cell cols="3">+6.87% 0.2474 -10.72%</cell></row><row><cell cols="2">MayoPayload</cell><cell cols="4">0.4730 +11.32% 0.2981 +7.58%</cell></row><row><cell cols="3">MayoExpanded 0.4097</cell><cell cols="3">-3.58% 0.2652</cell><cell>-4.29%</cell></row><row><cell></cell><cell cols="5">Lucene MetaData Payload Expanded</cell></row><row><cell>Lucene</cell><cell></cell><cell>-</cell><cell>0.6451</cell><cell cols="2">0.9632</cell><cell>0.8125</cell></row><row><cell>MetaData</cell><cell cols="2">0.6451</cell><cell>-</cell><cell cols="2">0.6336</cell><cell>0.6279</cell></row><row><cell>Payload</cell><cell cols="2">0.9632</cell><cell>0.6336</cell><cell></cell><cell>-</cell><cell>0.7770</cell></row><row><cell>Expanded</cell><cell cols="2">0.8125</cell><cell>0.6279</cell><cell cols="2">0.7770</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,205.31,350.64,196.67,9.62"><head>Table 3 :</head><label>3</label><figDesc>Correlations between the 2012 runs.</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,87.50,702.05,213.38,9.62;5,87.50,714.00,213.38,9.62;5,326.34,74.83,213.36,9.62;5,326.34,86.78,22.67,9.62" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,209.58,702.05,91.29,9.62;5,87.50,714.00,120.18,9.62">Overview of the trec 2011 medical records track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,235.63,714.00,65.25,9.62;5,326.34,74.83,207.15,9.62">The Twentieth Text REtrieval Conference Proceedings TREC</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,326.34,106.71,213.37,9.62;5,326.34,118.67,213.35,9.62;5,326.34,130.62,213.34,9.62;5,326.34,142.57,91.99,9.62" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,471.49,106.71,68.22,9.62;5,326.34,118.67,213.35,9.62;5,326.34,130.62,139.43,9.62">Semantic Characteristics of NLP-extracted Concepts in Clinical Notes vs. Biomedical Literature</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hongfang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,490.06,130.62,49.62,9.62;5,326.34,142.57,61.37,9.62">Proceedings of AMIA 2011</title>
		<meeting>AMIA 2011</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,326.34,162.50,213.37,9.62;5,326.34,174.46,213.35,9.62;5,326.34,186.41,213.36,9.62;5,326.34,198.37,213.34,9.62;5,326.34,210.33,213.36,9.62;5,326.34,222.28,78.80,9.62" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,353.87,186.41,185.83,9.62;5,326.34,198.37,136.43,9.62">UMLS Term Occurrences in Clinical Notes: A Large-scale Corpus Analysis</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hongfang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dingcheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cui</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Musen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Chute</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nigam</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,490.06,198.37,49.62,9.62;5,326.34,210.33,213.36,9.62;5,326.34,222.28,48.41,9.62">Proceedings of the AMIA Joint Summit on Clinical Research Informatics</title>
		<meeting>the AMIA Joint Summit on Clinical Research Informatics</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,326.34,242.20,213.37,9.62;5,326.34,254.16,213.35,9.62;5,326.34,266.12,213.37,9.62;5,326.34,278.07,213.36,9.62;5,326.34,290.02,135.78,9.62" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,456.34,254.16,83.35,9.62;5,326.34,266.12,213.37,9.62;5,326.34,278.07,88.13,9.62">A simple algorithm for identifying negated findings and diseases in discharge summaries</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">W</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Bridewell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">G</forename><surname>Buchanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,425.73,278.07,113.98,9.62;5,326.34,290.02,39.03,9.62">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="301" to="310" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,326.34,309.95,213.37,9.62;5,326.34,321.91,213.36,9.62;5,326.34,333.86,213.36,9.62;5,326.34,345.81,213.36,9.62;5,326.34,357.77,160.49,9.62" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,414.43,321.91,125.27,9.62;5,326.34,333.86,213.36,9.62;5,326.34,345.81,116.59,9.62">Context: An algorithm for determining negation, experiencer, and temporal status from clinical reports</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Harkema</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">N</forename><surname>Dowling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Thornblade</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">W</forename><surname>Chapman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,451.97,345.81,87.72,9.62;5,326.34,357.77,63.68,9.62">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="839" to="851" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,326.34,377.70,213.36,9.62;5,326.34,389.65,213.37,9.62;5,326.34,401.60,213.37,9.62;5,326.34,413.56,213.38,9.62;5,326.34,425.52,205.67,9.62" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,462.51,377.70,77.19,9.62;5,326.34,389.65,213.37,9.62;5,326.34,401.60,139.04,9.62">Semantic vectors: a scalable open source package and online technology management application</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Widdows</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Ferraro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,477.34,401.60,62.37,9.62;5,326.34,413.56,213.38,9.62;5,326.34,425.52,96.43,9.62">Proceedings of the Sixth International Language Resources and Evaluation (LREC&apos;08)</title>
		<meeting>the Sixth International Language Resources and Evaluation (LREC&apos;08)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1183" to="1190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,326.34,445.44,213.37,9.62;5,326.34,457.39,213.36,9.62;5,326.34,469.35,213.36,9.62;5,326.34,481.31,213.36,9.62;5,326.34,493.26,213.36,9.62;5,326.34,505.22,93.24,9.62" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,510.64,445.44,29.07,9.62;5,326.34,457.39,213.36,9.62;5,326.34,469.35,50.14,9.62">A simple and efficient sampling method for estimating ap and ndcg</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,395.84,469.35,143.87,9.62;5,326.34,481.31,213.36,9.62;5,326.34,493.26,181.19,9.62">Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 31st annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="603" to="610" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
