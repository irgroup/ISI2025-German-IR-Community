<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,189.60,82.58,216.02,14.36">PRIS at TREC2012 KBA Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,144.24,107.00,30.80,10.80"><forename type="first">Yan</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,182.64,107.00,74.62,10.80"><forename type="first">Zhaozhao</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,266.52,107.00,45.32,10.80"><forename type="first">Baojin</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,319.92,107.00,56.46,10.80"><forename type="first">Yong</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,385.08,107.00,60.33,10.80"><forename type="first">Ruiyang</forename><surname>Luo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,215.28,122.60,49.08,10.80"><forename type="first">Weiran</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,273.24,122.60,57.58,10.80"><forename type="first">Guang</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,339.60,122.60,40.44,10.80"><forename type="first">Jun</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,189.60,82.58,216.02,14.36">PRIS at TREC2012 KBA Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F9195DC8B9718A4111A58C69D88D7AD9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our system to KBA Track at TREC2012 is described in this paper, which includes preprocessing, index building, relevance feedback and similarity calculation. In particular, the Jaccard coefficient was applied to calculate the similarities between documents. We also show the evaluation results for our team and the comparison with the best and median evaluations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1．Introduction</head><p>Knowledge Base Acceleration (KBA) seeks to help humans expand knowledge bases like Wikipedia by automatically recommending edits based on incoming content streams. For our first year in TREC, we are evaluating systems on a single, simple task called cumulative citation recommendation: filter a stream of content for information that should be linked from a given Wikipedia page or an specific entity.</p><p>Figure <ref type="figure" coords="1,241.22,679.89,3.96,9.50">1</ref>. The framework of KBA system Figure <ref type="figure" coords="1,141.27,725.13,5.28,9.50">1</ref> shows the framework of our KBA system. First of all, we focused on the "cleansed" and "NER" part of the corpus. Preprocessing filtered out the useless documents and information and built the Indri index of the remain corpus. Secondly, the relevance feedback was conducted to expand the query information. Three expanded terms were generated for each entity. We used these terms to query the index and obtained an initial candidate for the relevant documents to be recommended. Finally we utilized an variation of the Jaccard coefficient to calculate the similarities between documents and generate the final recommended documents according to a threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preprocessing and Index Building</head><p>To fulfill the succeeding algorithm, we need to preprocess the original corpus and build a index for the retrieval system. After deciphering the corpus using a standard gpg and XZ decompression, we get the original data collected from Wikipedia. The corpus has been split into three components: linking, social and news. We only focused on documents labeled with 'cleansed' &amp; 'ner', and extracted essential part for index building. Then some text processing procedures were executed for these documents: We converted the documents into the "trectext" format used by Indri toolset for building index.</p><p>Besides the text itself, we kept the information of "DOCNO", "stream_id" and "Time". We used a simple stop word list to help Indri exclude useless words. In addition, the Porter algorithm was used for the stemming task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Relevance Feedback</head><p>KBA uses entities as filter topics for this year's CCR task. However, it is not enough to retrieve the index just according to a single entity name. In order to get more information about the topic, we expanded the topic entity utilizing two kinds of profiles. One is the Wikipedia page of the entity and another is the annotation set provided by TREC. From the annotation, we picked out documents labeled with either 'R' (Relevant) or 'C' (Central) for each entity.</p><p>After that we used the following formula to calculate the weight of each term:</p><formula xml:id="formula_0" coords="2,250.44,604.56,75.81,20.94">P ml (t|M d ) = tf (t,d) dl d</formula><p>(1)</p><formula xml:id="formula_1" coords="2,235.68,648.60,265.46,23.34">P avg (t) = ∑ P ml (t|M d ) d (t∈d) df t<label>(2)</label></formula><p>where tf (t,d) is the raw term frequency of term t in document d, dl d is the total number of tokens in document d, dft is the document frequency of t and P avg (t) is the weight of each word. Then we set a threshold to choose the top three words as the final expanded queries. Besides the initial entity topic, these terms were queried searching the index to find out the candidate similar documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Similarity Calculation</head><p>For the purpose of generating final recommended documents from the candidate above, we utilized the Jaccard coefficient to calculate the similarity between candidate documents and the original Wikipedia page for each topic entity. The Jaccard similarity coefficient is a statistic used for comparing the similarity and diversity of sample sets. The Jaccard coefficient measures similarity between sample sets, and is defined as the size of the intersection divided by the size of the union of the sample sets. We used an variation of the traditional Jaccard formula for our specific task showing as follows:</p><formula xml:id="formula_2" coords="3,212.82,229.96,288.30,49.14">| | , 2 2 | | ( )* ( ) R [ ( ) ( )] wiki d t wiki d wiki d wiki d t wiki d tf t tf t tf t tf t ∈ ∩ ∈ ∩ = + ∑ ∑<label>(3)</label></formula><p>where wiki and d stands for Wikipedia page and candidate document respectively. 𝑡𝑓(𝑡) means the term frequency of t. The calculated Jaccard coefficient should be multiplied by 1000 as the final confidence score for each candidate. We then compared the confidence score with the similarity threshold: if the coefficient is larger than the threshold, the document is recommended. The threshold is actually set from 400 to 1000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5．Evaluation Results</head><p>We have submitted up to 7 runs for this year's task. Due to the limited space, we only show the best results of us and the comparison of others. Table <ref type="table" coords="3,138.02,458.26,5.28,9.50">1</ref> and Figure <ref type="figure" coords="3,195.01,458.26,5.28,9.50">2</ref> shows the Precision, Recall, F1 and Scaled Utility of our run. It can be seen that F1 measure increases when the cutoff goes down and arrives peak at 400 cutoff, whereas the Scaled Utility shows an inverse trend.</p><p>Table <ref type="table" coords="3,231.97,505.18,3.90,9.50">1</ref> Table <ref type="table" coords="5,128.28,91.91,5.28,9.50" target="#tab_2">2</ref> shows the comparison between our run and the best, median and mean results on F1 measure at cutoff 400. We can conclude that the F1 measures of two entities (Masaru_Emoto and William_H.Gates,_Sr) are higher than the median and mean results; the F1 measures of four entities (Aharon_Barak, Darren_Rowse, Frederick_M._Lawrence and Mario_Garnero) are comparable to the median and mean while the results of remaining entities are lower than average.</p><p>The average F value is 0.0678 while the average median and mean is 0.2506 and 0.2066 respectively, which means that there is still a large room for improvement.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,108.00,307.19,126.55,9.50;2,108.00,322.67,146.55,9.50;2,108.00,338.27,207.61,9.50;2,108.00,353.87,118.68,9.50;2,108.00,369.47,150.50,9.50"><head>•</head><label></label><figDesc>Non-English text deletion • Lowercasing the capital letters • Removing the external linking inside the text • Abbreviation expansion • Removing useless punctuations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,107.16,505.18,385.24,248.79"><head>. Average performance of the PRIS run</head><label></label><figDesc></figDesc><table coords="3,107.16,524.71,385.24,229.27"><row><cell></cell><cell>Figure 2.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>cutoff</cell><cell>Precision</cell><cell>Recall</cell><cell>F1</cell><cell>Scaled Utility</cell></row><row><cell>0</cell><cell>0.267298</cell><cell>0.05809</cell><cell>0.067795</cell><cell>0.250206</cell></row><row><cell>100</cell><cell>0.267298</cell><cell>0.05809</cell><cell>0.067795</cell><cell>0.250206</cell></row><row><cell>200</cell><cell>0.267298</cell><cell>0.05809</cell><cell>0.067795</cell><cell>0.250206</cell></row><row><cell>300</cell><cell>0.267298</cell><cell>0.05809</cell><cell>0.067795</cell><cell>0.250206</cell></row><row><cell>400</cell><cell>0.267298</cell><cell>0.05809</cell><cell>0.067795</cell><cell>0.250206</cell></row><row><cell>500</cell><cell>0.210405</cell><cell>0.02739</cell><cell>0.041212</cell><cell>0.292443</cell></row><row><cell>600</cell><cell>0.056385</cell><cell>0.005454</cell><cell>0.008731</cell><cell>0.304233</cell></row><row><cell>700</cell><cell>0.03046</cell><cell>0.003025</cell><cell>0.005293</cell><cell>0.319105</cell></row><row><cell>800</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.325258</cell></row><row><cell>900</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.33285</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,119.05,216.83,367.15,543.86"><head>Average performance of the PRIS runTable 2 . Comparison with the Best, Median and Mean F1 measure on cutoff 400</head><label>2</label><figDesc></figDesc><table coords="4,129.12,264.40,357.07,496.28"><row><cell>URL name</cell><cell>PRIS</cell><cell>Best</cell><cell>Median</cell><cell>Mean</cell></row><row><cell>Aharon_Barak</cell><cell>0.1163</cell><cell>0.3841</cell><cell>0.1909</cell><cell>0.1664</cell></row><row><cell>Alex_Kapranos</cell><cell>0</cell><cell>0.4298</cell><cell>0.2706</cell><cell>0.2263</cell></row><row><cell>Alexander_McCall_Smith</cell><cell>0.0832</cell><cell>0.3963</cell><cell>0.1955</cell><cell>0.1593</cell></row><row><cell>Annie_Laurie_Gaylor</cell><cell>0.0233</cell><cell>0.5021</cell><cell>0.3046</cell><cell>0.2304</cell></row><row><cell>Basic_Element (company)</cell><cell>0.0952</cell><cell>0.8497</cell><cell>0.1670</cell><cell>0.2714</cell></row><row><cell>Basic_Element (music_group)</cell><cell>0.0104</cell><cell>0.8483</cell><cell>0.0757</cell><cell>0.1238</cell></row><row><cell>Bill_Coen</cell><cell>0.0769</cell><cell>0.4375</cell><cell>0.1984</cell><cell>0.1709</cell></row><row><cell>Boris_Berezovsky_(businessman)</cell><cell>0.0015</cell><cell>0.5371</cell><cell>0.4859</cell><cell>0.3503</cell></row><row><cell>Boris_Berezovsky_(pianist)</cell><cell>0</cell><cell>0.5714</cell><cell>0.0045</cell><cell>0.0369</cell></row><row><cell>Charlie_Savage</cell><cell>0.0202</cell><cell>0.6846</cell><cell>0.1135</cell><cell>0.1339</cell></row><row><cell>Darren_Rowse</cell><cell>0.1505</cell><cell>0.3271</cell><cell>0.1910</cell><cell>0.1676</cell></row><row><cell>Douglas_Carswell</cell><cell>0</cell><cell>0.5562</cell><cell>0.1352</cell><cell>0.1286</cell></row><row><cell>Frederick_M._Lawrence</cell><cell>0.1818</cell><cell>0.7027</cell><cell>0.2684</cell><cell>0.2621</cell></row><row><cell>Ikuhisa_Minowa</cell><cell>0</cell><cell>0.5860</cell><cell>0.5229</cell><cell>0.3749</cell></row><row><cell>James_McCartney</cell><cell>0.0293</cell><cell>0.5757</cell><cell>0.2637</cell><cell>0.2275</cell></row><row><cell>Jim_Steyer</cell><cell>0.0556</cell><cell>0.7419</cell><cell>0.4599</cell><cell>0.3296</cell></row><row><cell>Lisa_Bloom</cell><cell>0.0566</cell><cell>0.6341</cell><cell>0.1302</cell><cell>0.1524</cell></row><row><cell>Lovebug_Starski</cell><cell>0</cell><cell>0.2462</cell><cell>0.1176</cell><cell>0.0913</cell></row><row><cell>Mario_Garnero</cell><cell>0.4930</cell><cell>0.9211</cell><cell>0.7741</cell><cell>0.6095</cell></row><row><cell>Masaru_Emoto</cell><cell>0.1091</cell><cell>0.2</cell><cell>0.1014</cell><cell>0.0843</cell></row><row><cell>Nassim_Nicholas_Taleb</cell><cell>0.0056</cell><cell>0.4747</cell><cell>0.3143</cell><cell>0.2578</cell></row><row><cell>Rodrigo_Pimentel</cell><cell>0.0390</cell><cell>0.5385</cell><cell>0.0751</cell><cell>0.1168</cell></row><row><cell>Roustam_Tariko</cell><cell>0.0408</cell><cell>0.4982</cell><cell>0.3634</cell><cell>0.2786</cell></row><row><cell>Ruth_Rendell</cell><cell>0.0132</cell><cell>0.4430</cell><cell>0.3357</cell><cell>0.2304</cell></row><row><cell>Satoshi_Ishii</cell><cell>0.0061</cell><cell>0.6556</cell><cell>0.4239</cell><cell>0.3266</cell></row><row><cell>Vladimir_Potanin</cell><cell>0.0552</cell><cell>0.7508</cell><cell>0.2556</cell><cell>0.2580</cell></row><row><cell>William_Cohen</cell><cell>0</cell><cell>0.3484</cell><cell>0.0816</cell><cell>0.0815</cell></row><row><cell>William_D._Cohan</cell><cell>0.0529</cell><cell>0.6538</cell><cell>0.3458</cell><cell>0.3041</cell></row><row><cell>William_H._Gates,_Sr</cell><cell>0.3039</cell><cell>0.3943</cell><cell>0.1803</cell><cell>0.1491</cell></row><row><cell>average</cell><cell>0.0678</cell><cell>0.4263</cell><cell>0.2506</cell><cell>0.2066</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,111.00,247.91,374.54,9.50;5,111.00,263.50,257.73,9.50" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="5,158.16,247.91,327.38,9.50;5,111.00,263.50,84.51,9.50">PRIS at 2009 Relevance Feedback track: Experiments in Language Model for Relevance Feedback</title>
		<author>
			<persName coords=""><forename type="first">Si</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
