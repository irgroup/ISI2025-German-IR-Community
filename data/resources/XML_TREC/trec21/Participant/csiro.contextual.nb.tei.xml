<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,119.13,58.32,373.73,17.10;1,74.12,83.04,463.70,17.10">Finding, Weighting and Describing Venues: CSIRO at the 2012 TREC Contextual Suggestion Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,202.71,106.36,59.55,11.36"><forename type="first">David</forename><surname>Milne</surname></persName>
							<email>dave.milne@csiro.au</email>
							<affiliation key="aff0">
								<orgName type="department">CSIRO ICT Centre</orgName>
								<address>
									<postBox>PO Box 76</postBox>
									<postCode>1710</postCode>
									<settlement>Epping</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,270.65,106.36,66.28,11.36"><forename type="first">Paul</forename><surname>Thomas</surname></persName>
							<email>paul.thomas@csiro.au</email>
							<affiliation key="aff0">
								<orgName type="department">CSIRO ICT Centre</orgName>
								<address>
									<postBox>PO Box 76</postBox>
									<postCode>1710</postCode>
									<settlement>Epping</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,346.66,106.36,62.74,11.36"><forename type="first">Cecile</forename><surname>Paris</surname></persName>
							<email>cecile.paris@csiro.au</email>
							<affiliation key="aff0">
								<orgName type="department">CSIRO ICT Centre</orgName>
								<address>
									<postBox>PO Box 76</postBox>
									<postCode>1710</postCode>
									<settlement>Epping</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,119.13,58.32,373.73,17.10;1,74.12,83.04,463.70,17.10">Finding, Weighting and Describing Venues: CSIRO at the 2012 TREC Contextual Suggestion Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">79A61424F70AF071DFDA4B485400CC26</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We report on the participation of CSIRO 1 in the TREC 2012 contextual suggestion track, for which we submitted four runs. Two submissions were baselines that investigate the performance of a commercial system (namely the Google Places API), and whether the current experimental setup encourages diversity. The remaining two submissions were more complex approaches that explore the importance of time and personal preference. For the former, check-in statistics provided by Foursquare were used to identify which times of day and which days of week venues are more likely or less likely to be frequented. For the latter, textual similarity was used to weight venues with respect to positive and negative examples provided for each profile.</p><p>Our submissions all fall either slightly above or slightly below the mean, depending on how they are judged. Interestingly, our baselines consistently outperform our more complex submissions, which suggests that a) venue quality (as given by Google review score) is a more important signal than either time or personal preference, at least in the context of this evaluation, and b) that the evaluation is biased to a specific type of venue, namely pubs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>This paper describes CSIRO's participation in the 2012 TREC Contextual Suggestion track. The task tackled here is to suggest venues for an individual to visit, given the context of where they are, what the time is, and what the individual has liked and disliked in the past. We provide an evaluation of two baseline systems that rely on the Google Places API and the user reviews it provides, and two more complex systems that incorporate information from the Foursquare API, and are sensitive to personal preference and time.</p><p>The remainder of this paper is structured as follows. The next section describes our approaches for identifying candidate venues, weighting them according to personal preference and time sensitivity, and locating explanatory text to describe them. Section 3 evaluates how this combination of candidate selection, weighting and summarization performs against baseline techniques and the submissions of other participants. Section 4 concludes with some recommendations for future contextual suggestion tracks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">IDENTIFYING, WEIGHTING AND DESCRIBING VENUES</head><p>The next section describes how candidate venues were extracted from Foursquare and Google Places, and is followed by an explanation of how duplicate venues were identified across the two sources. Section 2.3 describes a function for scoring venues against a profile of suggestions that a person has liked or disliked <ref type="bibr" coords="1,54.00,705.71,3.00,5.27">1</ref> Commonwealth Scientific and Industrial Research Organisation in the past. Section 2.4 describes a function for scoring venues based on time-sensitivity, to identify times of day and days of week in which it makes sense to suggest them. The track guidelines call for each venue to be described with a textual snippet, and our approach for obtaining this is explained in Section 2.5. These threads are all brought together in Section 2.6, which describes the final runs that were submitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Candidate selection</head><p>The basic approach to candidate selection was to use the Yahoo! Placefinder API<ref type="foot" coords="1,378.00,277.31,3.00,5.27" target="#foot_0">2</ref> to establish sensible search bounds for each context city, and then exhaustively mine the Foursquare Venues API<ref type="foot" coords="1,332.16,298.19,3.00,5.27" target="#foot_1">3</ref> and the Google Places API<ref type="foot" coords="1,444.24,298.19,3.00,5.27" target="#foot_2">4</ref> for suggestions within these bounds. We expected these two services to be complementary, with Foursquare providing check-in statistics to identify popular venues and suitable times to recommend them, and Google providing reviews. An additional intuition was that the intersection of these services (i.e., the venues that are known by both) would be a tidier source of suggestions than each individually.</p><p>The name and state of the 36 distinct context cities was issued to Yahoo! Placefinder to retrieve suitable bounding areas. The bounds for several of these cities are listed in Table <ref type="table" coords="1,508.08,407.88,3.36,7.80" target="#tab_0">1</ref>. Foursquare was then queried with each bounding rectangle and a filter to exclude venues that did not belong to Food, Arts &amp; Entertainment, Great Outdoors, Nightlife Spot, or one of their descendent categories. Unfortunately the foursquare service is not designed for exhaustive search, and so it cannot handle overly large search areas, and will return a maximum of 50 locations for each query. To overcome these limitations, any time the service returned either an area-too-large exception or a full list of 50 venues, the search area was split into four quadrants to be issued as further queries. These in turn were split as necessary. This successive quartering of search areas continued until each query returned fewer than 50 venues, or to a maximum of 15 recursions, whichever came first. Even for the largest context cities, the recursion limit translates to a minimum search area of approximately 3m by 3m.</p><p>Figure <ref type="figure" coords="1,344.33,577.32,4.44,7.80">1</ref> provides a visual demonstration of this recursive search algorithm in action over Sydney, Australia. The initial bounding box was split repeatedly, with the boxes predictably becoming smallest over downtown Sydney, where the venues are most densely clustered. There is a distinctive dense vertical bar just north of the "Sydney" label, which corresponds to George Street. There are other visible clusters that correspond to Manly, Bondi and other populous areas. There are also a few areas in which the crawling algorithm appears to have broken down or in which venues are unexpectedly sparse, most notably around Parramatta and Darling Harbour. In total, 1411 "leaf" bounding boxes (those that did not need to be split further) were required to capture all of the 15438 relevant venues that Foursquare knew of in the area.</p><p>The same recursive process was followed to gather candidate venues from Google Places, with a few small differences. Google does not allow searching with rectangular bounding areas, and so each search box was replaced by a circle centred in the same location with a diameter equal to the square's diagonal. It is also limited to 20 results per query, and consequently the search circles were split more often. Finally, Foursquare's category filters were translated by hand to match Google's place types.</p><p>It should be noted that the recursive crawling of these APIs goes against their intended use, and is somewhat wasteful. In Foursquare's case it directly contravenes their terms of service, which unambiguously forbids attempting to obtain exhaustive lists of venues. Permission was obtained directly from Foursquare via email for these experiments; but this should not be seen as permission for the research community as a whole. See Section 4 for our recommendations for future investigations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Disambiguating candidates</head><p>Mapping between common listings across the Foursquare and Google Places is a non-trivial task. There are many small variations in both the names and locations of venues. For example, the Google venue Joey's Delicatessen in New York is listed by Foursquare as Joey's Deli, and there is a distance of 126m between the listings. A common problem is the inconsistent inclusion or omission of words related to the type of venue and its location. For example, Tope Cocktail Bar Lounge in Google is listed simply as Tope in Foursquare, and Tarantino's Restaurant is expanded to Tarantino's Restaurant at Fisherman's Wharf.</p><p>Fortunately, words that are related to type and location are easy to identify, because they occur disproportionately often in the listings while terms like Tope and Tarantino's are comparatively rare.</p><p>For each Google venue, we locate all Foursquare venues within a radius of 500m, and score each potential pairing by the following formula:</p><formula xml:id="formula_0" coords="3,68.20,384.32,189.18,18.88">𝑠𝑐𝑜𝑟𝑒 𝐹, 𝐺 = 𝑖𝑑𝑓 𝑥 !∈ !∩! - 𝑖𝑑𝑓 𝑥 !∈ !∪!!!∩!</formula><p>where F is the set of tokens in the name of the Foursquare venue, G is the set of tokens in the name of the Google venue, and idf (x) is the inverse document frequency of the token x, as calculated by the following:</p><formula xml:id="formula_1" coords="3,68.20,454.88,70.38,20.61">𝑖𝑑𝑓 𝑥 = 𝑙𝑜𝑔 𝑇 𝑐 𝑥</formula><p>where T is the multiset of all tokens in all venue titles and c(x) is the number of occurrences of token x in T. In short, each individual token is weighted so that rare tokens are valued highly. A pair of titles is then weighted by their matching and mismatching tokens, with matches adding to the combined score, and mismatches subtracting from it. All negatively scored pairings are thrown away, and the highest weighted pairing for each Google venue is retained. The listings for each context city are treated entirely separately.</p><p>Again, we note that the terms of use for the Google and Foursquare APIs may prohibit such aggregation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Identifying personal preference</head><p>We attempted to match candidates to users' preferences by looking at the text describing each candidate and each example. If a candidate's description is similar to examples a user has liked in the past, it should score well (all else being equal); if a candidate's description is similar to examples a user didn't like, it should score poorly. We used a simple vector-space approach to implement this.</p><p>The description of each candidate was treated as a bag of words, with stopwords removed and terms stemmed with the Porter stemmer. Terms were weighted with BM25, and all examples were summed to give a single vector for each profile:</p><formula xml:id="formula_2" coords="3,331.96,211.52,89.21,18.88">𝑝 = 𝛽 𝑒 -𝛾 𝑒′ ! ! ∈! !∈!</formula><p>where 𝛽 and 𝛾 are tuning constants, P is the set of positive examples, and N is the set of negative ones. Assuming positive examples are more informative than negative ones, we set 𝛽=0.75 and 𝛾=0.25. This is equivalent to Rocchio relevance feedback with the initial query a zero vector.</p><p>Table <ref type="table" coords="3,341.74,291.72,4.44,7.80" target="#tab_2">2</ref> provides a sample of terms and preference vectors, and shows the differences in weights from profile to profile. We can see that in general users who (dis)like bars tend to (dis)like pubs (rho=0.46), and those who (dis)like walks tend to (dis)like the outdoors (rho=0.30); on the other hand, there is no correlation between liking bars and liking walks (rho=0.02) and there is wide variation even amongst the first ten profiles.</p><p>Armed with a preference vector for each profile, we scored each candidate according to the cosine distance between its description and the preference vector 𝑝.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Identifying time sensitivity</head><p>Time is an important factor when suggesting a venue or activity: it makes little sense to suggest a café at 4am, or a water park in the middle of winter. The track's guidelines discuss three levels of time sensitivity: time of day (morning, afternoon or evening), day of week (weekend or weekday) and season (spring, summer, winter, or fall).</p><p>Foursquare's check-in statistics are essentially histograms of popularity over time, and as such are an ideal source of data for identifying the time sensitivity of a venue. Unfortunately the API provides public access only to the current check-in statistics for each venue. Historical statistics are only available to the venue's registered owner. The API could be polled to retrieve statistics over time, but that would not be practical for all 477k foursquare candidates our crawling algorithm identified in the 36 context cities (see Table <ref type="table" coords="3,384.01,566.28,3.24,7.80" target="#tab_0">1</ref>). Gathering such statistics even once was a taxing effort for both our systems and for the generously shared APIs. Doing so repeatedly would be pushing one's luck.</p><p>Consequently, we generalize to measuring time sensitivity for broad classes of venues rather than individuals. Over the course of approximately two weeks, the city of Toronto was crawled every hour, and check-in counts of each venue were aggregated up into the hierarchy of categories they belong to. With this short timeframe for data collection, any attempt to measure long-term (i.e., seasonal) trends was abandoned, and instead we focus on time-of-day and day-of-week by building histograms of the kind shown in Figure <ref type="figure" coords="3,378.51,683.88,3.36,7.80">2</ref>.</p><p>The graph in Figure <ref type="figure" coords="3,402.21,698.52,8.44,7.80">2a</ref> was built by calculating the average number of check-ins per hour for all Theme Parks, divided by the These graphs demonstrate some interesting patterns. The graph of theme parks, for example, is markedly different for weekdays (where most visits occur in the middle of the day) and weekends (where visits are even throughout the day). In contrast, visits to movie theatres follow the same pattern (heavily biased towards the evening) regardless of day-of-week.</p><p>It is important to point out that each bar in these graphs has been normalised against the total number of visits per hour during each period, so comparing the bars within each graph is potentially misleading. Figure <ref type="figure" coords="4,124.82,430.20,8.44,7.80">2c</ref> plots the average number of visits per hour to all venues captured by our Toronto crawl, and demonstrates that visits are much more likely in weekend evenings than at any other time. This information is lost in Figure <ref type="figure" coords="4,227.19,461.40,8.44,7.80">2a</ref> and Figure <ref type="figure" coords="4,282.85,461.40,7.48,7.80">2b</ref>, which are designed to identify a good type of venue to visit at a particular time of day (i.e., to compare across graphs), rather than a good time of day to visit a particular type of venue (i.e., to compare within each graph).</p><p>To calculate a time-based score for a venue at a particular point in time, the relevant histogram is consulted to retrieve the visitprobability. Each probability is individually very small (there are many types of venues), and so they are normalised by the maximum probability of any one type of venue being visited at the given time. Venues belonging to multiple categories are scored using their highest scoring category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Describing venues</head><p>Only in rare cases did the commercial APIs directly provide textual snippets to describe venues. For all of the remaining venues, snippets were generated in a simple-minded way, by feeding the venue's URL into the Yahoo BOSS search API, retrieving the first result with a matching URL, and extracting Yahoo!'s snippet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Runs submitted</head><p>We submitted a total of four runs to the contextual suggestion track. Two submissions were baselines: a commercial baseline, which gives a benchmark based on a commercial API; and a "pub-run" baseline, which tests the track's evaluation criteria.</p><p>The other two submissions were based on different combinations of the preference-based and time-based signals above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.1">The commercial baseline</head><p>The "commercial" baseline (baselineA) is output from the Google Places API, a commercial database of places and reviews. It allows us to evaluate how this API performs on the task (admittedly, used simple-mindedly), and to benchmark other runs. Implicitly is also evaluates the importance of personal preference, because this baseline makes absolutely no use of users' profiles.</p><p>Each context was split into day, time, and location. For each context, we issued a query to the Google Places API and retrieved the top 20 venues in the given location. This was a single call centered on the context's stated location, rather than a crawl of the type described in Section 2.1. The call was issued at a number of days and times to cover the context: for example, a "weekend morning" would see queries issued from 0800 to 1045, local time, on a Saturday and Sunday. The union of all results was taken, deduplicated, and sorted by Google's own ratings. The top-rated results were kept as suggestions. Profile information was not used in this run because commercial APIs do not expose this for general use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.2">The pub-run baseline</head><p>The "pub-run" baseline (baselineB) tests whether the track guidelines are adequate, and especially whether the 2013 guidelines need to consider diversity. On the assumption that our student judges tend to like going to the pub, we just recommend the closest pubs, restaurants, or similar. Any one suggestion like this is probably good: but if a list scores well despite being entirely pubs or restaurants, then we should encourage diversity in future tasks.</p><p>The baseline is formed the same way as the commercial baseline: from commercial APIs with no personalisation, but suggestions are restricted to pubs, restaurants, and cafes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.3">Time-emphasis and preference-emphasis runs</head><p>Our other two runs used candidates identified from Foursquare and Google, as described in Section 2.2, and scores for personal preference (Section 2.3) and time (Section 2.4). The scores were combined in a linear fashion: As discussed above, our runs all suffer when judged by their representative websites: with the exception of the commercial baseline, every run falls behind the median (0.34) and well behind the best submission (0.79). Performance improves in relation to other participants when geographical and temporal dimensions are considered, with performance in both WGT and GT following the same pattern: our baselines perform slightly higher than the mean, while our more complex submissions fall slightly below it.</p><formula xml:id="formula_3" coords="4,335.43,711.92,200.76,7.89">𝑠𝑐𝑜𝑟𝑒 = 𝜆 𝑠𝑐𝑜𝑟𝑒 𝑝𝑟𝑒𝑓𝑒𝑟𝑒𝑛𝑐𝑒 + 1 -𝜆 𝑠𝑐𝑜𝑟𝑒 𝑡𝑖𝑚𝑒</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">DISCUSSION AND CONCLUSIONS</head><p>In this paper, we have presented our efforts to recommend venues for people to visit, given where they are, what the time is, and what they have liked and disliked in the past. We have provided an evaluation of two baseline systems that rely on the Google Places API and the user reviews it provides, and two more complex systems that are sensitive to personal preference and time.</p><p>The baselines outperform our other submissions, which suggests either that time-and preference-based signals are less important in the current experimental setup than venue rating (i.e., Google review score), or simply that our attempts to capitalize on these signals are faulty. The relatively high performance of the pub-run baseline (which emphasizes one specific class of venue) suggests that the track does not encourage diversity.</p><p>This track has presented interesting and challenging research problems, including information retrieval, recommendation, and summarization. We hope it becomes a staple in future TREC conferences. Moving forwards, we would recommend that organizers of the track make efforts to either approach industrial partners to locate more realistic sources of data, or to tailor the task to fit the data they have already released.</p><p>There are well-established organizations such as Foursquare and Yelp that already tackle the task of recommending venues. They have very rich data to work with:</p><p>• They have a large volume of structured information about venues (which is only available to researchers via the somewhat dubious lengths we discussed in Section 2.1) • They service a diverse range of people (as opposed to a limited pool of similar participants) • They have explicit measures of what participants have liked and disliked, sourced from reviews and check-in statistics (as opposed to laborious manual annotation).</p><p>Access to such data-Yelp's Academic Dataset is a good example-would resolve the concerns we raised in Section 3 about diversity and consistent annotation. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,184.10,248.52,243.87,7.80;4,110.88,98.40,71.04,90.48"><head>Figure 4</head><label>4</label><figDesc>Figure 2: Histograms of time-sensitivity for Foursquare venues.</figDesc><graphic coords="4,110.88,98.40,71.04,90.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,110.60,240.80,392.83,7.89"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Performance (P@5) of baselines and runs against best and median of all submissions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="2,82.00,246.35,447.45,289.70"><head></head><label></label><figDesc></figDesc><graphic coords="2,82.00,246.35,447.45,289.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,78.72,57.00,449.27,501.72"><head>Table 1 : A sample of context cities, and the candidate venues extracted for them</head><label>1</label><figDesc></figDesc><table coords="2,78.72,71.61,449.27,165.09"><row><cell>Location</cell><cell></cell><cell cols="2">NE corner</cell><cell cols="2">SW corner</cell><cell></cell><cell>Venues</cell><cell></cell></row><row><cell>City</cell><cell>State</cell><cell>lat</cell><cell>long</cell><cell>lat</cell><cell>long</cell><cell>Google</cell><cell>Foursquare</cell><cell>mutual</cell></row><row><cell>Akron</cell><cell>OH</cell><cell>41.17</cell><cell>-81.40</cell><cell>41.00</cell><cell>-81.40</cell><cell>1061</cell><cell>3207</cell><cell>584</cell></row><row><cell>Albuquerque</cell><cell>NM</cell><cell>35.22</cell><cell>-106.42</cell><cell>34.94</cell><cell>-106.42</cell><cell>678</cell><cell>3213</cell><cell>277</cell></row><row><cell>Ann Arbor</cell><cell>MI</cell><cell>42.33</cell><cell>-83.66</cell><cell>42.22</cell><cell>-83.66</cell><cell>794</cell><cell>1947</cell><cell>526</cell></row><row><cell>…</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Los Angeles</cell><cell>CA</cell><cell>34.34</cell><cell>-117.93</cell><cell>33.69</cell><cell>-117.93</cell><cell>18947</cell><cell>68227</cell><cell>9660</cell></row><row><cell>Mesa</cell><cell>AZ</cell><cell>33.53</cell><cell>-111.58</cell><cell>33.26</cell><cell>-111.58</cell><cell>2639</cell><cell>13267</cell><cell>1492</cell></row><row><cell>New York</cell><cell>NY</cell><cell>40.92</cell><cell>-73.69</cell><cell>40.50</cell><cell>-73.69</cell><cell>58458</cell><cell>110428</cell><cell>23994</cell></row><row><cell>…</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>San Diego</cell><cell>CA</cell><cell>33.11</cell><cell>-116.80</cell><cell>32.51</cell><cell>-116.80</cell><cell>4353</cell><cell>30940</cell><cell>2123</cell></row><row><cell>San Francisco</cell><cell>CA</cell><cell>37.85</cell><cell>-122.32</cell><cell>37.70</cell><cell>-122.32</cell><cell>5574</cell><cell>15193</cell><cell>3085</cell></row><row><cell>…</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Virginia Beach</cell><cell>VA</cell><cell>37.03</cell><cell>-75.87</cell><cell>36.55</cell><cell>-75.87</cell><cell>1407</cell><cell>5707</cell><cell>762</cell></row><row><cell>Washington</cell><cell>DC</cell><cell>39.00</cell><cell>-76.90</cell><cell>38.80</cell><cell>-76.90</cell><cell>5107</cell><cell>18166</cell><cell>3001</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>total</cell><cell>157972</cell><cell>477541</cell><cell>72059</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,200.68,550.92,247.94,7.80"><head>The recursive search algorithm in action over Sydney, Australia.</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,76.08,57.48,456.17,112.98"><head>Table 2 : A sample of terms and preference vectors</head><label>2</label><figDesc></figDesc><table coords="3,76.08,75.36,456.17,95.10"><row><cell>Term</cell><cell>User 1</cell><cell>User 2</cell><cell>User 3</cell><cell>User 4</cell><cell>User 5</cell><cell>User 6</cell><cell>User 7</cell><cell>User 8</cell><cell>User 9</cell><cell>User 10</cell></row><row><cell>bar</cell><cell>0.74</cell><cell>-0.34</cell><cell>3.39</cell><cell>2.87</cell><cell>2.32</cell><cell>-0.87</cell><cell>-0.74</cell><cell>4.3</cell><cell>-0.08</cell><cell>1.66</cell></row><row><cell>pub</cell><cell>0.00</cell><cell>-0.31</cell><cell>-0.31</cell><cell>-0.31</cell><cell>0.00</cell><cell>-0.31</cell><cell>-0.31</cell><cell>0.93</cell><cell>0.00</cell><cell>0.93</cell></row><row><cell>walk</cell><cell>0.00</cell><cell>1.54</cell><cell>1.54</cell><cell>1.54</cell><cell>1.54</cell><cell>-0.51</cell><cell>1.54</cell><cell>0.00</cell><cell>1.54</cell><cell>0.00</cell></row><row><cell>outdoor</cell><cell>0.69</cell><cell>0.44</cell><cell>3.08</cell><cell>1.73</cell><cell>3.08</cell><cell>-0.32</cell><cell>1.79</cell><cell>3.08</cell><cell>0.44</cell><cell>1.42</cell></row><row><cell>shrine</cell><cell>0.00</cell><cell>-0.36</cell><cell>1.09</cell><cell>0.00</cell><cell>0.00</cell><cell>-0.36</cell><cell>-0.36</cell><cell>1.09</cell><cell>-0.36</cell><cell>-0.36</cell></row><row><cell>seafood</cell><cell>-0.30</cell><cell>0.00</cell><cell>0.00</cell><cell>-0.30</cell><cell>0.00</cell><cell>0.89</cell><cell>0.89</cell><cell>0.00</cell><cell>0.89</cell><cell>0.89</cell></row></table><note coords="4,54.00,277.32,240.04,7.80;4,54.00,287.88,240.04,7.80;4,54.00,298.20,240.08,7.80;4,54.00,308.52,239.99,7.80;4,54.00,318.60,129.20,7.80"><p><p><p>total number of new check-ins per hour for all venues regardless of category. Figure</p>2b</p>was built in the same fashion, for Movie Theaters. The y-axis in each graph represents the probability that a random check-in occurring at a particular hour would have occurred at the given type of venue.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="1,323.01,648.36,154.92,7.80;1,331.96,658.44,160.44,7.80"><p>The Yahoo! Placefinder API is available at http://developer.yahoo.com/geo/placefinder/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="1,323.01,673.08,196.68,7.80;1,331.96,683.16,188.83,7.80"><p>The Foursquare Venue Search endpoint is described at http://developer.foursquare.com/docs/venues/search</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="1,323.01,697.80,178.68,7.80;1,331.96,707.88,216.45,7.80"><p>The Google Place Search endpoint is described at https://developers.google.com/places/documentation/search</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>weekend weekday</head><p>The time-emphasis run (csiroht) placed more emphasis on suitable times, with 𝜆=0.3. The preference-emphasis run (csiroth) put more emphasis on per-user preference with 𝜆=0.7. Note that for both runs there are implicit location, popularity and rating components in addition to the explicit time-based and preferencebased signals, because candidates had to be geographically relevant and present in the commercial APIs to be considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EVALUATION</head><p>Submissions to the TREC Contextual Suggestion Track were evaluated along four separate dimensions: the interestingness of the venue's descriptive snippet (D) and website (W), and it's appropriateness given the context's geographical location (G) and timeframe (T). Table <ref type="table" coords="5,132.06,525.24,4.44,7.80">3</ref> shows the performance of each of our runs with respect to these dimensions, when P@5 scores are averaged across all judged contexts and profiles.</p><p>Scores for the W and D dimensions are low across all runs. Much of the problem may be due to the process described in Section 2.5 breaking down and failing to identify a suitable website for the venue. In these situations we fell back to presenting the Google Places webpage (with a map, short description, and reviews), and simply using the name of the venue as its description. However, spot-checking the results showed that these dimensions where judged somewhat unexpectedly. Evaluation involved presenting the websites and descriptions to the Toronto students who provided the original profiles, and asking them to judge whether they found the suggested venue interesting. For example, in Context 22 we were asked to provide venues close to Escondido CA to visit during a weekend morning in the winter. Figure <ref type="figure" coords="5,272.65,684.60,4.44,7.80">3</ref> lists our suggestions for profile 15, the first four of which were judged "not interesting", and the 5 th does not appear to have been judged.</p><p>One would expect that at least one of these diverse and popular suggestions to be interesting, no matter what individual the suggestions are being personalized for.</p><p>Performance is consistently high for the geo-location dimension, with scores ranging from 0.76 for the preference-emphasis run to 0.81 for the time-emphasis run. It is surprising that these scores are not higher across all runs, however. The candidate selection algorithm described in Section 2.1 should have ensured that every venue-even the lowest ranked ones-were appropriate. We have spot-checked the judgments and again found unexpectedly judged candidates. For example, Context 5 asked for suggestions in Los Angeles. For many of the profiles we suggested Whisky A Go-Go (a famous nightclub on the Sunset Strip) and the Honda Center (an arena hosting concerts and sporting events located 40mins drive from downtown LA). Both venues were judged geographically inappropriate. This is surprising, and suggests tighter guidelines might be needed for geo-location in future; both participants and judges should be able to agree on what makes a reasonable travel time, for example.</p><p>Performance for the time dimension ranges from 0.47 for the time-emphasis run to 0.59 for the pub-run baseline. Disappointingly, the naïve baselines that choose highly rated venues regardless of time outperform the runs that are informed by Foursquare's check-in data. Again there are cases of inconsistent judging here: for example, the same Los Angeles venues described above (Whisky A Go-Go and the Honda Center) were judged inappropriate for a weekday evening, despite foursquare check-in data indicating that they are very popular during these times.  </p></div>			</div>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
