<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,101.54,57.64,408.94,16.65">UGent participation in the Microblog Track 2012</title>
				<funder>
					<orgName type="full">Ghent University</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,62.04,80.32,71.83,11.10"><forename type="first">Thong</forename><surname>Hoang</surname></persName>
							<email>thoang@intec.ugent.be</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Information Technology -IBCN</orgName>
								<orgName type="institution">Ghent University -iMinds</orgName>
								<address>
									<settlement>Ghent</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,136.94,80.32,42.61,11.10"><forename type="first">Van</forename><surname>Duc</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Information Technology -IBCN</orgName>
								<orgName type="institution">Ghent University -iMinds</orgName>
								<address>
									<settlement>Ghent</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,188.78,80.32,101.03,11.10"><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
							<email>tdmeeste@intec.ugent.be</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Information Technology -IBCN</orgName>
								<orgName type="institution">Ghent University -iMinds</orgName>
								<address>
									<settlement>Ghent</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,299.09,80.32,76.48,11.10"><forename type="first">Joannes</forename><surname>Deleu</surname></persName>
							<email>jdeleu@intec.ugent.be</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Information Technology -IBCN</orgName>
								<orgName type="institution">Ghent University -iMinds</orgName>
								<address>
									<settlement>Ghent</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,384.43,80.32,78.50,11.10"><forename type="first">Piet</forename><surname>Demeester</surname></persName>
							<email>piet.demeester@intec.ugent.be</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Information Technology -IBCN</orgName>
								<orgName type="institution">Ghent University -iMinds</orgName>
								<address>
									<settlement>Ghent</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,472.18,80.32,78.01,11.10"><forename type="first">Chris</forename><surname>Develder</surname></persName>
							<email>cdvelder@intec.ugent.be</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Information Technology -IBCN</orgName>
								<orgName type="institution">Ghent University -iMinds</orgName>
								<address>
									<settlement>Ghent</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,101.54,57.64,408.94,16.65">UGent participation in the Microblog Track 2012</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A79410F8B91AA0629B50025184C8F60F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>D.3.3 [Microblog Storage and Retrieval]: Microblog Search and Retrievalretrieval models</term>
					<term>information filtering</term>
					<term>search process Microblog Retrieval models Twitter</term>
					<term>query expansion</term>
					<term>document expansion</term>
					<term>classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe the search system, developed at Ghent University for the TREC 2012 Microblog Track in order to rank Twitter messages or 'tweets' from a fixed corpus in response to a number of search requests. Our system ranks the tweets based on a Logistic Regression classifier trained with data from the Microblog Track 2011. The features used for training the classifier include local tweets features, but also, query expansion and tweet expansion features, based on external Web data, which appear to significantly improve results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Microblog services such as Twitter, Tumblr, Jaiku, etc. have become major types of social media on the web. These blogging applications allow users to broadcast short messages, individual images, status updates, or video links as well as general web links, to share information with friends, family and the general public. Recently, people have become more interested in the ubiquitous communication medium of the microblog, than in "long" forms of communications (e.g., traditional blogs). Despite the amount of research in the microblog area in the past few years <ref type="bibr" coords="1,257.93,513.64,14.98,8.10" target="#b8">[13]</ref>  <ref type="bibr" coords="1,276.87,513.64,13.92,8.10" target="#b9">[14]</ref>, search and online ranking on microblogs have not yet been addressed extensively. Therefore, the TREC Microblog Track was initiated in 2011 to replace the previous Blog Track. For TREC 2012, we participated in the real-time ad-hoc task of the Microblog Track. A corpus of more than sixteen million tweets, Twitter microblog messages, was fetched using the Twitter API, and 60 search topics and relevance judgments were provided by the track organizers [1]. In the real-time adhoc task, the user issues a query at a temporal reference point and is looking for tweets that contain the most relevant and recent information to the query. Hence, the system should answer a query by providing a list of relevant tweets ordered from latest to earliest, up until the time the query was issued. This search task leads to a number of interesting issues, specific to the nature of a microblog service, which became apparent while we developed our system. First, each microblog post is very short, by definition. Tweets are limited in length to 140 characters but may contain hyperlinks to a specific topics or users. Abbreviations, phonetically shortened terms, drop vowels, etc. [2] are often found in tweets. This frequently leads to a vocabulary mismatch problem between the query and Twitter messages. Second, users write tweets in various formats. Some microblog posts are carefully written and clear to read, whereas others are quite difficult to read. However, the links, properties (hashtag, retweets, etc.) of a low quality post may still produce valuable information. Finally, microblogs are in multiple languages for people all around the world. However, this track only considers non-English messages by default as nonrelevant. Therefore, we had to filter out non-English tweets first. For our system, we applied various techniques to retrieve more relevant tweets. In particular, we explored query expansion and tweet expansion. We applied Logistic Regression to model the relevance scores of the retrieved tweets, based on features that were extracted from the tweets themselves and some external data, in order to improve the accuracy of our search system with respect to traditional IR methods. The paper is organized as follows. In Section 2, we briefly describe our retrieval system. In Section 3, we show our experimental results, based on feedback received from the TREC organizers. Finally, we summarize our findings and possible future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RETRIEVAL SYSTEM</head><p>As this is the first time we participate in the Microblog Track, we focus on establishing a baseline system that can be easily extended for addressing related research questions and for further developing our retrieval system in the future. These are the main elements of our baseline system:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ï‚·</head><p>A language detector, used to filter the English tweets in Twitter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ï‚·</head><p>A Lucene [3] index, used for basic tweet scoring with respect to queries. ï‚· Document expansion and query expansion, used to help overcome the vocabulary mismatch problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ï‚·</head><p>A linear classifier (logistic regression) <ref type="bibr" coords="1,510.66,610.27,9.61,8.10" target="#b1">[4]</ref>, used to combine multiple features into an overall relevance score.</p><p>Figure <ref type="figure" coords="1,346.82,640.15,4.50,8.10" target="#fig_0">1</ref> briefly outlines architecture of our search system's architecture. We submitted four officials runs that are different combinations of these basic elements. The following sections will be a brief description of each building block. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preprocessing Data</head><p>According to the track guidelines, only English tweets are considered as potentially relevant. We therefore use the language detection tool LangDetect <ref type="bibr" coords="2,149.76,374.90,10.58,8.10" target="#b0">[5]</ref> to filter non-English tweets from the total tweets collection, as it is fast and accurate [12].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Text Scoring</head><p>One of the used features is the basic score that a standard IR system assigns to the tweets in response to the training queries from the 2011 track. The reason we chose for the Lucene search engine, is that it is a robust, powerful, free and flexible search toolkit. Note that we could just as well have used other search engines like Indri, Terrier, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Document and Query Expansion</head><p>As indicated earlier, text-based messages in Twitter are limited to 140 characters. This leads to a vocabulary mismatch problem between queries and documents (tweets). We explore two common approaches to overcome the lexical gap between documents and queries: document expansion and query expansion. Document expansion: By inspecting the judgments used for relevance evaluation in 2011, we find that most of the relevant tweets contain URLs in their post (around 94% of the highly relevant tweets and 80% of all relevant tweets, as opposed to 53% in the non-relevant tweets). This suggests that the presence of URLs can lead to valuable information for extending a large fraction of the tweets and queries. However, collecting the entire pages linked to by these URLs was judged unnecessary to build a baseline system. Not only would we need a general parser to detect possible relevant blocks of text in the result files, many of the URLs also pointed to graphics or multimedia data, which could not be directly used for our purposes. However, when we investigated the source files of these URLs, in most of the cases the page titles appeared to bring the essence of the page's content in well-chosen terms. Additionally, mostly informative (and therefore potentially relevant) tweets (e.g., press articles) contained links to pages with a clear title. For these reason, our crawler system just extracted the page title for the URLs. To avoid having to crawl data from each tweet that contains a URL in the whole collection, we chose the top 2000 tweets with the highest Lucene scores for each of the 2012 test queries. For this top 2000 (per query), the page titles related to the URLs were collected. After extracting the titles from the URLs, we just simply appended these to the original tweets to expand them. As expected, some of the titles could not be crawled because the website was blocked, spam or no longer existed. Table <ref type="table" coords="2,527.34,507.76,4.50,8.10" target="#tab_0">1</ref> shows the number of titles that were collected by our system for the training queries. Ave.tweets means the average number of tweets which are returned for each query, ave.URLs means the average fraction of URLs in the tweet collection, and ave.title collected are the fraction of tweets for which the page title was collected by our crawler system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query expansion:</head><p>We also used the crawled titles to perform query expansion. Again, based on the initial Lucene ranking, we used the URL titles found within the top K tweets (K = 10, 30, or 50) to extend the queries. Note that the top tweets as ranked by Lucene display the highest similarity with the original query. Therefore, if K is too high, more terms that are non-relevant will appear in the expanded queries. To clarify the advantages of query expansion in the context of microblog search, here is an example. The original query in topic 87 is "chicken recipes". For this query, the collected title terms of the top 30 tweets are "chicken" (10x), "recipes" (14x), "recipe" (2x), "better" (4x), "healthy" (2x), and "easy" (2x). These terms intuitively form a sensible query (like, e.g., "[Easy | better] healthy chicken [recipes | recipe]"). In the expanded queries, the terms were weighted according to the term frequencies in the titles. It is therefore possible that high quality queries will describe the particular topic. We intend, using this form of query expansion, to capture more hidden terms (named entities, nouns, verbs, news sources, etc.). However, based on the original Lucene ranking, the expanded query is not always 'better' than the original one. A counter example is the query "Steve Jobs' health" in topic 106. For this query, user wants to know about the health situation of Steve Jobs'. However, the returned title terms of top 30 tweets for this query are "steve" (7x), "jobs" (7x), "is" (2x), "of" (3x), "health" (1x), "apple" (5x), "destroyer" (2x), "creator" (3x), "composed" (2x), and "products" (2x). These terms can be formed another query like: "Steve Jobs is [destroyer and creator] of apple composed products". The new query can be interpreted differently with respect to the original query. Moreover, some topics like "Chipotle raid" (topic 80), "Superbowl commercials" (topic 99), etc. did not allow collecting any additional title terms. By expanding the original document and query with the collected title terms, we get the idea that it is indeed possible to discover more relevant tweets. However, the method now suffers from some obvious flaws (e.g., biased by the original Lucene ranking). Therefore, further research is required to explore the full potential of the approach. By expanding the original document and query with the collected title terms, we get the idea that it is indeed possible to discover more relevant tweets. However, the method now suffers from some obvious flaws (e.g., biased by the original Lucene ranking).</p><p>Therefore, further research is required to explore the full potential of the approach.</p><p>In future research, we also intend to make use of other external sources like Wikipedia, large newspaper website, etc. to add semantics to the original tweets and queries (e.g., see <ref type="bibr" coords="3,256.61,508.36,13.58,8.10" target="#b7">[11]</ref>). The effectiveness of the expansion might also be improved by means of techniques like relevance-based language models <ref type="bibr" coords="3,281.11,532.12,9.86,8.10" target="#b2">[6]</ref>, temporally-biased expansion models <ref type="bibr" coords="3,188.10,544.00,9.66,8.10" target="#b3">[7]</ref>, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Logistic Regression</head><p>In this section, we would like to focus on the classification step, whereby the relevance of a tweet for a query is determined by applying logistic regression on the given topics for the 2012 Track, trained on the 2011 topics. As mentioned in the introduction, tweets often contain abbreviated or skeleton terms to describe feelings or ideas. For example, some users write, e.g., ^-^, or =^^= to express happiness.. In general, many of these terms are barely decipherable, let alone in official English. However, because messages with these low-quality terms may still contain valuable information, we need to extract as many features as possible, in order to improve the effectiveness of the search system. We chose logistic regression as a classifier to estimate the (binary) relevance because it is a simple yet powerful technique, and apart from a predicted label, we can use the estimated probability of relevance, directly resulting from the algorithm, to propose a sensible ordering of the results, as in a simple learning-to-rank approach. The features could however be combined in many different approaches like inference networks <ref type="bibr" coords="3,486.38,151.19,9.75,8.10" target="#b4">[8]</ref>, neural network <ref type="bibr" coords="3,317.93,163.19,9.62,8.10" target="#b5">[9]</ref>, or other learning-to-rank approaches, see for instance <ref type="bibr" coords="3,527.38,163.19,13.89,8.10" target="#b6">[10]</ref>. In the following, we briefly describe the features that were extracted from tweets and appeared to be useful in discriminating between relevant and non-relevant tweets:</p><p>1) text_score (d,q): This is a Lucene score which is calculated between the text in tweet d and query q. 2) textTitle_score (d,q): The Lucene score between text in tweet d, if possible extended with the title tokens, and query q. 3) textTitle_Qtop10_score (d,q): The Lucene score between text in tweet d with the title terms, and query q is extended by using the URLs titles found within top 10 tweets. 4) textTitle_Qtop30_score (d,q): The Lucene score between text in tweet d with the title terms, and query q is extended by using the URLs titles found within top 30 tweets. 5) textTitle_Qtop50_score (d,q): The Lucene score between text in tweet d with the title terms, and query q is extended by using the URLs titles found within top 50 tweets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6) url (d) -binary:</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>12) avetextTitle_length (d):</head><p>The average word length in the expanded tweet d, i.e., including added title terms. 13) query_length (q): Number of terms of query q without the title tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>14) avequery_length (q):</head><p>The average word length in query q without the title tokens.</p><p>Because of the limited time, we did not investigate the relationship between Twitter users. For example, if a twitter user has many 'followers', he/she is more likely to provide relevant tweets than other users who has very few followers. Our future work will take into account these aspects as well. Other potentially interesting features might be formed by clustering the textual data, e.g., to deal with very short tweets (which have very low Lucene ranking, because they do not contain any query terms, or are ranked artificially high, if they do).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EXPERIMENTAL RESULTS</head><p>We briefly describe the Twitter data collection process, the training data set, our submitted runs, and our results as we received them from the Microblog Track organizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Twitter data</head><p>For this year, the organization used the Tweets2011 corpus, already released for last year's track. The data collection contained a list of tweet ID's for approximately 16 million tweets, sampled between January 23 rd and February 8 th , 2011. The Track also provided the twitter-corpus-tools, to help all the participants download the tweets directly from Twitter. All participating groups had to retrieve the data by themselves, directly from the Twitter API, which means that each participant has a more or less different tweet collection. We had to fetch the data in HTML format (as we have no access to the API that provides the more complete JSON tweet meta-data).</p><p>The data was crawled on a personal desk top (Intel i3 processor, 4GB of RAM) in May 2012. The received HTTP response codes are given below: ï‚· Status 200a good tweet for downloading. ï‚· Status 302a re-tweet will be downloaded via redirect. ï‚· Status 403invalid request: Twitter refuses to respond. ï‚· Status 404the requested resource could not be found.</p><p>Table <ref type="table" coords="4,77.63,385.10,4.50,8.10" target="#tab_1">2</ref> shows some details about our tweet collection data. The table includes the English tweets which were detected by means of the LangDetect toolkit. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Relevance judgment data</head><p>We used last year's topics and relevance judgments, which were released by TREC, for developing and training our system. The used relevant scores for the judged tweets are the following: ï‚· 2a highly relevant tweet. ï‚· 1a relevant tweet. ï‚· 0a non-relevant tweet.</p><p>ï‚· -2a spam tweet.</p><p>However, some relevant tweets had in the mean time disappeared, (tweets deleted by the Twitter users, or user accounts no longer exist). Table <ref type="table" coords="4,102.92,675.43,4.50,8.10" target="#tab_2">3</ref> provides details on the annotated data in the total collection. Table <ref type="table" coords="4,116.69,687.31,4.50,8.10">4</ref> summarizes the collected titles. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Submitted runs</head><p>We submitted the following four official runs with different feature combinations. 1. IBCN1 -This run does not include any external resource (i.e., URL page titles). Only basic features which are combined using logistic regression. The features used are 1, 6, 7, 8, 9, 10, 13 and 14 from Section 2.4. 2. IBCN2 -Logistic regression on all our features (1-14) in the Twitter collections data, including scores for extended tweets and queries with collected URLs page titles. 3. IBCN3 -We only combined the best features (as estimated on the 2011 data set) in order to improve the efficiency of our search system. This was done in the following heuristic manner: we successively added one feature at a time (in order of decreasing performance for the corresponding single feature system), tested the performance on last year's topics, only retaining the added feature if performance improved (i.e., if it didn't we discarded it before continuing with the next). 4. IBCN4 -The run is the same with IBCN3, however, we ordered the top 2% tweets (that's 6.12 tweets per query on average for the 2011 relevance judgment data; 91.62 per query for the 2012 Microblog TREC) based on their recency. For training and testing our system, we applied 10-fold cross validation in which the relevance judgment data was divided into 10 parts (9 used as training and 1 as test data, and swapping the test "fold" for each of the 10 possible folds). Results were then averaged over all 10 executions. Table <ref type="table" coords="4,464.22,545.08,4.50,8.10" target="#tab_3">5</ref> shows the P@5, 10, 15 and 30 of relevance judgment data for each run. As we expected, IBCN3 outperforms the runs IBCN1 and IBCN2. However, results of IBCN4 are better than IBCN3 in P@5, 10, 15 and worse than IBCN3 in P@30. It proves that the the top relevant tweets are indeed more recent than the other tweets in the collections, although the relationship between recency and relevance remains a future topic of research. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results</head><p>Table <ref type="table" coords="5,77.38,74.85,4.50,8.10" target="#tab_4">6</ref> gives details of the P@30, R-precision and MAP for our system in response to the 2012 topics, for each run. IBCN2 outperforms the other runs, especially IBCN1 and IBCN4. This suggests that the document and query expansion, are indeed helpful in order to improve the effectiveness of the tweet ranking system. Since the recency of the tweets is not explicitly taken into account for the shown metrics, the evaluation results from IBCN4 do not match the purpose of the submitted run. Note that we only used the title field from the referred web pages, in order to extend the tweet and the original query. However, the meta descriptor tag of the web pages, as well as other elements, could have been employed as well, and is kept for future work. Also a more specific analysis as to what extent either the document expansion or the query expansion yield more to the increased effectiveness, is left for future work. The Microblog Track 2012 received 121 runs from 33 participating groups. From the overall results <ref type="bibr" coords="5,223.00,265.34,14.19,8.10" target="#b10">[15]</ref>, no participant seems to have obtained significant improvements. A major reason may be the vocabulary mismatch between original query and tweets collection, which is difficult to overcome. From these results, we suggest that document expansion needs to be included from 'external evidence' like Wikipedia, News, etc. Moreover, using expanded queries does not always give better (additional) information than the original unexpanded query. These approaches are potential ways to develop the system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSION AND FUTURE WORK</head><p>In this paper, we described our approaches to developing a search system for the Microblog Track 2012. Based on the existing system, we intend to test novel and effective approaches to improve our results in the future. We used a logistic regression classifier based on features extracted from the tweets, to predict their relevance. These tweet features describe local characteristics of the tweets, but also include ranking coefficients for the tweets, in combination with data crawled from the links provided in the tweets. In the future, we plan to investigate the influence of specific new features, and to use more advanced retrieval methods and unsupervised machine learning methods in order to capture more relevant terms in queries and topics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,222.41,307.58,167.21,8.10;2,106.46,54.00,400.74,243.72"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Overview of tweet ranking system</figDesc><graphic coords="2,106.46,54.00,400.74,243.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,409.75,419.08,114.74,8.10;3,332.35,431.08,220.63,8.10;3,332.35,442.96,225.52,8.10;3,346.75,454.84,57.64,8.10;3,332.35,466.72,225.69,8.10;3,346.75,478.60,81.45,8.10;3,332.35,490.48,225.67,8.10;3,346.75,502.48,211.33,8.10;3,346.75,514.36,38.85,8.10;3,332.35,526.24,225.76,8.10;3,346.75,538.12,155.64,8.10"><head></head><label></label><figDesc>Does tweet d contain any links? 7) hashtag (d) -binary: Does tweet d contain any hashtag? 8) retweet (d) -binary: Does tweet d repost any tweet in Twitter system? 9) text_length (d): Number of words appearing in tweet d without the title terms. 10) avetext_length (d): The average word length (i.e., number of characters) in tweet d without the title term expansion. 11) textTitle_length (d): Number of words in the expanded tweet d, i.e.,including the added title terms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,347.11,597.23,182.76,36.37"><head>Table 1 : Titles collection data</head><label>1</label><figDesc></figDesc><table coords="2,347.11,612.11,182.76,21.49"><row><cell>ave.tweets</cell><cell cols="2">ave.URLs ave.titles collected</cell></row><row><cell>1379.72</cell><cell>0.47</cell><cell>0.24</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,66.50,424.04,214.95,110.19"><head>Table 2 : Tweets collection data summary (May 2012)</head><label>2</label><figDesc></figDesc><table coords="4,85.22,438.80,171.43,95.43"><row><cell>types</cell><cell>no. elements</cell></row><row><cell>tweets status 200</cell><cell>13,762,808</cell></row><row><cell>tweets status 302</cell><cell>744,461</cell></row><row><cell>tweets status 403 and 404</cell><cell>1,621,972</cell></row><row><cell>tweets found</cell><cell>14,004,761</cell></row><row><cell>tweets null</cell><cell>2,124,480</cell></row><row><cell>English tweets</cell><cell>4,597,488</cell></row><row><cell>Total tweets corpus</cell><cell>16,129,241</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,345.91,56.17,181.91,135.03"><head>Table 3 : Tweets training data set</head><label>3</label><figDesc></figDesc><table coords="4,345.91,70.93,181.91,120.27"><row><cell cols="2">tweet types</cell><cell>no. elements</cell></row><row><cell cols="2">highly relevant (2)</cell><cell>502</cell></row><row><cell></cell><cell>relevant (1)</cell><cell>2150</cell></row><row><cell cols="2">non-relevant (0)</cell><cell>44423</cell></row><row><cell></cell><cell>spam (-2)</cell><cell>47</cell></row><row><cell cols="2">Total tweets training data</cell><cell>47122</cell></row><row><cell></cell><cell cols="2">Table 4: Titles training data</cell></row><row><cell cols="2">no.tweets ave.URLs</cell><cell>ave. titles collected</cell></row><row><cell>24467</cell><cell>0.99</cell><cell>0.69</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,338.83,643.55,198.20,72.01"><head>Table 5 : Result on 2011 relevance judgment data</head><label>5</label><figDesc></figDesc><table coords="4,342.55,656.63,189.88,58.93"><row><cell>P@5</cell><cell>P@10</cell><cell>P@15</cell><cell>P@30</cell></row><row><cell>IBCN1 0.4000</cell><cell cols="3">0.3898 0.3578 0.2959</cell></row><row><cell>IBCN2 0.4367</cell><cell cols="3">0.4041 0.3904 0.3323</cell></row><row><cell>IBCN3 0.4612</cell><cell cols="3">0.4241 0.3931 0.3558</cell></row><row><cell>IBCN4 0.4979</cell><cell cols="3">0.4388 0.3932 0.3163</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,84.50,378.66,178.84,73.71"><head>Table 6 : Result from Microblog TREC 2012</head><label>6</label><figDesc></figDesc><table coords="5,98.06,393.42,149.80,58.95"><row><cell cols="2">P@30 R_prec</cell><cell>MAP</cell></row><row><cell>IBCN1 0.1469</cell><cell>0.1585</cell><cell>0.1096</cell></row><row><cell>IBCN2 0.1904</cell><cell>0.1727</cell><cell>0.1408</cell></row><row><cell>IBCN3 0.1825</cell><cell>0.1712</cell><cell>0.1399</cell></row><row><cell>IBCN4 0.1379</cell><cell>0.1590</cell><cell>0.1190</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This research was supported by <rs type="funder">Ghent University</rs> and iMinds (the former IBBT) in Belgium. We would like thank our colleagues who kindly helped us in crawling the Twitter corpus.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,322.43,174.10,92.29,10.80" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,332.47,230.75,225.43,8.10;5,317.93,242.63,239.91,8.10;5,317.93,254.66,100.69,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,487.69,230.75,70.21,8.10;5,317.93,242.63,171.09,8.10">An Introduction to Logistic Regression Analysis and Reporting</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">M</forename><surname>Ingersoll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,498.50,242.63,59.35,8.10;5,317.93,254.66,78.14,8.10">The Journal of Educational Research</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,333.43,278.42,224.55,8.10;5,317.93,290.30,74.14,8.10;5,392.11,288.39,4.80,5.40;5,400.39,290.30,157.59,8.10;5,317.93,302.18,237.09,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,459.43,278.42,98.55,8.10;5,317.93,290.30,24.14,8.10">Relevance-based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,360.73,290.30,31.35,8.10;5,392.11,288.39,4.80,5.40;5,400.39,290.30,157.59,8.10;5,317.93,302.18,151.96,8.10">Proc. 24 th Ann. Int. ACM SIGIR Conf. on Research and Development in Information Retrieval</title>
		<meeting>24 th Ann. Int. ACM SIGIR Conf. on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,332.23,314.18,225.54,8.10;5,317.93,326.06,240.09,8.10;5,317.93,337.94,120.39,8.10;5,438.31,336.03,4.92,5.40;5,450.07,337.94,107.83,8.10;5,317.93,349.73,240.11,8.19;5,317.93,361.70,60.70,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,317.93,326.06,240.09,8.10;5,317.93,337.94,61.19,8.10">Incorporating query expansion and quality indicators in searching microblog posts</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Massoudi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tsagkias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Weerkamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,403.63,337.94,34.69,8.10;5,438.31,336.03,4.92,5.40;5,450.07,337.94,107.83,8.10;5,317.93,349.73,70.68,8.18">Proc. 33 rd Eur. Conf. on Information Retrieval, ECIR&apos;11</title>
		<meeting>33 rd Eur. Conf. on Information Retrieval, ECIR&apos;11<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="362" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,333.07,373.58,224.91,8.10;5,317.93,385.58,240.29,8.10;5,317.93,397.46,38.31,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,428.47,373.58,129.51,8.10;5,317.93,385.58,78.71,8.10">Evaluation of an interence networkbased retrieval model</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,404.74,385.58,111.73,8.10">ACM Trans. Information Sys</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="187" to="222" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,334.27,409.34,223.45,8.10;5,317.93,421.24,240.09,8.10" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="5,375.86,409.34,181.86,8.10;5,317.93,421.24,154.74,8.10">Introduction to Fuzzy Systems, Neural Networks, and Genetic Algorithms. Intelligent System</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Takaki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="1" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,335.94,433.12,221.98,8.10;5,317.93,445.12,240.03,8.10;5,317.93,457.00,84.09,8.10;5,402.19,455.09,5.88,5.40;5,413.95,457.00,144.04,8.10;5,317.93,468.88,58.23,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,421.51,445.12,136.45,8.10;5,317.93,457.00,27.26,8.10">Learning to Rank using Gradient Descent</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Renshaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lazier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Deeds</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hullender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,368.40,457.00,33.62,8.10;5,402.19,455.09,5.88,5.40;5,413.95,457.00,112.51,8.10">Proc. 22 nd Int. Conf. Machine Learning</title>
		<meeting>22 nd Int. Conf. Machine Learning<address><addrLine>Bonn, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.43,480.76,221.51,8.10;5,317.93,492.64,135.21,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,480.22,480.76,77.72,8.10;5,317.93,492.64,58.05,8.10">Adding Semantics to Microblog Posts</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Weerkamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,381.60,492.64,49.01,8.10">Proc. WSDM</title>
		<meeting>WSDM</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,335.35,516.52,210.50,8.10;5,317.93,528.40,231.05,8.10;5,317.93,540.28,121.76,8.10" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,481.06,516.52,64.79,8.10;5,317.93,528.40,111.80,8.10">What is Twitter, a social network or a news media</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Moon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,436.04,528.40,41.66,8.10">Proc. WWW</title>
		<meeting>WWW<address><addrLine>North Carolina, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="591" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,335.47,552.16,222.37,8.10;5,317.93,564.04,169.44,8.10" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,482.02,552.16,75.82,8.10;5,317.93,564.04,75.88,8.10">Ranking Approaches for Microblog Search</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nagmoti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Teredesai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">De</forename><surname>Cock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,399.80,564.04,83.19,8.10">Proc. ACM WI-IAT&apos;10</title>
		<meeting>ACM WI-IAT&apos;10</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,335.90,576.04,221.92,8.10;5,317.93,587.95,240.23,8.10;5,192.38,613.31,227.25,8.53;5,87.50,627.79,22.46,8.10;5,332.95,627.79,35.36,8.10;5,59.64,641.47,71.35,8.10;5,297.89,640.51,105.43,8.10;5,59.64,654.07,69.23,8.10;5,247.01,653.23,207.02,8.10;5,59.64,667.51,75.20,8.10;5,208.37,666.19,284.66,8.10;5,59.64,680.95,74.66,8.10;5,271.61,679.75,158.03,8.10;5,59.64,693.67,70.62,8.10;5,241.13,692.71,218.75,8.10;5,59.64,707.11,73.76,8.10;5,188.90,705.79,323.44,8.10" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,498.31,576.04,59.52,8.10;5,317.93,587.95,123.04,8.10;5,112.28,667.51,22.56,8.10;5,208.37,666.19,267.72,8.10">1A Expatriate Tax Senior Director job BDO USA LLP New York NY Indeed</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://bit.ly/euZXzGbestarticlepublisherlisting" />
	</analytic>
	<monogr>
		<title level="m" coord="5,474.07,587.95,84.09,8.10;5,192.38,613.31,227.25,8.53;5,87.50,627.79,22.46,8.10;5,332.95,627.79,18.03,8.10;5,297.89,640.51,105.43,8.10;5,108.10,654.07,20.77,8.10;5,247.01,653.23,207.02,8.10;5,271.61,679.75,101.43,8.10;5,241.13,692.71,218.75,8.10">Proc. TREC 2011. Table 7: Examples of crawled page titles in Twitter data URLs Title</title>
		<meeting>TREC 2011. Table 7: Examples of crawled page titles in Twitter data URLs Title</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>State of Green Business 2011 MNN Mother Nature Network. info The Leading Best Article Publisher Listing Site on the Net</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
