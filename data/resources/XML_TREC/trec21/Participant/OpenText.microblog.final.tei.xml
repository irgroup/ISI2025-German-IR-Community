<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,98.68,112.00,414.63,15.15;1,155.09,133.91,301.83,15.15">Measuring Robustness with First Relevant Score in the TREC 2012 Microblog Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013-02-03">February 3, 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,264.32,167.81,83.35,8.74"><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
							<email>stomlins@opentext.com</email>
							<affiliation key="aff0">
								<address>
									<settlement>Ottawa</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,98.68,112.00,414.63,15.15;1,155.09,133.91,301.83,15.15">Measuring Robustness with First Relevant Score in the TREC 2012 Microblog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2013-02-03">February 3, 2013</date>
						</imprint>
					</monogr>
					<idno type="MD5">1742A0DAA9FB9F679EE1AFF0DAF93CF4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we measure the effectiveness of various experimental search techniques not just with traditional TREC ad hoc search measures such as Average Precision, R-precision and Precision@30, but also with robust measures based on just the rank of the first relevant item retrieved such as First Relevant Score and Generalized Success@30. We report the results of our experiments conducted in the context of the Real-Time Adhoc Search Task of the TREC 2012 Microblog Track which investigated the effectiveness of ad hoc search of a collection of more than 10 million tweets. For the experimental technique of favoring tweets with urls, we found that both the traditional and robust measures indicated statistically significant increases in the mean score. However, for an experimental blind feedback technique, a technique known to be non-robust as it typically makes poor results even worse, the traditional Average Precision measure indicated a statistically significant increase in the mean score, but some of the measures just based on the rank of the first relevant item successfully discerned a statistically significant decrease in the mean score from the non-robust technique.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>OpenText Search Server R , eDOCS Edition (formerly known as Open Text eDOCS SearchServer TM ) is a toolkit for developing enterprise search and retrieval applications. The eDOCS SearchServer kernel is also embedded in various components of the OpenText eDOCS Suite <ref type="foot" coords="1,352.89,497.10,3.97,6.12" target="#foot_0">1</ref> .</p><p>The eDOCS SearchServer kernel works in Unicode internally <ref type="bibr" coords="1,354.11,510.63,10.52,8.74" target="#b1">[2]</ref> and supports most of the world's major character sets and languages. The major conferences in text retrieval experimentation (TREC <ref type="bibr" coords="1,483.38,522.58,9.96,8.74" target="#b4">[5]</ref>, CLEF <ref type="bibr" coords="1,529.48,522.58,10.52,8.74" target="#b0">[1]</ref> and NTCIR <ref type="bibr" coords="1,128.07,534.54,10.79,8.74" target="#b2">[3]</ref>) have provided judged test collections for objective experimentation with the SearchServer kernel in more than a dozen languages.</p><p>This paper describes experimental work with the eDOCS SearchServer kernel (experimental post-6.0 builds) conducted in part by participating in the Real-time Adhoc Search Task of the TREC 2012 Microblog Track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Real-Time Adhoc Search Task</head><p>The Real-Time Adhoc Search Task of the TREC 2012 Microblog Track was, given a short query at a particular time, to produce a ranked list of the most relevant tweets in the "Tweets2011" corpus prior to that time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Downloading the Tweets2011 Corpus</head><p>While the Tweets2011 corpus ostensibly consisted of 16,141,812 tweets (sampled from Twitter during the 2-week period of Jan 24-Feb 8, 2011), only 10,624,958 of the tweets were eligible this year (based on the number that NIST successfully downloaded with http status 200 in their 2012 crawl, as listed in the "idstatus.01-May-2012" file that NIST provided).</p><p>Furthermore, each participant had to download the tweets themselves from twitter.com, one at a time, based on the given list of 16,141,812 urls. The availability of tweets could change over time (such as from users deleting tweets, or a timeout occurring while attempting to download a tweet), hence each participant likely had a different subset of the corpus.</p><p>While many of the track participants had downloaded the corpus last year, we had not, and we did not decide to participate in the Microblog track this year until shortly after May 10, 2012 when the Legal Track suddenly announced it was not running this year.</p><p>There were many adventures attempting to download the collection which were documented on the track mailing list at the time. Apparently the html pages on twitter.com became much larger (approx May 2012) compared to last year, to approx 89,000 bytes per html page (with just 1 tweet, famously known to be at most 140 characters, scraped per page), which caused the provided download tool to fail from a writeUTF() 64KB limit, and increased the download footprint over the wire to approximately a terabyte. A track participant, Myle Ott, was particularly heroic at fixing the open-source download tool to deal with the html format changes, and also reducing its memory usage, reducing its disk space footprint while increasing the richness of the downloaded information, increasing its speed, and adding the capability to follow redirected tweets.</p><p>We performed our download from June 17-29, 2012, using Myle Ott's enhanced crawler "AsyncEmbeddedJsonStatusBlockCrawler" of myleott-twitter-corpus-tools-c254443.zip from https://github.com/myleott/twitter-corpus-tools . The downloading was just done during off hours (overnight and weekends).</p><p>We downloaded the urls in random order so any glitches during the download process (e.g., web server rejecting requests for a few minutes) should be spread over the collection rather than clustered to particular tweet time periods.</p><p>In our first download pass (June 17-23, 2012), we used the crawler's -noFollow option (which did not follow http status 301 redirects), and it downloaded 11,218,704 tweets successfully, including 10,296,356 of the previously mentioned eligible 10,624,958 tweets (though it was not announced until July 3, 2012 that the eligible list was just the 10,624,958 tweets of status 200 in the NIST download, so we thought we might be missing more of the eligible tweets).</p><p>In our second (and final) pass (June 24-29, 2012), we re-attempted to download the 4,923,108 tweets missing after the first pass, and we did not use the -noFollow option (so that the crawler would follow http status 301 redirects, which again, we did not know were ineligible until July 3, 2012).</p><p>We ended up downloading 13,551,650 tweets in total, including 10,414,471 of the previously mentioned eligible 10,624,958 tweets (98.0%). (Also, compared to the NIST id-status.01-May-2012 list, we successfully downloaded 2,198,005 of the 3,015,117 tweets it labelled status 301 (redirected), 787,723 of the 815,794 tweets it labelled status 302 (retweet), 130,326 of the 817,273 tweets it labelled status 403 (forbidden), 21,125 of the 868,667 tweets it labelled status 404 (not found), and 0 of the 3 tweets it did not label.)</p><p>Cross-checking against last year's relevance assessments (qrels), our download included 94% of the tweets judged relevant in at least 1 topic (2778 of 2965), including 94% of the tweets judged highly relevant in at least 1 topic (530 of 561). Hence we had ample coverage of last year's relevance assessments for doing training experiments.</p><p>As a later followup, when the relevance assessments (qrels) for the 2012 task were received on August 31, 2012, it turned out that our download included 99.49% of the tweets judged relevant in at least topic (6233 of 6265), including 99.53% of the tweets judged highly relevant in at least topic (2549 of 2561).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Indexing</head><p>We indexed the 13,551,650 downloaded tweets as follows.</p><p>First, we reformatted the tweets to the XML format of the IIT CDIP collection used in the Legal Track in 2006-2009 so that we could re-use essentially the same indexing scripts.</p><p>While the downloaded tweets in .json format had a lot of detailed information, e.g., how many followers the author had, the only information we wrote out in our XML version was the tweet itself (e.g., "BBC News -BBC World Service cuts to be outlined to staff http://www.bbc.co.uk/news/entertainment-arts-12283356"), the tweet author (e.g., "ashstreetltd") and the tweet id (e.g., "30198105513140224").</p><p>In particular, for each tweet, we added a "&lt;record&gt;" tag at the beginning, followed by the tweet id inside "&lt;tid&gt;..&lt;/tid&gt;" tags (a 17-digit number ranging from 28965131362770944 to 35123253429284864), followed by the first 2 digits of the tweet id inside "&lt;DD&gt;..&lt;/DD&gt;" tags (a 2-digit number ranging from 28 to 35), followed by the tweet author userid inside "&lt;BX&gt;..&lt;/BX&gt;" tags, followed by the tweet (which seemed to already be in XML-safe form, i.e., it used &amp;lt; and &amp;gt; instead of &lt; and &gt;, though it did not escape the ampersand to &amp;amp;, but the ampersand handling seemed unlikely to matter for our purpose), followed by a closing "&lt;/record&gt;" tag. We ended up with 212 .xml files totalling 2,123,389,692 bytes.</p><p>Our indexing script, for each record, indexed from the "&lt;/tid&gt;" tag to the "&lt;/record&gt;" tag. Any tags themselves were indexed (we just didn't bother to discard them; a minor side effect is that this meant the term "record" matched every document). Entities (e.g. "&amp;gt;") were converted back to the character they represented (e.g. "&gt;").</p><p>This year we used an English stopword list of 86 words to not index (e.g., "the", "of", etc.). We indexed 4 punctuation characters as 1-character words (#, $, %, @). The apostrophe was considered a word separator. The index supported both searching on just the surface forms of the words and also searching on inflections from English lexical stemming. The documents were assumed to be in the UTF-8 character set. Words were normalized to upper-case and any accents were dropped.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Searching</head><p>The track organizers created 60 test topics numbered 51 to 110, each including a short query and the querytweettime. Participants could submit up to 4 runs listing the top-10,000 tweets scored by relevance for each topic. Submissions were due July 10, 2012. The experimental techniques used for our 4 submitted runs (plus one other unsubmitted run produced at the time) are described below.</p><p>For reference, here are the codes used in the run names (explained in more detail below): 'i' indicates "uses full-collection idf"; 'h' indicates "added HTTP to query"; 'e0' indicates "uses blind feedback based on first-30 (non-future) retrieved"; 'e' indicates "50% blind feedback, 50% ih".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Baseline Run -otM12i</head><p>The submitted run 'otM12i' was produced as follows.</p><p>The run just searched for tweets matching a Boolean-OR of the query words or their English inflections by passing the query to the SearchServer IS ABOUT predicate.</p><p>The SearchServer '2:3' relevance method was the same as described in previous years <ref type="bibr" coords="3,477.52,560.66,14.61,8.74" target="#b9">[10]</ref>. The relevance function dampened the term frequency and adjusted for document length in a manner similar to Okapi <ref type="bibr" coords="3,101.63,584.57,10.52,8.74" target="#b3">[4]</ref> and dampened the inverse document frequency using an approximation of the logarithm. (SET RELEVANCE DLEN IMP 750 was used for document length importance.) In runs which used inflectional matching (which was the case for all the runs this year), these calculations were based on the stems of the terms.</p><p>To remove at least some of the tweets from after the "querytweettime" given in the topic, a Boolean-AND was also in the query (with relevance weight 0) based on the DOCDATE field (which corresponded to the "DD" field in the XML format described earlier).</p><p>For example, for topic 71, for which the query was "Australian Open Djokovic vs. Murray" and querytweettime was "31692185296441344", the SearchSQL query was as follows:</p><p>SELECT RELEVANCE('2:3') AS REL, DOCNO, FT_CID FROM TW12 WHERE ((FT_TEXT IS_ABOUT 'Australian Open Djokovic vs. Murray') AND (DOCDATE CONTAINS '28' WEIGHT 0|'29' WEIGHT 0|'30' WEIGHT 0|'31' WEIGHT 0)) ORDER BY REL DESC;</p><p>From this first-pass query, the top 100,000 matches (based on the relevance function) were retrieved (or all the matches if there fewer than 100,000).</p><p>As a second pass, a Java program was run on these (up to) 100,000 matches to remove the remaining tweets whose id was after the querytweettime.</p><p>As a third pass, another Java program was run to remove tweets which were not eligible because they were not listed as http status 200 in the previously mentioned organizer-provided "id-status.01-May-2012" file. Also in this pass, tweets starting with "RT" were discarded because "retweets" were also considered non-relevant by the task guidelines.</p><p>On the fourth and final pass, another Java program was run to just keep the first 10,000 remaining matches (or all the remaining matches if there were fewer than 10,000). There was also some other formatting for the official submission in this pass, e.g., remove the rank column that was not wanted this year.</p><p>There was also a post-hoc check that if a query ended up with fewer than the desired 10,000 matches, it was not the case that the first-pass heuristic of cutting off at 100,000 had filtered out some possible matches. (Otherwise we would have redone the run with a larger number in the first step.)</p><p>This run was labelled as using "future evidence" only because the inverse document frequency (idf) of each term was based on the term's frequency in the entire collection rather than just the tweets up to the given querytweettime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">HTTP Run -otM12ih</head><p>The submitted run 'otM12ih' was produced in the same way as the baseline run otM12i except that the word "http" was added to each query.</p><p>The motivation for doing so was that we had observed in the relevance assessments (qrels) of 2011, after crossing them with our download of the tweets, that a surprising 95% of the (downloaded) tweets judged highly relevant in at least one topic (503 of 530) included the string "http:", indicating that the highly relevant tweet referenced a web page via a url.</p><p>Also, 78% of the other (downloaded) tweets judged relevant in at least one topic (1753 of 2248) included the string "http:".</p><p>However, 52% of the remaining (downloaded) tweets that were judged in at least one topic (25205 of 48822) also included the string "http:" (these were tweets that were always judged non-relevant, though that they were judged likely means that some participant system last year gave a high rank to the tweet for at least one topic).</p><p>Overall, 18% of the entire (downloaded) collection of tweets contained the word "http" (2,419,519 of 13,551,650).</p><p>In our training experiments with last year's topics, adding the word "http" gave a modest boost to most of the evaluation metrics.</p><p>When "http" was added to the query, every query (even after all the time and eligibility filters) returned at least 10,000 tweets, unlike the baseline query.</p><p>Note that we did not ever download the web pages referred to by the tweets. (None of our runs used "external evidence" from outside the Tweets2011 corpus.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">No-IDF Run -otM12h</head><p>The submitted run 'otM12h' was produced in the same way as the "http" run otM12ih except that inverse document frequency (idf) was not used to weight the query terms. All query terms were given equal weight by specifying the SearchServer '2:5' relevance method instead of '2:3'. The task guidelines requested that at least one submitted run "not use any external or future source of evidence". This run satisfied that criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.4">Blind Feedback Run -otM12ihe</head><p>The submitted run 'otM12ihe' was a blind feedback run based 50% on otM12ih and 50% on an expansion query based on the first 30 pre-querytweettime tweets in the second-pass result of otM12ih. Some notes: Our feedback set excluded not just tweets after the querytweettime, but also the tweet of exactly the querytweettime (if it would have otherwise been in the top-30) because the guidelines originally disallowed this tweet. The organizers decided to allow this tweet on July 9, 2012 (the day before submissions were due) because the perl checker for submissions had accidentally been allowing it. We did not redo our feedback run at this time other than to not filter the querytweettime tweet from the final result.</p><p>Our feedback set included retweets and the tweets of non-200 status (likely from status 301 redirects). It's unclear whether keeping these in the feedback set was helpful or detrimental compared to filtering them out; we haven't done any experiments on this point.</p><p>Roughly speaking, the expansion query appended together the 30 tweets and filtered out the terms in more than 5% of the tweets in the full collection. It kept the remaining top-200 terms (based on stems actually) in a tf.idf calculation.</p><p>The result of the expansion query was saved in an (unsubmitted) run called otM12ihe0. The final otM12ihe run was a fusion run based 50% on the base otM12ih run and 50% on the otM12ihe0 expansion run (based on the relevance() function score). This run was labelled as using "future evidence" only because the inverse document frequency (idf) of each term was based on the term's frequency in the entire collection rather than just the tweets up to the given querytweettime. No other future evidence was used; in particular, as already noted, the feedback set did not include any tweets from after the querytweettime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>The track organizers released the relevance assessments (qrels) on August 31, 2012.</p><p>59 of the topics had at least one tweet judged relevant, averaging 106.5 relevant tweets per topic (ranging from as low as 1 relevant tweet for a topic to as high as 572). 56 of the topics had at least one tweet judged highly relevant, averaging 45.9 highly relevant tweets per topic (ranging from 1 to 322).</p><p>Table <ref type="table" coords="7,115.29,597.69,4.98,8.74" target="#tab_0">1</ref> lists the mean scores of the previously described 4 submitted runs and 1 additional run. (A glossary with the definitions of the measures is in Section 4.1.) We see that the robust measures, such as FRS and GS30, find that the plain word+http run (otM12ih) has a higher score than the blind feedback runs (otM12ihe and otM12ihe0). However, the non-robust traditional TREC measures, such as MAP, R-prec and P30, favor the non-robust blind feedback runs. All of the measures agree that adding the word 'http' to the query increased the mean score (otM12ih vs. otM12i).</p><p>Tables <ref type="table" coords="7,118.27,669.42,4.98,8.74" target="#tab_1">2</ref> and<ref type="table" coords="7,145.95,669.42,4.98,8.74" target="#tab_2">3</ref> isolate the differences between runs in more detail as explained in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Impact of Adding HTTP to Query</head><p>The 'h' lines (otM12ih score minus otM12i score) of Tables <ref type="table" coords="8,336.33,96.98,4.98,8.74" target="#tab_1">2</ref> and<ref type="table" coords="8,364.72,96.98,4.98,8.74" target="#tab_2">3</ref> show that adding "http" to the query produced a statistically significant increase in the mean scores of both traditional TREC measures (P30, R-prec, GMAP', MAP, HP30, HP@R, HGMAP', HMAP) and some robust measures (HFRS, HMRR).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Impact of Inverse Document Frequency</head><p>The 'i' lines (otM12ih score minus otM12h score) of Tables <ref type="table" coords="8,322.97,169.68,4.98,8.74" target="#tab_1">2</ref> and<ref type="table" coords="8,348.68,169.68,4.98,8.74" target="#tab_2">3</ref> show that using full-collection idf produced a statistically significant increase in the mean scores of some of the traditional TREC measures (P30, R-prec, MAP, HMAP), but none of the robust measures were able to discern a statistically significant impact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Impact of Blind Feedback</head><p>The 'e' lines (otM12ihe score minus otM12ih score) of Tables <ref type="table" coords="8,336.79,242.38,4.98,8.74" target="#tab_1">2</ref> and<ref type="table" coords="8,363.51,242.38,4.98,8.74" target="#tab_2">3</ref> show that the blind feedback technique produced a statistically significant increase in the mean scores of some of the traditional TREC measures (MAP, HP@R, HMAP), but a statistically significant decrease in the mean score of one of the robust measures (GS30).</p><p>We have seen this result before not just in our own experiments but in 7 other groups' blind feedback experiments at the 2003 RIA Workshop <ref type="bibr" coords="8,248.87,302.15,9.96,8.74" target="#b6">[7]</ref>.</p><p>More background on robust retrieval: The objective of robust retrieval <ref type="bibr" coords="8,397.68,314.11,15.50,8.74" target="#b10">[11]</ref> is to reduce the frequency of very poor results. The blind feedback technique is considered non-robust because of its tendency to "not help (and frequently hurt) the worst performing topics" <ref type="bibr" coords="8,298.55,338.02,14.61,8.74" target="#b10">[11]</ref>. Success@10 (S10) has been suggested as a "direct measure" of robustness, but it "has the drawback of being a very coarse measure" <ref type="bibr" coords="8,431.10,349.97,14.61,8.74" target="#b10">[11]</ref>. We have introduced less coarse variants such as "First Relevant Score" <ref type="bibr" coords="8,290.79,361.93,10.52,8.74" target="#b8">[9]</ref> and "Generalized Success@30" <ref type="bibr" coords="8,439.57,361.93,10.52,8.74" target="#b5">[6]</ref> and have found that they often can discern statistically significant negative impacts from the non-robust blind feedback technique <ref type="bibr" coords="8,72.00,385.84,9.96,8.74" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Glossary</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Retrieval Measures</head><p>This section states the definition of all of the retrieval measures of Table <ref type="table" coords="8,392.05,456.45,3.87,8.74" target="#tab_0">1</ref>.</p><p>Robust measures -these measures are based just on the rank of the first relevant item retrieved:</p><p>• Success@n (S@n): For a topic, Success@n is 1 if a relevant item is retrieved in the first n rows, 0 otherwise. This paper lists Success@10 (S10) and Success@1 (S1) for all runs.</p><p>• First Relevant Score (FRS): For a topic, FRS is 1.08 1-r where r is the rank of the first row for which a relevant item is found, or zero if a relevant item was not found. This measure was introduced in <ref type="bibr" coords="8,526.72,546.11,9.96,8.74" target="#b8">[9]</ref>. The measure is also known as Generalized Success@10 (GS10) because it rounds to 1 for r≤10 and to 0 for r&gt;10. Intuitively, FRS is approximately the percentage of topics for which a relevant item is returned in the first 10 rows.</p><p>• Generalized Success@30 (GS30): For a topic, GS30 is 1.024 1-r where r is the rank of the first row for which a relevant item is found, or zero if a relevant item was not found. Compared to FRS, GS30 further de-emphasizes small differences at the top of the result list.</p><p>• Reciprocal Rank (RR): For a topic, RR is 1 r where r is the rank of the first row for which a relevant item is found, or zero if a relevant item was not found. "Mean Reciprocal Rank" (MRR) is the mean of the reciprocal ranks over all the topics.</p><p>Traditional TREC ad hoc search measures -these measures place most of their weight on additional relevant items for a topic (after the first one):</p><p>• Precision@n: For a topic, "precision" is the percentage of retrieved items which are relevant. "Precision@n" is the precision after n items have been retrieved. This paper lists Precision@30 (P30) for all runs.</p><p>• Average Precision (AP): For a topic, AP is the average of the precision after each relevant item is retrieved (using zero as the precision for relevant items which are not retrieved). By convention, AP is based on the first 1000 retrieved items for the topic. The score ranges from 0.0 (no relevant items retrieved) to 1.0 (all relevant items retrieved at the top of the list). "Mean Average Precision" (MAP) is the mean of the average precision scores over all of the topics (i.e. all topics are weighted equally).</p><p>• R-Precision (R-prec): For a topic, R-precision is Precision@R where R is the number of relevant items for the topic. It is also equivalent to Recall@R where "recall" is the percentage of relevant items retrieved.</p><p>• Geometric MAP (GMAP): GMAP (introduced in <ref type="bibr" coords="9,316.25,264.45,15.50,8.74" target="#b11">[12]</ref>) is based on "Log Average Precision" which for a topic is the natural log of the max of 0.00001 and the average precision. GMAP is the exponential of the mean log average precision.</p><p>• GMAP' : We also define a linearized log average precision measure (denoted GMAP') which linearly maps the 'log average precision' values to the [0,1] interval. For statistical significance purposes, GMAP' gives the same results as GMAP, and it has advantages such as that the individual topic differences are in the familiar -1.0 to 1.0 range and are on the same scale as the mean.</p><p>If a J suffix is appended to the measure code, the measure is just evaluated using judged items (as if unjudged items were not retrieved). In particular, GS30J, FRSJ, S10J, MRRJ, S1J, P30J, R-precJ, GMAPJ and MAPJ are the same as GS30, FRS, S10, MRR, S1, P30, R-prec, GMAP and MAP (respectively) except that only judged items are considered.</p><p>If a H prefix is affixed to the measure code, the measure is just evaluated counting highly relevant items as relevant. In particular, HGS30, HFRS, HS10, HMRR, HS1, HP30, HP@R, HGMAP and HMAP are the same as GS30, FRS, S10, MRR, S1, P30, R-prec, GMAP and MAP (respectively) except that only highly relevant items are counted as relevant.</p><p>The measures were calculated using the l07 eval utility (which is available at http://trec.nist.gov/data/legal09.html ). The scores may differ from trec eval because l07 eval discards topics with no relevant documents (e.g., the H measures are averaged over just the 56 applicable topics, not 60) and l07 eval does no re-ordering of documents tied in rsv score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Difference Tables</head><p>For the comparison tables (i.e., Tables <ref type="table" coords="9,242.55,546.36,4.98,8.74" target="#tab_1">2</ref> and<ref type="table" coords="9,270.23,546.36,3.87,8.74" target="#tab_2">3</ref>), the columns are as follows:</p><p>• "Expt" specifies the experiment (the codes of the two runs being compared are listed, indicating first run minus second run).</p><p>• "∆" is the difference of the mean scores of the two runs being compared (the column heading says for which retrieval measure).</p><p>• "95% Conf" is an approximate 95% confidence interval for the mean difference (calculated from plus/minus twice the standard error of the mean difference). If zero is not in the interval, the result is "statistically significant" (at the 5% level).</p><p>• "vs." is the number of topics on which the first run scored higher, lower and tied (respectively) compared to the second run. These numbers should always add to the number of topics.</p><p>• "3 Extreme Diffs (Topic)" lists 3 of the individual topic differences, each followed by the topic number in brackets. The first difference is the largest one of any topic (based on the absolute value). The third difference is the largest difference in the other direction (so the first and third differences give the range of differences observed in this experiment). The middle difference is the largest of the remaining differences (based on the absolute value).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we measured the effectiveness of various experimental search techniques not just with traditional TREC ad hoc search measures such as Average Precision, R-precision and Precision@30, but also with robust measures based on just the rank of the first relevant item retrieved such as First Relevant Score and Generalized Success@30. We reported not just the mean scores of the experimental approaches but also the largest per-topic impacts of the techniques for several measures. Our experiments were conducted in the context of the Real-Time Adhoc Search Task of the TREC 2012 Microblog Track which investigated the effectiveness of ad hoc search of a collection of more than 10 million tweets. For the experimental technique of favoring tweets with urls, we found that both the traditional and robust measures indicated statistically significant increases in the mean score. However, for an experimental blind feedback technique, a technique known to be non-robust as it typically makes poor results even worse, the traditional Average Precision measure indicated a statistically significant increase in the mean score, but some of the measures just based on the rank of the first relevant item successfully discerned a statistically significant decrease in the mean score from the non-robust technique. We continue to advocate that researchers investigate the impacts of search techniques on the rank of the first relevant item.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,79.85,82.08,452.31,314.93"><head>Table 1 :</head><label>1</label><figDesc>Mean Scores of Submitted Microblog Adhoc Search Runs</figDesc><table coords="5,79.85,96.77,452.31,300.24"><row><cell>Run</cell><cell>GS30</cell><cell>FRS</cell><cell>S10</cell><cell>MRR</cell><cell>S1</cell><cell>P30</cell><cell>R-prec</cell><cell>GMAP</cell><cell>MAP</cell></row><row><cell>otM12h</cell><cell>0.925</cell><cell>0.854</cell><cell>53/59</cell><cell>0.660</cell><cell>31/59</cell><cell>0.375</cell><cell>0.286</cell><cell>0.128</cell><cell>0.231</cell></row><row><cell>otM12i</cell><cell>0.910</cell><cell>0.831</cell><cell>52/59</cell><cell>0.641</cell><cell>30/59</cell><cell>0.377</cell><cell>0.294</cell><cell>0.142</cell><cell>0.250</cell></row><row><cell>otM12ih</cell><cell>0.923</cell><cell>0.856</cell><cell>53/59</cell><cell>0.685</cell><cell>33/59</cell><cell>0.397</cell><cell>0.324</cell><cell>0.164</cell><cell>0.278</cell></row><row><cell>otM12ihe</cell><cell>0.891</cell><cell>0.811</cell><cell>48/59</cell><cell>0.662</cell><cell>33/59</cell><cell>0.411</cell><cell>0.326</cell><cell>0.158</cell><cell>0.299</cell></row><row><cell>(otM12ihe0)</cell><cell>0.855</cell><cell>0.768</cell><cell>46/59</cell><cell>0.617</cell><cell>31/59</cell><cell>0.411</cell><cell>0.317</cell><cell>0.117</cell><cell>0.288</cell></row><row><cell>[on judged]</cell><cell>GS30J</cell><cell>FRSJ</cell><cell>S10J</cell><cell>MRRJ</cell><cell>S1J</cell><cell>P30J</cell><cell cols="3">R-precJ GMAPJ MAPJ</cell></row><row><cell>otM12h</cell><cell>0.925</cell><cell>0.854</cell><cell>53/59</cell><cell>0.660</cell><cell>31/59</cell><cell>0.375</cell><cell>0.295</cell><cell>0.174</cell><cell>0.269</cell></row><row><cell>otM12i</cell><cell>0.910</cell><cell>0.831</cell><cell>52/59</cell><cell>0.642</cell><cell>30/59</cell><cell>0.377</cell><cell>0.302</cell><cell>0.186</cell><cell>0.281</cell></row><row><cell>otM12ih</cell><cell>0.923</cell><cell>0.856</cell><cell>53/59</cell><cell>0.685</cell><cell>33/59</cell><cell>0.397</cell><cell>0.327</cell><cell>0.214</cell><cell>0.307</cell></row><row><cell>otM12ihe</cell><cell>0.891</cell><cell>0.811</cell><cell>48/59</cell><cell>0.662</cell><cell>33/59</cell><cell>0.411</cell><cell>0.331</cell><cell>0.204</cell><cell>0.329</cell></row><row><cell>(otM12ihe0)</cell><cell>0.855</cell><cell>0.768</cell><cell>46/59</cell><cell>0.617</cell><cell>31/59</cell><cell>0.411</cell><cell>0.325</cell><cell>0.172</cell><cell>0.324</cell></row><row><cell>[highly rel]</cell><cell cols="2">HGS30 HFRS</cell><cell>HS10</cell><cell>HMRR</cell><cell>HS1</cell><cell>HP30</cell><cell cols="3">HP@R HGMAP HMAP</cell></row><row><cell>otM12h</cell><cell>0.793</cell><cell>0.695</cell><cell>41/56</cell><cell>0.494</cell><cell>21/56</cell><cell>0.225</cell><cell>0.229</cell><cell>0.083</cell><cell>0.200</cell></row><row><cell>otM12i</cell><cell>0.794</cell><cell>0.661</cell><cell>39/56</cell><cell>0.423</cell><cell>16/56</cell><cell>0.207</cell><cell>0.208</cell><cell>0.083</cell><cell>0.181</cell></row><row><cell>otM12ih</cell><cell>0.811</cell><cell>0.700</cell><cell>42/56</cell><cell>0.493</cell><cell>21/56</cell><cell>0.232</cell><cell>0.225</cell><cell>0.105</cell><cell>0.214</cell></row><row><cell>otM12ihe</cell><cell>0.787</cell><cell>0.676</cell><cell>39/56</cell><cell>0.486</cell><cell>21/56</cell><cell>0.243</cell><cell>0.248</cell><cell>0.094</cell><cell>0.238</cell></row><row><cell>(otM12ihe0)</cell><cell>0.759</cell><cell>0.645</cell><cell>38/56</cell><cell>0.448</cell><cell>19/56</cell><cell>0.247</cell><cell>0.246</cell><cell>0.067</cell><cell>0.227</cell></row><row><cell>[on judged h]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>otM12h</cell><cell>0.794</cell><cell>0.695</cell><cell>41/56</cell><cell>0.494</cell><cell>21/56</cell><cell>0.225</cell><cell>0.231</cell><cell>0.113</cell><cell>0.216</cell></row><row><cell>otM12i</cell><cell>0.794</cell><cell>0.661</cell><cell>39/56</cell><cell>0.424</cell><cell>16/56</cell><cell>0.207</cell><cell>0.209</cell><cell>0.106</cell><cell>0.192</cell></row><row><cell>otM12ih</cell><cell>0.811</cell><cell>0.700</cell><cell>42/56</cell><cell>0.493</cell><cell>21/56</cell><cell>0.232</cell><cell>0.226</cell><cell>0.129</cell><cell>0.225</cell></row><row><cell>otM12ihe</cell><cell>0.787</cell><cell>0.676</cell><cell>39/56</cell><cell>0.486</cell><cell>21/56</cell><cell>0.243</cell><cell>0.249</cell><cell>0.123</cell><cell>0.249</cell></row><row><cell>(otM12ihe0)</cell><cell>0.764</cell><cell>0.645</cell><cell>38/56</cell><cell>0.448</cell><cell>19/56</cell><cell>0.247</cell><cell>0.248</cell><cell>0.102</cell><cell>0.240</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,101.00,82.08,410.01,456.60"><head>Table 2 :</head><label>2</label><figDesc>Impact of Microblog Adhoc Search Techniques on Measures counting All Relevant</figDesc><table coords="6,101.00,96.77,410.01,441.91"><row><cell>Expt</cell><cell>∆GS30</cell><cell>95% Conf</cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>e (ihe-ih)</cell><cell>-0.032</cell><cell>(-0.061,-0.004)</cell><cell>12-17-30</cell><cell>-0.47 (58), -0.41 (105), 0.15 (82)</cell></row><row><cell>h (ih-i)</cell><cell>0.013</cell><cell>(-0.003, 0.028)</cell><cell>12-5-42</cell><cell>0.23 (77), 0.18 (51), -0.19 (72)</cell></row><row><cell>i (ih-h)</cell><cell>-0.002</cell><cell>(-0.019, 0.014)</cell><cell>9-9-41</cell><cell>0.27 (72), -0.20 (53), -0.25 (51)</cell></row><row><cell>e0 (ihe0-ih)</cell><cell>-0.068</cell><cell>(-0.117,-0.019)</cell><cell>12-22-25</cell><cell>-1.00 (80), -0.63 (61), 0.15 (82)</cell></row><row><cell></cell><cell>∆FRS</cell><cell></cell><cell></cell><cell></cell></row><row><cell>e (ihe-ih)</cell><cell>-0.044</cell><cell>(-0.095, 0.006)</cell><cell>12-17-30</cell><cell>-0.60 (80), -0.60 (61), 0.42 (82)</cell></row><row><cell>h (ih-i)</cell><cell>0.024</cell><cell>(-0.007, 0.055)</cell><cell>12-5-42</cell><cell>0.44 (77), 0.43 (107), -0.33 (72)</cell></row><row><cell>i (ih-h)</cell><cell>0.002</cell><cell>(-0.020, 0.023)</cell><cell>9-9-41</cell><cell>0.27 (99), -0.21 (54), -0.24 (51)</cell></row><row><cell>e0 (ihe0-ih)</cell><cell>-0.088</cell><cell>(-0.158,-0.018)</cell><cell>12-22-25</cell><cell>-1.00 (80), -0.96 (61), 0.42 (82)</cell></row><row><cell></cell><cell>∆MRR</cell><cell></cell><cell></cell><cell></cell></row><row><cell>e (ihe-ih)</cell><cell>-0.023</cell><cell>(-0.122, 0.076)</cell><cell>12-17-30</cell><cell>-0.92 (61), -0.92 (80), 0.88 (82)</cell></row><row><cell>h (ih-i)</cell><cell>0.043</cell><cell>(-0.002, 0.089)</cell><cell>12-5-42</cell><cell>0.88 (59), 0.67 (99), -0.25 (110)</cell></row><row><cell>i (ih-h)</cell><cell>0.025</cell><cell>(-0.036, 0.086)</cell><cell>9-10-40</cell><cell>0.80 (99), 0.75 (96), -0.67 (98)</cell></row><row><cell>e0 (ihe0-ih)</cell><cell>-0.067</cell><cell>(-0.182, 0.047)</cell><cell>12-22-25</cell><cell>-1.00 (80), -0.98 (61), 0.88 (82)</cell></row><row><cell></cell><cell>∆P30</cell><cell></cell><cell></cell><cell></cell></row><row><cell>e (ihe-ih)</cell><cell>0.014</cell><cell>(-0.006, 0.033)</cell><cell>23-20-16</cell><cell>0.23 (81), 0.20 (65), -0.13 (96)</cell></row><row><cell>h (ih-i)</cell><cell>0.020</cell><cell>( 0.001, 0.039)</cell><cell>27-11-21</cell><cell>-0.23 (78), 0.17 (57), 0.17 (102)</cell></row><row><cell>i (ih-h)</cell><cell>0.022</cell><cell>( 0.003, 0.041)</cell><cell>27-14-18</cell><cell>0.23 (110), 0.20 (83), -0.17 (79)</cell></row><row><cell>e0 (ihe0-ih)</cell><cell>0.014</cell><cell>(-0.009, 0.038)</cell><cell>23-23-13</cell><cell>0.30 (81), 0.23 (79), -0.17 (61)</cell></row><row><cell></cell><cell>∆R-prec</cell><cell></cell><cell></cell><cell></cell></row><row><cell>e (ihe-ih)</cell><cell>0.003</cell><cell>(-0.017, 0.022)</cell><cell>25-19-15</cell><cell>0.29 (79), -0.17 (105), -0.25 (84)</cell></row><row><cell>h (ih-i)</cell><cell>0.030</cell><cell>( 0.016, 0.044)</cell><cell>32-6-21</cell><cell>0.14 (79), 0.14 (102), -0.09 (78)</cell></row><row><cell>i (ih-h)</cell><cell>0.037</cell><cell>( 0.015, 0.060)</cell><cell>34-15-10</cell><cell>0.29 (110), 0.26 (66), -0.16 (79)</cell></row><row><cell>e0 (ihe0-ih)</cell><cell>-0.007</cell><cell>(-0.030, 0.017)</cell><cell>22-26-11</cell><cell>0.31 (79), 0.19 (65), -0.25 (84)</cell></row><row><cell></cell><cell>∆GMAP'</cell><cell></cell><cell></cell><cell></cell></row><row><cell>e (ihe-ih)</cell><cell>-0.003</cell><cell>(-0.019, 0.012)</cell><cell>36-22-1</cell><cell>-0.34 (61), -0.15 (80), 0.08 (72)</cell></row><row><cell>h (ih-i)</cell><cell>0.012</cell><cell>( 0.004, 0.020)</cell><cell>47-10-2</cell><cell>0.15 (59), -0.07 (78), -0.10 (72)</cell></row><row><cell>i (ih-h)</cell><cell>0.021</cell><cell>(-0.001, 0.043)</cell><cell>44-15-0</cell><cell>-0.42 (63), 0.26 (110), 0.27 (72)</cell></row><row><cell>e0 (ihe0-ih)</cell><cell>-0.030</cell><cell>(-0.060, 0.001)</cell><cell>35-23-1</cell><cell>-0.51 (80), -0.49 (96), 0.09 (72)</cell></row><row><cell></cell><cell>∆MAP</cell><cell></cell><cell></cell><cell></cell></row><row><cell>e (ihe-ih)</cell><cell>0.022</cell><cell>( 0.004, 0.040)</cell><cell>36-22-1</cell><cell>0.24 (79), 0.17 (55), -0.23 (84)</cell></row><row><cell>h (ih-i)</cell><cell>0.028</cell><cell>( 0.016, 0.040)</cell><cell>47-10-2</cell><cell>-0.13 (78), 0.11 (88), 0.11 (52)</cell></row><row><cell>i (ih-h)</cell><cell>0.047</cell><cell>( 0.029, 0.064)</cell><cell>44-15-0</cell><cell>0.24 (66), 0.21 (71), -0.05 (79)</cell></row><row><cell>e0 (ihe0-ih)</cell><cell>0.011</cell><cell>(-0.014, 0.035)</cell><cell>35-23-1</cell><cell>0.29 (79), 0.22 (75), -0.26 (84)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,88.95,82.08,434.10,456.60"><head>Table 3 :</head><label>3</label><figDesc>Impact of Microblog Adhoc Search Techniques on Measures counting just Highly Relevant</figDesc><table coords="7,96.99,96.77,418.03,441.91"><row><cell>Expt</cell><cell>∆HGS30</cell><cell>95% Conf</cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>e (ihe-ih)</cell><cell>-0.024</cell><cell>(-0.070, 0.021)</cell><cell>17-19-20</cell><cell>-0.93 (61), -0.37 (58), 0.28 (101)</cell></row><row><cell>h (ih-i)</cell><cell>0.017</cell><cell>(-0.020, 0.054)</cell><cell>24-8-24</cell><cell>-0.62 (72), -0.30 (101), 0.60 (102)</cell></row><row><cell>i (ih-h)</cell><cell>0.018</cell><cell>(-0.027, 0.063)</cell><cell>12-13-31</cell><cell>0.93 (61), 0.60 (110), -0.37 (96)</cell></row><row><cell>e0 (ihe0-ih)</cell><cell>-0.053</cell><cell>(-0.115, 0.010)</cell><cell>19-23-14</cell><cell>-1.00 (80), -0.93 (61), 0.38 (59)</cell></row><row><cell></cell><cell>∆HFRS</cell><cell></cell><cell></cell><cell></cell></row><row><cell>e (ihe-ih)</cell><cell>-0.024</cell><cell>(-0.081, 0.033)</cell><cell>17-18-21</cell><cell>-0.79 (61), -0.60 (80), 0.63 (82)</cell></row><row><cell>h (ih-i)</cell><cell>0.039</cell><cell>( 0.006, 0.072)</cell><cell>22-8-26</cell><cell>0.46 (102), 0.44 (77), -0.34 (101)</cell></row><row><cell>i (ih-h)</cell><cell>0.005</cell><cell>(-0.040, 0.050)</cell><cell>10-13-33</cell><cell>0.79 (61), -0.43 (82), -0.64 (96)</cell></row><row><cell>e0 (ihe0-ih)</cell><cell>-0.055</cell><cell>(-0.126, 0.015)</cell><cell>18-23-15</cell><cell>-1.00 (80), -0.79 (61), 0.63 (82)</cell></row><row><cell></cell><cell>∆HMRR</cell><cell></cell><cell></cell><cell></cell></row><row><cell>e (ihe-ih)</cell><cell>-0.007</cell><cell>(-0.094, 0.079)</cell><cell>17-18-21</cell><cell>0.93 (82), -0.83 (52), -0.92 (80)</cell></row><row><cell>h (ih-i)</cell><cell>0.070</cell><cell>( 0.023, 0.116)</cell><cell>24-8-24</cell><cell>0.67 (71), 0.67 (99), -0.17 (109)</cell></row><row><cell>i (ih-h)</cell><cell>-0.001</cell><cell>(-0.043, 0.041)</cell><cell>12-14-30</cell><cell>0.80 (99), 0.25 (61), -0.67 (68)</cell></row><row><cell>e0 (ihe0-ih)</cell><cell>-0.045</cell><cell>(-0.154, 0.063)</cell><cell>19-23-14</cell><cell>-1.00 (80), -0.86 (75), 0.93 (82)</cell></row><row><cell></cell><cell>∆HP30</cell><cell></cell><cell></cell><cell></cell></row><row><cell>e (ihe-ih)</cell><cell>0.011</cell><cell>(-0.006, 0.027)</cell><cell>19-16-21</cell><cell>0.17 (99), 0.17 (62), -0.13 (96)</cell></row><row><cell>h (ih-i)</cell><cell>0.025</cell><cell>( 0.009, 0.041)</cell><cell>24-6-26</cell><cell>0.30 (66), 0.13 (96), -0.07 (101)</cell></row><row><cell>i (ih-h)</cell><cell>0.007</cell><cell>(-0.006, 0.020)</cell><cell>17-13-26</cell><cell>0.17 (110), 0.13 (83), -0.13 (79)</cell></row><row><cell>e0 (ihe0-ih)</cell><cell>0.015</cell><cell>(-0.005, 0.035)</cell><cell>19-19-18</cell><cell>0.23 (79), 0.20 (99), -0.13 (96)</cell></row><row><cell></cell><cell>∆HP@R</cell><cell></cell><cell></cell><cell></cell></row><row><cell>e (ihe-ih)</cell><cell>0.022</cell><cell>( 0.000, 0.045)</cell><cell>19-10-27</cell><cell>0.34 (79), 0.33 (109), -0.10 (64)</cell></row><row><cell>h (ih-i)</cell><cell>0.017</cell><cell>( 0.003, 0.031)</cell><cell>19-6-31</cell><cell>0.20 (64), 0.13 (99), -0.12 (98)</cell></row><row><cell>i (ih-h)</cell><cell>-0.003</cell><cell>(-0.020, 0.013)</cell><cell>12-12-32</cell><cell>-0.22 (79), -0.17 (103), 0.15 (83)</cell></row><row><cell>e0 (ihe0-ih)</cell><cell>0.020</cell><cell>(-0.006, 0.047)</cell><cell>20-15-21</cell><cell>0.39 (79), 0.33 (109), -0.18 (94)</cell></row><row><cell></cell><cell>∆HGMAP'</cell><cell></cell><cell></cell><cell></cell></row><row><cell>e (ihe-ih)</cell><cell>-0.009</cell><cell>(-0.036, 0.018)</cell><cell>32-23-1</cell><cell>-0.67 (61), -0.17 (80), 0.11 (81)</cell></row><row><cell>h (ih-i)</cell><cell>0.020</cell><cell>( 0.008, 0.032)</cell><cell>49-6-1</cell><cell>0.26 (59), 0.13 (102), -0.11 (72)</cell></row><row><cell>i (ih-h)</cell><cell>0.020</cell><cell>(-0.010, 0.051)</cell><cell>36-19-1</cell><cell>0.46 (72), 0.39 (61), -0.44 (63)</cell></row><row><cell>e0 (ihe0-ih)</cell><cell>-0.037</cell><cell>(-0.077, 0.004)</cell><cell>28-27-1</cell><cell>-0.71 (96), -0.67 (61), 0.11 (81)</cell></row><row><cell></cell><cell>∆HMAP</cell><cell></cell><cell></cell><cell></cell></row><row><cell>e (ihe-ih)</cell><cell>0.024</cell><cell>( 0.002, 0.046)</cell><cell>32-23-1</cell><cell>0.27 (109), 0.25 (79), -0.12 (84)</cell></row><row><cell>h (ih-i)</cell><cell>0.033</cell><cell>( 0.021, 0.045)</cell><cell>49-6-1</cell><cell>0.18 (56), 0.14 (66), -0.05 (72)</cell></row><row><cell>i (ih-h)</cell><cell>0.014</cell><cell>( 0.003, 0.025)</cell><cell>36-19-1</cell><cell>0.13 (83), 0.13 (110), -0.08 (79)</cell></row><row><cell>e0 (ihe0-ih)</cell><cell>0.013</cell><cell>(-0.017, 0.042)</cell><cell>28-27-1</cell><cell>0.35 (109), 0.30 (79), -0.23 (91)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,87.24,660.96,452.76,6.99;1,72.00,670.43,468.00,6.99;1,72.00,679.89,468.00,6.99;1,72.00,689.36,340.59,6.99"><p>OpenText, Open Text eDOCS SearchServer and Open Text eDOCS Suite are trademarks or registered trademarks of Open Text Corporation in the United States of America, Canada, the European Union and/or other countries. This list of trademarks is not exhaustive. Other trademarks, registered trademarks, product names, company names, brands and service names mentioned herein are property of Open Text Corporation or other respective owners.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,86.71,375.66,317.80,8.11" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><surname>Cross-Language</surname></persName>
		</author>
		<ptr target="http://www.clef-campaign.org/" />
		<title level="m" coord="10,153.52,375.66,107.63,7.86">Evaluation Forum web site</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,86.71,394.59,453.29,7.86;10,82.52,405.55,20.99,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,160.04,394.59,196.98,7.86">Converting the Fulcrum Search Engine to Unicode</title>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Hodgson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,363.63,394.59,172.11,7.86">Sixteenth International Unicode Conference</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,86.71,424.48,421.60,9.85" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="10,124.30,424.48,154.83,7.86">NII-Test Collection for IR) Home Page</title>
		<author>
			<persName coords=""><surname>Ntcir</surname></persName>
		</author>
		<ptr target="http://research.nii.ac.jp/~ntcadm/index-en.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,86.71,443.40,453.28,7.86;10,82.52,454.36,60.66,7.86" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
		<title level="m" coord="10,400.95,443.40,139.05,7.86;10,82.52,454.36,31.38,7.86">Okapi at TREC-3. Proceedings of TREC-3</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,86.71,473.29,297.17,8.12" xml:id="b4">
	<monogr>
		<ptr target="http://trec.nist.gov/" />
		<title level="m" coord="10,86.71,473.29,190.87,7.86">Text REtrieval Conference (TREC) Home Page</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,86.71,492.22,453.29,7.86;10,82.52,503.18,218.63,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="10,168.73,492.22,371.28,7.86;10,82.52,503.18,117.31,7.86">Comparing the Robustness of Expansion Techniques and Retrieval Measures. Working Notes for the CLEF 2006 Workshop</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<idno>LNCS 4730</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,86.71,522.11,453.29,7.86;10,82.52,533.07,49.14,7.86" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="10,169.65,522.11,311.92,7.86">Early Precision Measures: Implications from the Downside of Blind Feedback</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="705" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,86.71,552.00,429.23,7.86;10,515.95,550.23,11.72,5.24;10,531.81,552.00,8.19,7.86;10,82.52,562.96,165.57,7.86" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Enterprise</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Qa</surname></persName>
		</author>
		<title level="m" coord="10,238.65,552.00,277.30,7.86;10,515.95,550.23,11.72,5.24;10,531.81,552.00,8.19,7.86;10,82.52,562.96,161.37,7.86">Robust and Terabyte Experiments with Hummingbird SearchServer TM at TREC 2005. Proceedings of TREC 2005</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,86.71,581.89,379.32,7.86;10,466.03,580.12,11.72,5.24;10,480.87,581.89,59.13,7.86;10,82.52,592.84,185.11,7.86" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<title level="m" coord="10,168.55,581.89,297.47,7.86;10,466.03,580.12,11.72,5.24;10,480.87,581.89,59.13,7.86;10,82.52,592.84,180.36,7.86">European Ad Hoc Retrieval Experiments with Hummingbird SearchServer TM at CLEF 2005. Working Notes for the CLEF 2005 Workshop</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,91.32,611.77,439.83,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,174.06,611.77,237.72,7.86">Learning Task Experiments in the TREC 2011 Legal Track</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,419.09,611.77,107.87,7.86">Proceedings of TREC 2011</title>
		<meeting>TREC 2011</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,91.32,630.70,409.34,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,170.88,630.70,210.42,7.86">Overview of the TREC 2003 Robust Retrieval Track</title>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,388.59,630.70,107.87,7.86">Proceedings of TREC 2003</title>
		<meeting>TREC 2003</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,91.32,649.63,409.34,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,170.88,649.63,210.42,7.86">Overview of the TREC 2004 Robust Retrieval Track</title>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,388.59,649.63,88.01,7.86">Proceedings of TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
