<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,112.99,152.35,391.41,14.93;1,220.22,174.27,176.96,14.93">Using a Bayesian Model to Combine LDA Features with Crowdsourced Responses</title>
				<funder ref="#_2mUbENZ">
					<orgName type="full">UK Research Council EPSRC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013-02-05">February 5, 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,226.91,208.00,76.06,10.37"><forename type="first">Edwin</forename><surname>Simpson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering Science</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,326.21,208.00,64.26,10.37"><forename type="first">Steven</forename><surname>Reece</surname></persName>
							<email>reece@robots.ox.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering Science</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,213.88,279.93,68.74,10.37"><forename type="first">Antonio</forename><surname>Penta</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Electronics and Computer Science</orgName>
								<orgName type="institution">University of Southampton</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,305.86,279.93,97.65,10.37"><forename type="first">Sarvapali</forename><surname>Ramchurn</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Electronics and Computer Science</orgName>
								<orgName type="institution">University of Southampton</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,112.99,152.35,391.41,14.93;1,220.22,174.27,176.96,14.93">Using a Bayesian Model to Combine LDA Features with Crowdsourced Responses</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2013-02-05">February 5, 2013</date>
						</imprint>
					</monogr>
					<idno type="MD5">39FEB722478B45B7ECE903E2670009E5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes a crowdsourcing system that integrates machine learning techniques with human classifiers, showing how to apply a Bayesian approach to classifier combination to the challenge of crowdsourcing document topic labels. First, we use a number of NLP techniques to extract informative document features. We then screen and select workers using Amazon Mechanical Turk to label selected documents. We then apply Independent Bayesian Classifier Combination (IBCC) to classify the complete set of documents in a semi-supervised manner, taking into account the unreliability of crowd-sourced labels. More documents are then selected intelligently for labeling by the crowd. We demonstrate superior results using IBCC compared to a two-stage classifier and strong performance with only 16% documents labelled by the crowd.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Information Retrieval is becoming a serious challenge in the face of Big Data and the Internet of Things where information is generated by people, communities, sensors, and agents on the web. The Crowdsourcing track of the Text Retrieval Conference has the following objectives:</p><p>• Develop crowdsourcing techniques to label 15424 documents • Use human-machine collaboration to minimise cost and maximise efficiency This chapter reports on our approach to achieving these objectives using a combination of Natural Language Processing (NLP), Machine Learning, and crowdsourcing.</p><p>The TREC challenge was to judge 18260 topic-document pairs. Ten topics were randomly chosen by the TREC organising committee. Each topic had a title, description and narrative and these were used to determine if a document was relevant to a topic. Examples of topics included definition of creativity and recovery of treasure from sunken ships. The documents came from the TREC corpus (TREC 8), previously labelled by the National Institute of Standards and Technology (NIST) experts. Document sources included the Financial Times, Los Angeles Times and Federal Register articles. As of writing we are aware that out of 17 groups that participated in the TREC challenge we came in the top four according to the NIST committee's evaluation of our results using standard statistical measures (chiefly the Receiver Operating Curve Area Under Curve (AUC)).</p><p>This chapter is structured as follows: Section 2 presents a brief overview of our approach to solving the TREC crowdsourcing challenge problem. Section 3 then describes the natural language processing applied to the documents to extract distinct features for each topic type. Section 4 describes in detail our approach to crowdsourcing using Amazon Mechanical Turk which includes a description of the user interface we built into Amazon Mechanical Turk for document labelling, a method for evaluating a turker's trust and a method for paying turkers upon completion of their labelling tasks. Section 5 describes two classifiers that were developed for predicting labels for unlabelled documents. These classifiers where the Independent Bayes Classifier Combination (IBCC) algorithm and a traditional two-stage Bayesian classifier. A mechanism which uses the output of these classifiers to select documents for crowdsourced labelling is then presented in Section 6. The efficacy of the IBCC and two-stage classifier are compared on the TREC challenge problem in Section 7. Finally, we discuss our solution to the TREC challenge problem in Section 8 and offer some ideas for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Overview of the Document Classification System</head><p>We called on the crowd to label a subset of documents from which we inferred probabilities of topic relevance of the unlabelled documents. We developed a document labelling system comprising the following modules:</p><p>1. Feature extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Crowdsourcing.</head><p>3. Classification to infer probabilities of class labels for unlabelled documents.</p><p>Stage 1 was performed initially off-line. Stages 2 and 3 then iterated until all documents were labelled with sufficient confidence.</p><p>For the feature extraction module we first applied some classical NLP stages and then extracted different features using word-based counting with the computational complexity of this approach mitigated with word clustering. A measure based on the features extracted was also used to define an initial relevance rank to select the first set of documents to be labelled by the crowd.</p><p>To crowdsource the labelling of documents we developed the following components using Amazon Mechanical Turk (AMT) as the crowdsourcing platform:</p><p>1. a Bayesian trust model which computes the level of trust we can assign to a turker to complete specific "gold" tasks (which are tasks for which the ground truth topic labels are known) 2. a hiring process which is the workflow for hiring workers 3. an HIT (Human Intelligence Task) interface which controls the presentation of the labelling task to maximize efficient labelling, perform verification and avoid boredom by the turker.</p><p>Both the turkers' confidence and accuracy in their gold responses were combined to give an overall indication of the workers' trustworthiness at labelling a document correctly. At each iteration of the system we choose a set of documents to be passed to the AMT such that the documents whose labelling would yield the greatest potential information gain across the corpus were preferred. The turkers then responded with both a single topic classification (or no topic) and confidence in their labelling.</p><p>We have developed a novel Bayesian unsupervised classifier which accommodates agents' own confidence in their responses as well as an assessment of their reliability obtained from the trust model. This classifier uses these unreliable labels extracted from the crowd to learn the correspondence between features and topics. The occurrence of features is assumed to be conditionally independent and the likelihoods used in the Bayesian classifier are learned directly from the data using an unsupervised formalism couched in a Variational Bayes learning framework. The classifier is then used to assign a probability that each document in the corpus belongs to a topic. We describe each of the above modules in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Natural Language Processing and Feature Extraction</head><p>Before extracting the features from the documents, we pre-processed the documents using classical Natural Language Processing (NLP) steps Part of Speech (PoS), Lemmatization and Stemming <ref type="bibr" coords="3,465.98,288.71,10.58,8.64" target="#b0">[1]</ref>. The PoS reduced our set of words to nouns and verbs using a maximum entropy classifier. 1 Lemmatization and Stemming were then used to reduce inflectional forms and derivationally related forms of a word to a common base form. For example, the forms "am, are, is " become "be" and "cat, cats, cat's, cats' " become "cat". In particular, we used Pling-stemming <ref type="bibr" coords="3,317.60,336.53,11.62,8.64" target="#b1">[2]</ref> for nouns and the lemmatization method from WordNet <ref type="bibr" coords="3,138.04,348.48,11.62,8.64" target="#b2">[3]</ref> for verbs.</p><p>We compared two feature extraction methods based on word weight models: Term Frequency-Inverse Document Frequency (TF-IDF) <ref type="bibr" coords="3,230.49,372.39,11.62,8.64" target="#b3">[4]</ref> and Divergence from Randomness (DFR) <ref type="bibr" coords="3,418.60,372.39,10.58,8.64" target="#b4">[5]</ref>. We observed better performance from the DFR model on a subset of TREC-7 collections but could not manage the huge matrices in central memory for the next stages of the NLP process. So, we used a cluster strategy to aggregate similar words. However, classical clustering algorithms are computationally costly as they use pair-wise distances between words and, for that reason, we clustered using a latent topic model. Latent topics are the foundation of Latent Dirichlet Allocation (LDA) <ref type="bibr" coords="3,384.93,432.17,11.62,8.64" target="#b5">[6]</ref> for which a document can be approximated as a mixture distribution of topics where each topic is a distribution of words. We applied LDA 2 in our feature extraction process by considering each document as a feature vector generated from the topic distribution. We experimented with different numbers of topics (i.e. 500, 1000, 1500, 2000) 3  and, on a subset of TREC-7 collections, we observed that 2000 topics gave the best performance.</p><p>We also used LDA to select the first documents to send to the crowd, aiming to find some examples of documents that match the query topics in the TREC challenge. For each TREC relevance topic, we ranked the documents in the collection using the measure:</p><formula xml:id="formula_0" coords="3,222.73,531.17,171.95,12.99">r(d, L, τ ) = ∑ N i=1 ∑ K j=1 ρ(w i , T j , τ )θ(T j ; d)</formula><p>where d is a document, L={w 1 , . . . , w N } is a set of words extracted from a TREC topic description, τ ∈ N is a threshold (in our experiments set to 50), T i is the i-th LDA topic, θ(i; d) is the probability of the i-th LDA topic given the document d and ρ(w i , T j , τ ) = 1 if w i belongs to the set of the most τ probable words of T j 0 elsewhere.  2 We used the implementation in the MALLAT package (http://mallet.cs.umass.edu/) 3 We were limited by the dimension of our matrices to 2000 as our upper bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Crowdsourcing Techniques</head><p>We chose to use Amazon Mechanical Turk to crowdsource the document labelling because of the versatile and ease of use of the application programming interface (API) that is available to this service and also because it provided access to the largest number of workers without polluting trust metrics. Given the large size of the document set, it was deemed inefficient to crowdsource the labelling of documents by consensus. That is, to ask multiple turkers to label the same document and aggregate the votes to produce a single label. In more detail, the crowdsourcing approach has to balance the complexity and potential monetary cost of crowdsourcing against the quality of performance of the individual turkers. Indeed, the labelling task requires the reader to read every sentence and check whether a particular sentence could render the document relevant to a particular topic. The majority of documents were not more than a page long but a significant number were also more than two or three pages long. This would require significant effort from the reader to read every sentence and this task would, therefore, take considerably longer to complete. It was also obvious that, if a particular turker had to verify lots of documents, this process would quickly become boring and reduce the effectiveness of the turker. To address the above issues, we developed a number of mechanisms to ensure:</p><p>1. The best turkers were chosen (i.e., those that can be trusted to perform tasks correctly).</p><p>2. The task of labelling a document was made easier for the turkers.</p><p>3. The turkers were encouraged to perform tasks quickly.</p><p>We describe each of these mechanisms in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Trust Mechanism</head><p>Before we assigned paid tasks to workers, we ran a screening process to exclude those turkers that were likely to produce uninformative responses. In the screening process, workers had to assign the correct topics to 10 "Gold task" documents for which the true topic label was known. Workers also marked their decisions as confident or not confident. We then calculated the trust T (k), i.e. the probability that a worker k was correct,</p><formula xml:id="formula_1" coords="4,164.42,470.14,353.70,14.78">T (k) = ((n (k) cc + 1) + G(n (k) cn + 1) + (1 -G)(n (k) in + 1))/(N (k) + 4)<label>(1)</label></formula><p>where</p><formula xml:id="formula_2" coords="4,126.38,494.94,16.36,12.24">n (k)</formula><p>cc , is the number of tasks where turker k was correct and confident, n</p><p>cn is the number of tasks where the turker was correct but not confident, n (k) in is the number of tasks where the turker was incorrect and not confident. N (k) is the total number of tasks they actually performed. The variable G distributes the weight of a"not confident" answer between the possible responses. In preliminary tests, 70% of not confident responses were correct, so we set G = 0.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Derivation of Trust Mechanism</head><p>Trust in a turker is defined as the belief that the label assigned to a document by the turker is the correct label for that document and follows from a general definition of trust <ref type="bibr" coords="4,384.96,608.21,10.58,8.64" target="#b6">[7]</ref>. Formally, given an assigned label, r w , by a turker, w, and some true label, t, for a document then the trustworthiness, T (w), of that turker is, For ease of exposition we drop the index w and assume a uniform prior over the document classes, p(t = j). We now expand this definition of trust to incorporate the intuition behind decisions labelled as"confident" or "not confident". A worker who is not confident about labels which turn out incorrect and confident in labels that turn out correct is more trustworthy than a worker who expresses high confidence in all her labels whether they turn out to be correct or not.</p><formula xml:id="formula_4" coords="4,222.35,653.72,152.77,18.45">T (w) = ∑ j p(r w = j | t = j)p(t = j) .</formula><p>Each turker who labels a Gold standard document returns a report pair [s, d]: a document label, s, and a statement of confidence in her labelling d. We assume the turker either correctly labels the document, s = j, or incorrectly labels the document, s = ¬j. Furthermore, the turker is either confident in her label in which case d = c or unconfident, in which case d = n. Now, We assume uninformative priors so that p(r</p><formula xml:id="formula_5" coords="5,170.76,457.82,343.49,19.04">p(r = j | t = j) = ∑ s∈{j,¬j} ∑ d∈{c,n} p(r = j | [s, d])p([s, d] | t = j)<label>(2</label></formula><formula xml:id="formula_6" coords="5,286.34,549.37,228.06,8.96">= j | [s, d]) ∼ Beta(1, 1) and p([s, c] | t = j) ∼ Dir(1, 1, 1, 1</formula><p>) for all values of j. We can thus learn the trust values from the data,</p><formula xml:id="formula_7" coords="5,174.65,582.93,343.47,50.08">p(r = j | t = j) = ∑ s∈{j,¬j} ∑ d∈{c,n} p(r = j | [s, d]) p([s, d] | t = j) (3) = ∑ s ∈{c,i} ∑ d∈{c,n} G s d n s d + 1 N + 4 (<label>4</label></formula><formula xml:id="formula_8" coords="5,514.24,614.29,3.87,8.64">)</formula><p>where N is the total number of gold standard test documents submitted to the turker and, for example, n in is the number of documents with low confidence labellings which are incorrectly labelled. The probability</p><formula xml:id="formula_9" coords="5,99.27,668.99,120.40,9.73">G cc = p(r = j | [s = j, c]) = 1</formula><p>is the turker's expected belief that the document should be labelled j given that it has been labelled j and she has absolute confidence in that label. Alternatively, G nc = p(r = ¬j | [s = j, c]) = 0 is the turker's belief that the document should be labelled ¬j given that she has labelled it j and she has absolute confidence in that label. G cn = p(r = j | [s = j, n]) = G is the turker's belief that the document should be labelled j given that she has labelled it j and she has some doubt in that labelling. Finally,</p><formula xml:id="formula_10" coords="6,131.73,160.84,157.11,9.73">G nn = p(r = ¬j | [s = j, n]) = (1 -G)</formula><p>is the turker's belief that the document should be labelled ¬j given that she has labelled it j and she has some doubt in that labelling. Thus, inserting G into (4) we arrive the expression in <ref type="bibr" coords="6,331.00,185.07,10.58,8.64" target="#b0">(1)</ref>. The value for G can be inferred from data comprising the ground truth document labels, t, and worker response pairs [s, d].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Hiring Process</head><p>After computing the trustworthiness for each turker using the mechanism reported above, we then only allowed those with trust greater than 0.5 to perform tasks in order to get more than 50% of the turkers to do tasks. This, however, resulted in very poor performance and the participation threshold was therefore raised to 0.65 and this resulted in only about 40% of the turkers being available to do tasks (see Figure <ref type="figure" coords="6,507.32,280.08,3.60,8.64" target="#fig_0">1</ref>). The classifier (to be described later) was then queried for those documents that were considered most important to be labelled. These documents were then chunked into parts not more than 20KB in size to make sure they were readable within 5 minutes. Then, depending on the document size, a payment level was determined for the labelling tasks required. We chose the following payment levels depending on document size,</p><p>• $0.03 for tasks less than 5KB</p><p>• $0.05 for tasks between 5KB and 15KB</p><p>• $0.08 for tasks beyond 15KB.</p><p>Once the tasks were uploaded into AMT, the trusted turkers were notified through the AMT messaging service to start working on the tasks. The trust mechanism was good at filtering turkers and the labelling task was completed to a high quality. However, we noticed that those turkers performing large numbers of tasks generally under performed as they completed lots of tasks, possibly due to boredom.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">HIT Interface</head><p>The principle we adopted for our Human Interface Technology (HIT) interface was that the task should be straightforward for the user and should include checks to make sure the task was completed to a high level of quality. Therefore, the labelling task required the turker, 1. To read the document which was divided into three sections this is to break down the reading task into more manageable segments and avoid the reader feeling overwhelmed.</p><p>2. Paste a key sentence from each section into the page this is meant to check whether the reader actually read the section.</p><p>3. Choose a topic for the document as well as assign a confidence level to the label she gave.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Document-Topic Classification</head><p>We applied the Independent Bayesian Classifier Combination (IBCC) algorithm to automatically label documents using the responses from the turkers. We also compared it to a more traditional two-stage Bayes classifier. Both classifiers were used to infer the probability of relevance of each document to each topic from the document features identified using the NLP algorithms described in Section 3 and crowdsourced labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">IBCC: One-stage Classifier</head><p>Members of the crowd can be seen as imperfect base classifiers, where each individual has their own probability of producing a particular label. Features occur with different probabilities given each topic, so can also be seen as base classifiers ranging from highly indicative of a topic to completely uninformative. Our method learns the probabilities of features and crowd responses, simultaneously combining them to infer topic probabilities. This differs from traditional classification, which has separate training and prediction phases. The one-stage classifier is a semi-supervised approach that allows latent structure in the unlabelled documents to influence the results, which is particularly effective when there is limited training data. The graphical model for IBCC <ref type="bibr" coords="7,242.44,267.33,11.62,8.64" target="#b7">[8]</ref> is shown in Figure <ref type="figure" coords="7,336.10,267.33,3.74,8.64" target="#fig_4">2</ref>. For a set of documents indexed from 1 to N , the ith document has topic t i = 1...J that we wish to infer, where J is the number of topics. We assume t i is generated from a multinomial distribution with class probabilities κ : p(t i = j|κ) = κ j . For the challenge problem we have assumed that the topics are mutually exclusive based on our understanding of the topics, and that there also exists a "none of the above" topic for documents of unknown topic. The total number of base classifiers (features and turkers) is K and the set of values assigned by base classifiers to documents is c. A turker k may produce a label c is assumed to be generated from a multinomial distribution dependent on the topic of document i, with parameters π (k) </p><formula xml:id="formula_11" coords="7,108.93,377.98,127.22,14.78">j : p(c (k) i = l|t i = j, π (k) j ) = π</formula><formula xml:id="formula_12" coords="7,192.96,462.08,325.16,27.46">p(κ, Π, t, c|A 0 , ν) = N ∏ i=1 {κ t i K ∏ k=1 π (k) t i ,c (k) i }p(κ|ν)p(Π|A 0 ),<label>(5)</label></formula><p>A key feature of IBCC is that π (k) represents a confusion matrix that quantifies the reliability of each crowd member and feature. The prior distribution over each π (k) is specified through the hyperparameters A 0 , which can be regarded as pseudo-counts of prior observations of base classifier outputs. Through our choice of these hyper-parameters, we assume that turkers are likely to be informative but not perfect, allowing us to perform inference without observing true topic labels directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Inference over IBCC using Variational Bayes</head><p>The unknown variables t, Π, and κ can be estimated using maximum a posteriori (MAP) estimation <ref type="bibr" coords="7,496.03,592.07,11.62,8.64" target="#b8">[9]</ref> or inferred in a Bayesian manner <ref type="bibr" coords="7,222.29,604.03,11.62,8.64" target="#b7">[8]</ref> using Gibbs Sampling <ref type="bibr" coords="7,327.83,604.03,15.27,8.64" target="#b9">[10]</ref>. Here we applied a principled approximate Bayesian method, variational Bayes (VB) <ref type="bibr" coords="7,270.21,615.98,15.27,8.64" target="#b10">[11]</ref>, as this converges rapidly to a good approximate solution <ref type="bibr" coords="7,99.27,627.94,15.27,8.64" target="#b11">[12]</ref>. VB can be seen as a Bayesian generalisation of the Expectation-Maximisation (EM) algorithm <ref type="bibr" coords="7,499.03,627.94,15.27,8.64" target="#b12">[13]</ref>.</p><p>For the variational treatment of IBCC, VB-IBCC, we assume an approximate form of the posterior distribution over the unknown variables: jl ] and E[ln κ j ] from their prior distributions. We then iterate over a two-stage procedure, updating each of the factors q(t) and q(κ, Π) to their optimal values in turn, using the current expectations over parameters not in that factor.</p><formula xml:id="formula_13" coords="7,251.81,668.96,266.31,9.11">q(κ, t, Π) = q(t)q(κ, Π)<label>(6)</label></formula><p>The optimal factor q * (t) for the topics is defined by taking the joint distribution in ( <ref type="formula" coords="8,451.25,351.79,3.87,8.64" target="#formula_12">5</ref>) and absorbing terms not dependent on t into the normalisation constant:</p><formula xml:id="formula_14" coords="8,221.13,383.00,293.11,12.08">ln q * (t) = E κ,Π [ln p(κ, t, Π, c)] + const. (<label>7</label></formula><formula xml:id="formula_15" coords="8,514.24,385.67,3.87,8.64">)</formula><p>This factorises into independent data points:</p><formula xml:id="formula_16" coords="8,135.76,428.18,382.35,27.56">ln ρ ij = E κ j ,π j [ln p(κ j , t i , π j , c)] = E κ [ln κ j ] + K ∑ k=1 L ∑ l=1 p(c (k) i = l)E π j [ln π (k) j,c (k) i ].<label>(8)</label></formula><p>For a base classifier that is a turker, the value of c (k)</p><p>i is known and p(c</p><formula xml:id="formula_17" coords="8,372.94,466.77,25.96,14.78">(k) i = l</formula><p>) is either 0 or 1. However, for features we receive probabilities rather than discrete outputs, hence the term p(c (k) i = l) in the equation above. We then obtain the approximate probability of a topic, which also gives its expected value:</p><formula xml:id="formula_18" coords="8,235.94,514.47,278.30,25.51">q * (t i = j) = E t [t i = j] = ρ ij ∑ J ι=1 ρ iι . (<label>9</label></formula><formula xml:id="formula_19" coords="8,514.24,521.60,3.87,8.64">)</formula><p>For the parameters of the model we have the following optimal factor. Terms involving κ and terms involving each confusion matrix in Π are independent, so we can factorise q * (κ, π) further into</p><formula xml:id="formula_20" coords="8,236.51,582.71,144.37,27.46">q * (κ,Π) = q * (κ) K ∏ k=1 J ∏ j=1 q * π (k) j .</formula><p>In IBCC we assume a Dirichlet prior for κ, which gives us a Dirichlet posterior for the optimal factor q * (κ) ∝ Dir(κ|ν 1 , ..., ν J )</p><formula xml:id="formula_21" coords="8,357.70,643.85,156.27,9.90">ν j = ν 0,j + N j (<label>10</label></formula><formula xml:id="formula_22" coords="8,513.96,644.16,4.15,8.64">)</formula><p>where ν is updated by adding the data counts to the prior counts ν 0 and</p><formula xml:id="formula_23" coords="9,380.76,109.86,76.91,27.38">N j = N ∑ i=1 E t [t i = j]</formula><p>is the expected number of documents of each topic. The expectation of ln κ required to update ( <ref type="formula" coords="9,419.57,138.12,3.87,8.64" target="#formula_16">8</ref>) is therefore:</p><formula xml:id="formula_24" coords="9,245.25,159.47,268.72,27.38">E [ln κ j ] = Ψ(ν j ) -Ψ J ∑ ι=1 ν ι (<label>11</label></formula><formula xml:id="formula_25" coords="9,513.96,168.66,4.15,8.64">)</formula><p>where Ψ is the standard digamma function <ref type="bibr" coords="9,279.89,202.87,15.27,8.64" target="#b13">[14]</ref>. For the confusion matrices π (k) j , the priors are also Dirichlet distributions, giving us a posterior Dirichlet distribution of the form</p><formula xml:id="formula_26" coords="9,99.27,235.57,418.84,40.69">q * π (k) j = Dir π (k) j |α (k) j1 , ..., α (k) jL , α (k) jl = α (k) 0,jl + N (k) jl .<label>(12) where α (k)</label></formula><p>j is updated by adding data counts to prior counts α (k) 0,j , and</p><formula xml:id="formula_27" coords="9,379.61,263.80,19.47,12.24">N (k)</formula><p>jl is defined as</p><formula xml:id="formula_28" coords="9,244.16,290.79,273.96,27.38">N (k) jl = N ∑ i=1 p(c (k) i = l)E t [t i = j]<label>(13)</label></formula><p>i.e. the number of times that classifier k has assigned value l to a document of class j. The expectation required for ( <ref type="formula" coords="9,152.94,341.08,3.87,8.64" target="#formula_16">8</ref>) is given by</p><formula xml:id="formula_29" coords="9,224.33,362.43,293.78,27.38">E ln π (k) jl = Ψ α (k) jl -Ψ L ∑ m=1 α (k) jm .<label>(14)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Two-Stage Bayes Classifier</head><p>The traditional approach to classification is two-stage. In the first stage labelled training data is used to build models for the probability of each class and the probability of features conditioned on each class.</p><p>The second stage uses this model to infer class probabilities of unlabelled documents. We assume that the true label t is generated from a multi-nomial distribution with probability κ: p(t = j | κ) = κ j . We also assume that the observed features c are binary so that c i = 1 indicates the presence of feature i in a document and c i = 0 indicates its absence. Thus, the observed features are generated from binomial distributions dependent on the class of the true label with parameters β: p(c i = b | t = j, β) = β jib . The parameters β have Beta prior distributions with hyperparameters µ and κ have Dirichlet prior distributions ν. Values for µ and ν are inferred from the training data as we will demonstrate. Given some test (or unlabelled) document the distribution over the true label t * of this document given the features c * for that document is,</p><formula xml:id="formula_30" coords="9,126.50,568.25,358.04,74.89">p(t * = j | c * , µ, ν) = π κ p(c * | t * = j, β)p(t * = j | κ)Be(β | µ)Dir(κ | ν)dβ dκ = β p(c * | t * = j, β)Be(β | µ)dπ κ p(t * = j | κ)Dir(κ | ν)dκ = ∏ i β jib β jib Be(β | µ)dβ κ κ j Dir(κ | ν)dκ</formula><p>In the training stage, the labelled data is used to infer the expected likelihoods β and class probabilities κ. For any variable θ and multi-variate φ, θBe(θ | •)dθ and φDir(φ | •)dφ are the means of a Beta and Dirichlet distribution, respectively. Assuming uninformative priors for β and κ and training data {t, c}, the posterior means are:</p><formula xml:id="formula_31" coords="10,125.59,145.39,355.14,33.33">β jib Be(β | µ(t, c))dβ = N (i) jb + 1 ∑ 1 d=0 (N (i) jd + 1) , κ j Dir(κ | ν(t, c))dκ = N j + 1 ∑ k (N k + 1)</formula><p>where</p><formula xml:id="formula_32" coords="10,126.46,190.17,17.80,12.24">N (i)</formula><p>jb is the number of documents labelled j that contain feature c i = b in the training data, {t, c}, and N j is the number of documents labelled j.</p><p>Stage two is the prediction phase and for test features c * from a document the probability that the document is class j is,</p><formula xml:id="formula_33" coords="10,176.17,249.23,232.32,34.84">p(t * = j | c * , µ, ν) = ∏ i   N (i) j c i + 1 ∑ 1 d=0 (N (i) jd + 1)   N j + 1 ∑ k (N k + 1)</formula><p>.</p><p>In summary, we can determine the posterior document class probability, p(t * = j | c * , µ, ν) exactly and efficiently using only the sufficient statistics of Beta and Dirichlet distributions.</p><p>6 Selecting Documents to Pass to the Crowd</p><p>We aimed to maximize the information gained from crowdsourcing by choosing documents with particular features, using approximate methods to reduce computational expense. Each time we receive a set of labels from the crowd, we must select n more documents to label. Documents may be labelled multiple times as the turkers are not reliable. Optimally, we would select the set of n documents that maximise the expected information gain over the set of all documents. However, to calculate the expected information gain, we must re-run the classifier for each of the possible labels we could receive for every combination of n documents. This becomes prohibitively expensive with more than a few documents, so we turn to approximate methods. Learning the label of a document affects the counts N j and N (k)</p><p>jl in <ref type="bibr" coords="10,462.93,450.56,16.60,8.64" target="#b9">(10)</ref> and <ref type="bibr" coords="10,499.03,450.56,15.27,8.64" target="#b11">(12)</ref>. First, we consider the information gain I(t i ; c (k)</p><p>x ) about the topic of a single document:</p><formula xml:id="formula_34" coords="10,99.27,488.01,418.84,53.06">E[I(t i ; c (k) x )] ≤ J ∑ j=1 -p(t i = j) ln p(t i = j) (15) If E[I(t i ; c (k)</formula><p>x )] is low, we assume that the overall information gain for all documents E[I(t; c (k)</p><p>x )] is unlikely to be high as we expect to make only small updates to the counts N j and N (k) jl given the new label. Therefore we make the document selection problem tractable by considering n f ilter documents with highest E[I(t i ; c (k)</p><p>x )] &gt; θ. The assumption requires that the documents are evenly dispersed in feature space so that we do not include only outliers. We use a further approximation to (15) and identify most of the documents with high entropy by finding those with the lowest probability for their most likely class.</p><p>Information gain from labelling a document i is higher when we have few previous examples of the features of i. Therefore, we can choose documents with different sets of features to explore the feature space fully. To select maximally different documents, we apply k-means clustering to group the documents according to their features, then select a document from each cluster with approximate highest entropy. This way, each document is selected to reduce entropy significantly for all documents in its cluster. If some clusters are much larger than others, this method can be sub-optimal as the information gain for a small cluster may be less than from labelling a second document in a larger cluster. However, in this application, features are generated to give a reasonable distribution across documents. Although this method is highly approximate, we found a noticeable improvement over random selection. To summarise, the steps of the algorithm are as follows.</p><p>1. Receive a set of labels from the crowd.</p><p>2. Run the classifier over current set of data to obtain probabilities of topics for all documents. x ) upper bound using the probabilities of the most probable class for each document.</p><p>4. Select the n f ilter documents with the highest approximate information gain.</p><p>5. Cluster the n f ilter documents by features using k-means into n clusters clusters 6. From each cluster, select the document with the highest approximate information gain.</p><p>7. Send the selected documents to the crowd and repeat the process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results</head><p>Fourteen out for forty two turkers had a trust value which exceeded the cut-off of 0.65 and the Gold standard test cost $20 dollars. The trustworthy turkers classified 2500 documents (i.e. 16% of the corpus) within 4 hours at a cost of between $0.03 and $0.08 per document. The total spend was $210. However, less than five turkers completed most tasks and one strategic turker was blocked. Since workers got bored over time we issued a bonus of $3 to complete the task to a deadline.</p><p>Using the crowdsourced labelled documents as training data we compared IBCC to the traditional two-stage Bayes classifier on the TREC 2012 crowdsourcing track dataset, which contained 18260 topicdocument pairs. Within each pair, the classifiers calculated the relevance of the document to the topic. IBCC outperformed the alternative classifier. The area under curve (AUC) of the Receiver Operating Characteristic for IBCC was 0.806 against 0.774 for the two stage classifier. The AUC for each individual topic and for each classifier is shown in Figure <ref type="figure" coords="11,287.46,453.66,3.74,8.64" target="#fig_5">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Discussion and Conclusions</head><p>We concluded that Amazon Turk may not be the best approach to crowdsourcing the labelling of documents with a small set of topics when the corpus contains a large number of irrelevant documents. In this context, there is a need to maintain attention levels, for example through Gamification (or GWAP-based, Games With A Purpose) of the task, whereby the task is re-written as a game.</p><p>We also concluded that the IBCC classifier was about 4% more accurate at inferring the class of each document than the traditional two-stage classifier. There are two reasons for this difference in performance. First, the two-stage approach uses only the labelled document data to infer the classifier model parameters. However, the IBCC uses the test data (i.e. the unlabelled data) as well as the labelled data to infer the classifier model parameters. Thus, although the test data is unlabelled the features can provide a strong indication of the class membership. Consequently, this information provided by the test data can be used along with the labelled data to provide a more accurate model of the class prior and feature-class likelihood than would be possible using the two-stage approach.</p><p>The second advantage of IBCC is that it models the unreliability of crowdsourced labels compared to the ground truth. In contrast, the class labels referred to within the two-stage model are the class labels provided by the turker. Thus, the feature-class likelihood is interpreted as the probability of a feature occurring in a document given the turker has labelled the document as belonging to a class. The two-stage model, as formulated in this chapter, cannot make explicit reference to the ground-truth document labels as, in the TREC challenge data set, there is no training data labelled with the ground truth. Consequently, for our two-stage classifier to provide accurate predictions of the document labels we must ensure that the crowd's responses are statistically similar to the ground truth dictated by the NIST committee as we have no opportunity to filter out untrustworthy turkers using the two-stage approach. Thus, the initial filtering of trustworthy turkers described in this chapter is a critical component of the two-stage approach. This paper describes our approach to solving TREC crowdsourcing challenge of 2012, and demonstrates each of the algorithmic components required for a successful system, demonstrated by our placement as 2nd out of 17 participating groups in terms of AUC curves. We intend to revisit our solution and produce an integrated design for the components of the system based around the IBCC model. For example, using IBCC to derive the trust values for workers. The system also collected confidence responses, and future work could consider how to exploit these with extensions to IBCC.</p><p>We aim to apply our approach to more challenging hard/soft data fusion problems, again in collaboration with Southampton University. Specifically, we will apply these algorithms to the Ushahidi data set. This dataset is particularly relevant to Orchid it is an example of a scenario in disaster recovery which is one of Orchids application domains. Examples of soft information in Ushahidi setting are human translations of free-text to constrained text (i.e. feature-spaces) and examples of hard data are the times and GPS locations of events.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,157.79,307.27,301.81,9.46;5,152.69,108.86,312.00,182.00"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Trust levels of the 42 turkers that performed our gold tasks.</figDesc><graphic coords="5,152.69,108.86,312.00,182.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,514.24,458.14,3.87,8.64;5,99.27,489.59,418.85,8.96;5,99.27,501.55,418.84,8.96;5,99.27,513.50,418.84,8.96;5,99.27,525.46,418.84,8.96;5,99.27,537.41,327.16,8.96"><head></head><label></label><figDesc>) where p(r = j | [s, d]) is drawn from a beta distribution, i.e. r is binomial distributed, and p([s, d] | t = j) is drawn from a Dirichlet, i.e [s, d] is multinomial distributed. The turker's response pair [s, d] can take one of four values: cc, correct and confident labelling in which case s = j and d = c; ic, incorrect and confident labelling with s = ¬j and d = c; cn, correct but unconfident labelling in which case s = j and d = n and in, incorrect and unconfident labelling in which case s = ¬j and d = n.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,366.65,337.23,10.38,6.47;7,366.65,345.55,2.98,6.47;7,381.36,340.74,136.76,8.96;7,99.27,355.58,221.31,8.96;7,320.58,352.08,10.38,6.47;7,320.58,360.39,2.98,6.47;7,335.32,355.58,123.24,8.96;7,458.56,352.08,10.38,6.47;7,458.56,360.39,2.98,6.47"><head></head><label></label><figDesc>values l = 1..L, where L is the number of topics. A feature k can have values c (k) i of either 0 or 1. The value c (k) i</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,236.51,377.98,10.38,6.47;7,236.16,386.54,6.58,6.47;7,249.88,381.80,268.23,8.64;7,99.27,397.97,53.86,8.99;7,153.51,394.50,10.38,6.47;7,153.51,402.81,3.48,6.47;7,167.33,397.97,262.26,8.99;7,429.59,394.50,10.38,6.47;7,429.59,403.10,9.67,6.39;7,442.93,398.00,19.34,8.74;7,462.31,394.50,10.38,6.47;7,462.27,403.10,13.78,6.39;7,476.56,398.00,22.42,8.74;7,499.02,394.50,10.38,6.47;7,498.98,403.21,15.88,6.39;7,515.35,398.00,2.77,8.74;7,99.27,414.40,231.04,10.04;7,330.68,410.93,10.38,6.47;7,330.68,419.25,3.48,6.47;7,343.81,414.43,174.31,9.08;7,105.91,431.33,6.80,8.77;7,113.08,427.86,10.38,6.47;7,113.08,436.17,3.48,6.47;7,123.95,431.33,287.49,9.93;7,411.44,427.86,10.38,6.47;7,411.44,436.46,14.36,6.71;7,426.73,431.36,91.39,8.96;7,99.27,445.94,246.10,8.64"><head></head><label></label><figDesc>jl . IBCC assumes conditional independence between base classifiers. Parameters π (k) j and κ have Dirichlet prior distributions with hyper-parameters α ] and ν = [ν 0,1 , ...ν 0,J ] respectively. We refer to the set of π (k) j for all base classifiers and all classes as Π = π (k) j |j = 1...J, k = 1...K and also denote the hyper-parameters A 0 = α (k) 0 j |j = 1...J, k = 1...K . The joint distribution over all variables for the IBCC model is</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="8,72.00,267.28,473.39,9.46;8,72.00,280.83,374.04,9.46;8,190.35,114.54,229.35,136.33"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Graphical Model for IBCC. The shaded node represents observed values, circular nodes are variables with a distribution and square nodes are variables instantiated with point values.</figDesc><graphic coords="8,190.35,114.54,229.35,136.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="11,110.35,202.19,94.22,9.73;11,204.56,198.69,10.38,6.47"><head>3 .</head><label>3</label><figDesc>Approximate I(t c ; c (k)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="12,72.00,383.30,473.39,9.46;12,72.00,396.85,166.53,9.46"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: AUC for each of the ten topics within the TREC 2012 challenge problem. Shown are the AUCS for the IBCC and the two-stage approach.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We gratefully acknowledge funding from the <rs type="funder">UK Research Council EPSRC</rs> for project ORCHID, grant <rs type="grantNumber">EP/I011587/1</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_2mUbENZ">
					<idno type="grant-number">EP/I011587/1</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="13,121.33,199.68,369.12,8.82" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<title level="m" coord="13,271.94,199.68,119.10,8.59">Modern Information Retrieval</title>
		<imprint>
			<publisher>Addison Wesley</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,121.33,215.62,396.79,8.82;13,121.33,227.58,247.88,8.82" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,237.10,215.80,211.57,8.64">Learning to extract information by linguistic analysis</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fabian</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Leila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,478.64,215.62,39.48,8.59;13,121.33,227.58,162.48,8.59">Workshop on Ontology Population at ACL/COLING</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="18" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,121.33,243.52,396.79,8.82;13,121.33,255.65,22.42,8.64" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,193.55,243.70,151.83,8.64">Wordnet: a lexical database for english</title>
		<author>
			<persName coords=""><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,351.83,243.52,57.89,8.59">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995-11">November 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,121.33,271.41,396.79,8.82;13,121.33,283.37,181.80,8.82" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="13,406.10,271.41,112.02,8.59;13,121.33,283.37,34.98,8.59">Introduction to Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prabhakar</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hinrich</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Schtze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,121.33,299.49,396.78,8.64;13,121.33,311.26,396.79,8.82;13,121.33,323.40,57.00,8.64" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,317.95,299.49,200.16,8.64;13,121.33,311.44,187.86,8.64">Probabilistic models of information retrieval based on measuring the divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">Gianni</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cornelis Joost</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,319.72,311.26,128.95,8.59">ACM Trans. Information System</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="389" />
			<date type="published" when="2002-10">October 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,121.33,339.16,396.78,8.82;13,121.33,351.11,172.40,8.82" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,340.36,339.34,101.88,8.64">Latent dirichlet allocation</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,450.04,339.16,68.07,8.59;13,121.33,351.11,62.51,8.59">Journal Machine Learning Result</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-03">March 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,121.33,367.23,396.78,8.64;13,121.33,379.01,396.79,8.82;13,121.33,390.96,361.11,8.82" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,342.18,367.23,175.93,8.64;13,121.33,379.19,243.48,8.64">Rumours and reputation: Evaluating Multi-Dimensional Trust within a Decentralised Reputation System</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Reece</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">R</forename><surname>Jennings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,395.61,379.01,122.50,8.59;13,121.33,390.96,293.22,8.59">Proceedings of the Sixth International Joint Conference on Autonomous Agents and Multiagent Systems</title>
		<meeting>the Sixth International Joint Conference on Autonomous Agents and Multiagent Systems</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>In. press</note>
</biblStruct>

<biblStruct coords="13,121.33,406.90,396.79,8.82;13,121.33,418.86,245.59,8.82" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="13,257.08,406.90,261.04,8.82;13,121.33,418.86,49.52,8.59">Bayesian classifier combination. Gatsby Computational Neuroscience Unit</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">C</forename><surname>Kim</surname></persName>
		</author>
		<idno>GCNU-T.</idno>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>London, UK</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="13,121.33,434.98,396.78,8.64;13,121.33,446.76,237.59,8.82" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,459.92,434.98,58.19,8.64;13,121.33,446.93,26.58,8.64">Learning from crowds</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">C</forename><surname>Raykar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">H</forename><surname>Valadez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Florin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bogoni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Moy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,155.93,446.76,80.95,8.59">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1297" to="1322" />
			<date type="published" when="2010-08">August 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,121.32,462.87,396.79,8.64;13,121.33,474.65,396.79,8.82;13,121.33,486.78,66.66,8.64" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,227.10,462.87,291.01,8.64;13,121.33,474.65,207.31,8.82">Stochastic relaxation, gibbs distributions, and the Bayesian restoration of images. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,335.79,474.65,87.59,8.59">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="721" to="741" />
			<date type="published" when="1984-11">November 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,121.32,502.55,396.79,8.82;13,121.33,514.68,227.36,8.64" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="13,164.60,502.55,353.51,8.82;13,121.33,514.68,131.70,8.64">Advances in Neural Information Processing Systems 12, chapter A Variational Bayesian Framework for Graphical Models</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Attias</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="209" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,121.32,530.44,396.79,8.82;13,121.33,542.58,228.10,8.64" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,189.61,530.44,171.84,8.59">Pattern recognition and machine learning</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,374.30,530.62,143.81,8.64;13,121.33,542.58,134.61,8.64">Information Science and Statistics. Springer Science+Business Media</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>LLC, 4 edition</note>
</biblStruct>

<biblStruct coords="13,121.32,558.52,396.79,8.64;13,121.33,570.29,396.79,8.82;13,121.33,582.43,55.89,8.64" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,325.34,558.52,192.77,8.64;13,121.33,570.47,69.72,8.64">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,199.56,570.29,264.74,8.59">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977-01">January 1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,121.32,598.19,396.79,8.82;13,121.33,610.14,266.22,8.82" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Abramowitz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">A</forename><surname>Stegun</surname></persName>
		</author>
		<title level="m" coord="13,296.18,598.19,221.93,8.59;13,121.33,610.14,134.11,8.59">Handbook of Mathematical Functions: with Formulas, Graphs, and Mathematical Tables</title>
		<imprint>
			<publisher>Dover Publications</publisher>
			<date type="published" when="1965-06">June 1965</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
