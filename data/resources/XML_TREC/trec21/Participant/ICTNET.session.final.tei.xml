<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,213.41,74.90,168.43,12.00">ICTNET at Session Track TREC 2012</title>
				<funder ref="#_MSp8Wzm">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder>
					<orgName type="full">NIST</orgName>
				</funder>
				<funder ref="#_9BwhuEZ #_EvYBjAM #_mAqdWZG">
					<orgName type="full">NSF of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,213.41,74.90,168.43,12.00">ICTNET at Session Track TREC 2012</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CDC90254B3B87AB491B2174157E9C2B1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we describe our solutions to the Session Track at TREC 2012. The main contribution of our work is that we implement the learning to rank model to re-rank the documents retrieved by our search engine <ref type="bibr" coords="1,175.80,231.67,12.97,9.96" target="#b1">[2]</ref>. We notice that Huurninket al. <ref type="bibr" coords="1,322.39,231.67,12.61,9.96" target="#b2">[3]</ref> have used learning to rank algorithm to d l s ss f t r s t l st y r's S ss Tr k. D t l k f training data, their model did not outperform substantially than others. I t t v ly w s l st y r's s ss d t f r t the weights of ranking features. Meanwhile, we define several useful features to model session search intent.</p><p>The rest of this paper is organized as follows.We detail our models in section 2. Section 3 describes our experiments,including retrieve system setup,our research structure and our evaluation results. Conclusions are made in the last section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our approach</head><p>In our work, we pose several methods utilizing the session information to improve search engine results. It should be noted that all our methods are used to re-rank the documents retrieved by our search engine only using each session's last query, unlike most of other participants, who usevariant query expansions to get results from Indri. Details of our search engine setup are described in section 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.1Query Expansion</head><p>We use the previous queries in the same session to extend the current query. The final query consists of all the terms both in the historical queries and the current query. Let to stand for previous queries and stands for the current query, then w denotes the weight of the word w in final query q, which is calculated as <ref type="bibr" coords="1,350.84,512.52,11.80,9.96" target="#b0">(1)</ref>.</p><formula xml:id="formula_0" coords="1,120.74,528.00,148.03,9.96">w d w<label>(1)</label></formula><p>Aiming to enhance the importance of the terms occur in the latter query, we set the control parameter d as 0.05.</p><p>We re-rank the documents by calculating the Weighted-BM25 score between the extended query and the retrieved documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.2Virtual Document Model</head><p>Obviously, the ranked list returned by the search engine can serve as a good profile of the search intent. We can use this contextual information to construct the so-called virtual document to model the information need of the user. We simply incorporate the titles and snippets of each past query together.Then we use the cosine similarity between the retrieved document and the virtual document to re-rank the results. Depending on the source of the ranked list, we developtwo methods. Firstly, we use the given session data from the NIST to construct the virtual document. Secondly, we submit the current query of each session to Google and obtain the virtual document based on the first 24 results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">O t z t B s d Us r's Att t T I l st y r's S ss</head><p>Track, BUPT_WILDCAT team achieved the best results in RL4. We simply implement their model <ref type="bibr" coords="2,190.49,106.87,12.49,9.96" target="#b3">[4]</ref> as one of our runs. Parameters are the same value as the BUPT_WILDCAT team used in their work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Learning to Rank</head><p>In this section, we detail the main contribution of our work, using machine learning to model the s r's s r t t. ly t S <ref type="bibr" coords="2,278.21,169.51,12.49,9.96" target="#b4">[5]</ref>  We use various combinations of the features to generate our learning to rank model for different runs. Since Google Virtual Document Model may be consider as using external resource, we design two separate runs, one of which uses the GoogleVD feature, while the other not uses it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We have conducted experiments to verify the effectiveness of our models. In this section, we first describe the search engine and search strategy we used to retrieve the result set of each session.</p><p>Then we detail all our submissions and evaluation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experiment Setup</head><p>We submit the last query of each session to Golaxy <ref type="bibr" coords="2,301.07,484.32,13.02,9.96" target="#b1">[2]</ref>. Our search strategy is to retrieve the initial document set that satisfy the condition that the content filed of each document contains all the terms of the query or the title field contains at least one term, without any stop word removal or stemming. Then we use Waterloo spam r k s r <ref type="bibr" coords="2,319.21,531.12,12.49,9.96" target="#b5">[7]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.3Evaluation Results</head><p>Evaluation results of our submissions at 2012 Session Track are showed in Table <ref type="table" coords="3,434.27,186.31,4.80,9.96" target="#tab_2">3</ref>.The highest score for each experimental condition is indicated in bold. According to Table <ref type="table" coords="3,419.36,201.91,3.78,9.96" target="#tab_2">3</ref>, we can conclude that our models can significantly improve the performance of a search engine when take advantage of session information. We obtain 80.14% of performance increase when compare our best result (ICTNET12SER3.RL4) with the direct result from our search engine (ICTNET12SER1.RL1). Again, we want to emphasize that all our methods are used to re-rank the documents retrieved by our search engine. In Figure <ref type="figure" coords="3,314.33,279.94,3.78,9.96" target="#fig_0">1</ref>, we simply compare ICTNET12SER3.RL4</p><p>with the median result of RL4 of all participators and observe that nearly 80% of the sessions outperform the median result.  In this paper, we presented several approaches to verify whether a retrieve system can use increasing amounts of information prior to a query to improve effectiveness for that query. Each one of our methods models a special aspect of the relationship between the query and the corresponding document. Thus, when combining all these models with a learning to rank algorithm, we can expect significantly improvement in effectiveness. Experiment results confirm our expectation impressively. We have achieved 80.14% of performance increase compared with the result from our search engine.</p><p>For the future work, w w ll s d r r r t r f t r s t d l s r's s r t t including URL and anchor information. Besides, we will investigate other learning to rank algorithms and similarity measures. Feature selection and parameter optimization will also be applied to achieve better performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,90.02,641.79,417.08,9.96;3,90.02,657.39,242.11,9.96;3,90.02,672.99,58.28,9.96;3,90.00,423.65,415.30,210.49"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Comparison between ICTNET12SER3_RL4 and Median_RL4 on ndcg@10 for all sessions, nearly 80% of the sessions outperform the median result 4 Conclusions</figDesc><graphic coords="3,90.00,423.65,415.30,210.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,90.02,531.12,409.70,230.45"><head>Table 2 :</head><label>2</label><figDesc>The research structure and models implemented in each runs are listed in Table2. Methods in all runs</figDesc><table coords="2,333.96,531.12,144.94,9.96"><row><cell>t f lt r d</cell><cell>ts w t "f s " s</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,90.02,326.74,370.49,74.40"><head>Table 3 :</head><label>3</label><figDesc>Results on 2012 Session Track, in terms of NDCG@10</figDesc><table coords="3,90.02,343.42,370.49,57.72"><row><cell></cell><cell>RL1</cell><cell>RL2</cell><cell>RL3</cell><cell>RL4</cell></row><row><cell>ICTNET12SER1</cell><cell>0.1586</cell><cell>0.2043</cell><cell>0.2039</cell><cell>0.2392</cell></row><row><cell>ICTNET12SER2</cell><cell>0.2144</cell><cell>0.2168</cell><cell>0.2732</cell><cell>0.2827</cell></row><row><cell>ICTNET12SER3</cell><cell>0.2481</cell><cell>0.2476</cell><cell>0.2640</cell><cell>0.2857</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5">Acknowledgements</head><p>We would like to thank all organizers and assessors of <rs type="institution">TREC</rs> and <rs type="funder">NIST</rs>. This work is sponsored by <rs type="funder">NSF of China</rs> Grants No. <rs type="grantNumber">60933005</rs>, No. <rs type="grantNumber">61100083</rs> and No.<rs type="grantNumber">61173064</rs>, and by <rs type="programName">242 Program</rs> of China Grants No.<rs type="grantNumber">2011F65</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_9BwhuEZ">
					<idno type="grant-number">60933005</idno>
				</org>
				<org type="funding" xml:id="_EvYBjAM">
					<idno type="grant-number">61100083</idno>
				</org>
				<org type="funding" xml:id="_mAqdWZG">
					<idno type="grant-number">61173064</idno>
					<orgName type="program" subtype="full">242 Program</orgName>
				</org>
				<org type="funding" xml:id="_MSp8Wzm">
					<idno type="grant-number">2011F65</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,104.66,262.90,125.70,9.96" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,104.66,262.90,125.70,9.96">Session Track 2011 Overview</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,104.66,278.50,175.74,9.96" xml:id="b1">
	<monogr>
		<title level="m" coord="4,104.66,278.50,175.74,9.96">ICTNET at Web Track 2011 Ad-Hoc Track</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,104.66,294.10,262.29,9.96" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="4,104.66,294.10,262.29,9.96">The University of Amsterdam at the TREC 2011 Session Track</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,104.66,309.70,190.47,9.96" xml:id="b3">
	<monogr>
		<title level="m" coord="4,104.66,309.70,190.47,9.96">BUPT_WILDCAT at TREC 2011 Session Track</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,104.66,325.30,376.06,9.96;4,90.02,340.90,222.57,9.96" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<title level="m" coord="4,316.62,325.30,164.10,9.96;4,90.02,340.90,191.20,9.96">Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>the ACM Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>Training Linear SVMs in Linear Time</note>
</biblStruct>

<biblStruct coords="4,104.67,372.10,382.11,9.96;4,90.02,387.70,391.16,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,369.87,372.10,116.90,9.96;4,90.02,387.70,193.46,9.96">Efficient and effective spam filtering and re-ranking for large web datasets</title>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Charles</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,289.92,387.70,89.97,9.96">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="441" to="465" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
