<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,189.72,83.17,215.75,12.64;1,173.76,114.37,247.78,12.64">PRIS at 2012 TREC Medical Track: Query Expansion, Retrieval and Ranking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,123.24,138.71,54.00,9.50"><forename type="first">Jiayue</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,184.79,138.71,30.06,9.50"><forename type="first">Lin</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,221.75,138.71,57.89,9.50"><forename type="first">Shudang</forename><surname>Diao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,286.43,138.71,37.97,9.50"><forename type="first">Yukun</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,330.97,138.71,48.27,9.50"><forename type="first">Runnan</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,385.92,138.71,43.17,9.50"><forename type="first">Weiran</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,436.81,138.71,35.40,9.50"><forename type="first">Jun</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,189.72,83.17,215.75,12.64;1,173.76,114.37,247.78,12.64">PRIS at 2012 TREC Medical Track: Query Expansion, Retrieval and Ranking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">48378CBC905679B44A0EB378DFAA5F86</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The official datasets are XML format so we have to parse them before indexing. We choose Lucene as our tool for indexing and searching ,we select the Jakarta-commons-Digester (the following we referred to as digester) to parse the xml documents. The xml document is processed by the Digester to be a java object and then we can get the fields that we would use from the java object .In addition, we also process the tag "report_text" in the xml documents so that we can get the age and sexuality information which are very important fields for searching task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Negation Detection</head><p>People always find some phrases like "did not have head pain" or "there is no pain in your leg"in the medical diagnosis reports .These phrases will make some boring troubles in the medical text retrieval. For example, when we want to find someone who have a headache we may get a report like this This patient is a**AGE[in 50s]-year-old male with a past medical history of multiple transplants including small bowel, liver, and pancreas in 1998 and status post kidney transplant in 2006, presents with fever. The patient states he woke this morning and thought to have fevers and chills. He also has had some vomiting and diarrhea. Denies any belly pain. He states he feels a little short of breath. He denies any chest pain. No sore throat. No headache..... In fact, this patient just has fevers and chills. To solve this problem, we use the famous NegEx algorithm .NegEx [5]  algorithm is mostly known to Text Mining researchers for finding terms used in negative senses. While, there is a java class to implement Wendy Chapman's NegEx algorithm. This class' author is Junebae Kye .On the base of this class, we write a program to finish the negation detection work and the result show us that this method takes us a better performance. 2 Indexing Model main component is a search engine based on Apache Lucene. Lucene is a powerful Java library that lets you easily add document retrieval to any application. In recent years Lucene has become exceptionally popular and is now the most widely used information retrieval library We utilized Lucene for indexing purpose. Lucene provided the function to achieve this goal. Documents and fields are Lucene's fundamental units of indexing and searching. A document is Lucene's atomic unit of indexing and searching. It is a container that holds one or more fields, which in turn contain the real content. Each field has a name to identify it, a text or binary value, and a series of detailed options that describe what Lucene should do with the field value. We use the "age","sex","icd9 code"...as the fields to build the index. This process is not very difficult.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Concept-based Query Expansion</head><p>In medical search, we have the challenge of 'semantic gap', that is, the vocabulary mismatch between relevant documents and topic description. A large part of the reason is the diversification of expression in the medical field. For instance, "Hypertension" in a report has the same meaning with "high blood pressure" in the topic plain text. The presence of a certain organism in a report may also denote a certain disease described in a topic. So it's import for us to expand the query with expressions that refer to the same meaning. We expanded our queries with the help of UMLS (Unified Medical Language System) meta-thesaurus and SNOMED medical domain knowledge. First, we used the Meta-Map program to extract UMLS Meta-thesaurus concepts associated with the original query. Second, we mapped the concepts to their SNOMED-CT equivalents using the UMLS Meta-thesaurus. Then, we had our query concepts expanded with SNOMED-CT descriptions. Now, each query concept is replaced by a group of thesauruses. We call it concept group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Queries Construction</head><p>Queries were constructed for Lucene to search different texts against various indexed fields. Each query is consisted of a collection of filters and clauses containing subqueries. (Each subquery contained search terms for only one field, and most of the subqueries had a boost Table <ref type="table" coords="2,251.03,419.51,3.96,9.50">1</ref>. Query fields and relations applied to them in order to improve precision by keeping certain clauses from dominating the scoring algorithm.) In different runs, we had different ways to generate the boosts. Table <ref type="table" coords="2,454.56,388.43,5.28,9.50">1</ref> shows the fields and their relations to the parent-query. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Retrieval</head><p>We use Lucene to realize our retrieval. And except for the basic run, our retrieval contained two stages. On the first stage, we retrieve relative reports using the queries generated on the previous step. Then we map the results to visit ids. We set a threshold of 15. When the number of result visit ids was less than the threshold, and no less than one subquery got visit id number which less than 100, we abandoned the subquery which got least visit ids to relax the requirements. Then we go into the second stage of retrieving. We looped this process until we got visit id number greater than the set threshold, or when we had only one subquery left.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Learning to rank</head><p>In our buptpris_Lrank run, we tried to make the ranking of our results more meaningful. We refer to a semi-supervised approach to learing to rank that uses Boosing <ref type="bibr" coords="3,381.76,247.90,13.65,9.50" target="#b0">[1]</ref>. We have 5 features for learning: the Lucene average scores for fields of contents, chief_complaint, admit_diagnosis, sex and age. By this way, we got more suitable boosts for queries.</p><p>Because of the limit of deadline, we did't have much research on this method. But it did improve our ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Our Runs</head><p>The descriptions of our runs: buptpris_Base: A baseline using Lucene,with query expanded by several tools including MetaMap,UMLS Metathesaurus and SNOMED,and ICD9 information mining.The weight of each indexed field is defined by personal experiences.Result scores computed with lucene retrival scores. buptpris_Int: To make improvement to buptpris_Base,this run split a query into several subquerys,and compute the intersection of their retrival results.At the same time,this run include a algorithm to deal with the topics returning few results. buptpris_Cscore: The buptpris_Cscore run considers "contents" field exclusively when getting the final score of each returned visit.With intersection algorithm and few-result-deal algorithm the same as buptprisInt. buptpris_Lrank: A try to improve the ranking with learning to rank algorithm on the basis of buptpris_Int run.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,178.19,435.59,25.53,9.50;2,384.24,435.59,39.64,9.50;2,90.00,451.67,35.07,9.50;2,303.00,451.67,88.17,9.50;2,90.00,467.75,68.21,9.50;2,303.01,467.75,88.17,9.50;2,90.00,483.95,68.79,9.50;2,303.01,483.95,101.61,9.50;2,90.00,500.03,14.64,9.50;2,303.00,500.03,29.24,9.50;2,90.00,516.11,14.03,9.50;2,303.01,516.11,29.24,9.50;2,90.00,532.19,415.18,9.50;2,89.99,547.78,192.93,9.50;2,89.99,563.38,415.36,9.50;2,89.99,578.98,415.45,9.50;2,89.99,594.58,415.36,9.50;2,89.99,610.17,63.95,9.50;2,223.07,719.37,148.91,9.50"><head></head><label></label><figDesc>use negEx to detect the negative contents in the topics. For negative contents, we make the relation of the relate subqueries MUST_NOT. And each subquery referring to field of contents and chief_complaint consisted of several concept group subqueries connecting with relation MUST. Each concept group subquery was made up of several phrases included in the group with relation SHOULD. Graph 1 shows the construct of one example query. Graph 1. Query Construct Example</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,102.89,622.89,402.49,8.10;3,90.00,638.37,223.52,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,251.40,622.89,240.65,8.10">Ranking Refinement and Its Application for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hamed</forename><surname>Valizadegan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,90.00,638.37,195.15,8.10">International Conference on World Wide Web (WWW)</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
