<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,170.42,83.07,256.22,12.64">10.1162/jmlr.2003.3.4-5.993</title>
				<funder ref="#_xbFntjy">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_nxaPUyN #_yfJ2Ynj #_uRA2NzH">
					<orgName type="full">NSF of China</orgName>
				</funder>
				<funder>
					<orgName type="full">NIST</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Test accounts</publisher>
				<availability status="unknown"><p>Copyright Test accounts</p>
				</availability>
				<date type="published" when="2000">2000</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,128.54,107.46,49.24,8.96"><forename type="first">Zilong</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,192.17,107.46,51.70,8.96"><forename type="first">Yuanhai</forename><surname>Xue</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,258.75,107.46,53.02,8.96"><forename type="first">Xiaoming</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,319.63,107.46,43.40,8.96"><forename type="first">Hongbo</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,370.24,107.46,29.97,8.96"><forename type="first">Yue</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,408.43,107.46,53.13,8.96"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,170.42,83.07,256.22,12.64">10.1162/jmlr.2003.3.4-5.993</title>
					</analytic>
					<monogr>
						<title level="j" type="main">CrossRef Listing of Deleted DOIs</title>
						<title level="j" type="abbrev">CrossRef Listing of Deleted DOIs</title>
						<idno type="ISSN">0003-6951</idno>
						<imprint>
							<publisher>Test accounts</publisher>
							<biblScope unit="volume">1</biblScope>
							<date type="published" when="2000" />
						</imprint>
					</monogr>
					<idno type="MD5">07FE30B5CBD1DC8A909F8256BC9EC77B</idno>
					<idno type="DOI">10.1162/jmlr.2003.3.4-5.993</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we report our experiments at Diversity task, Web Track 2012. In this year, we attempt to use query expansion and topic model such as LDA <ref type="bibr" coords="1,317.23,183.03,7.56,5.83" target="#b3">[5]</ref> to get subtopics. And an model based on xQuAD <ref type="bibr" coords="1,121.58,198.51,10.80,5.83" target="#b6">[10]</ref> was used to re-rank the ad-hoc search results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="596.04" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="596.04" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="596.04" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The TREC Web Track explores and evaluates web retrieval technology over large collections of web data. As an inherently indistinct representative of more complex or ambiguous information needs, keywords submitted to a web search engine are often ambiguous. Such a query may cover many different aspects. Traditional IR systems use document-query relevance as the only measure of relevance to rank the web pages. Excessive redundancy web Pages of same aspects may be ranked higher. The goal of diversity task is to return a ranked list of pages that together provide complete coverage for a query, while avoiding excessive redundancy in the result list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Data Preparation</head><p>In this task, we used the search results from the ad-hoc task with the same method and settings. Then we cluster the search results and re-rank them according to our clustering results.</p><p>The search result for a single query from the ad-hoc task is a list of structured data; each contains a web TREC-ID and the extracted main body of content. Since the extracting work has filtered most spam, the main body is still raw. So before clustering, we did some usual preprocessing on our web content.</p><p>First we tokenize the text and remove all the punctuation, digits and tokens whose length is no more than 2. Then, we remove all the stop-words according a stop-word list. At last, we stem the words on the content using a tool called lib-stemmer library <ref type="bibr" coords="1,291.53,463.28,7.56,5.83">[1]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Clustering</head><p>Clustering is a usual and simple way to get the aspects of the original topic explicitly from the search results themselves. There are many text clustering methods can be applied, such as K-means, PAM, Hierarchy Clustering, OPTICS and so on. The year before last year, we applied a developed K-means algorithm which is called Bisecting K-means <ref type="bibr" coords="1,274.37,541.04,7.56,5.83" target="#b0">[2]</ref> . Last year, we found an obvious drawback of bisecting k-means. It's a hard clustering method which is usually not true in the real scene. In last year's diversity task, we use a soft clustering called fuzzy c-means <ref type="bibr" coords="1,296.45,572.84,7.68,5.83" target="#b1">[3]</ref> to re-cluster the documents based on the result of bisecting k-means. To our strange, as the result, it only improved the result slightly in our experiments. This year, we find an interpretation. In our diversity model, what we consider about is the probability of document with every individual aspect of origin topic. In clustering, it is the distance between the document and every individual clustering center. We don't care about which clustering center a document belong to, but the similarity to every clustering center. So a soft re-clustering not improving remarkably is reasonable.</p><p>In this year, we abandon the traditional clustering ways and try the topic model. A topic model is a type of statistical model for discovering the abstract "topics" that occur in a collection of documents. An early topic model was described by Papadimitriou, Raghavan, Tamaki and Vempala in 1998 <ref type="bibr" coords="1,470.86,711.95,7.56,5.83" target="#b2">[4]</ref> . In our diversity task, we use the most common topic model currently, Latent Dirichlet allocation (LDA). LDA was first presented as a graphical model for topic discovery by David Blei, Andrew Ng, and Michael Jordan in 2002 <ref type="bibr" coords="2,153.74,74.05,7.56,5.83" target="#b3">[5]</ref> . Using LDA, given the result documents from a single query, we can easily get subtopic-document distributions, i.e., P (topic|document) by setting number of sub-topics.</p><p>There are many open source implementations of LDA. Such as "Latent Dirichlet Allocation in C" <ref type="bibr" coords="2,494.98,105.03,7.68,5.83">[6]</ref> , "GibbsLDA" <ref type="bibr" coords="2,143.18,120.51,7.56,5.83">[7]</ref> , "JGibbLDA" <ref type="bibr" coords="2,210.05,120.51,7.68,5.83">[8]</ref> and so on. Finally we choose JGibbLDA, A Java Implementation of Latent Dirichlet Allocation using Gibbs Sampling for Parameter Estimation and Inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Query Expansion</head><p>Query expansion (QE) is the process of reformulating a seed query to improve retrieval performance in information retrieval operations <ref type="bibr" coords="2,219.77,183.39,7.56,5.83" target="#b4">[9]</ref> . In diversity task, we can consider each query expansion as an aspect or sub-topic of the origin query. According to our experience in TREC 2009, TREC 2010 and TREC 2011, query expansion is effective to improve the result. So we also try this method in TREC 2012.</p><p>We expanded the queries by commercial search engines Google. Actually, we put each query into the search engine and extracted the items of "Related Searches" on the result page. Usually there are total 8 items. We considered each item as one sub-topic. We treat these expansions as new queries to retrieve documents using the identical model in the ad-hoc task. For each result document by the originating query from ad-hoc task, we try to find it in every query expansion's retrieval results, and use the relevance score as the coverage of this document to the sub-topic.</p><p>But this year, maybe we didn't get good query expansions, or maybe there is something wrong with the experiment. We get many zero values when compute the coverage of this document to the sub-topic.</p><p>And the final result is not as good as in former years. So at last, we didn't use any query expansion result in our submitted run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Re-ranking Model</head><p>In the diversity task, our goal is re-ranking the documents which make them look diversified. The sub-topics from LDA or query expansion just provide guidance and supports when re-ranking. For how to re-ranking, our model is based on xQuAD <ref type="bibr" coords="2,274.97,432.66,10.80,5.83" target="#b6">[10]</ref> proposed by Santos in 2010, the same as last year. In last year's task, we changed the original probability formula and gained a new formula. This year, we use both formulas in our experiment. The result is shown in the next section. We also try some modification, but none of them showed a remarkable outperformance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Result</head><p>In TREC 2011, we submitted three runs for diversity task. We do the parameter training on the data from the past three years (TREC2009, TREC2010, and TREC2011). All the three runs have the same model and framework. But there is still some difference in the details. In run 1, we didn't do any preprocessing before clustering using LDA, no stop-words removing, stemming or normalization. We didn't try any modification on the original model, just naive LDA and xQuAD. In run 2, we added stop-words removing, stemming and normalization, using our modified formula last year instead of the original formula in xQuAD. In run 3, we abandon word stemming before clustering because we found it express better in the past three years without stemming. And we apply the original formula back. RUN ERR-IA@20 nERR-IA@20 α-DCG@20 α-nDCG@20 The results are listed in Table <ref type="table" coords="2,211.97,716.78,3.77,8.96" target="#tab_0">1</ref>. We can observe that run 1 and run 3 have a better expression than run 2. Run 1 performs slightly better than run 3 in ERR-IA@20 and nERR-IA@20. But run 3 is better in α-DCG@20 andα-nDCG@20.</p><formula xml:id="formula_0" coords="2,84.26,652.51,61.20,9.96">ICTNET11DVR1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion and Future Work</head><p>We describe our methods and experiment of the diversity task in this report above. This year, we apply a new clustering method which is LDA model to cluster the documents and used the xQuAD model to re-rank them. From the results we can see: 1. From the experiment result of the 4 years data, LDA and xQuAD model has effectively performed in document diversity; 2. The change in the probability formula of xQuAD doesn't influence the perform much; 3. Without stemming before LDA clustering outperform with stemming. To the third point, we think it may be the reason that we set the same sub-topics number in the LDA model for every query. But in real scenes, for a different query, the number of aspects (sub-topics) may vary greatly.</p><p>Usually we all don't know the number of aspects of a query, using LDA may face a risk: how to set the topic number before training? In the future we will try to find some methods to deal with the problems.</p><p>And we will also attempt to improve the present diversity model in our future experiment.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,84.26,652.51,369.69,57.96"><head>Table 1 . Performance of our runs in TREC 2011 diversity task</head><label>1</label><figDesc></figDesc><table coords="2,84.26,652.51,369.69,42.00"><row><cell></cell><cell>0.3257</cell><cell>0.3466</cell><cell>0.4001</cell><cell>0.4223</cell></row><row><cell>ICTNET12DVR2</cell><cell>0.3183</cell><cell>0.3396</cell><cell>0.3950</cell><cell>0.4175</cell></row><row><cell>ICTNET12DVR3</cell><cell>0.3243</cell><cell>0.3448</cell><cell>0.4012</cell><cell>0.4239</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="8.">Acknowledgements</head><p>Thank all the organizers of TREC 2012 and <rs type="funder">NIST</rs>. Thank all the participants and assessors. We really appreciate of your efforts for judging the runs. This work is sponsored by <rs type="funder">NSF of China</rs> Grants No. <rs type="grantNumber">60933005</rs>, No. <rs type="grantNumber">61100083</rs> and No.<rs type="grantNumber">61173064</rs>, and by <rs type="programName">242 Program</rs> of China Grants No.<rs type="grantNumber">2011F65</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_nxaPUyN">
					<idno type="grant-number">60933005</idno>
				</org>
				<org type="funding" xml:id="_yfJ2Ynj">
					<idno type="grant-number">61100083</idno>
				</org>
				<org type="funding" xml:id="_uRA2NzH">
					<idno type="grant-number">61173064</idno>
					<orgName type="program" subtype="full">242 Program</orgName>
				</org>
				<org type="funding" xml:id="_xbFntjy">
					<idno type="grant-number">2011F65</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="3,104.90,356.42,404.25,9.96;3,90.02,371.90,186.62,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,264.65,356.42,207.52,9.96">A Comparison of Document Clustering Techniques</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Steinbach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,491.74,356.42,17.41,9.96;3,90.02,371.90,103.42,9.96">KDD Workshop on Text Mining</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="34" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,103.58,387.98,401.43,9.96;3,90.02,403.70,37.55,9.96" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="3,155.42,387.98,248.99,9.96">Pattern Recognition with Fuzzy Objective Function Algorithms</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Bezdek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981-07-31">July 31, 1981</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>1 edition</note>
</biblStruct>

<biblStruct coords="3,105.02,419.30,399.66,9.96;3,90.02,434.90,288.04,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,479.39,419.30,25.28,9.96;3,90.02,434.90,169.39,9.96">Latent Semantic Indexing: A probabilistic analysis</title>
		<author>
			<persName coords=""><forename type="first">Christos</forename><forename type="middle">;</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><surname>Prabhakar</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Tamaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><surname>Hisao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Santosh</forename><surname>Vempala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,269.33,434.90,103.74,9.96">Proceedings of ACM PODS</title>
		<meeting>ACM PODS</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,103.94,450.52,405.06,9.96;3,90.02,466.00,46.16,9.96;3,152.18,466.00,29.47,9.96;3,197.69,466.00,8.32,9.96;3,222.17,466.00,35.20,9.96;3,273.29,466.00,34.90,9.96;3,324.19,466.00,36.31,9.96;3,376.51,466.00,5.05,9.96;3,397.63,466.00,23.78,9.96;3,437.38,466.00,13.07,9.96;3,466.42,466.00,42.59,9.96;3,90.02,481.60,129.76,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="3,446.75,450.52,62.24,9.96;3,90.02,466.00,38.47,9.96">Latent Dirichlet allocation</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Michael</surname></persName>
		</author>
		<idno type="DOI">10.1162/jmlr.2003.3.4-5.993</idno>
	</analytic>
	<monogr>
		<title level="j" coord="3,152.18,466.00,29.47,9.96;3,197.69,466.00,8.32,9.96;3,222.17,466.00,35.20,9.96;3,273.29,466.00,34.90,9.96;3,324.19,466.00,36.31,9.96">Journal of Machine Learning Research</title>
		<editor>
			<persName><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-01">January 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,103.70,545.20,407.71,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="3,302.83,545.20,170.86,9.96">The THISL broadcast news retrieval system</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Abberley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Renals</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,491.02,545.20,20.39,9.96">Proc</title>
		<meeting>null</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="3,90.02,560.68,421.47,9.96;3,90.02,576.28,221.56,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="3,481.54,560.68,29.95,9.96;3,90.02,576.28,118.25,9.96">Section on Query Expansion -Concise</title>
	</analytic>
	<monogr>
		<title level="m" coord="3,90.02,560.68,310.66,9.96">ESCA ETRW Workshop Accessing Information in Spoken Audio, (Cambridge)</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="14" to="19" />
		</imprint>
	</monogr>
	<note>mathematical overview</note>
</biblStruct>

<biblStruct coords="3,109.10,592.36,395.58,9.96;3,90.02,608.08,222.16,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="3,277.85,592.36,226.83,9.96;3,90.02,608.08,56.33,9.96">Exploiting Query Reformulations for Web Search Result Diversification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,162.50,608.08,54.19,9.96">Proc. of WWW</title>
		<meeting>of WWW</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="881" to="890" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
