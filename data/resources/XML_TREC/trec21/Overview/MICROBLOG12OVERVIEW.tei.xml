<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,117.72,71.87,374.28,16.84">Overview of the TREC-2012 Microblog Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,150.22,116.90,65.13,11.06"><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
							<email>ian.soboroff@nist.gov</email>
							<affiliation key="aff0">
								<orgName type="institution">NIST</orgName>
								<address>
									<settlement>Gaithersburg</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,226.15,116.90,57.82,11.06"><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
							<email>iadh.ounis@glasgow.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<settlement>Glasgow</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,294.76,116.90,90.24,11.06"><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
							<email>craig.macdonald@glasgow.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<settlement>Glasgow</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,395.80,116.90,53.62,11.06"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
							<email>jimmylin@umd.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Twitter</orgName>
								<address>
									<settlement>San Francisco</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,117.72,71.87,374.28,16.84">Overview of the TREC-2012 Microblog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E8CEA148197B747069A9331657351A84</idno>
					<note type="submission">1569 automatic yes no no AIrun1 AI ROMA3 0.1994 0.1522 automatic yes no yes uiucGSLIS03 uiucGSLIS 0.1983 0.1717 automatic yes no no IRITbnetK IRIT 0.1983 0.1715 automatic yes no no uwatrrflm UWaterlooMDS 0.1977 0.1742 automatic yes no no uiucGSLIS02 uiucGSLIS 0.1972 0.1751 automatic yes no no cmuPhrE CMU Callan 0.1966 0.1854 automatic yes yes no york12mb4 york 0.1966 0.1694 automatic yes no no indri udel 0.1960 0.1953 automatic no no no IRITbnetKSO IRIT 0.1960 0.1717 automatic yes no no uwcmb12CP waterloo 0.1955 0.1646 automatic no no no uwcmb12NT waterloo 0.1949 0.1657 automatic no no no uwcmb12BL waterloo 0.1944 0.1623 automatic yes no no UNCTQE UNC SILS 0.1938 0.1641 automatic yes no no KLIMLL FUB 0.1932 0.1836 automatic yes no no XMRUN4 XMU PANCHAO 0.1932 0.1575 automatic yes no yes KLIMLP1 FUB 0.1921 0.1949 automatic yes no yes QEWebFB QCRI 0.1921 0.1710 automatic yes no yes prisRun3 BUPT WILDCAT 0.1904 0.1453 automatic yes yes no IBCN2 UGENT IBCN SIS 0.1904 0.1408 automatic yes yes no</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Table <ref type="table" coords="3,76.83,724.32,3.73,8.06">1</ref>: Adhoc runs, sorted by P@30 score, indicating run type (auto/manual), real-time (RT), if linked documents (docs?) and other external information were used (extern?). Continued on next page. Table 2: Table 1, continued Run group P@30 MAP manual? RT? docs? extern? BM25PRF qcri twitsear 0.1898 0.1545 automatic yes no no QEWeb QCRI 0.1881 0.1706 automatic yes no yes gucasQuery GUCAS 0.1876 0.1503 automatic yes no no gucasGen GUCAS 0.1876 0.1344 automatic yes no no KLIM FUB 0.1870 0.1948 automatic yes no no mergedRun qcri twitsear 0.1864 0.1573 automatic yes no no uwcmb12CT waterloo 0.1831 0.1620 automatic yes no no IBCN3 UGENT IBCN SIS 0.1825 0.1399 automatic yes yes no UNCRQE UNC SILS 0.1819 0.1490 automatic yes no no urlContent SCIAITeam 0.1808 0.1465 automatic yes yes no BM25TRF qcri twitsear 0.1802 0.1503 automatic yes no no UNCQE UNC SILS 0.1802 0.1461 automatic yes no no gucasGenReg GUCAS 0.1785 0.1318 automatic yes no no UvAfilter UvA 0.1774 0.1385 automatic yes no no gucasBasic GUCAS 0.1763 0.1476 automatic yes no no BAUjskls BAU 0.1740 0.1527 automatic yes no no XMRUN1 XMU PANCHAO 0.1723 0.1488 automatic yes no no XMRUN2 XMU PANCHAO 0.1723 0.1487 automatic yes no no BLFB QCRI 0.1718 0.1638 automatic yes no no BAUdfree BAU 0.1718 0.1518 automatic yes no no BAUdph BAU 0.1718 0.1510 automatic yes no no BL QCRI 0.1701 0.1512 automatic yes no no csiroQEll112 csiro 0.1616 0.1393 automatic no no no UDInfoMBEx udel fang 0.1616 0.1161 automatic no no yes csiroNE112 csiro 0.1605 0.1363 automatic no no no BM25 qcri twitsear 0.1605 0.1325 automatic yes no no BAUtf BAU 0.1605 0.1320 automatic yes no no uiucGSLIS04 uiucGSLIS 0.1599 0.1259 automatic yes no no RUN3 uog tw 0.1582 0.1297 automatic yes no no UNCTP UNC SILS 0.1559 0.1255 automatic yes no no csiroR112 csiro 0.1542 0.1324 automatic yes no no csiroQEt112 csiro 0.1537 0.1445 automatic no no no timemexp udel 0.1531 0.0987 automatic yes no no IIEIR01 IIEIR 0.1508 0.1127 automatic no no no IIEIR03 IIEIR 0.1508 0.1088 automatic no no no IIEIR04 IIEIR 0.1508 0.1088 automatic no no no IIEIR02 IIEIR 0.1497 0.1073 automatic no no no UDInfoMBCW udel fang 0.1492 0.1161 automatic no no yes UDInfoMBIDF udel fang 0.1475 0.1040 automatic yes no no IBCN1 UGENT IBCN SIS 0.1469 0.1096 automatic yes no no baseline SCIAITeam 0.1390 0.1224 automatic yes no no IRITfdvsmurl IRIT 0.1390 0.0975 automatic yes yes no IBCN4 UGENT IBCN SIS 0.1379 0.1190 automatic yes yes no UDInfoMBTp udel fang 0.1373 0.0960 automatic yes no no aWekaModel SCIAITeam 0.1350 0.1211 automatic yes no yes RUN2 uog tw 0.1333 0.1089 automatic yes no no IRSIISI IRSI 0.1333 0.0544 automatic no no no IRITfdvsm IRIT 0.1311 0.0886 automatic yes no no IRSIISI1 IRSI 0.1311 0.0592 automatic no no no expansion SCIAITeam 0.1282 0.0916 automatic yes no yes IRSIISI2 IRSI 0.1282 0.0508 automatic no no no IRSIISI3 IRSI 0.1260 0.0500 automatic no no no exttempwsf UEdinburgh 0.1226 0.0700 automatic yes no yes RUN1 uog tw 0.1192 0.0978 automatic yes no no exttempws UEdinburgh 0.1192 0.0812 automatic yes no no timemodel udel 0.1169 0.0694 automatic yes no no langluc udel 0.1130 0.0647 automatic yes no no uogTrCIDE uogTr 0.1124 0.0964 automatic yes yes no uwatgclrbase UWaterlooMDS 0.0994 0.0777 automatic yes no no Run group Prec Recl F(0.5) T11SU manual? RT? docs? extern? hitUWT HIT MTLAB 0.6219 0.1740 0.3338 0.4117 automatic yes yes no PRISrun3 PRIS 0.4096 0.5675 0.4071 0.3744 automatic yes yes no PRISrun1 PRIS 0.3445 0.5981 0.3671 0.3615 automatic yes no no uogTrFADmN uogTr 0.4206 0.3370 0.3435 0.3615 automatic yes no no PRISrun2 PRIS 0.3551 0.6273 0.3758 0.3602 automatic yes yes no expansion2 SCIAITeam 0.4405 0.3113 0.3570 0.3588 automatic yes no no csiroQERF111 csiro 0.4781 0.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The Microblog track examines search tasks and evaluation methodologies for information seeking behaviours in microblogging environments such as Twitter. It was first introduced in 2011, addressing a real-time adhoc search task, whereby the user wishes to see the most recent relevant information to the query. In 2012, the realtime adhoc task was changed slightly, and a new filtering task was added. The filtering task models a standing query where the user wishes to see relevant tweets as they are posted.</p><p>For the second year of the track, we reused the Tweets2011 corpus, described below. The corpus is comprised of 16M tweets distributed over two weeks, sampled courtesy of Twitter. The corpus was designed to be a reusable, representative sample of the twittersphere -i.e., both important and spam tweets were included. As the reusability of a test collection is paramount in TREC, we designed the corpus to be obtainable at any time by a researcher interested in conducting experiments. To accomplish this, in 2011, the TREC Microblog track introduced a novel methodology whereby participants sign an agreement for the ids of the tweets in the corpus. Tools are provided that permit the participants to download the corpus directly from Twitter.</p><p>The first Microblog track in TREC 2011 <ref type="bibr" coords="1,215.27,432.52,10.45,7.77" target="#b2">[3]</ref> was a remarkable success. In 2012, 40 groups participated in the track, with 33 groups submitting a total of 121 runs for the real-time adhoc task, and 19 groups submitting a total of 60 runs for the filtering task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">TWEETS2011 CORPUS</head><p>The TREC Microblog track in 2012 used the Tweets2011 corpus, which was created as part of last year's track. The corpus consists of an approximately 1% sample (after some spam removal) of tweets from January 23, 2011 to February 7, 2011 (inclusive), totaling approximately 16 million tweets. We summarize the corpus collection efforts here, but refer the reader to last year's track overview <ref type="bibr" coords="1,88.91,566.66,10.45,7.77" target="#b2">[3]</ref> for more details.</p><p>Creating a sharable reference collection of tweets is difficult because Twitter's terms of service forbid the redistribution of tweets. Last year, we devised a novel methodology whereby participants obtain a list of identifiers pointing to the tweets in the corpus after signing a usage agreement. Each identifier can be mapped to a URL at twitter.com which, when resolved, contains the tweet, delivered by Twitter according to their terms of service. Along with the cor-pus identifiers, we developed a set of tools to download a copy of the corpus, as well as sample code for indexing and retrieval. <ref type="foot" coords="1,535.36,218.95,2.99,5.18" target="#foot_0">1</ref>Note that individual downloads of the corpus would not be identical because tweets may have been deleted or made private since the corpus creation, and also some tweets may be unavailable due to transitory network failures. However, current evidence shows that corpus variability did not impact the evaluation results in the 2011 Microblog track <ref type="bibr" coords="1,398.09,283.58,9.52,7.77" target="#b1">[2]</ref>. We continue to monitor the availability and reusability of the collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">REAL-TIME ADHOC TASK</head><p>In this section, we describe the real-time search task (Section 3.1), the pooling and judging procedures used (Section 3.2), and provide a brief overview of the results (Section 3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Definition</head><p>A central aspect of search in microblog feeds is timeliness. In the real-time search task, we consider a user that makes a search query at a specific time, and wishes to see the most relevant information available up to that time. The real-time search task was the central task in 2011 <ref type="bibr" coords="1,362.89,424.14,10.45,7.77" target="#b2">[3]</ref> and this year underwent minor changes.</p><p>The main task for the 2012 Microblog track was the real-time search task, same as last year, where the user wishes to see the most recent and relevant information to the query. The real-time search task can be summarised as follows: At time t, find tweets about topic X <ref type="bibr" coords="1,369.60,476.45,9.52,7.77" target="#b4">[5]</ref>. This task is similar to adhoc search on Twitter's site, where a user's information need is represented by a query at a specific time <ref type="bibr" coords="1,364.63,497.37,9.52,7.77">[1]</ref>.</p><p>For 2012, NIST created 60 new topics representing information needs at specific points in time. Figure <ref type="figure" coords="1,487.68,518.29,4.48,7.77" target="#fig_2">1</ref> shows an example topic. The &lt;querytime&gt; tag contains the timestamp of the query in a human and machine readable ISO standard form, while the &lt;querytweettime&gt; tag contains the timestamp of the query in terms of the chronologically nearest tweet id in the corpus. While no narrative and description tags were provided to the participants, the topic developer recorded a clearly-defined information need for later use during assessment.</p><p>In last year's version of the task, participants were asked to rank relevant tweets by time. However, as reported in last year's track overview paper <ref type="bibr" coords="1,377.16,622.90,9.52,7.77" target="#b2">[3]</ref>, this created significant ambiguity regarding how to interpret participants' retrieval scores and ranks. Moreover, the real-time nature of the task was not addressed within the run format, because the chronological order of tweets is invariant for any run. Indeed, real-time search doesn't necessarily mean that search results must be ranked (reverse) chronologically, rather, the only requirement is that an information need arrives at a specific time and concerns something happening right now. This year, we revised the task by asking participants to return a score for all tweets in the collection before the query-tweet-time, and only that score. Any unscored tweet was assumed to have a score of negative infinity.</p><p>For assessing the tweets, the assessors judged the relevance of a tweet after reading it and also by following any URLs linked from the tweet. Tweets were judged on the basis of the defined information need using a three-point scale:</p><p>Not Relevant. The content of the tweet does not provide any useful information on the topic, or is written in a language other than English, or is a retweet (RT).</p><p>Relevant. The tweet provides some information on the topic, but it is not sufficiently informative.</p><p>Highly Relevant. A highly relevant tweet will either contain highly informative content, or link to highly informative content. It is the hope that systems will score highly relevant tweets higher than relevant ones.</p><p>All assessments were conducted by NIST assessors. All tweets were judged in isolation, without trying to determine novelty with respect to older tweets. The assessor judged retweets as not relevant unless the retweet added content (e.g., prior to the 'RT' string) and thus added possible value beyond the original tweet. Assessors marked tweets in languages other than English as not relevant. When a tweet contained a link, the assessor took the linked page's content into consideration when deciding the relevance of the tweet.</p><p>An end-user application resembling Twitter's current search interface might apply a threshold on the tweet retrieval score and only show tweets above some threshold in chronological order. Alternatively, a search engine might choose to display the top-scoring tweets in rank order (regardless of time). Effectiveness in these notional applications is modeled by the task metrics. The main measures for the task this year were the receiver operating characteristic (ROC) curve and precision at rank 30. The ROC curve shows precision versus fallout for every possible score threshold. Precision at 30 (P@30) provides a simple measure of search effectiveness on early result pages, whether ranked by time or score. We also report average precision as a robust measure for ranked retrieval. All measures are computed with "highly relevant" as the required level of relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Pooling and Judging</head><p>Participating groups were permitted to submit up to four runs to the real-time adhoc search task. At least one compulsory automatic run that does not use any external or future source of evidence was also requested. For the purposes of the task, we defined external and future evidence as follows:</p><p>External Evidence: Evidence outside the Tweets2011 corpus -for instance, this encompasses other tweets or information from Twitter, as well as other corpora, e.g., Wikipedia or the web.</p><p>Future Evidence: Information that would not have been available</p><p>to the system at the timestamp of the query. For example, idf scores computed using tweets not already posted at the timestamp of the query.</p><p>The participating groups were encouraged to rank their submitted runs by preference. In addition to one compulsory automatic, real-time run that uses no external resources, the participating groups were at liberty to submit manual (i.e., not automatic, involving a human in the loop at some point in the run), external (i.e. using external resources) and untimely (i.e., not adhering to the real-time constraint) runs, which could be useful to improve the quality of the test collection. TREC received 121 runs from 33 participating groups. All runs were pooled to depth 100, according to the retrieval scores indicated in each run. Simple retweets were removed from the pools (as they were deemed to be non-relevant). The tweets were clustered so that textually similar tweets could be judged consistently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>Tables <ref type="table" coords="2,352.00,270.17,4.48,7.77">1</ref> and<ref type="table" coords="2,375.48,270.17,4.48,7.77">2</ref> show the evaluation scores as well as metadata for all submitted runs, ordered by average precision at rank 30. Figure <ref type="figure" coords="2,342.33,291.10,4.48,7.77">2</ref> shows ROC curves for the different runs from each group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">FILTERING TASK</head><p>This section describes the filtering task (Section 4.1), the evaluation measures used (Section 4.2), and provides a brief overview of the results (Section 4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task Definition</head><p>This year, we introduced a new task, tweet filtering. The filtering task is exactly the reverse of the real-time search task: a query arrives at a defined point in time, and the system must filter the subsequent stream of messages to select tweets relevant to the information need.</p><p>The filtering task is modeled on the TREC 2002 adaptive filtering task <ref type="bibr" coords="2,333.06,448.22,9.52,7.77" target="#b3">[4]</ref>, and used topics MB 1-50 from last year's Microblog track. No new relevance judgments were created. The topics were retagged to reflect the altered meaning of the fields (see Figure <ref type="figure" coords="2,546.21,469.14,3.24,7.77" target="#fig_1">3</ref>). The earliest known relevant tweet in each of the 2011 topics was relabeled as the query-tweet-time trigger, and the original adhoc trigger was given as the endpoint, since no relevant tweets would exist after the original adhoc trigger tweet.</p><p>Topics with numbers 1, 6, 11 . . . 46, i.e., (n mod 5 = 1), were allotted for participants to use for training their systems. In the testing phase, systems were allowed access to the topic fields, including the trigger tweet. The systems processed the tweets from the query-tweet-time to the query-newest-time, one at a time, making a decision on whether or not to show the tweet to the user. If the system decided to show the tweet, it could access the tweet's relevance judgment (if any) as immediate relevance feedback, but not otherwise.</p><p>Systems returned the list of tweets processed, each with their retrieval score and a decision yes/no indicating whether the tweet was shown to the user. Since no new pools or relevance judgments were made, the task was completely run using last year's data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Measures</head><p>The filtering task used the TREC filtering measures <ref type="bibr" coords="2,524.50,680.09,9.52,7.77" target="#b3">[4]</ref>. Set precision and recall were computed over all retrieved tweets. The F β=0.5 measure was then computed. <ref type="bibr" coords="2,454.17,701.01,13.94,7.77">Van</ref>   relative weighting of each component:</p><formula xml:id="formula_0" coords="6,137.06,180.77,71.33,21.52">F β = (1 + β 2 )P R β 2 P + R</formula><p>A setting of β = 0.5 gives an emphasis to precision.</p><p>The other measure adopted from TREC filtering is linear utility. Imagine that a system receives a reward of two points for every relevant tweet retrieved, but takes a penalty of one point for every non-relevant tweet retrieved. Utility is the total points scored:</p><formula xml:id="formula_1" coords="6,65.65,268.43,214.49,8.06">T11U = 2 × relevant retrieved -nonrelevant retrieved</formula><p>Filtering according to a linear utility function is equivalent to filtering by estimated probability of relevance, in this case, to retrieve if P (rel ) &gt; 1/3.</p><p>Utility values are unbounded, and hence need to be scaled to enable comparisons across topics. The utility scores are normalized to a fraction of their theoretical maximum, and scaled against an arbitrary minimum normalized utility value of -0.5 so that they may be averaged across topics:</p><formula xml:id="formula_2" coords="6,90.80,375.41,163.90,60.53">MaxU = 2 × total relevant MinU = -0.5 NormU = T11U/MaxU T11SU = max(NormU, MinU) -MinU 1 -MinU</formula><p>Note that a T11SU value of 1/3 can be achieved by a run that retrieves nothing -not helping but not wasting the user's time with non-relevant information either. This is called the "zero effort" baseline. TREC 2012 received 60 runs from 19 groups for the filtering task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>Table <ref type="table" coords="6,85.15,516.96,4.48,7.77">3</ref> provides the evaluation results for run, along with metadata included at submission time. Runs are sorted by descending T11SU score. Utility and F-measure are not always correlated, as seen in Figure <ref type="figure" coords="6,118.39,548.34,3.36,7.77">4</ref>. The scatterplot is shown with a diagonal line which would represent equal scores and a vertical line at the utility point of zero effort. While most "useful" runs with utility scores &gt; 1/3 also have high F-measures, there is a wide range of Fmeasures that correspond to the zero-effort utility point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>This year marked the second iteration of the Microblog track, which featured a refinement of the real-time adhoc task and a new adaptive filtering task over tweets. The track continues to generate considerable interest, which we hope to sustain next year.  q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q Figure 4: F β versus scaled utility. The diagonal line shows where scores would lie if the two were equal. The vertical line shows the utility point of zero effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">REFERENCES</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,53.80,116.32,239.11,8.06;2,53.80,126.79,82.10,8.06"><head></head><label></label><figDesc>Figure 1: Topic MB051 from the TREC 2012 Microblog track, real-time search task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,53.80,123.56,239.11,8.06;6,53.80,134.02,150.71,8.06"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Topic MB002 from TREC 2011 Microblog track, retagged for use in the 2012 filtering task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,58.28,701.01,224.97,7.77;6,73.22,711.47,190.82,7.77"><head>[ 1 ]</head><label>1</label><figDesc>R.L.T. Santos, C. Macdonald, R. McCreadie, I. Ounis, and I. Soboroff. Information retrieval on the blogosphere.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,433.39,270.01,15.37,4.57;6,319.28,150.04,4.57,25.66;6,327.63,244.48,5.72,3.81;6,327.63,203.66,5.72,3.81;6,327.63,162.84,5.72,3.81;6,327.63,122.02,5.72,3.81;6,327.63,81.21,5.72,3.81;6,347.81,262.25,5.72,3.81;6,391.73,262.25,5.72,3.81;6,435.64,262.25,5.72,3.81;6,479.56,262.25,5.72,3.81;6,523.47,262.25,5.72,3.81"><head>T11SUF</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,316.81,701.01,239.10,18.23"><head></head><label></label><figDesc>Rijsbergen's F-measure is a function of precision and recall; the parameter β controls the</figDesc><table coords="3,127.02,55.28,355.68,18.63"><row><cell>&lt;top&gt;</cell><cell>Run</cell><cell>group</cell><cell>P@30 MAP</cell><cell>manual?</cell><cell>RT? docs? extern?</cell></row><row><cell cols="6">hitURLrun3 0.05085 0.05089 AI_ROMA3 GUCAS HIT_MTLAB HIT MTLAB BAU 0.05085 0.05089 BUPT_WILDCAT CMU_Callan 0.2701 0.2642 automatic yes 0.05085 0.05089 csiro FASILKOMUI 0.05085 0.05089 FUB IBM ICTNET IIEIR IRIT IRSI KobeU ot PKUICST QCRI qcri_twitsear SCIAITeam udel udel_fang UEdinburgh UGENT_IBCN_SIS uiucGSLIS UNC_SILS uog_tw uogTr UvA 0.05085 0.05089 UWaterlooMDS waterloo 0.05085 0.05089 XMU_PANCHAO york &lt;num&gt; Number: MB002 &lt;/num&gt; true positive rate 0.0 0.2 0.4 0.6 0.8 0.0 0.2 0.4 0.6 0.8 0.0 0.2 0.4 0.6 0.8 &lt;title&gt; 2022 FIFA soccer &lt;/title&gt; &lt;querytime&gt; Tue Feb 08 18:51:44 +0000 2011 &lt;/querytime&gt; &lt;querytweettime&gt; 29058771531595776 &lt;/querytweettime&gt; &lt;querynewesttweet&gt; 35048150574039040 &lt;/querynewesttweet&gt; yes false positive rate &lt;/top&gt;</cell><cell>0.0 0.2 0.4 0.6 0.8 0.0 0.2 0.4 0.6 0.8</cell></row><row><cell></cell><cell></cell><cell cols="4">Figure 2: curves for runs within each group.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,321.30,711.47,74.98,7.77"><p>http://twittertools.cc/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,336.23,341.90,215.78,7.77;6,336.23,352.36,34.37,7.77" xml:id="b0">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j" coord="6,336.23,341.90,173.95,7.77">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="125" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,336.23,363.81,209.71,7.77;6,336.23,374.27,198.34,7.77;6,336.23,384.58,100.70,7.72" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,397.01,374.27,133.83,7.77">On building a reusable Twitter corpus</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mccullough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,336.23,384.58,78.28,7.72">Proceedings of SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,336.23,396.19,214.83,7.77;6,336.23,406.50,209.29,7.93;6,336.23,416.96,20.17,7.72" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,506.35,396.19,44.71,7.77;6,336.23,406.65,116.18,7.77">Overview of the TREC-2011 Microblog track</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,467.72,406.50,77.80,7.72;6,336.23,416.96,16.14,7.72">Proceedings of TREC 2011</title>
		<meeting>TREC 2011</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,336.23,428.57,204.50,7.77;6,336.23,438.88,126.60,7.93" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,430.65,428.57,110.08,7.77;6,336.23,439.03,20.27,7.77">The TREC 2002 filtering track report</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,371.84,438.88,68.58,7.72">Proceedings TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,336.23,450.49,215.70,7.77;6,336.23,460.95,196.22,7.77;6,336.23,471.41,198.49,7.77;6,336.23,481.87,81.68,7.77" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mccullough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename></persName>
		</author>
		<title level="m" coord="6,346.70,460.95,185.76,7.77;6,336.23,471.41,198.49,7.77;6,336.23,481.87,22.91,7.77">McCreadie Evaluating real-time search over tweets. AAAI International Conference on Weblogs and Social Media</title>
		<imprint/>
	</monogr>
	<note>ICWSM 2012</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
