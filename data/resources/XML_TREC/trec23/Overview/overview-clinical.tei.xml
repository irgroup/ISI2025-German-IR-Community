<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,75.57,112.10,173.84,16.56;1,254.42,115.42,34.43,8.49;1,293.86,112.10,243.05,16.56">Overview of the TREC 2014 Clinical Decision Support Track</title>
				<funder>
					<orgName type="full">U.S. National Library of Medicine, National Institutes of Health</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,138.17,144.57,109.87,11.50"><forename type="first">Matthew</forename><forename type="middle">S</forename><surname>Simpson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Lister Hill National Center for Biomedical Communications</orgName>
								<orgName type="institution" key="instit2">U.S. National Library of Medicine</orgName>
								<orgName type="institution" key="instit3">National Institutes of Health</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Introduction</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,259.48,144.57,96.55,11.50"><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">National Institute of Standards and Technology</orgName>
								<address>
									<settlement>Gaithersburg</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,391.20,144.57,77.65,11.50"><forename type="first">William</forename><surname>Hersh</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Medical Informatics and Clinical Epidemiology</orgName>
								<orgName type="institution">Oregon Health &amp; Science University</orgName>
								<address>
									<settlement>Portland</settlement>
									<region>OR</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,75.57,112.10,173.84,16.56;1,254.42,115.42,34.43,8.49;1,293.86,112.10,243.05,16.56">Overview of the TREC 2014 Clinical Decision Support Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F50800119DE4ECB8121D3B20D9D74A95</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In making clinical decisions, physicians often seek out information about how to best care for their patients. Information relevant to a physician can be related to a variety of clinical tasks such as determining a patient's most likely diagnosis given a list of symptoms, deciding on the most effective treatment plan for a patient having a known condition, and determining if a particular test is indicated for a given situation. In some cases, physicians can find the information they seek in published biomedical literature. However, given the volume of the existing literature and the rapid pace at which new research is published, locating the most relevant and timely information for a particular clinical need can be a daunting and time-consuming task.</p><p>To make biomedical information more accessible and to meet the requirements for the meaningful use of electronic health records, a goal of modern clinical decision support systems is to anticipate the needs of physicians by linking electronic health records with information relevant for patient care. The Clinical Decision Support Track aims to simulate the requirements of such systems and to encourage the creation of tools and resources necessary for their implementation.</p><p>The focus of the 2014 track was the retrieval of biomedical articles relevant for answering generic clinical questions about medical records. In the absence of a reusable, de-identified collection of medical records, we used short case reports, such as those published in biomedical articles, as idealized representations of actual medical records. A case report typically describes a challenging medical case, and it is often organized as a well-formed narrative summarizing the portions of a patient's medical record that are pertinent to the case.</p><p>Participants of the track were challenged with retrieving, for a given case report, full-text biomedical articles relevant for answering questions related to several types of clinical information needs. Each topic consisted of a case report and one of three generic clinical question types, such as "What is the patient's diagnosis?" Retrieved articles were judged relevant if they provide information of the specified type useful for the given case. The evaluation of the submissions followed standard TREC evaluation procedures.</p><p>In the remainder of this overview we describe the documents (Section 2) and topics (Section 3) used for the retrieval task and the evaluation (Section 4) of the retrieval results. We also include raw statistics (Section 5) summarizing the performance of the participants' submissions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Documents</head><p>The target document collection for the track was an open access subset<ref type="foot" coords="1,392.56,668.72,3.79,3.73" target="#foot_0">1</ref> of PubMed Central<ref type="foot" coords="1,486.55,668.72,3.79,3.73" target="#foot_1">2</ref> (PMC), an online repository of freely available full-text biomedical literature. Because documents are constantly being added to PMC, to ensure the consistency of the collection, we obtained a snapshot of the open access subset on January 21, 2014, which contained a total of 733,138 articles. The full text of each article in the open access subset is represented as an NXML file (XML encoded using the U.S. National Library of Medicine's Journal Archiving and Interchange Tag Library),<ref type="foot" coords="2,289.54,228.21,3.79,3.73" target="#foot_2">3</ref> and images and other supplemental materials are also available.</p><p>Each article in the collection is identified by a unique number (PMCID) that was used for run submissions. The PMCID of an article is specified by the &lt;article-id&gt; element within its NXML file. Although each article is represented by multiple identifiers (e.g., PubMed, PMC, Publisher, etc.), we used only PMCIDs for this task. The various identifier types are specified using the pub-id-type attribute of the &lt;article-id&gt; element. Valid values of pub-id-type that indicate a PMCID include pmc and pmcid. For example, the document identifier of an article with PMCID 3148967 might by specified in the article's NXML file as follows.</p><p>&lt;article-id pub-id-type="pmc"&gt; 3148967 &lt;/article-id&gt;</p><p>To make processing the document collection easier for the participants, we renamed each article NXML in the collection according to the article's PMCID. For example, an article with PMCID 3148967 was given the name 3148967.nxml.</p><p>Participants were able to obtain the document collection in one of two ways. First, participants who were only interested in indexing the text of the articles in the collection (most participants) could download files containing all 733,138 articles in the January 21, 2014 snapshot directly from the track's website. Second, for participants who were interested in utilizing additional media other than text, such as the images and videos included in the articles, track organizers published a Python script for downloading the full document content directly from the PMC Open Access FTP Service. <ref type="foot" coords="2,375.32,490.43,3.79,3.73" target="#foot_3">4</ref> The total size of the collection with the additional media is about 2 TB. Downloading the additional media associated with the full-text articles was entirely optional for participation in the track, and none of the topics required this information. We provided this option for participants who had an interest in analyzing the medical images included in many of the articles as part of their retrieval strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Topics</head><p>The topics for the track were medical case narratives created by expert topic developers at the U.S. National Library of Medicine that serve as idealized representations of actual medical records. The case narratives described information such as a patient's medical history, the patient's current symptoms, tests performed by a physician to diagnose the patient's condition, the patient's eventual diagnosis, and finally, the steps taken by a physician to treat the patient.</p><p>Having a set of case narratives to use as topics, there are many clinically relevant questions that can be asked of them. <ref type="bibr" coords="2,140.30,666.91,67.59,9.58" target="#b0">Ely et al. (2000)</ref> created a taxonomy of the most frequent questions posed in practice. They collected 1,396 clinical questions from 152 primary care physicians and categorized them into 64 generic To simulate the actual information needs of physicians, our topic creators manually labeled the case narratives they constructed according to these three categories. A case narrative labeled "diagnosis," for example, requires participants of the track to retrieve PMC articles a physician would find useful for determining the diagnosis of the patient described in the report. Similarly, for a case narrative labeled "treatment," participants should retrieve articles that would suggest to a physician the best treatment plan for the condition exhibited by the patient described in the report. Finally, participants should retrieve for "test" case narratives articles that would suggest appropriate medical tests to be performed for either diagnosis or treatment of the patient. When constructing the case-based topics, the topic creators were careful to omit information related to the question type. For example, a "diagnosis" report might contain information pertaining to a patient's treatments and tests, but not the patient's diagnosis. In doing so, we hoped to more accurately mimic real clinical scenarios. The topic creators produced 10 topics for each of the 3 topic types for a total of 30 topics.</p><p>In addition to annotating the topics according to the type of clinical information required, we also provided two versions of the case narratives. The topic "descriptions" contain a complete account of the patients' visits, including details such as their vital statistics, drug dosages, etc., whereas the topic "summaries" are simplified versions of the narratives that contain less irrelevant information. A topic's description and its summary are functionally equivalent: the set of relevant documents is identical for each version. However, we provided the summary versions of the case narratives for participants who were not interested in nor equipped for processing the detailed descriptions.</p><p>Tables <ref type="table" coords="3,117.86,614.70,5.06,4.91" target="#tab_1">2</ref> and<ref type="table" coords="3,145.86,614.70,5.06,4.91">3</ref> show examples of the case-based topics. Table <ref type="table" coords="3,364.83,614.70,5.06,4.91" target="#tab_1">2</ref> contains descriptions for Topics 1, 11, and 21, and Table <ref type="table" coords="3,154.20,626.65,5.06,4.91">3</ref> contains their corresponding summaries. These particular topics are shown because they are examples of each of the 3 topic types used in the task.</p><p>To make the results of the track more meaningful, we required that participants use only all topic descriptions or only all topic summaries for any given run submission. Participants were free to submit up to five runs so that they could experiment with the different representations. The meta-data collected about a run included which version of the topics was used for the run.</p><p>The topics were provided in XML format. Topic numbers were specified using the number attribute of each &lt;topic&gt; element and topic types (i.e., diagnosis, test, and treatment) were specified with the type the topic. Documents were judged not relevant if they either did not provide information of the specified type or they were not topical to the patient. Finally an article was judged possibly relevant if an assessor believed it was not immediately informative on its own, but that it may be relevant in the context of a broader literature review.</p><p>Once the initial judgments were obtained, eight topics were independently rejudged by a different assessor. Table <ref type="table" coords="5,139.81,462.79,5.00,4.91" target="#tab_3">5</ref> shows the agreement between the two assessors for these topics when the two relevance levels were conflated into a single relevant category. The middle columns in the table give the counts of the number of documents that fall into the cells of the contingency table; for example, column "RN" gives the counts of the number of documents for which the first assessor judged it relevant and the second judged it not relevant. The final column gives the overlap of the relevant sets of the two assessors where overlap is defined as the size of the intersection of the relevant sets divided by the size of the union of the relevant sets.</p><p>Mean overlap across the eight topics with multiple judgment sets is somewhat on the low side as compared to other studies of relevance judgment agreement <ref type="bibr" coords="5,341.76,556.51,70.22,9.58" target="#b3">(Voorhees, 2000)</ref>, but is not inconsistent with those studies, especially given the small sample set size of just eight topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Figure <ref type="figure" coords="5,104.17,626.78,5.08,4.91">1</ref> shows the distribution of evaluation scores per topic computed across the set of 102 submitted runs. The graph on the left of the figure shows infNDCG scores computed at a cut-off of 100 and graph on the right shows Precision(10) scores. The graphs are box-and-whisker plots in which the horizontal line in a box is the median value, the lower and upper limits of the box are the first and third quartile values, the whiskers extend to values that are within 1.5 × interquartile-distance, and circles plot individual outliers. Figure <ref type="figure" coords="5,143.51,686.56,5.02,4.91">2</ref> shows the topic type and topic text of topics that had interesting behavior as measured by infNDCG.</p><p>Recall that topics 1-10 are of type "diagnosis", topics 11-20 are of type "test", and topics 21-30 are of   type "treatment." There is little apparent difference in performance across topic types when considering all runs. Some participants did do topic-type-specific processing in their runs, for example by emphasizing particular MeSH terms related to the topic type when those terms were found in documents. However, participants found it difficult to improve retrieval effectiveness using such processing, largely because relevant documents for a topic do not necessarily have a focus on that type. That is, an article useful for diagnosing a case frequently is not an article focused on the process of diagnosis.</p><p>Figure <ref type="figure" coords="7,118.95,376.26,5.06,4.91" target="#fig_1">3</ref> shows the distribution of evaluation scores across topics for individual runs. As in Figure <ref type="figure" coords="7,533.65,376.26,3.80,4.91">1</ref>, the figure shows box-and-whisker plots with infNDCG scores on the left and P(10) scores on the right. The runs included in the graph are the most effective runs by mean value of the respective measure for each of the top eight participants, and runs are ordered by decreasing mean. Runs plotted with blue shading are manual runs.</p><p>Generally, mean retrieval scores were relatively poor. This is perhaps reflective of the difficulty of the retrieval task, the utility of the document collection in providing relevant information for the types of generic clinical questions posed in this task, or challenges involved in assessing the retrieved documents.</p><p>The topic statements developed for the track contained both a longer description field and a shorter summary field, each field representing the same fundamental information need. The motivation for including both fields was the research question of whether systems can recognize and successfully downweight the non-essential information included in the descriptions. Many participants included a direct comparison of otherwise identical summary-and description-based runs among their submissions. The summary-based runs were more effective than the description-based runs in these tests. However, it should be noted that the submission with the best mean infNDCG score was an automatic run that used the description field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>TREC 2014 was the inaugural year of the Clinical Decision Support Track. The broad goal of the track is to inform the creation of robust clinical decision support systems, and in doing so, help improve patient care. In this first year, we focused on linking idealized case reports to published biomedical literature and attempted to address common generic clinical information needs including inquiries pertaining to diagnoses, treatments and tests. Twenty-six groups participated in the track and together they submitted a total of 102 runs. Retrieval results were generally lower than expected reflecting the difficulty of the retrieval task, the utility of the document collection in addressing clinical needs, or challenges involved in assessing the retrieved documents. We hope to further investigate these issues in future evaluations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,86.53,471.85,438.93,9.58;6,72.00,283.91,230.40,172.80"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Per-topic scores computed over entire set of 102 runs for infNDCG (left) and P(10) (right)</figDesc><graphic coords="6,72.00,283.91,230.40,172.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,79.93,259.94,452.14,9.58;7,72.00,72.00,230.40,172.80"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: infNDCG (left) and P(10) (right) scores for the most effective run from the top 8 participants</figDesc><graphic coords="7,72.00,72.00,230.40,172.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,77.98,82.40,456.04,84.26"><head>Table 1 :</head><label>1</label><figDesc>Types of case-based topics</figDesc><table coords="2,77.98,101.68,456.04,64.97"><row><cell>Type</cell><cell>Generic question</cell><cell>Ely et al.'s Classification</cell><cell>Frequency (%)</cell></row><row><cell>Diagnosis</cell><cell>What is the patient's diagnosis?</cell><cell>1.1.x.1: Diagnosis/Cause/*</cell><cell>21.28</cell></row><row><cell>Test</cell><cell>What tests should the patient's receive?</cell><cell>1.3.x.1: Diagnosis/Test/*</cell><cell>11.89</cell></row><row><cell cols="2">Treatment How should the patient be treated?</cell><cell>2.1.2.x: Treatment/Drugs/Indications/*</cell><cell>13.61</cell></row><row><cell></cell><cell></cell><cell>2.2.1.x: Treatment/General/Indications/*</cell><cell>5.95</cell></row><row><cell>All</cell><cell></cell><cell></cell><cell>52.72</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,71.58,82.40,468.81,300.86"><head>Table 2 :</head><label>2</label><figDesc>Example topic descriptions African-American woman presents to the ER with episodic pressing/burning anterior chest pain that began two days earlier for the first time in her life. The pain started while she was walking, radiates to the back, and is accompanied by nausea, diaphoresis and mild dyspnea, but is not increased on inspiration. The latest episode of pain ended half an hour prior to her arrival. She is known to have hypertension and obesity. She denies smoking, diabetes, hypercholesterolemia, or a family history of heart disease. She currently takes no medications. Physical examination is normal. The EKG shows nonspecific changes.11 TestA 40-year-old woman with no past medical history presents to the ER with excruciating pain in her right arm that had started 1 hour prior to her admission. She denies trauma. On examination she is pale and in moderate discomfort, as well as tachypneic and tachycardic. Her body temperature is normal and her blood pressure is 80/60. Her right arm has no discoloration or movement limitation.21 Treatment A 21-year-old female is evaluated for progressive arthralgias and malaise. On examination she is found to have alopecia, a rash mainly distributed on the bridge of her nose and her cheeks, a delicate non-palpable purpura on her calves, and swelling and tenderness of her wrists and ankles. Her lab shows normocytic anemia, thrombocytopenia, a 4/4 positive ANA and anti-dsDNA. Her urine is positive for protein and RBC casts.</figDesc><table coords="3,77.98,101.66,127.26,22.13"><row><cell>Topic Type</cell><cell>Description</cell></row><row><cell>1 Diagnosis</cell><cell>A 58-year-old</cell></row></table><note coords="3,71.72,301.94,468.28,9.58;3,72.00,313.90,468.00,9.58;3,72.00,325.85,468.00,9.58;3,72.00,337.81,468.00,9.58;3,72.00,349.76,468.39,9.58;3,71.58,361.72,468.42,9.58;3,72.00,373.67,423.68,9.58"><p><p><p>question types. Table</p>1</p>provides a coarse summary of some of their findings. The first column of the table indicates a broad category of clinical information need. The second column indicates the generic form of each question type. For example, the "diagnosis" type can be interpreted as posing the question: "What is the patient's diagnosis?" In the third column, we indicate which of Ely et al.'s 64 clinical question categories fit each generic form, and in the last column, we indicate how frequently questions of a given category were posed. The last row of the table indicates that clinical questions related to diagnoses, treatments, and tests account for a majority (52.72%) of the clinical questions posed by primary care physicians.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,77.98,82.40,456.04,292.31"><head>Table 4 :</head><label>4</label><figDesc>Participating groups and submitted runs</figDesc><table coords="5,77.98,101.68,149.27,7.67"><row><cell>Group</cell><cell>Affiliation</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,170.40,93.55,271.19,146.63"><head>Table 5 :</head><label>5</label><figDesc>Agreement between assessors for dual-judged topics</figDesc><table coords="6,203.98,113.22,204.05,126.95"><row><cell>Topic</cell><cell cols="5">NN NR RR RN Overlap</cell></row><row><cell>1</cell><cell>1349</cell><cell>32</cell><cell>35</cell><cell>47</cell><cell>0.3070</cell></row><row><cell>5</cell><cell>1360</cell><cell>1</cell><cell cols="2">14 119</cell><cell>0.1045</cell></row><row><cell>12</cell><cell>838</cell><cell cols="3">17 114 508</cell><cell>0.1784</cell></row><row><cell>17</cell><cell>1040</cell><cell>53</cell><cell>13</cell><cell>6</cell><cell>0.1806</cell></row><row><cell>19</cell><cell>977</cell><cell>25</cell><cell cols="2">70 134</cell><cell>0.3057</cell></row><row><cell>25</cell><cell>1351</cell><cell>70</cell><cell>28</cell><cell>6</cell><cell>0.2692</cell></row><row><cell>27</cell><cell>437</cell><cell cols="3">17 296 158</cell><cell>0.6285</cell></row><row><cell>28</cell><cell>1070</cell><cell>10</cell><cell>35</cell><cell>17</cell><cell>0.5645</cell></row><row><cell>Mean</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.3173</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,86.35,701.23,201.13,6.59"><p>http://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,86.35,710.69,131.35,6.59"><p>http://www.ncbi.nlm.nih.gov/pmc/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,86.35,698.89,192.92,6.59"><p>http://jats.nlm.nih.gov/archiving/versions.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,86.35,708.35,172.39,6.59"><p>http://www.ncbi.nlm.nih.gov/pmc/tools/ftp/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank <rs type="person">Swapna Abhyankar</rs>, <rs type="person">Amos Cahan</rs>, <rs type="person">Dina Demner-Fushman</rs>, and <rs type="person">Laritza Rodriguez</rs> for their help in preparing the topics; <rs type="person">Suchet Chachra</rs> for his help in preparing the document collection; and the <rs type="institution">Department of Medical Informatics and Clinical Epidemiology at Oregon Health &amp; Science University</rs> for performing the assessment.</p><p><rs type="person">Matthew Simpson</rs> was partially supported by the intramural research program at the <rs type="funder">U.S. National Library of Medicine, National Institutes of Health</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Judgments</head><p>The retrieval task in the track was an ad hoc task. Participants were permitted to submit in trec_eval format a maximum of five automatic or manual runs, each run consisting of a ranked list of up to one thousand PMCIDs per topic. As shown in Table <ref type="table" coords="4,243.92,449.42,3.75,4.91">4</ref>, the track had a total of 26 participants that together submitted a total of 102 retrieval runs. We were encouraged by the broad participation in a medically-oriented track, especially given that 2014 was the inaugural year of the Clinical Decision Support track.</p><p>All of the 102 runs contributed to the judgment sets, which were constructed to be compatible with computing inferred retrieval measures <ref type="bibr" coords="4,250.90,495.32,88.19,9.58" target="#b1">(Yilmaz et al., 2008)</ref>. Inferred measures are used as a means of getting more accurate estimates of a run's quality than is likely possible with traditional measures when judging a relatively small number of documents. The runs were sampled following an effective sampling strategy <ref type="bibr" coords="4,109.82,531.19,71.14,9.58" target="#b2">(Voorhees, 2014)</ref> for computing inferred measures. In particular, judgment sets were created using two strata: all documents retrieved in ranks 1-20 by any run in union with a 20% sample of documents not retrieved in the first set that were retrieved in ranks 21-100 by some run. Documents in the judgment set were judged on a three-point scale of 0: "not relevant," 1: "possibly relevant," and 2: "definitely relevant." For the evaluation reported here, the measures were computed by conflating the possibly relevant and definitely relevant sets into a single relevant set, except for the infNDCG measure, which makes use of the different relevance grades. A total of 34,949 documents were judged across the topics, with a mean of 1265.0 [min: 908, max: 1669] documents judged per topic.</p><p>The assessment was performed by physicians, most of whom are biomedical informatics students in the Department of Medical Informatics and Clinical Epidemiology at Oregon Health &amp; Science University. (A few are physicians from other sites. The topic creators did not perform assessment.) For a document to be judged definitely relevant to a given topic, it had to provide information of the specified type (i.e., diagnosis, test, and treatment) and provide information relevant to the particular patient described in the topic. The assessors were encouraged to not view a retrieved article as providing a "correct answer" to the generic clinical question posed by the topic, but were instead instructed to judge a document relevant if there was a reasonable chance a physician might find the article useful having seen the patient described in</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="8,72.00,217.40,467.99,9.58;8,81.96,229.35,332.79,9.58" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,473.09,217.40,66.91,9.58;8,81.96,229.35,198.88,9.58">A taxonomy of generic clinical questions: classification study</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Ely</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Osheroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Gorman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">H</forename><surname>Ebell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Chambliss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Pifer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,289.25,229.35,18.83,9.58">BMJ</title>
		<imprint>
			<biblScope unit="volume">321</biblScope>
			<biblScope unit="issue">7258</biblScope>
			<biblScope unit="page" from="429" to="432" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,249.28,468.00,9.58;8,81.96,261.24,458.03,9.58;8,81.96,273.19,248.66,9.58" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,253.17,249.28,286.84,9.58;8,81.96,261.24,27.05,9.58">A simple and efficient sampling method for estimating AP and NDCG</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,139.36,261.24,400.64,9.58;8,81.96,273.19,167.52,9.58">Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="603" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,293.12,468.00,9.58;8,81.96,305.07,459.78,9.58;8,81.47,318.95,47.32,4.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,146.92,293.12,230.06,9.58">The effect of sampling strategy on inferred measures</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,400.91,293.12,139.08,9.58;8,81.96,305.07,418.49,9.58">Proceedings of the 37th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 37th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1119" to="1122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,336.95,469.74,9.58;8,81.96,348.91,259.17,9.58" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,157.95,336.95,379.56,9.58">Variations in relevance judgments and the measurement of retrieval effectiveness</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,81.96,348.91,184.04,9.58">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="697" to="716" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
