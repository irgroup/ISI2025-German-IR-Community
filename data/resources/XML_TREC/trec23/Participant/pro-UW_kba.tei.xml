<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,103.79,91.02,391.68,12.90;1,223.34,108.96,150.20,12.90">Distributed Non-Parametric Representations for Vital Filtering: UW at TREC KBA 2014</title>
				<funder>
					<orgName type="full">Argentine Ministry of Science, Technology and Productive Innovation</orgName>
				</funder>
				<funder>
					<orgName type="full">MARCO</orgName>
				</funder>
				<funder>
					<orgName type="full">TerraSwarm</orgName>
				</funder>
				<funder>
					<orgName type="full">DARPA</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,55.44,157.55,56.74,8.96"><forename type="first">Ignacio</forename><surname>Cano</surname></persName>
							<email>icano@cs.washington.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
								<address>
									<postCode>98195</postCode>
									<settlement>Seattle</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,55.44,169.50,58.95,8.96"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
							<email>sameer@cs.washington.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
								<address>
									<postCode>98195</postCode>
									<settlement>Seattle</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,55.44,181.46,68.35,8.96"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
							<email>guestrin@cs.washington.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
								<address>
									<postCode>98195</postCode>
									<settlement>Seattle</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,103.79,91.02,391.68,12.90;1,223.34,108.96,150.20,12.90">Distributed Non-Parametric Representations for Vital Filtering: UW at TREC KBA 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">20C8E00203AF82BCC441D5B7ED114431</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Identifying documents that contain timely and vital information for an entity of interest, a task known as vital filtering, has become increasingly important with the availability of large document collections. To efficiently filter such large text corpora in a streaming manner, we need to compactly represent previously observed entity contexts, and quickly estimate whether a new document contains novel information. Existing approaches to modeling contexts, such as bag of words, latent semantic indexing, and topic models, are limited in several respects: they are unable to handle streaming data, do not model the underlying topic of each document, suffer from lexical sparsity, and/or do not accurately estimate temporal vitalness. In this paper, we introduce a word embedding-based non-parametric representation of entities that addresses the above limitations. The word embeddings provide accurate and compact summaries of observed entity contexts, further described by topic clusters that are estimated in a non-parametric manner. Additionally, we associate a staleness measure with each entity and topic cluster, dynamically estimating their temporal relevance. This approach of using word embeddings, non-parametric clustering, and staleness provides an efficient yet appropriate representation of entity contexts for the streaming setting, enabling accurate vital filtering.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>To build up to date entity profiles from streaming text corpora, we need to find references to entities of interest, and study the information trends over time. Unfortunately, this is an incredibly difficult task to perform efficiently on streams, and thus, a large number of pertinent articles are seldom retrieved by automated approaches. For example, <ref type="bibr" coords="1,498.23,272.75,44.96,8.64;1,307.11,284.70,26.85,8.64" target="#b7">Frank et al. (2012)</ref> observe a considerable lag between the publication date of articles and the date of their citations in Wikipedia. The median time is over a year, and the distribution has a long and heavy tail. This gap can be drastically reduced if automated systems can accurately and efficiently suggest relevant documents for entities of interest to editors as soon as they are published.</p><p>The Knowledge Base Acceleration (KBA) track at TREC addresses this task. Recent submissions to KBA <ref type="bibr" coords="1,501.64,386.32,41.04,8.64;1,307.44,398.28,23.15,8.64" target="#b16">(Liu et al., 2013;</ref><ref type="bibr" coords="1,333.67,398.28,100.40,8.64" target="#b3">Bouvier &amp; Bellot, 2013;</ref><ref type="bibr" coords="1,437.14,398.28,75.27,8.64" target="#b5">Efron et al., 2013;</ref><ref type="bibr" coords="1,515.47,398.28,25.96,8.64;1,307.44,410.23,50.52,8.64" target="#b28">Zhang et al., 2013;</ref><ref type="bibr" coords="1,361.78,410.23,89.90,8.64" target="#b1">Bellogín et al., 2013)</ref> focus on solving the aforementioned problems with supervised methods, using mainly document, document-entity, and temporal level features. They are, however, somewhat limited: they depend heavily on labeled data, do not handle lexical sparsity in contexts appropriately, and further, do not model the various semantic topics in the references.</p><p>In this submission, we introduce a semi-supervised approach suitable for streaming settings that uses word embedding clusters and temporal relevance to represent entity contexts. In particular, the word embeddings provide low-dimensional yet accurate summaries of previously observed entity contexts, and our algorithm updates the topic clusters, number of topics, and the entities and topics temporal relevance in an online fashion, observing only a single document at a time. We use this representation of unlabeled documents as features in a supervised classifier to utilize labeled data. This combination of word embeddings, non-parametric clustering, and temporal relevance (staleness) provides an efficient yet accurate representation of entity contexts that can be updated in a streaming manner, thus addressing the document filtering requirements on large streams of text. We present experimental results that demonstrate the benefits of our method and show our performance on the TREC KBA 2014 Vital Filtering task. As part of the Accelerate and Create task, we also describe an exploratory tool for efficient and intuitive visualization of large streams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Vital Filtering Task</head><p>In this section, we formalize the problem setup and introduce our notation. We assume a set of m target entities E = {e 1 , ..., e m }. We further assume a set of n documents D = {d 1 , ..., d n } that arrive in chronological order.</p><p>Each document is a sequence of sentences composed by collections of words, annotated with NLP tools. Further, we assume w.l.o.g. that every document in D refers to a single entity e ∈ E. Since our focus here is to distinguish vital and non-vital references, we use a naive classifier based resolution to identify the documents relevant (or referent) to each entity (details in Section 6.4), although in practice this is a challenging task and more sophisticated techniques are required <ref type="bibr" coords="2,91.13,279.87,68.90,8.64" target="#b22">(Rao et al., 2010;</ref><ref type="bibr" coords="2,162.52,279.87,71.54,8.64" target="#b24">Singh et al., 2011)</ref>.</p><p>A mention to e in a document d i ∈ D is identified by a string matching algorithm that searches for exact matches of canonical and surface form names of the entity e. We represent each d i as a compound of a timestamp t i and a bag of words W i = {w i1 , ..., w ip } located in the context of (and including) mentions to the entity e. Finally, we assume an online setting, i.e. the algorithm should provide predictions for documents arriving at time t before seeing any documents arriving at time t + 1.</p><p>Given this setup, the vital filtering task requires classification of each document d relevant to an entity e as follows:</p><p>• Vital if the document contains information that, at the time it enters the stream, would cause an update to the entity e with timely, new information about the entity current state, actions or situation, e.g. "Barack Obama has been elected President". • Non-Vital if the document is relevant, but contains information that is not timely, i.e. it may contain information relevant when building an initial profile of the entity e, but does not contain information that an accurate, updated profile would not have, e.g. "Barack Obama was born on August 4th, 1961".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Approach</head><p>Given a stream of documents D that refer to entity e, the task at hand is to predict whether each document is vital or non-vital to e. To detect whether a document contains novel information, one needs to provide an accurate and generalizable representation of historical contexts, while also capturing the temporal dynamics of the references.</p><p>To this end, we propose a three-pronged solution: (1) represent documents with low-dimensional embeddings that address sparsity and generalization (Section 3.1), (2) represent the entity context using non-parametric topic clustering (Section 3.2), and (3) estimate the novelty of the document information using a staleness measure (Section 3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Document Embeddings</head><p>To identify whether an entity context in a document contains novel information, or even if it is relevant for the entity, we need a structured representation of the context. A common solution to this problem is to use vector space models, often the Bag of Words (BOW) models, where a document is represented as the bag of its words, disregarding grammar and even word order. Unfortunately, vector space models are often too sparse to represent fine-grained information in contexts, for example, straightforward BOW representations will have minimal overlap between "Barack was elected president today" and "Obama has won the election", treating the other as novel information even after having seen one of them. Further, the size of BOW representations grows over time when the vocabulary is not predefined beforehand, which is a problem in streaming settings.</p><p>In order to address these concerns, we propose to represent contexts of entities in documents using word embeddings.</p><p>A word embedding is a dense, low-dimensional, and realvalued vector associated with every word in a vocabulary such that they capture useful syntactic and semantic properties of the contexts that the word appears in. The lowdimensionality of the embeddings as compared to vector space models (hundreds instead of millions) make them an elegant solution to address lexical sparsity in settings with very few labels <ref type="bibr" coords="2,368.27,443.09,75.53,8.64" target="#b26">(Turian et al., 2010)</ref>, and further, they can be efficiently trained on massive corpora. Many of the syntactic patterns can be represented with simple algebraic operations. For example, the result of v paris -v f rance + v germany is closer to v berlin than to any other word vector <ref type="bibr" coords="2,503.54,490.91,38.15,8.64;2,307.44,502.87,49.62,8.64">(Mikolov et al., 2013a;</ref><ref type="bibr" coords="2,357.06,502.87,8.42,8.64" target="#b1">b)</ref>.</p><p>We introduce a function f : w → v w ∈ R d that defines the pre-computed word embedding representation of the word type w 1 . To define the embedding for a set of words W , we define g : W → v W ∈ R d that computes embedding as:</p><formula xml:id="formula_0" coords="2,360.87,572.79,180.57,26.80">g(W ) = v W = 1 |W | w∈W f (w)<label>(1)</label></formula><p>Given the document d i ∈ D that refers to entity e and contains the words w i ∈ W i , we compute its vector representation using function g as follows:</p><formula xml:id="formula_1" coords="2,384.06,650.49,157.38,9.65">v di = v Wi = g(W i )<label>(2)</label></formula><p>With this, we intend to capture the context where the entity 1 We use the 300-dimensional word embeddings trained on the Google News Corpus, available at https://code.google. com/p/word2vec/.</p><p>e is mentioned in a document, i.e. the topic, and represent it with a dense, low-dimensional vector.</p><p>Further, it may be useful to separately capture the context in terms of different parts of speech. Let W in denote the set of all common nouns in W i , W i N the set of the proper nouns, and W iv the set of all verbs in W i , where W in ∪ W i N ∪ W iv = W i . We compute the embedding vectors of all the common nouns, proper nouns, and verbs that appear in the context of entity e using function g, as:</p><formula xml:id="formula_2" coords="3,112.50,191.01,176.94,41.14">v di n = v Wi n = g(W in ) (3) v di N = v Wi N = g(W i N ) (4) v di v = v Wi v = g(W iv )<label>(5)</label></formula><p>Computing separate embeddings for different word types is a flexibility our method provides that may better encapsulate the underlying content of the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Non-parametric Clustering</head><p>Although word embeddings capture the context around a single topic quite accurately, they are unable to represent the variety of topics that an entity may be mentioned in.</p><p>For example, the context around Obama during elections is quite different from the context for presidential speech or international visit. Using a single word embedding to represent multiple such topics may result in embeddings that conflate them, i.e. a single embedding is inaccurate for representing multiple topics.</p><p>One typical approach to tackle this problem is using topic models <ref type="bibr" coords="3,87.35,433.61,47.29,8.64" target="#b2">(Blei, 2012)</ref>. Such models can be trained in an offline manner over a large corpus, followed by streaming inference for each document. However, the number of topics often needs to be decided apriori, which is quite difficult to specify for each entity of interest (non-parametric approaches to LDA are quite expensive). Further, drift over time can make the topic distributions obsolete. Finally, it is difficult to learn per entity topic distributions, especially if some of the entities have very few relevant documents.</p><p>Instead of representing the context using only a single embedding, we propose to use a number of embeddings that capture the different topic clusters of the entity, retaining the advantages of using embeddings while still having a precise context representation. We assume that the context in a single document belongs to a single topic, though we dynamically estimate the number of topic clusters in a non-parametric manner. As we are concerned with a streaming setting, topic clusters evolve over time, i.e. identities, members and number of clusters change over time.</p><p>We represent each topic cluster by the mean embedding vector of the documents assigned to that cluster at a certain timestamp. More precisely, the vector representation of the j-th topic cluster at timestamp t i , c j i , can be computed using: </p><formula xml:id="formula_3" coords="3,384.79,273.27,156.65,30.61">v c j i = 1 |D j i | d∈D j i v d (6)</formula><p>where D j i is the subset of all the documents that belong to cluster j at timestamp t i , and ∀ d q ∈ D j i , t q ≤ t i . The number of topic clusters for the context of entity e is unknown beforehand. Initially, we let the entity context to have zero topic clusters. We create the first topic cluster for the entity context when the first relevant document is observed. For any following relevant document d, the topic clusters are updated as follows. We first compute a distance of v d with every existing topic cluster. If the minimum distance to any topic cluster is greater than or equal to α (0 ≤ α ≤ 1), we create a new topic cluster just containing document d, otherwise we merge document d into the closest cluster to v d , and update the cluster vector representation. Our approach is closely related to the online non-parametric clustering procedure described in <ref type="bibr" coords="3,441.06,487.20,98.02,8.64" target="#b20">Neelakantan et al. (2014)</ref>.</p><p>More formally, ∀ c j i-1 , at time i, document d i is added to the topic cluster that solves the following optimization problem:</p><formula xml:id="formula_4" coords="3,352.89,536.72,188.55,35.32">arg min j dist(v di , v c j i-1 ) subject to dist(v di , v c j i-1 ) &lt; α (7)</formula><p>where dist(•, •) is the cosine distance defined as:</p><formula xml:id="formula_5" coords="3,338.04,597.48,203.40,22.31">dist(x, y) = 1 -cos(x, y) = 1 - x • y ||x||||y|| (8)</formula><p>The j-th topic cluster at time i is updated, and therefore composed by the subset of documents D j i ⊆ D, where</p><formula xml:id="formula_6" coords="3,307.44,651.71,79.82,13.68">D j i = D j i-1 ∪ {d i }.</formula><p>Note that the cluster center is updated in constant time by incrementally maintaining the sum of the member embeddings. Figure <ref type="figure" coords="3,335.06,696.62,4.88,8.64" target="#fig_0">1</ref> illustrates an example of such clustering, using twodimensions to represent the vectors. Let's assume document d 1 appears in the stream first, and mentions the days Barack Obama was a senator. As it is the first document referring to the entity Obama, we add a new topic cluster senator with vector v d1 . Then, document d 2 appears in the stream, and refers to Obama as being elected President of the United States. The distance with the previous cluster senator is greater than α due to semantic difference in the words, therefore the algorithm proceeds to create a new topic cluster president centered at v d2 . Finally, d 3 enters the stream. It talks about Obama as the current President of the U.S. The algorithm compares its distance to the previous clusters and finds that it is closest to the president cluster. The distance is less than α, hence it adds d 3 to the president cluster and updates the cluster center.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Staleness</head><p>We have been concerned with detecting whether a document d contains a novel context in terms of the documents seen so far. By representing the context of an entity as a set of topic clusters, each with an embedding vector, we are able to accurately summarize the entity context information. We expect that documents that are not close to existing clusters contain novel information. Unfortunately, this representation ignores the timeliness of the information, and it is quite possible that a document that is similar to existing clusters contains novel information. For example, when a document describes Obama victory in an election, it may be assigned to an existing cluster describing a previous election he won, nonetheless it actually contains new information.</p><p>A potential solution is to keep track of when the last document was assigned to a cluster, however, KBA challenge requires all documents that contain novel information within a time frame to be marked vital as per the timeliness of the document. Such timeliness is a subjective interpretation that can vary per entity and event. As an example let's assume that several documents talk about an event that happened to entity e. During a "short" time frame (here is where the subjective interpretation comes in) that information can be considered new. After a while, that new information transitions to a background state, so as the documents transition from being vital to non-vital.</p><p>In order to address such temporal dynamics that capture novelty and transition documents from a vital to a non-vital state, we propose a dynamic staleness measure λ i , 0 &lt; λ i ≤ 1. This staleness measure can be used both for entities and topic clusters. Low staleness of the assigned entity/cluster represents vital documents, while high staleness intends to represent non-vital ones.</p><p>The staleness of an entity/cluster at any time t depends on the staleness and the time of the last document d j assigned to the entity/cluster. The staleness decay rate is exponential, </p><formula xml:id="formula_7" coords="4,369.56,406.20,171.88,22.31">λ t = λ j exp (-γ dec t -t j T )<label>(9)</label></formula><p>where γ dec ≥ 0, t j and λ j are the timestamp and staleness of the last document assigned to the entity/cluster, and T is a constant (used to transform the units of time).</p><p>When a new document d i is assigned to an entity/cluster at time t i , we can estimate the staleness of the entity/cluster at that time using the above equation,</p><formula xml:id="formula_8" coords="4,307.44,501.29,234.00,23.55">λ ti = λ i-1 exp (-γ dec ti-ti-1 T</formula><p>). This staleness can be used to estimate the novelty of the information in d i , i.e. a low λ ti suggests the document contains information that has not been observed for a while.</p><p>Thereafter, since we have just observed a relevant document for the entity/cluster, we need to increase its staleness. We use a simple interpolation to increase it:</p><formula xml:id="formula_9" coords="4,377.49,610.75,163.96,9.65">λ i = 1 -γ inc (1 -λ ti )<label>(10)</label></formula><p>where 0 ≤ γ inc ≤ 1. The staleness for the entity/cluster is now λ i , which is used when the next document d i+1 is observed.</p><p>Figure <ref type="figure" coords="4,336.23,672.71,5.04,8.64" target="#fig_1">2</ref> illustrates an example of an entity with a decreasing staleness. There are almost no documents referring to the entity. As soon as some activity is detected, i.e. a document mentioning the entity appears (t = 10), the staleness increases slightly. Given the fact that there is not much information about the entity, every new document would drive an update to the entity profile, strongly suggesting vitalness.</p><p>Figure <ref type="figure" coords="5,84.77,112.38,5.08,8.64">3</ref> represents staleness of an entity with fluctuating activity levels in the stream of documents. An important event involving the entity starts at time t=10 and continues for a substantial period, showing a growing trend in popularity. At the beginning, those documents can be considered vital, but as documents continue commenting on the same event over time, the information starts getting stale, clearly indicating non-vitalness. Near t=40 when the event is over, a steep decrease in popularity is observed. At a later time, t = 50, a new event occurs, strongly suggesting vitalness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Visualization for Accelerate and Create</head><p>Intuitive and effective visualization techniques can provide valuable tools in assisting editors to populate entity profiles and to perform exploratory analysis of large collections of documents. In this section, we describe the requirements of such visualization tools for streaming documents. Then, we present our visualization prototype for the Accelerate and Create task that enables users to enlarge parts of the visual space while simultaneously shrinking the context, a technique called focus-plus-context <ref type="bibr" coords="5,199.44,363.56,82.88,8.64" target="#b23">(Silic &amp; Basic, 2010)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Goals and Challenges</head><p>Visual exploration of text streams is a challenging task.</p><p>As text streams continuously evolve, visualization methods should allow tracing the temporal evolution of existing topics, detection of new ones, and examination of the relationships between them. Such systems should also allow users to interactively change the information they are seeking at any time. Interactivity is therefore a crucial factor in a domain where users do not know the text documents in advance <ref type="bibr" coords="5,90.32,502.98,87.57,8.64" target="#b0">(Alsakran et al., 2012)</ref>.</p><p>In this work we intend to provide an easy-to-use vizualization that enables users debug what is going on in the sytem. We provide different mechanisms to select data based on users interests; in particular we focus our attention on providing interactive time-series widgets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Our Implementation</head><p>We propose a browser-based visualization prototype that enables users to switch between multiple entities of interest, select the time ranges to explore over, explore the prominence of topics over time, and understand the topics using lists of similar words. The visualization tool initiates with the user selecting an entity of interest using an autocompleteenabled text-box. For the selected entity, our visualization consists of two views: Document and Topic. The Document view shows the distribution of vital and nonvital documents over the complete timeline, summarizing and differentiating the time frames when the documents contain a non-vital reference to the entity, and when they contain vital information. Figure <ref type="figure" coords="5,441.25,595.00,9.45,8.64" target="#fig_2">4a</ref> illustrates the distribution of predictions of entity Kshama Sawant in a specific period of time. Once the interesting time frames have been identified, this view also allows the user to navigate to and read individual documents.</p><p>The Topic view shows the evolution of the topic clusters for the entity, illustrating the predicted proportion of topic clusters over time. This view primarily plots the staleness of a cluster over time, indicating when a cluster was started, mentioned in the documents, and fall into obsolescence. The user can also study the topics in finer detail; clicking on any point in the timeline brings up a word cloud representation of the topic at that time. Figure <ref type="figure" coords="6,182.37,94.45,8.31,8.64" target="#fig_2">4b</ref>, for example, shows the staleness evolution for the different topic clusters of entity Mike Kluse. Figure <ref type="figure" coords="6,138.35,118.36,9.59,8.64" target="#fig_2">4c</ref> is the result of a user click on the point highlighted in Figure <ref type="figure" coords="6,167.20,130.31,8.47,8.64" target="#fig_2">4b</ref>. It shows the closest words to the topic cluster C1 at that time.</p><p>Both views consist of a timeline over the whole stream, allowing users to quickly navigate them over different time frames. The timeline is an active (zoomed) section that can be changed using the time range filters located below.</p><p>Legends also act as filters, users have the option of observing specific clusters or predictions by selecting them in the legend. These interactive time-series controls combined with the word cloud representations allow users to explore streaming data and filter information based on their needs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Related Work</head><p>Several knowledge based acceleration competitions have been done in the recent past, testifying the great progress achieved in these fields <ref type="bibr" coords="6,154.15,327.69,77.87,8.64" target="#b11">(Gross et al., 2012)</ref>. <ref type="bibr" coords="6,241.15,327.69,48.29,8.64;6,55.11,339.65,26.08,8.64" target="#b15">Liu &amp; Fang (2012)</ref> present one of the best performing systems in TREC KBA 2012. They created broader representations of entity profiles based on a Wikipedia snapshot and considered the anchor text of all internal Wikipedia links as related entities. In TREC KBA 2013 competition, different families of methods were proposed, including query expansion, classification, and learning to rank.</p><p>Our strategy is somewhat similar to <ref type="bibr" coords="6,194.43,429.31,71.32,8.64" target="#b27">Wang et al. (2013)</ref> in the sense that we first target a high recall system and then apply different classification methods to differentiate between vital and non-vital documents. One key difference is that we do not exploit any external resources to construct features, e.g. we do not use Wikipedia entity pages nor existing citations in the Wikipedia page of an entity.</p><p>Representing words as continuous vectors has been studied for a number of years <ref type="bibr" coords="6,147.05,530.93,83.09,8.64" target="#b12">(Hinton et al., 1987;</ref><ref type="bibr" coords="6,233.00,530.93,53.81,8.64" target="#b6">Elman, 1990)</ref>.</p><p>The progress in machine learning techniques in recent years has enabled training more complex models on much larger data sets <ref type="bibr" coords="6,94.08,566.79,93.97,8.64">(Mikolov et al., 2013a)</ref>. One popular approach to improving accuracy by exploiting large datasets is to use unsupervised methods to create word features, or to download word features that have already been produced <ref type="bibr" coords="6,55.11,614.62,77.69,8.64" target="#b26">(Turian et al., 2010)</ref>. In our method, we do the latter, using already induced word embedding features in order to improve our system accuracy. To the best of our knowledge, no other technique has proposed the use of word embeddings representations for the vital filtering task.</p><p>One of the pioneering work on detecting novel documents was introduced by <ref type="bibr" coords="6,135.80,692.32,79.98,8.64" target="#b29">Zhang et al. (2002)</ref>. They explicitly model relevance and redundancy as separate concepts. They propose different redundancy measures and empirically show that the cosine similarity metric is effective in identifying redundant documents; one limitation is that they just keep only the 10 most recent documents for a profile. In our method, we summarize the complete history of documents for a given entity, which allows a more accurate estimate of the query document redundancy. <ref type="bibr" coords="6,441.49,142.27,58.92,8.64" target="#b9">Gamon (2006)</ref> addresses the problem of staleness detection by building an association graph that connects sentences and sentence fragments, and uses graph-based features as indicators of lack of novelty. Though the task is somewhat similar, it is more limited in the sense that they do not need to model the transition from new to background information.</p><p>Many of the recent approaches have focused on scaling novel detection algorithms, also known as First Story Detection, in the streaming setting, by either using LSH <ref type="bibr" coords="6,505.76,255.84,35.68,8.64;6,307.44,267.80,47.39,8.64" target="#b21">(Petrović et al., 2010)</ref> or just employing simple heuristics <ref type="bibr" coords="6,499.14,267.80,43.54,8.64;6,307.44,279.75,21.87,8.64" target="#b17">(Luo et al., 2007)</ref>. While their work mainly focuses on efficiency at the cost of accuracy, our work aims to achieve accurate representations without compromising efficiency.</p><p>Streaming document filtering is also related to several other fields, including but not limited to, entity linking <ref type="bibr" coords="6,506.32,333.55,32.16,8.64;6,307.44,345.51,51.68,8.64" target="#b13">(Ji &amp; Grishman, 2011</ref>), text categorization <ref type="bibr" coords="6,447.50,345.51,95.19,8.64;6,307.44,357.46,21.87,8.64" target="#b14">(Kjersten &amp; McNamee, 2012)</ref>, news surveillance <ref type="bibr" coords="6,414.29,357.46,78.05,8.64" target="#b25">(Steinberger, 2014)</ref>, and crossdocument coreference <ref type="bibr" coords="6,397.30,369.42,68.27,8.64" target="#b22">(Rao et al., 2010;</ref><ref type="bibr" coords="6,468.06,369.42,70.88,8.64" target="#b24">Singh et al., 2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">KBA Vital Filtering Evaluation</head><p>In this section we describe the TREC KBA Vital filtering task, and our evaluation setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Data</head><p>To assess our contributions we use TREC KBA 2014 filtered stream corpus. The filtered corpus contains around 20M documents annotated with BBN's Serif NLP tools, including within-doc coreference and dependency parse trees. Further, we use the 71 target entities given by KBA organizers for the Vital Filtering task. Among the 20M documents, around 28K have truth labels. From these labeled example, 8K are treated as training instances, while the rest as test instances.</p><p>We preprocess the corpus to retain only the documents that contain exact string matches to the target entities names, including canonical and surface form names.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Features</head><p>Our approach extends the classifier introduced by <ref type="bibr" coords="6,517.97,636.43,23.46,8.64;6,307.44,648.39,47.19,8.64" target="#b27">Wang et al. (2013)</ref>. We construct a basic set of features based on the document and the entity of interest. Using our representation, we include additional features for the embedding, clustering, and staleness. A summary of the features we use is presented in Table <ref type="table" coords="6,391.86,696.21,3.74,8.64">1</ref>.  Table <ref type="table" coords="7,98.55,482.57,3.88,8.64">1</ref>: Features for Vital Filtering classification</p><formula xml:id="formula_10" coords="7,61.42,334.41,202.84,66.87">1v dn =0, set to 1 if v dn is 0 v d N mean word embedding for proper nouns zero(v d N ) 1v d N =0, set to 1 if v d N is 0 v dv mean word embedding for verbs zero(v dv ) 1v dv =0, set to 1 if v dv is 0 Clustering Features, Fc</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Relevance Classification</head><p>TREC KBA 2014 corpus contains documents that do not refer to the target entities, even though they may contain mentions to them. We therefore need to use a non-referent category of documents. A non-referent document denotes that it does not refer to a target entity or the context is so ambiguous that it is impossible to decide whether the mention refers to an entity or not. An example of the former case is "Barack Ferrazzano provides a wide range of businessoriented legal". It clearly does not refer to Barack Obama.</p><p>For the latter, an example is "Barack is a great father and a better husband". The mention "Barack" may refer to any married parent named Barack, therefore, we consider it nonreferent. The vital and non-vital classes described in section 2 fall into a referent (or relevant) category, which contains documents that refer to the target entities. We use randomized tree ensembles classifiers <ref type="bibr" coords="7,489.03,294.06,53.65,8.64;7,307.44,306.02,23.71,8.64" target="#b10">(Geurts et al., 2006)</ref> for both rnr and vnv, each composed of 100 weak learners. The maximum depth of each tree in the ensembles is 150. All our experiments use the same rnr model trained with the basic features listed in section 6.2. The different methods differ in the features used in the vnv classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Methods</head><p>We evaluate the following approaches in our experiments.</p><p>To compare against existing baselines, we use just the F b features (Baseline); <ref type="bibr" coords="7,389.99,421.53,75.72,8.64" target="#b27">Wang et al. (2013)</ref> and <ref type="bibr" coords="7,485.68,421.53,57.51,8.64;7,307.11,433.49,26.03,8.64" target="#b1">Bellogín et al. (2013)</ref> propose a similar technique, although they train their models with a few more features. We also include an additional baseline that uses multi-task learning <ref type="bibr" coords="7,478.77,457.40,63.34,8.64" target="#b4">(Caruana, 1993)</ref> to learn separate parameters for each entity, called Baseline, Multi-task. In order to evaluate the effect of adding word embeddings, we introduce two extensions to the baselines that use the embedding features: Embedding, Single that uses a single embedding for every document (F c e features), and Embedding, POS that maintains different embeddings for common nouns, proper nouns and verbs (F p e features); see Section 3.1 for details. We separately evaluate the utility of temporal modeling via staleness by introducing the Staleness only method that includes the F t features. Similarly, we propose the method that uses only clustering (F c features), but not the temporal ones, called Clustering only. Finally, the approach that combines all contributions, Combined, includes all the F b , F p e , F t , and F c features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Results and Discussion</head><p>Table <ref type="table" coords="7,332.34,672.71,5.08,8.64" target="#tab_0">2</ref> shows the submitted and revised precision, recall and F1 results of the methods explained in 6.4, computed using KBA scorer tool, using the 2014-07-11 truth data. The models that include the F c features use α = 0.8, whereas  According to the official results, our submissions achieved the 2 nd best precision in the competition, but performed poorly in the overall macro F1 (8 th position). Revisiting our submission files, we found that we misinterpreted the concept of confidence. Figure <ref type="figure" coords="8,177.07,457.52,9.41,8.64" target="#fig_6">6a</ref> shows that we only make vital predictions with confidence greater than or equal to 500, i.e. the right part of the curve is just constant. We should have also predicted vital with low confidence, i.e. flip our high confidence non-vital predictions to be vital with low confidence. That minor change boosts our recall (in most cases), while the precision slightly suffers, as shown in Figure <ref type="figure" coords="8,93.85,541.20,8.22,8.64" target="#fig_6">6b</ref>, leaving our system in the 2 nd overall position.</p><p>The baseline provided by TREC KBA organizers (not to be confused with our Baseline model) assigns a vital rating to every document that matches a surface form name of an entity, assigning a confidence score based on the number of matches of tokens in the name. The values reported by the organizers are: macro-P=0.316, macro-R=0.520, macro-F1=0.393, SU=0.3334 <ref type="bibr" coords="8,147.22,630.87,74.84,8.64" target="#b8">(Frank et al., 2014)</ref>.</p><p>Baseline performs as expected, i.e. has lower F1 than the other models. On the other hand, Baseline, Multi-task performs far better than Baseline, which suggests the contexts vary sufficiently across entities to benefit from separate parameterization. Our proposed models further improve upon the Baseline, Multi-task. Further, using a single em-  <ref type="table" coords="8,536.36,624.89,5.08,8.64" target="#tab_0">2</ref> for different confidence cutoffs. Figures <ref type="figure" coords="8,476.72,636.84,9.59,8.64" target="#fig_7">7a</ref> and<ref type="figure" coords="8,507.28,636.84,10.16,8.64" target="#fig_7">7b</ref> show that the macro recall has a substantial increase in the lower confidence half of the plot, while retaining most of the precision; this results in a boost to F1 scores in the revised macro scenario. For micro-averaging on the other hand, the precisions and recalls (shown in Figures <ref type="figure" coords="8,471.02,696.62,9.48,8.64" target="#fig_8">8a</ref> and<ref type="figure" coords="8,499.96,696.62,8.92,8.64" target="#fig_8">8b</ref>) follow opposite trends, causing the micro revised F1s to be almost </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion &amp; Future Work</head><p>Filtering streaming documents in order to fill gaps plays a crucial role in the maintenance and timely updates of knowledge bases. With the exponential increase of information on the web, it becomes critical to detect relevant documents and incorporate their information in a timely manner. In this paper we introduced a semi-supervised learning model for document filtering tasks. We proposed a word embeddings based non-parametric representation of documents groups entity references into topic clusters, and is suitable for streaming data. Further, we present a notion of staleness for entities and topics that dynamically estimates the temporal relevance of the entity contexts. The combination of these three core contributions (distributed word embedding representations, non-parametric clustering, and staleness) results in an accurate representation of entity contexts, while simultaneously addressing the filtering requirements of large corpora of streaming text documents.</p><p>A number of avenues exist for further work. A possible line of future research would be exploring hierarchical clustering  <ref type="bibr" coords="9,515.23,541.09,26.98,8.64;9,307.44,553.04,47.82,8.64" target="#b15">(Liu &amp; Fang, 2012)</ref> will likely further improve the accuracy of our method. It would also be worthwhile to assess the effects of using different pre-trained word embeddings.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,326.88,234.27,195.12,8.64;3,342.54,67.06,163.79,155.37"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of Non-parametric Clustering</figDesc><graphic coords="3,342.54,67.06,163.79,155.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,344.86,201.75,159.16,8.64;4,342.54,67.06,163.79,122.84"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Staleness of Unpopular Entity</figDesc><graphic coords="4,342.54,67.06,163.79,122.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,330.96,502.30,186.97,8.64;5,363.69,367.33,121.50,107.18"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Staleness and Topic cluster evolution</figDesc><graphic coords="5,363.69,367.33,121.50,107.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,141.31,72.43,69.29,8.41;7,61.42,87.46,77.24,7.86;7,61.42,97.42,134.51,8.06;7,61.42,107.38,38.69,7.86;7,120.17,107.38,81.21,8.06;7,61.42,117.34,144.86,7.86;7,61.42,127.31,25.88,7.86;7,120.17,127.31,136.88,8.06;7,61.42,137.27,22.29,7.86;7,83.72,135.50,3.84,5.24;7,88.05,137.27,3.58,7.86;7,120.17,137.27,148.24,8.06;7,61.42,147.23,35.76,8.06;7,120.17,147.23,151.51,8.06;7,61.42,157.48,15.44,7.77;7,76.86,161.68,4.60,5.24;7,81.96,157.19,20.32,7.86;7,120.17,157.19,151.81,8.06;7,61.42,167.16,32.18,8.06;7,93.60,165.39,3.84,5.24;7,97.94,167.16,3.58,7.86;7,120.17,167.16,153.99,8.06;7,61.42,177.41,15.44,7.77;7,76.86,181.60,4.60,5.24;7,81.96,177.12,16.74,7.86;7,98.70,175.35,3.84,5.24;7,103.03,177.12,173.29,8.06;7,61.42,187.08,35.27,8.06;7,120.17,187.08,150.01,8.06;7,61.42,197.33,14.95,7.77;7,76.37,201.53,4.60,5.24;7,81.46,197.05,20.32,7.86;7,120.17,197.05,151.32,8.06;7,61.42,207.01,31.68,8.06;7,93.10,205.24,3.84,5.24;7,97.44,207.01,3.58,7.86;7,120.17,207.01,170.82,8.06;7,61.42,217.26,14.95,7.77;7,76.37,221.45,4.60,5.24;7,81.46,216.97,16.73,7.86;7,98.20,215.20,3.84,5.24;7,102.54,216.97,49.31,8.06;7,151.86,215.20,3.84,5.24;7,156.20,216.97,119.64,8.06;7,61.42,226.93,43.72,8.06;7,120.17,226.93,82.29,8.06;7,61.42,237.18,23.40,7.77;7,84.82,241.38,4.60,5.24;7,89.92,236.90,190.03,8.06;7,61.42,246.86,40.14,8.06;7,101.56,245.09,3.84,5.24;7,105.90,246.86,45.96,8.06;7,151.86,245.09,3.84,5.24;7,156.20,246.86,42.93,7.86;7,199.13,245.09,3.84,5.24;7,203.47,246.86,3.58,7.86;7,61.42,257.11,23.40,7.77;7,84.82,261.30,4.60,5.24;7,89.92,256.82,16.74,7.86;7,106.66,255.05,3.84,5.24;7,111.00,256.82,49.31,8.06;7,160.31,255.05,3.84,5.24;7,164.65,256.82,119.64,8.06;7,129.23,271.72,93.45,8.06;7,61.42,286.75,154.63,7.86;7,217.32,284.98,3.34,5.24;7,216.04,290.37,3.52,5.24;7,61.42,296.71,8.32,8.35;7,120.17,296.71,151.85,8.06;7,61.42,306.68,31.41,8.35;7,120.17,304.52,9.26,11.04;7,129.43,306.68,78.16,9.49;7,61.42,316.64,107.24,7.86;7,169.94,314.87,3.84,5.24;7,168.66,320.26,3.52,5.24;7,61.42,326.60,12.70,8.35;7,120.17,326.89,152.07,7.77;7,61.42,336.56,36.30,8.35"><head></head><label></label><figDesc>Basic Features, F b Based on document d log(len(d)) log of the length of d source(d) discretized source of d Based on document d and target entity e n(d, e) # of occurrences of target entity e in d n(d, e p ) # of occurrences of partial name of e in d fpos(d, e) position of first occurrence of entity e in d fpos n (d, e) fpos(d, e) normalized by document length fpos(d, e p ) position of first partial occurrence of e in d fpos n (d, e p ) fpos(d, ep) normalized by document length lpos(d, e) position of last occurrence of entity e in d lpos n (d, e) lpos(d, e) normalized by document length lpos(d, e p ) position of last partial occurrence of entity e in d lpos n (d, e p ) lpos(d, e p ) normalized by document length spread(d, e) lpos(d, e)fpos(d, e) spread n (d, e) spread(d, e) normalized by document length spread(d, e p ) lpos(d, e p )-fpos(d, e p ) spread n (d, e p ) spread(d, e p ) normalized by document length Embedding Features, Fe Based on a single, combined embedding, F c e v d mean word embedding representation of d zero(v d ) 1v d =0, set to 1 if v d is 0 Based on POS embeddings, F p e v dn mean word embedding for common nouns zero(v dn )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="7,61.42,408.25,221.29,8.35;7,61.42,418.50,12.77,7.77;7,74.19,422.69,3.34,5.24;7,78.03,418.21,197.36,8.35;7,133.22,433.11,85.47,8.06;7,61.42,448.14,16.83,7.86;7,120.17,448.14,98.41,8.06;7,61.42,458.10,24.91,7.86;7,120.17,458.10,157.02,8.06"><head></head><label></label><figDesc>minc(v d , vc) minimum distance of v d to topic clusters of e avg c (v d , vc) average distance of v d to topic clusters of e Temporal Features, Ft λ(e) current staleness of entity e λ(e, c) current staleness of topic c of target entity e</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="7,361.46,128.99,125.96,8.64"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Classification process</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="8,64.09,342.36,216.71,8.64;8,299.25,328.28,131.13,98.35"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Examples of P-R-F1 over confidence cutoffs</figDesc><graphic coords="8,299.25,328.28,131.13,98.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="8,320.10,454.42,208.68,8.64;8,418.50,328.28,131.13,98.35"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Macro P-R-F1-SU over confidence cutoffs</figDesc><graphic coords="8,418.50,328.28,131.13,98.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="9,68.93,302.03,207.02,8.64;9,47.25,175.89,131.13,98.35"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Micro P-R-F1-SU over confidence cutoffs</figDesc><graphic coords="9,47.25,175.89,131.13,98.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9" coords="9,357.60,252.19,133.69,8.64;9,305.52,264.84,243.84,182.88"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Macro Precision-Recall</figDesc><graphic coords="9,305.52,264.84,243.84,182.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="8,56.63,71.43,472.85,258.03"><head>Table 2 :</head><label>2</label><figDesc>26.6 26.5 63.4 35.5 37.5 47.5 36.6 23.8 94.0 31.7 52.7 Baseline, Multi-task F b 60.7 60.7 41.4 41.4 49.2 49.2 36.7 36.6 40.5 94.0 38.5 52.7 Embedding, Single F b + F c e 54.7 54.7 52.1 51.8 53.4 53.2 44.9 38.3 37.6 85.5 40.9 52.9 Embedding, POS F b + F p e 53.9 49.9 46.4 53.1 49.8 51.4 44.0 36.6 32.9 94.0 37.6 52.7 Staleness only F b + F p e + Ft 57.3 57.3 48.3 48.3 52.4 52.4 47.5 39.1 33.8 85.8 39.5 53.7 Clustering only F b + F p e + Fc 57.0 57.0 49.0 48.9 52.7 52.6 46.4 38.7 34.2 85.0 39.4 53.2 Combined F b + F p e + Fc + Ft 56.2 56.2 48.1 48.1 51.8 51.8 46.1 36.6 32.6 94.0 38.2 52.7 Vital Filtering performance using the submitted and revised runs for TREC KBA 2014</figDesc><table coords="8,67.40,71.43,447.71,38.14"><row><cell>Model</cell><cell>Features</cell><cell></cell><cell>Vital only, micro</cell><cell></cell><cell></cell><cell>Vital only, macro</cell></row><row><cell></cell><cell></cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>Baseline</cell><cell>F b</cell><cell>53.9</cell><cell></cell><cell></cell><cell></cell></row></table><note coords="8,56.63,321.69,225.04,7.77"><p>(a) Example Submission Curve (b) Example Revised Curve</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0" coords="1,55.16,684.16,237.88,7.73;1,55.16,694.12,237.88,7.93;1,55.44,704.24,98.37,7.77"><p>Proceedings of the Text Retrieval Conference (TREC): Knowledge-Base Acceleration (KBA), Gaithersburg, MD, USA, 2014. Copyright 2014 by the author(s).</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported in part by the <rs type="funder">Argentine Ministry of Science, Technology and Productive Innovation</rs> with the program BEC.AR, and in part by <rs type="funder">TerraSwarm</rs>, one of six centers of STARnet, a Semiconductor Research Corporation program sponsored by <rs type="funder">MARCO</rs> and <rs type="funder">DARPA</rs>. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsors.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,55.44,87.13,235.12,7.77;10,64.88,97.09,224.55,7.77;10,65.40,106.89,224.04,7.93;10,65.11,116.85,199.62,7.93" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,202.74,97.09,86.70,7.77;10,65.40,107.05,197.38,7.77">Real-Time Visualization of Streaming Text with a Force-Based Dynamic System</title>
		<author>
			<persName coords=""><forename type="first">Jamal</forename><surname>Alsakran</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Dongning</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ye</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Jing</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wenwen</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shixia</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,270.12,106.89,19.32,7.73;10,65.11,116.85,133.19,7.73">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="page" from="34" to="45" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,55.44,136.51,235.12,7.77;10,65.40,146.48,224.04,7.77;10,65.08,156.44,225.85,7.77;10,65.40,166.40,225.61,7.77;10,65.40,176.20,224.04,7.93;10,64.80,186.16,52.55,7.93" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,141.13,156.44,149.79,7.77;10,65.40,166.40,221.89,7.77">CWI and TU Delft at TREC 2013: Contextual Suggestion, Federated Web Search, KBA, and Web Tracks</title>
		<author>
			<persName coords=""><forename type="first">Alejandro</forename><surname>Bellogín</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Gebremeskel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gebrekirstos</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Jiyin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Said</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Alan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Samar</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Thaer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arjen</forename><forename type="middle">P</forename><surname>Vries</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeroen</forename><forename type="middle">B P</forename><surname>Vuurens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,74.83,176.20,214.62,7.73;10,64.80,186.16,25.83,7.73">Proceedings of the Twenty-Second Text REtrieval Conference (TREC)</title>
		<meeting>the Twenty-Second Text REtrieval Conference (TREC)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,55.44,205.66,234.00,7.93;10,64.86,215.63,79.18,7.93" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,103.22,205.82,93.76,7.77">Probabilistic topic models</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,204.54,205.66,84.91,7.73;10,64.86,215.63,15.68,7.73">Communications of the ACM</title>
		<imprint>
			<biblScope unit="page">7784</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,55.44,235.29,234.00,7.77;10,65.40,245.25,224.29,7.77;10,65.40,255.05,224.04,7.93;10,65.11,265.01,115.97,7.93" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,201.84,235.29,87.61,7.77;10,65.40,245.25,224.29,7.77;10,65.40,255.21,32.60,7.77">Filtering Entity Centric Documents using Numerics and Temporals features within RF Classifier</title>
		<author>
			<persName coords=""><forename type="first">Vincent</forename><surname>Bouvier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrice</forename><surname>Bellot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,114.20,255.05,175.24,7.73;10,65.11,265.01,89.69,7.73">Proceedings of the Twenty-Second Text REtrieval Conference (TREC 2013)</title>
		<meeting>the Twenty-Second Text REtrieval Conference (TREC 2013)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,55.44,284.67,234.00,7.77;10,65.40,294.47,225.53,7.93;10,65.40,304.44,208.99,7.93" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,131.61,284.67,157.84,7.77;10,65.40,294.63,87.73,7.77">Multitask Learning: A Knowledge-Based Source of Inductive Bias</title>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,169.81,294.47,121.12,7.73;10,65.40,304.44,142.32,7.73">Proceedings of the Tenth International Conference on Machine Learning</title>
		<meeting>the Tenth International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,55.44,324.10,235.12,7.77;10,65.40,334.06,224.04,7.77;10,65.40,343.86,224.04,7.93;10,65.40,353.82,171.36,7.93" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,126.03,334.06,163.42,7.77;10,65.40,344.02,164.69,7.77">The University of Illinois Graduate School of Library and Information Science at TREC 2013</title>
		<author>
			<persName coords=""><forename type="first">Miles</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Willis</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Craig</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Organisciak</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Peter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brian</forename><surname>Balsamo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ana</forename><surname>Lucic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,245.92,343.86,43.52,7.73;10,65.40,353.82,144.64,7.73">Proceedings of the Text REtrieval Conference (TREC)</title>
		<meeting>the Text REtrieval Conference (TREC)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,55.44,373.32,235.49,7.93;10,65.13,383.28,96.89,7.93" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,124.75,373.48,90.53,7.77">Finding structure in time</title>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><forename type="middle">L</forename><surname>Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,223.70,373.32,67.23,7.73;10,65.13,383.28,20.13,7.73">COGNITIVE SCI-ENCE</title>
		<imprint>
			<biblScope unit="page" from="179" to="211" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,55.44,402.94,235.12,7.77;10,65.40,412.91,225.53,7.77;10,65.40,422.71,225.53,7.93;10,65.40,432.67,224.04,7.73;10,65.18,442.63,45.58,7.93" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,218.38,412.91,72.55,7.77;10,65.40,422.87,194.11,7.77">Building an Entity-Centric Stream Filtering Test Collection for TREC 2012</title>
		<author>
			<persName coords=""><forename type="first">John</forename><forename type="middle">R</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Max</forename><surname>Kleiman-Weiner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Niu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,275.23,422.71,15.70,7.73;10,65.40,432.67,196.97,7.73">Proceedings of the Twenty-First Text REtrieval Conference</title>
		<meeting>the Twenty-First Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>TREC 2012</note>
</biblStruct>

<biblStruct coords="10,55.44,462.29,235.12,7.77;10,65.08,472.25,225.84,7.77;10,65.40,482.22,225.61,7.77;10,65.40,492.02,171.53,7.93" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,205.68,472.25,85.25,7.77;10,65.40,482.22,163.39,7.77">Evaluating Stream Filtering for Entity Profile Updates in TREC 2012</title>
		<author>
			<persName coords=""><forename type="first">John</forename><forename type="middle">R</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Max</forename><surname>Kleiman-Weiner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,75.11,492.02,135.49,7.73">KBA Track Overview, Notebook Paper</title>
		<imprint>
			<date type="published" when="2013">2013. 2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,55.44,511.68,234.31,7.77;10,65.40,521.48,224.04,7.93;10,65.40,531.44,225.16,7.73;10,65.40,541.57,20.17,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,123.35,511.68,166.41,7.77;10,65.40,521.64,33.93,7.77">Graph-Based text Representation for Novelty Detection</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Gamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,116.13,521.48,173.31,7.73;10,65.40,531.44,221.29,7.73">Proceedings of TextGraphs: the First Workshop on Graph Based Methods for Natural Language Processing</title>
		<meeting>TextGraphs: the First Workshop on Graph Based Methods for Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,55.44,561.06,234.31,7.77;10,65.40,570.87,199.52,7.93" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,251.65,561.06,38.10,7.77;10,65.40,571.03,65.77,7.77">Extremely Randomized Trees</title>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Geurts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ernst</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Damien</forename><surname>Wehenkel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Louis</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,138.04,570.87,64.70,7.73">Machine Learning</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="3" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,55.44,590.53,235.49,7.77;10,65.40,600.33,224.04,7.93;10,65.40,610.29,225.61,7.93" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,249.62,590.53,41.32,7.77;10,65.40,600.49,154.41,7.77">Term Association Analysis for Named Entity Filtering</title>
		<author>
			<persName coords=""><forename type="first">Oskar</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antoine</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Toivonen</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Hannu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,236.05,600.33,53.39,7.73;10,65.40,610.29,151.94,7.73">Proceedings of the Twenty-First Text REtrieval Conference</title>
		<meeting>the Twenty-First Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,55.44,629.95,234.00,7.77;10,65.40,639.75,225.53,7.93;10,64.86,649.71,113.88,7.93" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,250.08,629.95,39.36,7.77;10,65.40,639.91,55.30,7.77">Distributed Representations</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,137.25,639.75,111.28,7.73">Parallel Distributed Processing</title>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="77" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,55.44,669.37,235.25,7.77;10,65.40,679.17,224.04,7.93;10,65.40,689.14,224.03,7.73;10,65.15,699.10,225.86,7.93;10,64.73,709.22,65.01,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,181.67,669.37,109.02,7.77;10,65.40,679.34,145.64,7.77">Knowledge Base Population: Successful Approaches and Challenges</title>
		<author>
			<persName coords=""><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,233.47,679.17,55.97,7.73;10,65.40,689.14,224.03,7.73;10,65.15,699.10,164.95,7.73">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1148" to="1158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.44,71.19,234.00,7.77;10,317.13,80.99,224.32,7.94;10,316.90,90.95,196.36,7.94" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,440.23,71.19,101.21,7.77;10,317.13,81.15,132.92,7.77">THE HLTCOE APPROACH TO THE TREC 2012 KBA TRACK</title>
		<author>
			<persName coords=""><forename type="first">Brian</forename><surname>Kjersten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,471.83,80.99,69.62,7.73;10,316.90,90.95,169.64,7.73">Proceedings of the Twenty-First Text REtrieval Conference (TREC)</title>
		<meeting>the Twenty-First Text REtrieval Conference (TREC)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.44,109.04,234.00,7.77;10,317.08,118.85,225.85,7.93;10,316.86,128.81,168.14,7.93" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,417.61,109.04,123.83,7.77;10,317.08,119.01,110.86,7.77">Entity Profile based Approach in Automatic Knowledge Finding</title>
		<author>
			<persName coords=""><forename type="first">Xitong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hui</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,444.74,118.85,98.19,7.73;10,316.86,128.81,141.41,7.73">Proceedings of the Twenty-First Text REtrieval Conference (TREC)</title>
		<meeting>the Twenty-First Text REtrieval Conference (TREC)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.44,146.90,234.00,7.77;10,317.08,156.70,224.36,7.93;10,317.40,166.67,182.32,7.93" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,458.61,146.90,82.84,7.77;10,317.08,156.86,155.15,7.77">A Related Entity based Approach for Knowledge Base Acceleration</title>
		<author>
			<persName coords=""><forename type="first">Xitong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jerry</forename><surname>Darko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hui</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,488.68,156.70,52.76,7.73;10,317.40,166.67,156.04,7.73">Proceedings of the Text REtrieval Conference (TREC 2013)</title>
		<meeting>the Text REtrieval Conference (TREC 2013)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.44,184.76,234.00,7.77;10,317.40,194.56,224.03,7.93;10,317.18,204.52,225.38,7.73;10,317.40,214.65,98.76,7.77" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,476.41,184.76,65.03,7.77;10,317.40,194.72,102.32,7.77">Resource-adaptive real-time new event detection</title>
		<author>
			<persName coords=""><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Gang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chunqiang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,435.76,194.56,105.67,7.73;10,317.18,204.52,225.38,7.73;10,317.40,214.65,48.25,7.77">Proceedings of the 2007 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;07</title>
		<meeting>the 2007 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;07</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.44,232.58,235.49,7.77;10,317.40,242.38,225.16,7.93;10,317.40,252.51,24.16,7.77" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,526.54,232.58,16.39,7.77;10,317.40,242.54,195.04,7.77">Efficient estimation of word representations in vector space</title>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Kai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,519.33,242.38,18.59,7.73">CoRR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.44,270.44,234.00,7.77;10,317.40,280.40,224.03,7.77;10,317.08,290.20,124.43,7.93" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="10,504.38,270.44,37.06,7.77;10,317.40,280.40,207.07,7.77">Linguistic Regularities in Continuous Space Word Representations</title>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wen</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,317.08,290.20,43.40,7.73">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.44,308.30,234.00,7.77;10,317.40,318.26,224.03,7.77;10,317.40,328.06,225.61,7.93" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="10,397.05,318.26,144.38,7.77;10,317.40,328.22,166.10,7.77">Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space</title>
		<author>
			<persName coords=""><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Jeevan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexandre</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,490.19,328.06,25.83,7.73">EMNLP</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.44,346.15,234.00,7.77;10,317.40,355.96,225.53,7.93;10,317.40,365.92,224.04,7.73;10,317.11,375.88,225.90,7.93" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="10,504.40,346.15,37.05,7.77;10,317.40,356.12,163.62,7.77">Streaming first story detection with application to twitter</title>
		<author>
			<persName coords=""><surname>Petrović</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Saša</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Victor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,497.17,355.96,45.76,7.73;10,317.40,365.92,224.04,7.73;10,317.11,375.88,200.57,7.73">Human Language Technologies: Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.44,393.98,234.00,7.77;10,317.40,403.78,225.16,7.93;10,317.40,413.90,78.46,7.77" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="10,482.31,393.98,59.13,7.77;10,317.40,403.94,142.81,7.77">Streaming Cross Document Entity Coreference Resolution</title>
		<author>
			<persName coords=""><forename type="first">Delip</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,475.02,403.78,64.19,7.73">COLING (Posters)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1050" to="1058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.44,431.83,234.00,7.77;10,317.40,441.64,225.53,7.93;10,317.40,451.60,171.85,7.93" xml:id="b23">
	<monogr>
		<title level="m" type="main" coord="10,462.97,431.83,78.47,7.77;10,317.40,441.64,225.53,7.93;10,317.40,451.60,105.26,7.73">Visualization of Text Streams: A Survey. Knowledge-Based and Intelligent Information and Engineering Systems</title>
		<author>
			<persName coords=""><forename type="first">Artur</forename><surname>Silic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bojana</forename><surname>Basic</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Dalbelo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="31" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.44,469.69,235.48,7.77;10,317.40,479.65,224.03,7.77;10,317.40,489.46,224.04,7.93;10,317.40,499.42,157.16,7.93" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="10,379.45,479.65,161.99,7.77;10,317.40,489.62,163.52,7.77">Large-scale cross-document coreference using distributed inference and hierarchical models</title>
		<author>
			<persName coords=""><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Sameer</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Subramanya</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Amarnag</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Mc-Callum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,498.76,489.46,42.68,7.73;10,317.40,499.42,130.68,7.73">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.44,517.51,234.00,7.77;10,317.40,527.31,209.34,7.93" xml:id="b25">
	<monogr>
		<title level="m" type="main" coord="10,372.27,517.51,169.17,7.77;10,317.40,527.47,156.53,7.77">A survey of methods to ease the development of highly multilingual text mining applications</title>
		<author>
			<persName coords=""><forename type="first">Ralf</forename><surname>Steinberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.44,545.41,235.49,7.77;10,317.40,555.37,224.03,7.77;10,317.40,565.17,134.71,7.93" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="10,498.42,545.41,44.51,7.77;10,317.40,555.37,224.03,7.77;10,317.40,565.33,28.11,7.77">Word representations: A simple and general method for semisupervised learning</title>
		<author>
			<persName coords=""><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,361.97,565.17,13.81,7.73">ACL</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="384" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.44,583.27,235.57,7.77;10,317.40,593.07,224.04,7.93;10,317.40,603.03,171.36,7.93" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="10,317.40,593.23,164.88,7.77">BIT and MSRA at TREC KBA CCR track 2013</title>
		<author>
			<persName coords=""><forename type="first">Jingang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Dandan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lejian</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,497.92,593.07,43.52,7.73;10,317.40,603.03,144.64,7.73">Proceedings of the Text REtrieval Conference (TREC)</title>
		<meeting>the Text REtrieval Conference (TREC)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.44,621.12,235.12,7.77;10,317.40,631.09,224.03,7.77;10,317.40,640.89,224.03,7.93;10,316.90,650.85,148.95,7.93" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="10,429.90,631.09,111.53,7.77;10,317.40,641.05,85.70,7.77">PRIS at TREC2013 Knowledge Base Acceleration Track</title>
		<author>
			<persName coords=""><forename type="first">Chunyun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Weiran</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ruifang</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Weitai</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ji</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Janshu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jing</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,419.74,640.89,121.69,7.73;10,316.90,650.85,122.23,7.73">Proceedings of the Twenty-Second Text REtrieval Conference (TREC)</title>
		<meeting>the Twenty-Second Text REtrieval Conference (TREC)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.44,668.94,235.48,7.77;10,317.40,678.75,224.03,7.93;10,317.18,688.71,224.26,7.73;10,317.13,698.67,164.38,7.93" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="10,474.92,668.94,68.00,7.77;10,317.40,678.91,130.78,7.77">Novelty and redundancy detection in adaptive filtering</title>
		<author>
			<persName coords=""><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Callan</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,465.14,678.75,76.30,7.73;10,317.18,688.71,224.26,7.73;10,317.13,698.67,73.52,7.93">Proceedings of ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;02</title>
		<meeting>ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;02</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
