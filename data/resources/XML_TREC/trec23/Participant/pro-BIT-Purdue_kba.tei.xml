<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,150.24,115.96,314.88,12.62;1,288.43,133.89,32.28,12.62;1,320.70,131.69,5.73,8.77">BIT and Purdue at TREC-KBA-CCR Track 2014 ⋆</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,138.21,171.74,62.13,8.74"><forename type="first">Jingang</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,210.89,171.74,51.21,8.74"><forename type="first">Ning</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Purdue University</orgName>
								<address>
									<settlement>West Lafayette</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,272.65,171.74,58.95,8.74"><forename type="first">Zhiwei</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName coords="1,342.15,171.74,58.54,8.74"><forename type="first">Dandan</forename><surname>Song</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Purdue University</orgName>
								<address>
									<settlement>West Lafayette</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,411.24,171.74,28.36,8.74"><forename type="first">Luo</forename><surname>Si</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Purdue University</orgName>
								<address>
									<settlement>West Lafayette</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,450.17,171.74,26.98,8.74;1,295.96,183.69,18.96,8.74"><forename type="first">Lejian</forename><surname>Liao</surname></persName>
							<email>liaolj@bit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,150.24,115.96,314.88,12.62;1,288.43,133.89,32.28,12.62;1,320.70,131.69,5.73,8.77">BIT and Purdue at TREC-KBA-CCR Track 2014 ⋆</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">74DE66F02287AB601C3DE4EFBE71FD2D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This report summarizes our participation at KBA-CCR track in TREC 2014. Our submissions are generated in two steps: (1) Filtering a candidate documents collection from the stream corpus for a set of target entities; and (2) Estimating the relevance levels between candidate documents and target entities. Three kinds of approaches are employed in the second step, including query expansion, classification and learning to rank. Query expansion is an unsupervised baseline by combining an entity and its related entities as a query to retrieve its relevant documents. Query expansion performs considerably well in vital + useful scenario. It's not difficult to filter a relevant document set from the stream corpus. However, in vital only scenario, supervised approaches are more powerful than query expansion in identifying vital documents for target entities. Our results reveal that learning to rank approaches are more suitable for CCR with current evaluation methodology.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Task Description. A CCR system is required to filter a chronological stream corpus to detect relevant documents for a set of Knowledge Base (KB) entities. Unlike traditional information retrieval and filtering tasks, CCR not only retrieve relevant documents from the stream corpus, but also distinguish relevant documents according to their relevance levels to the target entities. The relevance of a document to an entity is represented by a confidence score in the range of (0, 1000]. To evaluate the system performance, a cutoff value is varied from 0 to 1000 and the documents with scores above the cutoff are treated as relevant. Correspondingly, the documents with scores below the cutoff are irrelevant documents. Two measurements are calculated: (i) max(F (avg(P ), avg(R))) and (ii) max(SU ). SU (Scaled utility) is a metric introduce in <ref type="bibr" coords="1,370.94,612.94,10.51,8.74" target="#b2">[3]</ref> to evaluate the ability of a information filtering system to separate relevant and irrelevant documents. Given a cutoff, we could calculate P, R, F and SU respectively for each entity and obtain the macro-average values of all entities. Given a set of target entities, there are two scenarios: (i) vital only: detecting vital documents in the stream corpus, and (ii) vital + useful: detecting vital and useful documents in the stream corpus.</p><p>Stream Corpus. The stream corpus, a temporally-ordered document collection, contains approximately 20 million documents published during the period from Oct. 2011 to May 2013.</p><p>Target Entity. The target entity set is composed of 71 entities found in the stream corpus, including facilities, persons and organizations. Some entities are already contained in Wikipedia, while others do not exist in any existing KB.</p><p>Compared with previous tracks, TREC-KBA-CCR 2014 is unique from three aspects.</p><p>1. The target entities are selected from the stream corpus itself instead of an existing KB. In previous tracks, all target entities are from either Wikipedia or Twitter. 2. The annotation schema is revised more precisely, including four relevance levels: vital, useful, unknown and non-referent. In addition, the annotation quality is improved significantly. 3. The cutoff between training and test is not consistent for different entities.</p><p>This variation promises each entity exists annotation instances in each relevance levels.</p><p>In TREC-KBA-CCR 2014, we submitted 7 runs, including a baseline run, 2 query expansion runs, 2 classification runs and 2 learning to rank (LTR) runs.</p><p>The rest of this paper is organized as follows: Section 2 introduces an entitycentric filtering step to reduce the volume of stream corpus. Next, we present our relevance estimation approaches in Section 3. Section 4 introduces the bursty features utilized in our supervised approaches in detail. Finally, we summarize the results of our submissions and come up with some conclusions in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Filtering</head><p>According to the assessment analysis of former KBA tracks, most relevant documents mention the target entity explicitly, and merely 0.4% of documents without referring to the target entity are labeled as relevant <ref type="bibr" coords="2,381.34,572.09,9.96,8.74" target="#b1">[2]</ref>. Therefore, it is not indispensable to process all the documents in the corpus, which is extraordinarily time-consuming and laborious. Before further relevance estimation, we undertake an effective entity-centric filtering step to remove obviously irrelevant documents from the stream corpus.</p><p>As described in <ref type="bibr" coords="2,220.65,632.21,9.96,8.74" target="#b4">[5]</ref>, we first index the documents in the stream corpus with ElasticSearch, and then filter it with an entity-centric phrase query. To construct a high-recall query to retain as many candidate documents as possible, we need to expand enough surface forms for each target entity. Freebase<ref type="foot" coords="3,398.81,117.42,3.97,6.12" target="#foot_0">1</ref> hereby is utilized to expand the surface forms for the entities. The entities can not be found in Freebase are not considered as popular entities, so we do not expand it at all.</p><p>We formulate a baseline query to filter the stream corpus. Only the matched documents are retained and processed in subsequent process. Given an entity E, the surface form set of</p><formula xml:id="formula_0" coords="3,134.76,178.77,345.84,44.53">E is Rel(E) = {E i |i ∈ [1, M ]}, the baseline phrase query for E is E ∨ E 1 ∨ E 2 ∨ • • • ∨ E M , (<label>1</label></formula><formula xml:id="formula_1" coords="3,476.35,213.74,4.24,8.74">)</formula><p>where the ∨ operator ensures at least one operand is true, representing the corresponding term is matched in the document.</p><p>To evaluate the filtering performance, we calculate the maximum macro a vg(Recall) by setting the cutoff value as 0, in which case all the retrieved documents are considered as positive instances in both scenarios. The results are listed in Table 1. The filtering performance is surprisingly satisfactory, proving that most relevant documents, either vital or useful, mention the target entity explicitly. The volume of the candidate documents are reduced to less than 1 million after filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Relevance Estimation</head><p>A candidate document collection is obtained from the stream corpus after filtering, we estimate the relevance between the candidate documents and target entities. We have employed 3 kinds of approaches, including query expansion, classification and LTR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Query Expansion</head><p>Although the baseline query demonstrated in Equation 1 has achieved considerable filtering performance, it can not estimate the fine-grained relevance level between a document and an entity. Query Expansion (QE) is an effective approach to solve this problem. In our work, we expand the baseline phrase query with contextual entities found in target entities' profiles and annotation data, and then search against the built index to acquire the candidate documents. For example, {E i |i ∈ [1, N ] } is the related entity set we found for target entity E, the query is expanded as follows:</p><formula xml:id="formula_2" coords="4,235.54,171.97,245.05,9.65">Baseline ∧ {E 1 ∨ E 2 ∨ • • • ∨ E N } (2)</formula><p>Baseline represents the baseline query demonstrated in Equation <ref type="formula" coords="4,422.43,189.07,3.88,8.74" target="#formula_0">1</ref>. The return documents of the query are relevant documents and the ranking scores are scaled to the final confidence scores.</p><p>In addition to the baseline run, we submitted 2 other QE runs: QE-Profile and QE-Labeled. The differences lies in the query terms they utilized. QE-Profile expands the baseline query with the related entities found in entities' profiles, while QE-Labeled expands the baseline query with the related entities found in the annotation data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Classification</head><p>CCR is usually formulated as a binary classification task to distinguish relevant/irrelevant documents (i.e., vital + useful ) or vital/useful documents (i.e., vital only).</p><p>We submitted 2 classification runs: ClassificationV and ClassificationU. The former one classifies the candidate documents into vital or non-vital, yet the latter one classifies them into relevant (vital + useful ) or irrelevant (unknown + non-referent). All the classifiers are implemented with random forest classification model, which was reported as the best classification model in CCR.</p><p>Please note that we build a global classifier with all training instances instead of building a local classifier for each entity for simplicity. The classification results would be improved if local classification model could be built for every entity individually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Learning to Rank</head><p>CCR can be considered as a learning to rank (LTR) task as well because of the intrinsic ordering of different relevance levels, i.e., vital &gt; usef ul &gt; unknown &gt; non -ref rent.</p><p>We submitted 2 LTR runs: GlobalRank and BinaryRank. First, we build a global ranking model with all training instances. Moreover, we build a local ranking model for the entity with enough training instances . GlobalRank rank the test instances with the global ranking model. In terms of BinaryRank, if there exists a local model for an entity, we rank the test instances with the local model, otherwise the global model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Features</head><p>Classification and LTR are both supervised approaches, for whom we adopt the same semantic feature sets introduced in <ref type="bibr" coords="4,323.44,644.17,9.97,8.74" target="#b4">[5]</ref>. CCR is filtering relevant documents from a temporally-ordered stream corpus and entities are evolving with the passage of time, but the semantic features can not portray the dynamic characteristics of entities in the stream corpus. Temporal features are introduced to make up for this deficiency in previous work <ref type="bibr" coords="5,331.17,142.91,10.52,8.74" target="#b4">[5,</ref><ref type="bibr" coords="5,341.69,142.91,7.01,8.74" target="#b0">1]</ref>.</p><p>We develop bursty features as our temporal features. The underlying intuition is that the appearance of an entity in the stream corpus is signaled by a 'burst of activity', with relevant documents rising sharply in frequency as something important are happening around the target entity. In previous work, Wikipedia daily view statistics are utilized to detect entities' bursty period, during which documents appear is more possible to be relevant than those not. Unfortunately, not all entities are from Wikipedia, we can not adopt the statistics to capture bursty periods. Alternatively, we calculate the bursty periods based on two other statistics. (1) Google Trends<ref type="foot" coords="5,263.30,249.31,3.97,6.12" target="#foot_1">2</ref> is a similar resource we can resort to. It is a public web statistics, based on Google Search, that shows how often a particular search term is entered relative to the total search-volume. Besides, (2) entities' appearances in the stream corpus are also utilized to detect their bursty periods. Figure <ref type="figure" coords="5,165.66,298.71,4.98,8.74">1</ref> plots an example of the bursts of Wikipedia entity Benjamin Bronfman with two obvious bursty periods over the entire text stream.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1. Example of Bursts of Entity Benjamin Bronfman</head><p>For entity E, we have a daily view/search statistics sequence</p><formula xml:id="formula_3" coords="5,407.45,509.30,87.08,9.69">v = (v 1 , v 2 , • • • , v n ).</formula><p>We detect E's bursts from v with a tailored moving average (MA) method <ref type="bibr" coords="5,467.32,521.29,9.96,8.74" target="#b3">[4]</ref>. Unlike the moving average method in <ref type="bibr" coords="5,303.66,533.24,10.51,8.74" target="#b3">[4]</ref> using a unified cutoff, we calculate an individual cutoff for each moving average (MA). More concretely, for each item v i in v,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Calculate its moving average of length w as</head><formula xml:id="formula_4" coords="5,138.97,575.73,387.47,24.87">M A w (i) = vi+vi-1+•••+vi-w+1 w . 2. Calculate cutoff c(i) based on previous MA sequence P re M A = (M A w (1), • • • , M A w (i))</formula><p>as c(i) = mean(P re M A ) + β • std(P re M A ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Bursty day sequence: d</head><formula xml:id="formula_5" coords="5,256.31,635.46,94.08,9.66">= {i|M A w (i) &gt; c(i)}.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Calculate daily bursty weights w</head><formula xml:id="formula_6" coords="6,298.37,116.31,94.29,14.38">= {w i | M Aw(i) c(i) , i ∈ d}.</formula><p>The moving average length can be varied to detect long-term or short-term bursts. We set the moving average length as 7 days (i.e., w = 7). The cutoff value is empirically set as 3 times the standard deviation of the M A (i.e., β = 2). Moreover, we compact the consecutive days in d into bursty periods. The bursty weight for each period is calculated as the average weight of all the bursts in this period. </p><p>1-t-tstart t end -tstart is a decaying coefficient reflecting the intuition that the documents appear at the beginning of a burst are more informative than those appear at the end.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>All the results are listed in Table <ref type="table" coords="6,281.97,423.46,3.87,8.74" target="#tab_2">2</ref>. It's surprising that baseline and Query Expansion are excellent enough to filter the relevant documents from the stream corpus. Nearly all the truth data are detected from the stream corpus. In vital + useful scenario, the value of F is dominated by recall, and the best performance is achieved when cutoff is equal to 0. This phenomenon also exist in vital scenario, all our approaches achieve close values of macro average F . In vital only scenario, LTR methods achieve better micro average F than classification approaches, and BinaryRank achieves the best performance out of all approaches. This reveals that LTR approachs are more suitable for CCR in current evaluation framework. A possible explain is that the ranked output of LTR approaches can be transformed to the desired format of confidence score in a straightforward manner, while the binary output of classification need additional mechanisms to be transformed into the target format. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,156.85,327.99,301.65,83.80"><head>Table 1 .</head><label>1</label><figDesc>Recall of baseline expansion</figDesc><table coords="3,156.85,348.79,301.65,63.00"><row><cell>Filtering Method</cell><cell cols="2">max(macro average(R)) Vital Vital + Useful</cell></row><row><cell cols="2">baseline query .987</cell><cell>.985</cell></row><row><cell cols="3">Note: The recall metrics are calculated with ground truth data</cell></row><row><cell cols="3">(trec-kba-2014-10-15-ccr-and-ssf.after-cutoff.tsv ) excluding entities without</cell></row><row><cell cols="3">training end date field.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.76,231.02,345.84,99.70"><head>4.1 Feature Representation Given</head><label></label><figDesc>a document D and entity E, we define a bursty value b(D, E) to represent their temporal relations. Let t be the timestamp of D. If t is in E's bursty period [t start , t end ], then b(D, E) is calculated as Equation3shows. If t is not in any butsy period, b(D, E) would be set as 0.</figDesc><table /><note coords="6,166.64,314.23,65.01,9.30;6,241.74,307.49,37.38,9.65;6,235.06,321.06,50.74,9.66;6,287.49,314.23,161.22,10.63"><p>b(D, E) = (1 -t -t start t end -t start ) • bw (tstart,t end ) (E), t ∈ [t start , t end ]</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,134.76,115.91,345.82,72.90"><head>Table 2 .</head><label>2</label><figDesc>Results of official runs. All the measurements are reported by official scorer with cutoff-step-size=10.</figDesc><table coords="7,165.82,147.67,297.95,41.14"><row><cell></cell><cell></cell><cell cols="2">Vital Only</cell><cell></cell><cell></cell><cell cols="2">Vital + Useful</cell></row><row><cell>Run</cell><cell cols="8">Macro Average Micro Average Macro Average Micro Average</cell></row><row><cell></cell><cell>F</cell><cell>SU</cell><cell>F</cell><cell>SU</cell><cell>F</cell><cell>SU</cell><cell>F</cell><cell>SU</cell></row><row><cell>baseline</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.73,657.44,117.68,7.47"><p>https://www.freebase.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,144.73,657.44,136.51,7.47"><p>http://www.google.com/trends/</p></note>
		</body>
		<back>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Bursts</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="6,138.34,623.93,342.23,7.86;6,146.91,634.88,333.67,7.86;6,146.91,645.84,333.68,7.86;6,146.91,656.80,315.98,8.11;7,215.91,180.95,16.38,7.86;7,247.92,180.95,109.06,7.86;7,372.60,180.95,16.38,7.86;7,404.60,180.95,47.36,7.86;7,160.33,192.31,71.96,7.86;7,247.92,192.31,109.06,7.86;7,372.60,192.31,16.38,7.86;7,404.60,192.31,47.36,7.86;7,157.65,203.66,74.64,7.86;7,247.92,203.66,109.06,7.86;7,372.60,203.66,16.38,7.86;7,404.60,203.66,47.36,7.86;7,151.59,215.02,80.70,7.86;7,247.92,215.02,109.06,7.86;7,372.60,215.02,16.38,7.86;7,404.60,215.02,47.36,7.86;7,151.59,226.38,80.70,7.86;7,247.92,226.38,109.06,7.86;7,372.60,226.38,16.38,7.86;7,404.60,226.38,47.36,7.86;7,157.39,237.74,74.90,7.86;7,247.92,237.74,109.06,7.86;7,372.60,237.74,16.38,7.86;7,404.60,237.74,47.36,7.86;7,157.69,249.09,199.29,7.86;7,372.60,249.09,16.38,7.86;7,404.60,249.09,47.36,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,261.82,623.93,218.75,7.86;6,146.91,634.88,28.91,7.86">Cumulative citation recommendation: classification vs. ranking</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ramampiaro</surname></persName>
		</author>
		<idno type="DOI">10.1145/2484028.2484151</idno>
		<idno>2484151 .461 .299 .348 .329 .960 .950 .962 .970 QE-Profile .461 .321 .360 .336 .960 .950 .962 .970 QE-Labeled .461 .317 .370 .344 .960 .950 .962 .970 ClassificationU .464 .301 .344 .295 .951 .938 .955 .963 ClassificationV .460 .344 .341 .348 .951 .938 .955 .963 BinaryRank .459 .341 .379 .345 .951 .938 .955 .963 GlobalRank ..460 .343 .373 .348 .951 .938 .955 .963</idno>
		<ptr target="http://doi.acm.org/10.1145/2484028" />
	</analytic>
	<monogr>
		<title level="m" coord="6,198.04,634.88,282.54,7.86;6,146.91,645.84,197.44,7.86;6,407.90,645.84,66.61,7.86">Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 36th international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="941" to="944" />
		</imprint>
	</monogr>
	<note>SIGIR &apos;13, ACM</note>
</biblStruct>

<biblStruct coords="7,138.34,285.42,342.24,7.86;7,146.91,296.38,333.67,7.86;7,146.91,307.34,333.69,8.11;7,146.91,318.94,320.09,7.47" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,181.25,296.38,299.33,7.86;7,146.91,307.34,16.79,7.86">Building an Entity-Centric Stream Filtering Test Collection for TREC 2012</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kleiman-Weiner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Re</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<ptr target="http://trec.nist.gov/act_part/conference/notebook.papers/KBA.OVERVIEW.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="7,188.30,307.34,192.96,7.86">Proceedings of the Text REtrieval Conference</title>
		<meeting>the Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.34,329.25,342.24,7.86;7,146.91,340.21,139.24,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,262.98,329.25,146.89,7.86">The trec 2002 filtering track report</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,433.58,329.25,47.00,7.86;7,146.91,340.21,110.57,7.86">TEXT RE-TRIEVAL CONFERENCE</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.34,351.17,342.24,7.86;7,146.91,362.13,333.67,7.86;7,146.91,373.09,333.68,7.86;7,146.91,384.05,315.98,8.11" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,350.50,351.17,130.08,7.86;7,146.91,362.13,156.24,7.86">Identifying similarities, periodicities and bursts for online search queries</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Vagena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gunopulos</surname></persName>
		</author>
		<idno type="DOI">10.1145/1007568.1007586</idno>
		<ptr target="http://doi.acm.org/10.1145/1007568.1007586" />
	</analytic>
	<monogr>
		<title level="m" coord="7,322.49,362.13,158.09,7.86;7,146.91,373.09,193.97,7.86;7,399.35,373.09,51.21,7.86">Proceedings of the 2004 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2004 ACM SIGMOD International Conference on Management of Data<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="131" to="142" />
		</imprint>
	</monogr>
	<note>SIGMOD &apos;04</note>
</biblStruct>

<biblStruct coords="7,138.34,395.01,342.24,7.86;7,146.91,405.97,205.09,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,313.42,395.01,162.96,7.86">Bit and msra at trec kba ccr track 2013</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,146.91,405.97,176.43,7.86">Notebook of the TExt Retrieval Conference</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
