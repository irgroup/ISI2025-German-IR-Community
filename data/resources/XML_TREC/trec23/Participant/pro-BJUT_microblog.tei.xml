<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">97B61933C5219000E2F64F597D1D816C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Micro-blog retrieval</term>
					<term>graph-based method</term>
					<term>sentence similarity</term>
					<term>re-ranking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the second participation of BJUT in the TREC Micro-blog Track. Two tasks are proposed in this year, including ad hoc search task and tweet timeline generation task. We attended the first task and focused on the method for re-ranking of the returned search results. Specifically, a graph-based method is proposed to re-rank the twitters returned by the official API, namely we re-rank the results by detecting whether some given characteristics are existing or not. Also, we introduce the details of our system, which consists of data preprocessing, system structure, and rank method &amp; results analysis module.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>This paper describes the second participation of BJUT in the TREC Micro-blog Track <ref type="bibr" coords="1,144.72,405.69,7.38,6.98">[1]</ref> . This year's track focuses on two tasks that are Ad Hoc Search Task and Tweet Timeline Generation Task. We attended the first task and submitted three results. The task is the same as the last year, that all participants should answer a query by providing a list of relevant tweets ranked in decreasing order by predicted relevance score.</p><p>Since the whole data set is unknown in this year, we can only receive the 10 thousand tweets at most for each topic through the official API. Therefore in this track, we focus on the re-ranking methods for the received tweets through the API, but we only make use of 1500 tweets that are searching results to re-rank. We perform the experiments on the 2014 TREC Micro-blog data using the same re-ranking method with three sentence similarity computing methods as the value of linking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. CORPUS AND SYSTEM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Corpus</head><p>This year the corpus is the same as the data of 2013 Micro-blog track that is more than an order of magnitude larger than the previously use tweets 2011 collection. Approximately, the corpus consists of 259,057,269 tweets over a two-month period: 1 February, 2013-31 March, 2013 (inclusive). We cannot obtain the whole collection through the official API and only receive 10 thousand relevant tweets for each topic through the official search API <ref type="bibr" coords="1,134.46,703.95,7.38,6.98" target="#b1">[2]</ref> . The 10 thousand tweets are encoded by json and composed of tweet id, user id, text and so on. But we only deal with 1500 tweets of one topic with our system to get the result, and the number is an experience point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Pre-Processing</head><p>There are four tasks to be done when we deal with one tweet of each topic in our system: 1) extracting the tweet id and text, 2) judge features, including whether or not have http links and re-tweet, 3) removing the http links, and removing the no-English, 4) converting the tweet text to lowercase letters Firstly, we extract the tweet id and its text of each tweet from the corpus file that contains only a single topic. If a tweet with the label "RT" in the tweets text is found, we will give it a tag such as 1, if not found it would be 0. And the "http" feature is the dame. Then remove the http links, the retweeted_status object and the no-English char. Finally we convert the processed tweet text to lowercase letters. And write the content into a new file. For example we process the tweet that is "id: 0001, text: RT my name is rose, http://www.trec.cn, …" into "id: 0001, text: my name is rose, RT: 1, http: 1". As shown in FIG. <ref type="figure" coords="2,130.51,85.22,3.65,10.79" target="#fig_0">1</ref>, we performed the experiments on the 2013 TREC Micro-blog data using the official data API and my re-ranking system which consists of data preprocessing, re-ranking of searching results and results analysis module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. System Construction</head><p>As we cannot get the whole collection, we only deal with each topic one by one through our system. When we get the final results, the tweets of different topics are independent of each other. And our system mainly contains three parts as the Fig. <ref type="figure" coords="2,61.77,180.92,4.06,10.79" target="#fig_0">1</ref> shows.  The first chapter is the corpus and preprocessing. We already detailed introduce this part in previous chapter.  The second part is the re-ranking of search results. It is th e most important part. First of all, we make use of the top 1500 tweets in the new corpus file of one topic to first rerank through graph-based method, and then we make use of the features form the preprocessing tweet to fix the ord er of the results.  The final part is the results. The number of result tweets i s 1000 by one topic, and one result contains the topic nu mber, an unused column, a tweet id, the rank, the score an d the run tag such as 'MB171 Q0 307353530413490177 1 2.946289 OSIM'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. RE-RANKING</head><p>In our system, there are two reorder on tweets. The first time of re-ranking is sorting the whole tweets that have been pre-processed by the graph-based method, that is we treat every tweet as a node and treat the similarity between two tweets as an edge, so they constitute a graph; and the next time is ranking by the order of the features, that is the ranking of tweets that contain the most important characteristic is high, and the ranking of tweets that contain the second important characteristic is following and so on, in addition, the tweets belong to one characteristic is ranked by the score from the first time order.</p><p>For every topic we import the top 1500 tweets which are pre-processed through our system into one file which we consider as an initial whole text. All of our three results are based on above hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Graph-based ranking method</head><p>A social network is a mapping of relationships between interacting entities (e.g. people, organizations, and computers). Social networks are represented as graphs, where the nodes represent the entities and the links represent the relations between the nodes. For one topic of micro-blog TREC, the 1500 tweets got through the official API can be viewed as a network of tweets that are related to each other. Some tweets are more similar to each other while some others may share only a little information with the rest of the tweets. Inspired by the work of ref. [3][4], we think that the tweets that are similar to many of the other tweets in the searching results are more central to the topic. So there are two points to clarify in the task. First is how to define similarity between two tweets, and second is how to compute the overall centrality of a tweet given its similarity to other tweets. a. Define similarity To define similarity, we use three methods. The first measure of similarity between two tweets is cosine similarity. This given two vectors of attributes, A and B, and the attribute in a tweet is a word which is not English stop word, the cosine similarity <ref type="bibr" coords="2,539.82,131.73,7.38,6.98" target="#b4">[5]</ref> , cos(θ), is represented using a dot product and magnitude as</p><formula xml:id="formula_0" coords="2,306.24,158.60,242.57,44.37">  cos  =     1 2 2 1 1 n i i i n n i i i i A B A B         (1)</formula><p>The second measure of similarity between two tweets is dice coefficient <ref type="bibr" coords="2,346.26,216.81,6.72,6.98" target="#b5">[6]</ref>. Formula is as follows  </p><formula xml:id="formula_1" coords="2,306.54,230.93,243.11,28.48">, sim A B = 2C A B  = 2 A B A B  <label>(2)</label></formula><p>where A and B are the number of words in tweets A and B, respectively, and C is the number of words shared by the two tweets.</p><p>The third one is improved dice coefficient, as follows</p><formula xml:id="formula_2" coords="2,306.42,312.43,243.20,28.44">  , msim A B = C B = A B B <label>(3)</label></formula><p>This method can build the whole tweets into a directed graph.</p><p>All three of these can also use the tf-idf of word to create the vector, but this we can use it because we can't acquire it.</p><p>b. Compute the overall centrality A simple way of assessing tweet centrality is to count the number of similar tweets for each tweet. When computing tweet centrality, we have treated each edge as a vote to determine the overall centrality value of each tweet. So a tweet centrality can be computed one time as follow</p><formula xml:id="formula_3" coords="2,305.94,467.74,243.66,26.02">  TR  = [ ] [ ] deg[ ] adj TR     <label>(4)</label></formula><p>where   TR  is the centrality of tweet  , [ ] adj  is the set of tweets that are adjacent to  , and deg[ν] is the degree of the tweet  .</p><p>If we assign a uniform probability for jumping to any node in the graph, we are left with the following modified version of Equation ( <ref type="formula" coords="2,345.76,566.44,3.46,10.76" target="#formula_3">4</ref>), which is known as PageRank <ref type="bibr" coords="2,473.10,565.11,7.44,6.98" target="#b6">[7]</ref> :</p><formula xml:id="formula_4" coords="2,305.94,581.19,243.54,26.04">  TR  = [ ] [ ] (1 ) deg[ ] adj TR N        <label>(5)</label></formula><p>Various studies have tested different damping factors, but it is generally assumed that the damping factor will be set around 0.85.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Re-ranking by features</head><p>When computing centrality, we have treated each edge as a vote to determine the overall centrality value of each tweet. This is a totally democratic method where each vote counts the same. However, in many types of social networks, not all of the relationships are considered equally important. Centrality may have a negative effect in the quality of the ranking in some cases where several uncorrelated tweets vote for each other and raise their centrality, and make the correlated tweets get a low order. So we will make use of the features to modify it.</p><p>In our system, we get some features, such as whether to forwarding, whether to have http and the similarity between tweet and query. Then we make the ranking of tweets that contain the most important characteristic be high order, and the ranking of tweets that contain the second important characteristic is following and so on, in addition, the tweets belong to one characteristic is ranked by the score from the first time order.</p><p>In here, we make the similarity between tweets and query to be the most important characteristic. If a tweet contain the whole words of query, we will mark it a high order, and these tweets that contain the whole words of query are ranked by the score computed through the first method, if some of these tweets have the same score, we will rank them by the characteristic, whether to forwarding and whether to have http.</p><p>In this part, we can also make use of more features to improve the ranking. We will do it in the future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RESULTS</head><p>In this year's TREC Microblog Track, we submit 3 versions of runs which are shown in the Tab. 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper, we describe the details of our methods and system structure. In our system the first run have received the best performance, and this year's performance is much better than last year because the emphasis of the two years is different, because last year focus on query expansion and this year is re-ranking of searching results. This year, our results that are good or bad depends on the search results by the official API. But we also improve the results through other method, including calculating the similarity value of two tweets by tf-idf, and distinguish the linking term of two tweets by features. Then in the coming time, we will make use of these methods to improve the results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,359.76,726.50,134.72,10.79;1,343.14,452.94,167.94,273.12"><head>FIG. 1</head><label>1</label><figDesc>FIG. 1 The Framework of System</figDesc><graphic coords="1,343.14,452.94,167.94,273.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,45.54,374.61,227.24,55.41"><head>TABLE 1 .</head><label>1</label><figDesc>RESULTS OF OUR TEAM</figDesc><table coords="3,45.54,384.41,227.24,45.62"><row><cell>Run id</cell><cell>MAP</cell><cell>R-Prec</cell><cell>bpref</cell><cell>P@10</cell><cell>P@20</cell></row><row><cell>OSIM</cell><cell>0.1708</cell><cell>0.2207</cell><cell>0.2673</cell><cell>0.4182</cell><cell>0.3682</cell></row><row><cell>NSIM</cell><cell>0.1690</cell><cell>0.2169</cell><cell>0.2655</cell><cell>0.3982</cell><cell>0.3536</cell></row><row><cell>NCOS</cell><cell>0.1659</cell><cell>0.2198</cell><cell>0.2667</cell><cell>0.3673</cell><cell>0.3255</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,80.19,628.47,210.40,8.61;3,63.00,637.65,135.67,8.61" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Micro-Blog Track</forename><surname>Guidelines</surname></persName>
		</author>
		<ptr target="https://github.com/lintool/twitter-tools/wiki/TREC-2014-Track-Guidelines" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,63.00,646.83,227.62,8.61;3,63.00,655.95,137.19,8.61" xml:id="b1">
	<monogr>
		<ptr target="https://github.com/lintool/twitter-tools/wiki/TREC-2013-API-Specifications" />
		<title level="m" coord="3,63.00,646.83,99.91,8.61">TREC 2013 API Specifications</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,63.00,665.13,227.60,8.61;3,63.00,674.31,95.80,8.61" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="3,136.50,665.13,154.10,8.61;3,63.00,674.31,74.82,8.61">LexRank: Graph-based lexical centrality as salien ce in text summarization</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,63.00,683.43,225.64,8.61;3,62.88,692.61,227.63,8.61;3,62.88,701.79,48.87,8.61" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="3,120.24,683.43,168.41,8.61;3,62.88,692.61,76.37,8.61">Topic-sensitive pagerank: A context-sensitive ranking algorithm for web search</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">H</forename><surname>Haveliwala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,144.23,692.61,146.28,8.61;3,62.88,701.79,28.26,8.61">IEEE Transactions on Knowledge and Data En gineering</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,63.00,710.97,201.26,8.61" xml:id="b4">
	<monogr>
		<ptr target="http://en.wikipedia.org/wiki/Cosine_similarity" />
		<title level="m" coord="3,63.00,710.97,52.19,8.61">Cosine similarity</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="3,63.00,720.09,227.62,8.61;3,63.00,729.27,99.51,8.61" xml:id="b5">
	<monogr>
		<ptr target="http://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient" />
		<title level="m" coord="3,63.00,720.09,81.56,8.61">Sørensen-Dice coefficient</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="3,63.00,738.45,227.58,8.61;3,62.88,747.57,117.23,8.61" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="3,200.07,738.45,90.51,8.61;3,62.88,747.57,95.54,8.61">The PageRank Citation Rank ing: Bringing Order to the Web</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
