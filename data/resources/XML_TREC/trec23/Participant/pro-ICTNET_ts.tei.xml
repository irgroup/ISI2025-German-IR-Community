<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,152.64,96.73,292.68,6.74">ICTNET at Temporal Summarization Track TREC 2014</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,121.20,108.94,31.47,9.00"><forename type="first">Lei</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<postCode>100190</postCode>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,162.97,108.94,45.88,9.00"><forename type="first">Hainan</forename><surname>Zhang</surname></persName>
							<email>zhanghainan@software.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<postCode>100190</postCode>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,218.88,108.94,29.24,9.00"><forename type="first">Siying</forename><surname>Li</surname></persName>
							<email>lisiying@software.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<postCode>100190</postCode>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,258.24,108.94,33.56,9.00"><forename type="first">Zhiyuan</forename><surname>Ji</surname></persName>
							<email>jizhiyuan@software.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<postCode>100190</postCode>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,303.37,108.94,28.83,9.00"><forename type="first">Qian</forename><surname>Liu</surname></persName>
							<email>liuqian@software.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<postCode>100190</postCode>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,342.00,108.94,26.91,9.00"><forename type="first">Yue</forename><surname>Liu</surname></persName>
							<email>liuyue@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<postCode>100190</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,377.76,108.94,40.60,9.00"><forename type="first">Dayong</forename><surname>Wu</surname></persName>
							<email>wudayong@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<postCode>100190</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,426.96,108.94,42.99,9.00"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<postCode>100190</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,152.64,96.73,292.68,6.74">ICTNET at Temporal Summarization Track TREC 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BDE96E4A293B59BE9D00E1DD4664BD72</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Temporal Summarization task is a standard Information Retrieval problem. The goal of the task is to generate sequential update summarization, which are useful, new and timely sentence-length updates about a developing event <ref type="bibr" coords="1,193.20,260.17,7.67,5.79" target="#b0">[1]</ref> . The event refers to a temporally acute topic, and each topic contains the start time and end time. There are more event types than the last year. They are accident, bombing, hostage, impact event, protest, riot, shooting and storm. Formally, given the time-ordered corpus, the query and the relevant time range, our system outputs a list of relevant sentence identifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Preprocessing</head><p>The first step of preprocessing is downloading the filtered data from the TREC-TS website <ref type="bibr" coords="1,495.12,356.17,7.67,5.79" target="#b1">[2]</ref> . Then we use the GPG key, which can be obtained after submitting the TREC agreement, to decompress the data. In order to deal with the big scale of the data downloading from the website, we filtered the data in two steps. First, any documents that were published out-with the time periods of the 15 events from the TREC-TS 2014 track topics were removed, i.e. only documents with timestamps between the start and end tag for one or more TREC-TS 2014 topics were kept. Second, we build index for the documents whose titles and contents were likely to contain at least one word of the query. Then we use the useful open source indexing tool Lucene to build the index of the filtered data to further reduce the amount of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">query analysis</head><p>We also analyze the 15 test queries. There are 6 test query belonging to protest category, 3 belonging to storm, and each have 1 test query of category accident, bombing, riot, hostage, impact even, shooting. Timeframe of two query with same category may have crossed. Such as query22 and query23, belonging to protest category, and time overlap. So, we cannot judge whether it is related with query just by topic category. It make getting related document sentences matching the query more difficulty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Idea</head><p>We consider not only the accuracy but also recall. Matching to the query can get more accurate of the search result, but the recall is extremely low. In order to improve the recall, query expansion is almost an essential process. Thus we expand the test query, and then use the expended query on the matching method. Using query expansion method, recall has been greatly improved. For the expanded query is still relatively strict, not much loss of accuracy.</p><p>But It have two drawbacks . They are as followed:</p><p>1. Limited by the degree of expansion, the recall amount of relative result is still low 2. It may miss some related documents and recall some not related documents using method of matching to the query. Now we talk about the second. Missing related documents is because the document does not appear the query or expansion query. So it will miss the document though it is relate to the query. Recalling not related documents because the page of the document is not a regular document. There may be a lot of advertising, or other related content recommendation. If the query appeared in advertising or related recommendation, it may cause fault result be recalled and reducing the accuracy. So, I consider to use the topic of the document to judge if the document is related to the test query, not just using matching expanded query words. We use some keyword as feature to describe topic. To select keyword feature, we use LDA <ref type="bibr" coords="2,140.40,168.49,7.68,5.79" target="#b2">[3]</ref> and SVM <ref type="bibr" coords="2,189.36,168.49,7.68,5.79" target="#b3">[4]</ref> model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Generate Sequential Update Summarization</head><p>After data preprocessing, we use two methods to get the final results. They are LDA and SVM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Latent Dirichlet Allocation Module</head><p>LDA is an unsupervised learning method. We use the LDA to find the latent semantic topic. For each query, we used each document which in the time range as the input of the LDA model, and we would get ten different topics. Then we build the all-query index as the standard documents which title have all of the query words. For each topic we score the all-query index and get its scores. Comparing the scores of the ten topics and the all-query score, we can identify the most similar topic of the query in the ten topics from the result of LDA automatically.</p><p>The LDA model can generate a list of keywords, in which every word has its own weight. Thus we can use the list of keywords to score the sentence and drop the sentences with score lower than the threshold. The keyword scoring method is described as following:</p><formula xml:id="formula_0" coords="2,208.80,376.77,182.15,10.43">𝑆𝑐𝑜𝑟𝑒 𝑆 = ∑ 𝑣𝑎𝑙𝑢𝑒 𝑤 , 𝑤 ∈ 𝑆 ,</formula><p>where value 𝑤 is the score of word 𝑤 in the list of keywords, 𝑆 is the 𝑖 sentence of topic k. If the score of sentence is larger than the threshold, we put this sentence into the result of our method. Otherwise, drop it.</p><p>After the process of sentences scoring, we need post-processing on the results of our method. On the one hand, we have to sort the results timely due to the importance of expected gain with latencydiscounted. We use a simple distance function to find the same sentences and drop the latter one with time stamp. On the other hand, we drop the sentence with the length shorter than 3 and longer than 40. Because the short sentences and the long sentences may not contain the important information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Support Vector Machine method</head><p>SVM is a supervised learning classifier. Its classification results often depend on the features chosen for SVM. According to this idea, we marked some corpus for training SVM classifier for each query. We used chi-square to select keywords for each query as SVM features. As the same time, we can also get the weight of the keyword. Then, we train classifiers for each test query. After getting the classifier, we classify documents within the time range of test query, judging whether the document is related to the query. If related, remain it for further processing. Or discarded directly. After classifying the documents, we get the related documents. Then we calculate the sentence score of the related document as the method of LDA use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>We submitted a total of four runs. Run1 is the most basic result of LDA module. Run4 is the improved version of run1. Run4 removes the sentences that do not contain any of the top 100 key words. Run2 and run3 are the results of SVM module. We compare these runs as Table <ref type="table" coords="2,442.75,709.90,3.56,9.00" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This paper describes the two methods and the complete process of us when doing this temporal sequential update summarization task. We use both supervised and unsupervised method to accomplish the requirements of the task of this year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Acknowledge</head><p>We would like to thank all organizers and assessors of TREC and NIST. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,99.12,77.57,375.50,319.35"><head>Table 1 .</head><label>1</label><figDesc>The comparison of our four runs.</figDesc><table coords="3,133.44,96.05,341.18,300.87"><row><cell>Run  ID</cell><cell></cell><cell>Latency  Gain</cell><cell>Latency  Comp.</cell><cell>HM</cell></row><row><cell></cell><cell>AVG</cell><cell>0.0082</cell><cell>0.4929</cell><cell>0.016</cell></row><row><cell></cell><cell>STD</cell><cell>0.0063</cell><cell>0.2201</cell><cell>0.0121</cell></row><row><cell></cell><cell>MIN</cell><cell>0.0015</cell><cell>0.1537</cell><cell>0.0029</cell></row><row><cell>run1</cell><cell>MAX</cell><cell>0.0219</cell><cell>0.965</cell><cell>0.0422</cell></row><row><cell></cell><cell>AVG</cell><cell>0.0458</cell><cell>0.0773</cell><cell>0.0311</cell></row><row><cell></cell><cell>STD</cell><cell>0.1152</cell><cell>0.101</cell><cell>0.0473</cell></row><row><cell></cell><cell>MIN</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>run2</cell><cell>MAX</cell><cell>0.468</cell><cell>0.339</cell><cell>0.1543</cell></row><row><cell></cell><cell>AVG</cell><cell>0.0632</cell><cell>0.105</cell><cell>0.053</cell></row><row><cell></cell><cell>STD</cell><cell>0.1265</cell><cell>0.1366</cell><cell>0.0882</cell></row><row><cell></cell><cell>MIN</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>run3</cell><cell>MAX</cell><cell>0.468</cell><cell>0.4515</cell><cell>0.3327</cell></row><row><cell></cell><cell>AVG</cell><cell>0.0092</cell><cell>0.4927</cell><cell>0.0178</cell></row><row><cell></cell><cell>STD</cell><cell>0.0069</cell><cell>0.2201</cell><cell>0.0131</cell></row><row><cell></cell><cell>MIN</cell><cell>0.0023</cell><cell>0.1537</cell><cell>0.0046</cell></row><row><cell>run4</cell><cell>MAX</cell><cell>0.0238</cell><cell>0.965</cell><cell>0.0456</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,90.00,505.90,417.75,64.20"><head></head><label></label><figDesc>This work is sponsored by 973 Program of China Grants No.2012CB316303&amp;No.2013CB329602, 863 program of China Grants No. 2012AA011003&amp;No. 2013AA01A213,NSF of China Grants No.61232010&amp;No.61173064, and by 242 Program of China Grants No. 2013F099, and by the National Key Technology R&amp;D Program Grants No.2012BAH39B02&amp;No.2012BAH39B04.</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,111.12,605.04,394.08,7.07;3,111.12,616.32,296.46,7.07" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="3,313.17,605.04,82.69,7.07;3,111.12,616.32,53.90,7.07">Temporal Summarization</title>
		<author>
			<persName coords=""><surname>Aslam</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ekstrand-Abueg</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Pavlu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Sakai</surname></persName>
		</author>
		<ptr target="googlegroups.com/site/temporalsummarization/trec2014-ts-guidelines.pdf" />
		<imprint/>
	</monogr>
	<note>cb3a1a-s-sites</note>
</biblStruct>

<biblStruct coords="3,111.12,634.32,325.50,7.07" xml:id="b1">
	<monogr>
		<ptr target="http://s3.amazonaws.com/aws-publicdatasets/trec/ts/index.html" />
		<title level="m" coord="3,111.12,634.32,72.33,7.07">TREC-TS-2014F dataset</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="3,111.12,652.32,391.26,7.07" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,220.90,652.32,81.63,7.07">Latent dirichlet allocation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,310.97,652.32,126.67,7.07">The Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,111.12,670.08,396.02,7.07;3,111.12,681.36,115.98,7.07" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="3,185.52,670.08,160.42,7.07">LIBSVM: a library for support vector machines</title>
		<author>
			<persName coords=""><forename type="first">C C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,351.11,670.08,156.03,7.07;3,111.12,681.36,36.62,7.07">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
