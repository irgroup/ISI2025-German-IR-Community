<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,136.07,76.37,340.42,13.06">Atigeo at TREC 2014 Clinical Decision Support Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,135.51,107.55,54.15,10.54"><forename type="first">Yishul</forename><surname>Wei</surname></persName>
							<email>yishuwei@uw.edu</email>
							<affiliation key="aff0">
								<address>
									<addrLine>LLC 800 Bellevue Way NE, Suite 600 Bellevue</addrLine>
									<postCode>98004</postCode>
									<settlement>Atigeo</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,204.52,107.55,78.81,10.54"><forename type="first">Chenchieh</forename><surname>Hsu</surname></persName>
							<email>cjhsu@uw.edu</email>
							<affiliation key="aff0">
								<address>
									<addrLine>LLC 800 Bellevue Way NE, Suite 600 Bellevue</addrLine>
									<postCode>98004</postCode>
									<settlement>Atigeo</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,298.20,107.55,64.33,10.54"><forename type="first">Alex</forename><surname>Thomas</surname></persName>
							<email>alex.thomas@atigeo.com</email>
							<affiliation key="aff0">
								<address>
									<addrLine>LLC 800 Bellevue Way NE, Suite 600 Bellevue</addrLine>
									<postCode>98004</postCode>
									<settlement>Atigeo</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,371.87,107.55,104.99,10.54"><forename type="first">Joseph</forename><forename type="middle">F</forename><surname>Mccarthy</surname></persName>
							<email>joe.mccarthy@atigeo.com</email>
							<affiliation key="aff0">
								<address>
									<addrLine>LLC 800 Bellevue Way NE, Suite 600 Bellevue</addrLine>
									<postCode>98004</postCode>
									<settlement>Atigeo</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,136.07,76.37,340.42,13.06">Atigeo at TREC 2014 Clinical Decision Support Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">55A7A9451610DECCBC42AC61E8945D60</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The TREC 2014 Clinical Decision Support Track task involves retrieval and ranking of medical journal articles with respect to their relevance to prescribing tests, diagnosing or treating a patient represented in a short case report. The Atigeo xPatternsâ„¢ platform supports a variety of ensemble methods for developing and tuning information retrieval (IR) system components for a task and/or domain using labeled data. For TREC 2014, we combine results from an ensemble of search engines, each with a configurable suite of natural language processing (NLP) components, to compute a relevance score for each article and topic. We describe our ensemble approach, the strategies and tools we use to create labeled data to support this approach, the components in our IR / NLP pipeline, and our results on the TREC 2014 CDS task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The TREC 2014 Clinical Decision Support (CDS) track was designed to assess the ability of search engines to find biomedical journal articles relevant to clinical questions about a patient. Each topic within this track consists of a sentence-long summary and a paragraph-long description of a patient case, along with one of three types of clinical information need: diagnosis, test or treatment. The CDS task is to retrieve a ranked set of up to 1000 documents that are relevant to a particular case -based on the summary, description, or both -which are likely to support a physician's decision on appropriate patient care, including proper diagnosis, the tests the patient should undergo, and how the patient should be treated.</p><p>The corpus for the retrieval task is a snapshot of the PubMed Central (PMC) Open Access Subset 1 on January 21, 2014. This set contains the abstracts, full texts, and other metadata of 733,138 articles in the biomedical domain, available in XML format conforming to the National Library of Medicine Journal Publishing DTD 2 . CDS participants were invited to submit up to 5 sets of ranked documents deemed relevant to 30 topics (summary, description pairs), 10 for each of the three types of information need. The 30 evaluation topics were to be considered "blind", with one sample topic summary along with three examples of relevant documents on the CDS track website 3 available for use in development and testing. The large size of the corpus and the sparseness of the development set of topics posed considerable challenges for the CDS track this year.</p><p>The Atigeo team developed an end-to-end document retrieval pipeline for the TREC 2014 CDS task and produced a set of unofficial topics together with relevance judgments for internal evaluation. The pipeline utilizes two open-source search engines -Solr/Lucene 4 and Indri/Lemur 5 -and includes several text processing and natural language processing (NLP) modules, such as negation tagging, age grouping, and semantic-based query expansion, as well as a final ensemble algorithm that combines different ranked lists to improve retrieval results.</p><p>We conducted numerous experiments with different configurations of components to determine the five runs we submitted as our official results.</p><p>The following sections provide more details about our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>In Sections 2.1 and 2.2 we describe the indexing and retrieval strategies for the Indri-based search pipeline of our system. The indexing strategy for the Solr-based pipeline is similar. Our query expansion strategy, however, relies heavily on the Indri query language, which is not compatible with Solr. Section 2.3 describes the ensemble algorithm that combines the search results from Indri and Solr to produce the final results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Indexing Strategy</head><p>For each document in the corpus, we extract its title, abstract, keywords and body, and index the documents by <ref type="bibr" coords="2,143.25,307.07,155.77,9.48">Krovetz-stemmed (Krovetz 1993)</ref> terms in these fields except for those on the stopword list developed by Atigeo for its clinical autocoding (CAC) product.</p><p>We constructed several indexes wherein documents were preprocessed to different extents. We utilize three independent preprocessing modules: negation tagging, string normalization, and age grouping. The negation tagging module involves identifying negated terms using the open-source program NegEx<ref type="foot" coords="2,143.58,431.05,3.48,6.11" target="#foot_0">6</ref> and prepending an "nx" prefix to the negated terms, following <ref type="bibr" coords="2,203.20,446.03,91.27,9.48" target="#b9">Limsopatham (2011)</ref>. The string normalization module removes nonalphanumeric characters. Acronyms with periods and hyphenated words thus become single terms. (The default setting of Indri is to break them into several terms.)</p><p>The age grouper first matches age-description phrases (e.g. "a 30-year-old woman") with a few hand-designed rules, and then replaces them with an age-group identifier. We divided ages into groups of 0-10 years old, 10-20 years old, 20-30 years old, and so on. The rationale for age grouping is that a document with a case description should be regarded as relevant if the patients described in the document and the query are in the same age group and share similar clinical conditions, even though their exact ages are different. Without age grouping, a 34-year-old appears as dissimilar to a 36-year-old as to a 70-year-old to the search engine, since in either case the age-relevant string does not match. In contrast, with age grouping, the 34-year-old and the 36-year-old would be regarded as more similar since they are in the same age group.</p><p>Since the three preprocessing modules can be independently turned on or off, we created a total number of 8 indexes including the basic index (where documents were indexed without any preprocessing) that we could conduct our experiments on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Retrieval Strategy</head><p>At the retrieval stage, we experimented with using either topic summaries or descriptions as the queries submitted to the search engine, but not both, since we assumed that all information in the summary would also be contained in the description (although with no sample descriptions, we were unable to validate this assumption during development). The queries are preprocessed with the same three modules as described above, depending on the index being used. For example, when querying the index with tagged negated terms, we also apply the negation tagger to the queries.</p><p>Query expansion has been shown to be an effective strategy for improving search results in biomedical information retrieval <ref type="bibr" coords="2,454.65,412.43,80.66,9.48">(Srinivasan 1996a</ref><ref type="bibr" coords="2,313.50,424.91,30.50,9.48">(Srinivasan , 1996b;;</ref><ref type="bibr" coords="2,347.68,424.91,128.63,9.48" target="#b0">Aronson &amp; Rindflesch 1997)</ref>. Recognizing the fact that clinical descriptions in the queries might use different terms than those used in the documents when referring to similar concepts, we developed a semantic-based query expansion module in our search pipeline. The idea is to add to the queries the synonyms of the clinical terms present in the query. To achieve this goal we used Met-aMap <ref type="bibr" coords="2,343.84,526.19,70.47,9.48" target="#b1">(Aronson 2001)</ref>, a widely known tool for extracting clinical concepts from free text. For each query, MetaMap maps the clinical terms it identifies to Medical Subject Headings (MeSH), a comprehensive controlled vocabulary representing many concepts described in biomedical journal articles.</p><p>The query expansion module then queries the Unified Medical Language System (UMLS) database to get all the string variants of the concepts. These string variants are then added to the queries, using the phrase-level matching and synonym operators of the Indri query language. Specifically, each string variant that comprises more than one word is wrapped inside a phrase-level matching operator #1(...), and all string variants of a single concept are grouped as synonyms using the synonym operator {...}. The reason for crafting the expanded queries this way is that if we simply added the string variants as independent terms, we would inflate the weight of the concepts with more string variants. The synonym operator enables us to specify the variants to be matched in the documents while maintaining the total weight for each concept to be the same as a single term.</p><p>The following example shows how a summary from the official topics (Topic 13) is transformed by different modules of our system. The original summary is: 30-year-old woman who is 3 weeks post-partum, presents with shortness of breath, tachypnea, and hypoxia.</p><p>After preprocessing (with string normalization and age grouping; there is no negated term in this summary) and removing stop-words, we have: threenxage woman who is weeks postpartum presents shortness breath tachypnea hypoxia Running MetaMap on the original summary returns the following concepts: After querying the UMLS database, the string variants of all concepts are combined with the preprocessed summary to form the final query: This query is then sent to the Indri search engine to query the indexes of the properly preprocessed documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Ensemble Re-Ranking</head><p>Indri and Solr both implement state-of-the-art information retrieval algorithms that deliver highquality search results. To further improve them, we developed an ensemble framework to combine different ranked retrieval results into a single ranked list. We believe each information retrieval model encapsulated by Indri and Solr has its own advantages. The logic of the ensemble is thus to keep all the documents that are predicted to be highly relevant by either search engine.</p><p>As an illustrative example, suppose the two search engines retrieve four documents: A, B, C and D. Document A is ranked as highly relevant by both Indri and Solr, Document B is ranked as highly relevant only by Indri, Document C is ranked as highly relevant only by Solr, and Document D is ranked as only marginally relevant by both Solr and Indri. We believe the optimal aggregate ranking for these four documents should be "A &gt; B â‰¥ C &gt; D" or "A &gt; C â‰¥ B &gt; D". To model this idea, our system uses the following formula below to calculate the final score of each document:</p><p>where SolrWeight and IndriWeight are parameters that represent our relative confidence of each search engine. For most common cases, the sum of the two weights should be 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Unofficially Labeling Unofficial Topics</head><p>One of the challenges we faced in participating in the inaugural offering of the CDS track in TREC 2014 was the lack of labeled data. A single sample diagnostic topic summary and three sample relevant documents were provided on the TREC 2014 CDS homepage. No sample summaries for test or treatment topics were provided, nor were any sample descriptions of any topic types made available to participants.</p><p>A post on the TREC 2014 CDS Google Group suggested participants might find potentially useful examples of short case histories at CasesDatabase.com<ref type="foot" coords="4,114.78,285.37,3.48,6.11" target="#foot_1">7</ref> and the topics provided for the Im-ageCLEF 2013 medical task<ref type="foot" coords="4,201.18,298.09,3.48,6.11" target="#foot_2">8</ref> . We discovered that the single sample topic provided on the CDS track website was a topic from the ImageCLEF collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Creating Unofficial Topics</head><p>We created two sets of unofficial topic summaries for unofficial evaluation during our development efforts. We decided not to create any topic descriptions because there were no examples to guide us.</p><p>One set of topic summaries was derived from CasesDatabase.com. We randomly selected cases to review for potential relevance and generality; those that seemed sufficiently general were used as "seeds" from which we derived 3 topics, one for each type of information need. This derivation of 3 topics from a single case was done to reduce the cognitive overhead of labeling the search results: rather than having to analyze n cases when judging results, we could analyze n/3 cases, with some additional overhead due to the difference between the topic types (see below).</p><p>For a given seed case, the test topic we created contains patient demographics, history and signs and symptoms at the time of presentation of a chief complaint. Our interpretation of a test topic was that it should represent a scenario in which a physician would be searching for relevant information to help decide which tests to prescribe for a patient. It would thus not include any test results, diagno-ses or treatments. The diagnosis topic includes all the information from the test topic, plus any results of any tests presented in the case, and the treatment topic includes everything in the diagnosis topic plus any diagnoses included in the case. The following topics illustrate 3 topics derived from the same case: We initially identified 10 seed cases from which we derived 30 topics. However, in the process of rendering unofficial relevant judgments on results returned by our system for those topics, several of these cases presented significant challenges with respect to our ability to assess the relevance of articles. We discarded all 3 topics derived from some cases, and discarded 1 or 2 of the topics derived from others. We ended up with 12 topics that we deemed sufficiently "assessable" for use in our ongoing development process (which involved iteratively generating additional results from additional system configurations that would then need to be judged or labeled).</p><p>As might be expected, many of the ImageCLEF 2013 topics -all of which are of the diagnosis type -are based on cases in which medical imaging information played a significant diagnostic role. However, we identified 3 cases with sufficient information not directly related to imaging to warrant inclusion in our unofficial topics. We derived 3 additional unofficial topics (one of each type) from 2 of the ImageCLEF topics, and included the other one directly (with no further derivations) in our unofficial topics. Our final set has 19 unofficial topics (6 test, 7 diagnosis and 6 treatment topics).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Labeling Unofficial Topics</head><p>In order to understand the effect of our system components and configurations on the quality of retrieval, we needed to obtain relevance labels. For determining the quality of simple components in isolation, unit tests and spot-checking may be sufficient, but more comprehensive measurements are needed when determining the quality of a system of multiple components on a large data set. A comprehensive measurement requires that the judgments be as consistent as possible, so that a comparison of different configurations of the system is meaningful. We limited our set of judges to 2 members of the team to maximize consistency, and monitored inter-rater agreement to make sure that there was a shared understanding of the topics and documents.</p><p>Another aspect of consistency is establishing an agreed upon definition of relevance. The topics in this task consist of both a case history as well as the type of clinical information need, so relevance must be defined in terms of both parts. There was some guidance from NIST on how relevance would be determined. In March, an introductory message with a task definition was posted to the TREC CDS mailing list. In June, another post provided further guidance with respect to how to interpret the diagnosis type. With this guidance in hand we could create some basic guidelines for each topic type.</p><p>Even with the basic guidelines we established, there were still many challenges in producing the internal judgments. There were no medical experts on the team, so for each topic substantial research had to be done to understand the case. In order to maintain a tenable workload, the top five results of each run were judged, to calculate NDCG@5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results on Unofficial Topics</head><p>There are 16 possible configurations for Indri, given all the possible combinations of using or not the four indexing and retrieval preprocessing modules (negation tagging, string normalization, age grouping, query expansion). There are only 8 possible configurations for Solr, since query expansion is not available for Solr. We tested 22 of the configurations on the unofficial topics we created (2 Solr indexes were not completed in time). The best performing configurations -shown in Table <ref type="table" coords="5,506.96,212.75,5.40,9.48" target="#tab_2">1</ref> -are ranked according to their normalized discounted cumulative gain (NDCG) scores averaged over all topics. We show only the configurations with average NDCG above 0.75. Some interesting trends can be observed in the table. First, baseline Indri with no pre-processing (row 9) performs surprisingly well. Second, negation tagging has more positive effects for Solr than for Indri; in fact, negation appears to negatively impact the NDCG score for Indri. Third, we see that Solr with preprocessing but without query expansion can yield results comparable to those of Indri with query expansion. In general, different components appear to have different effects on the performance of each search engine. With some configurations Solr performs better, but with other configurations Indri wins.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1: Configurations &amp; Scores on Unofficial Topics</head><p>We also ran our ensemble algorithm on every pair of configurations (with same or different search engines). This produced 462 sets of results in addition to our 22 "singleton" results. We rendered 529 unofficial judgments on 19 unofficial topics based on the aggregated set of the top 5 results from all 484 configurations. Ensemble configurations tend to perform better than singleton configurations such as those shown in Table <ref type="table" coords="6,112.77,100.43,4.10,9.48" target="#tab_2">1</ref>. Our best-performing ensemble (NDCG 0.7983) combines the Indri search engine with string normalization, age grouping, and query expansion with Indri using only negation tagging and query expansion. However, since many of the other configurations achieve NDCG scores very close to 0.7983, and since these are all based on unofficial labels for unofficial topics, we did not want to rely too heavily on small differences in the scores.</p><p>The configurations used for our final submissions to TREC were: the "best" ensemble: row 2 in the "full" Indri singleton configuration: row 5 in Table <ref type="table" coords="6,140.30,355.31,4.10,9.48" target="#tab_2">1</ref>, (NDCG 0.7780).</p><p>Our unofficial topics only contain summaries, and so we did not run any experiments using descriptions, but we did want to see how our system would perform on both fields. We decided to allocate 4 of our allotted 5 runs to using our "best" and "full" ensemble configurations on both the summary and description fields, and allocated our 5 th run to the "full" Indri singleton configuration.</p><p>Given our uncertainty about the reliability and statistical significance of small differences in our unofficial scores, we decided to designate the "full" ensemble configuration on the summary field as our official run (atigeo1). The configurations, target topic fields, scores on our unofficial judgments of unofficial topics, and corresponding labels are shown in Table <ref type="table" coords="6,187.47,565.55,4.10,9.48" target="#tab_3">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Official Topics</head><p>The official topics were released April 30th; however participants are prohibited from viewing official TREC topics until after they have ceased system development, i.e., the topics should be treated as "blind" and thus not influence the development or tuning of any system. Once we submitted our runs, we examined the official topics to assess the accuracy of our expectations.</p><p>The diagnosis topics focus on determining the most likely diagnosis given a set of patient complaints and a patient history; some of them also include a set of test results, which violate one of the assumptions we made in developing our unofficial topics. The test topics focus on determining the next test that should be performed given a set of complaints and a patient history; some of these topics also include results of previous tests, which also violate our assumptions. The treatment topics appear to follow one of two general patterns: determining a curative or palliative treatment for some diagnosed illness or symptom, or determining a preventative treatment for a concerned patient. We had assumed treatment topics would follow only the first pattern. We compared the lengths, in terms of tokens, of the official and our unofficial topics sets, as well as the sample topic given at the CDS track website (Figure <ref type="figure" coords="6,348.78,647.63,3.95,9.48" target="#fig_1">1</ref>). The sample topic length is not very representative of either the official summaries or descriptions, but is instead between the two. The ImageCLEF topic lengths are also between official summary and description lengths. Our unofficial topic summaries have a wider distribution of lengths, but their median length is closer to that of official topic descriptions than official summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Analysis of Results on Official Topics</head><p>Table <ref type="table" coords="7,100.28,146.99,5.40,9.48">3</ref> shows the average scores across all 30 topics for inferred Average Precision (infAP), inferred Normalized Discounted Cumulative Gain (infNDCG), R-precision (Rprec) and Precision@10 (P10) for each of our 5 submitted runs. Asterisks indicate the best performing run for each metric.</p><p>Table <ref type="table" coords="7,136.21,246.83,4.25,9.48">3</ref>: Official Scores for 5 Runs Our "official" run (atigeo1) -representing the "full aggregation" configuration and targeting only the summary field -achieved the highest infAP and P10 scores (0.0524 and 0.3033) of the 5 runs, and was a very close second <ref type="bibr" coords="7,209.78,377.39,89.28,9.48">(0.1960 vs. 0.1996)</ref> under the infNDCG metric.</p><p>We observed a large gap between the NDCG scores for our system on the unofficial and the official topics. This difference suggests that our unofficial topics are not representative of the official topics. In examining the topics, it appears that the official summaries or descriptions tend to contain more general terms in describing symptoms or patient conditions, while our unofficial topics tend to use specific terms extracted from specific cases.</p><p>Also, as mentioned above, our unofficial topics were created in an incremental way. We assumed that test topics contain the least amount of information, while treatment topics contain the greatest amount of information. However, as we looked at the official topics, we found that this was not the case, and that the official topics usually only contain descriptions about symptoms or conditions, regardless of the query type. We believe these differences in terminology and length contribute to the substantially different NDCG scores for the two sets of topics. However, it is noteworthy that our preprocessing and query expansion modules yield consistent performance gains over the baseline search engines for both sets of topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>Many ideas explored in the submissions to the Medical Records track<ref type="foot" coords="7,415.26,109.21,3.48,6.11" target="#foot_3">9</ref> of TREC 2011 and TREC 2012 were either similar to the approach we took in the TREC 2014 Clinical Decision Support track, or have potential to be utilized for improving the CDS system. We need to bear in mind, nevertheless, that although both were biomedical information retrieval tasks, the scopes for the Medical Records and CDS tracks are different. In TREC 2011 and TREC 2012, the Medical Records track focused on the problem of cohort selection. Given patient descriptions, that goal was to identify similar patient in a corpus of electronic medical records (EMRs). The strategies that the submissions took can be generally classified into two types, knowledge-based query formation and semanticbased query/document preprocessing, which are discussed in Sections 7.1 and 7.2, respectively. Some follow-up studies on applying more advanced NLP techniques to this problem are discussed in Section 7.3. Finally, Section 7.4 returns back to the issues in medical document retrieval in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Knowledge-Based Query Formation</head><p>The knowledge-based approach was first developed for clinical question answering <ref type="bibr" coords="7,497.53,436.19,42.70,9.48;7,313.50,448.67,96.26,9.48" target="#b2">(Demner-Fushman &amp; Lin 2007)</ref>. Under this framework, clinical queries were formulated in accordance with the guidelines of evidenced-based medicine (EBM, see <ref type="bibr" coords="7,331.19,486.59,85.57,9.48" target="#b13">Sackett et al. 1996)</ref>. Specifically, each clinical query can be divided into several parts: Clinical task, such as etiology, prognosis, diagnosis, and treatment or prevention. (This classification scheme was first proposed by <ref type="bibr" coords="7,342.40,557.87,88.24,9.48" target="#b5">Haynes et al. 1994.)</ref> PICO elements, which stand for population/problem, intervention, comparison, and outcome <ref type="bibr" coords="7,383.03,603.71,104.29,9.48" target="#b12">(Richardson et al. 1995)</ref>.</p><p>Strength of evidence, the level of confidence in the results presented in the research.</p><p>The U.S. National Library of Medicine's systems for TREC 2011 and TREC 2012 Medical Records track <ref type="bibr" coords="7,377.08,682.91,129.79,9.48">(Demner-Fushman et al. 2012</ref><ref type="bibr" coords="7,506.87,682.91,33.36,9.48">, 2013)</ref> involve reformulating the cohort selection problem into a query of this knowledge-based model. An EBM-like query frame is created for each topic, which was then submitted to search engines to retrieve documents.</p><p>Although this approach achieved the best performance among all submissions to the Medical Records track, it was not an automated retrieval system. The transformation of the topics into the query frame was done by hand. In the clinical decision support context, this might be less a problem. Since physicians are usually trained in EBM, we can require that physicians always formulate their information need in the EBM query frame. In fact, the rationale for advocating EBM is that by formulating the structured queries, physicians will be able to reflect more on their information need, thereby improving the quality of the clinical decision processes and patient care. Still, if one really wants a fully automated system that can do freetext search with this knowledge-based framework, then obviously a sophisticated information extraction module needs to be applied to the free-text query first in order to convert it into an EBM-style structured query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Semantic-Based</head><p>Query/Document Preprocessing Many of the systems that participated in the TREC 2011 and TREC 2012 Medical Records track that achieved good performance utilized semantic mapping (e.g. MetaMap) or computer-based medical coding tools. Many of these systems convert documents and queries into "bags of concepts" by running them through semantic mapping tools and then perform concept-based indexing and retrieval. This approach was more feasible for the 2011 and 2012 tasks because the sizes of the corpora were much smaller. We estimated that running Met-aMap on all 733K documents in the TREC 2014 CDS corpus would take weeks to months so we investigated other options.</p><p>We believe that our query expansion approach best approximates this "bag of concepts" strategy given our constraints. Indeed, in our query expansion step, we group all string variants corresponding to a concept as synonyms. Any string variant in the document matches this synonym equally, and so this approach is almost equivalent to that which first converts the terms in the documents into con-cepts and then matches them with the concepts in the query.</p><p>In Atigeo's participation in the TREC 2012 Medical Records track <ref type="bibr" coords="8,417.19,113.15,85.38,9.48" target="#b16">(Tinsley et al. 2013</ref>) a taskspecific method of semantic-based document preprocessing was explored. The system first extracts the ICD-9 codes from the EMRs and then enriches the medical records with the text descriptions of the ICD-9 codes and their parent codes before indexing them. We conducted similar explorations on the MEDLINE corpus, in which each document is indexed with human-assigned MeSH terms. Some experiments showed that enriching the documents with the text descriptions -or "scope notes" -of the MeSH terms could lead to significant performance gain in document retrieval. However, as the MeSH terms are not included in the PubMed Central corpus, this approach would not work for the TREC 2014 CDS task. An alternative approach is to add the text descriptions of the terms identified by MetaMap to the queries, but our experiments suggested this would introduce too much noise and harm the result.</p><p>Another common query expansion technique is pseudo-relevance feedback. We have found the effect of pseudo-relevance feedback to be very sensitive to the numerical values of its parameters. Since we did not have many topics that we could tune our system on, we decided not to pursue this approach. There is also a query expansion approach to be discussed in Section 7.4 that combines semantic information and pseudo-relevance feedback, but sadly, that approach also only works for the MEDLINE corpus and not for the PubMed Central Corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Advanced NLP Techniques for Medical Records Search</head><p>There have been several follow-up studies of the Medical Records track beyond the TREC 2011 and TREC 2012 submissions. With the labeled data from 2011 and 2012 available, and free from the time limitations imposed on TREC participants, these studies were able to pursue the applications of advanced (usually statistical) NLP techniques to the Medical Records track. It can be expected that similar studies will be spurred up for the CDS track. <ref type="bibr" coords="8,324.85,691.55,124.93,9.48">Limsopatham et al. (2013a)</ref> addressed the issue that there are richer relationships between the med-ical concepts beyond the hierarchical order specified by thesauri such as MeSH. For example, we might have some drug that is primarily used for treatment of certain diseases, but the drug and the disease concepts in the thesauri are usually unrelated. The authors developed an inference framework where this kind of relationship can be inferred statistically from the EMR corpus. Although the authors did not report significant improvement on the cohort selection task, this approach might be effective for the CDS task. We might, for instance, add in the concepts of drugs that are derived statistically in this framework from the diseases present in the query, if the query is of the treatment type.</p><p>In <ref type="bibr" coords="9,95.92,265.55,121.29,9.48">Limsopatham et al. (2013b)</ref>, the authors evaluated a strategy that aggregates the results of the term-based and concept-based retrieval models. The aggregated score for each document is a weighted sum of the scores from both models, where the weights are estimated by supervised learning. An interesting feature of the aggregation strategy is that the weights are different for each query. Conceptually, this means that the aggregation function tries to infer the relative importance of the words and of the concepts for a given query. Again, although it did not yield significant improvement on the cohort selection task, it might be effective for the CDS task.</p><p>A more recent study of the Medical Records track was <ref type="bibr" coords="9,117.93,454.91,82.14,9.48" target="#b17">Wang et al. (2014)</ref>, in which the authors propose an axiomatic method to regularize the weights of the concepts in the "bag of concept" representations, and experiments showed that this weighting scheme did improve the retrieval results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Studies on Medical Document Retrieval</head><p>Medical document retrieval has been an active research area for decades. This section surveys some studies on general-purpose document retrieval, focusing on efforts that have been made to improve search results beyond basic term-based retrieval. This line of work, however, has mostly been done with respect to the MEDLINE corpus, and although they provide interesting insight to the problem, many of the methods may not be applicable to other corpora such as PubMed Central.</p><p>A series of experiments by <ref type="bibr" coords="9,208.37,692.27,85.95,9.48" target="#b5">Haynes et al. (1994</ref><ref type="bibr" coords="9,72.30,704.75,19.76,9.48" target="#b6">Haynes et al. ( , 2004</ref><ref type="bibr" coords="9,101.65,704.75,25.60,9.48" target="#b7">Haynes et al. ( , 2005) )</ref> investigated the best strategy for re-trieving documents pertaining to different clinical tasks (e.g. treatment or diagnosis), focusing on creating search rules that produce results with either the highest sensitivity or specificity. This effort has evolved into the PubMed Clinical Queries tool<ref type="foot" coords="9,530.46,123.37,6.84,6.11" target="#foot_4">10</ref> . The rules function as filters on the search results and thus can be combined with other boolean retrieval or ranked retrieval queries that suit the user's information need. However, some of the rules devised by Haynes et al. include restriction on the MeSH terms assigned to the documents and thus apply only to searching the MEDLINE corpus. Even for those rules that only involve constraints on article titles and abstracts, the evaluation in the papers were only done based on the results of MEDLINE search. The performance of these filtering rules for searching other medical databases merits further critical evaluation. <ref type="bibr" coords="9,324.85,302.75,84.47,9.48">Srinivasan (1996a)</ref> explored different query expansion methods for querying MEDLINE and discovered that adding MeSH terms in a pseudorelevance fashion yields a significant improvement. This query expansion is done in two steps. First, a set of documents is first retrieved with the original query. Then the MeSH terms assigned to the top-ranked documents retrieved in the first step are added, and the final documents are retrieved using the expanded query. This method only works for MEDLINE, but a similar idea can be applied when querying other corpora. For example, we can add the terms found in the keywords fields of the top-ranked documents retrieved using the original query. However, in the PubMed Central corpus, we noticed that many of the documents do not have the keyword field. Therefore, we did not investigate how well this strategy might benefit performance on the CDS task. <ref type="bibr" coords="9,324.85,542.75,87.27,9.48">Srinivasan (1996b)</ref> conducted experiments on the MEDLINE corpus with more indexing and retrieval strategies, among which the best result was achieved by expanding the query with MeSH terms in the same fashion as described in <ref type="bibr" coords="9,493.80,593.39,46.40,9.48;9,313.50,606.11,32.29,9.48">Srinivasan (1996a)</ref>, then querying a free-text index and another MeSH index, and finally aggregating the results using a weighted sum of the scores.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,365.49,584.27,122.71,9.48;6,313.50,413.34,226.80,168.00"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Lengths of Topics</figDesc><graphic coords="6,313.50,413.34,226.80,168.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,86.75,247.55,212.32,75.96"><head>Table 1</head><label>1</label><figDesc></figDesc><table coords="6,101.20,247.55,197.87,34.68"><row><cell>plus an-</cell></row><row><cell>other configuration not shown in the table</cell></row><row><cell>(NDCG 0.7983)</cell></row></table><note coords="6,86.75,301.31,212.24,9.48;6,101.20,314.03,71.42,9.48"><p><p><p>the "full" ensemble: rows 4 and 5 in Table</p>1</p>(NDCG 0.7852)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,84.56,589.79,202.20,9.48"><head>Table 2 :</head><label>2</label><figDesc>Configurations for 5 Submitted Runs</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_0" coords="2,77.55,712.50,116.47,7.80"><p>http://code.google.com/p/negex/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_1" coords="4,77.55,702.18,110.87,7.80"><p>http://www.casesdatabase.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_2" coords="4,77.55,712.50,122.72,7.80"><p>http://imageclef.org/2013/medical</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_3" coords="7,318.75,712.50,133.22,7.80"><p>http://trec.nist.gov/data/medical.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_4" coords="9,321.75,712.50,167.50,7.80"><p>http://www.ncbi.nlm.nih.gov/pubmed/clinical/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The authors are grateful for the contributions of many of our colleagues at <rs type="institution">Atigeo</rs> in supporting our work on TREC 2014, especially the assistance of <rs type="person">Bryan Tinsley</rs>, a veteran of our TREC 2012 team.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="10,72.30,177.14,226.75,8.64;10,83.80,188.42,215.31,8.64;10,83.80,199.94,165.25,8.64" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,256.12,177.14,42.92,8.64;10,83.80,188.42,182.39,8.64">Query Expansion Using the UMLS Metathesaurus</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">C</forename><surname>Rindflesch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,278.30,188.42,20.80,8.64;10,83.80,199.94,95.11,8.64">Proc. AMIA Annu. Fall Symp</title>
		<imprint>
			<biblScope unit="page" from="485" to="489" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.30,222.98,226.74,8.64;10,83.65,234.50,215.36,8.64;10,83.65,246.02,172.74,8.64" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,162.74,222.98,136.31,8.64;10,83.65,234.50,215.36,8.64;10,83.65,246.02,32.29,8.64">Effective Mapping of Biomedical Text to the UMLS Metathesaurus: The MetaMap Program</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,123.09,246.02,73.14,8.64">Proc. AMIA Symp</title>
		<meeting>AMIA Symp</meeting>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="page" from="17" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.30,263.54,226.75,8.64;10,83.65,275.06,215.39,8.64;10,83.65,286.34,215.37,8.64;10,83.65,297.86,17.46,8.64" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,232.01,263.54,67.04,8.64;10,83.65,275.06,215.39,8.64;10,83.65,286.34,44.13,8.64">Answering Clinical Questions with Knowledge-Based and Statistical Techniques</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,140.07,286.34,111.68,8.64">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="103" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.30,315.38,226.75,8.64;10,83.65,326.90,215.40,8.64;10,83.65,338.42,215.40,8.64;10,83.65,349.94,215.37,8.64;10,83.65,361.46,93.46,8.64;10,177.19,359.13,5.05,5.69;10,186.95,361.46,112.08,8.64;10,83.65,372.98,57.17,8.64" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,239.11,338.42,59.94,8.64;10,83.65,349.94,198.04,8.64">A Knowledge-Based Approach to Medical Records Retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Abhyankar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jimeno-Yepes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Loane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Rance</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F.-M</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ide</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Apostolova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,83.65,361.46,93.46,8.64;10,177.19,359.13,5.05,5.69;10,186.95,361.46,112.08,8.64">Proceedings of the 20 th Text REtrieval Conference</title>
		<meeting>the 20 th Text REtrieval Conference</meeting>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2011">2012. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.30,390.26,226.75,8.64;10,83.65,401.78,215.40,8.64;10,83.65,413.30,215.42,8.64;10,83.65,424.82,169.01,8.64;10,252.74,422.49,4.33,5.69;10,260.87,424.82,38.18,8.64;10,83.65,436.34,133.86,8.64" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,171.39,413.30,127.68,8.64;10,83.65,424.82,58.04,8.64">NLM at TREC 2012 Medical Records Track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Abhyankar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jimeno-Yepes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Loane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Mork</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ide</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,161.93,424.82,90.73,8.64;10,252.74,422.49,4.33,5.69;10,260.87,424.82,38.18,8.64;10,83.65,436.34,74.10,8.64">Proceedings of the 21 st Text REtrieval Conference</title>
		<meeting>the 21 st Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2012">2013. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.30,453.86,226.70,8.64;10,83.65,465.38,215.38,8.64;10,83.65,476.90,215.33,8.64;10,83.65,488.18,215.44,8.64;10,83.65,499.70,86.34,8.64" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,252.45,465.38,46.58,8.64;10,83.65,476.90,215.33,8.64;10,83.65,488.18,117.23,8.64">Developing Optimal Search Strategies for Detecting Clinically Sound Studies in MEDLINE</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">B</forename><surname>Haynes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">L</forename><surname>Wilczynski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">A</forename><surname>Mckibbon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Sinclair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,211.17,488.18,87.92,8.64;10,83.65,499.70,26.90,8.64">J. Am. Med. Inform. Assoc</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="447" to="458" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.30,517.22,226.69,8.64;10,83.65,528.74,215.43,8.64;10,83.65,540.26,215.39,8.64;10,83.65,551.78,122.20,8.64" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,266.26,517.22,32.73,8.64;10,83.65,528.74,215.43,8.64;10,83.65,540.26,215.39,8.64;10,83.65,551.78,26.40,8.64">Optimal Search Strategies for Retrieving Scientifically Strong Studies of Diagnosis from MEDLINE: Analytical Survey</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">B</forename><surname>Haynes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">L</forename><surname>Wilczynski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,116.99,551.78,19.39,8.64">BMJ</title>
		<imprint>
			<biblScope unit="volume">328</biblScope>
			<biblScope unit="issue">7447</biblScope>
			<biblScope unit="page">1040</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.30,569.30,226.68,8.64;10,83.65,580.82,215.36,8.64;10,83.65,592.10,215.37,8.64;10,83.65,603.62,215.41,8.64;10,83.65,615.14,88.86,8.64" xml:id="b7">
	<analytic>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">B</forename><surname>Haynes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">A</forename><surname>Mckibbon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">L</forename><surname>Wilczynski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">D</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Werre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,236.47,580.82,62.54,8.64;10,83.65,592.10,215.37,8.64;10,83.65,603.62,211.01,8.64">Optimal Search Strategies for Retrieving Scientifically Strong Studies of Treatment from MEDLINE: Analytical Survey</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">330</biblScope>
			<biblScope unit="page">1179</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.30,632.66,226.72,8.64;10,83.65,644.18,69.80,8.64;10,153.53,641.85,5.05,5.69;10,161.59,644.18,137.43,8.64;10,83.65,655.70,215.41,8.64;10,83.65,667.22,88.56,8.64" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,147.44,632.66,151.57,8.64;10,83.65,644.18,28.88,8.64">Viewing Morphology as an Inference Process</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Krovetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,119.70,644.18,33.75,8.64;10,153.53,641.85,5.05,5.69;10,161.59,644.18,137.43,8.64;10,83.65,655.70,215.41,8.64;10,83.65,667.22,44.14,8.64">Proc. 16 th Annu. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval (SIGIR&apos;93)</title>
		<meeting>16 th Annu. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval (SIGIR&apos;93)</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="191" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.30,684.74,226.76,8.64;10,83.65,696.02,215.40,8.64;10,83.65,707.54,215.34,8.64;10,324.85,74.90,152.07,8.64;10,477.02,72.57,5.05,5.69;10,484.80,74.90,55.44,8.64;10,324.85,86.42,115.49,8.64" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,221.35,696.02,77.70,8.64;10,83.65,707.54,215.34,8.64;10,324.85,74.90,46.95,8.64">University of Glasgow at Medical Records Track 2011: Experiments with Terrier</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Limsopatham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-M</forename><surname>Bouamrane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,389.41,74.90,87.52,8.64;10,477.02,72.57,5.05,5.69;10,484.80,74.90,55.44,8.64;10,324.85,86.42,55.74,8.64">Proceedings of the 20 th Text REtrieval Conference</title>
		<meeting>the 20 th Text REtrieval Conference</meeting>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2011">2012. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,313.50,103.94,226.70,8.64;10,324.85,115.46,215.40,8.64;10,324.85,126.74,123.30,8.64;10,448.23,124.41,5.05,5.69;10,457.89,126.74,82.36,8.64;10,324.85,138.26,215.41,8.64;10,324.85,149.78,17.46,8.64" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,324.85,115.46,215.40,8.64;10,324.85,126.74,79.07,8.64">Inferring Conceptual Relationships to Improve Medical Records Search</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Limsopatham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,412.80,126.74,35.35,8.64;10,448.23,124.41,5.05,5.69;10,457.89,126.74,82.36,8.64;10,324.85,138.26,154.84,8.64">Proc. 10 th Conf. on Open Research Areas in Information Retrieval</title>
		<meeting>10 th Conf. on Open Research Areas in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,313.50,167.30,226.71,8.64;10,324.85,178.82,215.41,8.64;10,324.85,190.34,105.79,8.64;10,430.72,188.01,5.05,5.69;10,439.96,190.34,100.30,8.64;10,324.85,201.86,215.40,8.64;10,324.85,213.38,116.61,8.64" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,324.85,178.82,215.41,8.64;10,324.85,190.34,62.36,8.64">Learning to Combine Representation for Medical Records Search</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Limsopatham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,395.70,190.34,34.94,8.64;10,430.72,188.01,5.05,5.69;10,439.96,190.34,100.30,8.64;10,324.85,201.86,215.40,8.64;10,324.85,213.38,72.20,8.64">Proc. 36 th Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval (SIGIR&apos;13)</title>
		<meeting>36 th Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval (SIGIR&apos;13)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="833" to="836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,313.50,230.66,226.71,8.64;10,324.85,242.18,215.40,8.64;10,324.85,253.70,215.41,8.64;10,324.85,265.22,86.07,8.64" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,416.66,242.18,123.58,8.64;10,324.85,253.70,176.04,8.64">The Well-Built Clinical Question: A Key to Evidence-Based Decisions</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">S</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nishikawa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>Hayward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,509.79,253.70,30.47,8.64;10,324.85,265.22,19.37,8.64">ACP J. Club</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="12" to="13" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,313.50,282.74,226.68,8.64;10,324.85,294.26,215.36,8.64;10,324.85,305.78,215.39,8.64;10,324.85,317.30,71.90,8.64" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,475.12,294.26,65.09,8.64;10,324.85,305.78,185.31,8.64">Evidence Based Medicine: What It Is and What It Isn&apos;t</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">L</forename><surname>Sackett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">M</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">B</forename><surname>Haynes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">S</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,520.85,305.78,19.39,8.64">BMJ</title>
		<imprint>
			<biblScope unit="volume">312</biblScope>
			<biblScope unit="issue">7023</biblScope>
			<biblScope unit="page" from="71" to="72" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,313.50,334.58,226.78,8.64;10,324.85,346.10,167.43,8.64" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,402.18,334.58,132.16,8.64">Query Expansion and MEDLINE</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,324.85,346.10,102.97,8.64">Inform. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="431" to="443" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,313.50,363.62,226.75,8.64;10,324.85,375.14,215.39,8.64;10,324.85,386.66,61.90,8.64" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,404.37,363.62,135.88,8.64;10,324.85,375.14,97.13,8.64">Optimal Document-Indexing Vocabulary for MEDLINE</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,432.72,375.14,107.52,8.64">Inform. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="503" to="514" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,313.50,404.18,226.88,8.64;10,324.85,415.70,215.44,8.64;10,324.85,427.22,215.32,8.64;10,324.85,438.50,215.40,8.64;10,324.85,450.02,86.87,8.64;10,411.80,447.69,4.33,5.69;10,423.27,450.02,116.96,8.64;10,324.85,461.54,57.18,8.64" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,369.06,415.70,171.23,8.64;10,324.85,427.22,215.32,8.64;10,324.85,438.50,178.94,8.64">Atigeo at TREC 2012 Medical Records Track: ICD-9 Code Description Injection to Enhance Electronic Medical Record Search Accuracy</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Tinsley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lazarus</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,523.06,438.50,17.19,8.64;10,324.85,450.02,86.87,8.64;10,411.80,447.69,4.33,5.69;10,423.27,450.02,116.96,8.64">Proceedings of the 21 st Text REtrieval Conference</title>
		<meeting>the 21 st Text REtrieval Conference</meeting>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2012">2013. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,313.50,479.06,226.75,8.64;10,324.85,490.58,215.41,8.64;10,324.85,502.10,173.13,8.64;10,498.09,499.77,6.49,5.69;10,510.86,502.10,29.38,8.64;10,324.85,513.62,215.40,8.64;10,324.85,525.14,177.45,8.64" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,472.82,479.06,67.42,8.64;10,324.85,490.58,215.41,8.64;10,324.85,502.10,64.44,8.64">A Study of Concept-Based Weighting Regularization for Medical Records Search</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,399.86,502.10,98.11,8.64;10,498.09,499.77,6.49,5.69;10,510.86,502.10,29.38,8.64;10,324.85,513.62,215.40,8.64;10,324.85,525.14,30.48,8.64">Proceedings of the 52 nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52 nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="603" to="612" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
