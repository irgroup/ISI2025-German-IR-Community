<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,145.95,114.94,320.11,15.12">Endicott College at 2014 TREC Session Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,276.01,148.84,59.99,10.48"><forename type="first">Henry</forename><surname>Feild</surname></persName>
							<email>hfeild@endicott.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Endicott College Beverly</orgName>
								<address>
									<postCode>01915</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,145.95,114.94,320.11,15.12">Endicott College at 2014 TREC Session Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">759BFB3F3D6A4155C5C7EA48735EF75C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Endicott College submitted three runs to Task 1 of the 2014 TREC Session Track. All runs reranked the baseline runs provided by the track organizers. One of the runs made use of a click graph to re-rank results for RL1, RL2, and RL3. The other two used relevance models computed over snippets from the session, and boosted their RL3 run using click graph recommendations. In the absence of clicks (e.g., RL1 and clickless sessions in RL2 and RL3), two of the runs used pseudo relevance feedback over the session, while the other used the unmodified baseline ranking.</p><p>All runs used a similar pre-processing procedure, which we describe in Section 2. We then discuss our click graph re-ranking technique for the ECxCGxPRF run in Section 3 and the session relevance modeling technique for our ECxSRMxOS and ECxSRMxPRF runs in Section 4. We follow that with an analysis of the performance of our runs compared to each other, as well as the track minimums, medians, and maximums. Finally, we wrap up with some closing thoughts and future directions in Section 6.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preprocessing</head><p>While the interaction history for each session includes the snippets for all displayed documents for queries other than currentquery, the baseline runs for currentquery provided by the Session Track coordinators were in the TREC run format and did not include snippets. Since the snippet relevance model re-ranking technique used in two of our runs requires snippets, we had to generate these.</p><p>To generate snippets, we used an index we created earlier consisting of the content plus the inlink, URL, and title fields of all non-spam documents in the ClueWeb2012 Category A collection. We split the corpus into 10 shards. We used Indri version 5.7 with Krovetz stemming and a short stoplist of 12 words: a, at, i, you, we, it, the, of, he, she, there, and them. Documents were considered spam if they were marked with a Waterloo spam score lower than 65 <ref type="bibr" coords="1,453.70,589.00,10.90,9.57" target="#b0">[1]</ref>. 1 This resulted in 256,555,383 documents being white listed as non-spam. The final index consisted of 256,554,159 documents (we did not investigate what caused the 1,224 document discrepancy). As we planned to generate snippets, we included the collection and the core index. The index portion took up 842 GB of disk space, and collection 2.5 TB. The total combined took 3.3 TB of disk space. Each shard took between 22-37 hours to process with up to five shards being processed in parallel on a single machine with two 8-core processors (2GHz/core) and 64 GB of RAM with Ubuntu 12.04 server edition.</p><p>For each baseline run, we removed all spam documents (i.e., documents not in our index), after which we kept only the top 100 results (or fewer if the list size was less than 100) and generated the snippets. We generated snippets by submitting the currentquery text to Indri and using the workingSetDocno parameter to specify only the results we kept from the previous step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Click Graph</head><p>Craswell and Szummer <ref type="bibr" coords="2,190.58,174.88,11.52,9.57" target="#b1">[2]</ref> demonstrated the effectiveness of random walks on click graphs to improve ranking. For our ECxCGxPRF runs, as well as the RL3 runs for both ECxSRMxOS and ECxSRMxPRF, we relied on a simple click graph to provide document suggestions, and then used these to re-rank the top 50 documents in a run. A description of the graph generation process is below, followed by the particulars for different runs, including what was used to define "clicked" documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Generating a click graphs</head><p>The click graphs used in this work were generated using the following procedure. First, we generate a directed graph G = {V, E}, where V is the union of the identifiers of all clicked documents in the input data set (in our case, the TREC Session data from 2013, 2014, or both) and E is a set of weighted edge tuples: (v i , v j , w ij ). Weights are calculated in three stages as follows. For each session, consider the set of clicked documents {d 1 , d 2 , . . . , d n }, and their click frequencies {f 1 , f 2 , . . . , f n } (in many sessions, certain documents are clicked several times). In stage 1 of the weight calculation, we generate the weight for each of the n 2 pairs of documents in each session. For any pair (d i , d j ) : i = j, we create the weighted edges (d i , d j , f i × f j ) and (d j , d i , f i × f j ). This means that if document d i is clicked five times, d j is clicked once, and d k is clicked once, then the weight between d i and either of d j or d k will be five times stronger than between d j and d k .</p><p>In stage 2, weights are summed across weighted edges between the same two documents, which generates an unnormalized set of edges of the form (v i , v j , ŵij ) where there is exactly one weight corresponding to each pair (v i , v j ).</p><p>In stage 3, we normalize the weights of all outgoing edges of each vertex such that they sum to one, giving us the final set of edges for G: E = {. . . , (v i , v j , w ij ), . . .}. Note that for a pair of documents v i and v j , the edges (v i , v j , w ij ) and (v j , v i , w ji ) are not necessarily weighted the same as they were normalized independently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Generating suggestions from a click graph</head><p>To generate suggestions from a click graph, we used a random walk with restarts <ref type="bibr" coords="2,453.01,559.03,10.91,9.57" target="#b2">[3]</ref>. The algorithm takes an initialization vector u, which consists of starting weights for each vertex in the graph. The following formula is used to compute the suggestions:</p><formula xml:id="formula_0" coords="2,249.03,613.19,113.95,10.67">v t+1 = (1 -c)Av t + cu,</formula><p>where c is the restart factor, v t is a vector containing the probabilities of being at each vertex in the graph after t iterations, and A is the transition matrix between vertices in the graph. Initially, v 0 is set to u. We continue to compute v t+1 for increasing values of t until either it has converged, meaning the L 1 distance between two iterations is less then some value , i.e., ||v t+1 -v t || 2 &lt; , or ρ iterations have been completed. For all of our experiments, we used a restart factor of c = 0.2, a convergence distance of = 0.005, and a max iteration cap of ρ = 1000. We used a custom implementation of the algorithm, available on GitHub. <ref type="foot" coords="3,223.92,264.84,4.23,6.99" target="#foot_0">2</ref>For use with the graphs described above, the weights in the initialization vector u are the click frequencies of the corresponding documents in the session under examination, that is, u[d i ] = f i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Defining clicks</head><p>The algorithm to generate suggestions requires some definition of what it means for a document to be clicked. In RL1 runs, for example, we have no click information-only the currentquery is known. As listed in Table <ref type="table" coords="3,197.42,370.80,4.24,9.57" target="#tab_0">1</ref>, we simulated clicks for sessions in the ECxCGxPRF RL1 runs as the top retrieved document from the baseline for the currentquery. For RL2 and RL3, we used real clicks in sessions with at least one click, and simulated clicks as the top retrieved baseline result for each query in the session for clickless sessions. The 'PRF' (pseudo relevance feedback) in the run tag denotes our use of top results as click surrogates. <ref type="foot" coords="3,306.18,423.04,4.23,6.99" target="#foot_1">3</ref>To be clear, we used only real clicks from the 2012 and 2013 datasets to generate the click graphs. Click surrogates were only used when creating the initialization vector u in the suggestion generation phase (Section 3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Session Relevance Modeling</head><p>Jiang and He <ref type="bibr" coords="3,142.46,524.36,11.52,9.57" target="#b3">[4]</ref> demonstrated that using clicked summaries as explicit relevance feedback is a useful tool in session-based retrieval. Motivated by their work, two of our runs, ECxSRMxOS and ECxSRMxPRF, use session relevance modeling (SRM) to re-rank the baseline results. SRM considers a set of clicked summaries, S, from a session. These summaries are then used in the same way as the Relevance Model Method 1 proposed by Lavrenko and Croft <ref type="bibr" coords="3,387.18,578.56,10.91,9.57" target="#b4">[5]</ref>, except we substitute clicked summaries in place of the top k documents as the relevant set and we retrieve over result snippets in the top 100 baseline results.</p><p>All snippets in S and the baseline result snippets were stemmed using the Porter stemmer and stopped with a 119-term stoplist. <ref type="foot" coords="3,231.91,630.81,4.23,6.99" target="#foot_2">4</ref> We used Dirichlet smoothing with µ = 50. Out of vocabulary words were given a default term frequency of 0.00000005.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Queries</head><p>Queries nDCG@10 w/ nDCG@10=1 w/ nDCG@10=0 ECxCGxPRF R1</p><p>. As with the click graph, we used multiple definitions of a click. For ECxSRMxOS RL1, we used the baseline ('OS' is short for 'original SERP', i.e., the baseline), post spam removal. For the ECxSRMxOS RL2, we used real clicks in sessions with at least one click, and the baseline in clickless sessions. RL3 was the RL2 run, boosted by click graph suggestions (which used a click surrogate for clickless sessions, as describe in Section 3.3).</p><p>In ECxSRMxPRF RL1, we used the top result from the baseline for currentquery in each session as a surrogate for a click. For the ECxSRMxPRF RL2 runs, we used real clicks when possible, and the top results retrieved per query in the session for clickless sessions. The RL3 run was the result of boosting the RL2 run with click graph suggestions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Performance Analysis</head><p>The results for the 2014 TREC Session Track are based on judgments made for the top ten documents retrieved for the first 100 sessions from each participant's top three priority runs. The official measure of the track is nDCG@10, which is the only measure we report on here. When we refer to sessions below, we specifically mean the currentquery of each session.</p><p>All three systems improved mean nDCG@10 from RL1 to RL2, and again from RL2 to RL3. Figure <ref type="figure" coords="4,107.28,504.05,5.45,9.57">1</ref> shows the per session and mean nDCG@10 for all three run levels for each run group. Of note, the ECxCGxPRF runs (top row) never achieved an nDCG@10 above 0.88 for any session in any run level. ECxSRMxPRF was the only run group to achieve nDCG@10=1 for at least one session across all three run levels. ECxSRMxOS did so for only RL2 and RL3. All run groups saw the highest number of nDCG@10=0 sessions at RL2 and usually the lowest at RL3. Table <ref type="table" coords="4,454.89,558.24,5.45,9.57" target="#tab_1">2</ref> shows the exact counts, as well as a few other interesting statistics.</p><p>ECxSRMxOS RL2 and RL3 are the two best performing runs: highest mean nDCG@10, tied for highest number of nDCG@10=1 sessions, and almost the lowest number of nDCG@10=0 sessions (about a quarter of all sessions; a little worse than the ECxCGxPRF runs).</p><p>To understand how Endicott's three runs compare with runs submitted by other participants, consider Figure <ref type="figure" coords="4,151.48,639.54,4.24,9.57">2</ref>. In this figure, we take the difference in nDCG@10 for Endicott's RL3 runs and the minimum (left column), median (center column), and maximum (right column) across all participant runs (including Endicott's) by session. The difference reported on each graph shows the total difference for that run, or the area under the curve. For the median graphs, the difference is broken up between those where Endicott did better (above y = 0) and worse (below y = 0) than the median. In Figure <ref type="figure" coords="6,138.05,200.64,5.45,9.57">2</ref> (b), (e), and (h), we see the Endicott runs have a higher mass above the median than below. Plots (c), (f), and (i), however, show that Endicott's runs were well below the maximum performance. Indeed, Table <ref type="table" coords="6,234.09,227.74,5.45,9.57" target="#tab_2">3</ref> shows that each run demonstrates sub-median performance on roughly as many or more sessions as above-median performance (roughly 40 of the 100 sessions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><formula xml:id="formula_1" coords="6,201.07,74.00,209.86,37.40">-Median ∆ &gt; 0 ∆ = 0 ∆ &lt; 0 ECxCGxPRF RL3<label>39</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Directions</head><p>Of the three run groups submitted by Endicott, the highest performing run, ECxSRMxPRF RL3 used clicked document summaries to model relevance and re-rank spam-filtered baseline results, then boosted those results with recommendations from a click graph created over the 2013 and 2014 session data. While nDCG@10 was in general greater than the median performance across participant submissions, there is still for improvement. We have not conducted a failure analysis at this time, though such an analysis is crucial to understanding how the proposed methods may be improved. We leave such an analysis to future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,72.00,74.00,468.01,128.35"><head>Table 1 :</head><label>1</label><figDesc>For each run that used click graphs in some capacity, this table lists the data source used to generate the graph (either the 2013 session data, or the 2013+2014 session data), and what constituted a click when generating the initialization vector for the suggestion algorithm.</figDesc><table coords="3,108.85,74.00,394.30,77.74"><row><cell>ID</cell><cell cols="3">RL Graph source 'Click' definition</cell></row><row><cell cols="2">ECxCGxPRF 1</cell><cell>2013</cell><cell>Top document retrieved for currentquery.</cell></row><row><cell cols="2">ECxCGxPRF 2</cell><cell>2013</cell><cell>Real clicks or top document retrieved for each</cell></row><row><cell></cell><cell></cell><cell></cell><cell>query for clickless sessions.</cell></row><row><cell>ECx*</cell><cell>3</cell><cell>2013+2014</cell><cell>Real clicks or top document retrieved for each</cell></row><row><cell></cell><cell></cell><cell></cell><cell>query for clickless sessions.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,128.57,101.53,332.26,142.27"><head>Table 2 :</head><label>2</label><figDesc>A few performance stats across the 100 judged sessions.</figDesc><table coords="4,128.57,101.53,313.63,119.06"><row><cell></cell><cell>181</cell><cell>0</cell><cell>23</cell></row><row><cell>R2</cell><cell>.182</cell><cell>0</cell><cell>23</cell></row><row><cell>R3</cell><cell>.193</cell><cell>0</cell><cell>21</cell></row><row><cell>ECxSRMxPRF R1</cell><cell>.168</cell><cell>1</cell><cell>34</cell></row><row><cell>R2</cell><cell>.178</cell><cell>3</cell><cell>35</cell></row><row><cell>R3</cell><cell>.194</cell><cell>3</cell><cell>33</cell></row><row><cell>ECxSRMxOS R1</cell><cell>.179</cell><cell>0</cell><cell>23</cell></row><row><cell>R2</cell><cell>.195</cell><cell>3</cell><cell>26</cell></row><row><cell>R3</cell><cell>.205</cell><cell>3</cell><cell>24</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,72.00,101.53,468.00,73.73"><head>Table 3 :</head><label>3</label><figDesc>Number of sessions where Endicott's runs are above, at, and below the median nDCG@10 across all participant runs.</figDesc><table coords="6,201.07,101.53,199.68,36.97"><row><cell></cell><cell></cell><cell>23</cell><cell>38</cell></row><row><cell>ECxSRMxPRF RL3</cell><cell>37</cell><cell>21</cell><cell>42</cell></row><row><cell>ECxSRMxOS RL3</cell><cell>38</cell><cell>21</cell><cell>41</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="3,88.59,668.03,203.41,7.47"><p>https://github.com/hafeild/term-query-graph</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="3,88.59,678.35,451.41,8.12;3,72.00,689.31,193.75,7.86"><p>This naming convention was violated for ECxSRMxOS RL3, in which the associated RL2 run was boosted with PRF suggestions as used in the other RL3 runs.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="3,88.59,700.91,278.73,7.47"><p>http://www.textfixer.com/resources/common-english-words.txt</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="6,88.97,440.03,451.03,9.57;6,88.97,453.58,319.86,9.57" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,293.26,440.03,246.74,9.57;6,88.97,453.58,102.79,9.57">Efficient and effective spam filtering and re-ranking for large web datasets</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,201.26,453.58,101.81,9.57">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="441" to="465" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.97,476.10,451.03,9.57;6,88.97,489.64,451.03,9.57;6,88.97,503.19,168.52,9.57" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,242.12,476.10,160.67,9.57">Random walks on the click graph</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Szummer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,428.74,476.10,111.26,9.57;6,88.97,489.64,451.03,9.57;6,88.97,503.19,28.87,9.57">Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 30th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="239" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.97,525.71,451.03,9.57;6,88.97,539.26,290.28,9.57" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,197.38,525.71,148.10,9.57">Scaling personalized web search</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Jeh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,367.12,525.71,172.88,9.57;6,88.97,539.26,148.77,9.57">Proceedings of the 12th international conference on World Wide Web</title>
		<meeting>the 12th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="271" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.97,561.77,451.03,9.57;6,88.97,575.32,451.03,9.57;6,88.97,588.87,24.85,9.57" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,190.54,561.77,349.47,9.57;6,88.97,575.32,179.37,9.57">Pitt at TREC 2013: Different Effects of Click-through and Past Queries on Whole-session Search Performance</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,294.35,575.32,240.59,9.57">Proceedings of the 22nd Text Retrieval Conference</title>
		<meeting>the 22nd Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.97,611.39,451.03,9.57;6,88.97,624.94,451.03,9.57;6,88.97,638.49,168.52,9.57" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,242.97,611.39,159.47,9.57">Relevance based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,428.64,611.39,111.35,9.57;6,88.97,624.94,451.03,9.57;6,88.97,638.49,28.87,9.57">Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 24th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
