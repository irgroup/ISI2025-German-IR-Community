<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,70.85,72.35,468.03,16.84;1,54.46,92.27,500.81,16.84;1,237.31,112.20,135.11,16.84">University of Glasgow at TREC 2014: Experiments with Terrier in Contextual Suggestion, Temporal Summarisation and Web Tracks</title>
				<funder ref="#_JSWmJNb">
					<orgName type="full">EC co-</orgName>
				</funder>
				<funder ref="#_jR4dVKr">
					<orgName type="full">EC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,114.11,157.90,99.35,11.06"><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
						</author>
						<author>
							<persName coords="1,222.88,157.90,88.71,11.06"><forename type="first">Romain</forename><surname>Deveaud</surname></persName>
						</author>
						<author>
							<persName coords="1,321.23,157.90,89.07,11.06"><forename type="first">M-Dyaa</forename><surname>Albakour</surname></persName>
						</author>
						<author>
							<persName coords="1,419.14,157.90,70.64,11.06"><forename type="first">Stuart</forename><surname>Mackie</surname></persName>
						</author>
						<author>
							<persName coords="1,129.94,174.55,90.75,11.06"><forename type="first">Nut</forename><surname>Limsopatham</surname></persName>
						</author>
						<author>
							<persName coords="1,230.27,174.55,87.38,11.06"><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
						</author>
						<author>
							<persName coords="1,327.15,174.55,55.23,11.06"><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
						</author>
						<author role="corresp">
							<persName coords="1,391.44,174.55,80.41,11.06;1,471.84,167.97,1.54,7.86"><forename type="first">Thibaut</forename><surname>Thonet</surname></persName>
							<email>thibaut.thonet@irit.fr</email>
						</author>
						<author>
							<persName coords="1,263.67,193.40,98.21,11.06;1,361.89,186.82,2.05,7.86"><forename type="first">Bekir</forename><forename type="middle">Taner</forename><surname>Din√ßer</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">University of Glasgow Glasgow</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">IRIT</orgName>
								<orgName type="institution" key="instit2">Paul Sabatier University</orgName>
								<address>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Dept. of Statistics &amp; Computer Engineering</orgName>
								<orgName type="institution">Mugla University</orgName>
								<address>
									<settlement>Mugla</settlement>
									<country>Turkey. Email</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,70.85,72.35,468.03,16.84;1,54.46,92.27,500.81,16.84;1,237.31,112.20,135.11,16.84">University of Glasgow at TREC 2014: Experiments with Terrier in Contextual Suggestion, Temporal Summarisation and Web Tracks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1118679163C2B5410ECDAF8C87925318</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In TREC 2014, we focus on tackling the challenges posed by the Contextual Suggestion and Temporal Summarisation tracks, as well as enhancing our existing technologies to tackle risk-sensitivity as part of the Web track, building upon our Terrier Information Retrieval Platform. In particular, for the Contextual Suggestion track, we propose a novel bundled venue retrieval approach and experiment with text-based summarisation for building the venue description. For our participation to the Temporal Summarisation track, we propose a general framework for performing summarisation over time and two new real-time filtering approaches that leverage the semi-structured nature of news articles to enhance summary coverage. For the TREC Web track, we investigated a novel risk-sensitive learning to rank approach that is based on hypothesis testing and examined approaches that selectively apply different retrieval techniques based upon the query, with the aim of minimising risk.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In TREC 2014, we participate in the Web adhoc and risksensitive tasks, the Contextual Suggestion track "entertain me" task and the Temporal Summarisation sequential update summarisation task. Our focus is the development of effective and efficient approaches to these tasks, building upon our open-source Terrier Information Retrieval (IR) platform <ref type="bibr" coords="1,92.89,549.43,14.32,7.86" target="#b23">[23]</ref> and extensive experience working with machine learned models <ref type="bibr" coords="1,140.13,559.89,13.49,7.86" target="#b13">[13]</ref>. Our Web track participation further develops upon the core data-driven ranking models and infrastructure within Terrier v4.0, 1 and in-line with the Terrier vision <ref type="bibr" coords="1,97.41,591.27,13.49,7.86" target="#b11">[11]</ref>. Meanwhile, our Contextual Suggestion and Temporal Summarisation participations revolve around the development of new supervised real-time streaming applications and technologies building upon Terrier.</p><p>In the Contextual Suggestion track, we have two main goals. First, to investigate how to effectively diversify venue suggestions for a given user profile. Venue diversification is an important problem, since users are unlikely to want to be recommended only a single type of venue to visit. To tackle this challenge, we propose a new venue bundling method that uses Foursquare's venue category tree to diversify the venues suggested to the user and combine it with an estimate of venue popularity from within the city. Our second goal is to examine how to generate effective venue descriptions for the end-user. Indeed, the description of the venue provided is a key factor that users leverage to decide whether they want to visit a venue. We experiment with a novel venue summarisation approach that aims to help the user to better understand why a particular venue has been suggested with respect to its popularity and relevance to them.</p><p>We also participate in the sequential update summarisation task of the Temporal Summarisation track. In contrast to our 2013 participation to this track, we developed and experimented with a new fully real-time filtering framework, that aims to eliminate summarisation latency. Indeed, within the Temporal Summarisation track task, there exists an implicit effectiveness/latency trade-off between batchorientated 'rank-then-select' style approaches that delay the issuing of sentences until more evidence is available, in comparison to fully real-time solutions that aim to provide immediate updates. We experiment with both 'rank-thenselect' and real-time filtering approaches in our participation. Furthermore, one of the core challenges to temporal summarisation is identifying updates that have no semantic overlap with the event description (query). We develop two new real-time filtering approaches that leverage the semistructured nature of news articles when performing sentence selection to tackle this challenge. In particular, these approaches use sentence proximity to identify additional sentences that are on-topic, but do not share any semantic overlap with the event description.</p><p>In our participation to the Web track, we participated in both the adhoc and risk-sensitive tasks. Our participation in this track aims to build upon the data-driven learning infrastructure released in version 4.0 of the Terrier IR platform. In the adhoc task, we investigate how both traditional and risk-sensitive learning to rank techniques can impact upon retrieval effectiveness. Meanwhile for the risksensitive task, we experiment with two enhanced approaches for reducing risk during retrieval, namely: automatic selec-tion of the best retrieval model via statistical analysis of 115 features; and our recently proposed risk-sensitive learning to rank technique based on hypothesis testing. We investigate how transfer learning could be used to increase the robustness of our learning to rank techniques.</p><p>The remainder of this paper is structured as follows. In Section 2, we describe our participation in the Contextual Suggestion track. Section 3 details our participation in the Temporal Summarisation track. In Section 4, we describe our Web track adhoc and risk-sensitive task participations. Conclusions are provided in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">CONTEXTUAL SUGGESTION TRACK</head><p>The main aim of our participation in the TREC 2014 Contextual Suggestion track is to extend and refine novel contextual retrieval models, which we have developed upon our Terrier IR platform to address emerging information needs in smart cities, such as the "entertain me" zero-queries tackled in this track.</p><p>Building on our findings from last year's track <ref type="bibr" coords="2,261.09,261.46,13.50,7.86" target="#b16">[16]</ref>, we rely on Location-based Social Networks (LBSN's) such as Foursquare<ref type="foot" coords="2,98.26,280.61,3.65,5.24" target="#foot_0">2</ref> to obtain information concerning venues that we suggest to the users. We adopted a more data-driven approach this year, where we leveraged the wealth of structured information available within Foursquare and combined them in order to learn an effective ranker. We also explored two other research questions that are central to the problem of Contextual Suggestion: the diversity of the suggested venues, and the quality of the venue description provided for each suggestion. We tackled the first question by introducing a novel bundled venue retrieval approach (BVR), which jointly ranks venues with respect to their popularity (derived from Foursquare) and their similarity to the user profile. Concerning the second question, we improved the quality of the textual description that accompanies each venue by implementing a TextRank-based summarisation method that displays the most relevant sentences extracted from positive Foursquare reviews. Also, space permitting, the method augments the summary with a list of the most similar venues from the user's profile, highlighting why it is similar and hence potentially suitable.</p><p>At the heart of our two approaches lies Foursquare, an LBSN that can be seen as a comprehensive directory of venues in the entire world. For all the contexts (i.e. cities) of the TREC 2014 Contextual Suggestion, we started by crawling all their venues from Foursquare, thus allowing us to obtain a comprehensive representation of these cities as well as a deep pool of venues that would ideally suit a wide range of users (i.e. high recall). Apart from its completeness, the main rationale behind the choice of Foursquare is that it provides several attributes about venues within a city that we can use to augment venue recommendation. For instance, using Foursquare we are able to estimate a venue's popularity, using metrics such as the number of "check-ins", the number of photos that have been taken in the venue and the number of "likes". Moreover, Foursquare provides a finegrained categorisation of venues<ref type="foot" coords="2,184.08,646.74,3.65,5.24" target="#foot_1">3</ref> that we can use in order to understand the venue type (e.g. "whisky bar", "creperie", "national park") and hence why a user might want to visit them.</p><p>We consider the recommendation of venues to be comprised of two main components. First, the ranking of venues for a user and a city. Second, the generation of the venue description for each venue. This year, we experimented with two very different approaches to perform the first ranking component using Foursquare data, namely: Learningto-rank for Venues; and Bundled Venue Retrieval (BVR). Meanwhile, we propose a novel method for generating the venue description, referred to as Venue Summarisation. We describe these approaches below. Learning-to-rank for Venues: Our first approach relies on supervised learning, for which we learn a ranking model using the LambdaMART learning to rank technique. Our aim was to build upon our recent findings <ref type="bibr" coords="2,483.14,193.63,9.20,7.86">[6]</ref>, and to confirm that the strong results obtained on last year's data were generalisable. For each pair of context/user profile, we retrieve an initial personalised set of venues using our uogTrCFP method that already obtained above-median results in last year's track <ref type="bibr" coords="2,365.72,245.93,13.49,7.86" target="#b16">[16]</ref>. Then, we compute 64 different features for each venue based upon this initial set, before reranking them using a LambdaMART learning-to-rank model. This model was trained using the 2013 Contextual Suggestion dataset. To train this model, we defined four main feature groups:</p><p>‚Ä¢ Category features relate to the high-level categories of the suggested venue and to their similarity to the categories of venues that the user likes in his profile.</p><p>‚Ä¢ City features relate to the overall activity of the city, obtained by aggregating Foursquare social information over all the venues.</p><p>‚Ä¢ User features relate to the preferences and interests of the user, expressed through the categories of venues that he likes; we also integrated features accounting for the categories of venues that the user dislikes.</p><p>‚Ä¢ Venue features relate to the venue itself.</p><p>Bundled Venue Retrieval (BVR): For our second approach, we experimented with a novel technique that builds bundles of venues, with the goal of suggesting coherent (i.e. bundles that contain venues of the same category, or that are very similar) and relevant packages of venues to a user visiting a city. Building upon our recent findings showing that diversification is an important element when suggesting contextual venues <ref type="bibr" coords="2,391.76,522.89,9.20,7.86" target="#b1">[1]</ref>, we adapted the aforementioned bundle venue retrieval approach (BVR) to suggest only the most central venues of each bundle in order to promote diversity, while fitting to the Contextual Suggestion track guidelines. Bundles were created by using two main criteria: the overall popularity of their venues (inferred from their number of Foursquare "likes") and the similarity between the user's profile and the venue. The latter has been computed using a tree-matching technique that compares two trees of categories, thus allowing to compute a finer-grained category similarity.</p><p>Venue Summarisation: In addition to these two ranking strategies, we focused this year on the generation of more meaningful and interesting descriptions for each venue suggestion, instead of simply returning the LBSN's description. Indeed, we hypothesise that the description for a venue provided can play a major role with respect to how users judge that venue's relevance. We propose a new approach that produces a summary of the venue using venue reviews as follows. For each venue suggestion, we extracted the reviews that have been entered by Foursquare users for that venue.</p><p>We only kept sentences that expressed a positive opinion according to the SentiStrength tool 4 . We then treated all these positive sentences as a single document and computed their TextRank <ref type="bibr" coords="3,121.21,231.51,14.32,7.86" target="#b22">[22]</ref> in order to identify the most central and salient sentences, before iteratively adding the top scoring ones to the description. However, since the guidelines specifically state that the description may be tailored to the user's preferences, we also added at the end of the description (within the 512 characters limit) a list of venues that the user has rated positively in his profile and that were the most similar to the suggested venue.</p><p>We devised three different runs to evaluate our approaches described above (uogTrCFP, uogTrCsLtr, and uogTrBun-Sum). Only the last two were submitted:</p><p>‚Ä¢ uogTrCFP: This run serves as our baseline and was</p><p>shown to be competitive in last year's track. Venues for each user profile and context pair are ranked using the similarity score between the user profile and the venue. This run also constitutes our initial sample for the uogTrCsLtr run.</p><p>‚Ä¢ uogTrCsLtr: This run investigates the effectiveness of learning to rank techniques for suggesting venues. It uses a LambdaMART model learned with an ensemble of 64 features that represent both the venue and the preferences of the user <ref type="bibr" coords="3,170.54,463.79,9.20,7.86">[6]</ref>. All features are computed using the data that we obtained from Foursquare.</p><p>‚Ä¢ uogTrBunSum: This run produces coherent and personalised bundles of popular venues, and suggests the most central venue of each bundle to the user, thus ensuring a high diversity in the suggestions. Venue popularity and personalisation are computed using venue information obtained from Foursquare. This run also implements our summarisation approach for generating meaningful descriptions.</p><p>Table <ref type="table" coords="3,87.17,580.99,4.61,7.86" target="#tab_0">1</ref> reports the performance of our two submitted runs and the non-submitted run together with the TREC Median using the official measures. First, we observe that our submitted runs achieve above median performance for all measures. In particular, the uogTrBunSum, which implements our bundle venue retrieval approach along with the summarisation of venues' reviews, achieves the best performance, markedly above the median. While this result suggests that combining a diversified approach with informative descriptions can help to achieve strong performance, we need further investigation to determine which of these two components provides the most added value. Our learning to rank 4 http://sentistrength.wlv.ac.uk run (uogTrCsLtr) shows that supervised learing can be very effective for venue recommendation, especially in comparison to the the lower performance achieved by our baseline run (uogTrCFP). However, we hypothesise that this supervised approach may be prone to overfitting, which might explain why it is outperformed by our uogTrBunSum approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">TEMPORAL SUMMARISATION TRACK</head><p>The aims of our participation in the second year of the Temporal Summarisation track <ref type="bibr" coords="3,448.59,167.23,9.71,7.86" target="#b3">[3]</ref> are two-fold. First, to transition from incremental 'rank-then-select' style summarisation approaches that issue updates each hour <ref type="bibr" coords="3,512.23,188.15,14.32,7.86" target="#b16">[16,</ref><ref type="bibr" coords="3,529.98,188.15,10.74,7.86" target="#b17">17]</ref>, to approaches can issue updates as soon as new information arrives. Second, to investigate approaches to increase the coverage of the nuggets about an event, beyond those that can be semantically related to the event description. To this end, we develop an new modular real-time filtering framework that incorporates both filtering heuristics and supervised classification models to select sentences to issue as updates. Furthermore, using this framework as a base, we propose novel approaches that leverage sentence proximity to identify additional sentences to issue as updates that are ontopic, but do not share any semantic overlap with the event description, thereby enhancing coverage of the information nuggets about that event.</p><p>To perform summarisation, we first define a basic realtime filtering framework that describes a generic system for performing real-time summarisation. Under this framework, new documents are processed in real-time as they arrive, resulting in the selection of zero or more sentences from each document to issue immediately as updates to the user. Figure <ref type="figure" coords="3,332.42,397.36,4.61,7.86" target="#fig_0">1</ref> illustrates the main components of this framework. In particular, the document is first classified as predominantly relating to the event of interest or not. On-topic documents are passed to the next component to be further processed, while the remaining documents are discarded. This initial filtering step is critical to the efficiency of the framework as a whole, since it is computationally expensive to process a document in depth (since a typical document contains hundreds of sentences), while the document stream for a given event can contain hundreds of thousands of documents. If a document is identified as being on-topic, the sentences within that document are extracted and then classified based upon the following criteria: whether they contain useful information about the event or not; whether they are well written; and whether they contain boilerplate content. Sentences that pass these classification criteria are considered as candidates to issue as updates. Finally, each candidate is compared against those previously issued as updates to avoid reporting redundant information. Those sentences identified as containing novel information are then issued as updates.</p><p>We instantiate each of the three main components of the framework as follows: Document Filtering: Uses a machine learned document classifier trained on the TREC 2013 Temporal Summarisation topics. This classifier uses 43 features representing the similarity of the document to the initial event representation (query) and expanded event representations based upon Freebase and DBPedia.  to select sentences. In particular, sentences are filtered based upon their length (very short or long sentences are removed) and only sentences containing one or more named entities are considered. We then use a supervised classifier trained on a small manually annotated set of sentences extracted from the TREC 2013 Temporal Summarisation topics that aims to find well-written sentences. This classifier uses emergencyrelated term dictionaries, effective summarisation approaches from the literature <ref type="bibr" coords="4,132.78,460.13,14.31,7.86" target="#b14">[14,</ref><ref type="bibr" coords="4,150.54,460.13,10.73,7.86" target="#b15">15]</ref>, sentence information mass features (e.g. sentence TF-IDF based on a background Wikipedia corpus) and quality features such as term capitalisation.</p><p>Novelty-based Filtering: We use a greedy cosine similarity heuristic to remove sentences that are overly similar to those already selected. Sentences that have a cosine similarity less than a threshold are emitted as updates. The threshold was trained on the TREC 2013 Temporal Summarisation topics. Using this instantiation of the framework, we can automatically extract updates to issue to a user about a given event in real-time, without the hour's worth of latency introduced by the system we used last year <ref type="bibr" coords="4,232.13,585.66,13.49,7.86" target="#b16">[16]</ref>. However, another of the key challenges that we identified from our participation last year was the high degree of vocabulary mismatch that occurs between the event description (query) and the associated information nuggets for that event. For example, for the query 'buenos aires train crash', a highly relevant sentence might be 'The most likely cause was said to be brake failure', which exhibits no semantic overlap with the query. To tackle this issue, we developed two new realtime filtering approaches that leverage the semi-structured nature of news articles when performing sentence selection. In particular, our first approach, referred to as Browsing Window Selection (BWS) uses a variable-size sliding win-dow within each document to select only sentences nearby those estimated to be relevant. Meanwhile, our second approach, which we refer to as Supervised Proximity-Focused Selection (SPFS), uses a supervised classifier that represents each sentence using a series of topicality, quality, and informativeness features extracted from other sentences in close proximity to it. In this way, we leverage the positional relationship of sentences to find additional relevant sentences that do not exhibit any semantic overlap with the event query.</p><p>Using the basic real-time filtering framework in conjunction to our BWS and SPFS approaches, we submitted four runs (uogTr2A, uogTr4A, uogTr4AC and uogTr4ARas). The first three runs aim to test the effectiveness of BWS and SPFS, while the final run enables a comparison between the 'rank-and-select' style approach deployed last year and our new proposed framework.</p><p>‚Ä¢ uogTr2A: Uses the basic real-time filtering framework with BWS using a window of two sentences for selection.</p><p>‚Ä¢ uogTr4A: Uses the basic real-time filtering framework with BWS using a window of four sentences for selection.</p><p>‚Ä¢ uogTr4AC: The uogTr4A run combined with SPFS, where features are extracted from the closest four sentences.</p><p>‚Ä¢ uogTr4ARas: The uogTr4A run that simulates a 'rank-and-select' configuration with 1 hour worth of latency.</p><p>Table <ref type="table" coords="4,352.42,512.43,4.61,7.86" target="#tab_1">2</ref> reports the performance of our four submitted runs in terms of expected latency gain (ELG) and latency comprehensiveness (LC) and the ELG/LC Mean (the task target metric). From our submitted runs, we observe the following points of interest. First, under all measures, all of our runs outperform the average of the submitted systems, indicating that our proposed summarisation framework is effective. Second, comparing the uogTr2A and the uogTr4A runs that use our BWS approach, we see that using a larger browsing window increases summary comprehensiveness but harms expected latency gain. Third, comparing the uogTr4A run to the uogTr4AC run that incorporates our SPFS approach, we see that SPFS increases the expected latency gain of the updates issued, but at a modest cost to comprehensiveness, resulting in a net gain under the ELG/LC mean. This indicates that our SPFS classifier is able to better identify sentences containing novel content than just using the fixed size browsing window. Finally, comparing the real-time filtering uogTr4A run to the rank-and-select uogTr4ARas run, we see that uogTr4ARas outperforms uogTr4A, but exhibits the lowest overall comprehensiveness of any of our submitted runs. Overall, we conclude that the basic real-time filtering framework that we proposed when combined with either our BWS or SPFS approaches can be effective for sequential update summarisation, as highlighted by their enhanced performance in comparison to the TREC average. Furthermore, the high performance achieved by our BWS and SPFS approaches under Comprehensiveness indicate that using sentence proximity within documents can tackle the semantic gap when performing summarisation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">WEB TRACK</head><p>Our participation in the adhoc and risk-sensitive tasks had two overall goals: (1) to evaluate our recently proposed risk-sensitive learning to rank approach that is based on hypothesis testing; and (2) to continue our development of novel selective retrieval techniques that can attain an effective and robust retrieval performance. These aims build upon our existing data-driven learning infrastructure <ref type="bibr" coords="5,278.59,264.23,14.32,7.86" target="#b12">[12]</ref> that has proven effective during previous participations on ClueWeb09 <ref type="bibr" coords="5,102.93,285.15,14.31,7.86" target="#b10">[10,</ref><ref type="bibr" coords="5,120.96,285.15,11.77,7.86" target="#b18">18,</ref><ref type="bibr" coords="5,136.44,285.15,11.76,7.86" target="#b19">19,</ref><ref type="bibr" coords="5,151.92,285.15,10.74,7.86" target="#b26">26]</ref>. Indeed, our infrastructure encapsulates researching and deploying learning to rank approaches within Terrier using our fat framework <ref type="bibr" coords="5,248.86,306.07,14.32,7.86" target="#b13">[13]</ref> for the fast computation of document features. Moreover, as there are not yet many training queries available on ClueWeb12, we investigate using ClueWeb09 training data via transfer learning. Finally, we examine two approaches to minimise risk-sensitivity within a learning environment, based on risksensitive learning to rank <ref type="bibr" coords="5,156.73,368.84,14.32,7.86" target="#b27">[27]</ref> and the predictive selection of retrieval models per-query using estimated risk.</p><p>For TREC 2014, we indexed only the category A (‚àº716M English documents) subset of the ClueWeb12 corpus, without stemming or stopwords. At retrieval time, we apply one of several retrieval models (DPH from the Divergence from Randomness framework <ref type="bibr" coords="5,151.26,431.60,9.20,7.86" target="#b2">[2]</ref>, DFIC from the Divergence from Independence framework <ref type="bibr" coords="5,155.22,442.06,9.72,7.86" target="#b7">[7]</ref> or BM25) to identify the sample documents to re-rank using the learned models. Following the recommendations of <ref type="bibr" coords="5,155.33,462.98,14.32,7.86" target="#b13">[13]</ref> for ClueWeb09, we select the top 5000 documents for re-ranking using learning to rank, where the weighting model does not consider anchor text. For applying learning to rank, all of our runs use a total of 64 features, as described in Table <ref type="table" coords="5,196.18,504.83,3.58,7.86" target="#tab_2">3</ref>. Note that many different weighting model features are computed, as they can contribute differently to the learned models <ref type="bibr" coords="5,237.26,525.75,13.49,7.86" target="#b13">[13]</ref>. We also observe that there is no need to train the hyper-parameters of those weighting models that typically control document length normalisation, as the learning to rank technique will implicitly address any bias towards short or long documents as part of its learning process <ref type="bibr" coords="5,175.75,578.05,13.49,7.86" target="#b13">[13]</ref>.</p><p>The same features are also computed on the ClueWeb09 corpus for queries from TREC 2009-2012, for the purposes of training models from the older corpus. We thereafter deploy two learning to rank techniques, namely AFS <ref type="bibr" coords="5,270.69,619.89,14.32,7.86" target="#b20">[20]</ref> which creates a linear learned model -and also the state-ofthe-art LambdaMART learning to rank technique <ref type="bibr" coords="5,260.97,640.82,9.72,7.86" target="#b9">[9,</ref><ref type="bibr" coords="5,274.44,640.82,10.74,7.86" target="#b28">28]</ref>, <ref type="foot" coords="5,288.75,639.05,3.65,5.24" target="#foot_2">5</ref>which creates a learned model based on regression trees.</p><p>Next, for the purposes of the risk-sensitive retrieval task, we experimented with two techniques for reducing risk during retrieval, namely (a) our recently proposed Fully-Adaptive Risk-sensitive Optimisation and Semi-Adaptive Risk-sensitive Optimisation variants of LambdaMART (known as FARO and SARO, respectively) <ref type="bibr" coords="5,419.48,68.10,9.20,7.86" target="#b8">[8]</ref>, and (b) a novel selection technique that aimed to select the most effective/safe retrieval strategies for a given query. FARO and SARO are based on a new risk-sensitive evaluation measure called T Risk , and are integrated into the loss function that LambdaMART deploys, to favour learned models that are less risky when compared to a baseline retrieval effectiveness. In particular, SARO concentrates on down-side risk, while FARO considers both downside and upside risk. For more information on our proposed FARO and SARO techniques, we refer the reader to <ref type="bibr" coords="5,356.24,172.71,9.20,7.86" target="#b8">[8]</ref>.</p><p>Next, we investigated how the application of techniques from transfer learning can reduce risk. In particular, we mixed the transfer of learning to rank models obtained from training on the older ClueWeb09 corpus, which are then 'retrained' on ClueWeb12. Finally, through a thorough statistical analysis of 115 features that are calculated for each query, we trained a novel selection technique that aimed to select the most effective/safe retrieval strategies based upon the user query.</p><p>We submitted six runs to the adhoc and risk-sensitive retrieval tasks of the Web track, all using the category A ClueWeb12 corpus, and deploying 64 features for the purposes of learning to rank. The submitted runs were selected through a detailed cross-validation study conducted on the TREC 2013 Web track topics. In particular, for the adhoc task, we submitted three runs:</p><p>‚Ä¢ uogTrIwa: Uses a DFI model and the linear AFS learning to rank technique.</p><p>‚Ä¢ uogTrDwl: Uses the DFR DPH model and the Lamb-daAMRT learning to rank technique.</p><p>‚Ä¢ uogTrDuax: Deploys the xQuAD diversification framework <ref type="bibr" coords="5,361.16,428.68,13.49,7.86" target="#b25">[25]</ref>, on top of the DFR DPH model and the AFS learning to rank technique.</p><p>Meanwhile, for the risk-sensitive task, three runs were submitted, using the two standard runs as baselines, as well as one of our submitted adhoc runs:</p><p>‚Ä¢ uogTrDwsts Deploys our recently proposed hypothesis testing-based risk-sensitive learning to rank technique as well as leverages transfer learning. This considers the provided standard Terrier run as the baseline during risk-sensitive learning.</p><p>‚Ä¢ uogTrq1: Deploys a selective approach using different learned models on a per-query basis. The corresponding baseline for this run is uogTrDwl (as submitted to the adhoc task).</p><p>‚Ä¢ uogTrBwf Uses our risk-sensitive learning to rank technique when building upon the provided Indri standard baseline.</p><p>Table <ref type="table" coords="5,351.10,648.42,4.61,7.86" target="#tab_3">4</ref> summarises the configuration of each of these six submitted runs, as well as several unsubmitted runs that we evaluate for comparison.</p><p>Table <ref type="table" coords="5,350.41,679.80,4.61,7.86">5</ref> reports the effectiveness of all six of our submitted Web track runs, as well as various unsubmitted runs, and the four provided standard baselines. Results are reported in terms of NDCG@20 and ERR@20.</p><p>Features Total Sample: DPH, DFIC or BM25 1 Weighting models on the whole document <ref type="bibr" coords="6,199.37,72.92,11.68,6.20" target="#b13">[13]</ref> (DFRee, DPH <ref type="bibr" coords="6,262.87,72.92,7.51,6.20" target="#b2">[2]</ref>, PL2 <ref type="bibr" coords="6,291.44,72.92,7.51,6.20" target="#b2">[2]</ref>, BM25, Dirichlet LM, MQT <ref type="bibr" coords="6,396.03,72.92,11.01,6.20" target="#b12">[12]</ref>, LGD, DFIC <ref type="bibr" coords="6,454.47,72.92,7.51,6.20" target="#b7">[7]</ref>, DFIZ <ref type="bibr" coords="6,487.42,72.92,8.13,6.20" target="#b7">[7]</ref>) 8 Weighting models as above on each field, namely: title, URL, body and anchor text; + PL2F 37 Term-dependence proximity models (MRF <ref type="bibr" coords="6,201.46,88.84,11.01,6.20" target="#b21">[21]</ref>, pBiL <ref type="bibr" coords="6,236.49,88.84,11.69,6.20" target="#b24">[24]</ref>) 2 URL (e.g. length) link (e.g. PageRank,inlink counts) &amp; content quality (e.g., fraction of stopwords, table text <ref type="bibr" coords="6,423.08,96.79,7.51,6.20" target="#b4">[4]</ref>, spam classification <ref type="bibr" coords="6,499.15,96.79,8.13,6.20" target="#b5">[5]</ref>) features 16 TOTAL 64  On analysis of Table <ref type="table" coords="6,152.34,286.55,3.58,7.86">5</ref>, we observe that all of our runs are markedly above the TREC median. Indeed, in terms of NDCG@20, the uogTrDwl run, which deploys the state-ofthe-art LambdaMART learning to rank technique, was comparably the most effective, attaining 0.3243. For ERR@20, the unsubmitted uogTrIua run was our most effective, closely followed by uogTrDwl.</p><p>The xQuAD diversification technique helped to improve all measures (except ERR@20), but particularly benefited the diversity measures, namely Œ±-NDCG@20 and ERR-IA@20. Indeed, the performance of run uogTrDuax is comparable to our best run uogTrDwl, despite using much simpler learning and less aggressive stemming.</p><p>Next, we analyse the runs submitted to the risk-sensitive task. Table <ref type="table" coords="6,102.05,433.00,4.61,7.86">6</ref> reports the URISK values for Œ± = 0 and Œ± = 5 based on ERR@20. While each risk-sensitive run (row) uses a different baseline, to permit cross comparison, we evaluate each risk-sensitive run with respect to a different evaluation baseline (column), and provide a mean column to permit an overall conclusion.</p><p>On analysis of Table <ref type="table" coords="6,151.34,495.77,3.58,7.86">6</ref>, we first note that the runs submitted to the risk-sensitive task are less effective on average than the adhoc runs (see Table <ref type="table" coords="6,185.93,516.69,3.58,7.86">5</ref>). Next, we observe that the selective approach used in the uogTrq1 run is overall less risky than the other runs we submitted to the risk-sensitive task (c.f. last column of the table), across all evaluation baselines, since it balances the risk using two different retrieval approaches (namely uogTrIua &amp; uogTrDwl).</p><p>Overall, from our submitted runs, we conclude that our deployments of learning to rank and xQuAD diversification have once again been shown to be effective on ClueWeb12. Moreover, our selective approach (as deployed in run uogTrq1) provides real promise for improving the robustness of a retrieval approach. We leave for future work an analysis of FARO and SARO in the context of ClueWeb12, as well as the benefit of transfer learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>In TREC 2014, we participated in the Web adhoc and risk-sensitive tasks, the Contextual Suggestion track "entertain me" task and the Temporal Summarisation sequen-tial update summarisation task, using the Terrier IR platform. In particular, for the Web track, we built upon the data-driven learning infrastructure we released with Terrier 4.0, using our state-of-the-art xQuAD and Fat frameworks. We showed that state-of-the-art learning-to-rank techniques augmented with xQuAD are highly effective under both traditional and diversification metrics. Furthermore, our results for the risk-sensitive task indicate that learning how to automatically predict and select the least risky retrieval strategy shows real promise for improving search robustness. For the Contextual Suggestion track, we proposed a novel bundled venue retrieval approach that aims to diversify venue suggestion and examined how to build more effective venue descriptions using user-reviews, which in combination resulted in a marked increase in venue suggestion performance. Finally, for the Temporal Summarisation track, we proposed a new real-time summarisation framework that aims to find good quality candidate sentences to include in a temporal summary of an event, in a low latency manner. Further, using this framework as a base, we investigated two new approaches to increase the comprehensiveness of event summaries using semi-structured nature of news articles, both of which were shown to be highly effective at finding novel on-topic content relating to a given event.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run Submitted Task</head><p>Adhoc Measures Diversity Measures NDCG@20 ERR@20 Œ±-NDCG@20 ERR-IA@20  <ref type="table" coords="7,81.92,202.92,4.12,7.89">5</ref>: Results of our submitted and unsubmitted runs for the Web track under the normal adhoc measures, namely NDCG@20 and ERR@20, as well as their diversity counterparts, Œ±-NDCG@20 and ERR-IA@20. For risk-sensitive runs, the corresponding baseline is denoted in parenthesis. Table <ref type="table" coords="7,84.21,300.51,4.13,7.89">6</ref>: URISK ERR@20 results of our submitted runs for the Web track risk-sensitive task. For risksensitive runs, the corresponding baseline for a given is denoted in parenthesis. For each URISK column, the corresponding evaluation baseline is also denoted in parenthesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,53.80,326.41,239.11,7.89;4,53.80,336.87,52.06,7.89;4,56.72,167.37,235.68,147.91"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of our basic real-time filtering framework.</figDesc><graphic coords="4,56.72,167.37,235.68,147.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,137.55,242.51,63.98,7.86;7,215.89,237.28,64.59,7.86;7,299.26,237.28,148.68,7.86;7,466.44,237.28,51.31,7.86;7,216.98,247.74,22.80,7.86;7,256.59,247.74,22.80,7.86;7,296.47,247.74,22.80,7.86;7,334.55,247.74,22.81,7.86;7,375.96,247.74,22.81,7.86;7,417.75,247.74,22.80,7.86;7,461.34,247.74,22.81,7.86;7,500.95,247.74,22.80,7.86;7,80.75,258.70,448.22,7.86;7,80.75,269.16,39.80,7.86;7,145.66,269.16,47.75,7.86;7,211.77,269.16,317.20,7.86;7,80.75,279.62,33.27,7.86;7,135.48,279.62,391.19,7.86"><head></head><label></label><figDesc>01398 -0.26885 0.02178 -0.12092 -0.02059 -0.27401 -0.01152 -0.18095 uogTrBwf Risk (Indri) -0.00113 -0.22992 0.03463 -0.13225 -0.00773 -0.26402 -0.00295 -0.16465 uogTrq1 Risk (uogTrDwl) -0.00242 -0.22741 0.03334 -0.12489 -0.00902 -0.22614 0.0073 -0.1170</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,53.80,55.49,239.11,92.55"><head>Table 1 :</head><label>1</label><figDesc>Results of our runs in the Contextual Suggestions track. Figures in bold represent the top performances.</figDesc><table coords="3,65.78,55.49,215.15,50.70"><row><cell></cell><cell cols="2">Submitted P@5</cell><cell>MRR</cell><cell>TBG</cell></row><row><cell>TREC Median</cell><cell>-</cell><cell cols="2">0.3685 0.5350 1.3685</cell></row><row><cell>uogTrCFP</cell><cell></cell><cell cols="2">0.0922 0.2000 0.2356</cell></row><row><cell>uogTrCsLtr</cell><cell></cell><cell cols="2">0.3920 0.5207 1.9153</cell></row><row><cell>uogTrBunSum</cell><cell></cell><cell cols="2">0.4863 0.6653 2.1388</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,316.81,700.70,239.11,18.35"><head>Table 2 :</head><label>2</label><figDesc>Performance of our submitted runs to the sequential update summarisation task.</figDesc><table coords="3,316.81,700.70,239.11,18.35"><row><cell>Sentence Classification: Uses both a series of classifica-</cell></row><row><cell>tion heuristics and a supervised sentence classification model</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,96.42,123.98,416.89,118.73"><head>Table 3 :</head><label>3</label><figDesc>Document features used in the Web track, for both ClueWeb09 and ClueWeb12.</figDesc><table coords="6,140.31,145.56,329.10,97.15"><row><cell>ID</cell><cell cols="3">Submitted Stemming Sample</cell><cell>LTR</cell><cell>Other</cell></row><row><cell>Terrier baseline</cell><cell></cell><cell>Weak</cell><cell>DPH</cell><cell>-</cell><cell>-</cell></row><row><cell>uogTrDwl</cell><cell>Adhoc</cell><cell>Weak</cell><cell cols="2">DPH LambdaMART</cell><cell>-</cell></row><row><cell>uogTrIwa</cell><cell>Adhoc</cell><cell>Weak</cell><cell>DFIC</cell><cell>AFS</cell><cell>-</cell></row><row><cell>uogTrDua</cell><cell></cell><cell>None</cell><cell>DPH</cell><cell>AFS</cell><cell>-</cell></row><row><cell>uogTrDuax</cell><cell>Adhoc</cell><cell>None</cell><cell>DPH</cell><cell>AFS</cell><cell>xQuAD</cell></row><row><cell>uogTrIua</cell><cell></cell><cell>No</cell><cell>DFIC</cell><cell>AFS</cell><cell>-</cell></row><row><cell>uogTrDwsts</cell><cell>Risk</cell><cell>Weak</cell><cell>DPH</cell><cell>SARO/SARO</cell><cell>(transfer)</cell></row><row><cell>uogTrq1</cell><cell>Risk</cell><cell></cell><cell>-</cell><cell>-</cell><cell>Selective (uogTrIua/uogTrDwl)</cell></row><row><cell>uogTrBwf</cell><cell>Risk</cell><cell>-</cell><cell>Indri</cell><cell>FARO</cell><cell>(transfer)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,53.80,255.49,502.12,7.89"><head>Table 4 :</head><label>4</label><figDesc>Summary of submitted and unsubmitted runs to the adhoc and risk-sensitive tasks of the Web track.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,58.40,701.50,98.68,7.47"><p>http://foursquare.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="2,58.40,711.83,206.74,7.47"><p>http://developer.foursquare.com/categorytree</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="5,58.40,711.83,159.75,7.47"><p>http://code.google.com/p/jforests/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p><rs type="person">Dyaa Albakour</rs>, <rs type="person">Romain Deveaud</rs>, <rs type="person">Stuart Mackie</rs>, <rs type="person">Craig Macdonald</rs> and <rs type="person">Iadh Ounis</rs> acknowledge support from the <rs type="funder">EC</rs> cofunded <rs type="institution">SMART</rs> (<rs type="grantNumber">FP7-287583</rs>) project. <rs type="person">Richard McCreadie</rs>, <rs type="person">Craig Macdonald</rs> and <rs type="person">Iadh Ounis</rs> also acknowledge support from the <rs type="funder">EC co-</rs>funded <rs type="projectName">SUPER</rs> (<rs type="grantNumber">FP7-606853</rs>) project.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_jR4dVKr">
					<idno type="grant-number">FP7-287583</idno>
				</org>
				<org type="funded-project" xml:id="_JSWmJNb">
					<idno type="grant-number">FP7-606853</idno>
					<orgName type="project" subtype="full">SUPER</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,321.30,625.82,96.81,10.75" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,335.60,636.96,199.06,7.86;6,335.61,647.43,205.18,7.86;6,335.61,657.89,199.50,7.86;6,335.61,668.35,20.96,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,373.74,647.43,167.04,7.86;6,335.61,657.89,126.19,7.86">Diversifying Contextual Suggestions from Location-based Social Networks</title>
		<author>
			<persName coords=""><forename type="first">M.-D</forename><surname>Albakour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Deveaud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,480.79,657.89,50.46,7.86">Proc. of IIiX</title>
		<meeting>of IIiX</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,335.60,679.80,211.72,7.86;6,335.61,690.26,211.59,7.86;6,335.61,700.73,219.80,7.86;6,335.61,711.19,20.96,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,389.48,690.26,157.72,7.86;6,335.61,700.73,137.72,7.86">FUB, IASI-CNR and University of Tor Vergata at TREC 2007 Blog track</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ambrosi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gaibisso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gambosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,491.72,700.73,57.96,7.86">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.59,343.99,218.07,7.86;7,72.59,354.45,217.90,7.86;7,72.59,364.91,75.71,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,111.70,354.45,138.87,7.86">Trec 2013 temporal summarization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Aslam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ekstrand-Abueg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pavlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,269.55,354.45,20.94,7.86;7,72.59,364.91,46.58,7.86">Proc. of TREC&apos;13</title>
		<meeting>of TREC&apos;13</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.59,376.37,166.68,7.86;7,72.59,386.83,215.93,7.86;7,72.59,397.29,56.14,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,72.59,386.83,165.08,7.86">Quality-biased ranking of web documents</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Diao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,256.78,386.83,31.74,7.86;7,72.59,397.29,25.70,7.86">Proc. of WSDM</title>
		<meeting>of WSDM</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.59,408.75,215.71,7.86;7,72.59,419.21,220.31,7.86;7,72.59,429.67,208.48,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,72.59,419.21,220.31,7.86;7,72.59,429.67,75.72,7.86">Efficient and effective spam filtering and re-ranking for large Web datasets</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,155.30,429.67,36.62,7.86">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="441" to="465" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.59,441.13,199.06,7.86;7,72.59,451.59,199.64,7.86;7,72.59,462.05,169.77,7.86;7,72.59,472.51,150.79,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,110.73,451.59,161.50,7.86;7,72.59,462.05,169.77,7.86;7,72.59,472.51,45.09,7.86">On the Importance of Venue-Dependent Features for Learning to Rank Contextual Suggestions</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Deveaud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-D</forename><surname>Albakour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,136.33,472.51,57.43,7.86">Proc. of CIKM</title>
		<meeting>of CIKM</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.59,483.97,208.60,7.86;7,72.59,494.43,209.00,7.86;7,72.59,504.89,212.76,7.86;7,72.59,515.35,165.45,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="7,254.81,483.97,26.38,7.86;7,72.59,494.43,209.00,7.86;7,72.59,504.89,79.39,7.86">Irra at trec 2010: Index term weighting by divergence from independence model</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">T</forename><surname>Din√ßer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Kocabas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Karaoglan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>TREC. National Institute of Standards and Technology (NIST)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.59,526.81,218.99,7.86;7,72.59,537.27,202.55,7.86;7,72.59,547.73,220.31,7.86;7,72.59,558.19,208.98,7.86;7,72.59,568.65,210.29,7.86;7,72.59,579.11,117.12,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,247.25,526.81,44.33,7.86;7,72.59,537.27,202.55,7.86;7,72.59,547.73,29.46,7.86">Hypothesis testing for the risk-sensitive evaluation of retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">T</forename><surname>Din√ßer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,120.56,547.73,172.35,7.86;7,72.59,558.19,208.98,7.86;7,72.59,568.65,132.26,7.86">Proceedings of the 37th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;14</title>
		<meeting>the 37th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="23" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.59,590.57,206.39,7.86;7,72.59,601.03,217.58,7.86;7,72.59,611.49,170.93,7.86;7,72.59,621.95,220.05,7.86;7,72.59,632.41,214.25,7.86;7,72.59,642.87,137.84,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,246.38,590.57,32.59,7.86;7,72.59,601.03,217.58,7.86;7,72.59,611.49,59.63,7.86">Bagging gradient-boosted trees for high precision, low variance ranking models</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ganjisaffar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lopes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,151.14,611.49,92.39,7.86;7,72.59,621.95,220.05,7.86;7,72.59,632.41,156.94,7.86">Proceedings of the 34th international ACM SIGIR conference on Research and development in Information, SIGIR &apos;11</title>
		<meeting>the 34th international ACM SIGIR conference on Research and development in Information, SIGIR &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="85" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.59,654.33,200.68,7.86;7,72.59,664.79,183.13,7.86;7,72.59,675.25,207.77,7.86;7,72.59,685.71,215.85,7.86;7,72.59,696.17,131.25,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,72.59,675.25,207.77,7.86;7,72.59,685.71,215.85,7.86;7,72.59,696.17,24.84,7.86">University of Glasgow at TREC 2012: Experiments with Terrier in Medical Records, Microblog, and Web Tracks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Limsopatham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-D</forename><surname>Albakour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,116.13,696.17,57.96,7.86">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.59,707.63,193.99,7.86;7,335.61,343.99,202.15,7.86;7,335.61,354.45,201.86,7.86;7,335.61,364.91,49.58,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,373.74,343.99,164.01,7.86;7,335.61,354.45,69.75,7.86">From puppy to maturity: Experiences in developing terrier</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,411.88,354.45,95.71,7.86">Proc. of OSIR at SIGIR</title>
		<meeting>of OSIR at SIGIR</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="60" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,335.60,376.37,206.07,7.86;7,335.61,386.83,179.17,7.86;7,335.61,397.29,162.79,7.86;7,335.61,407.75,109.94,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,498.14,376.37,43.54,7.86;7,335.61,386.83,175.25,7.86">The whens and hows of learning to rank for web search</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10791-012-9209-9</idno>
	</analytic>
	<monogr>
		<title level="j" coord="7,335.61,397.29,85.82,7.86">Information Retrieval</title>
		<imprint>
			<biblScope unit="page" from="1" to="45" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,335.60,419.21,199.61,7.86;7,335.61,429.67,218.95,7.86;7,335.61,440.13,201.41,7.86;7,335.61,450.59,43.19,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,335.61,429.67,218.95,7.86;7,335.61,440.13,30.31,7.86">About learning models with multiple query-dependent features</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<idno>11:1-11:39</idno>
	</analytic>
	<monogr>
		<title level="j" coord="7,372.76,440.13,89.57,7.86">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2013-08">Aug. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,335.60,462.05,220.32,7.86;7,335.61,472.51,211.17,7.86;7,335.61,482.97,109.90,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,335.61,472.51,206.78,7.86">Comparing algorithms for microblog summarisation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mackie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,347.10,482.97,69.47,7.86">Proc. of CLEF&apos;14</title>
		<meeting>of CLEF&apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,335.60,494.43,220.32,7.86;7,335.61,504.89,214.31,7.86;7,335.61,515.35,199.83,7.86;7,335.61,525.81,20.96,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,335.61,504.89,214.31,7.86;7,335.61,515.35,113.64,7.86">On choosing an effective automatic evaluation metric for microblog summarisation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mackie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,468.19,515.35,63.22,7.86">Proc. of IIIX&apos;14</title>
		<meeting>of IIIX&apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,335.60,537.27,172.39,7.86;7,335.61,547.73,212.52,7.86;7,335.61,558.19,185.22,7.86;7,335.61,568.65,208.98,7.86;7,335.61,579.11,219.07,7.86;7,335.61,589.57,52.69,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,367.72,558.19,153.10,7.86;7,335.61,568.65,208.98,7.86;7,335.61,579.11,168.63,7.86">University of Glasgow at TREC 2013: Experiments with Terrier in Contextual Suggestion, Temporal Summarisation and Web Tracks</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-D</forename><surname>Albakour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mackie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Limsopatham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">T</forename><surname>Din√ßer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,522.94,579.11,31.74,7.86;7,335.61,589.57,22.94,7.86">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,335.60,601.03,176.33,7.86;7,335.61,611.49,220.31,7.86;7,335.61,621.95,215.43,7.86;7,335.61,632.41,64.24,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="7,335.61,611.49,220.31,7.86;7,335.61,621.95,165.31,7.86">Incremental update summarization: Adaptive sentence selection based on prevalence and novelty</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,519.30,621.95,31.74,7.86;7,335.61,632.41,35.19,7.86">Proc. of CIKM&apos;14</title>
		<meeting>of CIKM&apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,335.60,643.87,212.14,7.86;7,335.61,654.33,220.32,7.86;7,335.61,664.79,194.62,7.86;7,335.61,675.25,217.67,7.86;7,335.61,685.71,63.50,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="7,403.28,654.33,152.64,7.86;7,335.61,664.79,194.62,7.86;7,335.61,675.25,178.37,7.86">University of Glasgow at TREC 2009: Experiments with Terrier-Blog, Entity, Million Query, Relevance Feedback, and Web tracks</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,532.34,675.25,20.94,7.86;7,335.61,685.71,33.74,7.86">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,335.60,697.17,206.26,7.86;7,335.61,707.63,177.63,7.86;8,72.59,57.64,218.24,7.86;8,72.59,68.10,165.50,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="7,373.74,707.63,139.49,7.86;8,72.59,57.64,218.24,7.86;8,72.59,68.10,59.42,7.86">University of glasgow at trec 2011: Experiments with terrier in crowdsourcing, microblog, and web tracks</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,150.38,68.10,57.96,7.86">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.59,79.55,219.89,7.86;8,72.59,90.02,216.11,7.86;8,72.59,100.48,125.75,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="8,121.33,79.55,171.15,7.86;8,72.59,90.02,177.06,7.86">Automatic feature selection in the Markov random field model for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,267.77,90.02,20.94,7.86;8,72.59,100.48,33.21,7.86">Proc. of CIKM</title>
		<meeting>of CIKM</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="253" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.59,111.93,211.56,7.86;8,72.59,122.39,177.45,7.86;8,72.59,132.85,202.52,7.86;8,72.59,143.32,203.92,7.86;8,72.59,153.78,213.99,7.86;8,72.59,164.24,97.16,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="8,190.77,111.93,93.38,7.86;8,72.59,122.39,114.26,7.86">A markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,205.64,122.39,44.41,7.86;8,72.59,132.85,202.52,7.86;8,72.59,143.32,203.92,7.86;8,72.59,153.78,82.54,7.86">SIGIR &apos;05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.59,175.69,217.67,7.86;8,72.59,186.15,149.13,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="8,182.55,175.69,107.71,7.86;8,72.59,186.15,35.45,7.86">TextRank: Bringing Order into Text</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tarau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,126.79,186.15,64.93,7.86">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.59,197.61,169.68,7.86;8,72.59,208.07,184.53,7.86;8,72.59,218.53,187.83,7.86;8,72.59,228.99,176.16,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="8,195.67,208.07,61.45,7.86;8,72.59,218.53,187.83,7.86;8,72.59,228.99,32.97,7.86">Terrier: A high performance and scalable information retrieval platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,124.25,228.99,95.71,7.86">Proc. of OSIR at SIGIR</title>
		<meeting>of OSIR at SIGIR</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.59,240.45,203.57,7.86;8,72.59,250.91,214.47,7.86;8,72.59,261.37,200.38,7.86;8,335.61,57.64,194.18,7.86;8,335.61,68.10,205.97,7.86;8,335.61,78.56,162.14,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="8,110.73,250.91,176.34,7.86;8,72.59,261.37,40.34,7.86">Incorporating term dependency in the DFR framework</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,131.97,261.37,141.01,7.86;8,335.61,57.64,194.18,7.86;8,335.61,68.10,202.42,7.86">SIGIR &apos;07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,335.60,90.02,183.13,7.86;8,335.61,100.48,217.76,7.86;8,335.61,110.94,201.00,7.86;8,335.61,121.40,20.96,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="8,335.61,100.48,217.76,7.86;8,335.61,110.94,54.72,7.86">Exploiting query reformulations for Web search result diversification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,408.53,110.94,57.62,7.86">Proc. of WWW</title>
		<meeting>of WWW</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="881" to="890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,335.60,132.85,206.26,7.86;8,335.61,143.32,191.23,7.86;8,335.61,153.78,215.77,7.86;8,335.61,164.24,87.71,7.86" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="8,373.74,143.32,153.10,7.86;8,335.61,153.78,200.46,7.86">University of Glasgow at TREC 2010: Experiments with Terrier in Blog and Web tracks</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,335.61,164.24,57.96,7.86">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,335.60,175.69,207.84,7.86;8,335.61,186.15,219.26,7.86;8,335.61,196.62,213.08,7.86;8,335.61,207.08,174.54,7.86;8,335.61,217.54,215.92,7.86;8,335.61,228.00,117.12,7.86" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="8,335.61,186.15,215.17,7.86">Robust ranking models via risk-sensitive optimization</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Collins-Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,347.10,196.62,201.58,7.86;8,335.61,207.08,174.54,7.86;8,335.61,217.54,128.70,7.86">Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;12</title>
		<meeting>the 35th international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="761" to="770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,335.60,239.45,202.03,7.86;8,335.61,249.92,211.30,7.86;8,366.69,260.38,145.26,7.86" xml:id="b28">
	<monogr>
		<title level="m" type="main" coord="8,335.61,249.92,166.21,7.86">Ranking, boosting, and model adaptation</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">M</forename><surname>Svore</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno>MSR-TR-2008-109</idno>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Microsoft</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
