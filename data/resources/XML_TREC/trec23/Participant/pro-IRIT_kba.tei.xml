<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,210.65,87.86,185.01,12.93">IRIT at TREC KBA 2014</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,118.85,126.21,51.37,9.96"><forename type="first">Rafik</forename><surname>Abbes</surname></persName>
							<email>abbes@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">IRIT</orgName>
								<address>
									<addrLine>Paul Sabatier University 118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,178.54,126.21,98.76,9.96"><forename type="first">Karen</forename><surname>Pinel-Sauvagnat</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IRIT</orgName>
								<address>
									<addrLine>Paul Sabatier University 118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,285.25,126.21,84.23,9.96"><forename type="first">Nathalie</forename><surname>Hernandez</surname></persName>
							<email>hernandez@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">IRIT</orgName>
								<address>
									<addrLine>Paul Sabatier University 118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,397.09,126.21,90.33,9.96"><forename type="first">Mohand</forename><surname>Boughanem</surname></persName>
							<email>boughanem@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">IRIT</orgName>
								<address>
									<addrLine>Paul Sabatier University 118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,210.65,87.86,185.01,12.93">IRIT at TREC KBA 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B52306CA94AE3D1E504D85D0252F14B1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the IRIT lab participation to the Vital Filtering task (also known as Cumulative Citation Recommendation) of the TREC 2014 Knowledge Base Acceleration Track. This task aims at identifying vital documents containing timely new information that should help a human to update the profile of the target entity (e.g., Wikipedia page of the entity). In this work, we evaluate two factors that could detect vitality. The first one uses a Language Model to learn vitality from a sample of vital documents, and the second leverages the bursts of documents in the stream. Obtained results are presented and discussed.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Presentation of the task</head><p>The aim of the Vital Filtering task<ref type="foot" coords="1,256.72,354.11,3.97,6.97" target="#foot_0">1</ref> is to identify vital documents for a given entity. These documents should help knowledge base editors to update the profile of the entity (e.g. its Wikipedia article). A specially filtered subset of the full TREC 2014 StreamCorpus<ref type="foot" coords="1,479.51,378.03,3.97,6.97" target="#foot_1">2</ref> was provided for use in the 2014 TREC KBA Track. It consists of about 20 million timestamped documents from several sources (News, Social, Forum, Blog, etc.) having a size of 639 GB (compressed). The target topic set is composed of 71 entities including persons, organization and facilities. Each entity E has a training end time (that we denote by T T R end (E)). Documents before T T R end (E) can be used as training data and those after are used as test documents.</p><p>Document annotations were done as follows: a document is considered as Vital if it contains a timely relevant information about the entity, Useful if it contains relevant but not timely information about the entity, Neutral if it mentions the entity without providing any information about it, and Garbage if it does not mention the entity. The official metric for the task is the hF1 , i.e. the maximum macro-averaged F1 measured over all confidence cutoff i (i ∈ [0, 1000] where 1000 corresponds to the highest level of confidence and 0 corresponds to the level in which all documents are kept).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A two-step vitality filtering approach</head><p>Entity-centric document filtering methods have been classified into two categories: classification and ranking <ref type="bibr" coords="1,178.22,615.24,9.95,9.96" target="#b0">[1]</ref>. Unlike our past participation based on a classification approach <ref type="bibr" coords="1,476.39,615.24,9.95,9.96" target="#b1">[2]</ref>, we propose this year a ranking based vitality filtering approach which involves two main steps: filtering and scoring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Filtering step</head><p>The filtering step can be seen as a way to eliminate non-relevant documents. In this step, for each hour, we select only the topH documents that match the full entity name based on the following score:</p><formula xml:id="formula_0" coords="2,246.66,142.02,111.76,27.53">Score(d, E) = t∈E tf (t, d) |d|</formula><p>Where d is a document, and E represents the full entity name extracted from the given topic url. For example, for the topic https://kb.diffeo.com/Jeff Mangum, E= Jeff Mangum. tf (t, d) is the term frequency of term t in document d.</p><p>In addition, to reject documents matching the entity but more likely to be spam, we apply the following two filters:</p><p>-An enumeration filter that rejects documents mentioning the entity only in an abusive list of more than n entities such as E 1 , . . ., E t , . . ., E n . -A links filter that rejects documents having more than n hyper-links.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Scoring step</head><p>Documents that pass the filtering step are ranked using two vitality factors: a Language-Model-based factor and a Burst-based factor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Estimating vitality with the Language-Model-based factor</head><p>We use a Language Model to estimate a vitality model for each entity. With this model, we want to detect "vital" words that help identify upcoming vital documents. As vitality is unknown a priori, we leverage the set of training vital documents (before T T R end (E)). We believe that we can find some common features between vital documents of the training set and a new vital one. Formally, given an entity E and a sample of n vital documents vd i , we estimate the entity vitality model θ VE as follows:</p><formula xml:id="formula_1" coords="2,233.83,432.87,270.56,28.12">P (t|θ VE ) = n i=1 tf (t, vd i )df (t) n i=1 |vd i | (1)</formula><p>We note that P (t|θ VE ) is not a strict probability distribution tf (t, vd i ) is the term frequency of term t in document vd i df (t) = 1 log( n+1 m ) is used to boost terms often appearing in vital documents, where m represents the number of vital documents for E containing term t.</p><p>The vitality score of a new incoming document d with respect to an entity E is evaluated as follows:</p><formula xml:id="formula_2" coords="2,209.34,547.68,295.05,24.52">Score LM (d, E) = t∈top k (θV E ) P (t|θ d ) P (t|θV E )<label>(2)</label></formula><p>Where top k (θ VE ) is the set of top k terms in θ VE , and P (t|θ d ) is estimated using a Dirichlet Smoothing as follows:</p><formula xml:id="formula_3" coords="2,106.87,610.45,397.53,47.95">P (t|θ d ) = tf (t, d) + µ tf (t,C) t ′ ∈C tf (t ′ ,C) |d| + µ (3) tf (t, d)</formula><p>is the term frequency of term t in the document d tf (t, C) is the term frequency of term t in the collection C C is the reference collection composed from early stream documents before T T R end (E) µ is a smoothing parameter used to avoid null probabilities</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Estimating vitality with the burst-based factor</head><p>We assume that when new information is published about a given entity, this might lead to an accelerated growth of the number of documents describing this new information. Our idea is to consider that a document is vital regarding an entity E if it appears in a burst of documents that match the entity E. We hypothesize that the higher the number of matching documents is in a short period, the higher the probability of having vital documents will be. We leverage this idea in our burst-based factor. Formally, for a new incoming document d, we evaluate its vitality with respect to E as follows:</p><formula xml:id="formula_4" coords="3,106.87,194.43,397.53,51.60">Score Burst (d, E) = (1 -e -x 2 σ ) * t∈E P (t|θ d ) (4) 1 -e -x 2 σ</formula><p>is a cumulative distribution function used to capture the bursts of documents in the stream x is the number of documents mentioning the entity E in the last w hours preceding the time of d σ is a parameter reflecting the burst importance t∈E P (t|θ d ) is used to prioritize the bursty relevant documents 3 Proposed runs and results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Proposed runs</head><p>We proposed several runs that can be classified into five methods based on the scoring function:</p><p>-VLM runs : Score V itality = Score LM (d, E) (Equation 2 in Section 2.2.1) -ULM runs : Score V itality = Score LM (d, E) (u) (similar than the method in Section 2.2.1, but considering useful documents rather than vital, to build the Language Model) -Burst runs : Score V itality = Score Burst (d, E) (Equation <ref type="formula" coords="3,369.94,441.84,4.42,9.96">4</ref>) -Product runs:</p><formula xml:id="formula_5" coords="3,108.12,453.65,354.80,22.20">Score V itality (d, E) = Score LM (d, E) * Score Burst (d, E) -Linear runs: Score V itality (d, E) = αScore LM (d, E) + (1 -α)Score Burst (d, E).</formula><p>(We evaluated 3 values of the tuning parameter α: 0.25, 0.5 and 0.75)</p><p>In the filtering step, we evaluated 3 values of topH (top documents matching the entity per hour) : 10, 50 and 100. In addition, we used two spam filters to reject documents that have more than n = 30 links, and/or mentioning the entity only in an abusive enumeration of n = 30 entities. Values of n in filters are fixed based on some observations on the last year collection.</p><p>To set the parameters of the our factors, we performed a 3-fold cross-validation method using the 2013 KBA topics.</p><p>-For the Language-Model-based factor, we varied µ between 50 and 1000 (step=50), and top k (θ VE ) between 5 to 100 (step=5). Optimal parameters are to be µ =200 and top k (θ VE ) =25. -For the Burst-based factor, we jointly tuned the parameters w and σ by varying σ between 1 and 10 with a step of 1, and considering different numbers of hours for w: 1, 6, 12, 24 and 48. Optimal values retained are w =24h and σ =3.</p><p>Documents confidence scores are assigned as follows: rank 1 gets a confidence value 1000, rank 2 gets a confidence value 999, etc. Ranks greater than 1000 were assigned a confidence value of 0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>Table <ref type="table" coords="4,130.32,298.52,4.98,9.96" target="#tab_0">1</ref> compares our different runs using the official metric of the task (hF1 ). First, we notice that the higher the number of documents considered per hour (topH) is, the better is the recall, and thus the hF1. In addition, we observe that many runs sharing the same value of topH obtain exactly the same results independently of the scoring method used. In fact, the runs sharing the same topH deliver the same set of documents but with different ranking.</p><p>All of these runs have the same behaviour as depicted in Figure <ref type="figure" coords="4,378.98,358.30,3.87,9.96" target="#fig_0">1</ref>: when the confidence cutoff decrease (i.e., more documents are kept), we notice a constant increase in recall while precision is more stable. As a result, the macro-averaged F1 (harmonic mean of the macro averaged precision and the macro averaged recall) obtains its maximum in the last confidence cutoff i * = 0. In figure <ref type="figure" coords="4,158.62,536.79,3.87,9.96">2</ref>, we evaluate the impact of our filters (Enumerations filter and Links filter ) when used or not in the V LM, topH = 50 run. Considering None (V LM, topH = 50 run in which no filter is applied) as a reference, we notice that the Enumerations filter improves slightly hF1 whereas the use of Links filters degrades it slightly. These two filters do not have a significant impact in this year collection, which was not the case on last year collection <ref type="bibr" coords="4,491.12,584.62,9.95,9.96" target="#b2">[3]</ref>.</p><p>In the following paragraph, we investigate a deeper comparison of our configurations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deeper comparison of our configurations</head><p>We think that our different scoring methods perform differently although they have the same hF1. To verify this, we fixed topH (top considered documents in each hour) to 50 (as all our five scoring methods were tested using this value), and we considered only the top 50 documents independently of hours (i.e., conf idence cutof f = 950) (as 50 represents the mean of vital documents for all entities). Results are illustrated in Table <ref type="table" coords="4,421.47,684.25,3.87,9.96" target="#tab_1">2</ref> Unlike the hF1 metric, F1@950 (considering the top 50 documents) shows that our runs perform differently. We can therefore report the following finding:</p><p>-Results show that V LM run (based on a vital sample of documents) performs better than U V M run (based on a useful sample of documents) which indicates that the Language-Model-based factor (described in Section 2.2.1) can learn "vital" that not exist in useful documents. The learned "vital" terms, captured in the training time range, are very helpful to detect upcoming vital documents (in the test time range). -The Language-Model-based factor performs better than the Burst factor (0.357 vs. 0.350).</p><p>The latter factor performs the worst among all configurations. -Combining both Language model and Burst factors (Linear(α = 0.75 or 0.5) or P roduct) provides better results than using each factor individually. Furthermore, giving a high weight to the Language model factor when using a linear combination (Linear(α = 0.75)) provides the best performance.</p><p>We can conclude that estimating vitality using a Language Model is promising for vitality detection especially when combined with temporal feature such as the burst. The hF1 metric is unfortunately not an appropriate metric to confirm our findings.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,121.82,502.84,362.66,8.97;4,148.24,513.80,325.48,8.97"><head>Fig. 1 :</head><label>1</label><figDesc>Fig.1: Linear(α = 0.75), topH=50 results: macro averaged recall (mR), macro averaged precision (mP) and their harmonic mean F in function of the confidence cutoff i.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,113.32,89.29,371.16,169.65"><head>Table 1 :</head><label>1</label><figDesc>Comparison of the different configurations of our approach. i* corresponds to the confidence cut-off in which F1 is maximum. Presented results consider the official 71 KBA entities.</figDesc><table coords="4,113.32,89.29,365.61,130.71"><row><cell>Run</cell><cell>i*</cell><cell cols="2">mPrecision@i* mRecall@i*</cell><cell>F1@i*</cell></row><row><cell>VLM, topH=10</cell><cell>34</cell><cell>0.319</cell><cell>0.821</cell><cell>0.459</cell></row><row><cell>ULM, topH=10</cell><cell>0</cell><cell>0.306</cell><cell>0.900</cell><cell>0.457</cell></row><row><cell>Burst, topH=10</cell><cell>0</cell><cell>0.306</cell><cell>0.900</cell><cell>0.457</cell></row><row><cell>Product, topH=10</cell><cell>0</cell><cell>0.306</cell><cell>0.900</cell><cell>0.457</cell></row><row><cell cols="2">Linear(α ∈ {0.25, 0.5, 0.75}), topH=10 0</cell><cell>0.306</cell><cell>0.900</cell><cell>0.457</cell></row><row><cell>VLM, topH=50</cell><cell>34</cell><cell>0.322</cell><cell>0.841</cell><cell>0.466</cell></row><row><cell>ULM, topH=50</cell><cell>0</cell><cell>0.309</cell><cell>0.936</cell><cell>0.465</cell></row><row><cell>Burst, topH=50</cell><cell>0</cell><cell>0.309</cell><cell>0.936</cell><cell>0.465</cell></row><row><cell>Product, topH=50</cell><cell>0</cell><cell>0.309</cell><cell>0.936</cell><cell>0.465</cell></row><row><cell cols="2">Linear(α ∈ {0.25, 0.5, 0.75}), topH=50 0</cell><cell>0.309</cell><cell>0.936</cell><cell>0.465</cell></row><row><cell cols="2">Linear(α ∈ {0.25, 0.5, 0.75}), topH=100 0</cell><cell>0.310</cell><cell>0.938</cell><cell>0.466</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,425.34,684.25,3.87,9.96"><head>Table 2 :</head><label>2</label><figDesc>. Comparison of the different configurations of our approach considering the top 50 documents based on confidence score (i.e., confidence cutoff i to 950)</figDesc><table coords="5,121.82,92.29,362.65,201.35"><row><cell></cell><cell>0.47</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.469</cell></row><row><cell></cell><cell>0.465</cell><cell>0.465</cell><cell></cell><cell>0.466</cell></row><row><cell>hF1</cell><cell>0.46</cell><cell></cell><cell>0.463</cell></row><row><cell></cell><cell>0.455</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.45</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>None</cell><cell>Links</cell><cell>EnumeraƟons</cell><cell>Both</cell></row><row><cell cols="5">Fig. 2: Impact of each spam filter on hF1 when added to used or not in V LM, topH = 50</cell></row><row><cell>run</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Run</cell><cell></cell><cell cols="3">mPrecision@950 mRecall@950</cell><cell>F1@950</cell></row><row><cell>Linear(α = 0.75)</cell><cell></cell><cell>0.396</cell><cell></cell><cell>0.354</cell><cell>0.374</cell></row><row><cell>Product</cell><cell></cell><cell>0.403</cell><cell></cell><cell>0.333</cell><cell>0.364</cell></row><row><cell>Linear(α = 0.5)</cell><cell></cell><cell>0.393</cell><cell></cell><cell>0.334</cell><cell>0.361</cell></row><row><cell>VLM</cell><cell></cell><cell>0.375</cell><cell></cell><cell>0.341</cell><cell>0.357</cell></row><row><cell>Linear(α = 0.25)</cell><cell></cell><cell>0.385</cell><cell></cell><cell>0.329</cell><cell>0.354</cell></row><row><cell>ULM</cell><cell></cell><cell>0.368</cell><cell></cell><cell>0.333</cell><cell>0.350</cell></row><row><cell>Burst</cell><cell></cell><cell>0.368</cell><cell></cell><cell>0.333</cell><cell>0.350</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,111.85,663.07,218.46,8.97"><p>http://trec-kba.org/trec-kba-2014/vital-filtering.shtml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,111.85,674.04,373.88,8.97;1,111.85,685.00,9.46,8.97"><p>http://s3.amazonaws.com/aws-publicdatasets/trec/kba/index.html#kba-streamcorpus-2014-v0</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="1,124.64,685.00,61.42,8.97"><p>3 0-kba-filtered</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,105.47,594.44,398.93,8.97;5,114.04,605.40,390.35,8.97;5,114.04,616.35,258.27,8.97" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,279.76,594.44,224.65,8.97;5,114.04,605.40,28.91,8.97">Cumulative citation recommendation: Classification vs. ranking</title>
		<author>
			<persName coords=""><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heri</forename><surname>Ramampiaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,161.12,605.71,343.27,8.65;5,114.04,616.66,97.18,8.65">Proc. of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="941" to="944" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.47,627.32,398.93,8.97;5,114.04,638.28,280.06,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,472.10,627.32,32.30,8.97;5,114.04,638.28,207.85,8.97">IRIT at TREC knowledge base acceleration 2013: CCR task</title>
		<author>
			<persName coords=""><forename type="first">Rafik</forename><surname>Abbes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karen</forename><surname>Pinel-Sauvagnat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nathalie</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohand</forename><surname>Boughanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,341.35,638.58,22.95,8.65">TREC</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.47,649.23,398.93,8.97;5,114.04,660.19,390.37,8.97;5,114.04,671.16,147.43,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,460.74,649.23,43.66,8.97;5,114.04,660.19,258.40,8.97">Leveraging temporal expressions to filter vital documents related to an entity</title>
		<author>
			<persName coords=""><forename type="first">Rafik</forename><surname>Abbes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karen</forename><surname>Pinel-Sauvagnat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nathalie</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohand</forename><surname>Boughanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,389.93,660.50,114.47,8.65;5,114.04,671.46,72.93,8.65">ACM Symposium on Applied Computing (SAC)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
