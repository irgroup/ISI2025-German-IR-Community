<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,104.19,62.71,403.61,20.73">HU DB at TREC 2014 Microblog Track</title>
				<funder ref="#_fbzkAXR">
					<orgName type="full">Ministry of Science and Technology</orgName>
				</funder>
				<funder ref="#_bhQ5aEY">
					<orgName type="full">Israel Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,183.28,102.52,61.71,9.50"><forename type="first">Jennifer</forename><surname>Klein</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">The Rachel and Selim</orgName>
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
								<address>
									<country key="BJ">Benin</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,253.34,102.52,63.01,9.50"><forename type="first">Yishai</forename><surname>Oltchik</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">The Rachel and Selim</orgName>
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
								<address>
									<country key="BJ">Benin</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,324.64,102.52,39.85,9.50"><forename type="first">Nerya</forename><surname>Or</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">The Rachel and Selim</orgName>
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
								<address>
									<country key="BJ">Benin</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,372.95,102.52,51.92,9.50"><forename type="first">Sara</forename><surname>Cohen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">The Rachel and Selim</orgName>
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
								<address>
									<country key="BJ">Benin</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,104.19,62.71,403.61,20.73">HU DB at TREC 2014 Microblog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4CA1F766AFEB6D53908DBCB1A1809A31</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our system for the Tweet Timeline Generation (TTG) task of the Microblog track, at the Text Retrieval Conference (TREC) 2014. Intuitively, given a collection of microblog posts (i.e., tweets), and a keyword query Q, the goal is to generate a timeline of related tweets. Such a timeline consists of representative tweets, relevant to Q. In our system we employ query expansion to identify highly relevant tweets, and then use affinity propagation to cluster the tweets, based on their word similarity, hashtag similarity and temporal similarity. We then return a representative tweet from each cluster. The result is a system with relatively good precision, but, unfortunately, poor recall. We discuss the techniques employed, as well as the insights gleaned while developing and testing our system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Microblogging platforms, such as Twitter, Google+ and Tumblr, are a popular means to share and discover timely information. Such platforms differ from standard social networks, in that users post only short messages. As such, microblogging gives rise to new information retrieval challenges. One such important challenge, which is the focus of this TREC task, is that of summarizing non-redundant information, relevant to a given information need. Both the problem of finding relevant microblog posts, and that of grouping them into disjoint clusters, is challenging, due to the brevity of microblog posts.</p><p>The Microblog track at TREC 2014 focused only on Twitter, and defined the following task, called the Tweet Timeline Generation (TTG) task: Task 1. Given a keyword query Q and a time cutoff t, retrieve a timeline of the most informative tweets about Q which were posted no later than t, where a timeline is simply a list of representative tweets, sorted according to time.</p><p>As part of the TREC framework, an online API to a historical Twitter dataset was made available. Keyword queries were dispatched to the API and matching sets of tweets were returned. We used only this API in our implementation, and no additional external datasets. Our goal was to determine how well queries can be answered in this fashion, i.e., whether one must resort to additional external data in order to achieve satisfactory precision and recall in such a setting.</p><p>The TTG task poses several inherent difficulties. First, tweets are very short. Hence, determining whether a tweet is relevant is a difficult task. Unlike longer documents, considered in standard information retrieval tasks, there are few context clues that can help determine the tweet's topic focus. Second, as we are returning representative tweets, each such tweet should be non-redundant, given the other tweets, i.e., tweets should each contain distinct information one from another, and thus, every tweet containing distinctly different information should be returned. Third, the system should not return too many tweets, as the goal is to create a timeline of representative related tweets, and not to exhaustively return every related tweet. Thus, tweets similar one to another should have a single representative in the final results.</p><p>We note that the second and third challenges give rise to rather contradictory solutions. In order to make sure that all representatives are returned (Challenge 2) one is motivated to return many tweets. However, too many representatives should not be returned (Challenge 3), and thus, among tweets that are similar (but not identical) a single representative should be chosen. To deal with these challenges, we clustered the tweets and returned a single representative from each cluster. As it turned out, choosing the correct cluster sizes (and thereby determining the number of representatives) is critical to achieving satisfactory recall. As we discuss later on, our choice of too large clusters seems to have been a determining factor which caused our system to have recall that was insufficient.</p><p>This paper is organized as follows. Section II describes our system. Empirical results of our submitted runs are presented in Section III. In Section IV we discuss insights gleaned from participation in this task. Finally, in Section V we conclude.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. SYSTEM OVERVIEW</head><p>Given a keyword query Q and time t, our system proceeds in three stages:</p><p>1) Find relevant tweets, for the given query. 2) Cluster the tweets into highly related semantic groups.</p><p>3) Choose a representative tweet from each cluster.</p><p>Finally, we return a timeline consisting of a time-sorted list of representative tweets. Each of these stages is discussed in detail below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Generating a Corpus of Relevant Tweets</head><p>In the first stage, the system gathers tweets that seem to be relevant to the given keyword query Q. To find such tweets, we start by removing stop words from Q, thereby deriving a new query Q 1 . We dispatch Q 1 to the TREC API as a conjunctive query. If Q 1 returned no results, we attempt to dispatch variations of Q in which one or more terms is omitted. This gives us a first set of relevant tweets R 1 .</p><p>We then perform query expansion, to derive additional, relevant, tweets as follows. Let W be the set of words w in R 1 that satisfy the following conditions:</p><p>• w is not a stop word; • w appears in at least α|R 1 | of the tweets of R 1 . Intuitively, w is a popular term in the results of Q 1 , and is not a stop word, and hence, is likely to be relevant to query Q. After some testing, we chose α = 0.2. Now, if query Q 1 contained at least i terms, we create and dispatch additional queries, using the words in W . These new queries are created in the following fashion. For each word w 1 in Q 1 and each word w ∈ W , we create a query Q w1↔w derived by swapping w 1 with w. Note that a choice of a sufficiently large i is necessary to avoid topic drift. In our experiments, we often (but not always) chose i = 4. Additional details appear in Section III.</p><p>Let R 2 be the set of tweets containing both R 1 , as well as the results derived by all queries created in the expansion process. According the the TREC guidelines, we removed from R 2 tweets that are deemed to be "retweets" (i.e., duplicates of other tweets, generated as a result of a user sharing a tweet generated by another user), as well as non-English tweets. We also removed duplicates tweets. Note that we removed illegal tweets from R 2 (and not from R 1 ), as such tweets can contain valuable information (such as frequent words), even if they should not be returned to the user. Let R be the set of remaining tweets. We use R in the next stages, to create our clusters and final results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Clustering the Tweets</head><p>In the second stage, we cluster the corpus of tweets R, which was obtained in the first stage. The goal is to place similar tweets in the same cluster. However, determining whether tweets are similar is not a trivial problem. Our system is based on three assumptions:</p><p>• Tweets containing similar sets of words are similar. This is natural, as tweets using mostly the same words are likely to be on the same topic. • Tweets containing similar hashtags are similar. Hashtags are essentially labels, chosen by the microblog poster, to describe his or her tweet. If users choose the same labels, their tweets are likely to be on the same topic. • Tweets that were tweeted close in time one to another are similar. Since many tweets are tweeted based on breaking events, if users post tweets at similar times, their tweets are likely to be in reaction to the same event.</p><p>We now consider how to turn each of these assumptions into a numerical similarity score. Let t 1 and t 2 be tweets. </p><formula xml:id="formula_0" coords="2,378.81,75.68,164.99,23.23">) = |B(t 1 ) ∪ B(t 2 )| -2|B(t 1 ) ∩ B(t 2 )| |B(t 1 ) ∪ B(t 2 )| -|B(t 1 ) ∩ B(t 2 )| .</formula><p>Note that bag union and intersection is used in the above formula.</p><p>Definition 2 (Hashtag Similarity). Let H(t i ) be the set of hashtags in t i . Then, the hashtag similarity of t 1 and t 2 , denoted d hash (t 1 , t 2 ), is the Jaccard coefficient of H(t 1 ) and H(t 2 ), i.e.,</p><formula xml:id="formula_1" coords="2,360.99,187.30,153.02,23.23">d hash (t 1 , t 2 ) = 1 - |H(t 1 ) ∩ H(t 2 )| |H(t 1 ) ∪ H(t 2 )| .</formula><p>Finally, we define the temporal similarity of tweets t 1 and t 2 .</p><p>Definition 3 (Temporal Similarity). Let m be the maximal time difference between the timestamps of any two tweets in R. Let ts(t i ) be the timestamp of t i . Then, the temporal similarity of t 1 and t 2 , denoted d time (t 1 , t 2 ) is defined as follows</p><formula xml:id="formula_2" coords="2,351.99,300.92,171.03,9.65">d time (t 1 , t 2 ) = 1 -g m (|ts(t 1 ) -ts(t 2 )|) ,</formula><p>where g m is the Gaussian bell curve formula where parameter σ is chosen to be a linear function of m.</p><p>In order to compute the distance between t 1 and t 2 , we used a linear combination of the three similarity measures defined above. We considered three weighting schemes:</p><p>• Equal Weight: In this weighting scheme, we gave equal weight to all three parameters, based on the intuition that a priori, it is not known which is the most important, i.e.,</p><formula xml:id="formula_3" coords="2,335.30,429.46,224.43,36.36">d eqW eight (t 1 , t 2 ) = d word (t 1 , t 2 ) + d hash (t 1 , t 2 ) + d time (t 1 , t 2 ) 3 .</formula><p>• Decreased Temporal Weight: Due to the large number of tweets that are posted at any given moment in time, it is likely that many unrelated tweets will be posted at the same time. Hence, in this scheme, we give lower relative weight to temporal similarity, defining,</p><formula xml:id="formula_4" coords="2,332.00,536.80,231.77,23.70">d lowT emporal (t 1 , t 2 ) = 5 (d word (t 1 , t 2 ) + d hash (t 1 , t 2 )) + 2 • d time (t 1 , t 2 )</formula><p>12 .</p><p>• No Temporal Scoring: Finally, in our last weighting scheme, we completely ignored temporal similarity, as this factor may sometimes be more misleading than helpful, and defined</p><formula xml:id="formula_5" coords="2,341.08,629.85,212.87,22.31">d noT emporal (t 1 , t 2 ) = d word (t 1 , t 2 ) + d hash (t 1 , t 2 ) 2 .</formula><p>Now, given a tweet distance function d (which is one of d eqW eight , d lowT emporal , or d noT emporal ), we create a distance matrix M d , with dimensions |R| × |R|. The entry in place M d [i, j] is simply d(t i , t j ), where t i and t j are the i-th and j-th tweets in R. Note that identical tweets will have distance 0, and the largest possible distance value is 1.</p><p>Finally, we cluster the tweets using M d with the Affinity Propagation clustering algorithm <ref type="bibr" coords="3,187.48,71.42,10.58,8.64" target="#b0">[1]</ref>. Affinity Propagation is an iterative algorithm that uses message passing between samples in the data set in order to determine which samples are best exemplified by which other samples. One of the significant advantage of Affinity Propagation over other, more standard, clustering algorithms, is that the number of clusters does not have to be predetermined. This was a distinct advantage in the context of the TREC TTG task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Cluster Representative Selection</head><p>In our third, and final stage, for each cluster C created in the second stage, we choose a representative tweet. This is necessary in order to generate the final desired result-a timeline of informative tweets.</p><p>Let C be a cluster of tweets. Two ideas were used in order to choose a representative for C:</p><p>• Centrality: Intuitively, the closer a tweet is to the entire cluster, the more similar it is to all tweets in the cluster. Formally, for t ∈ C, and a tweet distance function d, we define</p><formula xml:id="formula_6" coords="3,121.99,304.42,119.40,24.72">cent d (t, C) = 1 t ∈C d(t, t )</formula><p>.</p><p>• Amount of retweets: Tweets which were shared many times by other users were deemed highly relevant by real users. Hence, such tweets received a boost in ranking. Formally, we define r etweet(t) as the number of times that t was retweeted. In our implementation, we also considered different ways of combining these two factors, with similar results derived.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. RESULTS</head><p>A total of 4 runs were submitted by our team, denoted Standard, SR, SRTD and SRTL. These runs differed one from each other in our choice of i (the minimal size of queries for which expansion is performed) and d (the tweet distance function). These choices appear in Table <ref type="table" coords="3,218.75,554.20,2.90,8.64">I</ref>  TTG task outputs are assessed according to two metrics: precision and recall. Precision is measured as the ratio of semantic clusters represented, divided by the total size of the result set. Recall is defined as the ratio between the number of semantic clusters represented and the actual number of semantic clusters that exist in the dataset, as determined by a human assessor. Additionally, a weighted variant of scoring was used, in which tweets that were marked as highly relevant by the human assessors contributed twice as much weight to the score of results that contained them.</p><p>Table <ref type="table" coords="3,349.67,588.18,6.64,8.64" target="#tab_4">II</ref> shows the results of our submitted runs. Figures 1 and 2 are scatter-plots of the results of all runs submitted by teams participating in the 2014 TREC microblog track. Within these figures, our results form a cluster around the top-left area, displaying high precision but relatively low recall performance. The low recall reflects the fact that our system tends to partition the tweet corpus into fewer large clusters, rather than many small ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. LIMITATIONS AND SUGGESTED IMPROVEMENTS</head><p>The TTG task was new for 2014, and thus, this was our first time in participating in such an initiative. In this  section we discuss insights, system limitations and suggested improvements, gleaned in a post-mortem, from our system results. It is our hope that these will be useful for others, interested in solving the TTG task (or similar problems) in the future.</p><p>Fixed parameter values. Our choices of i and d were fixed within a run. However, in practice, it is apparent that different choices were preferable for different queries. More experimentation is needed to learn query properties that imply preference for one set of parameters over another. If such learning is accomplished, a single run could combine different parameters for different queries, thus improving their results, in general.</p><p>Going beyond stop-words. Our system used a coarse separation of query terms into stop-words and non-stop-words. In practice, finer distinctions were necessary to determine words that are critical to a query, and should never be removed (i.e., swapped out) in the query expansion process. For example in the query 'Argo wins Oscar', the term 'Argo' is critical and it is virtually impossible to obtain a good set of results when searching without this term. The term 'wins' is not a stop-word, yet could have been omitted without incurring too much query drift.</p><p>Grammar-based term modification during query expansion. The corpus of tweets against which we applied queries was available only via the API. Hence, we could not perform stemming on this corpus. Thus, queries using terms in a different grammatical form from that of a tweet, could not return the tweet. A possible solution to this problem would have been expanding the query with modified grammatical forms of query terms, e.g., for the query 'injuries by pets', one could expand with terms such as 'injury' and 'pet'.</p><p>Using clustering to find representative tweets. Our system was built leveraging the idea that by clustering tweets, and choosing cluster representatives, one can create a timeline of representative tweets. Our clustering technique created relatively large clusters. At development time, this was deemed to be an advantage to the system, i.e., that it succinctly summarizes large numbers of tweets. In practice, our approach towards choosing representatives did not agree with that of the human assessors (who had many more representatives than us), and thus, our system received very low recall scores. We note that the semantic clusters created by the human assessors were often singletons, and thereby giving clear preference by them to large numbers of representative tweets.</p><p>Ontologies or external knowledge bases. Our system did not employ any sort of ontology or external knowledge base in order to better perform query expansion. As it turned out, this was a bad design decision. As tweets are short, it is not possible to find all related terms only by taking popular terms within the first tweet set R 1 . Use of an external knowledge base or ontology would have been helpful in overcoming this difficulty, e.g., in queries such as "injuries by pets', expanding pets with dogs, cats, etc., using an ontology, would have been beneficial.</p><p>Query expansion using hashtags. In Twitter, it is common that an event has more than one hashtag associated with it. Thus, by determining which hashtags are related to an event, one can derive new relevant queries to run and obtain more data. Thus, query expansion should proceed not only with words, but also with hashtags. This was not included in our system. Ambiguous queries. Choosing relevant tweets and creating timelines was made more difficult due the fact that (as often happens in real life), queries were ambiguous, and their interpretation as information needs were not available during system development. Some queries were interpreted in a very narrow fashion by the human assessors, e.g., 'cherry blossom Washington' was interpreted as tweets expressing interest in attending the National Cherry Blossom Festival in Washington (and not information about cherries blossoming in Washington). Obviously, query interpretation has a significant effect on precision, but it is difficult to overcome this issue in an information retrieval system.</p><p>In addition, the TTG task seems to be well fitted for queries searching for information about events, as in such a case it is natural for a timeline to be generated. On the other hand, queries looking for specific information do not seem to be suited for TTG. Some of the queries given for the task fell into the second category, which made finding representative tweets, in a timeline, more difficult. The ability to automatically differentiate between such queries, and apply different techniques, depending on query type, would be a useful future system feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>Our system employed a fairly simple mechanism, based on query expansion and clustering, to solve the TTG task. Even though external data sources were not used, relatively high precision was achieved, with somewhat less satisfactory recall. Besides providing system details, we have discussed new directions and extensions that can help to significantly boost the recall. We leave such implementations for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,58.92,396.65,241.09,8.96;3,48.96,408.60,251.06,8.96;3,48.96,420.88,24.90,8.64;3,77.41,439.13,77.06,8.74;3,137.91,447.60,14.09,6.12;3,154.47,439.13,117.10,9.65"><head></head><label></label><figDesc>For a representative tweet rep(C) of C, we chose the tweet t in C that maximized the combined centrality and retweet scores rep(C) = arg max t∈C (cent d (t, C) + r etweet(t)) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,311.97,60.22,251.06,6.91;3,311.97,69.19,15.72,6.91;3,311.97,74.47,257.03,192.78"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Unweighted recall vs. precision of all submitted TREC microblog runs.</figDesc><graphic coords="3,311.97,74.47,257.03,192.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,111.18,554.20,126.08,84.71"><head></head><label></label><figDesc>.</figDesc><table coords="3,111.18,576.23,126.08,62.68"><row><cell cols="2">Run Name i</cell><cell>d</cell></row><row><cell>Standard</cell><cell>3</cell><cell>d eqW eight</cell></row><row><cell>SR</cell><cell>4</cell><cell>d eqW eight</cell></row><row><cell>SRTD</cell><cell cols="2">4 d lowT emporal</cell></row><row><cell>SRTL</cell><cell cols="2">4 d noT emporal</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,155.72,131.07,300.55,15.88"><head>TABLE II RESULTS</head><label>II</label><figDesc>OF OUR SUBMITTED RUNS: UNWEIGHTED/WEIGHTED RECALL, AND PRECISION.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>VI. ACKNOWLEDGMENTS</head><p>The authors were partially supported by the <rs type="funder">Israel Science Foundation</rs> (Grant <rs type="grantNumber">1467/13</rs>) and the <rs type="funder">Ministry of Science and Technology</rs> (Grant <rs type="grantNumber">3-9617</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_bhQ5aEY">
					<idno type="grant-number">1467/13</idno>
				</org>
				<org type="funding" xml:id="_fbzkAXR">
					<idno type="grant-number">3-9617</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,63.23,269.38,236.78,6.91;5,63.23,278.21,119.05,7.05" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,150.57,269.38,149.45,6.91;5,63.23,278.35,18.41,6.91">Clustering by passing messages between data points</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Dueck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,88.38,278.21,23.04,6.87">Science</title>
		<imprint>
			<biblScope unit="volume">315</biblScope>
			<biblScope unit="page" from="972" to="976" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
