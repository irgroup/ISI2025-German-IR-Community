<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,132.14,72.35,345.44,16.84;1,76.47,92.27,456.78,16.84;1,135.65,112.20,338.41,16.84">PKUICST at TREC 2014 Microblog Track: Feature Extraction for Effective Microblog Search and Adaptive Clustering Algorithms for TTG</title>
				<funder ref="#_6Rt6D6g">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,129.53,165.06,44.52,11.06"><forename type="first">Chao</forename><surname>Lv</surname></persName>
							<email>lvchao@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,189.33,165.06,55.83,11.06"><forename type="first">Feifan</forename><surname>Fan</surname></persName>
							<email>fanff@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,260.44,165.06,74.96,11.06"><forename type="first">Runwei</forename><surname>Qiang</surname></persName>
							<email>qiangrw@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,350.68,165.06,39.52,11.06"><forename type="first">Yue</forename><surname>Fei</surname></persName>
							<email>feiyue@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,405.48,165.06,66.77,11.06;1,472.25,158.49,1.54,7.86"><forename type="first">Jianwu</forename><surname>Yang</surname></persName>
							<email>yangjw@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,132.14,72.35,345.44,16.84;1,76.47,92.27,456.78,16.84;1,135.65,112.20,338.41,16.84">PKUICST at TREC 2014 Microblog Track: Feature Extraction for Effective Microblog Search and Adaptive Clustering Algorithms for TTG</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F926B9A4D1A3626F768F63F5A48BB822</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our approaches to temporally-anchored ad hoc retrieval task and tweet timeline generation (TTG) task in the TREC 2014 Microblog track. In the ad hoc search, we apply a learning to rank framework which utilizes not only the various content relevance of a tweet, but also the quality of a tweet. External evidences are well incorporated in our approach with Web-based query expansion and document expansion techniques. In the TTG task, we apply star clustering and hierarchical clustering algorithm on the retrieved tweets from ad hoc retrieval task. Experimental results show that our learning to rank methods with many state-of-the-art features achieve good retrieval performance with respect to MAP and P@30 metrics. Besides, our systems for TTG task also obtain convincing recall and precision scores.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Information retrieval in microblogging environment has attracted increasing attention with the growing popularity of microblog. To explore the search behavior and boost the retrieval performance in the real-time environment, TREC first introduced Real-Time Search task in 2011 <ref type="bibr" coords="1,246.09,474.30,9.20,7.86" target="#b5">[5]</ref>, where a user's information need is represented by a query at a specific point in time. The Microblog track in 2014 will use the "evaluation as a service" (EaaS) model, where teams interact with the official corpus via a common API. Tweet Timeline Generation (TTG) is a new task for this year's Microblog track with a putative user model as follows: "I have an information need expressed by a query Q at time t and I would like a summary that captures relevant information." In this year's task, the summary is operationalized by a list of non-redundant, chronologically ordered tweets that occur before time t.</p><p>In the ad hoc search, we apply a learning to rank framework with the help of the official API. Hundreds of features, including semantic score features, semantic expansion features and document quality features, are extracted to obtain good retrieval performance in microblogosphere. For the semantic score and semantic expansion features, we utilize different retrieval models (i.e. language models, BM25 and TFIDF) along with query expansion and document expansion techniques, in order to compute the relevance score of a given topic and tweet from different perspectives. In the * Corresponding author. query side, aside from the traditional pseudo relevance feedback based on top ranked tweets, external evidences from the Google search results are also utilized in our retrieval models to better understand the user's search intent. In the document side, we use the topic information of the shorten URLs embedded in tweets as the external evidence, and form a new document for relevance computation. For the document quality features, we use several quality features such as the number of hashtags, the term number in the tweet, the time difference between the query issue time and the tweet post time, etc. Topics for TREC'13 Microblog track are used for model training. Finally, we re-rank the results from the API and select the top 1000 tweets as our ad hoc search results.</p><p>The submitted results for ad hoc search results (i.e. the run labeled as PKUICST3) are used as the input source of our TTG system. Two strategies are adopted to determine how many results to use as TTG candidates. One strategy is to select the top N tweets or the tweets whose ranking scores are greater than a threshold score, which is determined by preliminary experiments on the training topics. Another strategy is to select the top ranked tweets manually for each query. After selecting the candidate tweets, clustering algorithms (i.e. star clustering and hierarchical clustering) are adopted to further detect and eliminate redundant tweets in the candidate set. The star clustering algorithm is a graph partition based approach, and adopts a tuned parameter Î± to determine whether a tweet would generate a new cluster. We choose the central tweet of each cluster as the representative tweet and eliminate other reluctant tweets. For the hierarchical clustering algorithm, a tuned cluster distance threshold is utilized to determine the final returned cluster count. For each cluster, the tweet with the highest score is selected as the representative tweet. All the representative tweets are then collected to form our final results for TTG task.</p><p>The remainder of the paper is organized as follows: we first presents our approach for ad hoc search task in Section 2. In Section 3, we describe our system for TTG task in detail. Section 4 presents our experimental results. At last, we conclude the paper in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">AD HOC SEARCH TASK</head><p>In this section, we first briefly introduce our system architecture for temporally-anchored ad hoc search task. Then, the learning to rank framework is described in detail.</p><p>At last, all the extracted features for the ad hoc search task are presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">System Overview</head><p>As mentioned above, the Microblog track use the 'evaluation as a service' (EaaS) model, where teams interact with the official corpus via a common API. In this section, we mainly discuss the architecture of our system, which is shown in Figure <ref type="figure" coords="2,124.53,143.60,3.58,7.86" target="#fig_0">1</ref>. From the figure, we can see that our system mainly contains three components:</p><p>1. Candidate Generation Component, which submits topics to TREC-API<ref type="foot" coords="2,183.23,182.66,3.65,5.24" target="#foot_0">1</ref> to generate the candidate set. Additionally, we use the query expansion techniques to retrieve more topic related tweets.</p><p>2. Feature Generation Component, which generates the state-of-the-arts features for the candidate tweets.</p><p>In our system, three groups of features are generated, i.e. semantic score features, semantic expansion features and quality features.</p><p>3. Re-Ranking Component, which re-ranks candidate tweets with a pairwise learning to rank algorithm <ref type="bibr" coords="2,280.63,302.01,9.20,7.86" target="#b3">[3]</ref>.</p><p>The re-ranked top 1000 relevant tweets are selected as the final results of our system.  The preprocessings we adopted on the queries and corpora are described as follows:</p><p>â¢ Non-English Filtering: We discarded the non-English tweets by using a language detector with infinity-gram, named ldig<ref type="foot" coords="2,441.51,76.79,3.65,5.24" target="#foot_1">2</ref> .</p><p>â¢ Simple Retweet Elimination: We eliminated tweets that begin with 'RT' with the consideration that these tweets have no extra information beyond the original ones.</p><p>â¢ Stemming and Stopword Filtering: Each tweet was stemmed using the Porter algorithm. Moreover, stopwords were removed using InQuery words stoplists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Learning to Rank Framework</head><p>Learning to rank is a data-driven approach which integrates a bag of features in the model effectively. Our system adopts the similar framework that Duan et al <ref type="bibr" coords="2,506.73,233.29,9.72,7.86" target="#b1">[1]</ref> proposed except that we extract much more features for the ad hoc search task. The learning to rank framework is shown in Figure <ref type="figure" coords="2,347.20,264.68,3.58,7.86" target="#fig_1">2</ref>. In order to train an effective model, adequate training data and useful feature set are required. Our training set is generated from the official result set of TREC'13 Microblog track. Besides, features in our proposed approach take both the similarity of query-document and the quality of the document into consideration. RankSVM algorithm <ref type="bibr" coords="2,546.21,316.98,9.72,7.86" target="#b3">[3]</ref> is utilized to train a ranking model from the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Feature Generation</head><p>Several features have been proved effective in the prior work <ref type="bibr" coords="2,340.19,370.16,9.72,7.86" target="#b2">[2,</ref><ref type="bibr" coords="2,354.04,370.16,6.48,7.86" target="#b6">6]</ref>. However, these features are not fully utilized to further improve the performance of learning to rank approach in the microblogosphere. In this section, we describe the features used in RankSVM in detail. We classify all the feature into three groups as semantic score features , semantic expansion features and document quality features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Semantic Score Features</head><p>Semantic score features refer to the features that describe the relevance between the query and tweets by analyzing the content of tweets. These semantic score features are listed as follows:</p><p>â¢ TFIDF Model Score (QueryTFIDFTweet): This feature calculates the cosine similarity distance between a query and a tweet in the Vector Space Model with the TFIDF weighting method. Vector Space Model is an algebraic model for representing text documents as vectors of identifiers. We express the query and tweet as vectors:</p><formula xml:id="formula_0" coords="2,391.11,578.58,112.93,39.53">-â Qi = (w1q, w2q, w3q, â¢ â¢ â¢ wnq) -â Ti = (w1i, w2i, w3i, â¢ â¢ â¢ wni)</formula><p>The TFIDF weighting scheme is adopted as the term weight and the Cosine Similarity Metric is used to evaluate the relevance between tweets and query. The Cosine Similarity Metric is defined as Eq.1.  â¢ BM25 Score (QueryBM25Tweet): The standard Okapi BM25 weighting function is also adopted to measure the content relevance between query Q and tweet T . Okapi BM25 model is a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document, regardless of the inter-relationship between the query terms within a document (e.g., their relative proximity). The similarity of a document D to query Q is defined as Eq.2.</p><formula xml:id="formula_1" coords="2,409.77,671.00,146.15,28.34">Sim = -â Ti â¢ -â Q -â Ti â¢ -â Q (1)</formula><formula xml:id="formula_2" coords="3,163.54,81.73,288.25,183.67">M M N q t ï« ï« 1 1 ( , ) M Q q t ï« ï­ 1 2 ( , ) M Q q t ï« ï­ 1 1 ( , ) M Q M Q N q t ï« ï­ ï« ï­ ... ... ... 1 1 ( , ) M q t ï« 1 2 ( , ) M q t ï« Feature Selection Vectors 1 1 ( , ) M S q t ï« 1 2 ( , ) M S q t ï« 1 1 ( , ) M M N S q t ï« ï« ... 1 1 ( , ) M Q S q t ï« ï­ 1 2 ( , ) M Q S q t ï« ï­ 1 1 ( , ) M Q M Q N S q t ï« ï­ ï« ï­ ... ... Scores 1 1 ( , ) q t 1 2 ( , ) q t 1 1 ( , ) N q t ... 1 ( , ) M q t 2 ( , ) M q t ( , ) M M N q t ... ...</formula><note type="other">Training Set</note><p>Sim =</p><formula xml:id="formula_3" coords="3,105.91,423.43,185.79,24.67">q i âQ IDF (qi)â¢ f (qi, D) â¢ (k1 + 1) f (qi, D) + k1 â¢ (1 -b + b â¢ |D| avgdl )</formula><p>(2) where f (qi, D) is qi's term frequency in the document D, |D| is the length of the document D in words, and avgdl is the average document length in the text collection from which documents are drawn. k1 and b are free parameters.</p><p>â¢ Language Model Score (QueryLMDIRTweet, QueryLMJMTweet, QueryLMABSTweet): We utilize the KL-divergence language model based retrieval method to measure the relevance between query language model Î¸Q and tweet language model Î¸T .</p><p>The smoothing methods we use for language model are: (1) DIR (Bayesian Smoothing with Dirichlet Priors) smoothing, ( <ref type="formula" coords="3,161.69,592.58,3.92,7.86">2</ref>) JM (Jelinek-Mercer method) smoothing and (3) ABS (Absolute Discounting Smoothing).</p><p>LM Socre(T, Q)</p><formula xml:id="formula_4" coords="3,154.78,631.45,138.13,17.80">= wâQ P (w| Î¸Q) â¢ logP (w| Î¸T ) (3)</formula><p>Henceforth, we can generated 5 basic semantic score features in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Semantic Expansion Features</head><p>As microblog retrieval suffers severely from the vocabulary-mismatch problem (i.e.</p><p>term overlap be-tween query and tweet is relatively small), different semantic expansion techniques can be leveraged to improve the retrieval performance. In this section, we introduce several semantic expansion features on basis of query expansion and document expansion.</p><p>To extract features related to query expansion, we first name the origin query offered by TREC'14 OriginQuery. For a certain OriginQuery, we use two strategies to extend it: (1) twitter corpus based query expansion and (2) web-based query expansion. In twitter corpus based query expansion, we first use TREC-API to get the top ranked tweet set. Then, noun and verb terms from the top ranked tweet are recognized as extension terms to generate a new query (i.e. IssueQuery). Then, we generate the MergeQuery by interpolating the OriginQuery and IssueQuery.</p><formula xml:id="formula_5" coords="3,322.52,488.59,233.40,7.86">MergeQuery = Î± â¢ OriginQuery + (1 -Î±) â¢ IssueQuery (4)</formula><p>where Î± is an interpolation parameter and we set it as 0.4 in our system. In web-based query expansion, we submit the query to Google Search Engine API<ref type="foot" coords="3,466.42,524.90,3.65,5.24" target="#foot_2">3</ref> with time limitation (before the query issue time). Noun and verb terms from the returned top 5 tweets are extracted as extension terms to generate a new query (i.e. WebQuery). To conclude, we have four different queries: OriginQuery, IssueQuery, MergeQuery and WebQuery.</p><p>To get a corpus from TREC API, we submit OriginQuery, IssueQuery and MergeQuery to TREC-API to obtain three retrieval result sets. We merge the three candidate result sets and filter the same tweet to generate a corpus for the re-ranking algorithm. We name it OriginCorpus. Regarding to the importance of the URLs in tweet, we collected all the external URLs contained in OriginCorpus and extracted their title information for our document expansion process <ref type="bibr" coords="3,316.81,673.12,9.20,7.86" target="#b4">[4]</ref>. Note that web pages might be deleted as time elapses, we have only crawled a portion of the external URL set. We name the title information corpus TitleCorpus. When adding the title information to the original corpus, we name the newly generated corpus DocExCorpus. After preprocessing, we will have three different corpora: OriginCorpus, TitleCorpus and DocExCorpus. Now, we can generate lots of features via combining different queries, corpora and retrieval models. In our method, 120 features (4 Ã 3 Ã 5 Ã 2) have been generated. Here, 4 stands for query count, 3 stands for corpus count, 5 stands for retrieval model count and 2 stands for whether to use pseudo relevance feedback or not.</p><p>Note that we label the corpus generated by TREC as API api corpus. Besides, we also crawled a local copy of tweets from 1 February,2013 to 31 March,2013 via Tweet API, and name it local corpus. That means we could generate another 120 features on local corpus and we use all of them in our PKUICST3 run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Document Quality Features</head><p>Unlike semantic score features and semantic expansion features which are query-biased, document quality features are tended to estimate the quality of a tweet. Some specific features of social network services (SNS) can be used to measure the quality and potential popularity in the entire social network. Based on the assumption that users prefer those tweets that are related with their query or popular in the social network, we can conclude the following features:</p><p>â¢ Time Difference (TimeDiff ): this feature represents the time difference between the post time of the tweet and the query issue time. A short time difference usually indicates the highly temporal relevance between the tweet and the query.</p><p>â¢ Mention Count (MentionCnt): '@' symbol followed with a user's screen name stands for mentions and replies. A tweet with more '@' means this tweet may attract more persons' attention.</p><p>â¢ Hashtag Count (HashtagCnt): '#' symbol (i.e. hashtag) is used for organizing tweets into a particular topic. A symbol '#' marks the tweet as belonging to a particular topic.</p><p>â¢ Shortened URL Count (URLCnt): the number of shortened URLs may imply the tweet importance since URLs are likely to provide additional information for the origin tweets.</p><p>â¢ Word Count of Tweet (WordCnt): this feature represents the number of terms in a tweet (after stopword removal) and it may suggest the quality of tweets since longer tweet is likely to be more informative.</p><p>â¢ Length of Tweet Text (TweetLen): this feature represents the length of tweet text (after stopword removal) and it may suggest the quality of tweets since longer tweet is likely to be more informative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">TTG TASK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">System Overview</head><p>Our approach for TTG task mainly contains two steps: (1) retrieve adequate relevant documents for each query, and (2) utilize clustering algorithm to eliminate redundant tweets.</p><p>The architecture of our system is shown in Figure <ref type="figure" coords="4,518.40,57.64,3.58,7.86" target="#fig_2">3</ref>. Search results are clustered so that tweets about the same/similar topic are grouped together, and for each cluster only the informative tweets are kept.</p><p>The submitted results for ad hoc search results (i.e. the run labeled as PKUICST3) are used as the input source for our TTG system, and we apply two strategies to choose the relevant tweets for each query. One strategy is to select the top N tweets whose ranking scores are greater than a threshold score, which is determined by preliminary experiments on the training topics. Another strategy is to select the top ranked tweets manually for each query. After selecting the relevant tweets, two clustering algorithms are adopted in our system, one utilizing the star clustering algorithm and the other taking classic hierarchical clustering algorithm. Finally, we choose the most representative tweet from each cluster for each topic as the final result of our TTG system.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Clustering Algorithms</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Star clustering algorithm</head><p>Given a query Q, star clustering algorithm first constructs a pairwise similarity graph on the top N retrieved results based on the Vector Space Model. For each pair of tweets di and dj, their similarity score is computed by using cosine score of their corresponding TF vectors vi and vj, that is</p><formula xml:id="formula_6" coords="4,362.45,556.61,193.47,19.77">sim(di, dj) = cos(vi, vj) = vi â¢ vj |vi| â¢ |vj|<label>(5)</label></formula><p>G = (V, E) is a similarity graph constructed by using a similarity threshold parameter Ï. The top N documents compose vertex collection of G. If the similarity score between di and dj is no less than Ï, there would be a weighted edge connecting them. Star clustering algorithm <ref type="bibr" coords="4,316.81,637.96,9.72,7.86">[7]</ref> based on graph G is then utilized to generate the summarized tweet timeline as described in Algorithm 1. Ï is the threshold parameter to determine whether document di and dj have an edge in graph G. A large Ï enforces that the connected tweets have high similarities, and thus the clusters tend to be small. Each cluster is star-shaped, and we treat the center document as the most representative tweet for the whole cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 star clustering algorithm</head><p>Input: G = (V, E): vertex-weighted undirected graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output:</head><p>Centers of star-shape clusters set S. 1: S = â 2: T = â 3: while T != V do 4:</p><p>v * = nil 5: maxDegree = -1 6:</p><formula xml:id="formula_7" coords="5,57.69,163.12,175.26,28.81">for v â V -T do 7: degree(v) = {v | (v , v) â E} \ T 8:</formula><p>if maxDegree &lt; degree(v) then 9:</p><p>v * = v 10: maxDegree = degree(v) 11:</p><p>end if 12:</p><p>end for 13: S = S âª {v * } 14: T = T âª {v | (v , v * ) â E} 15: end while 16: return S</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Hierarchical clustering algorithm</head><p>Given a query Q, we first get relevant tweet collection from the input source. Here we say a tweet is relevant when its score computed by the learning to rank component is greater than a score threshold Î±, then we apply the agglomerative hierarchical clustering algorithm with parameter Î² which controls the clustering terminal condition to generate the summarized tweet of each cluster. The algorithm is shown in Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 hierarchical clustering algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input:</head><p>Relevant tweet collection R Cluster merging threshold Î² Output:</p><p>Clusters collection C 1: C = {R1, R2, â¢ â¢ â¢ , Rn} 2: repeat 3:</p><p>(Ci, Cj, M inDistance) â GetMinDistancePair(C) 4:</p><p>MergeCluster(Ci, Cj) 5: until (M inDistance &lt; Î²) 6: return C Note that the distance between cluster ci and cj is computed by the following equation:</p><formula xml:id="formula_8" coords="5,68.79,578.55,224.11,15.74">Distance(ci, cj) = 1 -sim( avg dmâc i (dm), avg dnâc j (dn))<label>(6)</label></formula><p>where sim(di, dj) is the cosine similarity score between document di and dj, and avg dmâc i (dm) is the average document in cluster ci which has the whole term and average term frequency. Finally, we choose documents with the highest ranking score in each cluster as the summarized tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RESULT ANALYSIS</head><p>Table <ref type="table" coords="5,88.38,690.26,4.61,7.86" target="#tab_3">1</ref> show the retrieval performance of our submitted four runs for ad hoc search task. The primary evaluation metric for this year's ad hoc search task is MAP (Mean Average Precision). Among all the runs, PKUICST1 uses learning to rank framework and adopts API corpus as candidate and API features as feature space; while PKUICST2 adopts local corpus as candidate and local features as feature space. PKUICST3 uses API corpus as candidate and API features plus local features as feature space. Unlike the previous three runs, PKUICST4 is an unsupervised run, which uses a language modeling framework with pseudo relevance feedback. More specifically, for the query modeling, we first combine IssueQuery and WebQuery with a interpolating coefficient. Then the combined query is further updated with the simple mixture model <ref type="bibr" coords="5,424.22,172.71,9.20,7.86" target="#b8">[8]</ref>. For the document modeling, we use the empirical word distribution on DocExCorpus, and choose Dirichlet smoothing method for model estimation.</p><p>From the table, we can observe that runs using learning to rank framework have a better retrieval performance than that only adopts language model (i.e. PKUICST4). Meanwhile, under learning to rank framework, runs using api corpus features (i.e. PKUICST1 and PKUICST3) perform better than the run just using local corpus features (i.e. PKUICST3) in terms of MAP score. For the TTG task, the primary evaluation metrics are unweighted recall, weighted recall (i.e. recall w ) and precision. The run TTGPKUICST1 applies star clustering method with tuned parameter Ï = 0.7 and N = 200, while TTGP-KUICST3 uses manually selected top N documents for each query. Both TTGPKUICST2 and TTGPKUICST4 apply hierarchical clustering method with distance threshold Î² = 0.3. Besides, the former one adopts score threshold Î± = 4.5 to select relevant tweets while the latter one employs manually selected top ranked N tweets for each query.</p><p>Table <ref type="table" coords="5,350.21,491.51,4.61,7.86" target="#tab_4">2</ref> shows recall (unweighted and weighted), precision, and F1 (unweighted and weighted) scores of different runs. Note that the w superscript indicates the weighted variant of the metric. The weighted version of the metrics attempts to account for the fact that some semantic clusters are (intuitively) more important than others. We can observe from the table that TTGPKUICST1 shows significant superiority in terms of unweighted recall and weighted recall over other runs, while it performs poorly in terms of precision and F1 values. TTGPKUICST2 performs better in precision and F1 values compared with other runs. Besides, TTGPKUICST3 and TTGPKUICST4 have medium and stable performance over all metrics. Both of them adopt manually selected top N parameter for each query.</p><p>Note that we utilize the ten subtopics' ground truth, which are provided by the official organization as our training set, to tune the threshold parameters for star clustering and hierarchical clustering algorithms. In the training set, there's no need to judge which tweet is relevant to the given query; while in the test set, our system has to determine how many retrieved tweets should be regarded as relevant tweets. Thus, the trained parameters may have a certain amount of deviation with optimal parameters for the test set. This may lead to the low precision of our four runs as it is hard for the system to trade off between the recall and precision. Further investigation and experiments are required to solve this issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSION</head><p>In this paper, we present our systems for TREC 2014 Microblog track. In the ad hoc search, we apply a learning to rank framework which utilizes not only the various content relevance of a tweet, but also the quality of a tweet. In the TTG task, we apply some traditional clustering algorithm, i.e. hierarchical and star clustering on the retrieved from hoc search task. Experimental results show the effectiveness of our systems for both tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,105.76,647.78,135.19,7.89"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System Framework</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,213.08,295.32,183.55,7.89"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Learning to Rank Framework</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,355.46,433.56,161.81,7.89"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: TTG System Framework</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,316.81,298.56,239.11,71.00"><head>Table 1 :</head><label>1</label><figDesc>Performance of submitted runs for ad hoc search</figDesc><table coords="5,372.83,317.87,127.06,51.70"><row><cell>Run ID</cell><cell>MAP</cell><cell>P@30</cell></row><row><cell cols="2">PKUICST1 0.5834</cell><cell>0.7242</cell></row><row><cell cols="2">PKUICST2 0.5648</cell><cell>0.7279</cell></row><row><cell cols="3">PKUICST3 0.5863 0.7224</cell></row><row><cell cols="2">PKUICST4 0.5422</cell><cell>0.6958</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,134.95,63.80,339.82,60.54"><head>Table 2 :</head><label>2</label><figDesc>Performance of submitted runs for TTG</figDesc><table coords="6,134.95,70.87,339.82,53.47"><row><cell>Run ID</cell><cell cols="2">Auto/Manual recall</cell><cell cols="3">recall w precision F1</cell><cell>F1 w</cell></row><row><cell cols="2">TTGPKUICST1 Auto</cell><cell cols="3">0.5221 0.7016 0.2682</cell><cell>0.2691</cell><cell>0.3276</cell></row><row><cell cols="2">TTGPKUICST2 Auto</cell><cell>0.3698</cell><cell>0.5840</cell><cell>0.4571</cell><cell>0.3540</cell><cell>0.4575</cell></row><row><cell cols="2">TTGPKUICST3 Manual</cell><cell>0.4849</cell><cell>0.6583</cell><cell>0.3635</cell><cell>0.3496</cell><cell>0.4062</cell></row><row><cell cols="2">TTGPKUICST4 Manual</cell><cell>0.5174</cell><cell>0.6615</cell><cell>0.3664</cell><cell cols="2">0.3579 0.4057</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,58.40,702.22,216.92,7.86;2,53.80,711.19,95.52,7.86"><p>https://github.com/lintool/twitter-tools/wiki/TREC-2013-API-Specifications</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,321.42,711.19,124.08,7.86"><p>https://github.com/shuyo/ldig</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,321.42,711.19,165.58,7.86"><p>http://developers.google.com/web-search</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6.">ACKNOWLEDGMENTS</head><p>The work reported in this paper was supported by the <rs type="funder">National Natural Science Foundation of China</rs> Grant <rs type="grantNumber">61370116</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_6Rt6D6g">
					<idno type="grant-number">61370116</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,58.28,384.06,96.81,10.75" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,400.85,213.07,7.86;6,67.99,411.31,222.00,7.86;6,67.99,421.77,215.82,7.86;6,67.99,432.23,219.69,7.86;6,67.99,442.69,47.81,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,153.39,411.31,136.60,7.86;6,67.99,421.77,55.46,7.86">An empirical study on learning to rank of tweets</title>
		<author>
			<persName coords=""><forename type="first">Yajuan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Long</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heung-Yeung</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,100.79,432.23,33.82,7.86">COLING</title>
		<editor>
			<persName><forename type="first">Chu-Ren</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</editor>
		<imprint>
			<publisher>Tsinghua University Press</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="295" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,454.15,213.07,7.86;6,67.99,464.61,222.00,7.86;6,67.99,475.07,165.58,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,153.39,464.61,136.60,7.86;6,67.99,475.07,55.46,7.86">An empirical study on learning to rank of tweets</title>
		<author>
			<persName coords=""><forename type="first">Yajuan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Long</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heung-Yeung</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,130.47,475.07,73.68,7.86">COLING &apos;10. ACL</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,486.53,211.11,7.86;6,67.99,496.99,198.15,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,149.81,486.53,129.29,7.86;6,67.99,496.99,69.03,7.86">Optimizing search engines using clickthrough data</title>
		<author>
			<persName coords=""><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,155.67,496.99,17.65,7.86">KDD</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,508.45,185.37,7.86;6,67.99,518.91,193.25,7.86;6,67.99,529.37,179.15,7.86;6,67.99,539.83,214.89,7.86;6,67.99,550.29,111.24,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,67.99,518.91,193.25,7.86;6,67.99,529.37,67.95,7.86">Exploiting real-time information retrieval in the microblogosphere</title>
		<author>
			<persName coords=""><forename type="first">Feng</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Runwei</forename><surname>Qiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianwu</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,154.75,529.37,92.39,7.86;6,67.99,539.83,211.07,7.86">Proceedings of the 12th ACM/IEEE-CS joint conference on Digital Libraries</title>
		<meeting>the 12th ACM/IEEE-CS joint conference on Digital Libraries</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="267" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,561.75,220.42,7.86;6,67.99,572.21,224.91,7.86;6,67.99,582.67,146.22,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,106.79,572.21,181.89,7.86">Overview of the TREC-2011 Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Craigand</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,79.49,582.67,106.43,7.86">Proceedings of TREC 2011</title>
		<meeting>TREC 2011</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,594.12,185.37,7.86;6,67.99,604.59,224.92,7.86;6,67.99,615.05,224.48,7.86;6,67.99,625.51,219.66,7.86;6,67.99,635.97,176.61,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,67.99,604.59,224.92,7.86;6,67.99,615.05,32.04,7.86">Exploiting ranking factorization machines for microblog retrieval</title>
		<author>
			<persName coords=""><forename type="first">Runwei</forename><surname>Qiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Feng</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianwu</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,118.15,615.05,174.32,7.86;6,67.99,625.51,219.66,7.86;6,67.99,635.97,48.28,7.86">Proceedings of the 22nd ACM international conference on Conference on information &amp; knowledge management</title>
		<meeting>the 22nd ACM international conference on Conference on information &amp; knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1783" to="1788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,647.42,220.83,7.86;6,67.99,657.89,221.90,7.86;6,67.99,668.35,216.73,7.86;6,67.99,678.81,219.13,7.86;6,67.99,689.27,102.05,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,225.20,647.42,63.62,7.86;6,67.99,657.89,147.08,7.86">Learn from web search logs to organize search results</title>
		<author>
			<persName coords=""><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,233.23,657.89,56.66,7.86;6,67.99,668.35,216.73,7.86;6,67.99,678.81,215.58,7.86">Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 30th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="87" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,700.72,191.06,7.86;6,67.99,711.19,205.70,7.86;6,331.01,148.01,181.74,7.86;6,331.01,158.47,82.29,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,216.30,700.72,42.74,7.86;6,67.99,711.19,205.70,7.86;6,331.01,148.01,81.91,7.86">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,419.54,148.01,89.57,7.86">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
