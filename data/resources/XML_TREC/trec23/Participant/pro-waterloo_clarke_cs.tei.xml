<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,85.04,110.91,425.20,15.12;1,162.40,132.83,270.48,15.12">University of Waterloo at TREC 2014 Contextual Suggestion: Experiments with suggestion clustering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,91.02,171.00,60.64,10.48"><forename type="first">Tan</forename><surname>Luchen</surname></persName>
							<email>luchen.tan@uwaterloo.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Cheriton School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,178.97,171.00,86.97,10.48"><forename type="first">Dean-Hall</forename><surname>Adriel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Cheriton School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,293.26,171.00,82.75,10.48"><forename type="first">Addala</forename><surname>Pragnya</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Cheriton School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,403.32,171.00,59.29,10.48"><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Cheriton School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,472.15,171.00,33.17,10.48;1,115.72,184.94,40.23,10.48"><forename type="first">David</forename><forename type="middle">R</forename><surname>Clarke</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Cheriton School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,85.04,110.91,425.20,15.12;1,162.40,132.83,270.48,15.12">University of Waterloo at TREC 2014 Contextual Suggestion: Experiments with suggestion clustering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">79F163F095A7D9297C9EE72E6B60728C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this work we present our group's first attempt at developing a system to solve the problem presented in the contextual suggestion task. As part of TREC 2014 the contextual suggestion track is running for the third time. The goal of this task is to tailor point-of-interest suggestions to users according to this preferences. Here we present how we gathered candidate points-of-interest, grouped them according to similarity using clustering, and picked points-of-interest that each user would find especially appealing.</p><p>The organizers of this track distributed users' personal profiles in three files: examples2014.csv, profiles2014-70.csv and profiles2014-100.csv. A list of 100 example points-of-interest, which each consist of an ID, a title, a description and a URL were included in examples2014.csv. 299 users indicated their preferences by giving a rating on a 5-point score (0, 1, 2, 3, 4) to the description and website of each example point-of-interest. 116 users, indicated preferences to all the 100 example points of interests, these profiles are distributed in profiles2014-100.csv. The other 183 users, only indicated 70% of all the example points of interest, these profiles are distributed in profiles2014-70.csv. There are 50 contexts which each represent a city in the United States which are listed in contexts2014.txt.</p><p>Each group is permitted to submit up to 2 runs of suggested point of interests in the 50 contexts. Below we describe in detail our approach for building both of our runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Gathering Candidate Suggestions</head><p>Before analysing users' tastes, we gathered a large selection of possible candidate suggestions. We exploited the resources available on the open web to build a large collection of all possible suggestions. Our collection includes both: a pool of suggestions for every context and a corpus of web pages related to the suggestions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Search Engine APIs</head><p>Many commercial search engines such as Yelp<ref type="foot" coords="1,292.76,633.47,3.97,6.12" target="#foot_0">1</ref> , Google Place<ref type="foot" coords="1,363.22,633.47,3.97,6.12" target="#foot_1">2</ref> , Foursquare<ref type="foot" coords="1,423.55,633.47,3.97,6.12" target="#foot_2">3</ref> and TripAdvisor<ref type="foot" coords="1,505.77,633.47,3.97,6.12" target="#foot_3">4</ref> provides friendly APIs for the developers to access their content such as listings, ratings and reviews. We queried these APIs for points-of-interest with contextual information such as the city name, latitude and longitude. This returned point-of-interest results for each context. From the retrieved results, we extracted the name, URL, location, categories, rating, tips and reviews for each point-of-interest. The name and URL are used later to merge point-of-interest data from different API sources. Approximately 120 points-of-interest were retrieved for each context, in total 6000 points-of-interest were extracted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Additional Crawling</head><p>In order to obtain more information on each candidate suggestion, we also crawled the point-ofinterest's website to collect related web pages. The home page of an attraction is expected to contain content that is highly relevant to the attraction. Thus, we parse text content on home web page of website of each candidate suggestion. Moreover, the web pages that home page links to are also expected to be informative. Most of them are within the same website, such as menu, history, introduction, price and contact information of a restaurant. In order to prevent too many pages from being crawled we only crawled pages linked directly from the home page. We also limited our crawl to only the first 50 linked pages (most pages contained less than 50 links), again in order to prevent too many pages from being crawled.</p><p>The corpus of web pages along with info supplied by the API (ratings, reviews, categories, descriptions) were used later to extract features for each candidate suggestion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Extracting Features of Candidate Suggestions</head><p>The features we extracted for each candidate suggestion were term features. We applied established key word extraction methods to the crawled web pages corresponding to each candidate suggestion, and added some category type terms as special tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Key Word Extraction</head><p>Each point-of-interest is associated with a set of web pages consisting of the home page and linked pages. We combined these pages together to form a large document, our candidate suggestion document (CSD). The home page is assigned a higher weight in this combination, since it is more likely to be relevant. To extract key words from this document, we use pointwise K-L divergence <ref type="bibr" coords="2,85.04,420.61,9.96,8.74" target="#b1">[2]</ref>.</p><p>In order to build a background model, we downloaded all English Wikipedia articles<ref type="foot" coords="2,460.07,436.97,3.97,6.12" target="#foot_4">5</ref> . All page content is tokenized and urls are excluded from the page content. The entire token set is treated as a collection that forms our background model.</p><p>We used K-L divergence to rank the tokens by how informative they are. We apply the same method to construct a language model separately from the background Wikipedia articles and each CSD.</p><p>The simple language model is the ratio of the number of times a token appears in source s to the total number of times all tokens appear. L s (t) = f t tâˆˆT f t We computed the divergence between the language model of CSD and the language model of Wikipedia articles. By applying the computation to each single token in CSD, we can rank the tokens based on the divergence score.</p><formula xml:id="formula_0" coords="2,244.28,635.29,106.72,23.23">L CSD (t) * log( L CSD (t) L W iki (t) )</formula><p>L CSD (t) is the language model of term t in the candidate suggestion document and L W iki (t) is the language model of term t in all the Wikipedia articles. We take the top-100 tokens from this ranking to form a set of features for each candidate suggestion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Building a Feature Vector</head><p>Our feature vector can be divided into two types of features: plain token features and category features. Top 100 K-L divergence ranked terms fulfill the plain token part of our feature vector.</p><p>The other group of important features are category data. We gathered category data from those search engine APIs, and here we use it as features. Since our features are all token features, however, we want to differ category features apart from normal token features. A prefix CAT is added to category token, which makes it a new and unique token. There can be multiple category terms from the APIs, and each term in this set is included as a category feature into our feature vector. Algorithm 1 describes our Hierarchical K-Means clustering. Here we recursively cluster, if the size of any sub layer cluster is greater than our threshold, we use K-Means clustering to separate it into multiple sub clusters. Also, to prevent infinitely deep clusters we limit the hight of the hierarchical clusters to 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Clustering Candidate Suggestions</head><p>Clusters are represented in numbers, such as cluster 3 and cluster 5, cluster names include their parent clusters which are separated with dots (.). If a cluster is divided into several sub clusters, we add a dot after the parent cluster's number, then output the child cluster's number. For example, cluster 7 can be divided into sub clusters: 7.1, 7.2 and 7.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Matching and Ranking Suggestions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">User Like and Dislike</head><p>Each user indicated their preference with a rating from 0 to 4 for both the description and website of each example point-of-interest. In our model, if the user assigned a score of 3 or 4 to the website, it means that the user like this suggestion. Otherwise, if the user assigned a score of 0 or 1 to the corresponding website, it means that the user dislike this suggestion. Based on this metric, since all example point-of-interests are clustered by our hierarchical K-means clustering method, we can construct a list of liked clusters and a list of disliked clusters.</p><p>A liked cluster means that there is at least one liked point of interest contained in the cluster, disliked clustered are calculated in a similar fashion. In the two liked and disliked cluster lists, we maintained both the cluster name and the number of example point of interests in the cluster. Note that since our clustering result is hierarchical, each suggestion's cluster result is the deepest cluster name in the hierarchical structure, such as 12.1.3.5. Thus, we also count its existence in parental clusters, such that a suggestion located in 12.1.3.5 is also counted in 12.1.3, 12.1 and 12. An example of user's liked cluster list is shown in Listing 1. c l u s t e r name : number o f l i k e d p o i n t o f i n t e r e s t s . . . c l u s t e r 7 . 1 0 : 2 c l u s t e r 1 6 . 7 . 7 . 4 . 8 . 5 : 1 4 . . . c l u s t e r 9 . 1 4 : 1 c l u s t e r 1 6 . 9 : 17 c l u s t e r 1 4 . 1 4 . 1 : 4 . . . Listing 1: UserID 700 's liked cluster counting</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Low quality profiles</head><p>Since the users are crowdsourcing contributors, some of the profiles have poor quality. Some users were not careful when selecting rating scores for the given example point of interests. Therefore, none or little opinion information can be extracted from these profiles. In order to handle these users, we simply looked for the users that assigned the same score for every suggestion. For example, we found that UserID 933 assigned score 2 to every description and website. For this user, we selected the top rated candidate suggestions from each context as our suggestions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Selecting Candidates</head><p>To suggest a point of interests for each user based on each context, cluster names are grouped by context. For each context, we have a list of clusters and number of suggestions that are assigned to each cluster in this context. All the search engine APIs we used provide rating scores for each suggestion, although with different scales. We normalize the rating scores and compute an average rating for each suggestion. Within a cluster, suggestions are ranked by their average rating. For this task we needed to provide 50 suggestions for each context. When selecting candidate suggestions, we started from the top of ranked clusters, and then choose one candidate from the top cluster. We then proceeded one by one to the bottom of the ranked cluster list. To achieve diversity, we only select suggestions from the clusters that had not been previously selected. If there are not enough suggestions when we reach the last ranked cluster, we start from the top ranked cluster again, until enough suggestions are selected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Ranking Candidate Clusters</head><p>The clusters in each context are ranked for each user. We assign a score for each cluster, which is ratio of the number of likes the user have in this cluster to the number of candidate suggestions in this cluster. #like user #candidate suggestion In order to generate descriptions for the suggested points-of-interest we took either a short description or short review from the data returned by the APIs. A category was appended to the front of this description in order to quickly give users an idea of what the point-of-interest was when the name and rest of description were unclear.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Runs and Results</head><p>The two runs we submitted were waterlooA and waterlooB. waterlooA used only positive preferences (see section 5.2.1), waterlooB incorporated both positive and negative preferences (see section 5.2.3). The evaluation metric used for the contextual suggestion task are P@5, MRR, and TBG which are described in last year's overview paper for this track <ref type="bibr" coords="5,387.59,620.48,9.96,8.74" target="#b0">[1]</ref>.</p><p>As can be seen in table 1 using both positive and negative preferences outperformed using only positive preferences. This is similarly reflected in table 2. Additionally from table 2 we can see that for P@5 baselineB got the highest P@5 score given across all runs for approximately 14% ( 41 299 ) of the context-profile pairs. 82% ( 244 299 ) of our submitted profile-context pairs got a median or better P@5 score compared to all runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>In this work we had described our system which makes personalized point-of-interest suggestions to users as part of the contextual suggestion track framework. We have seen a method for clustering Run P@5 MRR TBG waterlooA 0.4167 0.6021 1.7364 waterlooB 0.4308 0.6244 1.8379 attractions and determining which clusters of attractions users prefer to have attractions selected from. We have also seen that using both positive and negative preferences from users outperforms using only positive user preferences. Additionally we have seen that we are able to score best among all the runs for about 14% of the profile-context pairs using the techniques described here.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,85.04,248.47,425.20,261.61"><head></head><label></label><figDesc>Both candidate suggestions and example suggestions are extracted by our feature extraction method. Given the feature vectors of each candidate suggestion and example suggestion (more than six thousand item feature vectors), we applied a form of top-down Hierarchical K-Means Clustering. The Sofia-KMeans package 6 is used for our Hierarchical K-Means clustering.</figDesc><table coords="3,99.98,307.94,290.62,202.14"><row><cell>Input: Array of Cluster Cluster, Integer Layers</cell></row><row><cell>Output: Array of Clusters H Cluster</cell></row><row><cell>if Layers &gt;5 then</cell></row><row><cell>return null;</cell></row><row><cell>end</cell></row><row><cell>for every cluster c in Cluster do</cell></row><row><cell>if size of c &gt;threshold then</cell></row><row><cell>T = HKM Cluster(c, Layers+1);</cell></row><row><cell>if T = null then</cell></row><row><cell>insert T into H Cluster;</cell></row><row><cell>end</cell></row><row><cell>else</cell></row><row><cell>insert c into H Cluster;</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>return H Cluster;</cell></row><row><cell>Algorithm 1: HKM Cluster(Data, Layers)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,168.50,128.90,258.27,75.45"><head>Table 1 :</head><label>1</label><figDesc>P@5, MRR, and TBG scores for both of our runs.</figDesc><table coords="6,174.10,154.75,247.07,49.61"><row><cell>Run</cell><cell>Best</cell><cell></cell><cell cols="3">Median or better</cell></row><row><cell cols="6">P@5 MRR TBG P@5 MRR TBG</cell></row><row><cell>waterlooA 32</cell><cell>147</cell><cell>36</cell><cell>239</cell><cell>233</cell><cell>190</cell></row><row><cell>waterlooB 41</cell><cell>152</cell><cell>39</cell><cell>244</cell><cell>239</cell><cell>208</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,85.04,220.15,425.20,20.69"><head>Table 2 :</head><label>2</label><figDesc>Number of profile-context pairs (out of a total of 299) where our runs scored best (or median or better) among all runs.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,100.28,737.07,122.37,6.99"><p>http://www.yelp.com/developers</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,100.28,746.57,137.76,6.99"><p>https://developers.google.com/places</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="1,100.28,756.08,127.61,6.99"><p>https://developer.foursquare.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="1,100.28,765.58,153.72,6.99"><p>https://developer-tripadvisor.com/home/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="2,100.28,712.62,136.96,6.99"><p>http://dumps.wikimedia.org/enwiki/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="3,100.28,765.58,203.60,6.99"><p>https://code.google.com/p/sofia-ml/wiki/SofiaKMeans</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Since we queried the search engine APIs only based on context information and did not filter any results, the candidate suggestions may contain many chains or uninteresting places. When designing our system we made an effort to only make interesting suggestions to users and not suggest, for example, chain stores which are almost the same all over the world. Thus, we first find the candidate suggestions that exist in more than two contexts and add them to our potentially blacklisted set. Then we manually select items from this list, in order to produce our final blacklist. Listing 2 shows part of our blacklist URLs, that we do not wish to suggest to users.  In the second run we submit, we add dislike filtering to the candidate selection process. When we rank the clusters in each context for each user, the score assigned to each cluster becomes ratio of the number of liked example suggestions deducted by the number of disliked example suggestions in this cluster, to the number of candidate suggestions in this cluster. The score is limited by users' like and dislike preferences. #like user -#dislike user #candidate suggestion</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="6,100.54,365.08,409.70,8.74;6,100.54,377.03,409.70,8.74;6,100.54,388.99,188.23,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,148.48,377.03,249.23,8.74">Overview of the TREC 2013 contextual suggestion track</title>
		<author>
			<persName coords=""><forename type="first">Adriel</forename><surname>Dean-Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaap</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicole</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><surname>Simone</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,420.94,377.03,89.30,8.74;6,100.54,388.99,46.15,8.74">22nd Text REtrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,100.54,408.91,409.70,8.74;6,100.54,420.87,409.70,8.74;6,100.54,432.82,409.70,8.74;6,100.54,444.78,133.38,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,278.53,408.91,227.45,8.74">A language model approach to keyphrase extraction</title>
		<author>
			<persName coords=""><forename type="first">Takashi</forename><surname>Tomokiyo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><surname>Hurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,113.87,420.87,396.37,8.74;6,100.54,432.82,63.17,8.74;6,225.24,432.82,40.72,8.74">Proceedings of the ACL 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment</title>
		<meeting>the ACL 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
	<note>MWE &apos;03</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
