<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,69.50,57.64,473.04,16.65;1,168.98,78.30,273.98,16.65">QCRI at TREC 2014: Applying the KISS principle for the TTG task in the Microblog Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,99.50,124.48,68.39,11.10"><forename type="first">Walid</forename><surname>Magdy</surname></persName>
							<email>wmagdy@qf.org.qa</email>
							<affiliation key="aff0">
								<orgName type="department">Computing Research Institute Qatar Foundation Doha</orgName>
								<address>
									<country>Qatar, Qatar</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.73,124.48,46.14,11.10"><forename type="first">Wei</forename><surname>Gao</surname></persName>
							<email>wgao@qf.org.qa</email>
							<affiliation key="aff1">
								<orgName type="department">Computing Research Institute Qatar Foundation Doha</orgName>
								<address>
									<country>Qatar, Qatar</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,431.35,124.48,85.32,11.10"><forename type="first">Tarek</forename><surname>Elganainy</surname></persName>
							<email>telganainy@qf.org.qa</email>
							<affiliation key="aff2">
								<orgName type="department">Computing Research Institute Qatar Foundation Doha</orgName>
								<address>
									<country>Qatar, Qatar</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,268.97,202.84,69.85,11.10"><forename type="first">Zhongyu</forename><surname>Wei</surname></persName>
							<email>zywei@se.cuhk.edu.hk</email>
							<affiliation key="aff3">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<settlement>Kong Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,69.50,57.64,473.04,16.65;1,168.98,78.30,273.98,16.65">QCRI at TREC 2014: Applying the KISS principle for the TTG task in the Microblog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">901D53D0AA9A0165DD67DDE5100D4B5F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we present our work on the ad-hoc search and the tweet timeline generation (TTG) tasks of TREC-2014 Microblog track. Regarding the ad-hoc search task, we used our best developed system over the last year, which include hyperlinkbased query expansion and re-ranking models fusion. For the new tweet timeline generation task, we applied a straightforward and simple approach, which depends on clustering retrieval results based on Jaccard similarities between tweets. Our best adhoc results achieved the fifth rank and seventh rank among 21 participating groups when evaluated using P@30 and MAP respectively. However, our best TTG run achieved the second rank among participants, which shows that our simple TTG approach was more effective than most of the used TTG systems in TREC.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>We describe the participation of Qatar Computing Research Institute (QCRI) group in the TREC-2014 Microblog track. This year the track included two tasks; the ad-hoc search task, and the newly introduced tweets timeline generation (TTG) task. We applied what we have learned from our participation in the track in the past three years in the ad-hoc task, which include hyperlinkbased query expansion methods <ref type="bibr" coords="1,180.25,536.56,9.94,8.10">[ 4,</ref><ref type="bibr" coords="1,194.78,536.56,12.03,8.10" target="#b13">13]</ref> and the selection and fusion of multiple re-ranking models <ref type="bibr" coords="1,196.05,548.11,9.89,8.10">[ 4,</ref><ref type="bibr" coords="1,209.69,548.11,6.54,8.10" target="#b5">5]</ref>. We configured our retrieval system according to the best results achieved when tested on the topics of 2013 <ref type="bibr" coords="1,139.34,569.95,9.93,8.10">[ 4,</ref><ref type="bibr" coords="1,152.90,569.95,6.81,8.10" target="#b5">5,</ref><ref type="bibr" coords="1,163.34,569.95,10.69,8.10" target="#b13">13]</ref>, since it is the same collection used this year but with new topics set.</p><p>We submitted four runs for the ad-hoc task while enabling and disabling hyperlink-based pseudo relevance feedback (HPRF) and reranking. The run which applied both HPRF and reranking was then used in the TTG task by clustering the results according to similarity.</p><p>For the TTG task, since it is running for the first year, we decided to keep it simple and straightforward (KISS) by using a simple implementation of Jaccard similarity to measure the distance between tweets in the top N retrieved results and cluster those of high similarity together. Four runs was submitted for the TTG task by using different values for N, and applying two different formulas for calculating the similarity between tweets.</p><p>Although our best ad-hoc run achieved the seventh rank among participants, but when this run was applied to our TTG system, our best TTG system achieved the second rank. This shows the effectiveness of our simple TTG approach that outperformed most the systems of the other groups that used better lists of retrieved results.</p><p>Details and results of our runs are described below. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">AD-HOC SEARCH TASK</head><p>Figure <ref type="figure" coords="2,81.50,203.27,4.50,8.10" target="#fig_0">1</ref> presents the full architecture of our microblog ad-hoc retrieval system.</p><p>Overall, we designed our pipeline to combine query expansion and result re-ranking. For query expansion, we made use of the external documents linked by the URLs in the initial search results for query expansion. For result re-ranking, our system resorted to learning to rank by extensive engineering work for re-ranking search results given by combining the ranked lists of different rankers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Hyperlink-based Pseudo Relevance Feedback (HPRF)</head><p>A hyperlink in a tweet is more than a link to related content as in webpages, but actually it is considered a link to the main focus of the tweet. In fact, sometimes tweet"s text itself is totally irrelevant, and the main content lies in the embedded hyperlink, e.g."This is really amazing, you have to check htwins.net/scale2".</p><p>Analyzing the TREC microblog dataset over the past three years, we found more than 70% of relevant tweets contain hyperlinks. This motivates utilizing the hyperlinked documents content in an efficient way for query expansion.</p><p>The content of hyperlinked documents in the initial set of top retrieved tweets is extracted and integrated into the PRF process. Titles of hyperlinked pages usually act like heading of the document"scontent,whichcanenrichthevocabularyin the PRF process.</p><p>We apply hyperlinked documents content extraction on two different levels:</p><p>-Tweets level (PRF): which represents the traditional PRF, where terms are extracted from the initial set of retrieved tweets while neglecting embedded hyperlinks.</p><p>-Hyperlinked document titles level (HPRF): where the page titles of the hyperlinked documents in feedback tweets are extracted and integrated to tweets for term extraction in the PRF process.</p><p>Titles and meta-description of hyperlinked documents may include unneeded text. For example, titles usually contain delimiterslike"-"or "|"before/after page domainname,e.g.,"...| CNN.com" and "... -YouTube". We clean these fields through the following steps <ref type="bibr" coords="2,124.82,646.39,9.81,8.10">[ 4,</ref><ref type="bibr" coords="2,136.82,646.39,6.71,8.10" target="#b5">5]</ref>:</p><formula xml:id="formula_0" coords="2,72.02,663.58,4.14,8.18"></formula><p>Split page titles on delimiters and discard the shorter substring, which is assumed to be the domain name.  Detecterrorpagetitles,suchas"404,pagenotfound!" and consider them broken hyperlinks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>Remove special characters, URLs, and snippet of HTML/JavaScript/CSS codes. This process helps in discarding terms that are potentially harmful if used in query expansion.</p><p>TFIDF <ref type="bibr" coords="2,346.51,238.46,10.56,8.10" target="#b8">[ 8]</ref> and Okapi <ref type="bibr" coords="2,402.67,238.46,15.00,8.10" target="#b12">[ 12]</ref> weighting were used for ranking the top terms were used for query expansion. We calculate TFIDF for a term x as follows:</p><formula xml:id="formula_1" coords="2,346.39,281.05,214.70,15.48">( ) ( ) ( ) ( ) ( )<label>(1)</label></formula><p>where ( ) is the term frequency of term x in the top n d initially retrieved tweet documents used in the PRF process;</p><p>( ) is the term frequency of term x in the titles of hyperlinks in the top n d tweets; and</p><p>( ) is the term frequency of term x in the metadescription of hyperlinks in the top n d tweets. and are binary functions that equal to 0 or 1 according to the content level of hyperlinked documents used in the expansion process. df(x) is document frequency of term x in the collection; and N is the total number of documents in the collection. and free parameters of the Okapi weighting were selected as 2 and 0 respectively. The parameter b was set to 0 since the variation in tweets length is limited due to Twitter constraint on the number of characters used (max. 140 characters).</p><p>Terms extracted from the top n d initially retrieved documents are ranked according to equation 1, and top n t terms with the highest TFIDF are used to formulate for the expansion process. Weighted geometrical mean is used to calculate the final score of retrieval for a given query according to equation 2:</p><formula xml:id="formula_2" coords="2,361.75,522.27,201.50,9.48">( | ) √ ( | ) ( | )<label>(2)</label></formula><p>where is the original query; is the set of extracted expansion terms; ( | ) is the probability of query to be relevant to document d; and α is the weight given to expansion terms compared to original query (when α =0, no expansion is applied). Language-model-based retrieval model was used to calculate the probability of relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Tweets Re-ranking</head><p>Similar to our idea in TREC2013 <ref type="bibr" coords="2,459.53,631.15,9.68,8.10">[ 4]</ref>, we also explored to ensemble multiple ranking models for re-ranking the retrieved tweets. Our models were learned using Tweets2011-13 qrels and tested with Tweets2014 queries. We employed six learning to rank algorithms as the candidate rankers for search result fusion: RankNet <ref type="bibr" coords="2,352.60,684.07,9.57,8.10" target="#b2">[ 2]</ref>, RankBoost <ref type="bibr" coords="2,410.80,684.07,9.57,8.10" target="#b6">[ 6]</ref>, Coordinate Ascent <ref type="bibr" coords="2,496.57,684.07,13.86,8.10" target="#b10">[ 10]</ref>, MART <ref type="bibr" coords="2,545.24,684.07,9.68,8.10" target="#b7">[ 7]</ref>, LambdaMART <ref type="bibr" coords="2,379.75,695.59,15.12,8.10" target="#b14">[ 14]</ref> and RandomForests <ref type="bibr" coords="2,483.62,695.59,10.63,8.10" target="#b1">[ 1]</ref> using RankLib  <ref type="formula" coords="3,260.83,97.43,3.26,8.10" target="#formula_2">2</ref>); (4) A RankNet model was learned in the same way as (2); (5) Two Coordinate Ascent models were learned in the same way as (2) but one of them optimized MAP and the other optimized P@30; (6) Two LambdaMART models were learned in the same way as <ref type="bibr" coords="3,54.00,149.15,9.60,8.10" target="#b5">(5)</ref>. Different from the configurations of last year, we did not use query selection methods to construct validation set since this strategy did not bring much effectiveness to our system of TREC2013 <ref type="bibr" coords="3,97.58,181.07,9.54,8.10">[ 4]</ref>. However, we used exactly the same feature list as last year which were shown useful (see <ref type="bibr" coords="3,197.18,192.59,10.59,8.10">[ 4]</ref> for detail).</p><p>Last year, we simply summated relevance scores of all learningto-rank models for tweets re-ranking. Instead of that, we tried to combine the ranking scores of candidate rankers by weighted Condorcet-fuse this year. Condorcet-fuse is one of the state-ofthe-art fusion methods in metasearch due to its effectiveness <ref type="bibr" coords="3,276.89,251.54,13.78,8.10" target="#b11">[ 11]</ref>. The basic idea is that tweets that can beat more tweets in a pairwise manner based on scores they received from candidate rankers should be ranked higher. Taking ranked lists generated by candidate rankers as input, we produced a Condorcet graph and output the final ranked list by computing the Hamiltonian path of that graph.</p><p>The workflow of generating Condorcet graph is demonstrated in Figure <ref type="figure" coords="3,80.42,340.58,3.41,8.10" target="#fig_1">2</ref>. Given four candidate rankers and three tweets, we have relevance scores for tweets assigned by rankers which form a ranker-tweets matrix shown in the first frame. (r i , t j ) stands for the relevance score given by candidate ranker r i to tweet t j . We then derive the tweet-tweet relation matrix to reveal the pair-wise preference. For a pair of tweets (t j , t k ), we compute their relation score by counting the number of rankers giving higher score to t j than t k . And thirdly, we generate the Condorcet graph. For a pair of tweets t j and t k , there exists an edge from t j to t k if the value of (t j , t k ) in tweet-tweet relation matrix is higher than or equal to 0. For the tweets that tie, there is an edge pointing in each direction. A Hamiltonian traversal of this graph will produce the final ranked list. The detail of the algorithm can be found in <ref type="bibr" coords="3,252.89,465.64,13.78,8.10" target="#b11">[ 11]</ref>.</p><p>To reflect the different importance of candidate rankers, we implemented a weighted version of Condorcet-fuse. In this case, t j wins t k if the sum of the weights of those rankers that rank t j higher than t k is larger than the sum of the weights of those that prefer t k to t j . We used the mean average precision (MAP) obtained by individual candidate ranker on Tweets2011-2013 dataset as the weight of the corresponding ranking model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Submitted Runs &amp; Results</head><p>We had four submitted runs to the ad-hoc search task this year, as follows:</p><p>-PRF1030: Applied standard pseudo-relevance feedback with number of documents in feedback = 10, and number of terms in the feedback process = 30. Selection of values is based on our study to different values of feedback documents and terms in <ref type="bibr" coords="3,103.46,643.51,9.62,8.10" target="#b5">[ 5]</ref>.</p><p>-HPRF1020: Applied Hyperlink-based PRF with number of document and terms used in feedback = 10 and 20 respectively.</p><p>1 http://sourceforge.net/p/lemur/wiki/RankLib/ -PRF1030RR: PRF1030 run after applying reranking -HPRF1020RR: HPRF1020 run after applying reranking Results achieved by our runs are presented in Table <ref type="table" coords="3,506.26,204.23,3.41,8.10" target="#tab_0">1</ref>.</p><p>Results shows that HPRF led to slight improvement over just using PRF on both MAP and P@30. This improvement was found insignificant, which does not align with results reported on TREC-2013 dataset <ref type="bibr" coords="3,365.89,252.50,9.67,8.10" target="#b5">[ 5]</ref>. However, reranking led to noticable improvemet to P@30, with slight improvement to MAP. Our best achieved scores are highlighted in Table <ref type="table" coords="3,431.23,273.50,3.41,8.10" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">TWEETS TIMELINE GENERATION TASK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Approach</head><p>Our expectation was that HPRF1020RR would achieve the best result; this is why we used this run for the TTG task.</p><p>For generating the timeline of tweets, we applied the following:</p><p>1. Top ranked N tweets were normalized by removing name mentions, hashtags, urls, emoticons, and stopwords. 2. Porterstemmerwasappliedtotweets"text 3. Similarity was calculated among top N tweets in the results list. 4. 1NN clustering approach was applied to merge any tweets with close distance into the same cluster. Distance between two tweets was calculated as follow:</p><formula xml:id="formula_3" coords="3,367.99,469.35,174.76,9.00">( ) ( ( ) ( ))</formula><p>where ( ) is the normalized version of the tweet after applying step 1 and 2.</p><p>We applied two implementations to the similarity, which are a modification to the Jaccard similarity coefficient as follows:</p><formula xml:id="formula_4" coords="3,421.15,550.14,84.89,50.28">( ) | | (| | | |) ( ) | | (| | | |)</formula><p>calculates the similarity between the text of two tweets as the number of common terms divided by the length of the longest tweet. This leads to merging two tweets in the same cluster if most of the terms in the long tweet existed in the short tweet, and the difference in the length between both tweets is not large.</p><p>leads to severe merging, since it focus on how many of the terms of the short tweet exist in the long tweet without regard to the difference in length. In the extreme case, if a tweet contains only one word that exists in the long tweet, would equal to 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Submitted Runs &amp; Results</head><p>We had four submitted runs to the ad-hoc search task this year, as follows:</p><p>-EM50: Top 50 retrieved results from the HPRF1020RR run were clustered using as the distance function. A similarity of at least 0.6 was required to any of the tweets in a cluster to get the tweet merged to the cluster.</p><p>-EM100: similar to EM50, but top 100 retrieved results were used instead.</p><p>-SM50: similar to EM50, but was used instead.</p><p>-SM100: similar to EM100, but was used instead.</p><p>For all runs, the earliest tweet in each cluster is used to represent the cluster in the submitted run.</p><p>Results of our TTG runs are shown in Table <ref type="table" coords="4,238.85,373.70,3.35,8.10" target="#tab_1">2</ref>. The second similarity formula led to merging most of the tweets into a small number of clusters. This led to low recall but higher precision as compared to using . However, the overall F1 score was much lower than using . EM100 achieved a better unweighted F1 measure, while EM50 achieved a better weighted F1 measure, which according to the scatter plot of all submitted runs, achieved the 4 th rank among 48 runs. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,381.55,572.23,117.94,8.10"><head>Figure 1</head><label>1</label><figDesc>Figure 1 Ad-hoc search system</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,202.97,150.23,207.27,8.10;2,143.04,59.52,326.52,84.36"><head>Figure 2</head><label>2</label><figDesc>Figure 2 Demonstration for Condorcet-fuse algorithm</figDesc><graphic coords="2,143.04,59.52,326.52,84.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,328.85,55.65,218.06,85.88"><head>Table 1 QCRI results in TREC 2014 Microblog track for the ad-hoc search task</head><label>1</label><figDesc></figDesc><table coords="3,361.15,82.19,147.78,59.34"><row><cell>Run</cell><cell>MAP</cell><cell>P@30</cell></row><row><cell>PRF1030</cell><cell>0.4941</cell><cell>0.6679</cell></row><row><cell>HPRF1020</cell><cell>0.5075</cell><cell>0.6685</cell></row><row><cell>PRF1030RR</cell><cell>0.4998</cell><cell>0.6988</cell></row><row><cell>HPRF1020RR</cell><cell>0.5122</cell><cell>0.6982</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,57.72,70.91,232.33,85.86"><head>Table 2 QCRI results in TREC 2014 Microblog track for the TTG task</head><label>2</label><figDesc></figDesc><table coords="4,62.28,97.43,221.84,59.34"><row><cell>Run</cell><cell>P</cell><cell>R uw</cell><cell>R w</cell><cell>F1 uw</cell><cell>F1 w</cell></row><row><cell>EM50</cell><cell>0.4150</cell><cell>0.2867</cell><cell>0.4779</cell><cell>0.3391</cell><cell>0.4442</cell></row><row><cell>EM100</cell><cell>0.3301</cell><cell>0.3797</cell><cell>0.5650</cell><cell>0.3532</cell><cell>0.4167</cell></row><row><cell>SM50</cell><cell>0.4798</cell><cell>0.1688</cell><cell>0.3221</cell><cell>0.2497</cell><cell>0.3854</cell></row><row><cell>SM100</cell><cell>0.3881</cell><cell>0.2057</cell><cell>0.3416</cell><cell>0.2689</cell><cell>0.3634</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,322.43,56.84,92.28,10.80" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,321.34,69.81,236.85,8.10;4,335.93,80.15,20.35,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,382.78,69.81,56.33,8.10">Random forests</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,445.51,69.81,63.80,8.10">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,321.34,90.47,236.45,8.10;4,335.93,100.91,222.00,8.10;4,335.93,111.23,75.59,8.10" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="4,442.87,100.91,115.07,8.10;4,335.93,111.23,25.57,8.10">Learning to rank using gradient descent</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Renshaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lazier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Deeds</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hullender</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,321.34,121.55,236.71,8.10;4,335.93,131.87,171.86,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,447.44,121.55,110.60,8.10;4,335.93,131.87,121.37,8.10">Web-based Pseudo Relevance Feedback for Microblog Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">S</forename><surname>El-Din</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Magdy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,463.27,131.87,22.07,8.10">TREC</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,321.34,142.31,236.40,8.10;4,335.93,152.63,153.64,8.10" xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>El-Ganainy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Magdy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<idno>QCRI at TREC 2013 Microblog Track. TREC 2013</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,321.34,162.95,236.64,8.10;4,335.93,173.27,221.91,8.10;4,335.93,183.71,131.87,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,518.30,162.95,39.68,8.10;4,335.93,173.27,221.91,8.10;4,335.93,183.71,71.86,8.10">Hyperlink-Extended Pseudo Relevance Feedback for Improved Microblog Retrieval</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>El-Ganainy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Magdy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rafea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,413.71,183.71,31.51,8.10">SoMeRA</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,321.34,194.03,236.61,8.10;4,335.93,204.35,221.82,8.10;4,335.93,214.67,209.73,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,547.08,194.03,10.86,8.10;4,335.93,204.35,218.20,8.10">An efficient boosting algorithm for combining preferences</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,335.93,214.67,140.29,8.10">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="933" to="969" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,321.34,225.11,236.61,8.10;4,335.93,235.46,222.24,8.10;4,335.93,245.78,20.38,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,398.26,225.11,159.68,8.10;4,335.93,235.46,64.36,8.10">Greedy function approximation: a gradient boosting machine</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,409.27,235.46,73.03,8.10">Annals of Statistics</title>
		<imprint>
			<biblScope unit="page" from="1189" to="1232" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,321.34,256.10,236.45,8.10;4,335.93,266.54,222.23,8.10;4,335.93,276.86,33.80,8.10" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="4,380.99,256.10,176.80,8.10;4,335.93,266.54,91.58,8.10">A statistical interpretation of term specificity and its application in retrieval</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,433.27,266.54,93.43,8.10">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,321.34,287.18,236.55,8.10;4,335.93,297.50,64.84,8.10" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="4,414.54,287.18,143.35,8.10;4,335.93,297.50,16.77,8.10">Overview of the TREC2013 microblog track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,358.39,297.50,22.07,8.10">TREC</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,325.51,307.94,232.54,8.10;4,335.93,318.26,222.25,8.10;4,335.93,328.58,20.35,8.10" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="4,441.64,307.94,116.40,8.10;4,335.93,318.26,74.68,8.10">Linear feature-based models for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,417.31,318.26,78.19,8.10">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="257" to="274" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,325.51,338.90,232.43,8.10;4,335.93,349.34,116.39,8.10" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="4,474.50,338.90,83.44,8.10;4,335.93,349.34,65.65,8.10">Condorcet fusion for improved retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montague</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,407.09,349.34,22.50,8.10">CIKM</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,325.51,359.66,232.66,8.10;4,335.93,369.98,112.55,8.10" xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<idno>TREC-7. TREC 1998</idno>
		<imprint/>
	</monogr>
	<note type="report_type">Okapi at</note>
</biblStruct>

<biblStruct coords="4,325.51,380.30,232.63,8.10;4,335.93,390.76,221.88,8.10;4,335.93,401.08,96.59,8.10" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>El-Ganainy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Magdy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K-F</forename><surname>Wong</surname></persName>
		</author>
		<title level="m" coord="4,335.93,390.76,221.88,8.10;4,335.93,401.08,36.23,8.10">Ranking Model Selection and Fusion for Effective Microblog</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,325.51,411.40,232.34,8.10;4,335.93,421.72,222.21,8.10;4,335.93,432.04,115.78,8.10" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="4,524.34,411.40,33.52,8.10;4,335.93,421.72,169.04,8.10">Adapting boosting for information retrieval measures</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">M</forename><surname>Svore</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,515.02,421.72,43.12,8.10;4,335.93,432.04,31.74,8.10">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="254" to="270" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
