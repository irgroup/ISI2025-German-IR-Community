<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,76.21,70.99,445.13,12.64;1,139.82,86.93,317.89,12.64">Simple May Be Best -A Simple and Effective Method for Federated Web Search via Search Engine Impact Factor Estimation</title>
				<funder ref="#_jWBzaww">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_UfEMhzH">
					<orgName type="full">Shanghai Collaborative Innovation Center of Trustworthy Software for Internet of Things</orgName>
				</funder>
				<funder ref="#_mhunWaY">
					<orgName type="full">Science and Technology Commission of Shanghai Municipality</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,247.24,115.69,43.11,10.53"><forename type="first">Shan</forename><surname>Jin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Shanghai Key Laboratory of Multidimensional Information Processing Department of Computer Science and Technology</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<postCode>200241</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,298.07,115.69,47.50,10.53;1,345.57,113.99,1.41,7.44"><forename type="first">Man</forename><surname>Lan</surname></persName>
							<email>mlan@cs.ecnu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Shanghai Key Laboratory of Multidimensional Information Processing Department of Computer Science and Technology</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<postCode>200241</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,76.21,70.99,445.13,12.64;1,139.82,86.93,317.89,12.64">Simple May Be Best -A Simple and Effective Method for Federated Web Search via Search Engine Impact Factor Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C6B0E854ECDE0EB8C42D2640367C0659</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports our participation in the three tasks, i.e., vertical selection (VS), resource selection (RS) and results merging (RM) in TREC 2014 Federated Web Search track. In consideration of the connections between vertical and search engine (i.e., a vertical could contain multiple resources), we address the two tasks in an iterative way. Existing algorithms adopted relevance measures to calculate the semantic relatedness between query and resources or returned results. However they neglected the influence of search engine in itself. In this work, we propose a Search engine Impact Factor (SEIF) estimation approach to improve the performance of vertical and resource selection. The officially released results showed that our systems ranked 1st in RS task and 2nd in VS task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the explosive development of Internet, a huge number of rich information resources and thousands of search engines have emerged. Web search is the most popular way for people to find information on the web. Federated Web search is a kind of information retrieval, which allows the simultaneous search of multiple disparate content sources with one query <ref type="bibr" coords="1,175.06,633.41,92.63,9.59" target="#b6">(Nguyen et al., 2012)</ref>  <ref type="bibr" coords="1,270.28,633.41,14.99,9.59;1,72.00,646.96,86.79,9.59" target="#b4">(Demeester et al., 2013)</ref>.</p><p>The TREC 2014 FedWeb track provides a common platform to evaluate approaches to federated search in a realistic setting, which consists of three tasks, i.e., vertical selection (VS), resource selection (RS) and results merging (RM). We participated in these three tasks. The first two tasks in Federated Web Search, i.e., VS and RS, are to select the right vertical (specialty or topical search engines) or resource (search engine) from a large number of independent search engines given a query. Since a vertical could contain multiple resources (search engines), we consider to address the first two tasks together in an mutual way by combining the outputs of one task for another.</p><p>The traditional approaches to vertical or resource selection treat results returned from one source as a single big document and estimate the relevance score by calculating the text similarity between given query and the big document, such as CORI in <ref type="bibr" coords="1,357.20,359.15,83.22,9.59" target="#b3">(Callan et al., 1995)</ref>, or by building one language model for each resource and calculating the KL-divergence <ref type="bibr" coords="1,394.13,386.25,94.48,9.59" target="#b12">(Xu and Croft, 1999)</ref>. Other methods, such as ReDDE <ref type="bibr" coords="1,426.02,399.80,94.82,9.59" target="#b10">(Si and Callan, 2003)</ref>, CRCS <ref type="bibr" coords="1,339.63,413.35,76.46,9.59" target="#b9">(Shokouhi, 2007)</ref>, estimate the relevance of between query and each document and combine these scores as a final relevance score. More recent methods take supervised classification features into consideration. For example, <ref type="bibr" coords="1,473.32,467.55,52.22,9.59;1,307.28,481.10,46.13,9.59">(Arguello et al., 2009a)</ref> used Category-based Similarity to rank the resources and <ref type="bibr" coords="1,387.47,494.65,99.25,9.59">(Arguello et al., 2009b</ref>) build a probabilistic model by combining multiple types of queries with the corresponding search engine types.</p><p>Almost all these existing methods are devoted to propose various measures to estimate the relevance score between query and sources and this kind of relevance is very closely related with the semantic content of query and results. However, almost all of them ignore one important factor for resource selection, i.e., the impact factor of information source itself. We state that each source itself has a significant impact on the users' selection intention of resource selection rather than the semantic similarity between query and results alone.</p><p>In our work, we proposed a concept of Search Engine Impact Factor (SEIF), which serves as a meaningful and indicative evidence to measure the impact power of search engine. Usually, users prefer to use and believe the search engines which have more engine marketing share or have more good searching experience. And we observed that this evidence may be of great valuable for vertical selection and resource selection. To examine this idea, we propose two ways to calculate the SEIF. One is based on a economic exploration report regarding to the distribution of market shares of search engines, which is available to the public. Another is to use the existing TREC 2013 FedWeb track corpus to estimate SEIF.</p><p>The rest of the paper is organized as follows. Section 2 presents our two methods for SEIF estimation. Section 3 describes our VS system and results. Section 4 depicts our methodology for RS task and results. Section 5 simply reports our baseline system for RM task. Conclusions are provided in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Search Engine Impact Factor (SEIF) Estimation</head><p>We propose two methods for search engine impact factor (SEIF) estimation, which is used for both vertical selection and resource selection tasks. Currently, large amount of search engines are widely used in the world. They are of different languages, such as Chinese, English and Russian, and of quite different focus areas such as videos, books, news, shopping, micro-blogs, music, network, jobs, etc. Since Search Engine Impact Factor to a certain degree is able to reflect the users' selection preference and the amount of information within the search engine, it is natural to take this impact factor as an important feature of Fed-Web. Obviously, this SEIF estimation is independent of the user queries or the results returned from resources and verticals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">SEIF Estimation Using Market Shares</head><p>The first simple and direct way to estimate SEIF is based on the search engines' market shares. Since the market distribution reflect the users' selection preference for search engine, it is quite natural to take this market share value as a reference of impact factor. We refer to the data source in com-Score marketing search report, which is a global leader in measuring the digital world 1 . Figure <ref type="figure" coords="2,284.81,681.64,5.45,9.59">1</ref> shows the distributions of top search engines in market value.</p><p>From Figure <ref type="figure" coords="2,140.31,722.42,5.45,9.59">1</ref> we find that only a few of search engines cover more than 90% market shares. Meanwhile, many other search engines are missing in this market share list. To make a reasonable estimation for search engines with quite low market shares and new search engines not in this list, we adopt a discounting method to re-assign this distribution. The discounting method is widely used for probability estimation in many tasks in NLP, such as Language Modeling, Part-of-Speech task etc. The discounting formula is:</p><formula xml:id="formula_0" coords="2,368.84,346.69,156.70,12.67">IF * (x) = IF (x) -c (1)</formula><p>where we set c = 0.2. The remaining search engines not in this list would evenly share the missing probability mass.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">SEIF Estimation Using TREC 2013 FebWeb Corpus</head><p>The second method is to use the existing TREC 2013 FedWeb track corpus to make estimation. In TREC 2013 FebWeb track corpus, for each query-SE pair, the gold truth file provides the human judgments of relevance score. Then we aggregate these scores grouped by search engine and perform the L 1 normalization for each query. After that, this normalized score is used as the SEIF value for each search engine. Unlike the previous SEIF estimation based on market shares, the TREC corpus contains more than 100 search engines. Therefore, even for the search engines with quite low distribution, the second method still makes a more reasonable estimation than the rough discounting distribution estimation using market shares.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Vertical Selection</head><p>Vertical Selection (VS) is a new task in TREC 2014 FedWeb track, which is to predict the quality of different verticals for a particular query. To address this task, we present three methods to select appropriate verticals for each given query. The first method is to simply match the keywords in queries and vertical labels. The second is to build a supervised machine learning model on labeled training data and to classify unknown input query. Unlike these two methods, the third method is to use the results of RS (Resource selection) task which takes the SEIF into consideration. To evaluate the system performance, the widely-used F 1 score is adopted in this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Machine Learning-based Classification</head><p>Unlike the first method which used direct keyword matching, <ref type="bibr" coords="3,118.08,229.27,80.34,9.59" target="#b8">(Shen et al., 2006)</ref> presented a machine learning method to perform query classification. Following their work, we used the KDD 2005 data set<ref type="foot" coords="3,84.12,267.90,3.99,7.01" target="#foot_0">2</ref> which contains 911 query samples with manual annotation as training data.</p><p>Since the query is generally short and it is prone to produce search ambiguity, we performed query expansion by using Google search engine. For each query, we collected the titles and snippet descriptions from top 10 returned results from Google as expansion terms. By doing so, the averaged number words of each query increased from 3.8 words/query to 222.4 words/query. It is obviously that this query expansion operation dramatically enriches the content of query.</p><p>After query expansion, we used Natural Language Toolkit (NLTK)<ref type="foot" coords="3,170.30,444.38,3.99,7.01" target="#foot_1">3</ref> to remove stop words and to perform stemming. We also performed feature selection to select a subset of relevant features for model construction using χ 2 statistic <ref type="bibr" coords="3,238.46,487.05,51.81,9.59;3,72.00,500.60,73.59,9.59" target="#b11">(Tzeras and Hartmann, 1993;</ref><ref type="bibr" coords="3,148.04,500.60,86.24,9.59" target="#b7">Schütze et al., 1995)</ref>. Finally, we adopted the linear SVM algorithm from liblinear<ref type="foot" coords="3,285.78,512.13,3.99,7.01" target="#foot_2">4</ref> to train the classification model, which is used for prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">SEIF-based Resource Selection</head><p>Different from the previous two methods which take the query into consideration, the third method is to use the results of resource selection based on SEIF. Since the estimation of SEIF is independent of query, the third method is considered to be independent of the semantic of queries and results.</p><p>According to the SEIF value, we selected out the top 20 search engines and their corresponding vertical labels. Then we counted the occurrence of verticals and returned the top 2 vertical labels with maximum frequency to each query. Obviously, this is a query-independent method, which only considers the significance of search engines rather than the semantic relationship between queries and verticals. Moveover, for each given query, this method may assign the same vertical labels, i.e., the first two verticals with maximum frequency is of the same label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Postprocessing</head><p>Since we are allowed to submit more than three systems, we also performed two postprocessing operations in some system configurations. The first operation is to recognize if the queries involve location information. For each query, we collected the returned results from Google and examined if any one word in the list {country, city, street, park} exists in the results. If yes, this query is assigned a Travel vertical label.</p><p>Specifically, for the Q&amp;A vertical, we cannot collect its synonym set from WordNet. The second operation is to manually collect a Q&amp;A keyword list, i.e., {what, when, where, who, why, how}. Similarly, if a query contains any one word in this list, it is assigned a Q&amp;A vertical label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Experiments and Results</head><p>Based on the above mentioned three methods and postprocessing operations, we submitted the following five systems. The purpose of these experiments is two-fold. The first is to compare the performance of the three methods described above. The second is to examine the effects of two postprocessing operations involving manual intervene. ekwma: This system is to use the synonymbased keywords matching method and postprocessing operation.</p><p>svmtrain: This system is to build an supervised machine learning model on KDD data to make prediction.</p><p>esvru This system is similar to the svmtrain system. Besides, it also preforms the postprocessing operations after prediction. esevs: This system is to use the outputs of subsequent resource selection task. Firstly, the top 20 resources with maximal SEIF scores are collected. Since each resource has already assigned a vertical label, then the vertical labels with maximal counts are returned.</p><p>esevsru This system is similar to the esevs system. Also, it includes the postprocessing operations.  <ref type="table" coords="4,109.52,204.44,5.45,9.59" target="#tab_1">1</ref> shows the performance of different systems we submitted to the vertical selection task. It is interesting to find the following observations. Firstly, among the five systems, the two systems in combination of the outputs of resource selection task performed significantly better than the other systems. Specifically, the esevs system performed the best among these submissions and ranked 2nd in officially released results. This indicates that the SEIF based resource selection makes a great contribution to the vertical selection. Secondly, the two machine learning based systems, i.e., svmtrain and esvru, performed worse than the above the systems but outperformed the simple keywords matching method. Although the supervised machine learning method is widely used in NLP, in this task the data coverage may not be quite enough to build a reliable model. Thirdly, the baseline system ekwma performed the worst among these systems. Although this synonymbased keywords matching method is simple and direct, its performance is surprisingly quite low. We analyzed the synonym sets of queries and verticals and found that their common words are quite few. This may be the possible reason for this poor performance. Finally, we find that the postprocessing operations impaired the system performance. A further analysis is needed in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Resource Selection</head><p>The Resource Selection (RS) task is to predict the relevant relationships between queries and resources (search engines). To address it, we present four methods to rank the relevant resources for one given query (the most appropriate resources are ranked highest). The first is to use the surface similarity measurement between query and resources in bag-of-word representation. The second is to build a regression model in consideration of deeper semantic similarity between query and resource, which is expected to outperform the first method. The third method is to rank the resources based on SEIF estimation. The forth is to combine the outputs of the vertical selection task. The official evaluation measure for this task is nDCG (i.e., the normalized discounted cumulative gain), a variant introduced by Christopher Burges in <ref type="bibr" coords="4,351.92,161.39,87.21,9.59" target="#b2">(Burges et al., 2005)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Surface Text Similarity</head><p>The first method is to use the surface words to calculate the text similarity between query and resource. To do it, we first performed query expansion with the aid of Google as before. Then we extracted the content with title and description tags from snippet of resource provided by FebWeb track. Based on the bag-of-word representation and tf idf weighting scheme, we calculated cosine similarity between expanded queries and the contents of resources. For each query, the resources (search engines) with higher similarity score would be returned. Specifically, the tf idf is calculated on the TREC 2014 FebWeb corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Semantic Similarity</head><p>Unlike the first method only considering surface words rather than their actual meaning, the second method is to adopt semantic similarity presented by <ref type="bibr" coords="4,350.79,444.72,79.86,9.59" target="#b13">(Zhao et al., 2013)</ref> to capture the semantic representations of sentences. In this method, the weighted textual matrix factorization (WTFM) <ref type="bibr" coords="4,307.28,485.37,97.81,9.59" target="#b5">(Guo and Diab, 2012)</ref> model is adopted to represent semantics of sentences due to its good quality of modeling short texts. Then we used cosine, Manhattan, Euclidean and Pearson measures to calculate semantic similarity between expanded queries and snippets, resulting in four features. Finally, a gradient boosting regression model trained on TREC 2013 FebWeb data is used to rank search engines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">SEIF-based Ranking</head><p>The second method is to adopt SEIF for resource ranking. In our preliminary experiments, the SEIF estimated by using market shares performs worse than that by using TREC 2013 corpus. In this work we only estimate SEIF by using TREC 2013 data. By doing so, each search engine has a SEIF score, which is independent with queries or independent with the semantic similarity between query and results. For each given query, we use this SEIFscore to rank search engines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Outputs of VS System</head><p>Generally a query may be relevant to multiple search engines with the same vertical label. For example, given Vera Pavlova → {General, Ency-clopedia}, query Vera Pavlova is assumed to be related to all resources with General or Encyclopedia vertical label. Therefore, we consider to use the outputs of vertical selection task to perform resource selection. To do so, for each query, we collected the top verticals returned from online test in VS task and then the search engines which are assigned to the best vertical are returned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.1">Date set and Preprocessing</head><p>We adopt TREC 2013 FebWeb corpus to estimate SEIF, which consists of 157 web search engines. The format of TREC data is XML and we extract the texts with &lt; title &gt; and &lt; description &gt; tags. That is, we use the data set only containing snippet rather than documents. Then for each source, we combine all results into a big document. After that, tokenization and lemmatization are performed and stop words are removed for each document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2">Experimental Results</head><p>In resource selection task, we submitted the following six systems for the purpose of comparing the performance of above four methods. Furthermore, we also combine the results of these four methods in order to examine if the combination improves performance.</p><p>etfidf: This simple baseline is to use cosine similarity between query and resources in tfidf scheme.</p><p>esmimax: This system is to use semantic similarity score to rank search engines for each query.</p><p>eseif: This system is to use SEIF score estimated on TREC 2013 corpus. ecomsv: This system combines the outputs of SEIF and outputs of VS system. ecomsvt: This system is to combine the outputs of SEIF, VS and the first tfidf system. ecomsvz: This system is to combine all outputs of four methods, i.e., the outputs of SEIF, VS, tfidf and semantic similarity system.</p><p>Table <ref type="table" coords="5,109.56,715.10,5.45,9.59">2</ref> shows the official released performance of six systems we submitted to the resource selection task. From this table we find the following observations. First, the ecomsvz system, which This indicates that the SEIF feature is quite effective and using SEIF only makes more contribution than using semantic feature alone. But it still performed worse than the last three systems with combination configuration. Third, the last three systems, i.e., ecomsv,ecomsvt and ecomsvz, significantly outperformed other three systems which only considered one single feature. It shows that the combination of all these features makes significant contributions to performance improvement in resource selection task. Fourth, in comparison with etfidf considering only cosine similarity using tfidf, the esmimax system in consideration of semantic similarity achieved a better result. This shows that semantic analysis on texts does outperform simple surface word similarity.</p><p>From these observations we conclude that SEIF is surprisingly effective. It is independent of query but it makes more contributions than other similarity features , i.e., surface similarity and semantic similarity. This is surprisingly good. A reasonable explanation for this is the resources (search engines) themselves have adopted more deeper and sophisticated explorations on search strategy before they returned the results. Using SEIF is standing on the shoulders of giants. On the other hand, the drawback of SEIF is it did not take the query into consideration and returned the same results for every query. This is not reasonable. Therefore, the combination of all above features, i.e., similarity features, SEIF, outputs of VS, which both benefits from SEIF and takes other effective features into consideration, performed the best.</p><p>The resource merging (RM) task aims to merge the snippet results returned from previously selected resources into a ranked list. In this task, we simply return the output of resource selection baseline provided by organizer. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We employed several methods for vertical selection and resource selection tasks. The results showed that our proposed SEIF significantly improved the performance of both vertical selection and resource selection. In addition, the combination of multiple features can make up for each other and further improve performance. Our final results ranked 1st in RS task and 2nd in VS task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,72.00,65.32,218.27,148.71"><head>Table 1 :</head><label>1</label><figDesc>Officially released results of Vertical Selection in TREC 2014 FedWeb track Table</figDesc><table coords="4,107.29,65.32,147.69,79.48"><row><cell></cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell cols="4">ekwma 0.054 0.120 0.069</cell></row><row><cell cols="4">svmtrain 0.338 0.425 0.338</cell></row><row><cell>esvru</cell><cell cols="3">0.276 0.439 0.297</cell></row><row><cell>esevs</cell><cell cols="3">0.398 0.586 0.483</cell></row><row><cell cols="4">esevsru 0.388 0.598 0.440</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,72.00,141.74,218.27,95.56"><head>Table 3 :</head><label>3</label><figDesc>Table 2 lists the results on TREC 2014. Officially Released Results of Results Merging in FedWeb 2014</figDesc><table coords="6,98.43,177.20,165.41,23.69"><row><cell cols="3">System nDCG@20 nDCG@100</cell></row><row><cell>basedef</cell><cell>0.289</cell><cell>0.300</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="3,88.14,725.31,184.35,7.88;3,72.00,735.28,99.95,7.88"><p>http://www.sigkdd.org/kdd-cup-2005-internet-usersearch-query-categorization</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="3,84.65,744.32,2.99,5.25;3,88.14,746.15,58.39,7.88"><p>3 http://www.nltk.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="3,146.53,746.15,14.60,7.88;3,84.65,755.20,2.99,5.25;3,88.14,757.03,152.08,7.88"><p>org/ 4 http://www.csie.ntu.edu.tw/ cjlin/liblinear/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This research is supported by grants from <rs type="funder">National Natural Science Foundation of China</rs> (No.<rs type="grantNumber">60903093</rs>), <rs type="funder">Shanghai Collaborative Innovation Center of Trustworthy Software for Internet of Things</rs> (<rs type="grantNumber">ZF1213</rs>), and the <rs type="funder">Science and Technology Commission of Shanghai Municipality</rs> under research grant No.<rs type="grantNumber">14DZ2260800</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_jWBzaww">
					<idno type="grant-number">60903093</idno>
				</org>
				<org type="funding" xml:id="_UfEMhzH">
					<idno type="grant-number">ZF1213</idno>
				</org>
				<org type="funding" xml:id="_mhunWaY">
					<idno type="grant-number">14DZ2260800</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,72.00,562.81,218.27,8.76;6,82.91,573.77,207.36,8.76;6,82.91,584.82,207.37,8.55;6,82.91,595.69,207.35,8.76;6,82.91,606.65,49.69,8.76" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,116.45,573.77,155.04,8.76">Classification-based resource selection</title>
		<author>
			<persName coords=""><forename type="first">Jaime</forename><surname>Arguello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,82.91,584.82,207.37,8.55;6,82.91,595.78,146.09,8.55">Proceedings of the 18th ACM conference on Information and knowledge management</title>
		<meeting>the 18th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1277" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,626.71,218.27,8.76;6,82.91,637.67,207.37,8.76;6,82.91,648.63,207.35,8.76;6,82.91,659.68,207.36,8.55;6,82.91,670.55,207.36,8.76;6,82.91,681.51,44.71,8.76" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,209.29,637.67,80.99,8.76;6,82.91,648.63,80.01,8.76">Sources of evidence for vertical selection</title>
		<author>
			<persName coords=""><forename type="first">Jaime</forename><surname>Arguello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean-Francois</forename><surname>Crespo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,180.90,648.72,109.36,8.55;6,82.91,659.68,207.36,8.55;6,82.91,670.64,151.42,8.55">Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 32nd international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="315" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,701.57,218.28,8.76;6,82.91,712.53,207.37,8.76;6,82.91,723.49,207.36,8.76;6,82.91,734.54,207.37,8.55;6,82.91,745.41,207.37,8.76;6,82.91,756.37,92.14,8.76" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,111.43,723.49,160.38,8.76">Learning to rank using gradient descent</title>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tal</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Erin</forename><surname>Renshaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ari</forename><surname>Lazier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matt</forename><surname>Deeds</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicole</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Greg</forename><surname>Hullender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,82.91,734.54,207.37,8.55;6,82.91,745.41,128.55,8.76">Proceedings of the 22Nd International Conference on Machine Learning, ICML &apos;05</title>
		<meeting>the 22Nd International Conference on Machine Learning, ICML &apos;05<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,307.28,67.17,218.27,8.76;6,318.18,78.13,207.38,8.76;6,318.18,89.08,207.36,8.76;6,318.18,100.13,207.38,8.55;6,318.18,111.00,207.36,8.76;6,318.18,121.96,39.74,8.76" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,346.99,78.13,178.57,8.76;6,318.18,89.08,56.29,8.76">Searching distributed collections with inference networks</title>
		<author>
			<persName coords=""><forename type="first">Zhihong</forename><surname>James P Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bruce</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,397.13,89.17,128.41,8.55;6,318.18,100.13,207.38,8.55;6,318.18,111.09,161.57,8.55">Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 18th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="21" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,307.28,140.47,218.27,8.76;6,318.18,151.43,207.37,8.76;6,318.18,162.39,162.94,8.76" xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dolf</forename><surname>Trieschnigg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dong</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note>federated web search track. TREC</note>
</biblStruct>

<biblStruct coords="6,307.28,180.90,218.27,8.76;6,318.18,191.86,207.36,8.76;6,318.18,202.90,207.37,8.55;6,318.18,213.77,207.36,8.76;6,318.18,224.73,207.37,8.76;6,318.18,235.69,16.33,8.76" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,466.45,180.90,59.10,8.76;6,318.18,191.86,104.17,8.76">Modeling sentences in the latent space</title>
		<author>
			<persName coords=""><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,447.91,191.95,77.63,8.55;6,318.18,202.90,207.37,8.55;6,318.18,213.86,137.91,8.55">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="864" to="872" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct coords="6,307.28,254.20,218.28,8.76;6,318.18,265.16,207.37,8.76;6,318.18,276.12,207.37,8.76;6,318.18,287.08,207.37,8.76;6,318.18,298.13,207.37,8.55;6,318.18,309.00,176.68,8.76" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,445.34,265.16,80.21,8.76;6,318.18,276.12,207.37,8.76;6,318.18,287.08,58.44,8.76">Federated search in the wild: the combined power of over a hundred search engines</title>
		<author>
			<persName coords=""><forename type="first">Dong</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dolf</forename><surname>Trieschnigg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,402.21,287.17,123.34,8.55;6,318.18,298.13,207.37,8.55;6,318.18,309.09,69.56,8.55">Proceedings of the 21st ACM international conference on Information and knowledge management</title>
		<meeting>the 21st ACM international conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1874" to="1878" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,307.28,327.50,218.26,8.76;6,318.18,338.46,207.37,8.76;6,318.18,349.42,207.37,8.76;6,318.18,360.47,207.37,8.55;6,318.18,371.43,207.38,8.55;6,318.18,382.30,158.77,8.76" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,349.63,338.46,175.92,8.76;6,318.18,349.42,152.74,8.76">A comparison of classifiers and document representations for the routing problem</title>
		<author>
			<persName coords=""><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">A</forename><surname>Hull</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jan</forename><forename type="middle">O</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,489.48,349.51,36.07,8.55;6,318.18,360.47,207.37,8.55;6,318.18,371.43,207.38,8.55;6,318.18,382.39,62.82,8.55">Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 18th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="229" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,307.28,400.81,218.27,8.76;6,318.18,411.77,207.38,8.76;6,318.18,422.73,207.37,8.76;6,318.18,433.68,207.36,8.76;6,318.18,444.64,94.18,8.76" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,347.57,422.73,177.98,8.76;6,318.18,433.68,14.39,8.76">Query enrichment for web-query classification</title>
		<author>
			<persName coords=""><forename type="first">Dou</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rong</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jian-Tao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Junfeng Pan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kangheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jie</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,346.27,433.77,179.27,8.55;6,318.18,444.73,25.70,8.55">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="320" to="352" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,307.28,463.15,218.27,8.76;6,318.18,474.11,207.37,8.76;6,318.18,485.07,207.36,8.76;6,318.18,496.03,101.29,8.76" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,417.70,463.15,107.85,8.76;6,318.18,474.11,207.37,8.76;6,318.18,485.07,49.66,8.76">Central-rank-based collection selection in uncooperative distributed information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Milad</forename><surname>Shokouhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,385.72,485.16,135.93,8.55">Advances in Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="160" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,307.28,514.54,218.27,8.76;6,318.18,525.50,207.37,8.76;6,318.18,536.46,207.37,8.76;6,318.18,547.50,207.37,8.55;6,318.18,558.37,207.36,8.76;6,318.18,569.33,24.80,8.76" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,447.83,514.54,77.72,8.76;6,318.18,525.50,207.37,8.76;6,318.18,536.46,14.39,8.76">Relevant document distribution estimation method for resource selection</title>
		<author>
			<persName coords=""><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,357.75,536.55,167.80,8.55;6,318.18,547.50,207.37,8.55;6,318.18,558.46,136.31,8.55">Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval</title>
		<meeting>the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="298" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,307.28,587.84,218.27,8.76;6,318.18,598.80,207.37,8.76;6,318.18,609.76,207.37,8.76;6,318.18,620.81,207.37,8.55;6,318.18,631.68,207.36,8.76;6,318.18,642.64,24.80,8.76" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,510.06,587.84,15.49,8.76;6,318.18,598.80,207.37,8.76;6,318.18,609.76,22.29,8.76">Automatic indexing based on bayesian inference networks</title>
		<author>
			<persName coords=""><forename type="first">Kostas</forename><surname>Tzeras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephan</forename><surname>Hartmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,367.14,609.85,158.41,8.55;6,318.18,620.81,207.37,8.55;6,318.18,631.77,147.15,8.55">Proceedings of the 16th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 16th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="22" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,307.28,661.14,218.27,8.76;6,318.18,672.10,207.37,8.76;6,318.18,683.15,207.37,8.55;6,318.18,694.11,207.38,8.55;6,318.18,704.98,158.77,8.76" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="6,452.90,661.14,72.65,8.76;6,318.18,672.10,150.78,8.76">Cluster-based language models for distributed retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,489.48,672.19,36.07,8.55;6,318.18,683.15,207.37,8.55;6,318.18,694.11,207.38,8.55;6,318.18,705.07,62.82,8.55">Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 22nd annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="254" to="261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,307.28,723.49,218.27,8.76;6,318.18,734.45,207.37,8.76;6,318.18,745.41,207.38,8.76;6,318.18,756.37,177.27,8.76" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="6,511.72,723.49,13.83,8.76;6,318.18,734.45,207.37,8.76;6,318.18,745.41,207.38,8.76;6,318.18,756.37,35.17,8.76">Ecnucs: Recognizing cross-lingual textual entailment using multiple text similarity and text difference measures</title>
		<author>
			<persName coords=""><forename type="first">Jiang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Man</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zheng-Yu</forename><surname>Niu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">118</biblScope>
			<pubPlace>Atlanta, Georgia, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
