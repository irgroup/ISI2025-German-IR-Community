<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,178.56,80.22,238.08,10.54">ICTNET at Federated Web Search Track 2014</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,150.72,99.97,36.28,8.85"><forename type="first">Feng</forename><surname>Guan</surname></persName>
							<email>guanfeng@software.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,197.04,99.97,52.86,8.85"><forename type="first">Shuiyuan</forename><surname>Zhang</surname></persName>
							<email>zhangshuiyuan@software.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,259.92,99.97,43.00,8.85"><forename type="first">Chunmei</forename><surname>Liu</surname></persName>
							<email>liuchuanmei@software.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,312.96,99.97,43.25,8.85"><forename type="first">Xiaoming</forename><surname>Yu</surname></persName>
							<email>yuxiaoming@software.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,362.89,99.97,25.95,8.85"><forename type="first">Yue</forename><surname>Liu</surname></persName>
							<email>liuyue@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,397.44,99.97,43.00,8.85"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,178.56,80.22,238.08,10.54">ICTNET at Federated Web Search Track 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DDDEE45636C21095BE602D302C0BD7F1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>We have participated all the three tasks of FedWeb 2014 this year. Basic methods that we used for these tasks will be described in section 2. Section 3 shows combination of the basic methods for different runs and the results will also be introduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Proposed methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Vertical Selection task</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">LSI model</head><p>For a given query, vertical selection will choose a subset of candidate verticals to retrieve from.</p><p>The most intuitive approach is to look for the most similar query vertical pairs. To find a representation for both vertical and query, we take the help of Google Custom Search API (GCSA) <ref type="bibr" coords="1,436.08,339.71,7.67,5.69">[1]</ref> . With this API we can build a simple Custom Search Engine, and 10 results for each query will be returned as query representation. We also use a small portion of the given documents as vertical representation.</p><p>After query and vertical representation, we choose Latent Semantic Index (LSI) model to calculate similarity between them. LSI model uses a mathematical technique called singular value decomposition (SVD) to identify patterns in the relationships between terms <ref type="bibr" coords="1,401.76,417.71,7.44,5.69" target="#b0">[3]</ref> . As our representations of query and vertical are not likely similar in a literal way, LSI model can help us find the hidden commonality between vertical and query. Then two steps of voting will be taken. First, similarity between vertical representations and query representations will be calculated and the top 40 most similar vertical representations will be scored based on their similarity ranking. The score of vertical representation came from the same vertical will be summed. For each query representation, verticals whose score are no less than the threshold will be selected to the next voting step. Second, for each query, we choose verticals that appear more than twice as the candidate vertical set of all this query representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Text Classification</head><p>We use the state-of-art algorithm Random Forest (RF) to do classify job. RF model will be trained using the given documents. Each vertical is a class. Both the number of trees and the number of features in random feature selection are 100. We use tf-idf of terms as the features of documents, and do query expansion with GCSA based on the top 10 relevant documents. For each document returned, we can get its probabilities classified to a vertical by RF. Then, we sum the probabilities of the 10 documents as vertical's score. Finally, we recommend the verticals that have high score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Frequent Term Rank(FTR) based vertical representation</head><p>We believe that, excluding stop words, the more frequent that a term is in one vertical, the more probable that it can represent this vertical. Besides, the order of frequent terms maybe different during verticals. Thus we obtain the similarity score of query Q and vertical V according to equation 1 as follow:</p><formula xml:id="formula_0" coords="2,203.52,81.88,301.91,28.44">   Q q V q Rank V Q sim ) , ( 1 ) , (<label>(1)</label></formula><p>Rank(q, V) means the rank of term q in feature vector of vertical V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Resource Selection task 2.2.1 LSI model</head><p>LSI model used in resource selection task is similar with vertical selection task. Resource is represented by 20 random documents from provided data at this resource. Considering authority of resource will have an effect on ranking, we collect page rank score for every resource <ref type="bibr" coords="2,438.00,199.31,7.67,5.69">[2]</ref> . Besides, each resource belongs to one vertical, vertical ranking also has a huge impact on resource selection.</p><p>The final similarity score of a query resource pair is given in Equation <ref type="formula" coords="2,380.58,232.69,3.78,8.85">2</ref>. We choose top 20 resources</p><formula xml:id="formula_1" coords="2,90.00,248.29,415.44,41.49">for each query. 1 ( _ _ ) 1 _ i i sco re lsi sim p r p r w eig h t vertica l ra n k         (2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Information Retrieval</head><p>We build index of the provided documents with stop words. For each query and each resource, we sum the scores of documents in one resource as the score of one resource. Each field has different weight. When searching, we combine the results of query without stop words and the same query within window size of 5. Each document's final score should be multiplied by Penalty Factor. The Penalty Factor is defined as equation 3, which α equals 0.5, and R represents the ranking of each document.</p><formula xml:id="formula_2" coords="2,229.92,405.06,275.51,22.72">1 _ 1 p e n a lty fa c to r R    <label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Text Classification</head><p>This method is similar to that used in VS task. The difference is that the classes are the resources.</p><p>Besides, the score of each resource should relate to the rank of resources in VS task. Therefore, we raise the score of those resources.  <ref type="formula" coords="2,228.95,575.89,3.78,8.85" target="#formula_3">4</ref>. We also take page rank of page host into account in this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Result</head><formula xml:id="formula_3" coords="2,236.64,591.34,268.79,24.84">1 _ 1 g o o g le w eig h t ra n k    <label>(4)</label></formula><p>In the provided data, a document can appear in many resources with same url and different doc id.</p><p>The more search engines a document appears in, the more important the document is. Extra score will be added to documents which occur many times in different resources.</p><p>The final score for a document i is defined as Equation 5, pr_weight is used to adjust page rank to </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>(5)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Information Retrieval</head><p>We get origin score using information retrieval method mentioned above. We use the results in RS task and the origin score is multiplied by the penalty factor as we did in the RS task. What's more, we considered the duplicated times of each document and the ranking of the resource which the document belongs to. The expression defined as equation 6:</p><formula xml:id="formula_4" coords="3,221.28,128.55,284.15,29.46">2 1 0 0 , 1 1 1 1 du p r i sco re sco re R R           (6)</formula><p>Which the "dup" is the duplicated times of one document, and i r R , represents the document i's resource's ranking in last task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Pagerank-like model</head><p>Like the algorithm of PageRank, for each query, we set the initial Pr values as the scores generated by Information Retrieval method. The weight of each edge is the similarity generated by LSI model. The expression defined as equation 7:</p><formula xml:id="formula_5" coords="3,282.00,285.03,69.80,25.15">1 0 (<label>1</label></formula><formula xml:id="formula_6" coords="3,90.00,284.86,415.43,60.84">) i I j j k ik i k K p r sim p r O          (7) Which j i</formula><p>pr represents the PR value of document i in the jth iteration. I i represents the number of ingoing links of document i, O k represents the outgoing links of document k, sim ik represents the LSI similarity between document k and i, the α is Damping Factor equals 0.85.When the PR values tend to be stable, iteration would stop. The PR value of each document will be the final score of each document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Ensemble methods</head><p>In machine learning area, ensemble methods using multiple learning algorithms could obtain better predictive performance than any of the constituent learning algorithms <ref type="bibr" coords="3,417.36,448.91,7.67,5.69" target="#b1">[4]</ref> . We use ensemble methods in vertical selection and result merge task to merge our single model results, and for resource selection task, our submission run only based on single model result.</p><p>For vertical selection task, our ensemble method is to try getting a higher recall in single model, and intersecting single model results to get a balance precision and recall result. For result merge task, different model may have different score scale, we only use ranking data. Given several single model results, final score for a document i defined as Equation <ref type="formula" coords="3,324.24,544.69,3.66,8.85">8</ref>. Rank in the same interval will have same score, we choose interval=3 in our experiment.</p><formula xml:id="formula_7" coords="3,233.28,575.82,272.15,24.27">1 1 . 0 ( / ) i i s c o r e r a n k i n t e r v a l      (8)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Vertical Selection task</head><p>ICTNETVS1 is based on traditional information retrieval (IR) model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ICTNETVS02 uses</head><p>Random Forest text classification model, the result is the sum of probabilities.</p><p>ICTNETVS03 is based on LSI model using vertical representation and query representation with GCSA.</p><p>ICTNETVS04 uses ensemble method with 2 LSI models and text classification model.</p><p>ICTNETVS05 combines 2 LSI models and text classification model and information retrieval model together using set intersection.</p><p>ICTNETVS06 uses Random Forest text classification model, the result is the sum of voting.</p><p>ICTNETVS07 is the Borda Fuse combination of three methods. The first one is to calculate similarity between vertical and query using FTR. The second one also uses FTR that co-occurrence terms are used to expand query. The third one is IR model.The result is given below. The result is given below.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,90.00,685.09,60.35,8.85;2,181.92,706.26,22.94,9.10;2,269.75,706.26,5.18,9.10;2,359.02,706.26,5.18,9.10;2,437.73,706.26,5.18,9.10;2,472.28,706.26,3.45,9.10;2,152.40,711.79,1.67,5.26;2,126.72,706.26,25.47,9.10;2,185.98,706.26,285.40,9.10;2,158.40,705.94,5.69,9.42;2,226.07,705.94,5.69,9.42;2,312.94,705.94,5.69,9.42;2,335.97,705.94,5.69,9.42;2,402.20,705.94,5.69,9.42"><head></head><label></label><figDesc>google w eight pr pr w eight extra score     </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,90.00,498.05,415.32,86.69"><head>Merging task 2.3.1 LSI model Like</head><label></label><figDesc></figDesc><table /><note coords="2,132.72,529.09,372.60,8.85;2,90.00,544.69,415.19,8.85;2,90.00,560.29,415.14,8.85;2,90.00,575.89,136.32,8.85"><p>previous tasks, query is represented by 10 different snippets with GCSA. For each snippet, we use LSI model to calculate similarity between query representation (snippet) and document. For each query representation, snippet is more important if it has a higher rank in search results. So we define google_weight as Equation</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,90.00,123.88,415.29,262.62"><head>Table 1 :</head><label>1</label><figDesc>Vertical Selection results(+-st.dev.)</figDesc><table coords="4,90.00,139.96,415.29,246.54"><row><cell>Runtag</cell><cell>Precision</cell><cell>Recall</cell><cell>F1-measure</cell></row><row><cell>ICTNETVS1</cell><cell>0.230 (+-0.202)</cell><cell>0.638 (+-0.407)</cell><cell>0.299 (+-0.201)</cell></row><row><cell>ICTNETVS02</cell><cell>0.292 (+-0.201)</cell><cell>0.790 (+-0.368)</cell><cell>0.401 (+-0.228)</cell></row><row><cell>ICTNETVS03</cell><cell>0.276 (+-0.298)</cell><cell>0.410 (+-0.436)</cell><cell>0.298 (+-0.303)</cell></row><row><cell>ICTNETVS04</cell><cell>0.427 (+-0.419)</cell><cell>0.392 (+-0.419)</cell><cell>0.377 (+-0.375)</cell></row><row><cell>ICTNETVS05</cell><cell>0.423 (+-0.441)</cell><cell>0.365 (+-0.417)</cell><cell>0.359 (+-0.381)</cell></row><row><cell>ICTNETVS06</cell><cell>0.258 (+-0.201)</cell><cell>0.673 (+-0.394)</cell><cell>0.344 (+-0.217)</cell></row><row><cell>ICTNETVS07</cell><cell>0.591 (+-0.411)</cell><cell>0.545 (+-0.391)</cell><cell>0.496 (+-0.337)</cell></row><row><cell cols="2">3.2 Resource Selection task</cell><cell></cell><cell></cell></row><row><cell cols="3">ICTNETRS01 uses traditional information retrieval model.</cell><cell></cell></row><row><cell cols="4">ICTNETRS02 and ICTNETRS07 take VS results into account while using information retrieval</cell></row><row><cell cols="3">model. The difference is we use different vertical selection result.</cell><cell></cell></row><row><cell cols="4">ICTNETRS03 uses text classification model (RF), meanwhile VS results are considered.</cell></row><row><cell cols="2">ICTNETRS04 uses LSI model with page rank.</cell><cell></cell><cell></cell></row><row><cell cols="4">ICTNETRS05 and ICTNETRS06 use LSI model with page rank and vertical selection results.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,90.00,409.28,417.95,355.94"><head>Table 2 :</head><label>2</label><figDesc>Resource Selection results(+-st.dev.)</figDesc><table coords="4,90.00,425.36,417.95,293.06"><row><cell>Runtag</cell><cell>nDCG@20</cell><cell>nDCG@10</cell><cell>nP@1</cell><cell>nP@5</cell></row><row><cell>ICTNETRS01</cell><cell>0.268 (+-0.147)</cell><cell>0.226 (+-0.162)</cell><cell>0.163 (+-0.269)</cell><cell>0.193 (+-0.171)</cell></row><row><cell>ICTNETRS02</cell><cell>0.365 (+-0.154)</cell><cell>0.322 (+-0.175)</cell><cell>0.289 (+-0.334)</cell><cell>0.324 (+-0.197)</cell></row><row><cell>ICTNETRS03</cell><cell>0.400 (+-0.123)</cell><cell>0.340 (+-0.138)</cell><cell>0.160 (+-0.276)</cell><cell>0.351 (+-0.165)</cell></row><row><cell>ICTNETRS04</cell><cell>0.362 (+-0.113)</cell><cell>0.306 (+-0.146)</cell><cell>0.116 (+-0.256)</cell><cell>0.290 (+-0.212)</cell></row><row><cell>ICTNETRS05</cell><cell>0.436 (+-0.149)</cell><cell>0.391 (+-0.173)</cell><cell>0.489 (+-0.391)</cell><cell>0.377 (+-0.194)</cell></row><row><cell>ICTNETRS06</cell><cell>0.428 (+-0.160)</cell><cell>0.372 (+-0.176)</cell><cell>0.521 (+-0.377)</cell><cell>0.345 (+-0.197)</cell></row><row><cell>ICTNETRS07</cell><cell>0.373 (+-0.143)</cell><cell>0.334 (+-0.171)</cell><cell>0.267 (+-0.338)</cell><cell>0.334 (+-0.196)</cell></row><row><cell cols="2">3.3 Result Merging task</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">All of all submissions of result merging task are based on the provided resource selection baseline,</cell></row><row><cell cols="3">this baseline is the same as our ICTNETRS06.</cell><cell></cell><cell></cell></row><row><cell cols="3">ICTNETRM01 uses information retrieval method.</cell><cell></cell><cell></cell></row><row><cell cols="4">ICTNETRM02 removes duplicate urls from ICTNETRM01.</cell><cell></cell></row><row><cell cols="5">ICTNETRM03 uses Pagerank-like model, while the similarity is calculated with LSI model</cell></row><row><cell cols="2">without duplicate urls.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">ICTNETRM04 is based on LSI model, topic number is 5.</cell><cell></cell></row><row><cell cols="5">ICTNETRM05 uses 3 models ensemble method, which are LSI model, IR model and PR model.</cell></row><row><cell cols="4">ICTNETRM06 removes duplicate urls from ICTNETRM05.</cell><cell></cell></row></table><note coords="4,111.12,725.17,394.32,8.85;4,90.00,740.77,415.35,8.85;4,90.00,756.37,132.13,8.85"><p><p><p>ICTNETRM07 uses 2 models ensemble method, which are IR model and PR model, and duplicate urls are also removed.Detailed results are shown as table</p>3</p>. Ensemble method without duplicate urls gets the best score.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,90.00,77.12,415.74,223.46"><head>Table 3 :</head><label>3</label><figDesc>Result Merging results(+-st.dev.) We would like to thank all organizers and assessors of TREC and NIST. This work is sponsored by 973 Program of China Grants No.2012CB316303&amp;No.2014CB340405, 863 program of China Grants No.2012AA011003&amp;No.2014AA015204, NSF of China Grants No.61232010&amp;No.61173064, and by the National Key Technology R&amp;D Program Grants No. 2012BAH39B02&amp;No. 2012BAH39B04.</figDesc><table coords="5,90.00,93.20,383.43,142.52"><row><cell>Runtag</cell><cell>nDCG@20</cell><cell>nDCG@20_withdup</cell><cell>nDCG@20_local</cell><cell>nDCG-IA@20</cell></row><row><cell>ICTNETRM01</cell><cell>0.247 (+-0.146)</cell><cell>0.361 (+-0.215)</cell><cell>0.338 (+-0.186)</cell><cell>0.080 (+-0.054)</cell></row><row><cell>ICTNETRM02</cell><cell>0.309 (+-0.174)</cell><cell>0.314 (+-0.181)</cell><cell>0.362 (+-0.182)</cell><cell>0.095 (+-0.059)</cell></row><row><cell>ICTNETRM03</cell><cell>0.348 (+-0.160)</cell><cell>0.350 (+-0.161)</cell><cell>0.405 (+-0.158)</cell><cell>0.111 (+-0.063)</cell></row><row><cell>ICTNETRM04</cell><cell>0.381 (+-0.157)</cell><cell>0.386 (+-0.157)</cell><cell>0.451 (+-0.142)</cell><cell>0.121 (+-0.063)</cell></row><row><cell>ICTNETRM05</cell><cell>0.354 (+-0.138)</cell><cell>0.492 (+-0.201)</cell><cell>0.497 (+-0.183)</cell><cell>0.123 (+-0.071)</cell></row><row><cell>ICTNETRM06</cell><cell>0.402 (+-0.153)</cell><cell>0.407 (+-0.159)</cell><cell>0.473 (+-0.138)</cell><cell>0.132 (+-0.070)</cell></row><row><cell>ICTNETRM07</cell><cell>0.386 (+-0.153)</cell><cell>0.390 (+-0.157)</cell><cell>0.451 (+-0.148)</cell><cell>0.123 (+-0.068)</cell></row><row><cell cols="2">4. Acknowledgement</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,102.72,385.72,314.55,8.01" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="5,169.21,385.72,221.76,8.01">Improving information retrieval with latent semantic indexing</title>
		<author>
			<persName coords=""><forename type="first">Scott</forename><surname>Deerwester</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,102.72,401.32,318.49,8.01;5,103.44,416.92,114.60,8.01" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Maclin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Opitz</surname></persName>
		</author>
		<idno type="arXiv">arXivpreprintarXiv:1106.0257</idno>
		<title level="m" coord="5,225.36,401.32,169.11,8.01">Popular ensemble methods: An empirical study</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
