<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,61.08,76.41,489.78,16.20;1,75.26,97.05,461.25,16.20">Query Refinement: Negation Detection and Proximity Learning Georgetown at TREC 2014 Clinical Decision Support Track</title>
				<funder ref="#_HqGmmMS">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_52aNeeh #_wsQ63pV">
					<orgName type="full">DARPA</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,201.53,130.84,114.96,14.36"><forename type="first">Christopher</forename><surname>Wing</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Georgetown University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,347.72,130.84,62.53,14.36"><forename type="first">Hui</forename><surname>Yang</surname></persName>
							<email>huiyang@cs.georgetown.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Georgetown University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,61.08,76.41,489.78,16.20;1,75.26,97.05,461.25,16.20">Query Refinement: Negation Detection and Proximity Learning Georgetown at TREC 2014 Clinical Decision Support Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7FB57F0E0D1F8FFD3349D586D180D6FD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe our efforts for TREC Clinical Decision Support Track 2014. Our system takes medical case narratives as input and returns relevant biomedical articles to answer clinical questions to determine the patient's diagnosis, the tests the patient should receive, and how the patient should be treated. We model each topic as highly representative keyword-based structured queries. Since both the topics and returned documents are written in highly technical language, we address the traditional vocabulary gap present within medical information retrieval, while also focusing on employing methodologies to refine our queries by detecting negation and applying query proximity learning. We hypothesized terms with high frequency among the topics, which are likely to create noise and impair the return of highly relevant documents. Our top two runs utilizing negation detection perform above the median for P@10, R-Prec, and infAP, and our other three runs that utilized proximity learning performed approximately consistent with the median. More research is required to explore the potential benefits of proximity learning over a more robust set of topics.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Physicians can find relevant information in biomedical literature necessary to make clinical decisions. However, locating the most relevant and time-sensitive information for a particular clinical question can be a challenging and timely task. The TREC 2014 Clinical Decision Support track challenges participants to retrieve full-text biomedical articles to answer the three most common generic clinical questions faced by physicians on a daily basis: "what is the patient's diagnosis?", "what tests should the patient receive?", and "how should the patient be treated?" <ref type="bibr" coords="1,224.69,579.75,12.24,10.37" target="#b1">[1]</ref>.</p><p>Thirty topics were created to serve as idealized representations of actual medical records, and include information such as medical history, current symptoms, diagnosis, and the physician's plan to treat the patient. Each topic is tagged with one of the specified questions mentioned above. For a given topic, the retrieved documents are then used to provide specific information to a physician relevant to the clinical question. Each case narrative was provided in two forms: a longer, more complete patient account referred to as "descriptions" and a simplified version referred to as "summaries." In our approach, we utilized the descriptions for all of our submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Our Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Indexing</head><p>The document collection used for the track is a snapshot of the Open Access Subset of PubMed Central (PMC), containing 733,138 articles in NXML format. We adopt the Lemur Search Engine<ref type="foot" coords="2,468.94,128.06,3.78,6.80" target="#foot_0">1</ref> to build an index for the collection with stop word removal and Krovetz stemming <ref type="bibr" coords="2,355.48,143.59,12.36,10.37" target="#b2">[2]</ref>. We adopt the Language Modeling with Dirichlet smoothing <ref type="bibr" coords="2,149.18,156.79,13.44,10.37" target="#b3">[3]</ref> that Lemur implements as its default retrieval algorithm:</p><formula xml:id="formula_0" coords="2,237.89,180.88,136.40,30.79">ùëÉ(ùë°|ùëë) = ùë°ùëì ùë°,ùëë + ùúáùëÉ(ùë°|ùëÄ ùê∂ ) ‚àë ùë°ùëì ùë° ‚Ä≤ ,ùëë + ùúá ùë°‚Ä≤‚ààùëâ</formula><p>where ùë°ùëì ùë°,ùëë corresponds to the frequency of term t in document d, ùëÄ ùê∂ corresponds to the corpus model, and V corresponds to the Vocabulary. Lemur's default value of ùúá = 2500 was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Medical Concept Detection</head><p>Since the topics were written in natural language, we needed to generate representative keywords directly from the text. Each topic was queried on the National Library of Medicine's (NLM) MeSH on Demand,<ref type="foot" coords="2,532.54,290.93,3.78,6.80" target="#foot_1">2</ref> which generates relevant MeSH terms using the NLM Medical Text Indexer (MTI). <ref type="foot" coords="2,439.99,304.13,3.78,6.80" target="#foot_2">3</ref> MeSH, or Medical Subject Headings, are terminology used by the NLM to index articles, catalog books, and searching MeSHindexed databases such as PubMed.</p><p>However, since many medical conditions may be expressed in varying terminology, a single representation of a medical concept in one case report may not match a given representation in another medical case document. Thus, we queried each detected MeSH term in MetaMap, <ref type="foot" coords="2,368.95,383.45,3.78,6.80" target="#foot_3">4</ref> which maps text to the Unified Medical Language System (UMLS) Metathesaurus, in order to provide synonyms. A confidence score is given to each proposed synonym with a max value of 1000. Synonyms were only kept with candidate mapping scores of 1000. In addition, each synonym is also described by a classification. Any MeSH term not found in MetaMap were considered not relevant and were removed. Additionally, synonyms with categories belonging to the blacklist<ref type="foot" coords="2,170.66,449.59,3.78,6.80" target="#foot_4">5</ref> were removed. For some runs, a stricter MetaMap filtering methodology was applied. Only synonyms with categories on the whitelist <ref type="foot" coords="2,312.65,462.79,3.78,6.80" target="#foot_5">6</ref> were considered relevant, and the rest were removed. Subsequently, each list of MeSH terms and their synonyms was filtered by inverse document frequency (IDF). Terms with IDF &lt; 1.2 were considered overly common and predicted to create too much noise, thereby causing irrelevant documents to be returned in the ranked list. Terms comprised of more than one word such as "myocardial infarction" were ignored as Lemur's indexing functionality breaks on spaces when creating inverted lists. These lists of terms and their synonyms formed the initial queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Topic Sub-Classification and Query Expansion</head><p>Topics were already classified by diagnosis, test, or treatment. Yet, our system was heavily reliant on the MeSH on Demand and MetaMap APIs to detect relevant medical concepts. To reduce this dependence and increase the robustness of our keyword-based queries, we developed a sub-classification methodology to further expand queries as necessary.</p><p>The mean number of MeSH terms per query was then determined, ignoring synonyms. If a given query's number of terms was less than or equal to one-half the standard deviation from the mean, its corresponding topic was classified as a hard topic. Using the Stanford NLP parser, 7 nouns from the original topics were added to expand those queries. Duplicate terms already present in the queries were ignored. These nouns were also filtered by IDF and queried in MetaMap for synonym expansion and category filtering. The IDF threshold used varied according to the original size of the queries. For queries with an average number of terms less than or equal to one standard deviation from the mean, an IDF threshold of 0.7 was used.</p><p>Otherwise, a threshold of 1.1 was used. After filtering by IDF, a second layer of filtering was applied to the nouns using the classification blacklist or whitelist, as described above. All non-hard topics were not expanded to prevent introducing additional noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Query Learning Approach</head><p>A novel approach we implement in our methodology is that of allowing queries to learn from one another. We argue that if words are very common among queries, then their weights should be reduced. Such words are not likely specific enough to return highly relevant documents and are more likely to create additional noise, thereby introducing less relevant documents. After applying the topic classification and query expansion methodologies above, we built an index of the queries. The IDF of each query term was computed using the index of the queries. Terms with IDF &lt; threshold had their weight reduced in the final queries.</p><p>For example, certain symptoms such as fever and cough were very common among the topics. These symptoms are relevant to the diagnosis or pertinent clinical question, but they are also secondary symptoms to a large number of diseases. We believe it is more important to give greater weight to less common symptoms such as the presence of bilateral lung infiltrates, which gives greater confidence in diagnosing pneumonia.</p><p>While our runs that utilized this approach actually performed slightly worse than our other runs, we believe this may be due to the limitation of the topics rather than a limitation of the approach. We hypothesize that this approach may have greater effectiveness over a larger sample of topics or in a real-time application when used by health care professionals. As this is only the first year of the track and there were only 30 static topics present, the ability of queries to learn from one another may be limited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Negation Detection</head><p>The topics discuss both the presence and absence of symptoms. However, we observe that the documents to be retrieved more often discuss the symptoms present rather than symptoms that are not present. Consequently, we propose that the positive symptoms present in the topics have slightly greater importance. This can be illustrated by a simple example: The patient presented with abdominal pain but no fever. The MeSH terms detected to form the initial keyword query may be "abdominal pain" and "fever". However, to aid in diagnosing and treating the patient it is more relevant to read documents which primarily discuss patients experiencing abdominal pain rather than those patients experiencing fever. Yet, MeSH on Demand detects both positive and negative symptoms in the topics without discrimination. Thus, to decrease the probability of false positives, we reduced the weight of the MeSH terms and their synonyms that came from negated phrases. We utilized NegEx <ref type="bibr" coords="4,223.97,74.57,13.44,10.37" target="#b4">[4]</ref> to detect negated phrases in each topic. Any MeSH term mapping from the negated phrase had its weighting in the query reduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental Results</head><p>Table <ref type="table" coords="4,83.13,157.39,5.76,10.37">1</ref> presents our results compared to the median and max values obtained across all systems. Overall, our runs are fairly consistent with the median, with GuHSINeg, GuHSINegL, and GuHSNegProxL presenting a small improvement over the median for three of the four metrics.  <ref type="table" coords="4,83.75,331.03,4.25,9.94">1</ref>: Comparison of our approaches to the median result obtained across all TREC systems. The percent delta compared to the median is also shown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>The structured queries were written and formatted in Lemur Query Language. Unless otherwise specified, the weight of a given term = 1. Our five submitted automatic runs include various aggregations of the above methodologies and are summarized here: 5. GuHSNegProxL -Same as GuHSNegProxH, but query learning IDF threshold = 0.7 There were several topics for which the median and all five of our runs performed consistently poor: topics 3, 9, 18, 23, and 25 with P@10 ‚âà 0 and R-Prec ‚âà 0. Some generalizations regarding topics 3, 9, and 18 reveal a few limitations of our approach. Topics 3 and 9 were generally shorter and contained less technical, specific medical nouns. Thus the utility of MeSH on Demand, MetaMap and query expansion approaches to construct the base query was very limited. Topic 18 contained a lot of relevant information in numeric test results rather than in natural language. Our approach did not account for numeric text.</p><p>For topics 2, 5, 6, 7, 17, 24, and 29 all five of our runs generally outperformed the median for P@10 and R-Prec. These results suggest that the common features among our runs were successful for these topics. We observe that the queries corresponding to these topics were generally longer in length than our queries, due to strong performance of MeSH on Demand, MetaMap, and noun query expansion. The refinement of these queries by detecting negation and query proximity played less importance since there were enough medically specific keywords in the query to retrieve highly relevant documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>In our approach for the TREC 2014 Clinical Decision Support Track, we attempt to generate refined, medical keyword queries which accurately represent the provided topics: medical case reports written in natural language. Inferring from the topics for which our runs perform well, we recognize the importance of query length and robustness, which seemed to have more significant impact compared to our refinement strategies of negation detection and query learning. In future work, we would like to develop additional techniques to generate keywords from the topics before refining the queries with negation and query learning. Also, we would like to explore if query proximity learning can introduce greater improvements by utilizing a greater number of topics within a single year or queries spanning over multiple years of the track.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,72.02,422.04,88.27,10.37;4,90.02,435.36,135.95,10.37;4,90.02,448.56,204.92,10.37;4,90.02,461.76,189.50,10.37;4,90.02,474.96,331.93,10.37;4,72.02,494.16,69.72,10.37;4,90.02,507.48,135.95,10.37;4,90.02,520.68,204.92,10.37;4,90.02,533.88,358.73,10.37;4,90.02,547.08,189.50,10.37;4,72.02,566.28,76.75,10.37;4,90.02,579.60,262.98,10.37;4,72.02,598.83,95.91,10.37;4,90.02,612.03,135.95,10.37;4,90.02,625.23,204.92,10.37;4,90.02,638.43,358.39,10.37;4,90.02,651.75,189.50,10.37;4,90.02,664.95,337.87,10.37"><head></head><label></label><figDesc>and Query Expansion -NegEx (weight of negated terms = 0.5) -Query Learning (IDF threshold = 0.7; weight of common terms = 0.7) 2. GuHSINeg -Medical Concept Detection -Topic Classification and Query Expansion -Second level stricter filtering of MetaMap classifications using the whitelist -NegEx (weight of negated terms = 0.5) 3. GuHSINegL -Same as GuHSINeg, but weight of negated terms = 0.3 4. GuHSNegProxH -Medical Concept Detection -Topic Classification and Query Expansion -Second level stricter filtering of MetaMap classifications using the whitelist -NegEx (weight of negated terms = 0.5) -Query Learning (IDF threshold = 0.78; weight of common terms = 0.7)</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,59.76,584.30,117.60,8.96"><p>http://www.lemurproject.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,59.76,595.82,213.54,8.96"><p>http://www.nlm.nih.gov/mesh/MeSHonDemand.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,59.76,607.34,150.82,8.96"><p>http://ii.nlm.nih.gov/MTI/index.shtml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,59.76,618.86,113.90,8.96"><p>http://metamap.nlm.nih.gov/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="2,59.76,630.26,481.87,8.96;2,54.00,641.78,484.54,8.96;2,54.00,653.30,328.33,8.96"><p>Blacklist (remove these categories): geographic area, population group, activity, human, &lt;string&gt; activity, human rights, occupation or discipline, functional concept, bird, temporal concept, intellectual product, profession or occupation group, quantitative concept, qualitative concept, manufactured object, food, family group</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="2,59.76,664.82,497.38,8.96;2,54.00,676.34,492.35,8.96;2,54.00,687.85,488.60,8.96;2,54.00,699.25,458.37,8.96;2,54.00,710.77,154.02,8.96"><p>Whitelist (keep these categories): Amino Acid, Peptide, or Protein, Biologically Active Substance; Anatomical abnormality; Body Location or Region; Body Part, Organ, or Organ Component; Body System; Cell; Disease or Syndrome; Health Care Activity; Injury or poisoning; Finding; Laboratory procedure; Medical Device; Mental or Behavioral Dysfunction; Mental Process; Neoplastic Process; Organic chemical; Pathologic function; Pharmacologic Substance; Sign or Symptom; Therapeutic or Preventative Procedure</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5.">Acknowledgements</head><p>The research is supported by <rs type="funder">NSF</rs> grant <rs type="grantNumber">CNS-1223825</rs> and <rs type="funder">DARPA</rs> <rs type="programName">Memex program</rs>. This material is based on research sponsored by <rs type="funder">DARPA</rs> under agreement number <rs type="grantNumber">FA8750-14-2-0226</rs>. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_HqGmmMS">
					<idno type="grant-number">CNS-1223825</idno>
				</org>
				<org type="funding" xml:id="_52aNeeh">
					<orgName type="program" subtype="full">Memex program</orgName>
				</org>
				<org type="funding" xml:id="_wsQ63pV">
					<idno type="grant-number">FA8750-14-2-0226</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,59.30,558.32,81.05,12.64" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,58.32,587.43,487.70,10.37;5,72.02,600.75,367.60,10.37" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,537.70,587.43,8.32,10.37;5,72.02,600.75,272.52,10.37">A taxonomy of generic clinical questions: classification study</title>
		<author>
			<persName coords=""><forename type="first">Ely</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Osheroff</forename><surname>Jerome</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gormanpaul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ebell</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Chambliss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pifer</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,347.59,600.75,42.59,10.37">BMJ</title>
		<imprint>
			<biblScope unit="volume">321</biblScope>
			<biblScope unit="page">429</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,58.32,613.95,341.31,10.37" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,127.41,613.95,206.02,10.37">Viewing morphology as an inference process</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Krovetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,340.96,613.95,29.87,10.37">SIGIR</title>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,58.32,627.15,482.50,10.37;5,72.02,640.35,107.21,10.37" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="5,269.62,627.15,221.01,10.37">Search engines: Information retrieval in practice</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Addison-Wesley Reading</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,58.32,653.55,469.85,10.37;5,72.02,666.87,457.52,10.37" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,422.47,653.55,105.70,10.37;5,72.02,666.87,298.81,10.37">A simple algorithm for identifying negated findings and diseases in discharge summaries</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">W</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Bridewell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">G</forename><surname>Buchanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,379.03,666.87,81.39,10.37">J Biomed Inform</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="301" to="310" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
