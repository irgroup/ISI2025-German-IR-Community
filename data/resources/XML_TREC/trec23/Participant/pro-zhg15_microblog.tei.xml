<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,111.98,76.00,388.14,14.36">University of Pittsburgh at TREC 2014 Microblog Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,191.45,105.64,49.06,9.94"><forename type="first">Zheng</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science</orgName>
								<orgName type="institution">University of Pittsburgh</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,365.71,105.64,29.11,9.94"><forename type="first">Rui</forename><surname>Bi</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Information Science</orgName>
								<orgName type="institution">University of Pittsburgh</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,111.98,76.00,388.14,14.36">University of Pittsburgh at TREC 2014 Microblog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4E6C1FF276324B99CF5395F302674D3A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information retrieval</term>
					<term>query expansion</term>
					<term>Google result</term>
					<term>document expansion</term>
					<term>BM25</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>An ad hoc retrieval task aims at return the most relevant documents based on a particular query. And high precision and recall always depends on clear query and elaborative documents. If the query is ambiguous while document is short and general, common retrieval models may not work well on the feedback. In this way, more expansive information will be needed to add in order to implement original queries and documents. That is the main purpose of microblog track of 2014 TREC Conference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The paper describes the first participation of</head><p>University of Pittsburgh in 2014 TREC microblog track. The data is based on tweet collection which gathered in 2013. We got two runs for the final results which are base on BM25 feedback algorithm. The details of our retrieval model include query expansion, document expansion and retrieval model for the final rank.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction:</head><p>The corpus of TREC 2014 microblog track is the same as the corpus used in 2013. It is much larger than the tweet collection used in 2011 and 2012. Approximately, the corpus includes almost 260 million tweets within a two month period ( 2/1/2013 -3/31/2013 inclusive ). And we can obtain the whole collection through official API however we can only get 10 thousand relevant tweets for a particular query. The tweets' information is encoded in json format which includes tweet id, screen name, text and retweeted information, etc. Under this condition, our goal seems simple : re-rank the 10 thousand tweets through our own retrieval method to modify original results. We divided the whole task into three sub divisions: query expansion, document expansion and feedback retrieval model.</p><p>For the query expansion, there are many ways to implement query items, such as wordNet, Google search API, Bing search API and Yahoo Boss search API, etc. In the end, after several trials, we decided to use Google search results as our main method to expand query instead of other kinds of APIs.</p><p>As for document expansion. Because tweets are always short documents and can't more than 140 words, we chose two ways to get document expansion: implement original tweets with its most relevant tweets and crawl its affiliated link as another implementation of tweet documents.</p><p>Because affiliated links always related to the tweet content, it is always regarded as introduction and spread of the original tweet.</p><p>For the feedback retrieval model, there are many retrieval models to use, including boolean retrieval model, vector space model and language model. After compared the results with different kinds of model, we decided to use BM25 as the main retrieval method because it is more accurate to generate related results based on our whole retrieval system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System Designï¼š</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Data Preparation</head><p>We download twitter-tools-core 1 project from github, and then when turn it into maven project. We find we can only use command to get the tweet result. Then we modify the java code so that we can use IDE to deal with it. We then decide use eclipse as our IDE and java as programming language to finish the task. After we import the project to eclipse and test the baseline result of former year, we start to use new query set to retrieve tweet ranking lists. For each query, we can get a ranking list with 10,000 tweets. The information of the tweet include 13 items. We extract id, text as most useful information for retrieval model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Query Expansion</head><p>In this part, we have considered several ways to expand query such as WordNet or Google search API. However, after we do several trials, we find another way that is not only more accurate but also easier to handle for query expansion, which is key words extracted from Google results.</p><p>1 https://github.com/lintool/twitter-tools After we choose a particular query, we use it to get the first 10 Google result pages. Then we crawl these pages, extract their main contents as final documents. And using tf*idf method to rank the weight of each word in these 10 documents. After several experiments for considering the amount of words as query expansion, we find that 10 keywords are enough to support the query. So in the end, we choose the first 10 words ranking in tf*idf retrieval lists besides original words of query itself as the query expansion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Document Expansion</head><p>As tweets are short documents(A recent study in Harvard shows that the average words per tweet is 15 words ), if we use usual retrieval method, it will lose accuracy. For example, if the query is " Ron Weasley birthday" while a tweet's content is just " ron weasley! ron weasley! ron weasley! ron weasley!", the tweet will rank high under usual retrieval model, but this tweet doesn't match the query well because it doesn't contain the main word "birthday". To avoid this condition, we need to document expansion.</p><p>We divide the expansion into two parts. One part is 100 related tweets and the other part is affiliated link.</p><p>Due to the short length of a tweet, a way to increase its length is to add related tweets' content to it. Based on former research, we choose the top 100 related tweets for each tweets as tweet expansion.</p><p>Based on former research, we find if a tweet contains a link at the end of itself, the link can shows more information related to query. In this way, the tweet should weight higher in the final ranking list. So if a tweet contains a link at the end, we crawl the content of the link and then regard it as link expansion.</p><p>We count these two expansion together with different weight, and re-rank the 10,000 expanded tweets by using BM25 method, then we get the final ranking list as results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Design of Approach</head><p>The approach contains several steps. First of all, the query set offered by TREC Conference has 55 different queries. We divided these queries and get their related tweets separately. And then we deal with individual query through the following steps. The graph showed below is an overview of the whole procedure.</p><p>First thing is to deal with query. We crawl Google result page of a particular query and get the first 10 Google results. Then we crawl the then Google result pages and extract their main contents and filter stop words. After this step, each query get 10 Google result pages' content. We regard each page as a document and use tfidf weight method to get the first 10 words which are not appeared in the query. We add the 10 words to the original query and then the new query forms expanded query. We have checked the results of our way and of Google API manually and we find by using our way can get more accurate and related words for the original query.</p><p>We use q to denote a query and use t to denote a term in a query. The frequency of term t in a document d is denoted by f(t,d). And tf(t,d) is regarded as the term frequency of t in d. D means the whole documents in the collection c.</p><p>And N means the number of D. So the algorithm is defined as below:</p><p>As for the original 10,000 tweets, we need to do refinement on these original tweets. First of all, we filter all retweets and non-English tweets.</p><p>And then, we use Lucene to build index with stemming and filtering stop words. Then we use the index and vector space model to generate each tweet's related tweet ranking list. We choose the first 100 tweets out of 9,999 tweets and regard them as related. We add the content of 100 tweets to the original tweet to form tweet expansion. We denote ( ) as the current model. The algorithm of vector space model is defined below:</p><p>For the link expansion part, we first process the original tweet. If a tweet contains a link at the end of itself, we extract the link, crawl its web page and get the main content as link expansion of a tweet.</p><p>In the end, we get two sub-divisions for tweet document expansion: link expansion and tweet expansion.</p><p>The next step is to build index for queries. We use each tweet document expansion result as a document. Both link expansion result and tweet expansion result are regarded as a field of a document. We store the two filed in a document and then build index. We use and to judge the weight of tweet expansion and link expansion in the final retrieval model. We denote to link expansion and to tweet expansion. And the model is defined below.</p><p>For the retrieval model , after we considered several classic models, we decided to use a vector space model BM25 as our final feedback algorithm because it has better recall and precision when compared to other method we considered. And it runs faster to get the result than other method in our project. We have 2 runs in the final project and both of them use the same retrieval model with different weight. For the first run Upitt, we set and , while the other run NewBee is and . We set the different weight because both of them give a good feedback while we don't how much affiliated link weighs for the final official evaluation.</p><p>Based on classic BM25 algorithm, we set . And we denote to average length of a document in the whole collection.</p><p>Finally, we use the expanded query to match the 10,000 expanded documents, and generate final ranking list as final result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results:</head><p>Based on our retrieval model, we have 2 runs in the final. The feedback results are listed below: Run R-Prec MAP P @ 30 UPitt 0.2020 0.1648 0.4164 NewBee 0.3176 0.2745 0.4485</p><p>The statistics in the Ad-hoc runs column are computed over all 77 ad-hoc runs that were submitted to the track. The statistics in Automatic ad-hoc runs column are computed over only the 73 automatic ad-hoc runs. In the task, we mainly use R-Precision, average precision and P@30 to evaluate the results. Judgment pools are created using depth 100 across all submitted ad-hoc runs, plus a random selection of 100 documents per topic from each TTG run. These pools are further reduced by removing retweets (declared irrelevant by track fiat) and then clustered so that textually similar tweets are close to one another (a step taken to enhance judgment consistency). Tweets are judged on a three-way scale of not relevant, relevant, and highly relevant (represented as 0, 1, and 2 respectively in the judgment file). The judgment file, qrels2014.txt, is posted on the tracks page in the active participants' section of the TREC web site. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion:</head><p>Our system uses query expansion and document expansion to enlarge the size of each document in order to get a more clear sense of document. By using Google result to extract key words as expanded query as well as finding relevant tweets and crawling related links as expanded documents. We finally realize the goal of generating better feedback result for a specific query based on tweet collection. However, There are still some flaws in our retrieval system. First of all, it is not easy to consider some particular characters in queries. For example there is a query " Mad Men season 6 ". For the number"6", it is really hard to be considered in retrieval system. Moreover, the retrieval model is just simply used classic model BM25, we don't modify it for the particular task.</p><p>In the future, we can improve the retrieval model in order to be more suitable for the particular task. And another flow is that when we extract main content from a web page, we create our own method to realize it. After finishing the task, we find by using Boilerpipe library we can get better result for extracting main content of a web page.</p></div>		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,76.16,443.61,211.98,9.94;5,72.02,456.21,216.09,9.94;5,72.02,468.93,216.05,9.94;5,72.02,481.53,53.04,9.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,252.41,443.61,35.74,9.94;5,72.02,456.21,216.09,9.94;5,72.02,468.93,194.28,9.94">A Userin-the-Loop Process for Investigational Search: Foreseer in TREC 2013 Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,72.02,481.53,23.57,9.94">TREC</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,76.16,506.25,211.98,9.94;5,72.02,518.85,216.17,9.94;5,72.02,531.45,122.03,9.94" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="5,138.38,518.85,149.81,9.94;5,72.02,531.45,49.51,9.94">ICTCENT at Microblog Track in TREC 2013</title>
		<author>
			<persName coords=""><forename type="first">Jinhua</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guoxin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shenghua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">TREC</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,76.16,556.17,211.97,9.94;5,72.02,568.77,216.13,9.94;5,72.02,581.52,216.05,9.94;5,72.02,594.12,53.04,9.94" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,181.37,568.77,106.78,9.94;5,72.02,581.52,193.48,9.94">TREC 2013 Microblog Track Experiments at Kobe University</title>
		<author>
			<persName coords=""><forename type="first">Taiki</forename><surname>Miyanishi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sayaka</forename><surname>Kitaguchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kazuhiro</forename><surname>Seki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kuniaki</forename><surname>Uehara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,72.02,594.12,23.57,9.94">TREC</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,76.16,618.72,211.79,9.94;5,72.02,631.44,216.14,9.94;5,72.02,644.04,145.19,9.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,191.69,631.44,96.48,9.94;5,72.02,644.04,73.02,9.94">BJUT at TREC 2013 Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">Zhen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guangyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shuyong</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yingxu</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kefeng</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,164.30,644.04,23.52,9.94">TREC</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,76.16,668.76,212.00,9.94;5,72.02,681.36,216.01,9.94" xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hell-Mann</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.02,693.96,216.12,9.94;5,72.02,706.68,178.11,9.94" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,72.02,693.96,216.12,9.94;5,72.02,706.68,17.95,9.94">Dbpedia -a crystallization point for the web of data</title>
	</analytic>
	<monogr>
		<title level="j" coord="5,97.10,706.68,57.22,9.94">Web Semant</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="154" to="165" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,328.21,74.42,212.00,9.94;5,324.07,87.04,216.14,9.94;5,324.07,99.76,216.14,9.94;5,324.07,112.36,216.15,9.94;5,324.07,125.08,216.13,9.94;5,324.07,137.68,172.44,9.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,324.07,87.04,216.14,9.94;5,324.07,99.76,106.20,9.94">#twittersearch: a comparison of microblog search and web search</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Teevan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,453.94,99.76,86.27,9.94;5,324.07,112.36,216.15,9.94;5,324.07,125.08,163.77,9.94">Proceedings of the fourth ACM international conference on Web search and data mining, WSDM &apos;11</title>
		<meeting>the fourth ACM international conference on Web search and data mining, WSDM &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="35" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,328.21,162.28,212.03,9.94;5,324.07,175.00,216.10,9.94;5,324.07,187.60,216.14,9.94;5,324.07,200.32,216.14,9.94;5,324.07,212.92,216.17,9.94;5,324.07,225.52,189.27,9.94" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,499.80,175.00,40.37,9.94;5,324.07,187.60,216.14,9.94;5,324.07,200.32,77.11,9.94">Twitinfo: aggregating and visualizing microblogs for event exploration</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Badar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Karger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">C</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,424.30,200.32,115.91,9.94;5,324.07,212.92,216.17,9.94;5,324.07,225.52,86.61,9.94">Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the ACM SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="227" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,328.21,250.27,189.43,9.94;5,324.07,262.87,200.59,9.94;5,324.07,275.59,202.61,9.94;5,324.07,288.19,191.04,9.94;5,324.07,300.91,157.69,9.94;5,324.07,313.51,203.13,9.94;5,324.07,326.11,143.91,9.94" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,376.75,262.87,147.91,9.94;5,324.07,275.59,186.25,9.94">Toward whole-session relevance: Exploring intrinsic diversity in web search</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Collins-Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,324.07,288.19,191.04,9.94;5,324.07,300.91,157.69,9.94;5,324.07,313.51,203.13,9.94;5,324.07,326.11,11.70,9.94">Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;13</title>
		<meeting>the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;13</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="463" to="472" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
