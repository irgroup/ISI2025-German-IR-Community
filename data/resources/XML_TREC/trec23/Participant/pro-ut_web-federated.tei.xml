<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,129.93,164.85,351.40,15.12;1,239.29,190.36,132.66,10.48">Two selfless contributions to web search evaluation U. Twente at TREC 2014</title>
				<funder ref="#_qgnHz2d">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder>
					<orgName type="full">Dutch national program</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,221.22,219.25,85.41,10.48"><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
							<email>d.hiemstra@utwente.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Twente</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,333.29,219.25,52.83,10.48"><forename type="first">Robin</forename><surname>Aly</surname></persName>
							<email>r.aly@utwente.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Twente</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,129.93,164.85,351.40,15.12;1,239.29,190.36,132.66,10.48">Two selfless contributions to web search evaluation U. Twente at TREC 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4C28B3FDDD1EBDC0D311B75AA6A3E1ED</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present our results for the Web Search track and the Federated Web Search track for the 23rd Text Retrieval Conference TREC.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we describe the contributions from the University of Twente to the 23rd Text Retrieval Conference. We participate in the Web Track and the Federated Web Track. Our experiments are run by MIREX <ref type="bibr" coords="1,403.38,395.74,10.52,8.74" target="#b1">[2]</ref> <ref type="foot" coords="1,413.90,394.17,3.97,6.12" target="#foot_0">1</ref> (MapReduce Information Retrieval Experiments), a library of MapReduce programs to extract data and sequentially scan document representations. Built on Hadoop, sequential scanning becomes a viable approach. MIREX allows researchers to easily experiment with different retrieval models, because the framework is easy to extend. The paper is structured as follows: Section 2 describes our participation in the web track and Section 3 describes our participation in the Federated Web track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Web Track Participation</head><p>The Web track models a general web search scenario, with ad hoc queries on the ClueWeb12 web collection, i.e., we investigate the performance of approaches that search a static set of documents using previously-unseen topics.</p><p>Table <ref type="table" coords="1,177.69,570.06,4.98,8.74">1</ref> shows the precision at 5, 10 and 20 results of the three official Web Track runs. The runs tagged utbase and utexact use anchor texts as document representations, which we made available for download. <ref type="foot" coords="1,427.53,592.40,3.97,6.12" target="#foot_1">2</ref> The first run, tagged utexact, matches the exact query string to the anchors, and ranks the documents by the number of exact matches found. The run finds exact matches for 40 out of 50 queries. We appended the results from the second Run P@5 P@10 P@20 utexact 0. run, i.e. those documents that were not already found by exact matches, to the run as the final result. The second run, tagged utbase, uses a simple unigram language model with linear interpolation smoothing, λ = 0.95, and a document length prior. A run without smoothing (or λ = 1) retrieves the exact same top 10 documents for 45 out of 50 queries, and therefore also achieves the same precision at 5 and 10 documents. The third run, tagged utold, uses the same ranking as the second run on the full text of the web pages.</p><p>The experimental results show that utexact, exact matching of the full query string on the anchors, outperforms the other runs for precicion at 5 documents retrieved, whereas utold, the language model on the full text, performs best at precision at 10. Interestingly, we expected the full text run to perform much worse, because the anchor runs use a document length prior (the more anchor text, the better), that has a similar effect as an inlinks prior (also similar to PageRank). Table <ref type="table" coords="2,177.07,497.37,4.98,8.74" target="#tab_1">2</ref> shows the ability of the systems to retrieve documents judged as highly relevant, key, or navigational. So, documents judged as relevant were not considered in this evaluation. The results show that clearly, the exact query string matching favours highly relevant documents for 5 documents retrieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>J@10 J@20 J@30 utbase 1.000 All runs were pooled to depth 20 this year, an improvement over last year's TREC when for many topics, less than 20 documents per topic were judged, because the pool depth of 20 would have resulted in too many documents to be judged in the allotted amount of assessing time. Table <ref type="table" coords="3,370.53,139.92,4.98,8.74" target="#tab_2">3</ref> shows the effects of the pool depth of the fraction of judged documents for each run. The run utold was not part of the pool that was judged. Of the runs that contributed to the pool, at 30 documents retrieved, about 10 % of the documents is not judged. Last year, at 30 documents retrieved, judged fractions dropped between 22 % and 25 %. So, TREC seems to have done a better job judging documents this year, at least for our runs. Table <ref type="table" coords="3,177.03,361.37,4.98,8.74" target="#tab_3">4</ref> shows general statistics of the TREC 2013 and TREC 2014 Web Track collections. Of the total number of documents that are judged, more than 39 % were judged relevant, so it is likely that many more relevant documents would have been found if more resources would have been available for judging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Qrels</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">FedWeb Track Participation</head><p>The Federated Web Track models a distributed search scenario where users send requests to a broker which forwards the requests to a set of search engines that are likely to produce relevant results. We participated in the resource selection task, which requires selecting resources based on resource descriptions, given a search request. The track provides sample texts and snippets form documents sampled from each search engine. Prior to resource selection, these documents have to be transformed into a resource description. Currently, resource descriptions based directly on the sampled documents in a central sample index are the most popular. However, this approach also requires substantial storage space and administrative overhead when selecting resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>ndcg@20 nP@1 nP@5 UTTailyG2000 Table <ref type="table" coords="4,175.99,127.96,4.98,8.74" target="#tab_4">5</ref> shows the official overall evaluation score of the run UTTailyG2000. Our run uses Taily <ref type="bibr" coords="4,218.34,139.92,9.96,8.74" target="#b0">[1]</ref>, an approach for shard selection which showed good performance in centralized search, and adapt it for federated web search. Instead of using a centralized sample index, Taily uses vocabulary-based resource descriptions based on statistics of term related features in each shard that are used in ranking functions. Compared to this centralized setting, the full collection is only represented by a sample and and the ranking function of each individual search engine is unknown. Taily assumes a gamma distribution for scores of a query, which is inferred from the feature statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We tried simple, out-of-the-box approaches to this year's Web track and Federated Web track, contributing documents to the evaluation pools, and evaluation results to the TREC report. We love TREC, and hope to be there next year with some more novel approaches to text search.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,207.68,405.19,195.89,67.05"><head>Table 2 :</head><label>2</label><figDesc>High Relevance Precision (49 queries)</figDesc><table coords="2,227.49,405.19,156.27,45.03"><row><cell></cell><cell>P@5</cell><cell cols="2">P@10 P@20</cell></row><row><cell>utbase</cell><cell>0.188</cell><cell>0.186</cell><cell>0.163</cell></row><row><cell>utexact</cell><cell>0.216</cell><cell>0.184</cell><cell>0.161</cell></row><row><cell>utold</cell><cell>0.200</cell><cell>0.190</cell><cell>0.171</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="2,197.72,567.75,215.80,54.77"><head>Table 3 :</head><label>3</label><figDesc>Fraction of judged documents (50 queries)</figDesc><table coords="2,231.31,567.75,146.84,32.76"><row><cell></cell><cell></cell><cell>1.000</cell><cell>0.904</cell></row><row><cell>utexact</cell><cell>1.000</cell><cell>1.000</cell><cell>0.907</cell></row><row><cell>utold</cell><cell>0.910</cell><cell>0.842</cell><cell>0.789</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,162.79,233.88,285.67,102.36"><head>Table 4 :</head><label>4</label><figDesc>Number of documents judged</figDesc><table coords="3,162.79,233.88,285.67,80.90"><row><cell></cell><cell>total</cell><cell>per query</cell><cell>total</cell><cell>per query</cell></row><row><cell></cell><cell>in 2013</cell><cell>in 2013</cell><cell>in 2014</cell><cell>in 2014</cell></row><row><cell>all judged</cell><cell>14474</cell><cell>290</cell><cell>14432</cell><cell>289</cell></row><row><cell>highly rel. (&gt; 1)</cell><cell>1106</cell><cell>22</cell><cell>1877</cell><cell>38</cell></row><row><cell>relevant (&gt; 0)</cell><cell>4150</cell><cell>83</cell><cell>5665</cell><cell>113</cell></row><row><cell>irrelevant (= 0)</cell><cell>10090</cell><cell>202</cell><cell>8210</cell><cell>164</cell></row><row><cell>spam (= -2)</cell><cell>234</cell><cell>5</cell><cell>1614</cell><cell>32</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="3,133.77,594.11,343.71,66.18"><head>Table 5 :</head><label>5</label><figDesc>Official FedWeb Resource Selection results. Median and maximum performance shown for comparison.</figDesc><table coords="3,184.80,594.11,238.58,32.76"><row><cell></cell><cell>0.178</cell><cell>0.142</cell><cell>0.223</cell></row><row><cell>Median Performance</cell><cell>0.182</cell><cell>0.202</cell><cell>0.250</cell></row><row><cell>Maximum Performance</cell><cell>0.460</cell><cell>0.534</cell><cell>0.601</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,149.01,648.77,105.21,6.99"><p>http://mirex.sourceforge.net</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,149.01,658.27,278.39,6.99"><p>http://www.cs.utwente.nl/∼hiemstra/2013/anchor-text-for-clueweb12.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We are grateful to the <rs type="funder">European Union</rs> Project <rs type="projectName">AXES</rs> (<rs type="grantNumber">FP7-269980</rs>) and the <rs type="funder">Dutch national program</rs> COMMIT for funding our work.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_qgnHz2d">
					<idno type="grant-number">FP7-269980</idno>
					<orgName type="project" subtype="full">AXES</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,149.27,435.72,328.22,8.74;4,149.27,447.68,328.21,8.74;4,149.27,459.63,328.21,8.74;4,149.27,471.59,90.83,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,336.25,435.72,141.23,8.74;4,149.27,447.68,111.00,8.74">Taily: shard selection using the tail of score distributions</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Aly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Demeester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,285.75,447.68,191.73,8.74;4,149.27,459.63,324.37,8.74">Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 36th international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="673" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,149.27,491.51,328.21,8.74;4,149.27,503.47,328.22,8.74;4,149.27,515.42,328.21,8.74;4,149.27,527.38,154.56,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,270.24,491.51,207.23,8.74;4,149.27,503.47,176.50,8.74">Mapreduce for information retrieval evaluation: &quot;let&apos;s quickly test this on 12 TB of data</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hauff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,353.23,503.47,124.25,8.74;4,149.27,515.42,133.63,8.74">Multilingual and Multimodal Information Access Evaluation</title>
		<title level="s" coord="4,291.97,515.42,158.47,8.74">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6360</biblScope>
			<biblScope unit="page" from="64" to="69" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
