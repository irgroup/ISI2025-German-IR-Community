<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,126.06,81.73,343.18,16.20;1,224.29,112.92,146.74,16.20">BUPT_PRIS at TREC 2014 Knowledge Base Acceleration Track</title>
				<funder ref="#_kUFXFc4">
					<orgName type="full">111 Project of China</orgName>
				</funder>
				<funder ref="#_6CJxSy4">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_QAS6kUg">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_7sZS3Ay">
					<orgName type="full">Ph.D. Programs Foundation of Ministry of Education of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,180.12,138.26,61.00,10.80"><forename type="first">Yuanyuan</forename><surname>Qi</surname></persName>
							<email>qiyuanyuan@bupt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligence System</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,248.70,138.26,27.54,10.80"><forename type="first">Ye</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligence System</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,285.12,138.26,69.69,10.80"><forename type="first">Dongxu</forename><surname>Zhang</surname></persName>
							<email>zhangdongxuu@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligence System</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,363.24,138.26,51.96,10.80"><forename type="first">Weiran</forename><surname>Xu</surname></persName>
							<email>xuweiran@bupt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligence System</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,126.06,81.73,343.18,16.20;1,224.29,112.92,146.74,16.20">BUPT_PRIS at TREC 2014 Knowledge Base Acceleration Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2C15E6326B1C76FC048616C3392E61C1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the system in Vital Filtering and Streaming Slot Filling task of TREC 2014 Knowledge Base Acceleration Track. In the Vital Filtering task, The PRIS system focuses attention on query expansion and similarity calculation. The system uses DBpedia as external source data to do query expansion and generates directional documents to calculate similarities with candidate worth citing documents. In the Streaming Slot Filling task, The BUPT_PRIS system utilizes a pattern learning method to do relation extraction and slot filling. Patterns of regular slots which mostly are same to TAC-KBP slots are learned from KBP Slot Filling corpus. Other slots are manually picked up some training seeds for those slot types that KBP didn't contain to use bootstrapping method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of KBA track is filtering a large stream of text to find documents that can help update a knowledge base like Wikipedia. The KBA2014 includes three tasks: Vital Filtering(VF) task ,Streaming Slot Filling task and Accelerate &amp; Create. The third task is new open track which is not evaluated. For the Vital Filtering task, given a fixed list of target entities from Wikipedia and Twitter, systems should filter documents worth citing in a profile of the entity. For the Streaming Slot Filling task, given a slot for each of the target entities, systems should detect changes to the slot value, such as location of next performance or founder of an organization. Our team participated in Vital Filtering and Streaming Slot Filling tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Vital Filtering</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">System Overview</head><p>The Vital Filtering (VF) system focuses attention on query expansion, feature generation and vital classification. The framework of our system is shown in Figure <ref type="figure" coords="1,145.56,731.06,4.50,10.80">1</ref>.</p><p>Figure <ref type="figure" coords="2,207.66,309.86,6.00,10.80">1</ref> the framework of PRIS system for VF task First of all, we decompress the corpus and filter the field what we are interested in. Then we indexed the data we have filtered with ElasticSearch. The purpose of indexing is to make it convenient for our algorithms. At the same time we expand the entities with the DBpedia and wiki, then we used the training set to train a classifier,the input is the features we have extracted from the documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query Expansion</head><p>For each entity, the system chooses values of property name and values of property label as expansion terms from the corresponding DBpedia page and label these terms as Name and Label respectively; If the entity doesn't have a DBpedia page, the system chooses alternative names and the link of homepage as expansion terms from the corresponding twitter page and then visits the homepage to extract key words of homepages as expansion terms too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Feature Extraction</head><p>To present the document, we extract 10 features of one document as follows: 1.number of target name of an entity; 2.number of redirect name of an entity; 3.number of category of an entity; 4.number of target name in one document; 5.number of redirect name in one document; 6.number of category in one document; 7.An entity's first mention place in the document; 8. An entity's last mention place in the document; 9.length of a document; 10.the cosine similarity of the document and the mean value of related documents of an entity.. The first nine features are calculated directly. The 10th feature is calculated as formula 1 <ref type="bibr" coords="2,158.70,697.09,3.99,7.18" target="#b0">1</ref> 1 Formula 1 is the document is the mean value of all the related documents in the training set represented by the 10 features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Classify</head><p>We treat the task as a classify task, so we use three different ways to classify the vital documents: 1. Support Vector Machine (SVM); 2. Random Forest (RF); 3. K-Nearest Neighbor (KNN) and submit all the results generated by the 3 ways. In the Random Forest way, we set the number of trees is 10, and in the KNN way, we make the k=5;</p><p>3 Stream Slot Filling</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">System overview</head><p>For the Streaming Slot Filling task, our system achieved the goal of filling slots by employing a pattern learning and matching method. This automatic slot filling system contains three steps. First, with query expansion and coreference resolution, we found relative sentences (to make the search faster, we built index using ElasticSearch). Second, we found patterns of slots which are same to TAC-KBP by using KBP training data, and then used bootstrapping method with only single iteration to recall more patterns and also make patterns suit for KBA corpus. Finally, we generated slot answers by matching the patterns and ranking the candidate answers by scoring them with the patterns it was matched. Specially, we manually picked up some training seeds for those slot types that KBP didn't contain to use bootstrapping method. And there are also some rules found manually such as PER_GENDER, PER_CONTACT, PER_EMAIL, ORG_CONTACT. The system overview is shown in Fig. <ref type="figure" coords="3,293.18,465.86,4.67,10.80" target="#fig_0">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Find Seed Pattern</head><p>We had to find different patterns for those 52 slots separately. Fortunately, we could get training data, formed by sentences with specific query and slot value, for those slots which are in the TAC-KBP slot filling task. For the last several slots, we just collected some training data manually. Then, we used Stanford Parser toolkit to parse each sentence and matched query and slot value on the dependency tree of the sentence. After finding these two nodes, we extracted the path connecting them combined with the entity types of two nodes as our pattern. Notice that we jointed query and slot value which contained more than one word using an underscore so that those words would become only one node on the tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Bootstrapping for More Pattern</head><p>After gathering pattern seeds, we expanded them on KBA corpus using bootstrapping method so that we could get more patterns to improve the recall and also make our patterns suit for KBA corpus better. Due to unbearable computing time, we only took around 10GB clean text from the official corpus for dependency tree parsing, and implemented bootstrapping method for only one iteration concerning the semantic drift. After gathering lots of patterns by bootstrapping, we pruned them by their frequency of occurrence and literal length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Pattern Matching</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Find Relative Sentence</head><p>For prediction task, firstly we had to find relative sentences mentioned our 109 queries. With trigger words we obtained from task 1 and the coreference resolution information officially supplied, we could search for relative sentences, which we believed would contain most of the answers. Notice that we built an index to speed up our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Pattern Matching and scoring</head><p>After found those relative sentences and parsed them with Stanford Parser, we could match queries (or alias) and the specific entity type. If both query and slot entity type existed, we would extract the dependency tree path between them and matched that path with our pattern. Then if that path existed in pattern list relative to the entity type, we should add the slot value into our candidate set with the length of the pattern as a weight. After travel through all the relative sentences, we scored those candidates by summing their weights and set a threshold to limit the untrustworthy answers.</p><p>Table <ref type="table" coords="5,143.10,107.06,6.00,10.80">1</ref> shows the retrieval performance of our submitted four runs for vital filtering task with useful and vital documents. The primary evaluation metrics for this year's vital filtering are P(precision),R(recall),F(F-measure) and SU(Scaled Utility).Among all the runs, Run 1 uses the original query without any expansion to search the corpus and submit the retrieval documents. Run 2 uses nonlinear SVM which uses radial basis function as the kernel function. Run 3 uses random forest and with the setting of number of tree is 10. Run 4 uses K-Nearest Neighbor and set the K=5.</p><p>We can see from the table that runs using nonlinear SVM have better retrieval performance than others.</p><p>Table <ref type="table" coords="5,172.92,263.06,6.00,10.80">1</ref> The performance of submitted runs with useful included   In this paper, we present our systems for TREC 2014 Knowledge Base Acceleration Track. In the vital filtering task, we apply some traditional classification methods i.e. SVM, random forest , we focus on find ten features to classification to classify big data but we should notice the novel information of documents. In the SSF task, we apply bootstrapping method to find more pattern to find more relative documents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,213.72,747.15,167.85,9.45;3,152.64,509.64,340.15,232.75"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. The system overview of SSF task</figDesc><graphic coords="3,152.64,509.64,340.15,232.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="2,179.95,76.25,235.95,226.05"><head></head><label></label><figDesc></figDesc><graphic coords="2,179.95,76.25,235.95,226.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,95.64,359.66,409.66,153.94"><head>Table 2</head><label>2</label><figDesc>shows the retrieval performance of our submitted four runs for vital filtering task with only vital documents.We can see from the table that runs using random forest have better retrieval performance than others.Table2The performance of submitted runs with vital only</figDesc><table coords="5,95.64,439.04,381.16,74.56"><row><cell></cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>SU</cell></row><row><cell>Run 1</cell><cell>0.185</cell><cell>0.907</cell><cell>0.307</cell><cell>0.000</cell></row><row><cell>Run 2</cell><cell>0.201</cell><cell>0.879</cell><cell>0.328</cell><cell>0.000</cell></row><row><cell>Run 3</cell><cell>0.245</cell><cell>0.836</cell><cell>0.380</cell><cell>0.034</cell></row><row><cell>Run 4</cell><cell>0.200</cell><cell>0.245</cell><cell>0.220</cell><cell>0.170</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,90.00,518.66,415.42,191.59"><head></head><label></label><figDesc>Table3shows the retrieval performance of our submitted two runs for Stream Slotting Filling task. The primary evaluation metrics for this year's Stream Slotting Filling are sokalsneath, cosine, dot and c_TT metrics. The difference between Run 1 and Run 2 is filtering the short patterns.We can see from the table that Run 2 which has less short pattern gets better retrieval performance than others.Table3the result of SSF with 4 metrics</figDesc><table coords="5,90.00,636.22,410.37,74.04"><row><cell></cell><cell>sokalsneath metric</cell><cell>cosine metric</cell><cell>dot metric</cell><cell>c_TT metric</cell></row><row><cell>Run 1</cell><cell>90.317</cell><cell>41.7237</cell><cell>601.000</cell><cell>380.000</cell></row><row><cell>Run 2</cell><cell>91.517</cell><cell>61.1207</cell><cell>782.000</cell><cell>481.000</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgments</head><p>The work reported in this paper was supported by <rs type="funder">111 Project of China</rs> under Grant No. <rs type="grantNumber">B08004</rs>, <rs type="projectName">key project of ministry of science and technology of China</rs> under Grant No. <rs type="grantNumber">2011ZX03002-005-01</rs>, <rs type="funder">National Natural Science Foundation of China</rs> (<rs type="grantNumber">61273217</rs>) and the <rs type="funder">Ph.D. Programs Foundation of Ministry of Education of China</rs> (<rs type="grantNumber">20130005110004</rs>)</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_kUFXFc4">
					<idno type="grant-number">B08004</idno>
					<orgName type="project" subtype="full">key project of ministry of science and technology of China</orgName>
				</org>
				<org type="funding" xml:id="_6CJxSy4">
					<idno type="grant-number">2011ZX03002-005-01</idno>
				</org>
				<org type="funding" xml:id="_7sZS3Ay">
					<idno type="grant-number">61273217</idno>
				</org>
				<org type="funding" xml:id="_QAS6kUg">
					<idno type="grant-number">20130005110004</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,152.34,372.26,353.04,10.80;6,111.24,387.86,394.02,10.80;6,111.24,403.46,337.80,10.80" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,111.24,403.46,218.15,10.80">Evaluating Stream Filtering for Entity Profile</title>
		<author>
			<persName coords=""><forename type="first">John</forename><forename type="middle">R</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Max</forename><surname>Kleiman-Weiner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Roberts ; Ce</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Soborof</surname></persName>
		</author>
		<idno>Updates for TREC 2013</idno>
	</analytic>
	<monogr>
		<title level="j" coord="6,111.24,387.86,101.04,10.80">Nilesh Tripuraneni</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,151.62,419.06,353.64,10.80;6,111.24,434.66,285.78,10.80;6,135.24,450.26,370.02,10.80;6,111.24,465.86,376.08,10.80" xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Yan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhaozhao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Baojin</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ruiyang</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weiran</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guang</forename><surname>Chen ; Chunyun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weiran</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ruifang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weitai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Janshu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ji</surname></persName>
		</author>
		<idno>Guo. PRIS at TREC2012 KBA</idno>
		<imprint>
			<date>Jun</date>
		</imprint>
	</monogr>
	<note>Jing Yang. PRIS at TREC2013 Knowledge Base Acceleration Track</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
