<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.43,115.96,328.50,12.62;1,243.46,133.89,128.43,12.62">University of Padua at TREC 2014: Federated Web Search Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,214.57,172.80,88.70,8.74"><forename type="first">Emanuele</forename><forename type="middle">Di</forename><surname>Buccio</surname></persName>
							<email>dibuccio@dei.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,325.95,172.80,74.84,8.74"><forename type="first">Massimo</forename><surname>Melucci</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.43,115.96,328.50,12.62;1,243.46,133.89,128.43,12.62">University of Padua at TREC 2014: Federated Web Search Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">80BB6CAB2679080B9AB34041846EA8D7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports on the participation of the University of Padua to the TREC 2014 Federated Web Search track. The objective was the experimental investigation of the TWF•IRF weighting framework for resource and vertical selection in Federated Web Search settings.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper reports on the participation of the Information Management System (IMS) Research Group of the University of Padua to the TREC 2014 Federated Web Search track (FedWeb14). <ref type="foot" coords="1,268.38,379.43,3.97,6.12" target="#foot_0">1</ref> The participation to the FedWeb14 track aimed at the investigation of the effectiveness of the TWF•IRF weighting framework when adopted in Federated Web search setting; in particular, the participation to the second edition of the track allowed us to complement the experimental investigation carried out last year when our focus was on the effectiveness of the weighting scheme for resource selection <ref type="bibr" coords="1,325.10,440.78,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="1,337.27,440.78,7.01,8.74" target="#b4">5]</ref>. In the resource selection task, given a set of search engines and a query, the objective is to select the most promising search engines to which the query will be forwarded.</p><p>In FedWeb14, a new test collection was adopted and a new task was added: vertical selection. This task considers an additional resource level, i.e. the vertical level, where a vertical is a subset of the entire set of search engines. The vertical level can be considered as a categorization of the set of search engines; examples of verticals are Academic, Jobs, and Video search engines. In FedWeb14, the set of verticals was a partition over the set of search engines -each resource was associated to one and only one vertical. The objective of the task was to select the most promising verticals to retrieve from. Once the most promising verticals have been selected, resource selection could be performed for each vertical, thus selecting the most promising search engines associated to the vertical.</p><p>The remainder of this paper is organized as follows. Section 2 briefly reviews the TWF•IRF weighting framework; Section 3 reports the research questions, the experimental methodology and the obtained results. Section 4 reports some final remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A Recursive Weighting Scheme</head><p>According to the literature on Distributed IR <ref type="bibr" coords="2,343.78,140.35,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="2,355.96,140.35,7.01,8.74" target="#b1">2]</ref>, the approach adopted in this work is to describe the informative resources at the diverse levels (document, search engines, verticals) in terms of document descriptors, e.g. terms. Therefore, a search engine is described by a set of document descriptors, specifically the distinct descriptors appearing in the documents stored in it; each vertical is described by the set of document descriptors used to describe the search engines associated to the vertical. The innovative contribution of our approach consists in the way of computing the weights of the descriptors.</p><p>The weight of a descriptor in a resource consists of two components: TWF and IRF. The Inverse Resource Frequency (IRF) is a generalization of the Inverse Document Frequency (IDF) for the higher resource levels. Generalizations of the IDF were proposed in <ref type="bibr" coords="2,230.99,271.85,10.52,8.74" target="#b0">[1]</ref> to rank collections (Inverse Collection Frequency, ICF) and in <ref type="bibr" coords="2,167.22,283.81,10.52,8.74" target="#b1">[2]</ref> to rank peers (Inverse Peer Frequency, IPF). The IRF extends this idea for an arbitrary resource level:</p><formula xml:id="formula_0" coords="2,260.44,312.73,220.15,13.74">irf (z) t = log N (z) /n (z) t (1)</formula><p>where t denotes the term, N (z) is the number of resources at level z contained by the resource at level z + 1 and n (z) t is the number of those resources that are indexed by t. The instantiation of IRF at level 1 results in the IDF; ICF and IPF are instances of the IRF weight at level 2. In the FedWeb14 settings there are four resource levels: (1) document, (2) search engines, (3) verticals, and (4) set of verticals.</p><p>Unlike IRF, Term Weighted Frequency (TWF) is peculiar to this scheme. The weight of a descriptor t in a resource i at level z is</p><formula xml:id="formula_1" coords="2,260.58,436.62,220.01,14.07">w (z) i,t = twf (z) i,t • irf (z) t ,<label>(2)</label></formula><p>where twf</p><formula xml:id="formula_2" coords="2,248.91,467.30,231.69,25.08">(z) i,t = rj ∈R z i twf (z-1) j,t • irf (z-1) t<label>(3)</label></formula><p>and R z i denotes the sets of resources in the ith resource at level z. For a given query q, resources at level z can be ranked according to t∈q w (z) i,t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Methodology and Research Questions</head><p>The experimental methodology consists of two tasks:</p><p>-Resource selection: Consider a set of search engines S, a set of queries Q T and a set of sample documents obtained by query-based sampling performed on each of the search engines: The goal of this task is to return a ranked list of search engines for each query in Q T , where the search engines should be ranked according to their capability to satisfy the user's information need expressed by the query.</p><p>-Vertical selection: Consider a set of search engines S, a partition of the set of search engines in a set of verticals V , a set of queries Q T and a set of sample documents obtained by query-based sampling performed on each of the search engines: The goal of this task is to return the most promising verticals for each query in Q T .</p><p>Our approach to performing the vertical selection task was to rank the verticals by TWF•IRF and select the top k verticals in the ranked list, for a given query. The motivation for this choice was to gain some insights into the vertical ranking capability of the adopted weighting framework. The cut-off of k = 5 was arbitrarily chosen. The selection of the cut-off can affect the effectiveness since the number of relevant verticals for a query can be less than k or greater than k; in the former case we could provide non-relevant verticals, in the latter case we could provide only a subset of all the relevant verticals.</p><p>The participation to FedWeb14 allowed us to investigate some specific research questions on TWF•IRF, specifically on the problems of resource description and resource selection.</p><p>With regard to the problem of resource description, the main research question was:</p><p>-RQ0: In the Federated Web Search settings there is no complete information on the collections indexed by the distinct search engines. Is the TWF•IRF effective even if resource description is based on document obtained by querybased sampling?</p><p>The comparison with the other FedWeb participants in TREC2013 and TREC2014 will provide us with some insights into RQ0. Since TWF•IRF describes resources at the diverse levels by document descriptors, other research questions concerned with the pre-processing operations, such as stemming and stop-words removal:</p><p>-RQ1: How does stemming affect the TWF•IRF effectiveness? -RQ2: How does stop-words removal affect the TWF•IRF effectiveness? RQ1 was addressed by investigating diverse stemming algorithms, particularly Porter Stemmer, Krovetz Stemmer and comparing the effectiveness with the configuration without stemming. RQ2 was addressed by comparing the effectiveness of TWF•IRF with and without stop-words removal.</p><p>With regard to the problem of resource selection, the research questions involve the effect of the IRF component.</p><p>-RQ3: Is the IRF component necessary for improving resource selection? Is the TWF component sufficient?</p><p>In the experiments reported in this paper we did not compute IRF according to the Spark Jones formulation of IDF -that corresponds to Eq. 1; we instead used the formulation derived from the RSJ weight <ref type="bibr" coords="3,388.29,656.12,10.52,8.74" target="#b6">[7]</ref> when no relevance information is available, specifically log(x) where</p><formula xml:id="formula_3" coords="4,260.10,140.05,220.49,29.79">x = N (z) -n (z) t + 0.5 n (z) t + 0.5 (4)</formula><p>Since log(x) &lt; 0 when n (z) t &gt; N (z) /2, we considered the following variant irf (z) t = log(1 + x) in order to avoid negative values for the IRF. With regard to the IRF instantiations, the research question was:</p><p>-RQ4: What is the effect of the IRF instantiation on the resource selection effectiveness?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Test Collection and Effectiveness Measures</head><p>The experiments were carried out on the FedWeb14 test collection. This test collection consists of sampled search results from 149 web search engines crawled between April and May 2014. These 149 engines were a subset of the 157 search engines in the FedWeb 2013 test collection. Four thousand queries were adopted to gather samples from the diverse search engines; these samples were the basis for building descriptions for the informative resources at the various levels (search engines and verticals). The participants were provided with 75 test topics, but only 50 of them were actually used for the evaluation.</p><p>The effectiveness measures adopted in the resource selection task were nDCG@20 (official metric), nDCG@10, nP@1, nP@5. nDCG <ref type="bibr" coords="4,358.48,401.05,10.52,8.74" target="#b5">[6]</ref> was computed using the trec eval variant where the discounting factor is log 2 (i + 1); for the nP@k metric the reader can refer to <ref type="bibr" coords="4,235.89,424.96,9.96,8.74" target="#b2">[3]</ref>.</p><p>The effectiveness measures adopted in the vertical selection task were precision (P), recall (R) and F1-measure; the relevance for each vertical was obtained using the GMR+II approach described in <ref type="bibr" coords="4,319.45,460.99,9.96,8.74" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parsing and Indexing</head><p>The indexing module of our system relies on the Apache Lucene library and on an XML parser written in Java for extracting the document fields from the sample searches and the sample documents in the test collection. The sample documents in the FedWeb14 Test Collection were indexed by creating a distinct index for each of the 149 search engines. These indexes were document-level indexes. Each (Lucene) document in a document-level index was constituted of three fields: title, description, and the content of the document associated to the sample search result. For each field, the document-level index stored the positions and the frequency of the descriptors in each document and in the collection.</p><p>Starting from these indexes, a search engine-level index was built. The set of descriptors in this index is the union of all the distinct descriptors in the distinct document-level indexes associated to the search engines. As the document-level index, a list of posting is associated to each descriptor in the search engine-level index. Each posting stores information on the identifier of the search engine, the number of documents in the search engine where the descriptor appears, and the TWF of the descriptor -see Section 3.4 for the computation of the TWF at search engine-level. In the specific Lucene-based implementation adopted, the TWF weight was stored in the payload that can be associated to each term; the weight value was approximated and stored as a float. <ref type="foot" coords="5,370.24,177.20,3.97,6.12" target="#foot_1">2</ref> The search engine-level index was adopted for the resource selection task.</p><p>For the vertical selection task we built a search engine-level index for each of the 24 verticals. Starting from these indexes, a vertical level index was built. In a vertical level index the set of descriptors is the union of all the distinct descriptors in the diverse search engine-level indexes associated to the verticals. A list of posting is associated to each descriptor; each posting stores information on the identifier of the vertical, the number of search engines where the descriptor appears, and the TWF of the descriptor at vertical level -see Section 3.5 for the computation of the TWF at vertical level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Resource Selection</head><p>The runs submitted to the FedWeb14 track exploited both the TWF and the IRF components of the weighting framework described in Section 2. This score was adopted to rank search engines in the resource selection task. The score of a search engine for a query q was computed as</p><formula xml:id="formula_4" coords="5,270.86,385.48,209.73,22.75">t∈q twf (2) i,t • irf (2) t (5)</formula><p>where twf  </p><p>j,t = tf (t, j) is the term frequency of term t in the document d j . The IRF at the document level was implemented as:</p><formula xml:id="formula_6" coords="5,237.43,467.96,107.95,20.48">irf (1) t = log N (1) -n<label>(1)</label></formula><p>t + 0.5 n (1) t + 0.5 <ref type="bibr" coords="5,467.86,477.84,12.73,8.74" target="#b5">(6)</ref> where N (1) is the number of documents indexed by the search engine and n</p><p>(1) t is the number of those documents where the descriptor t appears.</p><p>Differently from last year, we exploited both the TWF and the IRF components because the experiments carried out with the FedWeb13 test collection suggested that IRF at search engine level can be beneficial in terms of resource ranking effectiveness <ref type="bibr" coords="5,225.64,568.13,9.96,8.74" target="#b4">[5]</ref>. The IRF at search engine level was computed as follows:</p><formula xml:id="formula_7" coords="5,237.43,586.24,107.95,20.48">irf (2) t = log N (2) -n<label>(2)</label></formula><p>t + 0.5 n</p><p>(2) t + 0.5 <ref type="bibr" coords="5,467.86,596.12,12.73,8.74" target="#b6">(7)</ref> where N (2) is the number of search engines and n</p><p>(2) t is the number of those search engines the index of which contains the descriptor t.</p><p>The ranked list of search engines was obtained by appending three ranked lists:</p><p>L 1 : the list of search engines ranked by their TWF•IRF weight with regard to the query, and using the AND boolean constraint among the occurrence of the distinct terms in the query<ref type="foot" coords="6,285.81,173.65,3.97,6.12" target="#foot_3">3</ref> ; L 2 : the list of search engines that did not belong to L 1 and ranked by their TWF•IRF weight with regard to the query by using the OR boolean constraint among the occurrence of the distinct terms in the query; L 3 : the list of search engines that did not belong to L 1 and L 2 , ranked by their identifier -the identifier associated to the search engine in the test collection.</p><p>The final ranked list of search engines was obtained by appending L 2 to L 1 , and then L 3 to the fusion of the first two lists. We submitted seven runs for the resource selection task; the difference among the diverse runs is determined by the following variables:</p><p>-adoption of the IRF variant used at the document-level also for the search engine-level -use of log(1 + x) instead of log x -stemming algorithm adopted -adoption of the stop-list</p><p>The label associated to the diverse runs is structured on the basis of the choice made for each variable. The first seven letters of each label (UPDFW14) are shared by all the runs since they refer to the participating group (UPD) and the track (FW14).</p><p>The eighth and the ninth letter denote the adopted IRF variant: ti refers to that reported in Equation <ref type="formula" coords="6,251.19,439.97,3.87,8.74">7</ref>, while r1 refers to the log(1 + x) variant.</p><p>The tenth letter refers to the stemming algorithm adopted: (k) Krovetz stemmer, (p) Porter stemmer, and (n) no stemmer.</p><p>The eleventh letter denotes whether or not a stop-list was adopted: (s) Lemur stop-list, and (n) no stop-list.</p><p>The twelfth letter refers to the Boolean constraint adopted on the query term occurrence: (m) denotes the "cascade approach" described above that exploits AND, OR and then append the list of remaining search engines ordered by search engine identifier.</p><p>Results. Table <ref type="table" coords="6,206.11,566.37,4.98,8.74" target="#tab_0">1</ref> reports the obtained results for the resource selection runs; we omitted the first seven letters from the run labels -reported in the first column -since they are the same for all the runs. The most effective configurations involve the adoption of the stemmer and the stop-list. The Porter stemmer seems to provide slightly better results than Krovetz stemmer in terms of nDCG@20 -the values of the metric are basically the same but looking at the standard deviation the configuration with Porter stemmer results in less variability among the topics. The most effective runs in terms of nDCG@20 are those for which the stop-list was adopted.</p><p>With regard to the adoption of the IRF component for resource selection, the results obtained using the FedWeb13 test collection <ref type="bibr" coords="7,382.31,166.81,10.52,8.74" target="#b4">[5]</ref> suggested that it is beneficial in terms of nDCG@20. The same results was observed on the Fed-Web14 test collection. Indeed, the nDCG@20 was 0.2985 in the most effective configuration -porter stemming and stop-words removal -when only the TWF component was adopted, and it was 0.3112 when both TWF and IRF were used.</p><p>The way IRF is instantiated affects the capability of the TWF•IRF at searchengine level as suggested by the comparison between the ti-k-s-m and the r1-k-s-m runs in terms of nDCG@20; the log(x) version outperformed the log(1 + x) version of the IRF. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Vertical Selection</head><p>As mentioned in Section 3.1 the vertical selection task was investigated as a ranking task using a cut-off of k = 5 in the ranked list. The runs submitted to the vertical selection task exploited only the TWF component of the adopted weighted scheme. Ranking was performed using the same approach adopted for resource selection, i.e. appending the three lists L 1 , L 2 , and L 3 ; in this case, the informative resources in the result lists are not search engines but verticals.</p><p>For the vertical selection task we submitted six runs; these runs were based on different configurations of two variables: the way in which the IRF at search engine level was computed -(v0) log(x) or (v1) log(1 + x), and the stemming algorithm adopted.</p><p>We do not report the results based on the official runs since they were affected by a bug in the ranking procedure. Table <ref type="table" coords="7,327.08,596.34,4.98,8.74" target="#tab_1">2</ref> reports the results where Porter stemming and stop-words removal were adopted in the two configurations v0 and v1. The results suggest that the way IRF is computed at search engine level -that affects the TWF weight at vertical level -affects the effectiveness in terms of vertical selection: differently from what was observed for resource selection, v1 performed better than v0. With regard to the research RQ0, i.e. on the effectiveness of TWF•IRF when resource description is based on document obtained by query-based sampling, the comparison with the other participants in TREC2013 and TREC2014 does not provide a clear picture. This year the approach was not so effective as in TREC2013 test collection; since the number of queries used for sampling doubled -4000 in 2014 versus 2000 in 2013 -the obtained results seems to suggest that TWF•IRF is more effective than other methods when less precise descriptions are available. In order to gain additional insights on the possible causes for the lack of effectiveness, future investigations will be focused on -the effect of sampling strategy on resource selection effectiveness, e.g. by using distributed IR test collections where also the complete description is available, or the samples obtained by considering the diverse query sets (for sampling) in the FedWeb test collections; -the use of diverse weighting scheme at document level, e.g. BM25 instead of the TF•IDF; -the use of external evidence to obtain a more effective information need representation.</p><p>With regard to the vertical selection task, a possible direction for future investigations is the adoption of TWF•IRF as a feature for document descriptors in classification algorithms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,180.36,418.05,10.20,6.12;5,179.29,426.00,8.19,6.12;5,193.82,421.18,7.75,8.74;5,214.86,426.21,22.41,6.12;5,243.08,421.18,15.88,8.74"><head>( 2 )</head><label>2</label><figDesc>i,t = dj ∈Di twf</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,260.03,418.05,10.20,6.12;5,258.96,426.00,8.64,6.12;5,272.61,421.18,17.74,8.74;5,291.43,418.05,10.20,6.12;5,290.35,425.67,3.01,6.12;5,305.28,421.18,175.31,9.65;5,134.77,437.54,115.79,8.74"><head></head><label></label><figDesc>and D i denotes the sets of documents in the ith search engine, twf</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,141.74,292.59,339.24,113.56"><head>Table 1 .</head><label>1</label><figDesc>Comparison among the UPD resource selections runs.</figDesc><table coords="7,141.74,316.57,339.24,89.58"><row><cell>run</cell><cell>nDCG@20</cell><cell>nDCG@10</cell><cell>nP@1</cell><cell>nP@5</cell></row><row><cell>ti-p-s-m</cell><cell>0.311 (+-0.143)</cell><cell>0.226 (+-0.156)</cell><cell>0.123 (+-0.219)</cell><cell>0.187 (+-0.163)</cell></row><row><cell>ti-k-s-m</cell><cell>0.310 (+-0.150)</cell><cell>0.223 (+-0.153)</cell><cell>0.126 (+-0.218)</cell><cell>0.188 (+-0.161)</cell></row><row><cell>ti-n-s-m</cell><cell>0.306 (+-0.152)</cell><cell>0.221 (+-0.155)</cell><cell>0.153 (+-0.255)</cell><cell>0.197 (+-0.184)</cell></row><row><cell>r1-k-s-m</cell><cell>0.292 (+-0.151)</cell><cell>0.209 (+-0.164)</cell><cell>0.148 (+-0.236)</cell><cell>0.180 (+-0.164)</cell></row><row><cell>ti-n-n-m</cell><cell>0.281 (+-0.155)</cell><cell>0.212 (+-0.146)</cell><cell>0.134 (+-0.242)</cell><cell>0.201 (+-0.179)</cell></row><row><cell>ti-p-n-m</cell><cell>0.280 (+-0.144)</cell><cell>0.212 (+-0.148)</cell><cell>0.115 (+-0.217)</cell><cell>0.191 (+-0.159)</cell></row><row><cell>ti-k-n-m</cell><cell>0.278 (+-0.152)</cell><cell>0.209 (+-0.146)</cell><cell>0.118 (+-0.216)</cell><cell>0.191 (+-0.157)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,134.77,115.91,345.83,279.84"><head>Table 2 .</head><label>2</label><figDesc>Comparison among the UPD vertical selections runs. This paper reported on the participation of the IMS Research Group of the University of Padua at the TREC2014 Federated Web Search Track. The participation allowed us to gain some insights into diverse research questions concerning with TWF•IRF, our recursive weighting scheme, when it is used in Federated Web Search setting: -(RQ1) stemming has no significant effect on the TWF•IRF effectiveness in terms of search engine ranking; -(RQ2) stop-words removal improves the TWF•IRF effectiveness in terms of search engine ranking; -(RQ3) the IRF component can improve the TWF•IRF effectiveness in terms of search engine ranking; -(RQ4) the way IRF is computed has different effects depending on whether it is used for search engine ranking or vertical representation.</figDesc><table coords="8,134.77,139.90,266.11,74.82"><row><cell>run</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>UPDFW14v0psm</cell><cell>0.1480</cell><cell>0.4337</cell><cell>0.2053</cell></row><row><cell>UPDFW14v1psm</cell><cell>0.1560</cell><cell>0.4737</cell><cell>0.2203</cell></row><row><cell>4 Final Remarks</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,656.80,251.41,8.12"><p>The identifier adopted in TREC for our research group is UPD.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,144.73,656.80,62.54,7.86"><p>Single-precision</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2" coords="5,210.33,656.80,123.00,7.86"><p>32-bit IEEE 754 floating point</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3" coords="6,144.73,645.84,335.86,7.86;6,144.73,656.80,69.67,7.86"><p>The Lucene query was a BooleanQuery constituted of PayloadTermQuery connected by MUST clause.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,138.35,142.59,342.24,7.86;9,146.91,153.55,333.68,7.86;9,146.91,164.51,333.67,7.86;9,146.91,175.46,117.25,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,293.56,142.59,187.03,7.86;9,146.91,153.55,33.97,7.86">Searching distributed collections with inference networks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,201.77,153.55,278.82,7.86;9,146.91,164.51,257.39,7.86">Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;95</title>
		<meeting>the 18th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;95<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="21" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,186.42,342.24,7.86;9,146.91,197.38,333.67,7.86;9,146.91,208.34,333.68,7.86;9,146.91,219.30,333.67,7.86;9,146.91,230.26,20.99,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,302.06,186.42,178.53,7.86;9,146.91,197.38,104.40,7.86">Text-Based Content Search and Retrieval in Ad-hoc P2P Communities</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Cuenca-Acuna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,237.57,208.34,185.25,7.86">Web Engineering and Peer-to-Peer Computing</title>
		<title level="s" coord="9,157.67,219.30,141.47,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Gregori</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cherkasova</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Cugola</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Panzieri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Picco</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2376</biblScope>
			<biblScope unit="page" from="220" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,241.22,342.24,7.86;9,146.91,252.18,333.68,7.86;9,146.91,263.14,333.67,7.86;9,146.91,274.09,55.80,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,388.62,241.22,91.97,7.86;9,146.91,252.18,136.49,7.86">Overview of the TREC 2013 Federated Web Search Track</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Trieschnigg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,303.98,252.18,176.62,7.86;9,146.91,263.14,73.29,7.86">Proceedings of the Twenty-Second Text REtrieval Conference</title>
		<meeting>the Twenty-Second Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2013">2013. 2014</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,285.05,342.24,7.86;9,146.91,296.01,333.67,7.86;9,146.91,306.97,55.80,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="9,312.40,285.05,168.19,7.86;9,146.91,296.01,91.40,7.86">University of Padua at TREC 2013: Federated Web Search Track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Di Buccio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Masiero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Melucci</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>TREC. National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,317.93,342.24,7.86;9,146.91,328.89,333.68,7.86;9,146.91,339.85,333.68,7.86;9,146.91,350.81,56.59,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,329.67,317.93,150.92,7.86;9,146.91,328.89,134.71,7.86">Evaluation of a Recursive Weighting Scheme for Federated Web Search</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Di Buccio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Masiero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Melucci</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="9,280.80,339.85,115.94,7.86">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Basili</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Pennacchiotti</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="volume">1127</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,361.77,342.24,7.86;9,146.91,372.72,284.54,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,277.08,361.77,199.45,7.86">Cumulated gain-based evaluation of ir techniques</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kekäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,146.91,372.72,174.25,7.86">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002-10">Oct. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,383.68,342.24,7.86;9,146.91,394.64,272.64,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,285.82,383.68,144.45,7.86">Relevance weighting of search terms</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,439.03,383.68,41.56,7.86;9,146.91,394.64,183.11,7.86">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="129" to="146" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,405.60,342.24,7.86;9,146.91,416.56,333.68,7.86;9,146.91,427.52,333.68,7.86;9,146.91,438.48,256.30,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,446.54,405.60,34.05,7.86;9,146.91,416.56,178.25,7.86">Aligning vertical collection relevance with user intent</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Trieschnigg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,346.00,416.56,134.59,7.86;9,146.91,427.52,333.68,7.86;9,146.91,438.48,39.42,7.86">Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, CIKM &apos;14</title>
		<meeting>the 23rd ACM International Conference on Conference on Information and Knowledge Management, CIKM &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1915" to="1918" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
