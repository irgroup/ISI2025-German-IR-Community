<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,95.52,81.18,420.97,12.64;1,207.08,99.12,197.84,12.64">Estimating Semantic Similarity between Expanded Query and Tweet Content for Microblog Retrieval</title>
				<funder ref="#_n4x9mFJ">
					<orgName type="full">Science and Technology Commission of Shanghai Municipality</orgName>
				</funder>
				<funder ref="#_pwGhpFM">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_3YEnKmY">
					<orgName type="full">Shanghai Collaborative Innovation Center of Trustworthy Software for Internet of Things</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,240.18,133.91,70.38,10.53"><forename type="first">Zhihua</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Shanghai Key Laboratory of Multidimensional Information Processing Department of Computer Science and Technology</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<postCode>200241</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,319.59,133.91,47.50,10.53;1,367.09,132.21,1.41,7.44"><forename type="first">Man</forename><surname>Lan</surname></persName>
							<email>mlan@cs.ecnu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Shanghai Key Laboratory of Multidimensional Information Processing Department of Computer Science and Technology</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<postCode>200241</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,95.52,81.18,420.97,12.64;1,207.08,99.12,197.84,12.64">Estimating Semantic Similarity between Expanded Query and Tweet Content for Microblog Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6FDB8AD7C3D0B3C96B87107853245501</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports the systems we submitted to the Microblog Track shared in TREC 2014 which focuses on ad hoc retrieval (i.e., retrieving top 1, 000 relevant tweet for every given topic). To address this task, we adopted a two-stage framework, i.e., firstly, we performed query expansion (i.e., expanding relevant inforamtion using pseudorelevance feedback and Google search engine results) to retrieve more relevant tweets, then extracted several effective semantic features (e.g., Jansen-Shannon Distance, Overlap Similarity, Lucene Score, etc) from retrieved results and built ranking model using supervised machine learning algorithms with the aid of these features to perform re-ranking. Our systems ranked 3th out of 21 teams.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Microblog is a form of personal content sharing which derives from blog, and focuses on the social network-style interactions timely and rapidly. In the past few years, there has been a huge growth in the use of microblog platforms such as Twitter<ref type="foot" coords="1,263.79,560.53,3.99,7.01" target="#foot_0">1</ref> , Facebook<ref type="foot" coords="1,93.82,574.08,3.99,7.01" target="#foot_1">2</ref> . Promoted by that growth, companies and media organizations are increasingly seeking ways to mine microblog for information about the view points of certain topics <ref type="bibr" coords="1,179.72,616.74,114.39,9.59" target="#b6">(Kouloumpis et al., 2011)</ref>. The first challenge of mining information from microblog is data retrieval.</p><p>The microblog track in TREC 2014 focuses on the real-time search on Twitter, namely, Temporally-Anchored Ad Hoc Retrieval. This ad hoc retrieval task can be summarized as follows: "At time T , retrieve the most relevant tweets about an information need expressed as query Q." There are two key points in this task: real-time and precise, which means that we should retrieve the most relevant tweets posted within a certain period of time. Thus, for each given query, participating team is required to return the top 1000 tweets ranked in decreasing order of predicted relevance score, which are published prior to (including) the query time defined by the organizers.</p><p>Twitter usually used to mine information because of its large amount of social information and timeless property. Although there are a wide variety of researches on microblog data for various data mining tasks (e.g., sentiment analysis, entity linking, semantic similarity, etc), relatively few work has done on microblog retrieval <ref type="bibr" coords="1,410.99,468.48,95.10,9.59" target="#b1">(Ferguson et al., 2012)</ref>. <ref type="bibr" coords="1,513.95,468.48,20.84,9.59;1,313.20,482.03,73.16,9.59" target="#b11">(Massoudi et al., 2011</ref>) developed a language model with aid of two groups of quality indicators and proposed a dynamic query expansion model to perform microblog retrieval. <ref type="bibr" coords="1,391.79,522.68,102.62,9.59" target="#b13">(O'Connor et al., 2010;</ref><ref type="bibr" coords="1,497.37,522.68,42.63,9.59" target="#b9">Li et al., ;</ref><ref type="bibr" coords="1,313.20,536.23,50.78,9.59" target="#b15">Zhu et al., )</ref> implemented simple but effective query expansion methods which much improved the performances of retrieval. Apart the common methods used in retrieval systems, some unique properties of microblog are exploited for retrieval purpose <ref type="bibr" coords="1,519.40,590.43,20.60,9.59;1,313.20,603.98,51.63,9.59" target="#b8">(Lau et al., 2011)</ref>. For example, <ref type="bibr" coords="1,436.33,603.98,59.61,9.59" target="#b0">(Efron, 2010;</ref><ref type="bibr" coords="1,499.65,603.98,40.35,9.59;1,313.20,617.53,41.39,9.59" target="#b4">Huang et al., 2010)</ref> showed the usefulness of Hashtag# in relevance feedback and query expansion. <ref type="bibr" coords="1,486.60,631.08,53.40,9.59;1,313.20,644.62,41.75,9.59" target="#b10">(Magnani et al., 2011;</ref><ref type="bibr" coords="1,358.68,644.62,94.61,9.59" target="#b12">Nagmoti et al., 2010;</ref><ref type="bibr" coords="1,457.02,644.62,82.97,9.59" target="#b7">Kwak et al., 2010)</ref> employed user information for retrieving conversations from microblog.</p><p>Following many previous work <ref type="bibr" coords="1,463.91,685.68,46.40,9.59" target="#b9">(Li et al., ;</ref><ref type="bibr" coords="1,513.34,685.68,26.66,9.59;1,313.20,699.23,28.73,9.59" target="#b14">Qiang et al., ;</ref><ref type="bibr" coords="1,344.30,699.23,48.50,9.59" target="#b15">Zhu et al., ;</ref><ref type="bibr" coords="1,395.18,699.23,71.52,9.59" target="#b3">Hasanain et al., ;</ref><ref type="bibr" coords="1,469.07,699.23,70.93,9.59" target="#b2">Han et al., 2012;</ref><ref type="bibr" coords="1,313.20,712.78,70.61,9.59" target="#b15">Zhu et al., 2012;</ref><ref type="bibr" coords="1,386.26,712.78,122.46,9.59">Hoang Van Duc et al., 2012)</ref>  task, we adopt a two-stage framework to address this work, i.e., query expansion (i.e., adding relevant information to query) and re-ranking (extracting several semantic features and using supervised machine learning algorithm to perform re-ranking).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>on this</head><p>The paper is organized as follows. Section 2 describes the framework of our system. Section 3 reports the experimental setting and results on training and test data. Finally, Section 4 concludes this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Overview</head><p>In this work, we employed a two-stage framework to settle the microblog retrieval, i.e., query expansion and re-ranking.</p><p>Figure <ref type="figure" coords="2,114.61,523.09,5.45,9.59" target="#fig_0">1</ref> depicts the architecture of our proposed system, where the left part is a query expansion module and the right part is a re-ranking module. In query expansion, we expanded the query from two distinct sources (i.e., tweet feedback and Google returned results) and optimized the best combination to perform query expansion. As for reranking part, we first extracted several effective semantic features (i.e., JansenShannon Distance, Overlap Similarity and Lucence Score, etc) from preliminary retrieval results, then we explored two ranking strategies (i.e., point-wise and pairwise) and compared several supervised machine learning algorithms with the aid of above features to perform re-ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Query Expansion</head><p>Since the text length in Twitter is usually short (limited to 140 words), given a query, the relevant tweets may not contain all the words in a query. Therefore, simply using keyword matching may not be able to retrieve all relevant tweets. In order to overcome the lexical gap between tweets and query, we proposed two methods to perform query expansion. The first method aims at using tweet feedback provided by organizers to extract the relevant information from tweets. The second is to use the returned results from Google search engine to expand the query. The difference between these two methods lies on the source of relevant information, i.e., internal (tweets) and external (Google search engine).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Tweet Feedback</head><p>Since organizers provided a API to retrieve tweets ranked by initial Lucene ranking score and these top tweets are expected to be closely relevant to the search query, we proposed to expand queries with the aid of the information from these top K feedback tweets. Here we adopt a variant of tf * idf to calculate the weight of each word as follows:</p><formula xml:id="formula_0" coords="2,345.53,628.54,162.14,34.63">F weight w = K ∑ j=1 ( f req (w) len (T j ) • score j )</formula><p>where F weight w is the weight of word w in feedback tweets, T j is the jth tweet returned by the API and score j is the corresponding Lucene relevant score provided by API, f erq(w) is the fre-quency of word w in T j , len(T j ) is the total number of words in T j . Since different words have quite different F weight w scores, we performed L 1 normalization. In this way, we expanded query words by adding top P words from the top K feedback tweets according to their F weight w scores. Obviously, this tweet feedback-based query expansion method takes both the relevancy of tweet and the frequency of word into consideration and thus it is expected to be able to comprehensively evaluate word relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Google Returned Results</head><p>The second query expansion method is to use Google returned results. This is based on the observation that the titles and snippets of Web pages returned by Google search engine are closely related to the search query. Similar to the above tweet feedback approach, we used the top K results returned by Google search engine to expand query. To select the significant words from the results, we adopted the traditional tf * idf <ref type="bibr" coords="3,173.32,346.67,75.15,9.59" target="#b5">(Joachims, 1996)</ref> to measure the relevance of the words with given query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Re-Ranking</head><p>After the above query expansion processing, we first extracted three types of semantic relevancy features between each expanded query and tweet, and then adopted supervised learning-to-rank algorithms to perform tweet re-ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Preprocessing Tweets</head><p>Firstly, we used the API provided by organizers to collect top 10, 000 tweets for each given query. Since the collected tweet dataset contains a lot of noise, we conducted a series of preprocessing procedures, including removing non-English tweets and retweets (retweets and Non-English tweets are judged as non-relevant), removing stop words and punctuations. After that, we changed words to their lowercase and performed tokenization and stemming.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Features</head><p>To measure the semantic relevance between query and tweet, we used the following three types of surface text similarity measures.</p><p>Jensen-Shannon Divergence (JSD): JSD (Fuglede and Topsoe, 2004) is a symmetrized and smoothed variant of Kullback-Leibler divergence, which is calculated as following:</p><formula xml:id="formula_1" coords="3,315.97,105.69,221.26,89.81">Jensen -Shannon Divergence (S, T ) = 1 2 KL (P S ∥ Q) + 1 2 KL (P T ∥ Q) Q (w) = 1 2 (P S (w) + P T (w)) KL (P ∥ Q) = ∑ x∈X P (x) log P (x) Q (x)</formula><p>where Q (w) denotes the distribution of the document collection of T and S, KL (P ∥ Q) means the Kullback-Leibler divergence between distribution P and Q. Here we proposed four JSD features by calculating the JSD between tweet and original query in unigram and bi-gram, denoted as JSD TvQu and JSD TvQb, and the JSD between tweet and Google returned results in unigram and bi-gram, denoted as JSD TvGu and JSD TvGb, respectively.</p><p>Overlap Similarity (OS): OS is a simple and effective similarity measure and calculated as follows:</p><formula xml:id="formula_2" coords="3,337.54,352.88,176.93,22.87">Overlap Similarity = |A ∩ B| |A| or |A ∩ B| |B|</formula><p>where |A ∪ B| denotes the size of intersection of set A and set B and |A| means the size of set A. We denote the word sets collected from tweet, query and Google returned results as T , Q and G. The ratio of |T ∩ Q| to |Q| (denoted as OS TvQ) and the ratio of |T ∩ G| to |G| (denoted as OS TvG) were calculated as OS features.</p><p>Lucene Score (LS): Lucene Score is a state-ofthe-art similarity score which combines several measures<ref type="foot" coords="3,335.62,498.70,3.99,7.01" target="#foot_2">3</ref> , e.g., cosine formula and dirichlet prior. It is calculated as follows:</p><formula xml:id="formula_3" coords="3,313.20,530.90,193.35,40.07">Lucnne Score(q, d) = coord q,d •queryN orm q • ∑ t in q (tf t,d • idf t,d • weight t • norm t,d )</formula><p>where coord q,d is a grade factor defined as Overlap M axOverlap , queryN orm q is a normalizing factor which does not affect the ranking, tf t,d denotes the term frequency in d, idf t,d is the inverse document frequency, weight t is the weight of term t in query q and norm t,d is encapsulated by a small part of weight t and the length of document d. The official API provides this Lucene Score between query and returned tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Learning-to-rank</head><p>We used supervised learning-to-rank approach to perform re-ranking. Generally, the learning-to-rank approach can be divided into three groups: pointwise, pair-wise and list-wise. In this work, we adopted the first two strategies.</p><p>In point-wise strategy, given a query, for each returned tweet, we first built a query-tweet pair with its relevant label. Then we adopted regression algorithm to build a regression model. For each unlabeled query-tweet pair, we used the regression model to calculate its relevant score. In this work we employed two regression algorithms, i.e., SVR and KNeighors Rrgressor.</p><p>In pair-wise strategy, given a query and several returned tweets, we constructed many tweet1-tweet2 pairs. If tweet1 is more relevant than tweet2 in terms of the given query, this pair label is set as 1, otherwise 0. By doing so, we adopted supervised classification method to predict the label of each pair. Since the classification model provides a confidence score for each instance, then these tweets are ranked by this confidence score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>The organizers provided two data sets of microblog track with gold annotation in TREC 2011 and TREC 2013. Therefore, we experimented on these two training datasets and employed the configured systems on TREC 2014.</p><p>In the microblog track of TREC 2014, the participants could interact with a tweet collection stored remotely via a search API. The motivation for this evaluation-as-a-service design is to increase the size of the collection while adhering to Twitter's terms of service. Past arrangements allowed teams to acquire local copies of a canonical corpus. But the logistics of this approach prohibited scaling the corpus size up dramatically. The total amount of tweets we obtained from the API is about 243 million which gathered from the public Twitter stream from February 1, to <ref type="bibr" coords="4,110.77,658.34,116.99,9.59">March 31, 2013 (inclusive)</ref>.</p><p>The tweets downloaded form API are in JSON format, which contain many fields, i.e., id (the unique identifier assigned by twitter), rsv (the relevance score of tweet), text (text of tweet), retweeted count (the number of times this tweet has been retweeted) etc. Since the raw text of each tweet contains a lot of noise, we performed data preprocessing to remove non-English tweets and retweets. We also used Natural Language Toolkit<ref type="foot" coords="4,495.74,127.92,3.99,7.01" target="#foot_4">4</ref> for tokenization, stemming and removing stop words.</p><p>Totally for each query, we collect up to 10, 000 tweets from API ranked by Lucene score as our original datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Performance Evaluation</head><p>The evaluation metrics provided by organizer are Mean Average Precision (MAP), Precision at rank 30 (P@30) and Reciprocal Precision (R-Prec) which are defined as follows.</p><p>MAP: Mean average precision depends on the precision at each point when a new relevant tweet gets retrieved which is calculated as:</p><formula xml:id="formula_4" coords="4,357.57,328.80,138.05,31.41">M AP = 1 N • N ∑ j=1 1 Q j • Qj ∑ i=1 P (T i )</formula><p>where Q j denotes the number of relevant tweets for query j, N presents the number of the queries and P (T i ) is the precision of the relevant tweets in top i tweets. MAP provides a single-figure measure of quality across recall levels. P@30: This metric denotes that the precision of top 30 tweets. It has advantage of not requiring any estimate of the size of the set of relevant tweets and the total number of relevant tweets for query has a strong influence on P@30.</p><p>R-Prec: If there are |Rel| relevant tweets for a query, we examine the top |Rel| tweets returned by the system, and find that r tweets are relevant, then the R-Prec is calculated as r/ |Rel|. Specifically, the recall of this tweets set is also r/ |Rel|.</p><p>In these three evaluation metrics, MAP is the main evaluation criteria for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Preliminary Experiments on Training Data</head><p>In order to determine the optimum system configuration, we conducted preliminary experiments on the datesets of TREC 2011 and TREC 2013. To make reasonable comparison, we performed crossover experiments on the two datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Query Expansion</head><p>Due to the shortness of information of initial query provided by organizer, we performed several query expansion methods with the aid of original query, tweet feedback and Google returned results. Only Query (Q):</p><p>We performed API search using the initial query Q provided by organizer only. This serves as our baseline for query expansion. The weight of each word in Q is calculated as the ratio of corresponding word frequency in query to the total number of words in query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query + Tweet Feedback (Q+T):</head><p>This query expansion pattern consists of the initial query and the top 20 relevant words extracted from the top 20 feedback tweets (T ) The weight of each word in this query pattern is the sum of respective word weight in two set (If word w not exist in set, the weight of w is 0 in corresponding set).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tweet Feedback + Google Returned (T+G):</head><p>We assumed that the top 20 Google returned results are quite relevant to the current query. Besides, we extracted the top 20 relevant words from these top 20 Google returned results as set G, then built a new expansion pattern consisted of T and G. Towards the weight of each term, the calculation is the same as before.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query + Tweet Feedback + Google Returned (Q+T+G):</head><p>We combined all elements mentioned before (i.e., initial query, the top 20 relevant words in top 20 tweets of feedback results and the most relevant 20 words in top 20 documents of Google returned results) as a new query expansion pattern. For the weight of each term, the computational method is similar as before but three sets rather than two sets.</p><p>To compare the performance of different query expansion patterns, we used the top 1, 000 tweets returned by API.</p><p>Table <ref type="table" coords="5,108.98,658.58,5.45,9.59" target="#tab_0">1</ref> shows the results of different query expansion methods on two TREC training datasets. We find that the query expansion pattern by combining tweets feedback with Google returned results outperformed other query expansion patterns. Based on our observation of the words in the three sets Q, T , G, we find that the words appearing in Q also have high weights in the other two sets. However, the words in T and G are quite different. That means, the words from the two query expansion methods may make up for their shortage of information and improve the performance. Thus, for the following experiments, we adopted the T+G pattern to perform query expansion. Furthermore, in order to examine the different contributions made from the two components (i.e., tweet feedback and Google returned results), we also conducted further experiments on different ratios between these two sets. Table <ref type="table" coords="5,465.29,498.82,5.45,9.59" target="#tab_1">2</ref> lists the further experimental results with different ratios between T and G. Since the query expansion pattern of tweets feedback and Google returned results with the ratio of 3 : 1 performed best, for the follow-up experiments, we used the returned tweets by API with this setting as datesets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Re-ranking</head><p>We adopted two learning-to-rank strategies to perform re-ranking. For point-wise strategy, we adopted a rbf -based SVR algorithm with c = 1 and a Kneighors Regressor algorithm with K = 1. For pair-wise strategy, the Random Forest and Rank-Boost algorithms with default parameters were used.</p><p>Table <ref type="table" coords="5,351.42,699.23,5.45,9.59" target="#tab_2">3</ref> shows the results of re-ranking part with different strategies and algorithms. From it is interesting to see that the pair-wise strategy method generally outperformed the point-wise strategy method in terms of MAP measure. In terms of P@30 measure, the performance of SVR is close to that of Random Forest. Thus, for the final systems, we selected these two algorithms with corresponding parameters to perform re-ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">System Configuration</head><p>Based on the preliminary experiments on training data, we chose the setting of tweets feedback and Google returned results with the ratio of 3 : 1 for query expansion part.</p><p>According the results of re-ranking part, we adopted a rbf -based SVR algorithm with c = 1 implemented in scikit-learn toolkit<ref type="foot" coords="6,213.54,383.17,3.99,7.01" target="#foot_5">5</ref> and Random Forest algorithm with default parameters implemented in RankLib<ref type="foot" coords="6,121.78,410.27,3.99,7.01" target="#foot_6">6</ref> . With regard to the setting in RankLib tooklit, the metric is set as MAP and the iteration is set as 300 times.</p><p>Besides, we find that the performance of using TREC 2013 as training data is much better than that of using TREC 2011. However, since the dataset of TREC 2013 contains more relevant tweets (9, 000 relevant tweets) than that of TREC 2011 (3, 000 relevant tweets), we also consider to build model on TREC 2013 only.</p><p>In summary, the configurations of our four submissions are shown in Table <ref type="table" coords="6,197.80,563.00,4.09,9.59" target="#tab_5">4</ref>.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Results and Discussion</head><p>Table <ref type="table" coords="6,339.36,394.58,5.45,9.59" target="#tab_6">5</ref> shows the official released results of our submitted four runs with the top 2 ranked systems and the best and median synthetic aggregated runs released by TREC official for ad hoc task. Form Table <ref type="table" coords="6,379.78,450.42,4.09,9.59" target="#tab_6">5</ref>, it is interesting to find following observations.</p><p>Firstly, the pair-wise strategy methods outperform point-wise strategy method. This consequence is consistent with the results on training data, which indicates that pair-wise is more applicable to this re-ranking task than point-wise. Furthermore, the regression model for point-wise strategy costs vast amounts of training time. Thus, we prefer to employ pair-wise strategy.</p><p>Secondly, the TREC 2013 dataset only is quite general to build the model. The performance of different datasets is almost equal in terms of the same re-rank strategy. There are almost no significantly improvement with the addition of TREC 2011. Moreover, the time cost of building model on TREC 2013 is much lower than which on TREC 2011 with TREC 2013.</p><p>In summary, the best result of our submissions ranked 3th out of 21 teams. Comparing with the top2 ranked systems, our systems are promising, although the simple features were adopted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>To address TREC 2014 Microblog track, we explored a two-stage framework, i.e., query expansion and re-ranking. For query expansion, the combination of two methods based on different sources of relevant information, i.e., internal (tweets) and external (Google search engin), outperformed each method alone. To re-rank tweets, the pair-wise strategy outperformed the point-wise strategy.</p><p>In future work, we would investigate more effective query expansion methods. Also we will explore more features, such as URL information, to enrich the feature set and improve the performance of reranking.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,206.54,276.35,198.92,8.76;2,142.20,72.04,327.52,187.39"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The framework of our proposed system.</figDesc><graphic coords="2,142.20,72.04,327.52,187.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,313.20,74.17,226.82,185.84"><head>Table 1 :</head><label>1</label><figDesc>Performances of different query expansion methods on two training datasets.</figDesc><table coords="5,324.61,74.17,203.98,185.84"><row><cell>Datasets</cell><cell cols="2">TREC 2011</cell><cell cols="2">TREC 2013</cell></row><row><cell>Metric</cell><cell cols="4">MAP(%) P@30 MAP(%) P@30</cell></row><row><cell>Q</cell><cell>25.68</cell><cell>30.00</cell><cell>20.44</cell><cell>37.56</cell></row><row><cell>Q+T</cell><cell>41.17</cell><cell>45.99</cell><cell>28.30</cell><cell>46.50</cell></row><row><cell>T+G</cell><cell>46.84</cell><cell>50.07</cell><cell>32.99</cell><cell>52.89</cell></row><row><cell>Q+T+G</cell><cell>44.70</cell><cell>50.02</cell><cell>32.01</cell><cell>52.00</cell></row><row><cell>Dataset</cell><cell>2011</cell><cell></cell><cell>2013</cell><cell></cell></row><row><cell>Metric</cell><cell cols="4">MAP(%) P@30 MAP(%) P@30</cell></row><row><cell>T+G(1:1)</cell><cell>46.84</cell><cell>50.07</cell><cell>32.99</cell><cell>52.89</cell></row><row><cell>T+G(2:1)</cell><cell>45.93</cell><cell>50.02</cell><cell>32.75</cell><cell>53.22</cell></row><row><cell>T+G(3:1)</cell><cell>47.34</cell><cell>50.34</cell><cell>33.02</cell><cell>53.56</cell></row><row><cell>T+G(5:1)</cell><cell>47.11</cell><cell>50.00</cell><cell>33.00</cell><cell>53.72</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,313.20,277.89,226.81,20.71"><head>Table 2 :</head><label>2</label><figDesc>Results of different ratio of T and G on two training datasets.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,503.80,712.78,36.20,9.59"><head>Table 3 ,</head><label>3</label><figDesc></figDesc><table coords="6,143.96,74.13,324.08,52.91"><row><cell>Strategy</cell><cell></cell><cell>Point-wise</cell><cell></cell><cell>Pair-wise</cell></row><row><cell>Algorithm</cell><cell>SVR</cell><cell cols="3">Kneighors Regressor Random Forest</cell><cell>RankNet</cell></row><row><cell>Metric</cell><cell cols="2">MAP P@30 MAP</cell><cell>P@30</cell><cell>MAP P@30 MAP P@30</cell></row><row><cell>2011</cell><cell cols="2">50.29 53.33 37.73</cell><cell>43.67</cell><cell>50.74 52.65 47.15 48.71</cell></row><row><cell>2013</cell><cell cols="2">34.70 55.22 28.60</cell><cell>50.44</cell><cell>36.12 56.39 32.60 53.33</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,185.90,144.92,237.12,8.76"><head>Table 3 :</head><label>3</label><figDesc>Results of re-ranking part on two training datasets.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,72.00,175.73,452.11,500.11"><head>Table 4 :</head><label>4</label><figDesc>Configurations of our four submissions. RF stands for Random Forest algorithm.</figDesc><table coords="6,329.09,175.73,195.02,98.74"><row><cell>System</cell><cell cols="3">MAP(%) P@30(%) R-Prec(%)</cell></row><row><cell>SVRA</cell><cell>53.51</cell><cell>70.00</cell><cell>53.30</cell></row><row><cell>SVR13</cell><cell>53.86</cell><cell>70.61</cell><cell>53.57</cell></row><row><cell>RFA(3)</cell><cell>55.29(3)</cell><cell>71.33(2)</cell><cell>54.27(5)</cell></row><row><cell>RF13</cell><cell>55.19</cell><cell>71.15</cell><cell>54.88</cell></row><row><cell cols="2">PKUICST3(1) 58.63(1)</cell><cell>72.24(1)</cell><cell>57.27(1)</cell></row><row><cell>hltcoe3(2)</cell><cell>57.07(2)</cell><cell>71.21(3)</cell><cell>56.60(2)</cell></row><row><cell>Best</cell><cell>67.51</cell><cell>83.45</cell><cell>66.59</cell></row><row><cell>Median</cell><cell>41.55</cell><cell>62.61</cell><cell>43.95</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="6,313.20,292.35,226.82,56.58"><head>Table 5 :</head><label>5</label><figDesc>Results of our four submissions, the top2 ranked systems, the best and median synthetic aggregated runs released by TREC official for the ad hoc search task. The numbers in the brackets are the rankings of corresponding metric.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,88.14,702.89,62.03,7.88"><p>http://twitter.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,88.14,714.06,74.37,7.88"><p>http://facebook.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,329.34,703.10,118.60,7.88"><p>http://lucene.apache.org/core/2 9</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3" coords="3,451.17,703.10,93.96,7.88;3,313.20,714.06,94.30,7.88"><p>4/api/core/org/apache/lucene/search/Similarity.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4" coords="4,329.34,714.06,72.98,7.88"><p>http://www.nltk.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5" coords="6,88.14,702.89,101.70,7.88"><p>http://scikit-learn.org/stable/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6" coords="6,88.14,714.06,167.75,7.88"><p>http://people.cs.umass.edu/ vdang/ranklib.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research is supported by grants from <rs type="funder">National Natural Science Foundation of China</rs> (No.<rs type="grantNumber">60903093</rs>), <rs type="funder">Shanghai Collaborative Innovation Center of Trustworthy Software for Internet of Things</rs> (<rs type="grantNumber">ZF1213</rs>), and the <rs type="funder">Science and Technology Commission of Shanghai Municipality</rs> under research grant no. <rs type="grantNumber">14DZ2260800</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_pwGhpFM">
					<idno type="grant-number">60903093</idno>
				</org>
				<org type="funding" xml:id="_3YEnKmY">
					<idno type="grant-number">ZF1213</idno>
				</org>
				<org type="funding" xml:id="_n4x9mFJ">
					<idno type="grant-number">14DZ2260800</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,72.00,481.28,226.81,8.76;7,82.91,493.24,215.90,8.76;7,82.91,505.28,215.91,8.55;7,82.91,517.15,188.38,8.76" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,152.40,481.28,146.41,8.76;7,82.91,493.24,48.08,8.76">Hashtag retrieval in a microblogging environment</title>
		<author>
			<persName coords=""><forename type="first">Miles</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,149.62,493.33,149.19,8.55;7,82.91,505.28,215.91,8.55;7,82.91,517.24,92.44,8.55">Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 33rd international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="787" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,530.34,226.81,8.76;7,82.91,542.30,215.91,8.76;7,82.91,554.25,215.91,8.76;7,82.91,566.21,215.89,8.76;7,82.91,578.16,36.26,8.76;7,72.00,591.36,226.81,8.76;7,82.91,603.32,215.90,8.76;7,82.91,615.36,215.90,8.55;7,82.91,627.23,70.83,8.76" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,231.55,542.30,67.27,8.76;7,82.91,554.25,212.39,8.76;7,268.93,591.36,29.88,8.76;7,82.91,603.32,197.01,8.76">An investigation of term weighting approaches for microblog retrieval</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Neil</forename><surname>Ohare</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Lanagan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Owen</forename><surname>Phelan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Mccarthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,93.73,566.30,136.08,8.55;7,72.00,591.36,150.56,8.76;7,82.91,615.36,215.90,8.55;7,82.91,627.32,11.83,8.55">IEEE International Symposium on Information Theory</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2012. 2004</date>
			<biblScope unit="page" from="31" to="31" />
		</imprint>
	</monogr>
	<note>Advances in Information Retrieval</note>
</biblStruct>

<biblStruct coords="7,72.00,640.43,226.81,8.76;7,82.91,652.38,215.90,8.76;7,82.91,664.34,215.89,8.76;7,82.91,676.38,31.44,8.55" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,221.03,652.38,77.78,8.76;7,82.91,664.34,52.15,8.76">Hit at trec 2012 microblog track</title>
		<author>
			<persName coords=""><forename type="first">Zhongyuan</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xuwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Muyun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Haoliang</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tiejun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,155.51,664.43,143.29,8.55;7,82.91,676.38,27.51,8.55">Proceedings of Text REtrieval Conference</title>
		<meeting>Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,689.49,226.81,8.76;7,82.91,701.44,215.90,8.76;7,82.91,713.40,56.70,8.76;7,313.20,76.36,226.81,8.76;7,324.11,88.31,215.90,8.76;7,324.11,100.27,215.90,8.76;7,324.11,112.22,207.26,8.76" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,82.91,701.44,215.90,8.76;7,82.91,713.40,56.70,8.76;7,313.20,76.36,226.81,8.76;7,324.11,88.31,215.90,8.76;7,324.11,100.27,195.65,8.76">Qu at trec-2013: Expansion experiments for microblog ad hoc search. Thong Hoang Van Duc, Thomas Demeester, Johannes Deleu, Piet Demeester, and Chris Develder. 2012. Ugent participation in the microblog track 2012</title>
		<author>
			<persName coords=""><forename type="first">Maram</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Latifa</forename><surname>Al-Marri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tamer</forename><surname>Elsayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,324.11,112.31,102.96,8.55">Text Retrieval Conference</title>
		<imprint>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
	<note>TREC-2012</note>
</biblStruct>

<biblStruct coords="7,313.20,124.93,226.81,8.76;7,324.11,136.88,215.91,8.76;7,324.11,148.84,215.91,8.76;7,324.11,160.79,175.95,8.76" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,405.73,136.88,130.80,8.76">Conversational tagging in twitter</title>
		<author>
			<persName coords=""><forename type="first">Jeff</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Katherine</forename><forename type="middle">M</forename><surname>Thornton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Efthimis</forename><forename type="middle">N</forename><surname>Efthimiadis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,334.87,148.93,205.15,8.55;7,324.11,160.88,79.13,8.55">Proceedings of the 21st ACM conference on Hypertext and hypermedia</title>
		<meeting>the 21st ACM conference on Hypertext and hypermedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="173" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,313.20,173.49,226.81,8.76;7,324.11,185.45,215.91,8.76;7,324.11,197.41,139.57,8.76" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="7,430.84,173.49,109.16,8.76;7,324.11,185.45,211.99,8.76">A probabilistic analysis of the rocchio algorithm with tfidf for text categorization</title>
		<author>
			<persName coords=""><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>DTIC Document</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="7,313.20,210.11,226.81,8.76;7,324.11,222.06,215.90,8.76;7,324.11,234.02,174.90,8.76" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Efthymios</forename><surname>Kouloumpis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Johanna</forename><surname>Moore</surname></persName>
		</author>
		<title level="m" coord="7,387.87,222.06,152.14,8.76;7,324.11,234.02,116.66,8.76">Twitter sentiment analysis: The good the bad and the omg! ICWSM</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="538" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,313.20,246.72,226.81,8.76;7,324.11,258.68,215.90,8.76;7,324.11,270.63,215.90,8.76;7,324.11,282.59,215.90,8.76" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,386.23,258.68,153.78,8.76;7,324.11,270.63,51.52,8.76">What is twitter, a social network or a news media?</title>
		<author>
			<persName coords=""><forename type="first">Haewoon</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Changhyun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hosung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sue</forename><surname>Moon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,390.85,270.72,149.16,8.55;7,324.11,282.68,119.37,8.55">Proceedings of the 19th international conference on World wide web</title>
		<meeting>the 19th international conference on World wide web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="591" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,313.20,295.29,226.82,8.76;7,324.11,307.24,215.90,8.76;7,324.11,319.20,146.22,8.76" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="7,353.25,307.24,186.76,8.76;7,324.11,319.20,63.64,8.76">Microblog retrieval using topical features and query expansion</title>
		<author>
			<persName coords=""><forename type="first">Cher</forename><surname>Han Lau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuefeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dian</forename><surname>Tjondronegoro</surname></persName>
		</author>
		<editor>TREC. Citeseer</editor>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,313.20,331.90,226.82,8.76;7,324.11,343.86,215.90,8.76;7,324.11,355.81,105.69,8.76" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="7,483.36,331.90,56.66,8.76;7,324.11,343.86,215.90,8.76;7,324.11,355.81,101.95,8.76">A user-in-theloop process for investigational search: Foreseer in trec 2013 microblog track</title>
		<author>
			<persName coords=""><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,313.20,368.51,226.81,8.76;7,324.11,380.47,215.90,8.76;7,324.11,392.42,215.88,8.76;7,324.11,404.38,76.11,8.76" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,427.91,380.47,112.09,8.76;7,324.11,392.42,24.46,8.76">Conversation retrieval from twitter</title>
		<author>
			<persName coords=""><forename type="first">Matteo</forename><surname>Magnani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Danilo</forename><surname>Montesi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gabriele</forename><surname>Nunziante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luca</forename><surname>Rossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,370.68,392.51,138.99,8.55">Advances in Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="780" to="783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,313.20,417.08,226.82,8.76;7,324.11,429.04,215.91,8.76;7,324.11,440.99,215.90,8.76;7,324.11,452.95,215.89,8.76;7,324.11,464.90,76.11,8.76" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,446.64,429.04,93.38,8.76;7,324.11,440.99,215.90,8.76;7,324.11,452.95,19.15,8.76">Incorporating query expansion and quality indicators in searching microblog posts</title>
		<author>
			<persName coords=""><forename type="first">Kamran</forename><surname>Massoudi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manos</forename><surname>Tsagkias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wouter</forename><surname>Weerkamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,368.17,453.04,140.77,8.55">Advances in Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="362" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,313.20,477.60,226.81,8.76;7,324.11,489.56,215.90,8.76;7,324.11,501.51,215.90,8.76;7,324.11,513.56,215.90,8.55;7,324.11,525.43,194.23,8.76" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,398.47,489.56,141.53,8.76;7,324.11,501.51,23.95,8.76">Ranking approaches for microblog search</title>
		<author>
			<persName coords=""><forename type="first">Rinkesh</forename><surname>Nagmoti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ankur</forename><surname>Teredesai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martine</forename><forename type="middle">De</forename><surname>Cock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,365.97,501.60,174.04,8.55;7,324.11,513.56,215.90,8.55;7,324.11,525.52,56.35,8.55">Web Intelligence and Intelligent Agent Technology (WI-IAT), 2010 IEEE/WIC/ACM International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="153" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,313.20,538.13,226.81,8.76;7,324.11,550.08,215.90,8.76;7,324.11,562.04,135.57,8.76" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,350.49,550.08,189.52,8.76;7,324.11,562.04,83.67,8.76">Tweetmotif: Exploratory search and topic summarization for twitter</title>
		<author>
			<persName coords=""><forename type="first">O'</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michel</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,425.65,562.13,28.36,8.55">ICWSM</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,313.20,574.74,226.82,8.76;7,324.11,586.70,147.20,8.76" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="7,324.11,586.70,143.47,8.76">Pkuicst at trec 2013 microblog track</title>
		<author>
			<persName coords=""><forename type="first">Runwei</forename><surname>Qiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yue</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yihong</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianwu</forename><surname>Yang</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,313.20,599.40,226.81,8.76;7,324.11,611.35,189.53,8.76;7,313.20,624.06,226.81,8.76;7,324.11,636.01,215.90,8.76;7,324.11,647.97,215.90,8.76;7,324.11,659.92,69.72,8.76" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="7,380.26,611.35,129.64,8.76;7,526.18,636.01,13.83,8.76;7,324.11,647.97,133.66,8.76">Ictnet at microblog track trec 2012</title>
		<author>
			<persName coords=""><forename type="first">Siming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhe</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yajing</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guang</forename><surname>Chen ; Bolong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jinghua</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiao</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cunhui</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shenghua</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yue</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xueqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Cheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>DTIC Document</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>Pris at trec 2013 microblog track</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
