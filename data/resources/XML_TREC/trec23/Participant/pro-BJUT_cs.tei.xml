<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,69.42,98.99,473.17,12.90;1,205.95,114.93,200.10,12.90">BJUT at TREC 2014 Contextual Suggestion Track: Hybrid Recommendation Based on Open-web Information</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,142.45,149.07,58.35,10.75"><forename type="first">Hanchen</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Beijing University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,208.55,149.07,53.02,10.75"><forename type="first">Zhen</forename><surname>Yang</surname></persName>
							<email>yangzhen@bjut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Beijing University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,276.29,149.07,54.95,10.75"><forename type="first">Yingxu</forename><surname>Lai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Beijing University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,339.29,149.07,62.25,10.75"><forename type="first">Lijuan</forename><surname>Duan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Beijing University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,410.71,149.07,58.84,10.75"><forename type="first">Kefeng</forename><surname>Fan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Beijing University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,69.42,98.99,473.17,12.90;1,205.95,114.93,200.10,12.90">BJUT at TREC 2014 Contextual Suggestion Track: Hybrid Recommendation Based on Open-web Information</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">51A285E635566224DCE387A45B2CE126</idno>
					<note type="submission">Submitted Results Training dataset Test dataset input</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe our efforts for TREC contextual suggestion task. Our goal of this year is to evaluate the effectiveness of: (1) Preference crawling method that as far as possible to obtain more candidate spots' information from open-web to model the users' interest profiles; (2) Automatic summarization method that leverages the information from multiple resources to generate the description for each candidate scenic spots; (3) Hybrid recommendation method that combing a variety of factors to construct a system of hybrid recommendation system. Finally, we conduct extensive experiments to evaluate the proposed framework on TREC 2014 Contextual Suggestion data set, and, as would be expected, the results demonstrate its generality and superior performance. Crawl TREC Contexts TREC Examples attractions of each city Examples data Data processi ng Dataset in VSM TF-IDF TREC Profiles Mark By Network retrieval Artificia l mark Examples with categories profiles analysi s profiles statistics data SVM classifier User-Attractions Profiles data Attractio ns selection</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>In this year Contextual Suggestion (CS) Track, we main aims are two folds: (1) combing a variety of factors which are crawled from open-web to construct a system of hybrid recommendation system. <ref type="bibr" coords="1,155.55,454.10,11.62,8.64" target="#b1">(2)</ref> Explore a new description generation method which combines multiple aspects of information. Information recommendation is always a dilemma. It's a contradiction by generality and individuality. Recommend items need to make a compromise between popularity and user's personalized interest. First, the higher popularity of items tend that each user will like it, but it can't reflect users personalized interest. At the same time, recommending according to user's personalized needs the data describes the user's interest accurately. The data about spots crawled from open-web has sparseness problem, and it is difficult to truly reflect the personal interest of each user and reflects more of the spots' popularity.</p><p>In this sense, we crawled a variety of indirect information of scenic spots from the open-web such as: attractions, spots rank, reviews of spots, etc. using this information to reflect the quality of spots. Through analysis user profiles, we can get the interest preference of each user to each Category, and use spots in Example as the training dataset to train the SVM classifier for each user interest. Then, we use classifier to get the judgments about like or dislike for each user-spots pairs. Finally, we use the information crawled from website as the reflecting of spots' popularity, while use the user's in-terest which is analyzed from profiles as the reflecting of user's personalized interest. In the recommendation algorithm module, we combine the spots popularity and user personalized interest to generate two recommendation algorithms, eventually get BJUTa and BJUTb as two submitted results.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Our Method</head><note type="other">System Framework</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Useful Information Gathering</head><p>The first step of solving the contextual suggestion problem is to gather useful information. Useful information contains not only the candidate scenic spots, but also their web Figure <ref type="figure" coords="2,113.10,457.13,5.74,11.33" target="#fig_2">2</ref> shows the meaning of each graph in Figure <ref type="figure" coords="2,320.69,457.13,4.31,11.33" target="#fig_0">1</ref>. Useful information gathering component mainly crawls everything that we need to rank the candidate scenic spots.</p><p>Examples labeling component determine the scenic spots' category in Examples through searching the internet and a small part of the manual scenic spots.</p><p>Profile Modeling and Interest classification component mainly consists of two parts :( 1) Modeling user profiles (2) user-spots Interest classification. Statistical method is used to identify    site, reviews associated with them and etc. For candidate scenic spots we use open web as they contain comprehensive information than ClueWeb12 does. We crawl the information such as candidate scenic spots, main page, categories and reviews of candidates exclusively from the website http://www.tripadvisor.com/ for all contexts. The crawl-ing is done per category. All scenic spots are crawled in five categories from TripAdvisor, i.e., attractions, activities, restaurants, nightlife and shopping.</p><p>In order to make up for the spots data sparse problem, we crawl the indirect description as supplementary information for spots as much as possible, includes: rank on TripAdvisor, rate on TripAdvisor, reviews of spots, a review information includes: content, number, helpful vote number. We get the proportion of each category of the spots in Example according to the example label and crawl the spots according to the proportion for each context. Attraction, restaurant and activities crawl 120 as the top for each category, nightlife and shopping crawl 60 as the top for each category. For some context don't have 50 spots, according to the requirement of the location choice spots as the supplement which near the context city. Finally, we ensure each context has at least 70 spots.</p><p>All the crawlers are developed by python and the data is stored in a hierarchical relationship. Some data are normalized using the class structure of storage by cpickle module of python.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Profile Modeling and Interest classification</head><p>We need to analyze each user's interest in all kinds of spots categories. The meaning of user rating in Profiles is showed as follow:</p><formula xml:id="formula_0" coords="3,54.00,57.16,107.38,85.15">• 4: Strongly interested • 3 Interested • 2: Neutral • 1: Disinterested • 0: Strongly disinterested • -1: Website didn't</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>load or no rating given</head><p>We take the website rate as the spot rate in profiles. Rate three and four points are considered as users likes the spot while zero and one points are considered as users don't like the spot. Point two is a neutral rating. First, in our Examples labeling module we classify each spot in Example, and then analyze the profiles to get the user interest to every Category. Finally, we get the probability of each user to every Category and the Users interested statistical Fig. <ref type="figure" coords="3,210.34,225.62,3.74,8.64" target="#fig_7">3</ref>.</p><p>We can see that the users of different categories of spots showed obvious interest orientation. For example: User for attraction and restaurant spots' like probability is higher than others and dislike probability is lower than others. Therefore, we can use the probability of user interest for each category as an important index of recommendation, to reflect the interest of each user. Through the analysis of the profiles, we classify spots in example into two categories, likes and dislikes for each user. Example spots are training set to train SVM classifier with RBF kernel function for each user. After that, each user will have a classifier which can classify a spot into like class or dislike class. So, we can use SVM classifier to classify every candidate spot for each user and label every spot with "like" or "dislike" for each userspot pairs. We call this "user-spot favorite label". User-spot favorite label also reflects each user's personalized interest. User interest probability is aiming at a class scenic spots of user interest, while user-spot favorite label is aiming at a spot of user interest. They all reflect the personalized interest of the user and recommendation system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recommendation algorithm</head><p>We determine some criteria of the recommendation system according to the three evaluation standards of TREC: P @5, MRR and TBG. First of all, the recommended spots should conform to the requirements of location in context, so we will use location as a criterion of the recommendation system. Second, we will use the rank of spots on TripAdvisor and the rate of the reviews as the indicators of spots' quality, it embodies the commonness of recommendation system, while we use the probability of user interest for each category and the classification label of each user-spots pairs as the reflecting of the user personalized interest, it embodies the personality of recommendation system.</p><p>According to the requirement of TREC, we need recommend 50 spots for each user-context pair. In this sense, the whole recommended Algorithm is divided into two process:</p><p>(1) choose 50 spots for each user-context pair (2) sort the spots of each user-context pair.</p><p>choose 50 spots for each user-context pair For 50 candidate spots, we choose the spots to follow the following principles. According to the priority order of each criterion, first, we choose the spots which location is meet the requirements of geographical of context. If all spots' location are conform to the requirements of geographical of context, location will not be a criteria of recommendation system. In order to guarantee the quality of TBG, the spots which conform the location requirement will be selected firstly. Then, we need determine the number of each category according to the probability of user's interests. We determine the number of each user-context pair by following formula:</p><formula xml:id="formula_1" coords="3,359.73,162.55,198.27,9.65">number i = sum i × p(like|category i )<label>(1)</label></formula><p>where i ∈ category{attraction/activities/restaurant/ shopping/nightlif e}, sum i is the spots number of category i in the context, p(like|category i ) is the conditional probability.</p><p>There, number i is the upper bound of category i .It is important to note that for the context that its spots don't fit the location requirement, we will prefer to select the spots which location fit with the requirements of context. If this strategy results in a certain number of spots of one category exceeded the upper bound, the spots of this category will not be selected any more. Other categories of spots will shrink their upper bound in Proportion of the category's upper bound.</p><p>After determine the spots' number of each category, our algorithm can be divided into two kinds:(1)Only-rank algorithm ,only using rank as a criteria, sort the spots of all categories together by rank and choose the spots in order. (2) like-rank algorithm, using rank and user-spot label (like or dislike) as criterion. We prefer to select the spot with like label. If some spots all have like label, choose the spot with higher rank. The result of Only-rank algorithm is BJUTa, while the result of like-rank algorithm is BJUTb. sort spots of each user-context pair After choosing the 50 recommended spots, we need to sort this 50 spots to generate the final recommended list. Here, we used two different algorithms to sort the 50 spots, the difference between two algorithms is whether to use the user-spot label as a criteria in sortingalgorithm. Because the TREC using P @5 as one of the main evaluation indicators, in order to improve the quality of the first five recommended spots, each spot sorting algorithm can be divided into two parts: (1) first six spots sorting (2) rest of the spots sorting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• First six spots sorting</head><p>In order to guarantee the quality of P @5, we recommend the former six spots continue to separate selection and sorting. In first six spots, two of them are selected from the category which the probability of user like is the highest. Two of them are selected from the category which the probability of user dislike is the lowest. Two of them are selected from the category which has the largest number of spots in recommended 50 spots. After this step, we can know the number of each category in first six spots. We sort the spots in each category by rank and select spots according to the amount of this category in first six spots. Then we will get the first six spots of BJUTA result. When we select the first six spots, if we need all these spot has the user-spot label with like, we will get the first six spots of BJUTb.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure.5. Users interested statistical</head><p>We can see that the users of different categories of spots showed obvious interest orientation. For example: User for attraction and restaurant spots' like probability is higher than others and dislike probability is lower than others. Therefore, we can use the probability of user interest for each category as an important index of recommendation, to reflect the interest of each user.</p><p>Through the analysis of the profiles, we classify spots in example into two categories, likes and dislikes for each user. Example spots are training set to train SVM classifier with RBF kernel function for each user. After that, each user will have a classifier which can classify a spot into like class or dislike class. So, we can use SVM classifier to classify every candidate spot for each user and label every spot with "like" or "dislike" for each user-spot pairs. We call this "user-spot favorite label". User-spot favorite label also reflects each user's personalized interest. User interest probability is aiming at a class scenic spots of user interest, while user-spot favorite label is aiming at a spot of user interest. They all reflect the personalized interest of the user and recommendation system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Recommendation algorithm</head><p>We determine some criteria of the recommendation system according to the three evaluation standards of TREC: P@5, MRR and TBG. First of all, the recommended spots should conform to the requirements of location in context, so we will use location as a criterion of the recommendation system. Second, we will use the rank of spots on TripAdvisor and the rate of the reviews as the indicators of spots' quality, it embodies the commonness of recommendation system, while we use the probability of user interest for each category and the classification label of each user-spots pairs as the reflecting of the user personalized interest, it embodies the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Rest of the spots sorting</head><p>First of all, we sort the probability of user interest of dislike for each category in ascending way. We use 0.3 and 0.8 as two thresholds to filter each category. The categories which user dislike probability less than 0.3 are as a bunch of classes and give priority to recommend. While the categories which user dislike probability greater than 0.8 are recommended at last. For the categories which user dislike probability are in 0.3 to 0.8, we use treat the probability as one-dimensional vector and use k-means method to cluster the categories into two clusters. We use each category vector as the center of initial cluster and get the best initial cluster center. If only two categories are remained, they will be treated as a cluster. Finally, we can get some cluster which consists of some categories that its dislike probability is in different level. Then, we choose spots in the cluster which has a lower dislike probability of cluster center, sorting these spots by rank and add them to the recommended list. The cluster which has a higher dislike probability of cluster center will be recommended later. Follow this rule, and we can get the recommended list of remaining spots.</p><p>At last, combining the two results of (1) (2) and we will get the final submitted results, BJUTa and BJUTb.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description Generation</head><p>There are mainly two parts of the data obtained from openweb by our method: less brief introductions and a great deal of consumer critics, and text information of websites of spots. Among the data lots of disordered information is included.</p><p>For great evaluation such as TREC, characteristics of automatic description for each user are not an important thing. Researchers show that language and logic are the prime factors for description. That is to say, a description that is lucid always tends to a better evaluation. Therefore, extraction for a whole sentence and the compound of other information are our method to generate automatic description. The descriptions are gained by following things:</p><p>• The introduction information of the spot net • Reviews has "helpful vote" or a good score to the scenic spot • Some introduction information on TripAdvisor Brief description of candidate spots are made following such a template: scenic spot's name + introduction information on TripAdvisor + concrete introduction of spots. More detailed methods for description are done according to 3 levels.</p><p>• Level 1: description information on spot website • Level 2: Critic information with helpful vote tag on critics • Level 3: Critics whose score provided by consumers is better than average points The sentences which have most number of words for each level are extracted. After all sentences for a higher level have been extracted, sentences at lower level can be extracted. Add extracted sentences until the brief description reaches 512 bytes. There, data structure similar to stack is used. rank has g k) and TBG (t geographic sc ime-biased g core of 1 or2 ain). For P@5 , and descrip     From top to bottom level, complete sentence are extracted and add to automatic description. The introduction information of spot website is obtained by statistics of word numbers of text in each html label and the number for words containing spot's name. These methods not only guarantee the fluency of the automatic description, but also make it best for description to have more information of spot advantages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Examples labeling</head><p>The spots in the example are provided by TREC. Interests towards the example spots have been evaluated by users. In order to analyze interests of users, classification on spots of the example is needed to get interest information of users. Internet search is utilized to classify each spot, whose realization method for is: search at the TripAdvisor using spot name in the Example as the key, and the scenic spot's category which its name and location information are satisfied with the example will be returned. For the spots that are not </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Submitted Runs and Experiment Results</head><p>We submitted two runs: BJUTa and BJUTb. BJUTa only uses spot rank and probability of user interest in each category as the basis for selection and sorting candidate's spots, while BJUTb uses spot rank and probability of user interest in each category and user favorite label of each spots as the basis for selection and sorting candidate's spots. For description, it combines the opening sentence, meta-description of the web site, the review which has helpful vote tag and the sentence from the reviews which are good reviews of the scenic. We use 10-fold cross-validation method for the parameters of RBF kernel function in SVM training process.</p><p>As for judgments, 304 profile/context pairs were sampled and judged. There are four criteria: geographic appropriateness, interestingness of website and description. Geographic appropriateness has 3 scales: 0, 1, 2, with 0 not geographically appropriate, 1 marginally geographically appropriate, and 2 geographically appropriate. Interestingness of website and description has 5 scales: 0, 1, 2, 3, 4, with 0 strongly uninterested, 1 uninterested, 2 neutral, 3 interested, 4 strongly interested. Moreover, geographic appropriateness was judged partially by NIST assessors and partially by users. Scores from NIST assessors were used if a profile/context pair was judged by both of them.</p><p>Three evaluation measurements were reported: P @5 (precision at 5), MRR (mean reciprocal rank) and TBG (timebiased gain). For P @5 and MRR, a suggestion is labeled as relevant only if it has geographic score of 1 or2, and description score of 3 or 4, and web site score of 3 or 4.</p><p>Figure <ref type="figure" coords="6,92.83,516.32,4.98,8.64" target="#fig_9">4</ref> and Figure <ref type="figure" coords="6,146.78,516.32,4.98,8.64" target="#fig_11">5</ref> show the performances of our two runs in terms of all evaluation measurements. The X axis consists of all profile/context pairs, ordered alphabetically in the format of "profile-context". One red point represents our result for that profile/context. Three bars corresponding to the best, median and worst results of that profile/context. The yellow line is the range which is above the average. We can see that our runs achieve some of the best results. Most of our results are equal or better than the median results, indicating the effectiveness of our proposed system. Table <ref type="table" coords="6,287.52,614.95,4.98,8.64" target="#tab_1">1</ref> shows the overall mean performances of our runs in terms of all evaluation measurements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In TREC 2014 Contextual Suggestion Track, we submitted two runs. Both of them use the indirect description information of candidate spots and user interest information to select and sort the candidate spots. Indirect description information of candidate spots include: spot's category, location and rank. User interest information includes: probability of user interest in each category and user favorite label of each spots. We use these indicators to make recommendation algorithm. The spots category, location information, rank, and probability of user interest in each category are used to get the result of BJUTa, while the spots category, location information, rank, and probability of user interest in each category and user favorite label of each spots are used to get the result of BJUTb. Due to the open-web data sparseness problem, our recommendation algorithm does not depend on the similarity between two spots, but using a variety of indirect description of scenic spot from the open -the web which reflect the quality of spots and user profile which reflect the user interest to select and sort the candidate spots. We use a variety of information on the open-web with whole sentence extraction method to generate spots brief automatically.</p><p>The performances of our two submitted runs are in general better than the median performance. Some of the results are even best results, indicating the effectiveness of our proposed method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,319.50,312.55,238.50,8.64;1,319.50,323.50,238.50,8.64;1,319.50,334.46,238.50,8.64;1,319.50,345.42,238.50,8.64;1,319.50,356.38,238.50,8.64;1,319.50,367.34,46.76,8.64;1,319.50,380.74,238.50,8.96;1,329.46,392.02,228.54,8.64;1,319.50,405.76,238.50,8.96;1,329.46,417.04,228.54,8.64;1,329.46,428.00,156.61,8.64;1,319.50,441.73,238.50,8.96;1,329.46,453.01,228.54,8.64;1,329.46,463.97,228.54,8.64;1,329.46,474.93,228.54,8.64;1,329.46,485.89,228.54,8.64;1,329.46,496.85,228.54,8.64;1,329.46,507.81,228.54,8.64;1,329.46,518.77,82.26,8.64;1,319.50,532.50,238.50,8.96;1,329.46,543.78,228.54,8.64;1,329.46,554.74,228.54,8.64;1,329.46,565.70,220.36,8.64;1,319.50,579.44,238.50,8.96;1,329.46,590.72,228.54,8.64;1,329.46,601.67,216.60,8.64;1,319.50,615.41,238.50,8.96;1,329.46,626.69,228.53,8.64;1,329.46,637.65,228.54,8.64"><head>Figure 1</head><label>1</label><figDesc>Figure 1 shows our system framework. It mainly consists of three parts: (1) Useful information gathering, (2) Examples labeling, (3) Profile Modeling and Interest classification, (4) Recommendation algorithm, (5) Description generation, (6) Results generation and checking. Figure 2 shows the legend of Figure 1.• Useful information gathering component mainly crawls everything that we need to rank the candidate scenic spots. • Examples labeling component determine the scenic spots' category in Examples through searching the internet and a small part of the manual scenic spots. • Profile Modeling and Interest classification component mainly consists of two parts: (1) Modeling user profiles; (2) user-spots Interest classification. Statistical method is used to identify each user preferences for each category of spots. User-spots Interest classification use the spots in Examples as the training sample to train to the SVM classifier, and use it to classify the spots into two class, user like and user dislike. • Recommendation algorithm component mainly consists of two parts: (1) for each user -context pair choose 50 candidate recommendation spots. (2) Sort the 50 candidate recommendation spots for each user -context pair. • Description generation component mainly utilizes multiresource information to generate spot's brief automatically. We also describe this part in details later this paper. • Results generation and checking component get the recommend spots and spots briefly together, and use the official script to check the results and submit results to TREC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,247.48,372.99,116.97,11.33"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. System Framework</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="2,274.80,659.09,104.54,11.33"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Legend of Fig. 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="2,246.68,377.74,118.64,8.64"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System Framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="2,87.69,302.91,120.60,11.68"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. System Framework</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="2,115.86,597.89,107.79,11.68"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Legend of Fig. 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="2,119.50,603.73,107.50,8.64"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Legend of Fig. 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="4,233.36,355.35,145.27,8.64;4,104.15,35.36,420.89,315.66"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Users interested statistical.</figDesc><graphic coords="4,104.15,35.36,420.89,315.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="5,222.56,285.97,47.72,12.77;5,203.11,207.19,66.85,72.09"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2. De</figDesc><graphic coords="5,203.11,207.19,66.85,72.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9" coords="5,232.24,296.07,147.53,8.64;5,204.33,319.53,67.00,72.71"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Detailed Results of BJUTa.</figDesc><graphic coords="5,204.33,319.53,67.00,72.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10" coords="5,77.21,590.33,61.73,12.88;5,68.16,609.46,76.77,12.88;5,66.32,628.60,73.60,12.88;5,68.67,647.73,70.95,12.88;5,68.60,666.86,71.24,12.88;5,67.20,686.00,74.87,12.88;5,71.47,705.13,72.79,12.88;5,68.31,724.27,75.78,12.88;5,138.95,590.33,65.45,12.88;5,138.66,609.46,68.88,12.88;5,136.97,628.60,73.43,12.88;5,139.62,647.73,64.91,12.88;5,136.89,666.86,64.62,12.88;5,138.14,686.00,66.57,12.88;5,137.48,705.13,71.15,12.88;5,137.92,724.27,68.57,12.88;5,138.24,472.60,67.06,72.71"><head></head><label></label><figDesc>Figure 2 an asurements. T mat of "profil s correspondi he range whi ults. Most of ctiveness of o erms of all eva d Figure 3 s The X axis c le-context". O ng to the be ich is above f our result our proposed aluation mea</figDesc><graphic coords="5,138.24,472.60,67.06,72.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11" coords="5,231.76,560.71,148.48,8.64;5,204.09,472.60,67.06,72.71"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Detailed Results of BJUTb.</figDesc><graphic coords="5,204.09,472.60,67.06,72.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,211.81,552.06,348.97,243.07"><head>Table 1 .</head><label>1</label><figDesc>Ove</figDesc><table coords="5,265.68,552.06,295.10,243.07"><row><cell cols="2">tailed Results s of BJUTb</cell><cell></cell><cell></cell></row><row><cell cols="5">rformances o of our two ru uns in terms</cell><cell>of all evalua ation</cell></row><row><cell cols="5">all profile/con ntext pairs, o ordered alph habetically in n the</cell></row><row><cell cols="5">nt represents s our result f for that profi ile/context. T Three</cell></row><row><cell cols="5">nd worst resu ults of that p profile/contex xt. The yellow w line</cell></row><row><cell cols="5">. We can see e that our ru uns achieve s some of the</cell><cell>best</cell></row><row><cell cols="3">or better t than the m</cell><cell cols="2">edian result ts, indicating g the</cell></row><row><cell cols="2">ble 1 shows t he overall m</cell><cell cols="2">ean perform</cell><cell>ances of our</cell><cell>runs</cell></row><row><cell cols="2">erall Mean Pe erformances</cell><cell></cell><cell></cell></row><row><cell>BJUTa</cell><cell>BJUTb</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,54.00,64.27,238.50,117.10"><head>Table 1 :</head><label>1</label><figDesc>Overall Mean Performances.</figDesc><table coords="6,54.00,78.46,238.50,102.91"><row><cell>BJUTa BJUTb</cell></row><row><cell>P@5 0.5057 0.5037</cell></row><row><cell>MRR 0.6850 0.6700</cell></row><row><cell>TBG 2.1993 2.2003</cell></row><row><cell>found in TripAdvisor, we will label them by hands. There</cell></row><row><cell>are 100 spots in the Example, among which 87 spots are</cell></row><row><cell>searched out, 13 spots are marked by hands.</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,323.24,324.48,234.77,8.64;6,319.50,335.43,238.50,8.64;6,319.50,346.39,219.18,8.64" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,446.10,324.48,111.90,8.64;6,319.50,335.43,204.03,8.64">A hybrid recommendation technique based on product category attributes[J]</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Albadvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Shahbazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,531.44,335.43,26.56,8.64;6,319.50,346.39,105.21,8.64">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="11480" to="11488" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,323.24,357.35,234.77,8.64;6,319.50,368.31,238.50,8.64;6,319.50,379.27,238.50,8.64;6,319.50,390.23,238.50,8.64;6,319.50,401.19,60.88,8.64" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="6,510.96,357.35,47.04,8.64;6,319.50,368.31,238.50,8.64;6,319.50,379.27,238.50,8.64;6,319.50,390.23,107.89,8.64">Application of hybrid recommendation in web-based cooking assistant[C]//Knowledge-Based Intelligent Information and Engineering Systems</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sobecki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Babiak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="797" to="804" />
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,323.24,412.15,234.77,8.64;6,319.50,423.11,238.50,8.64;6,319.50,434.06,238.50,8.64;6,319.50,445.02,238.50,8.64;6,319.50,455.98,70.45,8.64" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,409.85,412.15,148.15,8.64;6,319.50,423.11,238.50,8.64;6,319.50,434.06,16.98,8.64">Hybrid recommendation approaches: collaborative filtering via valuable content information</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,357.70,434.06,200.31,8.64;6,319.50,445.02,207.79,8.64">System Sciences, 2005. HICSS&apos;05. Proceedings of the 38th Annual Hawaii International Conference on</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="217" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,323.24,466.94,234.77,8.64;6,319.50,477.90,238.50,8.64;6,319.50,488.86,238.50,8.64;6,319.50,499.82,19.93,8.64" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,404.82,466.94,153.19,8.64;6,319.50,477.90,121.10,8.64">A SVM-based personal recommendation system for TV programs</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Araki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,489.81,477.90,68.20,8.64;6,319.50,488.86,205.36,8.64">Media Modelling Conference Proceedings, 2006 12th International</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,323.24,510.78,234.77,8.64;6,319.50,521.74,238.50,8.64;6,319.50,532.69,209.21,8.64" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="6,443.53,510.78,114.47,8.64;6,319.50,521.74,238.50,8.64;6,319.50,532.69,105.21,8.64">A hybrid approach for personalized recommendation of news on the Web[J]. Expert Systems with Applications</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Guan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="5806" to="5814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,323.24,543.65,234.77,8.64;6,319.50,554.61,200.99,8.64" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="6,381.11,543.65,176.90,8.64;6,319.50,554.61,184.48,8.64">Text categorization with support vector machines: Learning with many relevant features</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
