<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,114.51,132.91,382.97,18.57">LIMSI @ 2014 Clinical Decision Support Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,111.37,170.85,65.34,6.50"><forename type="first">Eva</forename><surname>D'hondt</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LIMSI (CNRS UPR 3251</orgName>
								<address>
									<postCode>91405</postCode>
									<settlement>Orsay</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,188.58,170.85,69.49,6.50"><forename type="first">Brigitte</forename><surname>Grau</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LIMSI (CNRS UPR 3251</orgName>
								<address>
									<postCode>91405</postCode>
									<settlement>Orsay</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,269.95,170.85,80.79,6.50"><forename type="first">Stéfan</forename><surname>Darmoni</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">CISMeF</orgName>
								<orgName type="institution" key="instit1">TIBS-LITIS EA</orgName>
								<orgName type="institution" key="instit2">Rouen University Hospital</orgName>
								<address>
									<postCode>4108, 76031</postCode>
									<settlement>Rouen</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,366.85,170.85,74.77,6.50"><forename type="first">Aurélie</forename><surname>Névéol</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LIMSI (CNRS UPR 3251</orgName>
								<address>
									<postCode>91405</postCode>
									<settlement>Orsay</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,453.50,170.85,47.13,6.50;1,214.52,184.80,38.43,6.50"><forename type="first">Matthieu</forename><surname>Schuers</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">CISMeF</orgName>
								<orgName type="institution" key="instit1">TIBS-LITIS EA</orgName>
								<orgName type="institution" key="instit2">Rouen University Hospital</orgName>
								<address>
									<postCode>4108, 76031</postCode>
									<settlement>Rouen</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,288.56,184.80,104.19,6.50"><forename type="first">Pierre</forename><surname>Zweigenbaum</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LIMSI (CNRS UPR 3251</orgName>
								<address>
									<postCode>91405</postCode>
									<settlement>Orsay</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,114.51,132.91,382.97,18.57">LIMSI @ 2014 Clinical Decision Support Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E31E86417B696A40A957894474625327</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Document Retrieval</term>
					<term>UMLS</term>
					<term>MeSH</term>
					<term>Clinical Decision Support</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we present our participation in the 2014 TREC Clinical Decision Support Track. The goal of this track is to nd relevant medical literature for a case report which should help address one specic clinical aspect of the case. Since it was the rst time we participated in this task, we opted for an exploratory approach to test the impact of retrieval systems based on Bag-of-Words (BoW) or Medical Subject Headings (MeSH) index terms. In all ve submitted runs, we used manually constructed MeSH queries to lter a target corpus for each of the three clinical question types. Query expansion (for both MeSH and BoW runs) was based on the automatic generation of disease hypotheses for which we used data from OrphaNet [4] and the Disease Symptom Knowledge Database [3]. Our best run was a MeSH-based run in which PubMed was queried directly with the MeSH terms extracted from the case reports, combined with the MeSH terms of the top 5 disease hypotheses generated for the case reports. Compared</p><p>to the other participants we achieved low scores. Preliminary analysis shows that our corpus ltering method was too strict and has a negative impact on recall.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of the Clinical Decision Support Track is to retrieve relevant biomedical articles given a patient record. This year is the rst time that this particular track has been organized. In this instalment the patient records are short case reports that describe a medical case, for example, A woman in her mid-30s presented with dyspnea and hemoptysis. CT scan revealed a cystic mass in the right lower lobe. Before she received treatment, she developed right arm weakness and aphasia. She was treated, but four years later suered another stroke.</p><p>Follow-up CT scan showed multiple new cystic lesions.</p><p>The case reports are available as short summaries or slightly longer case descriptions. In the experiments reported below we only used the case summaries.</p><p>The concept of `relevancy' in this task diers from that in standard document retrieval: The developed system should not just nd documents that refer to the illness or symptoms described in the case report, but that also answer a clinical question such as "What is the patient's diagnosis?".</p><p>In total there were three dierent clinical question types. Each case report had one associated clinical questions. A complicating factor in this year's task was the lack of ocial training material, that is, Gold Standard data on links between case reports and relevant journal articles in the Open Access set, according to the clinical question type. We looked into using material from the CasesDatabase website 1 , a website that aggregated case reports from dierent medical journals and used text mining tools to automatically extract condition, symptom, intervention, pathogen, patient demographic and other data elds from the articles. With this information the case reports could be grouped per particular symptom or condition. While initially promising, in practice the CasesDatabase proved dicult to use as a training set since it is not representative for our dataset: The articles contained in the CasesDatabase were all case reports, while the Open Access set is much more diverse. Moreover the case descriptions in the case reports were always not representative for the shorter description that make up the topics in the Clinical Decision Track. Due to time constraints we were not able to add extra information and turn it into a usable training set. The systems that were created for this task are therefore largely untrained.</p><p>The use of MeSH terms as index terms sets PubMed apart from other document collections. The majority of articles in PubMed are manually indexed by specialists with 5 to 15 MeSH terms that are considered the most pertinent and detailed for the subjects discussed. For example, an article describing a treatment of the Kawasaki Disease will generally be indexed with the MeSH heading for this disease "mucocutaneous lymph node syndrome" and the MeSH subheading "drug therapy". However, the specialists will often not add MeSH terms for the symptoms associated with the disease since many symptoms are not linked to one particular disease and therefore hold little classication value 2 . In our participation in the Clinical Decision Support track we were interested in the impact of using MeSH terms, which are more precise, versus a Bag of Words approach when expanding the query with disease hypotheses. These hypotheses were generated by a self-constructed Diagnostic Clinical Decision Support system, hereafter referred to as the Symptom Checker. The Symptom Checker takes a set of symptoms (extracted from the case report) as input, and returns a ranked list of disease hypotheses. This paper is organised as follows. In Section 2, we describe the individual components of the dierent systems that were built in the course of this track. In Section 3, we present the ve runs <ref type="bibr" coords="2,102.89,622.20,3.65,7.30" target="#b0">1</ref> Could be found at http://www.casesdatabase.com/ but has gone oine since July 2014. <ref type="bibr" coords="2,102.89,631.68,3.65,7.30" target="#b1">2</ref> A noted example are case reports which may be indexed for symptoms since they often describe atypical occurrences of a disease or condition. that were submitted for evaluation. Results are presented in Section 4, and the conclusions are discussed in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Components</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Clinical question types as MeSH queries</head><p>The clinical question aspect poses an interesting problem for retrieval: A document is only relevant if it refers to the disease or condition(s) described in the topic query and if it contains enough information that is useful for answering the clinical question.</p><p>We hypothesized that documents which are indexed with MeSH terms that pertain to the clinical questions, e.g. "diagnosis"[Subheading] for the diagnosis question, would be the most important to nd while other documents that may refer to the same disease but not contain information specic to the clinical question would only constitute noise, especially in the Bag-of-Word experiments (see infra).</p><p>We therefore opted for a ltering approach in which we translated the clinical question types into MeSH queries that were used to query PubMed Open Access subset online. The returned result sets were then ltered, only keeping those documents that also appeared in the provided snapshot.</p><p>This process resulted in three dierent subcorpora (hereafter referred to as `diagnosis corpus', `test corpus' and `treatment corpus') that were used for further experiments.</p><p>We used the following MeSH queries: 3 . The Test query was manually created for <ref type="bibr" coords="3,102.89,631.68,3.65,7.30" target="#b2">3</ref> These and other meta-terms can be found at http://doccismef.chu-rouen.fr/liste_des_meta_termes_ anglais.html this competition by a medical expert. It was designed to focus on patient care. Table <ref type="table" coords="4,485.68,100.02,4.98,6.64" target="#tab_1">1</ref> shows the number of documents in each subcorpus after ltering. Some documents appeared in all three subsets.</p><p>Clinical question type # of documents </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Symptom extraction and disease hypotheses generation</head><p>To bridge the gap between case report and MeSH index terms, we built a Diagnostic Clinical Decision Support System (a.k.a. Symptom Checker System) to generate hypotheses of possible diseases or medical conditions for a given case report. Our system is a simple retrieval engine (Terrier using the BM25 ranking algorithm) in which diseases and their associated symptoms have been indexed. It does not contain a rule-based component or an inference engine over previous case reports. Two knowledge bases were used to construct the index, i.e. OrphaNet 4 and the Disease- Symptom Knowledge Database 5 (DSKD) [3]. OrphaNet covers 6942 rare diseases; the DSKD covers 150 very frequent diseases. This is not an exhaustive list of possible diagnoses. We converted the UMLS terms in the DSKD for diseases and their symptoms to their associated MeSH terms using the "Restrict to MeSH" algorithm [1]. OrphaNet utilizes a combination of MeSH and UMLS terms as well as vocabulary from other sources. For these terms we tried to nd the related MeSH terms through "Restrict to MeSH" or related entry terms in the MeSH vocabulary. We indexed both the MeSH terms and the individual words that make up the terms.</p><p>We extracted MeSH terms from the case reports (topic queries) by annotating them with MetaMap 6 and transforming the output with "Restrict to MeSH". These were then provided to the Disease-Symptom Checker both as MeSH terms and as individual words. For each case report we collected the top 5 diagnoses outputted by the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Age and gender extraction</head><p>We wrote a short perl script to extract gender and age information from the case reports. were also included in the eventual query with OR operator so the nal query would not be too restrictive. Overall the extraction worked very well. For three topics we were not able to extract gender information since this was not explicitly mentioned in the case summaries. <ref type="bibr" coords="4,102.89,594.99,3.65,7.30" target="#b3">4</ref> Orphadata: Free access data from Orphanet. c INSERM 1997. Available on http://www.orphadata.org [4]. Data version 1.0.20</p><p>5 Freely accessible at http://people.dbmi.columbia.edu/~friedma/Projects/DiseaseSymptomKB/index.html 6 Can be found at http://metamap.nlm.nih.gov/ 2.4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieval</head><p>Two dierent retrieval engines were used for the reported experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Terrier</head><p>For the bag-of-words components of runs 1, 4 and 5 we used the Terrier search engine 7 (version 3.6) with an individual index for each of the three subcorpora described in Table <ref type="table" coords="5,456.38,174.65,3.87,6.64" target="#tab_1">1</ref>. We did not apply any stemming but did carry out stopword removal in indexing and searching processes for our runs. All runs consisted of a probabilistic retrieval model based on the BM25 scoring function with the default parameters.</p><p>We indexed all elds of the original NXML les except the &lt;journal-meta&gt; and dependent elds, the &lt;contrib-group&gt; from &lt;article-meta&gt; and the &lt;back&gt; and dependent elds.</p><p>We noticed that some of the PMC identiers were not indexed by Terrier since these codes violate the second tokeniser condition ("2. Any term which has more than 4 digits is discarded.") We therefore dened our own tokenizer which also allowed more than 3 consecutive identical characters to occur.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Retrieval using PubMed</head><p>The retrieval results in runs 2 and 3 were obtained by querying PubMed directly and then converting the retrieved PubMed Identiers (pm_id) to their PubMedCentral (pmc) equivalents. Since the Open Access set had grown (compared to the 21-01-2014 snapshot provided by the organizers), we ltered out the more recent articles. The rankings of the retrieved results are taken directly from PubMed's "Sort by Relevance" feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Submitted runs</head><p>As mentioned above, all 5 runs use the same approach of selecting documents by clinical question type. In runs 2 and 3 MeSH queries are constructed which are used to query PubMed directly.</p><p>Runs 1, 4 and 5 are BoW runs on the indexed subcorpora in Terrier.</p><p>Table <ref type="table" coords="5,134.14,464.97,4.98,6.64" target="#tab_4">2</ref> gives an overview of the components used for the dierent runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Representation of medical case</head><p>Strategy for Clinical Question type   <ref type="bibr" coords="5,102.89,632.67,3.65,7.30">7</ref> Can be downloaded at http://terrier.org/ Run1BoWC is a baseline run. The individual words from the case report form the query that is used to query the relevant subcorpus index (diagnosis|test| treatment) in Terrier.</p><p>In Run2MeSHDi each case report is put through the Symptom Checker and the top 5 of the resulting hypotheses are transformed into MeSH terms. These are combined (with OR) to form a basic query. In a second step, the age group and gender are extracted from case report, transformed into their respective MeSH terms and added to the query. Finally we combine the query with the manually made MeSH query for the relevant clinical type. We use the nal MeSH to query PubMed directly.</p><p>Run3MeSHDiCa is identical the procedure for Run2 except that the nal MeSH queries also contain the MeSH terms for symptoms extracted from the case reports which were selected using MetaMap and the "Restrict to MeSH" algorithm.</p><p>In Run4BoWDiCa each case report is put through the Symptom Checker and the name variants (extracted from UMLS, OrphaNet and DSKB) from the top 5 hypotheses are combined with the words from the case report to form Bag-of-Word queries. We then performed text-based retrieval in the relevant subcorpus index (diagnosis|test| treatment) in Terrier.</p><p>Run5BoWDiCaS is identical to the procedure for Run4 except that the nal nal BoW queries also include the name variants for the symptoms extracted from the case reports.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Table <ref type="table" coords="6,118.41,393.89,4.98,6.64" target="#tab_5">3</ref> summarizes the results of our ocial submitted runs as well as one additional run, according to the following ocial measures: bpref, R-prec and P10. The last column shows the number of relevant documents retrieved. We observe that the best among the ocial submitted runs is the run in which MeSH queries based on symptoms and disease hypotheses extracted from the case reports were used to query PubMed directly. Compared to the other participants we achieved relatively low scores: For only 6 out of 30 topics were our P10 scores equal or higher to the median of the scores of all participants for that topic.</p><p>Preliminary analysis of the ocial results shows that these low scores are -partly-caused by our too strict ltering approach in selecting documents per clinical question type. Table <ref type="table" coords="6,486.17,625.11,4.98,6.64" target="#tab_1">1</ref> shows that the three subsets comprise 236,846 documents in total which means that around 67% of the original corpus was not included. In regards to the number of relevant documents (based on the qrels that were made available after the competition), the ltering on clinical question type had a devastating eect on recall: In the diagnosis, treatment and test subcorpus respectively only 35%, 20% and 36% of the relevant documents were present. While the idea of using these MeSH terms to nd documents specic to the clinical questions still seems worthwhile, it would be better to use them for reranking purposes than for strict ltering.</p><p>To investigate the impact of the disease hypothesis generation we reran Run3 but this time did not add the MeSH terms for disease hypotheses. The scores of this run can be found in the bottom row of Table <ref type="table" coords="7,189.81,195.66,3.87,6.64" target="#tab_5">3</ref>. We can see that the scores are very close to the best performing run (Run3MeSHDiCa) which shows that the impact of the disease hypothesis generation is minimal.</p><p>A further analysis of the MeSH terms associated with the documents in the relevance assessments is needed to determine to what extent the disease generation method outputted incorrect terms and/or missed correct terms. We attribute its lack of impact -in part-to the incomplete coverage of potential diseases and conditions by the Symptom Checker.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper discussed LIMSI's participation in the 2014 Clinical Decision Support Track. We opted for an exploratory approach in which we tested the impact of retrieval systems based on Bag of Words versus MeSH index terms. The highest scoring ocial run was a MeSH run which combined MeSH terms extracted from the case reports with those of the top 5 disease hypotheses generated from the case reports. To solve the problem of relevancy in terms of clinical question type we performed ltering on selected MeSH terms which proved too strict and encumbered recall. Though our approach did not yield good results we see it as a good starting point for future participation in the track.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,103.98,191.75,204.24,6.64;2,103.98,210.91,222.56,6.64;2,103.98,230.07,278.14,6.64;2,106.75,250.07,413.45,6.64;2,91.80,262.02,428.39,6.64;2,91.80,273.98,46.59,6.64"><head>1 .</head><label>1</label><figDesc>What is the patient's diagnosis? (diagnosis) 2. How should the patient be treated? (treatment) 3. Which tests should be prescribed to treat the patient? (test) The target document collection is a 21-01-2014 snapshot from the Open Access Subset from PubMed Central (PMC). It contains 733,138 articles which were furnished in NXML format by the organizers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,167.28,157.01,277.44,60.92"><head>Table 1 :</head><label>1</label><figDesc>Size of clinical question subcorpora in # of documents</figDesc><table coords="4,204.94,157.01,154.68,30.55"><row><cell>Diagnosis</cell><cell>179,344</cell></row><row><cell>Treatment</cell><cell>126,026</cell></row><row><cell>Test</cell><cell>121,111</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,204.75,618.43,202.49,6.64"><head>Table 2 :</head><label>2</label><figDesc>System components for dierent runs</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,166.75,455.03,278.49,118.88"><head>Table 3 :</head><label>3</label><figDesc>Retrieval scores for ocial runs</figDesc><table coords="6,166.75,455.03,278.49,88.51"><row><cell>Run name</cell><cell cols="4">bpref R-prec P10 num_rel_ret</cell></row><row><cell>Run1BoWC</cell><cell>0.0104</cell><cell>0.0061</cell><cell>0.0100</cell><cell>63</cell></row><row><cell>Run2MeSHDi Run3MeSHDiCa</cell><cell cols="3">0.0106 0.0177 0.0135 0.0433 0.0077 0.0133</cell><cell>41 107</cell></row><row><cell>Run4BoWDiCa</cell><cell>0.0098</cell><cell>0.0076</cell><cell>0.0167</cell><cell>67</cell></row><row><cell>Run5BoWDiCaS</cell><cell>0.0067</cell><cell>0.0039</cell><cell>0.0100</cell><cell>45</cell></row><row><cell>RunMeSHDiCa</cell><cell>0.0168</cell><cell>0.0122</cell><cell>0.0467</cell><cell>109</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,107.30,448.65,412.91,6.64;7,107.30,460.60,300.04,6.64;7,410.79,454.48,109.40,14.81;7,107.30,466.43,50.11,14.81;7,160.72,472.56,258.08,6.64" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,465.53,448.65,54.67,6.64;7,107.30,460.60,281.77,6.64">Beyond synonymy: exploiting the UMLS semantics in mapping vocabularies</title>
		<author>
			<persName coords=""><forename type="first">Olivier</forename><surname>Bodenreider</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Stuart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><forename type="middle">T</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hole</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chang</forename><surname>Florence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,410.79,454.48,109.40,14.81;7,107.30,466.43,45.10,14.81">Proceedings of the AMIA symposium</title>
		<meeting>the AMIA symposium</meeting>
		<imprint>
			<publisher>American Medical Informatics Association</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page">815</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.30,492.48,412.90,6.64;7,107.30,504.44,412.90,6.64;7,107.30,516.39,132.82,6.64;7,244.27,510.27,193.74,14.81;7,441.20,516.39,79.00,6.64" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,199.25,504.44,320.94,6.64;7,107.30,516.39,128.59,6.64">Using CISMeF MeSH Encapsulated terminology and a categorization algorithm for health resources</title>
		<author>
			<persName coords=""><forename type="first">Aurélie</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lina</forename><forename type="middle">F</forename><surname>Soualmia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Magaly</forename><surname>Douyère</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexandrina</forename><surname>Rogozan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benoît</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stéfan</forename><forename type="middle">J</forename><surname>Darmoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,244.27,510.27,189.40,14.81">International journal of medical informatics</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">5764</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.30,536.32,412.90,6.64;7,107.30,548.27,295.49,6.64;7,405.82,542.15,114.38,14.81;7,107.30,554.11,52.41,14.81;7,163.03,560.23,318.40,6.64" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,107.30,548.27,278.21,6.64">Automated knowledge acquisition from clinical narrative reports</title>
		<author>
			<persName coords=""><forename type="first">Xiaoyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amy</forename><surname>Chused</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noémie</forename><surname>Elhadad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carol</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marianthi</forename><surname>Markatou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,405.82,542.15,114.38,14.81;7,107.30,554.11,48.05,14.81">AMIA Annual Symposium Proceedings</title>
		<imprint>
			<publisher>American Medical Informatics Association</publisher>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="page">783</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.30,580.16,412.90,6.64;7,107.30,592.11,137.60,6.64;7,249.12,585.99,173.89,14.81;7,426.23,592.11,93.97,6.64" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,438.51,580.16,81.69,6.64;7,107.30,592.11,133.53,6.64">Orphanet: a European database for rare diseases</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Steanie S Weinreich</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Mangon</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Sikkens</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Teeuw</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Cornel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,249.12,585.99,169.27,14.81">Nederlands tijdschrift voor geneeskunde</title>
		<imprint>
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">518519</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
