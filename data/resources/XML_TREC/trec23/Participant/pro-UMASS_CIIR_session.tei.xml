<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,200.80,111.03,210.41,15.48;1,186.10,130.96,239.81,15.48;1,200.62,150.88,210.77,15.48">UMass at TREC WEB 2014: Entity Query Feature Expansion using Knowledge Base Links</title>
				<funder ref="#_HZQhgdF">
					<orgName type="full">IBM</orgName>
				</funder>
				<funder ref="#_gqau3fk">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder>
					<orgName type="full">Center for Intelligent Information Retrieval</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,241.71,211.65,51.19,8.96"><forename type="first">Laura</forename><surname>Dietz</surname></persName>
							<email>dietz@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Massachusetts Amherst</orgName>
								<address>
									<region>MA</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,313.94,211.65,58.84,8.96"><forename type="first">Patrick</forename><surname>Verga</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Massachusetts Amherst</orgName>
								<address>
									<region>MA</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,200.80,111.03,210.41,15.48;1,186.10,130.96,239.81,15.48;1,200.62,150.88,210.77,15.48">UMass at TREC WEB 2014: Entity Query Feature Expansion using Knowledge Base Links</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D4441F21D4F75BB071CD03C5546495E7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Entity linking tools predict links between entity mentions in text and knowledge base entries. In this work we leverage the rich semantic knowledge available through these links to understand relevance of documents for a query. We focus on the ad hoc task on the category A subset and demonstrate the benefit of entity-centric approaches even for non-entity queries like "dark chocolate health benefits".</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent advances in automatic entity linking and knowledge base construction have resulted in entity annotations for document and query collections. For example, Google's FACC1 data set <ref type="bibr" coords="1,457.07,412.44,11.62,8.64" target="#b2">[3]</ref> contains entity annotations for all documents in the ClueWeb collection. Understanding how to leverage these entity annotations embedded in text to improve ad hoc document retrieval is an open research area.</p><p>Query expansion is a commonly used technique to improve retrieval effectiveness. Most previous query expansion approaches focus on text, mainly using unigram concepts. In this TREC submission, we follow up on our SIGIR paper <ref type="bibr" coords="1,267.17,471.77,10.58,8.64" target="#b1">[2]</ref>, where we propose a new technique, called entity query feature expansion (EQFE). Our approach is to enrich the query with features from relevant entities and their links to knowledge bases, including structured attributes and text. We use a graphical model that performs joint inference on the relevance of latent entities and relevance of documents from target collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>We assume availability of a general purpose knowledge base and the capability of establishing entity links from mentions in documents to the knowledge base. For this submission we use a Wikipedia dump from January 2012 (Wiki WEX dump), which we augment with extracted name variants from Wiki-internal anchor text and an anchor text resource from the open web <ref type="bibr" coords="1,416.23,597.51,10.58,8.64" target="#b5">[6]</ref>, and merged with Freebase names and types. We index all knowledge base articles with the retrieval engine Galago. <ref type="foot" coords="1,500.02,606.80,3.49,6.05" target="#foot_0">1</ref>We use entity links provided in the FACC1 dataset <ref type="bibr" coords="1,309.78,619.43,11.62,8.64" target="#b2">[3]</ref> for the ClueWeb12 corpus Category A and B.</p><p>We index all ClueWeb 12 Category A documents with Indri<ref type="foot" coords="1,362.02,633.26,3.49,6.05" target="#foot_1">2</ref> and merge them with entity link annotations from the FACC1 dataset.</p><p>We devise a retrieval model is not just based on keywords in the query and keyword expansion, but that further reasons about which entities are relevant and then uses entity-information to rank documents. Figure <ref type="figure" coords="1,188.78,683.30,4.98,8.64" target="#fig_1">1</ref> summarizes our retrieval model in factor graph notation, where each factor (black box) assigns a compatibility score to settings of indicent variable. We are using log-linear  factors that are formed through an inner product of a feature vector φ with a parameter vector that is to be determined. In this section we explain three parts of the model: 1) how to retrieve entities that are relevant for the query; 2) given entities and a query, how to retrieve documents that are relevant; and 3) how to identify the relevant aspects of each entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Joint Entity Retrieval</head><p>We found different ways to derive indicators for relevant entities. One indicator is to perform probabilistic document retrieval with the query Q against the Galago index of knowledge base documents. We refer to this distribution as E ∼ φ kb (Q, E).</p><p>Alternatively, we can derive indicators for relevant entities through a pseudo-relevance feedback approach on entity links in ClueWeb documents. Using conventional keyword retrieval models, we retrieve an initial distribution over documents D ∼ φ ir (Q, D). In this work, we consider the sequential dependence model <ref type="bibr" coords="2,221.54,350.15,11.62,8.64" target="#b4">[5]</ref> with relevance model query expansion (SDM-RM3) for the initial document distribution <ref type="bibr" coords="2,199.92,361.10,10.58,8.64" target="#b3">[4]</ref>. Extending the idea of the relevance model to bags-of-entities, we derive a distribution over entities as a document-weighted mixture model over document-wise entity language models.</p><formula xml:id="formula_0" coords="2,220.70,405.90,169.40,26.88">E ∼ φ doc (Q, E) = d p(d|Q) #{e ∈ d} #{• ∈ d}</formula><p>In order to prefer entities that are close to query keywords across many documents, we propose an alternative look onto the documents. Inspecting high ranked documents from the initial ranking, we consider the context surrounding each entity link using varying windows of 8 and 50 terms. Contexts are grouped by knowledge base entry, and all contexts surrounding the same entity are merged into one pseudo document which we call the entity contexts. We can score these entity contexts with the initial retrieval model for how relevant the entity is for the query. We refer to this entity distribution as E ∼ φ ecm (D, Q, E).</p><p>A last indicator can be derived by applying an entity linking tool to the query text and thereby identifying entity mentions in the query. For instance in the example query "obama family tree", the mention "obama" can be linked to the Wikipedia entry "Barack_Obama". In previous work we noticed that most entity linking tools do not work well on query text, due to lack of grammatical structure. As TREC web track queries are unlikely to mention entities directly, we omit this kind of source for this submission.</p><p>Given a parameter vector (which is to be determined), we can aggregate the different entity indicators into one distribution over entities p(E|Q) as in Figure <ref type="figure" coords="2,325.63,608.76,7.93,8.64" target="#fig_1">1a</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Joint Document Retrieval</head><p>The joint document retrieval model combines keyword-based retrieval models with entity-based retrieval models. We use different state-of-the-art keyword-based probabilistic retrieval models such as the sequential dependence model, a query likelihood model, and relevance model query expansion. With weight parameters, these can be integrated into one distribution over documents, e.g.</p><formula xml:id="formula_1" coords="2,108.00,696.60,65.40,12.28">D ∼ φ ir (Q, D).</formula><p>We combine these scores with additional indicators that take the distribution of query-relevant entities p(E|Q) into account. We exploit that each entity has distributions over name aliases, words, types, and an entity id associated. When mixed according to p(E|Q), we can use these different distributions to derive a new retrieval model.</p><p>For instance, we derive a distribution over categories C from the knowledge base as</p><formula xml:id="formula_2" coords="3,246.96,125.95,118.08,22.96">C ∼ ˆφ(E, Q)φ(E, C) dE,</formula><p>where φ(E, C) denotes a distribution over Wikipedia category labels for the entity E which is smoothed with the collection-level category distribution. We use this distribution over categories as query expansions as well as for features for supervised re-ranking-a parameter is the cut-off for number of entities E considered.</p><p>Likewise, distributions over name aliases A, entity identifiers E, ontological Freebase types T , and words W (from the Wikipedia article) can be derived. Retrieval models over words W and aliases A match against the full text of the web documents. Since entity linking annotations already exist for all documents are already entity linked, entity IDs E can be matched against entity link targets, as well as types T and categories C can be matched against types of link targets. For name aliases we use the sequential dependence model with collection level smoothing; for entities E, words W , categories C, and types T we use a query likelihood model with collection level smoothing.</p><p>The score of a document D under each respective retrieval model can be turned into an entityinspired feature φ(Q, D) over each vocabulary type or, given a weight vector, interpreted as a combined retrieval model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Learning Query-specific Entity-information</head><p>So far, we derived entity-typical information directly from the knowledge base article. This follows the assumption that if an entity is relevant, then all of its aspects are equally relevant. This is not necessarily true. For example, the entity "Agriculture" is clearly relevant for a query about farming in a developing country, but its aspect on large-scale corn farming in the United States is not relevant.</p><p>So far all entity-characteristic words W are taken form the Wikipedia article, which is the basis of the WikiRM model. An entity-independent source is a relevance model estimated from retrieved documents <ref type="bibr" coords="3,153.32,441.92,10.58,8.64" target="#b3">[4]</ref>. Here, we suggest a third option; using the entity context derived through entity links.</p><p>We build a collection-smoothed language model over context surrounding an entity's link to derive an alternative distribution over words W .</p><p>We also consider that depending on the context, an entity might be referred to via different names, e.g. referring to its function or nickname. We also consider the case of entities in documents that do not have an entry in the knowledge base. Both cases are addressed by deriving a distribution over named entity mentions M from documents through pseudo-relevance feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Learning Procedure</head><p>In Sections 2.1 through 2.3, we discussed several relevance indicators for entities given the query and documents given entities.</p><p>It is not realistic to expect availability of relevance data for entities, as typical IR benchmarks like the TREC Web training queries from 2013 only include relevance judgments for documents. We suggest a learning procedure that integrates over latent entity variables E by computing the cross product of entity-query features and document-entity features.</p><p>We denote document-entity features through the vocabulary that is matched in the document, i.e. entity link with identifier E, name aliases A, and unlinked entity mentions M , as well as Wikipedia category C and Freebase type T as a surrogate through the enity identifier.</p><p>For each of these vocabularies a query-indicative distribution can be derived through different entityrelevance distributions. In particular through issuing the query agains the knowledge base ("kb"); through documents of a pseudo-relevance feedback pass ("doc"), and the entity context ("ecm").</p><p>The cross-product of these features is further merged with different traditional retrieval models, such as the baseline retrievals, query expansion and spam scores provided by the organizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Evaluation</head><p>We use an Indri index of the ClueWeb12 Category A collection created using default parameters. We do not apply spam filtering on the ClueWeb12 documents, because we noticed many relevant documents with spam score 0. For all queries from the 2013 training set and the 2014 test set we derive a pooled corpus using the top 10,000 documents retrieved by the following models:</p><p>• Query Likelihood; provided by organizers • Query Likelihood with RM3; provided by organizers • Terrier; provided by organizers • Sequential Dependence Model (SDM) <ref type="bibr" coords="4,299.36,226.31,10.79,8.64" target="#b4">[5]</ref>; contributed as manual run • WikiRM1 baseline (expansion for SDM); contributed as manual run</p><p>WikiRM is an external feedback model which uses the Wikipedia knowledge base as a text collection. WikiRM1 extracts terms from the highest ranked Wikipedia articled returned by querying the knowledge base and to be used as expansion terms for a sequential dependence model on the original query terms (SDM-RM3). Models similar to WikiRM1 were shown to be effective for these collections in previous work <ref type="bibr" coords="4,224.71,296.61,10.79,8.64" target="#b0">[1,</ref><ref type="bibr" coords="4,238.33,296.61,7.19,8.64" target="#b6">7]</ref>. While WikiRM1 uses Wikipedia as an external corpus, it does not leverage entity links, entity names, categories, or ontological types from the knowledge base.</p><p>We pool the top 10,000 results of each retrieval model and merge the pooled documents with entity link annotations from the FACC1 data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Submitted Runs</head><p>We submitted three automatic runs, and two baselines as manual runs. All runs use a knowledge base index built from a January 2012 Wikipedia dump and entity links provided in the FACC1 annotations. The automatic runs were created with supervised reranking using RankLib's coordinate ascent optimized for ERR@20 with no normalization and 1 start.</p><p>Our five runs are described below.</p><p>CiirAll1 Combination of all 40 features, all entity context features and all baseline features as listed in Table <ref type="table" coords="4,166.70,457.32,3.74,8.64" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CiirSub1 and CiirSub2</head><p>Combination of a subset of 13 entity context features as marked with 'X' in Table <ref type="table" coords="4,142.62,490.04,3.74,8.64" target="#tab_0">1</ref>.</p><p>CiirSdm (Manual Run) Indri sequential dependence model with standard parameters 0.8, 0.15, 0.05</p><p>CiirWikiRm (Manual Run) SDM with Wikipedia expansion model (generated with Indri). Parameters: SDM default parameters 0.8, 0.15, 0.05; RM weight 0.8/0.2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results on Train/Validation data</head><p>We used a restricted training procedure due to time constraints before the submission. We trained the supervised models on a very limited training collection consisting the pooled top 100 documents retrieved by each method. Further, we used one re-start with coordinate ascent.</p><p>We measure the performance of each feature individually and the training set performance of the combined runs in terms of ERR-IA@20, ERR-IA@10, and MAP-IA.</p><p>Results on methods and invidual EQFE features on the training set are presented in Table <ref type="table" coords="4,477.95,661.56,3.74,8.64" target="#tab_0">1</ref>. We see that all contributed methods outperform the best baseline contributed by the organizers by 20% in ERR-IA@10. Also, our automatic run All1 is only marginally better than Sub2. All1 includes features from the baselines contributed by the organizers while Sub2 is trained only on a subset of the features. The subset of features are denoted by an 'X' in the last column of Table </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results on Test data</head><p>We applied the learned re-ranking model to the pool of the top 10,000 retrieved documents from each retrieval method. The difference in characteristics between the training (top 100) and test set (top 10,000) led to suboptimal results. We present the official results in Table <ref type="table" coords="6,264.83,390.16,8.30,8.64">3b</ref>. The reranking method with all features outperforms the SDM and WikiRM baselines. In contrast to the results on the training set, reranking based on feature subsets performed substantially worse achieving only about half the ERR@20 of the other methods.</p><p>Analyzing correlations in query-by-query performance, we notice that the performance of Sub1 is highly correlated to performance of Sub2, i.e., Sub1 is doing well when Sub2 is also doing well. This indicates that the few restarts are unlikely to be the issue. We notice that for ten queries, Sub1/2 are at least 1.5 times as good as the SDM baseline (cf. Table <ref type="table" coords="6,334.63,460.45,9.40,8.64" target="#tab_1">2a</ref> where we also display the best queries).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Crossvalidation experiments in Cat B</head><p>We also recap previous experiments on the ClueWeb12 category B subset with training queries from the 2013 dataset with five-fold-crossvalidation using the search engine Galago. The effectiveness of our query feature expansion is compared with sequential dependence model, the WikiRM1 method, and SDM expanded with Relevance Model (SDM-RM3), and Indri's query likelihood model (Indri-QL), as provided by the track organizers.</p><p>The overall retrieval effectiveness across different methods and collections is presented in Table <ref type="table" coords="6,494.60,571.84,9.40,8.64">3a</ref> and Figure <ref type="figure" coords="6,155.78,582.79,7.93,8.64">2a</ref>. Our proposed EQFE model is the best performer on MAP for the ClueWeb12B collection. A paired t-test with α-level 5% indicates that the improvement of EFQE over SDM is statistically significant.</p><p>We further analyze whether the EQFE method improves particularly difficult or easy queries. To do that, we order queries by performance achieved by the SDM baseline. In Figure <ref type="figure" coords="6,447.79,631.17,9.96,8.64">2b</ref> we display the different difficulty percentiles, organizing the queries from most difficult to easiest. The 5% of the hardest queries are represented by the left-most cluster of columns, the 5% of the easiest queries in the right-most cluster of columns, the middle half is represented in two middle clusters (labeled "25%-50%" and "50%-75%").</p><p>This analysis shows that EQFE especially improves hard queries. EQFE outperforms all methods, except for the top 5% of the easiest queries. We achieve this result despite having on average 7 unjudged documents in the top 20 and 2.5 unjudged documents in the top 10 (in both the "5%-25%" and "25%-50%" cluster), which are counted as negatives in the analysis. The WikiRM1 method, which is the most similar expansion method to EQFE, demonstrates the opposite characteristic, outperforming EQFE only on "easiest" percentiles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>We presented results from our Entity Query Feature Expansion approach <ref type="bibr" coords="7,406.84,347.20,11.62,8.64" target="#b1">[2]</ref> applied to data from the TREC web track 2013 Cat A, the test set from 2014 Cat A, and cross-validation experiments coducted on 2013 Cat B.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,116.64,113.80,6.10,6.76;2,158.45,114.55,5.69,6.76;2,200.05,114.55,6.38,6.76;2,112.48,153.82,100.00,6.24;2,253.91,101.54,5.69,6.76;2,307.10,101.54,5.78,6.76;2,305.82,125.17,7.28,6.76;2,253.94,137.01,5.51,6.76;2,281.10,137.01,4.51,6.76;2,249.35,151.25,85.61,6.24;2,389.88,94.80,6.38,6.76;2,430.85,94.80,7.48,6.76;2,473.77,94.80,5.69,6.76;2,389.00,130.27,7.28,6.76;2,386.97,153.82,99.92,6.24"><head></head><label></label><figDesc>Representation of documents D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,159.55,172.02,289.81,8.64"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Graphical model for joint document and entity retrieval model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,148.39,223.29,14.57,6.99;7,183.27,223.29,112.36,6.99;7,119.62,218.34,15.02,6.99;7,119.66,203.87,15.02,6.99;7,119.63,189.41,15.02,6.99;7,119.61,174.94,15.02,6.99;7,119.59,160.48,15.02,6.99;7,119.62,146.01,15.02,6.99;7,119.66,131.55,15.02,6.99;7,119.63,117.08,15.02,6.99;7,119.61,102.62,15.02,6.99;7,119.59,88.15,15.02,6.99;7,110.73,143.31,6.99,25.31;7,108.00,238.01,200.49,7.77;7,108.00,247.97,61.55,7.77;7,337.47,218.52,141.13,3.57;7,349.86,223.88,115.59,6.50;7,319.30,215.36,7.68,3.57;7,319.27,201.91,7.68,3.57;7,319.30,188.47,7.68,3.57;7,319.27,175.02,7.68,3.57;7,319.30,161.58,7.68,3.57;7,319.27,148.13,7.68,3.57;7,319.30,134.68,7.68,3.57;7,319.27,121.24,7.68,3.57;7,319.30,107.79,7.68,3.57;7,319.27,94.34,7.68,3.57;7,311.03,144.18,6.50,23.53;7,346.51,100.56,9.75,4.68;7,346.51,107.59,6.02,4.68;7,346.51,114.61,19.51,4.68;7,346.51,121.64,14.06,4.68;7,346.51,128.66,15.49,4.68;7,308.49,238.01,180.69,7.77;7,375.42,247.97,113.77,7.77;7,308.49,257.94,99.87,7.77"><head></head><label></label><figDesc>Mean retrieval effectiveness across different measured according to the percentile of the SDM method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,448.10,705.40,7.47,8.64"><head>Table 1 :</head><label>1</label><figDesc><ref type="bibr" coords="4,448.10,705.40,3.74,8.64" target="#b0">1</ref>. Performance of individual features, baselines (typewriter) and combined methods (bold), ordered by ERR-IA@20. The letters in the φ(E, D) column refer to the type of the information. W denotes words, E entity IDs, T types, C categories, M mentions, A name aliases, and W * words from KB article through entity links. The φ(Q, E) column refers to the indicator for relevant entities used where doc refers to corpus documents, kb to knowledge base documents, and ECM to entity contexts.</figDesc><table coords="5,113.98,85.17,346.80,485.27"><row><cell>Run / Feature</cell><cell>φ(E, D)</cell><cell>φ(Q, E)</cell><cell>Sub1/2</cell><cell>ERR-IA@10</cell><cell>ERR-IA@20</cell><cell>MAP-IA</cell></row><row><cell>CiirAll1</cell><cell></cell><cell></cell><cell></cell><cell>0.640817</cell><cell>0.651061</cell><cell>0.145293</cell></row><row><cell>CiirSub2</cell><cell></cell><cell></cell><cell></cell><cell>0.646</cell><cell>0.65</cell><cell>0.192</cell></row><row><cell>CiirSub1</cell><cell></cell><cell></cell><cell></cell><cell>0.585188</cell><cell>0.593584</cell><cell>0.182323</cell></row><row><cell>terrier-baseline</cell><cell></cell><cell></cell><cell></cell><cell>0.488953</cell><cell>0.499958</cell><cell>0.151134</cell></row><row><cell>CiirWikiRM (manual run)</cell><cell></cell><cell></cell><cell>X</cell><cell>0.441862</cell><cell>0.449224</cell><cell>0.146358</cell></row><row><cell>CiirSdm (manual run)</cell><cell></cell><cell></cell><cell>X</cell><cell>0.393408</cell><cell>0.402837</cell><cell>0.159584</cell></row><row><cell>rm-baseline</cell><cell></cell><cell></cell><cell></cell><cell>0.370645</cell><cell>0.375283</cell><cell>0.126118</cell></row><row><cell>feature-contextFeatsentity-8</cell><cell>W</cell><cell>ECM</cell><cell>X</cell><cell>0.357623</cell><cell>0.366816</cell><cell>0.106399</cell></row><row><cell>ql-baseline</cell><cell></cell><cell></cell><cell></cell><cell>0.355609</cell><cell>0.365256</cell><cell>0.135077</cell></row><row><cell>ql-spam-filtered</cell><cell></cell><cell></cell><cell></cell><cell>0.348758</cell><cell>0.360416</cell><cell>0.10684</cell></row><row><cell>rm-spam-filtered</cell><cell></cell><cell></cell><cell></cell><cell>0.343325</cell><cell>0.353163</cell><cell>0.104951</cell></row><row><cell>feature-contextFeats-idQL-entity-50-20</cell><cell>E</cell><cell>ECM</cell><cell>X</cell><cell>0.333337</cell><cell>0.342083</cell><cell>0.057906</cell></row><row><cell>feature-contextFeats-idQL-entity-8-20</cell><cell>E</cell><cell>ECM</cell><cell></cell><cell>0.321489</cell><cell>0.332868</cell><cell>0.05712</cell></row><row><cell>feature-contextFeatsentity-50</cell><cell>W</cell><cell>ECM</cell><cell></cell><cell>0.321362</cell><cell>0.33268</cell><cell>0.092048</cell></row><row><cell>feature-names-mention-numEnts20</cell><cell>M</cell><cell>doc</cell><cell>X</cell><cell>0.317012</cell><cell>0.325854</cell><cell>0.075703</cell></row><row><cell>feature-wikipedia-20</cell><cell>W*</cell><cell>kb</cell><cell>X</cell><cell>0.31368</cell><cell>0.32321</cell><cell>0.082976</cell></row><row><cell>feature-contextFeats-names-descentity-50</cell><cell>A</cell><cell>ECM</cell><cell>X</cell><cell>0.309812</cell><cell>0.317491</cell><cell>0.066934</cell></row><row><cell>feature-wikipedia-5</cell><cell>W*</cell><cell>kb</cell><cell></cell><cell>0.307967</cell><cell>0.315215</cell><cell>0.082003</cell></row><row><cell>feature-contextFeats-names-descentity-8</cell><cell>A</cell><cell>ECM</cell><cell></cell><cell>0.302711</cell><cell>0.315073</cell><cell>0.076</cell></row><row><cell>feature-linkedEnts-top1-idQl-20</cell><cell>E</cell><cell>doc</cell><cell>X</cell><cell>0.291321</cell><cell>0.298747</cell><cell>0.051835</cell></row><row><cell>feature-top1names-numEnts20</cell><cell>A</cell><cell>doc</cell><cell>X</cell><cell>0.286737</cell><cell>0.294396</cell><cell>0.065631</cell></row><row><cell>feature-names-mention-numEnts10</cell><cell>M</cell><cell>doc</cell><cell></cell><cell>0.283586</cell><cell>0.293901</cell><cell>0.063472</cell></row><row><cell>feature-wikipedia-1</cell><cell>W*</cell><cell>kb</cell><cell></cell><cell>0.278271</cell><cell>0.286035</cell><cell>0.076898</cell></row><row><cell>feature-collection-20 (RM1)</cell><cell></cell><cell></cell><cell></cell><cell>0.273644</cell><cell>0.282796</cell><cell>0.064824</cell></row><row><cell>feature-wikipedia-names-numEnts10</cell><cell>A</cell><cell>kb</cell><cell></cell><cell>0.244849</cell><cell>0.25628</cell><cell>0.067349</cell></row><row><cell>feature-wiki-idQL-50</cell><cell>E</cell><cell>kb</cell><cell>X</cell><cell>0.234009</cell><cell>0.243401</cell><cell>0.038373</cell></row><row><cell>feature-wikipedia-names-numEnts20</cell><cell>A</cell><cell>kb</cell><cell></cell><cell>0.227854</cell><cell>0.238997</cell><cell>0.070966</cell></row><row><cell>feature-wikipedia-names-numEnts5</cell><cell>A</cell><cell>kb</cell><cell></cell><cell>0.206007</cell><cell>0.219887</cell><cell>0.062106</cell></row><row><cell>feature-wiki-idQL-20</cell><cell>E</cell><cell>kb</cell><cell></cell><cell>0.203334</cell><cell>0.213179</cell><cell>0.037272</cell></row><row><cell>feature-top1-numEnts20</cell><cell>W*</cell><cell>doc</cell><cell></cell><cell>0.202596</cell><cell>0.207457</cell><cell>0.037763</cell></row><row><cell>feature-wiki-idQL-10</cell><cell>E</cell><cell>kb</cell><cell></cell><cell>0.195772</cell><cell>0.20508</cell><cell>0.03657</cell></row><row><cell>feature-wiki-idQL-1</cell><cell>E</cell><cell>kb</cell><cell></cell><cell>0.190529</cell><cell>0.199752</cell><cell>0.03292</cell></row><row><cell>feature-wikipedia-names-numEnts1</cell><cell>A</cell><cell>kb</cell><cell></cell><cell>0.171216</cell><cell>0.182375</cell><cell>0.055716</cell></row><row><cell>feature-top1-numEnts10</cell><cell>W*</cell><cell>doc</cell><cell></cell><cell>0.16566</cell><cell>0.17228</cell><cell>0.031786</cell></row><row><cell>feature-top1-numEnts1</cell><cell>W*</cell><cell>doc</cell><cell></cell><cell>0.159872</cell><cell>0.164304</cell><cell>0.040393</cell></row><row><cell>feature-wiki-categoryQl-1</cell><cell>C</cell><cell>kb</cell><cell></cell><cell>0.141777</cell><cell>0.152451</cell><cell>0.031231</cell></row><row><cell>feature-categoryQl-20</cell><cell>C</cell><cell>doc</cell><cell></cell><cell>0.139191</cell><cell>0.143512</cell><cell>0.026689</cell></row><row><cell>feature-wiki-typeQl-5</cell><cell>T</cell><cell>kb</cell><cell></cell><cell>0.085307</cell><cell>0.090245</cell><cell>0.009785</cell></row><row><cell>feature-wiki-typeQl-1</cell><cell>T</cell><cell>kb</cell><cell></cell><cell>0.073605</cell><cell>0.087839</cell><cell>0.015047</cell></row><row><cell>feature-wiki-categoryQl-5</cell><cell>C</cell><cell>kb</cell><cell></cell><cell>0.069046</cell><cell>0.074361</cell><cell>0.01673</cell></row><row><cell>feature-fbTypeQl-20</cell><cell>T</cell><cell>doc</cell><cell></cell><cell>0.060378</cell><cell>0.068659</cell><cell>0.015846</cell></row><row><cell>feature-cluespam</cell><cell></cell><cell></cell><cell></cell><cell>0.024334</cell><cell>0.030719</cell><cell>0.008195</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,116.47,83.05,408.00,280.29"><head>Table 2 :</head><label>2</label><figDesc>Best/Worst queries for Sub1/2 in comparison to SDM.</figDesc><table coords="6,116.47,103.92,408.00,259.42"><row><cell></cell><cell></cell><cell cols="2">(a) Best</cell><cell></cell><cell></cell><cell></cell><cell>(b) Worst</cell></row><row><cell cols="2">Query Title</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Query Title</cell><cell></cell></row><row><cell>271</cell><cell cols="4">halloween activities for middle school</cell><cell>264</cell><cell cols="3">tribe formerly living in alabama</cell></row><row><cell>255</cell><cell cols="2">teddy bears</cell><cell></cell><cell></cell><cell>295</cell><cell cols="3">how to tie a windsor knot</cell></row><row><cell>270</cell><cell cols="2">sun tzu</cell><cell></cell><cell></cell><cell>283</cell><cell cols="2">hayrides in pa</cell></row><row><cell>274</cell><cell cols="2">golf instruction</cell><cell></cell><cell></cell><cell>252</cell><cell cols="2">history of orcas island</cell></row><row><cell>291</cell><cell cols="3">sangre de cristo mountains</cell><cell></cell><cell>287</cell><cell cols="3">carotid cavernous fistula treatment</cell></row><row><cell>263</cell><cell cols="3">evidence for evolution</cell><cell></cell><cell>259</cell><cell cols="2">carpenter bee</cell></row><row><cell>300</cell><cell cols="3">how to find the mean</cell><cell></cell><cell>267</cell><cell cols="2">feliz navidad lyrics</cell></row><row><cell>262</cell><cell cols="2">balding cure</cell><cell></cell><cell></cell><cell>299</cell><cell cols="3">pink slime in ground beef</cell></row><row><cell>280</cell><cell cols="3">view my internet history</cell><cell></cell><cell>278</cell><cell cols="2">mister rogers</cell></row><row><cell>294</cell><cell cols="3">flowering plants</cell><cell></cell><cell>289</cell><cell cols="2">benefits of yoga</cell></row><row><cell>Model</cell><cell></cell><cell>MAP</cell><cell>ERR@20</cell><cell>NDCG@20</cell><cell cols="2">Model</cell><cell>ERR@20</cell><cell>NDCG@20 α-nDCG@20</cell></row><row><cell>SDM</cell><cell></cell><cell>4.18</cell><cell>9.15</cell><cell>12.61</cell><cell cols="2">CiirAll1</cell><cell>0.25</cell><cell>0.15</cell><cell>0.64</cell></row><row><cell cols="2">WikiRM1</cell><cell>4.00</cell><cell>9.31</cell><cell>12.80</cell><cell cols="2">CiirSub1</cell><cell>0.11</cell><cell>0.06</cell><cell>0.36</cell></row><row><cell cols="2">SDM-RM3</cell><cell>3.53</cell><cell>7.61</cell><cell>11.00</cell><cell cols="2">CiirSub2</cell><cell>0.12</cell><cell>0.07</cell><cell>0.36</cell></row><row><cell>EQFE</cell><cell></cell><cell>4.67</cell><cell>10.00</cell><cell>14.61</cell><cell cols="2">CiirSdm</cell><cell>0.23</cell><cell>0.13</cell><cell>0.53</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">CiirWikiRm</cell><cell>0.21</cell><cell>0.12</cell><cell>0.55</cell></row><row><cell></cell><cell cols="3">(a) Results on 2013 Cat B.</cell><cell></cell><cell></cell><cell></cell><cell cols="2">(b) Results on 2014 Cat A.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,124.14,713.17,86.20,7.77"><p>lemurproject.org/galago</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,124.14,724.02,79.28,7.77"><p>lemurproject.org/indri</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,124.14,724.02,140.55,7.77"><p>sourceforge.net/p/lemur/wiki/RankLib/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported in part by the <rs type="funder">Center for Intelligent Information Retrieval</rs> and in part by <rs type="funder">IBM</rs> subcontract #<rs type="grantNumber">4913003298</rs> under DARPA prime contract #<rs type="grantNumber">HR001-12-C-0015</rs>. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_HZQhgdF">
					<idno type="grant-number">4913003298</idno>
				</org>
				<org type="funding" xml:id="_gqau3fk">
					<idno type="grant-number">HR001-12-C-0015</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,124.60,510.85,379.41,8.64;7,124.60,521.63,379.40,8.82;7,124.60,532.59,353.69,8.82" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,369.82,510.85,134.19,8.64;7,124.60,521.81,113.54,8.64">Effective query formulation with multiple information sources</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,256.53,521.63,247.47,8.59;7,124.60,532.59,144.14,8.82">Proceedings of the fifth ACM international conference on Web search and data mining, WSDM &apos;12</title>
		<meeting>the fifth ACM international conference on Web search and data mining, WSDM &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="443" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,124.60,544.11,379.41,8.64;7,124.60,554.89,108.73,8.82" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,311.25,544.11,192.76,8.64;7,124.60,555.07,38.42,8.64">Entity query feature expansion using knowledge base links</title>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Laura</forename><surname>Dietz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,181.04,554.89,22.82,8.59">SIGIR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,124.60,566.41,379.41,8.64;7,124.60,577.37,379.41,8.64;7,124.60,588.33,77.91,8.64" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,415.01,566.41,89.00,8.64;7,124.60,577.37,379.41,8.64;7,124.60,588.33,28.65,8.64">FACC1: Freebase annotation of ClueWeb corpora, version 1 (release date 2013-06-26, format version 1, correction level 0)</title>
		<author>
			<persName coords=""><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Ringgaard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amarnag</forename><surname>Subramanya</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013-06">June 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,124.60,599.50,379.40,8.82;7,124.60,610.45,213.49,8.82" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,280.67,599.67,141.80,8.64">Relevance-Based Language Models</title>
		<author>
			<persName coords=""><forename type="first">Victor</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,443.84,599.50,60.15,8.59;7,124.60,610.45,119.39,8.59">Proceedings of the ACM SIGIR 01 conference</title>
		<meeting>the ACM SIGIR 01 conference</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,124.60,621.98,379.41,8.64;7,124.60,632.76,379.40,8.82;7,124.60,643.72,379.40,8.82;7,124.60,654.85,24.79,8.64" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,281.92,621.98,217.77,8.64">A Markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,136.07,632.76,367.93,8.59;7,124.60,643.72,188.30,8.82">Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;05</title>
		<meeting>the 28th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;05<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,124.60,666.20,379.41,8.64;7,124.60,676.98,285.99,8.82" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,305.94,666.20,198.07,8.64;7,124.60,677.16,33.20,8.64">A Cross-Lingual dictionary for english wikipedia concepts</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Valentin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Angel</forename><forename type="middle">X</forename><surname>Spitkovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,176.32,676.98,205.16,8.59">Conference on Language Resources and Evaluation</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,124.60,688.50,379.41,8.64;7,124.60,699.28,379.40,8.82;7,124.60,710.24,379.40,8.82;7,124.60,721.38,74.60,8.64" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,316.95,688.50,187.06,8.64;7,124.60,699.46,81.01,8.64">Query Dependent Pseudo-relevance Feedback Based on Wikipedia</title>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Gareth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bin</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,229.55,699.28,274.45,8.59;7,124.60,710.24,255.36,8.82">Proceedings of the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;09</title>
		<meeting>the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="59" to="66" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
