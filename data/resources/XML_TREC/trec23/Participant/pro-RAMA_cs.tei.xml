<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,129.02,57.46,353.92,16.88">User Modeling for Contextual Suggestion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,245.45,82.96,34.74,11.26"><forename type="first">Hua</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName coords="1,287.93,82.96,78.72,11.26;1,273.65,102.76,35.48,11.26"><forename type="first">Rafael</forename><forename type="middle">Alonso</forename><surname>Leidos</surname></persName>
						</author>
						<author>
							<persName coords="1,318.19,102.76,15.28,11.26;1,244.26,122.13,9.12,9.34"><forename type="first">Inc</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName coords="1,260.45,122.13,72.89,9.34"><forename type="first">Rafael</forename><surname>Alonso}</surname></persName>
						</author>
						<author>
							<persName coords="1,338.55,122.13,52.07,9.34"><forename type="first">Leidos</forename><surname>Com</surname></persName>
						</author>
						<title level="a" type="main" coord="1,129.02,57.46,353.92,16.88">User Modeling for Contextual Suggestion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A63F8C9F98B27397E3846044CCC7139D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>User Modeling</term>
					<term>Contextual Suggestion</term>
					<term>TREC</term>
					<term>Recommendation System</term>
					<term>General Interest</term>
					<term>Specific Interest</term>
					<term>Context</term>
					<term>Location</term>
					<term>Yelp</term>
					<term>Cosine Similarity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our work on the Contextual Suggestion Track of the Twenty-Third Text REtrieval Conference (TREC  2014). The key to our approach is user interest modeling. By building explicit models of user interests and information needs, we are able to make suggestions relevant to the user. We extended our Reinforcement and Aging Modeling Algorithm (RAMA) to create user interest models using the rated examples in a user profile as explicit relevance feedback. Two models, one for specific interests and the other for general interests, are built for each user profile. To ensure that the recommendations are contextually appropriate, we have also built a simple model to capture contextual relevance of a recommendation. Candidate suggestions are retrieved from the Yelp® 1 website using its application programming interface. For each candidate, we calculate three component scores based on the specific interest model, the general interest model, and the context model, respectively. Final scoring and ranking are computed as a weighted linear combination of the component scores. We hypothesize that the relative weighting of the components may affect the performance of our system. To test the hypothesis, we have submitted two runs with different weighting schemes. In particular, RUN1 has a specific interest priority whereas RAMARUN2 has a general interest priority. TREC evaluation reveals that both runs performed significantly better than the median of all submitted runs (i.e., the Track Median) on three performance metrics. In addition, RAMARUN2 has a slight performance edge over RUN1. The effectiveness of our approach is evidenced by the TREC evaluation result that RAMARUN2 and RUN1 ranked #2 and #6 out of the 31 runs submitted by the 17 participating teams from around the world.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>This is our first participation in the TREC Contextual Suggestion Track. We are interested in this track because of its connection to the area of user modeling. In our view, contextual suggestion is about modeling user's interests and preferences with user relevance feedback and using the models to make smart recommendations. In the past, we have worked on similar problems in a number of research programs. For example, in an IARPA (The Intelligence Advanced Research Projects Activity) program, we modeled the information needs of intelligence analysts and used the models to guide swarming digital ants and combat cognitive biases (Alonso and Li, 2005a, 2005b). In a U.S. Army research program, we dynamically built interest models of operators for discovering relevant information snippets in real-time from a large number of chat rooms (Li  et al., 2012). In a DARPA (The Defense Advanced Research Projects Agency) program, we used adaptive interest models to help mobile nodes to combat network disruptions by prefetching information (Li et al., 2014).</p><p>For the contextual suggestion task, a sensible suggested attraction should consider user's personal interests on the one hand and the contextual appropriateness on the other. To this end, we have extended our user modeling algorithm to model user's general and specific interests separately. Both models are used to assess the relevance of a suggested attraction. In addition, we have built a simple context model to capture the contextual relevance of a given attraction. The final scoring and ranking of a suggestion involve combining contributions from relevance factors captured in these models. As such, our approach differs from other participating teams in at least three important ways: a) the creation of explicit user interest models; b) the separation of general and specific interests for a user; and c) the explicit capture of contextual relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">OUR APPROACH</head><p>The contextual suggestion architecture shown in Figure <ref type="figure" coords="1,289.99,615.40,4.98,9.05" target="#fig_0">1</ref> involves five key sequential steps: 1) User Interest Modeling, which builds both general and specific interest models for a given user from the information in the provided user profile; 2) Yelp API, which is used to identify candidate suggestions for a given context, i.e., location from the Yelp website 2 ; 3) Component Scoring, which generates three component scores: general interest score, specific interest score, and context score for a given candidate suggestion; 4) Component Score Aggregation, which combines the three component scores to produce a single score for a candidate suggestion; and 5) Suggestion Ranking, which sorts and ranks all candidate suggestions to generate TREC submissions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">User Interest Modeling</head><p>User Interest Modeling is the key step to our approach for contextual suggestion. Here our user modeling algorithm, i.e., RAMA (Reinforcement and Aging Modeling Algorithm) is applied to build explicit user interest models, which is then used to score candidate suggestions. We describe user modeling in detail in the USER MODELING section below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">User Profile</head><p>National Institute of Standards and Technology (NIST) has provided 299 user profiles. For each user profile, 70 to 100 example points-of-interest from both Chicago, IL and Santa Fe, NM are rated on a scale from strongly uninterested (0) to strongly interested (4). Each point-of-interest contains a title, description, and URL. From a user modeling perspective, each rated example is a user event that provides explicit user relevance feedback. One user model is built for each profile with all available rating events in the profile using the RAMA algorithm.</p><p>The RAMA algorithm processes one user rating event at a time. Interest elements (content words and interest categories) and their associated ratings are extracted first from the event. Interest elements are extracted from title and description of profile examples using Lucene® <ref type="bibr" coords="2,155.54,461.39,5.12,5.45" target="#b2">3,</ref><ref type="bibr" coords="2,160.66,461.39,2.56,5.45" target="#b3">4</ref> , WordNet™ <ref type="bibr" coords="2,215.21,461.39,5.12,5.45" target="#b4">5,</ref><ref type="bibr" coords="2,220.33,461.39,2.56,5.45" target="#b5">6</ref> , and Yelp category taxonomy <ref type="bibr" coords="2,343.87,461.39,3.00,5.45" target="#b6">7</ref> . Lucene's StandardAnalyzer is used to extract terms from the text inputs. The non-noun words are removed using WordNet. Both the extracted interest elements and the ratings are used in the model adaptation steps of the RAMA algorithm. RAMA has two key functions in weight adaptation: reinforcement and decay. We did not apply the decay function (achieved by setting the attenuation factor to 0) for the TREC Contextual Suggestion track. This is because the track did not provide information regarding the sequential ordering of the user rating events. It is reasonable to assume that all ratings were done in a relatively short time-frame and the user's interests remained unchanged. The last step of the RAMA algorithm involves inserting new interest elements into the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">General Interest Model</head><p>The general interest model captures the user's interests in terms of categories (e.g., museums, landmarks, and galleries). For each rating event in a user profile, we extract the Yelp categories (see Yelp API section for how this is done) and feed them into the RAMA algorithm to build the model. The general interest model for user 814 is shown as a word cloud and a table in Table <ref type="table" coords="2,79.34,594.40,3.77,9.05" target="#tab_0">1</ref>. <ref type="bibr" coords="2,54.00,648.38,3.00,5.45" target="#b2">3</ref> Lucene is a registered trademark of the Apache Software Foundation in the United States and/or other countries. <ref type="bibr" coords="2,54.00,662.80,3.00,5.45" target="#b3">4</ref> http://lucene.apache.org/ <ref type="bibr" coords="2,54.00,677.08,3.00,5.45" target="#b4">5</ref> WORDNET is a trademark of the Trustees of Princeton University in the United States and/or other countries. <ref type="bibr" coords="2,54.00,691.48,3.00,5.45" target="#b5">6</ref> http://wordnet.princeton.edu/ 7 http://www.yelp.com/developers/documentation/v2/all_category_list</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Specific Interest Model</head><p>The specific interest model captures the user's interests in terms of content words (e.g., Chicago, history, and pier). For each rating event in a user profile, we extract the noun words from the title and description texts and feed them into the RAMA algorithm to build the model. Note, some of the content words may also be considered categories, but the majority of the words are not. The specific interest model for user 814 is shown as a word cloud and a table in Table <ref type="table" coords="3,460.30,615.64,3.77,9.05">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Yelp API</head><p>Yelp API is a restful web service provided by Yelp for searching business review and rating information for a particular geographic region or location. We used it to collect candidate suggestions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Yelp Website</head><p>We choose Yelp.com as the only source of candidate suggestions because of its comprehensive coverage of local business<ref type="foot" coords="4,552.60,67.48,3.00,5.45" target="#foot_2">8</ref> . As of the 3 rd quarter in 2014, Yelp had 139 million monthly visitors and 67 million reviews. It covers a variety of businesses that are considered attractions, including shopping, restaurants, arts and entertainments, nightlife, etc. Yelp API 2.0 allows applications to programmatically query local business using keywords, locations, or both. It permits 25,000 API calls per day without charge. Each Yelp search query can return up to 20 results. The results are in JSON (JavaScript Object Notation) format and contain business name, distance from context location, business category labels, number of reviews, average rating, review snippets, and other information (see Table <ref type="table" coords="4,283.49,137.84,4.98,9.05" target="#tab_1">3</ref> for an example Yelp API call). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Candidate Suggestion</head><p>Candidate suggestions are collected using Yelp API 2.0 for each one of the 50 contexts (i.e., locations) specified by the TREC task. In order to do this, we first identified the Yelp category labels associated with each individual user profile example by querying Yelp with the title and the location of the example. We then computed the union of all the categories from 100 examples. We found a total of 72 business categories associated with one or more examples, as shown in Figure <ref type="figure" coords="4,85.46,556.12,3.77,9.05" target="#fig_1">2</ref>. Finally, for each context, we issued one query per category to retrieve up to 20 results with highest ratings. In this way, we have collected a total of 11,641 candidate suggestions, which are grouped by context.</p><p>The resulting details of each candidate are parsed and used for component scoring. In particular, the name and snippet text fields are used for computing specific interest score whereas the categories field is used for computing the general interest score. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Component Scoring</head><p>Relevance scores for general interest, specific interest, and context are computed separately for each candidate suggestion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Cosine Similarity</head><p>Both general interest and specific interest scoring involve the calculation of cosine similarity between the respective user interest model and the candidate suggestion. The cosine similarity metric based on the vector space model has been widely used for comparing similarity between search query and document in the information retrieval literature (Salton et al., 1975). To apply this metric, we converted the user interest model into a vector representation with all weighted interest elements in the model. In addition, we extracted a vector representation for the candidate suggestion from its associated information.</p><p>We want to mention one novel use of the cosine similarity in this work. In the information retrieval literature, the cosine similarity has been typically used in the 0 to 1 range because the vector weights typically come from tfidf (term frequency inverse document frequency) <ref type="bibr" coords="5,170.90,181.38,3.00,5.45">9</ref> which also has a value from 0 to 1. In our work, we used the full range of the cosine similarity, which is between -1 and +1, inclusive, with +1 indicating the two identical vectors and -1 indicating two opposite vectors. This full range results naturally from the fact that our user models allow the interest elements to have weights from -1 to +1 to represent the full spectrum of interest intensities from hate to love.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">General Interest Score</head><p>In order to compute the general interest score for a candidate suggestion, the categories are fed into the RAMA algorithm to build a general interest model for the suggestion. This model is then converted into a vector representation as mentioned above. The general interest score is the cosine similarity between the user general interest model and the suggestion model in terms of their vector representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Specific Interest Score</head><p>Similarly for calculating the specific interest score, both the name of the suggestion and the review snippet text are fed into the RAMA algorithm to produce a specific interest model for the suggestion. The resultant model is also converted to a vector representation as described above. The specific interest score is the cosine similarity between the user specific interest model and the suggestion model in terms of their vector representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.4">Context Score</head><p>The context score is based the geographic distance from the user's location, the number of reviewers, and the Yelp rating of the candidate suggestion. It is computed as the linear combination of a distance score, a rating score, and a review count score (Formula 1). Distance score has a value between -1 and +1 mapped from the user's distance from the suggested location (Formula 1a). The closer it is, the higher the score. The rating score maps the Yelp rating of 1 to 5 stars to a value between -1 to +1 (Formula 1b). The review count score maps the number of reviews to a value between -1 to +1 (Formula 1c). The weights for the three scores should add up to 1. As a result, the context score has a range of -1 to 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ContextScore = Wd</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Component Score Aggregation and Candidate Suggestion Score</head><p>Component score aggregation produces the relevance score for the candidate suggestion as a weighted linear combination of the three component scores (Formula 2). Note that the total weights for the three components should equal to 1. The final score has a range of -1 to 1, inclusive, since each component score also ranges from -1 to 1, inclusive. Where: 0&lt;=Wg&lt;=1; 0&lt;=Ws&lt;=1; 0&lt;=Wc&lt;=1; Wg + Ws + Wc = 1</p><p>The weighting scheme for the components affects the quality of the suggestions. Two different weighting schemes were used for the two runs we submitted to TREC for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Suggestion Ranking</head><p>Suggestion ranking is done by sorting all candidate suggestions based on their relevance score and then assigning an integer rank value. The ranks are consecutive integers. The suggestion with the highest score has a rank value of 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Suggestions for TREC Submission</head><p>For a given user and context pair, all candidate suggestions for the context are ranked and the top 50 ranked candidates are formatted for TREC submission. The generated suggestion contains identification information along wtih the rank, title, description, and URL of the recommendation. The descriptions of candidate suggestions come from the original review snippet text generated by Yelp. An example of a formatted submission is shown in Figure <ref type="figure" coords="6,493.66,241.67,3.77,9.05" target="#fig_4">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">USER MODELING 3.1 User Model Representation</head><p>In the TREC context, the user model represents a dynamic and cohesive set of interest elements that a user may be interested in. It is automatically created and continually adapted by the RAMA adaptation algorithm. A user model is comprised of one or more facets, which describe different aspects or time-sensitive phases of a user's interests. A facet consists of a set of interest elements, each of which represents some dimension of a user's interests. Each element carries a weight to indicate its degree of importance. The interest element may take different forms including terms, named entities, ontological entities, topics and relationships. In particular, a term represents a user interest dimension corresponding to a word or phrase. For the TREC tasks, we have only extracted terms due to limited resources. The weight of an interest element ranges from -1 to +1, inclusive, where -1 indicates dislike and irrelevance, and +1 highest level of like and relevance.</p><p>Table <ref type="table" coords="6,80.42,388.69,4.98,9.05" target="#tab_2">4</ref> shows the XML of an example user interest model generated by applying RAMA to the rating events in the user profile. In this example, the user model contains one facet with a total of 72 term elements (e.g., "museums" with positive weight of 0.92 and "wineries" with negative weight of -0.08). The user model also contains a number of metadata items. For example, the item "intervals" captures the timestamps of the first and last user events used in the current facet. The item "numReportedEvents" keeps count of total user events for building the model. The item "pedigree" records the events   <ref type="table" coords="7,403.99,56.10,3.60,9.05" target="#tab_0">1</ref>). With the word cloud, the larger the font and the warmer the color, the higher the weight for the interest element is.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The User Modeling Algorithm</head><p>The user modeling algorithm is used for modeling the user's interests. The algorithm is based on RAMA, which was developed in our previous research programs and was demonstrated to be effective in a formative evaluation study conducted by NIST (Alonso et al., 2010).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5. User Modeling Algorithm Description</head><p>1) Initialize the user model: create an empty interest model for the user if it does not exist.</p><p>2) Extract interest elements from a user event: identify terms and categories from rating events in the user profile.</p><p>3) Age the current model: apply a decay function to all interest elements in the interest model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Reinforce interest elements recurring in user event:</head><p>increase or decrease the weights of these elements in the model, depending on whether the rating is favorable or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Insert new interest elements: incorporate unseen interest elements from the event into the interest model with a default weights. 6) Continue steps 2-5 for each incoming user event</head><p>The user modeling algorithm is described in Table <ref type="table" coords="7,259.61,279.95,3.71,9.05">5</ref>. To capture changing user interests, the adaptation algorithm continually updates the user model with incoming user events by applying a reinforcement mechanism and a decay function. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Extract Interest Elements from User Event</head><p>Interest elements (e.g., content words and interest categories) are extracted from the data associated with the user event (e.g., user ratings of an attraction) using tools such as NLP (natural language processing). We recognize that certain user events tell you a lot about the user's interests whereas others may tell you very little. We use the term event relevance to indicate the extent the event reflects the user's interests (e.g., see Table <ref type="table" coords="7,239.57,388.57,3.59,9.05" target="#tab_4">6</ref>). Event relevance ranges from -1 to +1, where -1 indicates negative interests (i.e., dislike), +1 indicates positive interests (i.e., like), 0 indicates neutral interests. It is used by the user modeling algorithm for reinforcement and insertion of new interest elements. For each user rating of an example, the ratings for both the title/description are mapped into event relevance (Table <ref type="table" coords="7,373.51,434.77,3.59,9.05" target="#tab_4">6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Age the Current Model</head><p>This aging step captures the observation that user interests tend to gradually decrease over time. The aging is performed as follows: with every new user event the decay function shown in formula (3) below is allied to all interest elements in the current facet of the model. The attenuation factor is a configurable parameter that controls the rate of decay. Its value ranges between 0 and 1 depending on the problem domain. Normally a non-zero value is used to cause interest weights to go down.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>newWeight = oldWeight * (1 -attenuationFactor)</head><p>(3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Reinforce Interest Elements Recurring in User Event</head><p>This reinforcement step is based on the observation that the greater number of interest mentions in times and contexts, the stronger the interest element is. The reinforcement mechanism processes user events differently based on the polarity of the event, i.e., positively or negatively reflecting user's interests. The polarity is indicated by the signage of event relevance (see Table <ref type="table" coords="7,80.30,604.36,4.98,9.05" target="#tab_4">6</ref> above). With positive events (e.g., high ratings in user profile) that express user's interests, the reinforcement will increase the importance or weight of the interest elements contained in them. With negative events (e.g., low ratings in user profile) that indicate user's lack of interest, the weight of the contained interest elements will decrease. The reinforcement mechanism is expressed in formula (4) below. The old weight is the weight of an interest element in the current facet of the user model prior to reinforcement where the new weight is the result of the reinforcement. The label Math.abs denotes the absolute value function, which is necessary because the old weight can be negative. The mention frequency is the number of occurrences of the interest element in the textual content of the user event, i.e., title and description of the example attraction in the case of this TREC work. The reinforcement factor is a configurable parameter that controls the rate of the reinforcement. The parameter has a value ranging from 0 to 1 depending on the problem domain. For this TREC work, the value is set at 0.5. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Insert New Interest Elements</head><p>With this insertion step, new interest elements are incorporated into the current facet of the user interest model. The initial weight for newly inserted interest element is decided using formula (5) below. By comparing with formula (4), it is noted that the initial weight is equal to the size of one reinforcement application. initialWeight = eventRelevance * reinforcementFactor * mentionFrequency (5)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EVALUATION</head><p>NIST has conducted an evaluation for the contextual suggestion track submissions. Seventeen (17) teams from academia and industry worldwide have submitted a total of 31 runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>NIST provided 299 user profiles with preference ratings for 70 to 100 points-of-interest from two contexts. Fifty (50) contexts are also given by NIST. We have used the open web as the source of our suggestions. Using the Yelp API 2.0, we collected a total of 11641 candidate suggestions for the 50 contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Metrics</head><p>Three metrics are used to rank runs: 1) Precision at Rank 5 (P@5); 2) Mean Reciprocal Rank (MRR); and 3) a modified version of Time-Biased Gain (TBG). P@5 is the main measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">TREC Submissions</head><p>A TREC submission is required to provide up to 50 suggestions for each profilecontext pair. We have submitted two runs for evaluation: RUN1 and RAMARUN2. They differ in weighting scheme for component score aggregation. RUN1 put priority on specific interests (i.e., high Ws). In contrast, RAMARUN2 favors general interests (i.e., high Wg) (Table <ref type="table" coords="8,245.69,363.73,3.63,9.05" target="#tab_5">7</ref>). Note, we generated a third run with priority on context (i.e., high Wc) but did not submit this run due to the submission limit of two runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>NIST judged the accuracy of our two RAMA runs for all the user-context pairs on three performance metrics, P@5, MRR, and TBG. In addition, NIST also provided the Best, Median, and Worst results from all participants who used Open Web as the source for suggestions. Figure <ref type="figure" coords="8,200.57,645.64,4.98,9.05" target="#fig_6">4</ref> shows the average of our results against the average Track-wide results. Note that metrics P@5 and MRR are using the Y-axis on the left while TBG is using the Y-axis on the right. Overall, RAMA performed significantly better than the average Track Median on all three metrics. Since the P@5 is the primary metric for evaluation, we looked closely at it in Figure <ref type="figure" coords="8,240.05,680.22,3.77,9.05">5</ref>. RUN1 and RAMARUN2 have P@5 values of 0.49 and 0.50, respectively, both significantly better than the average Track Median at 0.35.  Figure <ref type="figure" coords="8,361.39,607.28,3.77,8.89">5</ref>. RAMA performance on metric P@5. The improvement in performance over the Track Median is shown in Table <ref type="table" coords="9,368.35,197.60,3.77,9.05">9</ref>. Across the three metrics, RAMA shows the most improvement on TBG, medium on P@5 and the least on MRR. RAMARUN2 has the largest improvement (75%) on TBG whereas RUN1 on MRR shows the least improvement (24%). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Comparison with Average Track Median</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Comparison with Track Median by User by Context Pair</head><p>To understand the performance for individual user-by-context-pair, we plotted the P@5 score delta from the Track Median for our runs, the Track Best, and the Track Worst. For RUN1 (Figure <ref type="figure" coords="9,337.39,677.94,3.77,9.05" target="#fig_7">6</ref>, top panel), the number of user-by-context-pair has a pseudo-normal distribution over the P@5 score delta, i.e., pairs with extremely good or poor performance are in the minority whereas the majority of pairs have more moderate performance. In other words, the run improvement over the Track Median is distributed across the population, rather than confined to some subclass of super performers. Similar results are found in RAMARUN2 (Figure <ref type="figure" coords="10,144.50,79.28,3.77,9.05" target="#fig_7">6</ref>, bottom panel).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Comparison between Two RAMA Runs</head><p>The two RAMA runs have very similar performance; with RAMARUN2 having a slight edge over all three metrics (Table <ref type="table" coords="10,54.00,136.28,3.63,9.05">8</ref>). The performance improvement of RAMARUN2 over RUN1 ranges from 1% to 4% (Error! Reference source not found.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>This is our first participation in the NIST Contextual Suggestion Track. We have leveraged our prior work on user modeling to this task. In particular, we have extended our RAMA algorithm to model user's general and specific interests. These models were used to compute interest-specific relevance scores for a candidate suggestion. In addition, we built a simple context model to calculate a context-specific relevance score for the candidate. Different weighting schemes are used for our two runs to combine the relevance scores and rank the candidate suggestions collected from the Open Web (i.e., Yelp). RAMARUN2 emphasizes general interest whereas RUN1 gives specific interests priority. TREC evaluation shows that both runs performed significantly better than the average Track Median on all three metrics. We learned at the TREC conference in November, 2014, that our RAMARUN2 and RUN1 ranked #2 and #6, respectively, out of the 31 runs submitted by the 17 participating teams.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,191.81,295.71,228.44,8.89;2,72.00,87.50,467.85,194.65"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Contextual suggestion architecture diagram</figDesc><graphic coords="2,72.00,87.50,467.85,194.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,295.75,668.26,255.31,8.89;4,288.95,446.39,269.05,214.60"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Yelp business categories for user profile examples.</figDesc><graphic coords="4,288.95,446.39,269.05,214.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,180.44,446.09,258.61,8.89;5,472.18,446.09,11.69,8.89;5,126.74,464.93,283.72,8.89;5,469.30,464.93,17.24,8.89;5,204.17,483.89,129.07,8.89;5,469.30,483.89,17.24,8.89;5,113.06,502.85,311.42,8.89;5,469.90,502.85,16.16,8.89;5,90.86,519.99,263.47,9.06;5,90.86,535.47,247.06,9.06;5,106.94,550.95,374.93,9.06"><head></head><label></label><figDesc>= 0.6; Wr = 0.3; Wc = 0.1; Note: Wd + Wr + Wc = 1 DISTANCE_LIMIT_METERS = 8000 meters; (about 5 miles) REVIEW_COUNT_LIMIT = 100; (the review count at which the rating is regarded as stable)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="6,264.77,213.48,204.52,8.89;6,176.27,105.70,381.70,100.60"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. An example of a formatted suggestion.</figDesc><graphic coords="6,176.27,105.70,381.70,100.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="7,528.24,291.47,29.82,9.05;7,54.00,302.99,504.07,9.05;7,54.00,314.51,304.21,9.05"><head></head><label></label><figDesc>For the contextual suggestion track, the weight adjustment for the interest elements are primarily based on a) the ratings of the source profile examples; and b) their occurring frequencies in the profile examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="8,76.46,607.28,211.89,8.89;8,330.55,607.28,197.81,8.89;8,64.40,428.25,236.05,163.40"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. RAMA performance with the open web.Figure5. RAMA performance on metric P@5.</figDesc><graphic coords="8,64.40,428.25,236.05,163.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="9,156.98,632.36,297.61,8.89;9,72.73,440.24,466.55,184.85"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. RAMA performance compared with Track Median by User.</figDesc><graphic coords="9,72.73,440.24,466.55,184.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="3,54.30,359.35,250.50,249.60"><head></head><label></label><figDesc></figDesc><graphic coords="3,54.30,359.35,250.50,249.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="3,316.20,359.35,241.30,249.60"><head></head><label></label><figDesc></figDesc><graphic coords="3,316.20,359.35,241.30,249.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,184.73,58.66,242.55,292.26"><head>Table 1 . Visualizing General Interest Model for User 814 Table 2. Visualizing Specific Interest Model for User 814</head><label>1</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,68.42,157.68,396.29,70.24"><head>Table 3 . Example Yelp API Call: Query and Results for Context Erie, PA # Yelp Query PARAMETERS</head><label>3</label><figDesc></figDesc><table coords="4,68.42,194.60,302.49,33.32"><row><cell>{limit=20, sort=2, category_filter=beer_and_wine, ll=42.12922,-80.08506}</cell></row><row><cell># Yelp Query RESPONSE in JSON Format</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,195.29,455.69,221.37,8.89"><head>Table 4 . General Interest Model for User 814: XML processed</head><label>4</label><figDesc>. The user interest model can be visualized as a word cloud or a table(</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,379.16,56.10,22.29,9.05"><head>Table</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,434.26,365.69,121.99,20.53"><head>Table 6 . Mapping Ratings to Event Relevance newWeight = oldWeight + (eventRelevance * reinforcementFactor * mentionFrequency * (1 -Math.abs(oldWeight))) (4)</head><label>6</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,404.11,327.39,152.22,69.03"><head>Table 7 . Weighting Scheme for Our Runs</head><label>7</label><figDesc></figDesc><table coords="8,408.10,355.47,142.97,40.95"><row><cell></cell><cell>Wg</cell><cell>Ws</cell><cell>Wc</cell></row><row><cell>RUN1</cell><cell cols="2">0.09 0.9</cell><cell>0.01</cell></row><row><cell cols="2">RAMARUN2 0.9</cell><cell cols="2">0.09 0.01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,54.00,68.72,503.85,48.41"><head>Table 8 . RAMA performance compared to Track MedianTable 9 . RAMA performance improvement over Track Median</head><label>89</label><figDesc>Table8compares the two RAMA runs with the Track Median on all three performance metrics. Both runs perform significantly better than the Track Median on all three metrics.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,57.00,693.36,314.88,8.18"><p>Yelp is a registered trademark of Yelp, Inc. in the United States and/or other Countries.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,59.30,707.64,78.78,8.18"><p>http://www.yelp.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_2" coords="4,59.30,707.64,110.78,8.18"><p>http://www.yelp.com/factsheet</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_3" coords="5,59.30,707.64,172.00,8.18"><p>http://en.wikipedia.org/wiki/Tf%E2%80%93idf</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,72.02,302.38,448.35,9.06;10,72.02,314.02,347.66,9.06" xml:id="b0">
	<analytic>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bramsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,214.03,302.38,306.34,9.06;10,72.02,314.02,253.68,9.06">Incremental user modeling with heterogeneous user behaviors. International conference on knowledge management and information sharing</title>
		<imprint>
			<biblScope unit="volume">2010</biblScope>
			<biblScope unit="page" from="129" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.02,329.38,437.31,9.06;10,72.02,341.02,380.06,9.06" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,162.98,329.39,244.33,9.05">Model-guided information discovery for intelligence analysis</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,413.98,329.38,95.36,9.06;10,72.02,341.02,339.69,9.06">Proceedings of the 14th International Conference on Information and Knowledge Management</title>
		<meeting>the 14th International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<biblScope unit="page" from="269" to="270" />
		</imprint>
	</monogr>
	<note>CIKM 2005a</note>
</biblStruct>

<biblStruct coords="10,72.02,356.38,455.15,9.06;10,72.02,368.04,256.40,9.06" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,162.98,356.39,205.48,9.05">Combating cognitive biases in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,374.95,356.38,152.23,9.06;10,72.02,368.04,222.29,9.06">Proceedings of the First International Conference on Intelligence Analysis Methods and Tools</title>
		<meeting>the First International Conference on Intelligence Analysis Methods and Tools</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.02,383.41,439.20,9.05;10,72.02,395.05,168.70,9.05" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dean-Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhes</surname></persName>
		</author>
		<title level="m" coord="10,349.49,383.41,161.73,9.05;10,72.02,395.05,68.32,9.05">Overview of the TREC 2014 Contextual Suggestion Track</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>notebook paper</note>
</biblStruct>

<biblStruct coords="10,72.02,410.41,461.27,9.05;10,72.02,421.92,457.94,9.06;10,72.02,433.56,71.01,9.06" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Costantini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Anhalt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-O</forename><surname>Stehr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Talcott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wood</surname></persName>
		</author>
		<title level="m" coord="10,496.85,410.41,36.44,9.05;10,72.02,421.92,457.94,9.06">Adaptive Interest Modeling Enables Proactive Content Services at the Network Edge. Military Communications Conference</title>
		<imprint>
			<publisher>MILCOM</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.02,448.92,463.33,9.06;10,72.02,460.44,259.22,9.06" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Alonso</surname></persName>
		</author>
		<title level="m" coord="10,192.46,448.92,342.89,9.06;10,72.02,460.44,201.54,9.06">Discovering Virtual Interest Groups across Chat Rooms, International Conference on Knowledge Management and Information Sharing</title>
		<imprint>
			<publisher>KMIS</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.02,475.92,480.76,9.06;10,72.02,487.45,131.16,9.05;10,335.83,56.98,216.65,8.89;10,420.22,68.64,48.00,8.89" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,222.14,475.93,186.81,9.05;10,335.83,56.98,216.65,8.89;10,420.22,68.64,48.00,8.89">Table 10. RAMARUN2 performance improvement over RUN1</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,416.14,475.92,113.01,9.06">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="613" to="620" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
	<note>A Vector Space Model for Automatic Indexing</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
