<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.40,97.59,433.15,17.20;1,126.36,117.51,359.35,17.20">Concept Based Tie-breaking and Maximal Marginal Relevance Retrieval in Microblog Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,134.28,163.22,50.81,11.47"><forename type="first">Kuang</forename><surname>Lu</surname></persName>
							<email>lukuang@udel.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Delaware Newark</orgName>
								<address>
									<postCode>19716</postCode>
									<settlement>Delaware</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,277.80,163.22,56.45,11.47"><forename type="first">Diego</forename><surname>Roa</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Systems and Computing Engineering Department Universidad de los Andes</orgName>
								<address>
									<country key="CO">Colombia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,428.28,163.22,47.81,11.47"><forename type="first">Hui</forename><surname>Fang</surname></persName>
							<email>hfang@udel.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Delaware Newark</orgName>
								<address>
									<postCode>19716</postCode>
									<settlement>Delaware</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.40,97.59,433.15,17.20;1,126.36,117.51,359.35,17.20">Concept Based Tie-breaking and Maximal Marginal Relevance Retrieval in Microblog Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DDA407B02E92FB4C38881D0B7EBC891C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>There are enormous tweets posted on any given day, and the number keeps increasing. As a result, the needs of effectively retrieving tweets depending upon user's information need, and summarizing tweets pertaining to a given topic have become increasingly important. In this paper, Wikipedia concepts [1] was introduced in tie-breaking to perform ad-hoc microblog retrieval. The Maximal Marginal Relevance (MMR) [2] criterion is deployed to summarize relevant tweets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Microblog, as an extremely popular type of social media, has become increasingly involved in almost everyone's life. The need of finding relevant tweets also has become more prominent. Additionally, summarizing relevant tweets in order to offer users a concrete picture about a certain topic also has become more and more important. This year, a new task, called Tweet Timeline Generation is introduced which specifically focuses on this problem.</p><p>For microblog ad-hoc retrieval, as indicated in the previous work <ref type="bibr" coords="1,141.84,486.24,9.12,8.97" target="#b6">[6]</ref>, tie-breaking seems to be an appropriate solution. This year, we tried to include other new signal into our tie-breaking framework to improve the search performance. The signal we used is "Wikipedia concepts". The basic idea is that, given a query, we find out the Wikipedia concepts mentioned in the query as well as in the candidate tweets, and then use the number of concepts of the tweets as a new signal. Besides tie-breaking, other IR approaches, such as query expansion and learning-to-rank, are also likely to be effective, thus were tried by us.</p><p>Considering summarizing several tweets, it is clear that solely using classical IR models, such as Okapi BM25, might not work. The reason is that these models evaluate the relevance of documents and rank them independently. In generating tweet summery, retrieving highly relevant but redundant tweets might not be helpful since redundant information certainly may not be useful for a user.</p><p>In this year's track, we continued leveraging tiebreaking strategy <ref type="bibr" coords="1,153.72,695.40,9.64,8.97" target="#b7">[7]</ref> for ranking tweets as last year. Moreover, the concepts in tweets were also used as a new retrieval signal to enhance search results. Besides tie-breaking, query expansion and learning-torank implemented in Terrier <ref type="bibr" coords="1,440.76,265.44,9.64,8.97">[5]</ref> were also deployed as additional ranking method. For the second Tweet Timeline Generation task, Maximal Marginal Relevance <ref type="bibr" coords="1,343.68,296.88,9.64,8.97" target="#b2">[2]</ref> based ranking, combined with tie-breaking, were deployed to capture both relevance and novelty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">AD-HOC MICROBLOG RETRIEVAL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Concept Based Tie-breaking</head><p>As proposed in <ref type="bibr" coords="1,387.60,371.16,9.12,8.97" target="#b7">[7]</ref>, tie-breaking is a retrieval method combining retrieval signals in a simple way which explicitly differentiates the impact amongst IR signals. The basic idea is that, from pre-selected candidate IR signals, first choose only one of them to rank the tweets. For documents with the same score, another singal will be used to rank these documents to break the ties, but the relative orders of other documents against these documents remain the same. The tiebreaking step above is repeatedly applied to further break ties until all candidate signals are applied and the ranking is finalized. Ranking tweets in this way, signals that are applied earlier have more decisive impact on the final ranking than those applied latter.</p><p>In last year's microblog track <ref type="bibr" coords="1,446.64,517.56,9.12,8.97" target="#b6">[6]</ref>, only the term frequency (T F ), the inverse document frequency (IDF ), the document length (DL), the number of followers of the account posted the tweets (N OF ) were used and the implementations of them are shown in Table 1. The order of implementation of last year is IDF T F N OF DL. We chose this as the baseline method for this year. However, since tweets are short in nature, solely using classic IR signals might not be sufficient. Therefore, this year we incorporate a new signal, which is "Wikipedia concepts" in both queries and tweets. These concepts are extracted by the toolkit Wikimantic <ref type="bibr" coords="1,425.64,643.20,9.12,8.97" target="#b1">[1]</ref>. What this toolkit does is that for every string sent to the toolkit, it will detect the Wikipedia concepts related to it. The Wikipedia concepts are defined as the title of Wikipedia articles. We chose to use original query string and tweets as input, and selected the longest non-overlapping concepts detected by Wikimantic as the concepts of queries and   tweets. The reason we chose to include this signal is that the concepts, in our opinions, are more informative and can more accurately represent the information of tweets and queries. Therefore, using it could result in higher precision, meaning reducing the number of retrieved non-relevant tweets only containing query terms instead of containing query concepts. The way we implemented this signal is shown in Figure <ref type="figure" coords="2,286.92,433.80,3.56,8.97" target="#fig_1">1</ref>: Given a query and a document, we use Wikimantic to detect the number of Wikipedia concepts of them; count the number of matching concepts between the query and the tweet; and use the number of matching concepts as the signal value (denoted as CM ).</p><formula xml:id="formula_0" coords="2,114.48,119.75,168.29,37.04">(Q,D) t∈Q∩D c(t,D) c(t,D)+1 IDF(Q,D) t∈Q∩D log(1 + N df (t) ) DL(Q,D)</formula><p>After Wikipedia concept was decided to be used, the following step should be deciding how it should be applied in the tie-breaking framework. Since the Wikipedia concepts are widely recognized by a considerable number of Wikipedia users, we thought the Wikipedia matching concepts between queries and tweets (CM ) should be viewed as the most important signal, and thus we planed to apply it first. However, since it took a very long time to compute the concepts in all tweets, we only used it to re-rank the top 100 tweets of the baseline run to generate another run. After the submission, we were able to compute the CM signal for all tweets and include it as the first signal in the tie-breaking framework as originally planned to test its effectiveness, which will be discussed later. In addition to tie-breaking based runs, we also tried two runs using the T errir <ref type="bibr" coords="2,168.36,663.84,9.64,8.97">[5]</ref> toolkit to explore its built-in learning-to-rank and query-expansion methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Experiment Setup</head><p>The tweet pool is generated by retrieving tweets through the API<ref type="foot" coords="2,385.08,81.08,3.65,5.98" target="#foot_0">1</ref> provided by the organizers. Specifically, for each original query, we searched it on the Yahoo! search engine, which returned some query suggestions for the query. The original queries as well as their query suggestions were used to search against the API, and the number of results required to return was set to 10,000. The returned tweets were then used to build tweet collection for each original query respectively. The maximum id numbers were set to be the same as original queries in order to prevent retrieving feature tweets (posted after the query time), which will be deemed irrelevant.</p><p>Since non-English tweets will be treated as irrelevant regardless of whether it is relevant or not, we filtered the non-English tweets before building tweet index. In order to detect non-English tweets, the python package lang id.py <ref type="bibr" coords="2,398.04,249.96,9.64,8.97" target="#b4">[4]</ref> was used to identify the language of tweets. Only the tweets detected by the tool as English were kept, or otherwise discarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Results and Analysis</head><p>We submitted four runs for the ad-hoc task this year. The results are reported in Table <ref type="table" coords="2,478.20,313.43,7.12,8.97" target="#tab_1">2:</ref> • UDInfoTB: The baseline run same as last year <ref type="bibr" coords="2,525.86,334.08,10.90,8.97" target="#b6">[6]</ref>,</p><p>which is the tie-breaking with the order IDF T F N OF DL.</p><p>• UDInfoTBRR: In this run, we re-ranked the top 100 tweets of the results of U DInf oT B based on the CM signal.</p><p>• UDInfoLTR: The learning-to-rank implemented in T errir <ref type="bibr" coords="2,380.88,424.32,9.64,8.97">[5]</ref> was used to generate this run. The signals we used were BM 25, P L2 <ref type="bibr" coords="2,473.28,434.76,9.64,8.97" target="#b3">[3]</ref> and T F IDF .</p><p>• UDInfoQE: The built-in pseudo relevance feedback based query expansion tool in T errir was used to generate this run. Top 3 documents of each query were used to extract 10 most informative terms to expand the oroginal query.</p><p>After the evaluation was out, we also tested how useful the CM signal is in the tie-breaking framework. First, we added it to our baseline run's framework as the first signal to be applied to examine the usefulness of it (tie-breaking with the order CM IDF T F N OF DL). Thereafter, we tried different orders of signal application of theis experiment to test whether the performance could be improved. The results of the experiments are shown in Table <ref type="table" coords="2,473.76,599.88,3.56,8.97" target="#tab_2">3</ref>. As can be seen, the new signal CM is helpful in enhancing the performance (runs with this signal is better than the UDInfoTB run, which does not have the signal) and using a more appropriate order could further improve the performance.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">TWEET TIMELINE GENERATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Maximal Marginal Relevance</head><p>As mentioned previously, solely using existing IR model might not be helpful in the Tweet Timeline Generation (TTG) task. Intuitively, a good summery of a topic should cover as many distinct aspects of the topic as possible, meaning that returning redundant information about only few aspects of the topic might not be favorable. Unsurprisingly, according to this year's evaluation metrics for the TTG task, returning redundant tweets will actually decrease the evaluation score (F-measure based) of a result list. Therefore, for the idea result list, every tweet should be relevant to the original query, and each of them should carry some novel information that is not mentioned in any other tweets.</p><p>We noticed that the classical Maximal Marginal Relevance <ref type="bibr" coords="3,109.32,400.07,9.64,8.97" target="#b2">[2]</ref> framework might be suitable for our task. The MMR framework computes the ranking score of a tweet according to <ref type="bibr" coords="3,155.16,421.07,11.74,8.97" target="#b1">(1)</ref> the relevance score of it against the original query, and (2) the maximal similarity score between the current tweet and the tweets already retrieved. Notice that the second part explicitly captures how much novel information a tweet brings with regard to already retrieved tweets. By using MMR based ranking, novelty and relevance are both considered when deciding whether a tweet should be retrieved or not, which will, ideally, produce a tweet list that fits the TTG task.</p><p>Based on MMR, we built a general process for all of our runs. First, use the top 50 tweets for each query of the run U DInf oQE in the first task as the candidate tweets since we were most confident with this run. Second, use all the first-ranked tweets of each query as part of the result. Third, we slightly modified the MMR scoring function in <ref type="bibr" coords="3,245.04,588.35,9.64,8.97" target="#b2">[2]</ref> by using the same method to compute query-tweet and tweettweet similarity as the ranking method to iteratively select the highest ranked tweet for each query into the result. The ranking function can be described as Equation <ref type="formula" coords="3,119.16,640.67,3.56,8.97">1</ref>:</p><formula xml:id="formula_1" coords="3,101.04,677.15,192.94,38.59">M M R def == argmax D i ∈R/S [λ(Sim(Di, Q) -(1 -λ)max D j ∈S Sim(Di, Dj ))] (1)</formula><p>In the equation, R is the whole tweet collection; S is the tweets set already retrieved; R\S is the set of tweets in R not yet retrieved; Q is the query a user searches about; Sim is the measurement for querytweet and tweet-tweet similarity; λ is the predefined constant coefficient. We planed to use tie-breaking as the similarity measure. However, tie-breaking cannot offer numerical similarity scores, which are required by the MMR ranking function. We overcame it by using Equation 2, 3 to compute similarity scores:</p><formula xml:id="formula_2" coords="3,318.00,352.46,225.10,17.67">Simi(Q, D) = 0, i=0 µ * Sim i-1 (Q, D) + S i , i=1,2,...,k<label>(2)</label></formula><formula xml:id="formula_3" coords="3,318.00,392.39,214.66,9.30">Sim(Q, D) = Sim k (Q, D)<label>(3)</label></formula><p>Given a query Q, a tweet D, and a set of k signals, we denote the total score after the ith signal is applied as Simi(Q, D) and let Sim0(Q, D) be zero. The score computed only for the ith signal is denoted as Si(Q, D). Before ith signal is applied, we multiply the ranking score for the signals applied earlier (Si-1(Q, D)) with a big factor µ (set to 10000) so that the effect of signals applied latter cannot invert that of the signals applied ealier. After the score of current signal is computed, it is added to the amplified score described above to finally get Simi(Q, D). After all k signals are applied, the Sim k (Q, D) is used as the similarity score of the tweet (Sim(Q, D)). In this way, the ranking will be the same as that produced by the normal tie-breaking described in 2.1 and we are still able to obtain similarity scores. Finally, the tweet selection process will stop according to pre-defined stopping criteria, which could be different among different runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results and Analysis</head><p>According to the framework described previously, we came up with 4 runs. The differences among the runs lie on the similarity measures of the MMR ranking function and stopping criteria. The results of submitted 4 runs are shown in   order as IDF T F N OF DL. The stopping criterion was set to be when the score difference between two consecutively retrieved tweets is higher than 30% of the one retrieved earlier.</p><p>• UDInfoMMR5: Same similarity measure as U DInf oM M RA. The stopping criterion is returning 5 tweets for every query.</p><p>• UDInfoMMRWCA: The similarity measure is similar to U DInf oM M RA with signals and applying order as CM IDF T F N OF DL mentioned in 2.1. The stopping criterion is when the score difference between two consecutively retrieved tweets is higher than 1% of the one retrieved earlier.</p><p>• UDInfoMMRWC5: Use the same similarity measure as U DInf oM M RW CA. The stopping criterion is returning 5 tweets for every query.</p><p>As can be seen, we achieved high precision but relatively low recall. It is expected since we chose to only use 50 tweets as the candidate tweet pool for each query; return very few results for each query; and the dominating signal CM , which was implemented as the first signal, is likely to be helpful in improving precision with some sacrifice on recall. Therefore, after evaluation was out, we tried to increase the number of returned tweets for out best run U DInf oM M RW C5 in order to examine whether the performance would be improved. The result of this experiment is shown in Figure <ref type="figure" coords="4,120.72,639.12,3.56,8.97" target="#fig_2">2</ref>. As can be seen, the F1 score is indeed improved after returning more tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSION</head><p>Tie-breaking is an effective way of combining different retrieval signals in a simple way. We have explored the potential of it this year by adding a new signal (Wikipedia concepts) and there is still room for exploration: different signals, different signal implementations, or even combining it with other IR techniques such as query expansion could be further experimented. For the Tweet Timeline Generation task, even though we did not achieve high recall since we aimed at achieving high precision, relaxing the stopping criteria can help us achieve better results. Thus, we are likely to explore the MMR approach in the TTG task in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,238.08,146.48,3.65,5.98;2,230.76,153.11,18.23,5.70;2,112.80,161.78,40.49,7.97;2,213.72,161.66,52.13,7.97;2,81.60,175.34,41.81,7.97;2,79.32,184.34,155.02,7.97;2,79.32,193.34,146.85,7.97;2,79.32,202.34,163.49,7.97;2,79.32,211.22,111.22,7.97;2,79.32,220.22,227.38,7.97"><head></head><label></label><figDesc>log(N OF (D)) t : a term t c(t, D) : number of occurances of t in D N : number of tweets in the collection df (t) : number of tweets containing term t dl(D) : the length of tweet D N OF (D) : number of f ollowers of the account that posted D</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,202.56,132.14,206.78,7.97"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Wikipedia Concept Matching Implementation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,79.32,287.66,214.54,7.97;4,79.32,296.66,105.14,7.97"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: F1 Score Increases When Returning More Tweets for U DInf oM M RW C5 run</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,80.88,81.62,211.10,48.17"><head>Table 1 :</head><label>1</label><figDesc>Implementation of Signals Given a query Q and a tweet D</figDesc><table coords="2,99.84,110.45,174.02,19.34"><row><cell>Retrieval signal</cell><cell>Implementation</cell></row><row><cell>TF</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,85.20,241.58,200.60,85.73"><head>Table 2 :</head><label>2</label><figDesc>Ad-hoc Result</figDesc><table coords="2,85.20,262.49,200.60,64.82"><row><cell>Run Method</cell><cell>R-precision</cell><cell>MAP</cell><cell>P@30</cell></row><row><cell>UDInfoTB</cell><cell>0.3639</cell><cell>0.3386</cell><cell>0.5394</cell></row><row><cell>UDInfoTBRR</cell><cell>0.2594</cell><cell>0.2184</cell><cell>0.5733</cell></row><row><cell>UDInfoQE</cell><cell>0.4414</cell><cell>0.4154</cell><cell>0.6115</cell></row><row><cell>UDInfoLTR</cell><cell>0.2270</cell><cell>0.1926</cell><cell>0.2455</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,159.84,152.06,292.52,55.47"><head>Table 3 :</head><label>3</label><figDesc>Performance of Different Signal Implementation Order</figDesc><table coords="3,159.84,171.89,292.52,35.64"><row><cell></cell><cell cols="4">Run Method</cell><cell></cell><cell>R-precision</cell><cell>MAP</cell><cell>P@30</cell></row><row><cell>IDF</cell><cell>T F</cell><cell cols="2">N OF</cell><cell cols="2">DL (U DInf oT B)</cell><cell>0.3639</cell><cell>0.3386</cell><cell>0.5394</cell></row><row><cell>CM</cell><cell cols="2">IDF</cell><cell>T F</cell><cell>N OF</cell><cell>DL</cell><cell>0.3732</cell><cell>0.3393</cell><cell>0.5570</cell></row><row><cell>TF</cell><cell>CM</cell><cell></cell><cell>IDF</cell><cell>NOF</cell><cell>DL</cell><cell>0.3963</cell><cell cols="2">0.3701 0.5945</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,331.32,673.43,201.40,41.49"><head>Table 4 :</head><label>4</label><figDesc>• UDInfoMMRA: Use Equation 2, 3 to compute the similarity scores with signals and applying</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,106.75,79.70,358.63,198.49"><head>Table 4 :</head><label>4</label><figDesc>TTG Results</figDesc><table coords="4,106.75,99.53,358.63,178.66"><row><cell></cell><cell></cell><cell cols="2">Run Method</cell><cell></cell><cell>Unweighted Recall</cell><cell>Weighted Recall</cell><cell>Precision</cell></row><row><cell></cell><cell></cell><cell cols="3">UDInfoMMR5</cell><cell>0.0743</cell><cell>0.2035</cell><cell>0.5055</cell></row><row><cell></cell><cell></cell><cell cols="3">UDInfoMMRA</cell><cell>0.0652</cell><cell>0.1806</cell><cell>0.5314</cell></row><row><cell></cell><cell cols="4">UDInfoMMRWC5</cell><cell>0.0900</cell><cell>0.2191</cell><cell>0.5709</cell></row><row><cell></cell><cell cols="4">UDInfoMMRWCA</cell><cell>0.0852</cell><cell>0.2010</cell><cell>0.5919</cell></row><row><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>F1 Score</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">for unweighted recall</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">for weighted recall</cell><cell></cell></row><row><cell>5 0.1</cell><cell>10</cell><cell>15</cell><cell>20</cell><cell>25</cell><cell>30</cell></row><row><cell></cell><cell cols="4">Number of Returned Tweets</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,322.56,696.96,142.27,8.97;2,318.00,705.96,169.71,8.97"><p>https://github.com/lintool/twittertools/wiki/TREC-2013-API-Specifications</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,322.49,283.81,96.59,10.74" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,332.16,298.56,182.35,8.97;4,332.16,309.00,150.50,8.97;4,332.16,319.44,198.58,8.97;4,332.16,329.88,178.48,8.97;4,332.16,340.32,184.84,8.97;4,332.16,350.76,161.44,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,363.72,309.00,118.94,8.97;4,332.16,319.44,162.06,8.97">Wikimantic: Toward effective disambiguation and expansion of queries</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Boston</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Carberry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,332.16,340.32,184.84,8.97;4,332.16,350.76,101.19,8.97">Special Issue on Natural Language Processing and Information Systems</title>
		<imprint>
			<date type="published" when="2012">2014. 2012</date>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="22" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,332.16,362.28,191.68,8.97;4,332.16,372.71,159.28,8.97;4,332.16,383.15,198.54,8.97;4,332.16,393.90,44.20,8.26" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,457.08,362.28,66.76,8.97;4,332.16,372.71,159.28,8.97;4,332.16,383.15,147.69,8.97">The use of mmr, diversity-based reranking for reordering documents and producing summaries</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,498.96,383.46,31.74,8.26;4,332.16,393.90,40.50,8.26">Proc. of SIGIR &apos;98</title>
		<meeting>of SIGIR &apos;98</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,332.16,405.11,145.26,8.97;4,332.16,415.55,200.47,8.97;4,332.16,426.30,193.57,8.26;4,332.16,436.74,179.20,8.26;4,332.16,446.99,178.84,8.97;4,332.16,457.43,89.08,8.97" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,414.36,405.11,63.06,8.97;4,332.16,415.55,184.57,8.97">Term frequency normalisation tuning for bm25 and dfr models</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,332.16,426.30,193.57,8.26;4,332.16,436.74,179.20,8.26;4,332.16,446.99,32.58,8.97">Proceedings of the 27th European Conference on Advances in Information Retrieval Research, ECIR&apos;05</title>
		<meeting>the 27th European Conference on Advances in Information Retrieval Research, ECIR&apos;05<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="200" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,332.16,468.83,154.99,8.97;4,332.16,479.27,195.61,8.97;4,332.16,489.83,172.60,8.97" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,459.22,468.83,27.93,8.97;4,332.16,479.27,158.43,8.97">py: An off-the-shelf language identification tool</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Langid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,508.80,479.58,18.97,8.26;4,332.16,490.14,114.48,8.26">ACL 2012 System Demonstrations</title>
		<imprint>
			<biblScope unit="page" from="25" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,332.16,501.23,169.72,8.97;4,332.16,511.67,158.52,8.97;4,332.16,522.11,194.22,8.97;4,332.16,532.98,185.17,8.26;4,332.16,543.11,193.35,8.97;4,332.16,553.55,137.32,8.97;4,332.16,563.99,65.08,8.97" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,463.32,511.67,27.36,8.97;4,332.16,522.11,118.80,8.97">Terrier information retrieval platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,469.80,522.42,56.58,8.26;4,332.16,532.98,185.17,8.26;4,332.16,543.11,163.62,8.97">Proceedings of the 27th European Conference on Advances in Information Retrieval Research, ECIR&apos;05</title>
		<meeting>the 27th European Conference on Advances in Information Retrieval Research, ECIR&apos;05<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="517" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,332.16,575.51,196.86,8.97;4,332.16,585.95,184.08,8.97;4,332.16,596.39,186.62,8.97;4,332.16,606.83,97.36,8.97" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,469.32,575.51,59.70,8.97;4,332.16,585.95,184.08,8.97;4,332.16,596.39,74.48,8.97">Tie-breaker: A new perspective of ranking and evaluation for microblog retrieval</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Darko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,424.80,596.70,93.98,8.26;4,332.16,607.14,69.25,8.26">Proceedings of the 2014 TREC conference</title>
		<meeting>the 2014 TREC conference</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,332.16,618.35,197.58,8.97;4,332.16,628.79,200.68,8.97;4,332.16,639.23,20.80,8.97" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,417.12,618.35,112.62,8.97;4,332.16,628.79,105.60,8.97">Tie breaker: A novel way of combining retrieval signals</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,456.00,629.10,72.18,8.26">Proc. of ICTIR&apos;13</title>
		<meeting>of ICTIR&apos;13</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
