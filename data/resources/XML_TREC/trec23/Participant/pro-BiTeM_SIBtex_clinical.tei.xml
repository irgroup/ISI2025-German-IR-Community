<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,35.04,134.55,525.30,12.64;1,117.26,150.75,360.46,12.64">Full-texts representation with Medical Subject Headings, and co-citations network reranking strategies for TREC 2014 Clinical Decision Support Track</title>
				<funder ref="#_GvR6FdY">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_pY53f5n">
					<orgName type="full">European Commission</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,174.38,190.66,49.27,10.80"><forename type="first">J</forename><surname>Gobeill</surname></persName>
						</author>
						<author>
							<persName coords="1,239.93,190.66,63.36,10.80"><forename type="first">A</forename><surname>Gaudinat</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">BiTeM group</orgName>
								<orgName type="department" key="dep2">Information Studies Department</orgName>
								<orgName type="institution">University of Applied Sciences</orgName>
								<address>
									<settlement>Geneva</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,313.37,190.66,49.22,10.80"><forename type="first">E</forename><surname>Pasche</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">BiTeM group</orgName>
								<orgName type="institution">University and Hospitals of Geneva</orgName>
								<address>
									<settlement>Geneva</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,372.19,190.66,40.54,10.80"><forename type="first">P</forename><surname>Ruch</surname></persName>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">SIBtex group</orgName>
								<orgName type="institution">Swiss Institute of Bioinformatics</orgName>
								<address>
									<settlement>Geneva</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,35.04,134.55,525.30,12.64;1,117.26,150.75,360.46,12.64">Full-texts representation with Medical Subject Headings, and co-citations network reranking strategies for TREC 2014 Clinical Decision Support Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2949DE9BC8EFC4643A63DAFE61F312E9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In TREC 2014 Clinical Decision Support Track, the task was to retrieve full-texts relevant for answering generic clinical questions about medical records. For this purpose, we investigated a large range of strategies in the five runs we officially submitted. Concerning Information Retrieval (IR), we tested two different indexing levels: documents or sections. Section indexing was clearly below (-40% in R-Precision). In the domain of Information Extraction, we enriched documents with Medical Subject Headings concepts that were collected from MEDLINE or extracted in the text with exact match strategies. We also investigated a target-specific semantic enrichment: MeSH terms representing diagnosis, treatments or tests (relying on UMLS semantic types) were used both in collection and in queries to guide the retrieval. Unfortunately, the MeSH representation was not as complementary with the text as we expected, and the results were disappointing. Concerning post-processing strategies, we tested the boosting of specific articles types (e.g. review articles, case reports), but the IR process already tended to favour these article types. Finally, we applied a reranking strategy relying on the cocitations network, thanks to normalized references provided in the corpus. This last strategy led to a slight improvement (+5%).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The Bibliomics and Text Mining group (BiTeM) in Geneva has a long history of participation in TREC campaigns, including TREC Genomics <ref type="bibr" coords="1,191.33,562.44,11.79,9.94" target="#b0">[1]</ref>, TREC Medical Records <ref type="bibr" coords="1,68.18,575.40,12.91,9.94" target="#b1">[2]</ref> or TREC Chemical IR Tracks <ref type="bibr" coords="1,222.65,575.40,11.79,9.94" target="#b2">[3]</ref>. In parallel, the group has recently joined the Swiss Institute of Bioinformatics. Additionally, the group is currently involved in several translational medicine research project, including the MD-Paedigree project (EU FP7 Programme), where his task is to help clinicians to retrieve similar cases in a federated digital repository gathering data from 7 European clinical centres, for better personalised predictive medicine. The focus of the 2014 Clinical Decision Support Track was the retrieval of biomedical articles relevant for answering generic clinical questions about medical records <ref type="bibr" coords="1,160.34,717.98,11.79,9.94" target="#b3">[4]</ref>. This track provided a rare opportunity to investigate several approaches for linking medical cases to information relevant for patient care.</p><p>Indeed, a large range of strategies were implemented in the five runs we submitted. Concerning Information Retrieval (IR), we tested two different indexing levels: documents or sections. In the domain of Information Extraction, we enriched documents with Medical Subject Headings (MeSH) terms that were collected from MEDLINE or found in the text with exact match strategies. Depending on the runs, these metadata were added to the document representation, or exploited in a parallel index. We also investigated a target-specific semantic enrichment: MeSH terms representing diagnosis, treatments or tests (relying on UMLS semantic types) were used both in collection and in queries to guide the retrieval. Concerning post-processing strategies, we tested the boosting of specific articles types (e.g. review articles, case reports). Finally, we applied a reranking strategy relying on a co-citations network, thanks to normalized references provided in the corpus: articles that were cited by the top retrieved documents were added or boosted in the last run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data and strategies</head><p>We officially submitted five runs. As we had no training nor tuning data, all strategies were applied with a priori and intuitive settings. When results and qrel (gold file) were made available (what we call "in postcompetition"), we also evaluated supplementary runs with different settings in order to have a better idea on the optimal performances of our strategies. Obviously, due to the nature of the gold file (pooling judgments), when we compute a post-competition run, we have to keep in mind that it can be under-evaluated, as it can contain a larger part of non-judged documents than official runs. Yet, improvements and comparisons remain valid.</p><p>All retrievals were generated with Terrier <ref type="bibr" coords="2,231.99,281.35,11.80,9.94" target="#b4">[5]</ref>, an IR platform (in Java) which implements state-of-the-art indexing and retrieval functionalities, including a TREC format output. We used Terrier with a classical Okapi BM25 weighting scheme, with default settings, and an automatic relevance feedback query expansion: see <ref type="bibr" coords="2,267.00,346.15,12.96,9.94" target="#b5">[6]</ref> for more details about Terrier models. In the following, the Retrieval Status Value (RSV) is the relevance score attributed to a document by Terrier. Post-processing strategies were applied thanks to local scripts in Perl.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Full text indexing</head><p>Here are some statistics computed prior to the design of the full text search engine. The collection contained 733,328 documents from PubMed Central. Documents were in nxml format, and could be composed of an abstract, and/or different full-text sections. Most of them (79%) had an abstract and other sections, while 14% had sections but no abstract, and 7% had an abstract but no section. Documents had on average 11 sections, while a section contained on average 360 words, versus 160 for an abstract. Document or section indexing. We decided to test two indexing units: document or section. For document indexing, all sections were merged into a unique representation. For section indexing, each section was indexed; then, in the output of the search engine, when multiple sections from the same document appeared in the ranking, the RSV of the document was the RSV of its first retrieved section.</p><p>Query representation. In the official test set (30 queries), each query contained a full description of the information need, and a summary. For the official runs, we only used the summary part, but in post-competition we also evaluated retrieval with full queries. For all experiments, we removed numbers from the queries.</p><p>Boosting based on article types. Still for full text indexing, we also investigated a boosting strategy depending on article types. Our initial hypothesis was that review articles and case reports were more likely to be relevant for clinical decision support, thus we decided to apply a +20% boost on RSV for these article types. This +20% boost was applied to all official runs, but in postcompetition we evaluated different boosting values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) MeSH recognition and indexing</head><p>In parallel with full text indexing, we also investigated MeSH recognition and indexing. MeSH indexing can offer a complementary representation in some retrieval tasks, such as with clinical captions in previous CLEF evaluation campaigns <ref type="bibr" coords="2,419.03,299.11,11.77,9.94" target="#b6">[7]</ref>. MeSH concepts were recognised in documents using a classical strict mapping (Rabin-Karp algorithm). See <ref type="bibr" coords="2,450.88,325.03,12.97,9.94" target="#b7">[8]</ref> for further details and evaluation of MeSH recognition by Rabin-Karp algorithm. MeSH concepts manually assigned by human indexers also could be collected when the PubMed Central document had a corresponding citation in MEDLINE. Thus, each document (or section) could be represented and indexed with its MeSH concepts. Then, the same extraction was performed with queries.</p><p>MeSH concepts for document representation. We extracted an average of 422 MeSH concepts per document. Dealing with MeSH concepts collected from MEDLINE, 92% of the documents in the collection had an associated PMID, and only 53% had MeSH terms assignments in MEDLINE (usually around 10 MeSH concepts). Thus, for official submissions, we had the choice between building one index for text and one for MeSH, and then combining the rankings, or building a unique entity for each document, merging text and MeSH terms.</p><p>MeSH concepts for query representation. The same extraction was performed for queries. The Figure <ref type="figure" coords="2,530.81,610.20,5.52,9.94" target="#fig_0">1</ref> shows the MeSH concepts that were extracted from summaries of queries 1,11 and 21. MeSHtargets. Queries dealt with one of these three categories: diagnosis, tests or treatments. A particularly promising investigated strategy was to identify in documents the extracted MeSH concepts that belonged to the corresponding category, and to over-weight them.</p><p>For instance, for queries dealing with tests, documents that have a lot of MeSH concepts related to tests should be favoured. Thanks to the UMLS Semantic Types <ref type="bibr" coords="3,264.14,383.61,11.90,9.94" target="#b8">[9]</ref>, we designed sets of Semantics Types for each category.</p><p>For instance, for tests, we selected T060 Diagnostic Procedure and T059 Laboratory Procedure. Thus, for each document, for each MeSH concept belonging to the test category, we added the word MeSHtargetTest in the document representation. There was an average of 14 MeSHtargetTest in documents, versus 37 for MeSHtargetDiagnosis and 22 MeSHtargetTreatment.</p><p>The same MeSHtargets were used in queries. For instance, for queries dealing with tests, we added MeSHtargetTest three times in the query representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Co-citations network</head><p>At last, we explored post-processing strategies dealing with co-citations. The idea was to start from a ranking, and then to promote the citations of the top retrieved documents. This strategy achieved leading results with patents (see TREC Chem campaigns <ref type="bibr" coords="3,209.09,621.96,11.79,9.94" target="#b2">[3]</ref>, with up to +150% for MAP), but it was the first time we applied this to the medical literature. Formula 1 gives the final score of a document d after re-ranking. E is the set of retrieved documents (1000 by default), is_citedd,e is 1 if</p><formula xml:id="formula_0" coords="3,31.44,685.40,248.55,85.47">document d is cited in document e, 0 otherwise.  is a setting variable.      E e e d d d RSV cited is RSV Score  , _ Formula 1. Co-citations network boosting.</formula><p>In simple words, this reranking consists in scanning the retrieval ranking, and for each document e and its RSVe, adding   RSVe to its citations. This means that doc- uments that were not retrieved by IR can appear if they are cited by most top retrieved documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>In the following, we describe results in light of R-Prec.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Full text indexing</head><p>All the submitted runs were computed with both text and MeSH indexes, but in post-competition we investigated text-only indexes.</p><p>Document or section indexing. Official runs 1 and 2 were computed with document indexing, while official runs 3 et 4 were with section indexing. The official run 5 was supposed to be our optimal run, and was computed from the run 4: this illustrates how we thought that section indexing would have better results. Unfortunately, runs 1 and 2 were much better than runs 3 and 4.</p><p>In particular, runs 2 and 4 only differed on the indexing, and run 2 had a R-Prec of 0.187, versus 0.114 for run 4 (-39%). In post-competition, no further experiments were done with section indexing.</p><p>Query representation. All submitted runs were computed using only the summary part of the queries. In postcompetition, we compared the value of description and summary, evaluated with the document indexing, without automatic query expansion. In terms of R-Prec, descriptions obtained 0.169, summaries obtained 0.170, while a query representation with both fields obtained 0.185 (+9%). With automatic query expansion in Terrier, R-Prec reached 0.211 (+14%).</p><p>Boosting based on article types. In post-competition, we analysed the qrel in order to find which article types were overrepresented in the qrel compared with the collection, i.e. which article types are more likely to be relevant for this task. Our intuition was good, as review-articles and casereports are much more represented in qrel compared to the collection. For all our official runs, we applied a +20% boosting for RSV for these article types. Unfortunately, post-competition experiments did not confirm the effectiveness of this strategy. Starting from the previous post-competition run (R-Prec 0.211), the +20% boosting degraded the run (R-Prec 0.195, -8%). Actually, no tested value for boosting led to better results. Table <ref type="table" coords="4,47.75,426.33,5.52,9.94" target="#tab_1">1</ref> shows the distribution in our run, and it seems that the IR engine already returns a larger number of casereports.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) MeSH indexing</head><p>All the submitted runs were built with both text and MeSH indexes, but in post-competition we investigated MeSH-only indexes.</p><p>MeSH concepts for document representation. For the query representation in competition, we only used MeSH terms extracted from the summary. In postcompetition, like for text, we compared the value of description and summary. With the MeSH indexing, querying with MeSH terms extracted from description led to R-Prec of 0.123, versus 0.125 with MeSH terms extracted from summary. Like for text, both values are equivalent, and like for text the result is slightly better when using both sources: R-Prec of 0.143 (+14%). Unlike text, automatic query expansion is not useful for MeSH representation. Yet, the optimal performances of the MeSH representation are lower than text: R-Prec 0.143 versus 0.211. We then wanted to know how complementary both representations were. We thus analysed the qrel and our both runs (text and MeSH) and looked at the proportion of relevant documents that were found by each. The following Venn diagram (Figure <ref type="figure" coords="4,453.95,86.68,4.60,9.94" target="#fig_3">3</ref>) illustrates the distribution. Hence, starting from the text index, it seems hard to combine the MeSH index and to take benefit from the 6% of relevant documents only retrieved by MeSH. We tested different linear combinations but only achieved a little gain (R-Prec from 0.211 to 0.213) using 10% of the MeSH RSVs.</p><p>Finally, the impact of the MeSH concepts collected from MEDLINE was weak: when indexing only these MeSH concepts, the computed run had R-Prec 0.028.</p><p>MeSHtargets. In the official submissions, runs 3 and 4 only differed in the application of the MeSHtargets strategy. We observe a slight improvement in R-Prec (+6%). Unfortunately, these official runs were computed with section indexing. In post-competition, we explored a wide range of settings for applying this strategy to runs computed with document indexing, but we did not observed any significant gain. With  = 0.05 we observe a slight improvement (+5%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Co-citations network</head><p>In the official runs, we applied this strategy to the run 4 and arbitrarily set  to 0.10. Unfortunately, run 4 was computed with section indexing and was far from being the best one. Yet, a gain was also observed from run 4 to run 5 (R-Prec from 0.114 to 0.124, +8%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>For this TREC CDS 2014 campaign, we explored a wide range of strategies, such as :</p><p>-document or section indexing, -MeSH representation, -article-type boosting, -co-citations network.</p><p>Section indexing was clearly a weak approach. The article-type boosting was counter-productive, but it appeared that the IR process already tends to favour reviews and case reports. MeSH representations, extracted from the full-text or collected from MEDLINE, led to very slight improvement and did not show great complementarity with the text. Finally, the co-citations network strategy led to significant improvements (+5%).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,32.76,263.13,242.69,8.96;3,83.06,274.89,142.08,8.96"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Test set in the official format, with MeSH concepts that were extracted in the summary.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,315.29,196.00,251.70,9.94;3,315.29,208.96,251.63,9.94;3,315.29,221.92,215.22,9.94"><head>Figure 2</head><label>2</label><figDesc>contains different official R-Prec of TREC CDS 2014. BiTeM runs from 1 to 5 investigated different strategies that are discussed in the following.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,317.83,402.71,246.49,8.96;3,352.63,414.37,176.88,9.05;3,315.25,232.45,241.45,161.75"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Different official R-Prec values, for the BiTeM runs and the other teams' runs (median and best).</figDesc><graphic coords="3,315.25,232.45,241.45,161.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,317.71,347.61,246.66,8.96;4,324.43,359.37,233.22,8.96;4,323.23,371.13,235.58,8.96;4,381.79,382.91,118.52,8.96;4,318.25,122.75,251.50,203.30"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Complementarity of text and MeSH representations.17% of relevant documents were only retrieved by the text index (at rank 1000), 6% only by the MeSH index, 37% by both. 40% were not retrieved.</figDesc><graphic coords="4,318.25,122.75,251.50,203.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,50.04,191.09,208.26,79.08"><head>Article type Distribution in qrel in collection in our runs</head><label></label><figDesc></figDesc><table coords="4,50.04,213.74,199.75,56.43"><row><cell cols="2">research-article 52.2%</cell><cell>74.3 %</cell><cell>37.9 %</cell></row><row><cell>case-report</cell><cell>20.4 %</cell><cell>4.0 %</cell><cell>41.5 %</cell></row><row><cell cols="2">review-article 17.9 %</cell><cell>6.9 %</cell><cell>10.9 %</cell></row><row><cell>Other</cell><cell>3.2 %</cell><cell>2.6 %</cell><cell>3.6 %</cell></row><row><cell>brief-report</cell><cell>1.5 %</cell><cell>1.1 %</cell><cell>0.9 %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,38.28,279.93,231.61,20.72"><head>Table 1 .</head><label>1</label><figDesc>Distribution of article types in qrel (only relevant documents), in collection, and in one of our runs.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,315.29,678.12,251.85,35.88"><head>Table 2</head><label>2</label><figDesc>gives the result of the co-citation network strategy applied to the best run described (text representation + 10% MeSH representation, R-Prec 0.213). Prec 0.213 0.214 0.224 0.224 0.218 0.209</figDesc><table coords="5,38.64,71.25,225.93,24.05"><row><cell></cell><cell>0</cell><cell>0.01</cell><cell>0.05</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell></row><row><cell>R-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,36.00,104.46,236.32,20.72"><head>Table 2 .</head><label>2</label><figDesc>R-Prec after the co-citations network strategy with different values of alpha. 0 is the baseline.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was partially funded by the <rs type="funder">European Commission</rs> under grant agreement <rs type="grantNumber">600932</rs> (<rs type="grantNumber">FP7-ICT-2011-9</rs>), <rs type="projectName">MD-Paedigree</rs> project.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_pY53f5n">
					<idno type="grant-number">600932</idno>
				</org>
				<org type="funded-project" xml:id="_GvR6FdY">
					<idno type="grant-number">FP7-ICT-2011-9</idno>
					<orgName type="project" subtype="full">MD-Paedigree</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,42.48,581.30,237.16,8.96;5,42.48,593.06,237.59,8.96;5,42.48,604.82,94.22,8.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,264.09,581.30,15.55,8.96;5,42.48,593.06,237.59,8.96;5,42.48,604.82,48.15,8.96">Vocabulary-Driven Passage Retrieval for Question-Answering in Genomics</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tbahriti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ehrler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ruch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,108.66,604.82,22.43,8.96">TREC</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,42.48,622.58,237.17,8.96;5,42.48,634.34,237.38,8.96;5,42.48,646.10,188.38,8.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,175.17,634.34,104.69,8.96;5,42.48,646.10,142.52,8.96">BiTeM Group Report for TREC Medical Records Track 2011</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gaudinat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ruch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Pasche</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Teodoro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Vishnyakova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,202.83,646.10,22.43,8.96">TREC</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,42.48,663.86,237.06,8.96;5,42.48,675.62,237.21,8.96;5,42.48,687.38,237.27,8.96;5,42.48,699.16,22.65,8.96" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="5,232.10,663.86,47.44,8.96;5,42.48,675.62,237.21,8.96;5,42.48,687.38,118.62,8.96">Exploring a wide range of simple pre and post processing strategies for patent searching in CLEF IP</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Theodoro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ruch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009. 2009. 2009</date>
			<publisher>CLEF working notes</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,42.48,716.92,237.61,8.96;5,42.48,728.68,72.52,8.96" xml:id="b3">
	<monogr>
		<ptr target="http://www.trec-cds.org/2014.html" />
		<title level="m" coord="5,42.48,716.92,157.89,8.96">TREC 2014 CDS Track website</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,42.48,746.44,237.51,8.96;5,42.48,758.20,237.51,8.96;5,329.47,73.50,237.39,8.96;5,329.47,85.26,117.83,8.96" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<title level="m" coord="5,231.17,746.44,48.82,8.96;5,42.48,758.20,237.51,8.96;5,329.47,73.50,237.39,8.96;5,329.47,85.26,113.69,8.96">Proceedings of ACM SIGIR&apos;06 Workshop on Open Source Information Retrieval. Terrier: A High Performance and Scalable Information Retrieval Platform</title>
		<meeting>ACM SIGIR&apos;06 Workshop on Open Source Information Retrieval. Terrier: A High Performance and Scalable Information Retrieval Platform</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,329.47,103.02,237.35,8.96;5,329.47,114.78,237.31,8.96;5,329.47,126.54,237.40,8.96;5,329.47,138.30,149.52,8.96" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="5,400.39,103.02,166.43,8.96;5,329.47,114.78,187.82,8.96">Probabilistic Models for Information Retrieval based on Divergence from Randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>TREC-CHEM Track Guidelines</publisher>
		</imprint>
		<respStmt>
			<orgName>Science University of Glasgow, Department of Computing</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct coords="5,329.47,156.06,237.05,8.96;5,329.47,167.82,237.43,8.96;5,329.47,179.58,237.30,8.96;5,329.47,191.34,63.30,8.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,329.47,167.82,237.43,8.96;5,329.47,179.58,167.22,8.96">Taking benefit of query and document expansion using mesh descriptors in medical imageclef</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Theodoro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Patsche</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ruch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="5,531.34,179.58,35.43,8.96;5,329.47,191.34,57.95,8.96">Working Notes of CLEF</title>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,329.47,209.10,237.43,8.96;5,329.47,220.86,237.59,8.96;5,329.47,232.65,53.68,8.96" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="5,407.95,209.10,158.95,8.96;5,329.47,220.86,50.42,8.96">Modèles de Question/Réponse pour la Biomédecine</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gobeill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>University of Geneva</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Doctoral dissertation, PHD Thesis</note>
</biblStruct>

<biblStruct coords="5,329.47,250.41,237.35,8.96;5,329.47,262.17,237.34,8.96;5,329.47,273.93,237.32,8.96;5,329.47,285.69,114.51,8.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,512.28,250.41,54.54,8.96;5,329.47,262.17,201.05,8.96">Mapping the UMLS Semantic Network into general ontologies</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Burgun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,549.49,262.17,17.32,8.96;5,329.47,273.93,139.54,8.96">Proceedings of the AMIA Symposium</title>
		<meeting>the AMIA Symposium</meeting>
		<imprint>
			<publisher>American Medical Informatics Association</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page">81</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
