<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,140.27,70.07,329.23,18.83">IO-Top-k at TREC 2006: Terabyte Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,59.18,116.43,62.44,12.55"><forename type="first">Holger</forename><surname>Bast</surname></persName>
							<email>bast@mpi-inf.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="department">Max-Planck-Institut für Informatik</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,139.11,116.43,110.87,12.55"><forename type="first">Debapriyo</forename><surname>Majumdar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max-Planck-Institut für Informatik</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,267.48,116.43,73.51,12.55"><forename type="first">Ralf</forename><surname>Schenkel</surname></persName>
							<email>schenkel@mpi-inf.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="department">Max-Planck-Institut für Informatik</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,358.46,116.43,86.84,12.55"><forename type="first">Martin</forename><surname>Theobald</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max-Planck-Institut für Informatik</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,462.81,116.43,89.98,12.55"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
							<email>weikum@mpi-inf.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="department">Max-Planck-Institut für Informatik</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,140.27,70.07,329.23,18.83">IO-Top-k at TREC 2006: Terabyte Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5A543F5F6FB776E1D3BB565A13CB7849</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the setup and results of our contribution to the TREC 2006 Terabyte Track. Our implementation was based on the algorithms proposed in [1] "IO-Top-k: Index-Access Optimized Top-K Query Processing, VLDB'06", with a main focus on the efficiency track.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>IO-Top-k <ref type="bibr" coords="1,104.14,314.82,9.72,9.41" target="#b0">[1]</ref> extends the family of threshold algorithms (TA) <ref type="bibr" coords="1,76.93,325.27,9.72,9.41" target="#b2">[3,</ref><ref type="bibr" coords="1,89.57,325.27,7.16,9.41" target="#b3">4,</ref><ref type="bibr" coords="1,99.65,325.27,7.16,9.41" target="#b7">8]</ref> with a suite of new strategies. To retrieve the best-scoring (so-called top-k) answers to a multi-keyword query under a monotonic aggregation of per-keyword scores, TA-style algorithms perform index scans (so-called sorted accesses) over precomputed index lists, one for each keyword in the query, which are sorted in descending order of perkeyword scores. The key point of TA is that it aggregates scores on the fly, thus computes a lower bound for the total score of the current rank-k result document and an upper bound for the total scores of all other candidate documents, and is thus often able to terminate the index scans long before it reaches the bottom of the index lists, namely, when the lower bound for the rank-k result, the threshold, is at least as high as the upper bound for all other candidates. Additional, carefully selected random accesses to reveal the score of a candidate document in a list where it has not yet been seen so far can further speed up the computation. The goal of such algorithms is to minimize the sum of the access costs, assuming a fixed cost cS for each sorted access and a fixed cost c R for each random access. In a realistic scenario, random accesses are a factor of 50 to 50,000 more expensive than sorted accesses. We aim at accelerating queries and, at the same time, limit or even aim to reducing the memory consumption for candidate queues and other auxiliary data structures.</p><p>For our participation in TREC 2006, we selected two strategies from the suite of algorithms presented in <ref type="bibr" coords="1,262.70,597.26,9.21,9.41" target="#b0">[1]</ref>:</p><p>• A scheduling strategy for random accesses that postpones all random accesses to the end of the execution, switching from scans to random accesses when the estimated cost for them is the same.</p><p>• A heuristics for early termination that scans only a configurable fraction of the lists, regardless of the score bounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">COMPUTATIONAL MODEL AND SCOR-ING</head><p>We associate with each document-term pair a numeric score that reflects the "goodness" or relevance of the data item with regard to the term. As effectiveness was not in the focus of our experiments, we chose the well-known probabilistic Okapi BM25 score derived from term frequencies (TF) and inverse document frequencies (IDF) <ref type="bibr" coords="1,502.04,287.77,9.21,9.41" target="#b8">[9]</ref>. We boost the frequency of terms within important tags (like title, h1, or caption) by an additional, tag-specific weight. Denoting the score of document d j for the ith dimension by s ij , we get</p><formula xml:id="formula_0" coords="1,352.87,352.67,165.79,21.70">sij = (k1 + 1) • tfi(dj) K + tf i (d j ) • log N -dfi + 0.5 df i + 0.5</formula><p>where tf i (d j ) is the term frequency of term i in document d j , df i is the document frequency of term i, and</p><formula xml:id="formula_1" coords="1,359.32,405.82,146.11,21.29">K = k 1 • (1 -b) + b length(dj) avg(length(d))</formula><p>For our experiments, we chose k1 = 1.2 and b = 0.75. All scores are normalized to the interval [0, 1], with 1 being the best possible score.</p><p>A top-k query asks for those k documents with the highest score sum. Note that such a document must not necessarily contain all query words, because a document containing just some of the query words but with a high score each can have a larger score sum than a document which contains all query words, but with only a relatively low score each.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">INVERTED BLOCK-INDEX</head><p>The documents that contain specific terms and their corresponding scores are precomputed and stored in inverted index lists Li (i = 1..M ). There is one such index list per term. The entries in a list are &lt;docID, score&gt; pairs. The lists may be very long (millions of entries) and reside on disk, with a B + -tree or similar data structure for efficiently locating the keys of the lists (i.e., the attribute values or terms). We partition each index list into blocks and use score-descending order among blocks but keep the index entries within each block in docID order. This special ordering, which is halfway between an ordering by score and an ordering by doc id, is key to efficiently manage the substantial bookkeeping required in TA-style query processing.</p><p>The block size is a configuration parameter that is chosen in a way that balances disk seek time and transfer rate; a typical block size would be 32,768.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">QUERY PROCESSING</head><p>Our query processing model is based on the NRA and CA variants of the TA family of algorithms <ref type="bibr" coords="2,243.52,79.56,9.21,9.41" target="#b2">[3]</ref>. An mdimensional top-k query (with m search conditions) is primarily processed by scanning the corresponding m index lists in descending score orders in an interleaved, roundrobin manner (and by making judicious random accesses to look up index entries of specific documents). Without loss of generality, we assume that these are the index lists numbered L 1 through L m .</p><p>When scanning the m index lists, the query processor collects candidates for the query result and maintains them in two priority queues, one for the current top-k items and another one for all other candidates that could still make it into the final top-k. For simpler presentation, we assume that the score aggregation function is simple summation (but it is easy to extend this to other monotonic functions). The query processor maintains the following state information:</p><p>• the current cursor position posi for each list Li,</p><p>• the score values high i at the current cursor positions, which serve as upper bounds for the unknown scores in the lists' tails,</p><p>• a set of current top-k items, d1 through d k (renumbered to reflect their current ranks) and a set of data items d j (j = k + 1..k + q) in the current candidate queue Q, each with -a set of evaluated dimensions E(d j ) in which d j has already been seen during the scans or by random lookups, -a set of remainder dimensions Ē(d j ) for which the score of d j is still unknown, -a lower bound worstscore(dj) for the total score of dj which is the sum of the scores from E(dj), -an upper bound bestscore(d j ) for the total score of d j which is equal to</p><formula xml:id="formula_2" coords="2,124.81,452.01,96.64,21.28">worstscore(d j ) + ν∈ Ē(d j )</formula><p>high ν (and not actually stored but rather computed from worstscore(dj) and the current highν values whenever needed).</p><p>In addition, the following information is derived at each step:</p><p>• the minimum worstscore min-k of the current top-k docs, which serves as the stopping threshold,</p><p>• the bestscore that any currently unseen document can get, which is computed as the sum of the current highi values, and</p><p>• and for each candidate, a score deficit δj = min-kworstscore(dj) that dj would have to reach in order to qualify for the current top-k.</p><p>The top-k queue is sorted by worstscore values, and the candidate queue is sorted by descending bestscore values. Ties among scores may be broken by using the concatenation of &lt;score, docID&gt; for sorting. The invariant that separates the two is that the rank-k worstscore of the top-k queue is at least as high as the best worstscore in the candidate queue. The algorithm can safely terminate, yielding the correct top-k results, when the maximum bestscore of the candidate queue is not larger than the rank-k worstscore of the current top-k, i.e., when</p><formula xml:id="formula_3" coords="2,329.76,83.09,213.20,14.47">min d∈top-k {worstscore(d)} =: min-k ≥ max c∈Q {bestscore(c)}</formula><p>More generally, whenever a candidate in the queue Q has a bestscore that is not higher than min-k, this candidate can be pruned from the queue. Early termination (i.e., the point when the queue becomes empty) is one goal of efficient top-k processing, but early pruning to keep the queue and its memory consumption small is an equally important goal (and is not necessarily implied by early termination). The candidate bookkeeping is illustrated in Fig. <ref type="figure" coords="2,494.65,177.36,3.58,9.41" target="#fig_0">1</ref>. The state information we have to maintain for each document, from the point it is first encountered to the point where it is surely known that either the document is one of the top -k or that it cannot be, adds a noticeable amount of overhead to the algorithm. This has to be contrasted with a simple full merge (of the lists sorted by document ids), which can compute the full scores document by document, and then determine the top-k items by a (partial) sort. It is not at all obvious, and indeed put forward as an open problem in <ref type="bibr" coords="2,363.12,500.47,9.21,9.41" target="#b2">[3]</ref>, whether the state maintenance of any of the sophisticated TA-style algorithms can be implemented efficiently enough so that the gains in the abstract cost indeed show in faster running times.</p><p>In our first implementation we maintained all state information in a hash data structure; indeed, this is the approach taken in all top-k implementations that we are aware of <ref type="bibr" coords="2,326.98,573.70,13.51,9.41" target="#b10">[11]</ref>. However, despite their strong advantage in theoretical cost, none of our sophisticated algorithms could beat the simple full-merge baseline in this implementation. We then switched to the inverted block-index described in Section 3. An essential ingredient of our implementation is to keep the state information in-place, i.e., in a contiguous memory segment together with the document id. The process of merging two or more document lists, and updating all state information then has almost optimal locality properties.</p><p>The most time-critical step in the merge is the computation of the bestscore, which we do not store explicitly but rather compute from the worstscore and the set of lists in which the documents have been seen so far. We store this seen information by a simple m-bit vector, where m is the number of lists, and for each round precompute all 2 m partial sums of the high-scores high i of each list (see Section 4). For any document, the bestscore can then be computed from the worstscore by a simple table lookup with the seen-bitvector serving as a direct index into that table.</p><p>To keep the merges as fast as those of the baseline fullmerge, we also do not maintain the set of top-k items as we merge, and not even the min-k score. We rather do the merge twice, outputting only the scores in the first round, doing a partial sort of these to obtain the min-k score, and then repeat the merge, but this time with an on-the-fly pruning of all documents with a bestscore below that min-k score. By these, and a bag of other tricks, we managed to keep the overhead for maintaining the state-information a small fraction of the essential operations of reading and merging blocks of pairs of document ids and score, sorted by document id.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">SCHEDULING OF RANDOM ACCESSES</head><p>Random-access (RA) scheduling is crucial both in the early and the late stages of top-k query processing. In the early stage, it is important to ensure that the min-k threshold moves up quickly so as to make the candidate pruning more effective as the scans proceed and collect large amounts of candidates. Later, it is important to avoid that the algorithm cannot terminate merely because of a few pieces of information missing about a few borderline candidates. In <ref type="bibr" coords="3,280.52,333.11,9.21,9.41" target="#b0">[1]</ref>, we analyzed various strategies for deciding when to issue RAs and for which candidates in which lists; for our experiments, we focused on one of these strategies that was both efficient to compute and resulted in a good performance. Following the literature <ref type="bibr" coords="3,152.32,385.41,9.72,9.41" target="#b1">[2,</ref><ref type="bibr" coords="3,165.47,385.41,6.48,9.41" target="#b5">6]</ref>, we refer to score lookups by RA as probing. As in <ref type="bibr" coords="3,149.93,395.87,9.21,9.41" target="#b2">[3]</ref>, we denote by cS the cost of a sorted access, and by c R the cost of a random access.</p><p>Our scheduling strategy for random accesses, coined Last-Probing in <ref type="bibr" coords="3,98.97,427.25,9.21,9.41" target="#b0">[1]</ref>, does a balanced number of random accesses just as Fagin's CA algorithm, that is, the total cost of the random accesses is about the same as the total cost of all sorted accesses. In CA, this is trivially achieved by doing one random access after each round of c R /c S sorted accesses. In Last-Probing, we perform random accesses only after the last round, that is, we have a phase of only sorted accesses, followed by a phase of only random accesses.</p><p>We do this by estimating, after each round, the number of random accesses that would have to be done if this were the last round of sorted accesses. Two criteria must be met for this round of sorted accesses being the last. First, the estimated number of random accesses must be less than c R /c S times the number of all sorted accesses done up to this point Second, we must have m i=1 highi ≤ min-k, since only then we can be sure that we have encountered all the top-k items already. We remark that in all our applications, the second criterion is typically fulfilled long before (that is, after much fewer rounds than) the first criterion. A simple estimate for the number of random lookups that would have to be done if we stopped doing sorted accesses at a certain point, is the number of candidate documents which are then in our queue. When the distribution is very skewed, it is in fact quite a good estimate, because then each document in the queue has a positive but only very tiny probability of becoming one of the top-k items.</p><p>When doing the random accesses, it plays a role in which order we process the documents for which we do random lookups. In our algorithm, we first schedule RAs for any items in the current top-k that are not yet completely evaluated, in decreasing order of their worst scores. Then, we schedule RAs for items in the candidate queue, ordered by decreasing bestscore (Last-Best). This is similar to CA, which after each round of sorted accesses does a random access for the candidate document with the highest bestscore.</p><p>Note that unlike more aggressive pruning strategies proposed in the literature <ref type="bibr" coords="3,412.00,139.83,9.72,9.41" target="#b4">[5,</ref><ref type="bibr" coords="3,425.48,139.83,7.16,9.41" target="#b6">7,</ref><ref type="bibr" coords="3,436.41,139.83,11.77,9.41" target="#b9">10]</ref> that provide approximate top-k results, our method is non-approximative and achieves major runtime gains with no loss in result precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EARLY STOPPING HEURISTIC</head><p>We used an early stopping heuristic for two of our efficiency runs. For these runs, we ignored all the blocks after the first 1/5-th of the blocks in every list (e.g. if there are 14 blocks in a list, we only considered the first 3 blocks). Note that since the blocksize of our inverted block index was as large as 131,072, all the small lists were almost fully scanned. Only for the very long lists, the tails are ignored. As we find from the results (see Section 9.1), this heuristic works quite well in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">TEST PLATFORM</head><p>We parsed the collection on a small cluster of three servers, each with two Intel Xeon processors running Windows at 3 GHz. Our TREC runs were performed on a single machine having two 2390 MHz AMD Opteron CPUs and 8 GB of memory. The index files were stored on a local 44 GB SCSI disk with 10,000 rpm rotational speed. The operating system used was Linux.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">INDEXING</head><p>We indexed the collection using Okapi BM25 scoring function with standard parameters after removing stopwords, but without stemming. Prior to computing the BM25 scores, the term frequencies (tfs) of the terms were computed using a weighted sum of term-occurrences, with the weights being one for occurrences in standard text, and between 1.5 and 4 for occurrences inside special HTML tags (see Table <ref type="table" coords="3,332.28,489.28,4.61,9.41">1</ref> for details). The term scores were initially stored in a relational schema of the form (docID,term,score) in an Oracle database. After the parsing, the index lists were created from the database and stored in two files, namely one for sorted access and one for random access. HTML tag factor TITLE, in URL 4.0 H1 -H2 3.0 H3 -H6, STRONG, B, CAPTION, TH 2.0 EM, I, U, DL, OL, UL, A, META 1.5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1: Term weights for different tags</head><p>The inverted block-index for sorted access stored, for each term, a list of pairs of the form &lt;docID,score&gt;, together with a two level B-Tree to store the offsets of the lists corresponding to every term. The index for random access stored list of pairs &lt;termID,score&gt; for every document and the offsets for the lists were stored in a single array. The total size of our index files on disk was about 35 GB, each index contributing to little more than 17 GB. At runtime, only the offsets of the lists for random access (about 200 MB) resided in memory, all other data were read from disk. We did not use any caching other than some automatic filesystem caching over which we did not have any control.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">RUNS AND RESULTS</head><p>We submitted four runs for the efficiency task and four runs for the adhoc task. However, this year, our main focus was in the efficiency task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">Efficiency Task</head><p>For all of the efficiency runs, the queries were parsed automatically from the query streams, and all the words present in each query line were taken as keywords. Since stopwords were removed at the time of parsing, such words automatically did not play any role in retrieval.</p><p>The four runs submitted for the efficiency task were based on two versions of our algorithm, as follows:</p><p>• mpiiotopk -computation of exact top-20 documents (as defined in Section 4 and Section 5) for each query. The 100,000 queries were processed sequentially from a single stream. The average running time was 0.152 sec. This run essentially used a single processor.</p><p>• mpiiotopkpar -computation of exact top-20 documents using the same scheme as in mpiiotopk. However, for this run the queries were processed from four streams in parallel. Note that the documents returned by this run were the same as the documents returned by mpiiotopk. In spite of processing four streams parallally, this run is only about twice faster (average running time: 0.074 sec) than the previous run, because the machine we used had only two processors.</p><p>• mpiiotopk2 -avoids scanning deep into long lists using the early stopping heuristic as described in Section 6, with all 100,000 queries being processed sequentially from a single stream. The documents returned by this run are not the exact top-20. Using the early stopping heuristic, the average runtime improves by more than 2.5 times (average running time: 0.057 sec) from the exact run.</p><p>• mpiiotopk2p -same as mpiiotopk2, but four query streams were processed in parallel. Again, the parallelization improves the running time only by a factor of two (average running time: 0.028 sec), because the program was run on a machine with two processors. A proper parallelization of the process with at least 4 processors could boost the efficiency of these runs, but we did not have such a setup at the time of performing these experiments.</p><p>The documents returned by the first two runs (mpiiotopk and mpiiotopkpar) are precisely those that any retrieval model using standard BM25 scoring function would return. The precisons of these runs turned out to be decent, namely 0.5110 on average for topics 751-800 and 0.4280 on average for topics 801-850. Interestingly, the precisions of the runs mpiiotopk2 and mpiiotopk2p using the early stopping heuristic were not much worse for topics 751-800 (0.4820) and equally good for topics 801-850 (0.4330). Since the blocksize of our inverted block index was large (131,072), the first block of every list was always scanned and ignoring the tail of long lists did not affect the retrieval quality much, instead we gained a factor of more than 2.5 in running time.</p><p>The details of the runs are given </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Adhoc Task</head><p>Our adhoc runs were based on simple methods for constructing queries from the topics provided. For this task also we used the BM25 scoring model default parameters. For all runs, queries were processed automatically using the exact top-k algorithm same as our efficiency runs (e.g. as in mpiiotopk). For the four runs, the queries were constructed as follows:</p><p>• mpiirtitle -words in the title fields were taken as keywords.</p><p>• mpiirdesc -words in the description fields were taken as keywords.</p><p>• mpiircomb -words in the title as well as in the description fields (with possible repetition) were taken as keywords.</p><p>• mpiirmanual -only the construction of the queries were manual, as the keywords were chosen manually by only looking at the title, description and narrative fields.</p><p>Among these runs, the precisions of mpiircomb and mpiirmanual are better than the other two runs, as we see in Table <ref type="table" coords="4,342.14,556.84,3.58,9.41">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">CONCLUSIONS</head><p>Our focus this year was on the efficiency track. Telling from the statistics posted by the TREC organizers, our runs performed very well. Our slowest (single-processor) run was the median of all runs and our fastest run (processing 4 streams, but with only two processors, average query time: 0.028 sec) was close to the best run (average query time: 0.0125 sec). In all our experiments, most of the data was read from disk (as opposed to from main memory). The run P@20 bpref map infAP mpiirtitle 0.4270 0.2849 0.1805 0.1678 mpiirdesc 0.4240 0.2968 0.1743 0.1471 mpiircomb 0.5020 0.3146 0.2174 0.1876 mpiirmanual 0.4810 0.3041 0.1981 0.1692 Table <ref type="table" coords="5,84.27,130.81,4.12,9.41">3</ref>: Performances of runs in the adhoc task by P@20, bpref, map and infAP measures, averaged over topics 801-850. precisions of our runs were decent, but could be improved by more advanced scoring models, without compromising efficiency.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,333.46,384.86,205.75,9.41;2,348.76,192.09,175.19,179.30"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Top-k and candidate bookkeeping.</figDesc><graphic coords="2,348.76,192.09,175.19,179.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,316.81,96.71,239.01,181.28"><head>Table 2 :</head><label>2</label><figDesc>1 in Table2. Performances of runs in the efficiency task: the number of CPUs used, average running time per query and precision at top-20 for our runs. The median of the average running time taken over all 25 submitted runs by all groups turns out to be exactly the same as our slowest run (0.152 sec).</figDesc><table coords="4,334.82,118.45,203.06,75.56"><row><cell></cell><cell></cell><cell>avg</cell><cell>P@20</cell><cell>P@20</cell></row><row><cell>run</cell><cell>#cpu</cell><cell>query</cell><cell>topics</cell><cell>topics</cell></row><row><cell></cell><cell></cell><cell cols="3">time 751-800 801-850</cell></row><row><cell>mpiiotopk</cell><cell>1</cell><cell>0.152</cell><cell>0.5110</cell><cell>0.4280</cell></row><row><cell>mpiiotopkpar</cell><cell>2</cell><cell>0.074</cell><cell>0.5110</cell><cell>0.4280</cell></row><row><cell>mpiiotopk2</cell><cell>1</cell><cell>0.057</cell><cell>0.4820</cell><cell>0.4330</cell></row><row><cell>mpiiotopk2p</cell><cell>2</cell><cell>0.028</cell><cell>0.4820</cell><cell>0.4330</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,321.42,682.80,234.40,9.41;4,316.81,691.76,239.00,9.41;4,316.81,700.73,239.00,9.41;4,316.81,709.69,38.23,9.41"><p>Note that although our machine had two CPUs, for the runs mpiiotopk and mpiiotopk2, a single program processed 100,000 queries sequentially, so we write that only one CPU was used.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,72.62,239.36,220.18,9.41;5,72.62,249.81,206.92,9.41;5,72.62,260.28,199.76,9.41" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,124.11,249.81,155.43,9.41;5,72.62,260.28,65.49,9.41">Io-top-k: Index-access optimized top-k query processing</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Bast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schenkel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Theobald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,156.72,260.28,22.88,9.41">VLDB</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="475" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,271.73,213.41,9.41;5,72.62,282.19,211.91,9.41;5,72.62,292.66,149.82,9.41" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,216.15,271.73,69.88,9.41;5,72.62,282.19,196.59,9.41">Minimal probing: supporting expensive predicates for top-k queries</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S.-W</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,72.62,292.66,58.48,9.41">SIGMOD 2002</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="346" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,304.11,174.65,9.41;5,72.62,314.57,206.16,9.41;5,72.62,325.03,125.65,9.41" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,214.01,304.11,33.26,9.41;5,72.62,314.57,153.36,9.41">Optimal aggregation algorithms for middleware</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lotem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,233.52,314.57,45.27,9.41;5,72.62,325.03,36.66,9.41">J. Comput. Syst. Sci</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="614" to="656" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,336.49,211.65,9.41;5,72.62,346.95,187.49,9.41;5,72.62,357.41,205.76,9.41" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,250.66,336.49,33.61,9.41;5,72.62,346.95,187.49,9.41;5,72.62,357.41,51.80,9.41">Towards efficient multi-feature queries in heterogeneous environments</title>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Güntzer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W.-T</forename><surname>Balke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kießling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,143.35,357.41,23.30,9.41">ITCC</title>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="page" from="622" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,368.87,218.28,9.41;5,72.62,379.33,183.85,9.41;5,72.62,389.79,58.85,9.41" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,136.53,368.87,154.37,9.41;5,72.62,379.33,91.03,9.41">Space-limited ranked query evaluation using adaptive pruning</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Lester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,182.51,379.33,44.55,9.41">WISE 2005</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="470" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,401.25,202.39,9.41;5,72.62,411.71,200.83,9.41;5,72.62,422.17,175.53,9.41" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,231.64,401.25,43.37,9.41;5,72.62,411.71,172.09,9.41">Evaluating top-k queries over web-accessible databases</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Marian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Bruno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gravano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,252.01,411.71,21.44,9.41;5,72.62,422.17,86.43,9.41">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="319" to="362" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,433.63,218.23,9.41;5,72.62,444.09,168.92,9.41;5,72.62,454.55,82.39,9.41" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,171.00,433.63,119.85,9.41;5,72.62,444.09,68.95,9.41">Self-indexing inverted files for fast text retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,148.23,444.09,89.66,9.41">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="349" to="379" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,466.00,209.65,9.41;5,72.62,476.47,198.17,9.41;5,72.62,486.93,99.21,9.41" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,213.03,466.00,69.24,9.41;5,72.62,476.47,156.03,9.41">Query processing issues in image (multimedia) databases</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Nepal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">V</forename><surname>Ramakrishna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,247.47,476.47,23.32,9.41;5,72.62,486.93,17.10,9.41">ICDE 1999</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="22" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,498.38,215.36,9.41;5,72.62,508.85,170.87,9.41;5,72.62,519.31,207.78,9.41;5,72.62,529.77,212.63,9.41;5,72.62,540.23,86.78,9.41" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,202.18,498.38,85.80,9.41;5,72.62,508.85,170.87,9.41;5,72.62,519.31,123.22,9.41">Some simple effective approximations to the 2-poisson model for probabilistic weighted retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,193.59,529.77,23.89,9.41">SIGIR</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM/Springer</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,551.69,203.12,9.41;5,72.62,562.15,200.52,9.41;5,72.62,572.60,137.76,9.41" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,252.18,551.69,23.56,9.41;5,72.62,562.15,184.89,9.41">Top-k query evaluation with probabilistic guarantees</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Theobald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schenkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,72.62,572.60,46.43,9.41">VLDB 2004</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="648" to="659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,584.07,203.49,9.41;5,72.62,594.52,217.13,9.41;5,72.62,604.98,187.70,9.41" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="5,236.83,584.07,39.29,9.41;5,72.62,594.52,217.13,9.41;5,72.62,604.98,26.20,9.41">Managing Gigabytes: Compressing and Indexing Documents and Images</title>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">C</forename><surname>Bell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
