<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,177.54,79.00,256.85,16.72;1,88.62,105.76,434.73,16.72">The Splog Detection Task and A Solution Based on Temporal and Link Properties</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,142.86,136.07,47.28,10.46"><forename type="first">Yu-Ru</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NEC Laboratories America</orgName>
								<address>
									<addrLine>10080 N. Wolfe Road -Suite</addrLine>
									<postCode>SW3-350, 95014</postCode>
									<settlement>Cupertino</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,197.90,136.07,69.02,10.46"><forename type="first">Wen-Yen</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NEC Laboratories America</orgName>
								<address>
									<addrLine>10080 N. Wolfe Road -Suite</addrLine>
									<postCode>SW3-350, 95014</postCode>
									<settlement>Cupertino</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,275.60,136.07,52.13,10.46"><forename type="first">Xiaolin</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NEC Laboratories America</orgName>
								<address>
									<addrLine>10080 N. Wolfe Road -Suite</addrLine>
									<postCode>SW3-350, 95014</postCode>
									<settlement>Cupertino</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,335.31,136.07,55.45,10.46"><forename type="first">Richard</forename><surname>Sia</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NEC Laboratories America</orgName>
								<address>
									<addrLine>10080 N. Wolfe Road -Suite</addrLine>
									<postCode>SW3-350, 95014</postCode>
									<settlement>Cupertino</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,398.35,136.07,65.31,10.46"><forename type="first">Xiaodan</forename><surname>Song</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NEC Laboratories America</orgName>
								<address>
									<addrLine>10080 N. Wolfe Road -Suite</addrLine>
									<postCode>SW3-350, 95014</postCode>
									<settlement>Cupertino</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,142.44,152.93,36.94,10.46"><forename type="first">Yun</forename><surname>Chi</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NEC Laboratories America</orgName>
								<address>
									<addrLine>10080 N. Wolfe Road -Suite</addrLine>
									<postCode>SW3-350, 95014</postCode>
									<settlement>Cupertino</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,187.47,152.93,45.29,10.46"><forename type="first">Koji</forename><surname>Hino</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NEC Laboratories America</orgName>
								<address>
									<addrLine>10080 N. Wolfe Road -Suite</addrLine>
									<postCode>SW3-350, 95014</postCode>
									<settlement>Cupertino</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,241.17,152.93,72.21,10.46"><forename type="first">Hari</forename><surname>Sundaram</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NEC Laboratories America</orgName>
								<address>
									<addrLine>10080 N. Wolfe Road -Suite</addrLine>
									<postCode>SW3-350, 95014</postCode>
									<settlement>Cupertino</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,322.20,152.93,67.02,10.46"><forename type="first">Jun</forename><surname>Tatemura</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NEC Laboratories America</orgName>
								<address>
									<addrLine>10080 N. Wolfe Road -Suite</addrLine>
									<postCode>SW3-350, 95014</postCode>
									<settlement>Cupertino</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,413.23,152.93,56.35,10.46"><forename type="first">Belle</forename><surname>Tseng</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NEC Laboratories America</orgName>
								<address>
									<addrLine>10080 N. Wolfe Road -Suite</addrLine>
									<postCode>SW3-350, 95014</postCode>
									<settlement>Cupertino</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,177.54,79.00,256.85,16.72;1,88.62,105.76,434.73,16.72">The Splog Detection Task and A Solution Based on Temporal and Link Properties</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FAA5E40411FFF145456C1815EAC4317A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Spam blogs (splogs) have become a major problem in the increasingly popular blogosphere. Splogs are detrimental in that they corrupt the quality of information retrieved and they waste tremendous network and storage resources. We study several research issues in splog detection. First, in comparison to web spam and email spam, we identify some unique characteristics of splog. Second, we propose a new online task that captures the unique characteristics of splog, in addition to tasks based on the traditional IR evaluation framework. The new task introduces a novel time-sensitive detection evaluation to indicate how quickly a detector can identify splogs. Third, we propose a splog detection algorithm that combines traditional content features with temporal and link regularity features that are unique to blogs. Finally, we develop an annotation tool to generate ground truth on a sampled subset of the TREC-Blog dataset. We conducted experiments on both offline (traditional splog detection) and our proposed online splog detection task. Experiments based on the annotated ground truth set show excellent results on both offline and online splog detection tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The blogosphere is growing extremely fast and provides new business opportunities in areas such as advertisement, opinion extraction, and marketing. However, spam blogs (splogs) have become a major problem in the blogosphere-they reduce the quality of information retrieval results and waste network and storage resources <ref type="bibr" coords="1,54.00,442.62,11.83,9.57" target="#b7">[5,</ref><ref type="bibr" coords="1,65.83,442.62,7.89,9.57">8]</ref>. Therefore, detecting splogs in the blogosphere has great importance.</p><p>In this paper, we propose our solution to detect splogs in the blogosphere. The main contributions of our work are as follows:</p><p>1. Modeling the splog problem: Unlike web or email spam, a splog is dynamic since it continuously generates fresh content to drive traffic. To solve the splog problem, we need to take advantage of the unique splog properties.</p><p>2. Evaluation: Splogs are characterized by temporal content dynamics and hence need to be identified as quickly as possible before they waste network and storage resources. We propose a time-sensitive evaluation framework to measure splog detection performance based on how fast the detection is made.</p><p>3. Regularity based Detection: Our detection algorithm identifies unique features such as temporal and link properties useful for detecting splogs. We identify temporal content regularity (self-similarity of content) and temporal structural regularity (regular post times) as well as regularity in the linking structure (frequent links to non-authoritative websites).</p><p>We have evaluated our approach using the traditional offline task, as well as our proposed online metrics. The results are excellent indicating the combined feature set works well in both offline and online splog detection tasks. The online task reveals the sensitivity of the detection to the amount of evidence (posts) as well as the complimentary roles played by content and splog regularity features.</p><p>Most of previous work in spam detection comes from web spam detection. Prior work to detect web spams can be further categorized into content analysis <ref type="bibr" coords="2,234.18,87.78,12.64,9.57" target="#b8">[6,</ref><ref type="bibr" coords="2,246.82,87.78,8.43,9.57" target="#b9">7]</ref> and link analysis <ref type="bibr" coords="2,335.37,87.78,11.84,9.57">[2,</ref><ref type="bibr" coords="2,347.22,87.78,7.90,9.57" target="#b5">3]</ref>. Our work combines traditional features with temporal and link features that are unique to blogs.</p><p>The rest of this paper is organized as follows. In the next section we provide a high-level definition of splogs; we shall also discuss splog characteristics and how splog differ from web sites. In section 3, we provide the online task definition and also provide a baseline offline splog detection task. In section 4, we present out splog detection framework and we discuss our proposed regularity (temporal and link) based features. In section 5, we discuss data pre-processing and our annotation tool to label data. In section 6, we present out experimental results and we present our conclusions in section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">WHAT ARE SPLOGS?</head><p>In this section, we provide a high-level definition of splogs and the splog problem we face today (Section 2.1), the typical splog characteristics (Section 2.2), and the differences between splog and other types of spam (Section 2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Working definition of splogs</head><p>Spam blogs, which are called splogs, are undesirable weblogs that the creators use solely for promoting affiliated sites <ref type="bibr" coords="2,78.93,295.56,11.58,9.57">[1]</ref>. As blogs became increasingly mainstream, the presence of splogs has a detrimental effect in the blogosphere. According to multiple reports, the following are alarming statistics.</p><p>10-20% of blogs are splogs. For the week of Oct. 24, 2005, 2.7 million blogs out of 20.3 million are splogs <ref type="bibr" coords="2,120.90,340.74,11.55,9.57">[8]</ref>.</p><p>An average of 44 of the top 100 blogs search results in the three popular blog search engines came from splogs <ref type="bibr" coords="2,120.90,373.20,11.55,9.57">[8]</ref>.</p><p>75% of new pings came from splogs; more than 50% of claimed blogs pinging weblogs.com are splogs <ref type="bibr" coords="2,90.00,405.66,11.55,9.57" target="#b7">[5]</ref>.</p><p>The statistics exhibit serious problems caused by splogs, including (1) the degradation of information retrieval quality and (2) the tremendous waste of network and storage resources. Figure <ref type="figure" coords="3,86.07,75.06,5.49,9.57" target="#fig_0">1</ref> illustrates the overall scheme taken by splog creators. Their motive is to drive visitors to affiliated sites (including the splog itself) that have some profitable mechanisms. By profitable mechanism, we refer to webbased business methods, such as search engine advertising programs (e.g. Google AdSense) or pay-per-click (ppc) affiliate programs. There are several schemes used by spammers to increase the visibility of splogs by getting indexed with high ranks on popular search engines. To deceive the search engine, the spammer may boost (1) relevancy (e.g. via keyword stuffing), ( <ref type="formula" coords="3,230.47,138.66,4.27,9.57">2</ref>) popularity (e.g. via link farm), or (3) recency (e.g. via frequent posts), based on some ranking criteria used by search engines. The increased visibility is unjustifiable since the content in splogs is often nonsense or stolen from other sites <ref type="bibr" coords="3,311.80,164.10,11.55,9.57">[1]</ref>. The spammer also attacks regular blogs through comments and trackbacks to boost the splog ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Typical splog characteristics</head><p>In a typical splog, content is usually generated by machines in order to attract visitors through their appearance in either search engines or individual blogs. By splog, we refer to a blog created by an author who has the intention of spamming. Note that a blog that may contain spam in the form of comment spam or trackback spam is not considered a splog.</p><p>There are typical characteristics observed in splogs:</p><p>1. Machine-generated content: splog entries are generated automatically, usually nonsense, gibberish, repetitive or copied from other blogs or websites.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>No value-addition: splogs provide useless or no unique information to their readers. There are blogs using automatic content aggregating techniques to provide useful service such as podcasting-these are legitimate blogs because of their value addition.</p><p>3. Hidden agenda, usually an economic goal: splogs have commercial intention that can be revealed if we observe any affiliate ads or out-going links to affiliate sites. Some of these characteristics, such as no value-addition or hidden agenda, can also be found in other types of spams (e.g. web spam). However, splogs have unique properties that will be highlighted in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Uniqueness of splogs</head><p>Splogs are different from web spams in the following aspects.</p><p>1. Dynamic content: blog readers are mostly interested in recent entries. Unlike web spams where the content is static, a splog continuously generates fresh content to drive traffic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Non-endorsement link:</head><p>A hyperlink is often interpreted as an endorsement of other pages. It is less likely that a web spam gets endorsements from normal sites. However, since spammers can create hyperlinks (comment links or trackbacks) in normal blogs, links in blogs cannot be simply treated as endorsements.</p><p>Because of these two significant differences, the splog problem is different from that of traditional web spam as discussed next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">TASK DEFINITION</head><p>In this section we propose our evaluation methodology for comparing splog detection techniques on TREC blog dataset. We first describe the detection task framework in Section 3.1. Next, two detection tasks used in traditional information retrieval are given in Section 3.2. In Section 3.3 we propose an online detection task with novel assessment method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Framework for detection task</head><p>The objective of a splog detector is to remove unwanted blogs. Blog search engines need splog detectors to improve the quality of their search results. Blog search engines differ from general web search engines in their growing contents -namely feeds. The detection decision is performed on a blog that consists of a growing list of entries. Because entries become available gradually, there can be time delay to gather enough evidences (i.e., entries) for detection. Since a splog will persist in the index until it is detected, earlier detection with few evidences is crucial for the overall search quality. We refer a detector that can make a decision with less evidence fast.</p><p>An illustration of how early splog detection is beneficial is shown in Figure <ref type="figure" coords="4,411.26,120.24,4.12,9.57" target="#fig_1">2</ref>. The grid represents how the amount of entries (x-axis) increases over time for each blog (y-axis). For a specific time, the gray area denoted by "downloaded in the storage" shows the number of blogs discovered with the corresponding amount of entries. As time passes, more blogs are indexed as well as growing amounts of entries, as shown by the dashed border and arrows.</p><p>…... The target objective for blog search engines is to detect splogs as early as possible. As a result, we need to measure the speed of splog detection. Traditional detectors are evaluated offline, where a batch of data is inputted into the detector and some performance metrics are calculated on the detection results. Because we want to also evaluate the speed of splog detection, we propose an online detection evaluation. Another aspect of evaluation depends on the availability of ground truth information. Both offline and online detection can be evaluated with or without ground truth. Accordingly, there are four tasks as identified in Table <ref type="table" coords="4,405.96,560.22,4.12,9.57">1</ref>.</p><note type="other">time</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1: Four detection tasks are identified based on Offline and Online detections.</head><p>Dataset \ Task Type Offline </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Traditional IR-based detection</head><p>To compare different detection methods, there are two evaluation frameworks used in traditional information retrieval research and also widely applied in many TREC tracks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Evaluation with ground truth</head><p>Evaluation is designed to compare detectors for an input set of blogs. Given a set of input blogs B with labels, the detectors can be evaluated by k-fold cross-validation, where the performance can be measured by metrics such as precision/recall, AUC, or ROC plot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Evaluation without ground truth</head><p>To evaluate detector performances on a large dataset, there will be limited amount of labeled ground truth. Each detector makes its decision on the large dataset, and returns the detection results as a ranked list. The detector performance is evaluated by measuring the precision at top N (precision@N) of the ranked list based on pooling of multiple detection lists.</p><p>Based on the availability of ground truth, splog detectors can be compared using one of the above offline evaluations. However to measure the speed of detection efficiency, we propose an online detection framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Online detection</head><p>As discussed above, the benefit of early splog detection is to quickly remove entries by splogs from the search index. Hence, we propose a new framework to evaluate time-sensitive detection performance.</p><p>We want to measure the detection performance on newly discovered blogs and observe how the decisions on these blogs can improve as more entries are available. First, blogs in the dataset are partitioned based on the time of discovery (i.e., the first appearance in the dataset). We assume the splog detector evaluates the blog contents at uniform frequency, i.e. t 0 = t, t 1 = t+∆t, …, t k =t+k∆t. B(t i ) is defined as a partition that consists of blogs discovered after time t i-1 and before t i . B(t 0 ) is the initial training set, usually given with labels (splog or nonsplog). For each partition B(t k ) (k &gt; 0), the detector gives a decision at time t j (j &gt;= k), for which the performance p jk is measured. p jk is the detection performance at time t j on the partition at t k (B(t k )). In order to measure the speed of detection, we are interested in how the detector performance p jk improves as j increases. Then, we introduce an overall performance measure of all decisions made with a specific delay. More specifically, for each delay i = jk, the overall performance P i is given as an average, where</p><formula xml:id="formula_0" coords="5,320.64,674.82,70.13,10.22">P i =E[p jk | i=j-k].</formula><p>The performance is plotted with i on the x-axis as shown in Figure <ref type="figure" coords="5,191.45,687.54,4.12,9.57" target="#fig_3">3</ref>, to demonstrate how quickly the detector can make a good decision. Note that each performance p jk is measured based on the same evaluation metrics as the traditional offline evaluations. We expect the proposed online evaluation to provide significant insights on early detection of splogs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">OUR DETECTION METHOD</head><p>We have developed new techniques for splog detection based on temporal and linking patterns, which are unique features that distinguish blogs from regular web pages.</p><p>Due to the special characteristics of splogs, traditional content-based or link-based spam detection techniques are not sufficient. It is difficult to detect spams for individual pages (i.e., entries) by content-based techniques, since a splog can steal (copy) content from normal blogs. Link-based techniques based on propagation of trust from legitimate sites will work poorly for blogs since spammers can create links (comments and trackbacks) from normal blogs to splogs.</p><p>Our observation is that a blog is a growing sequence of entries rather than individual pages. We expect that splogs can be recognized by their abnormal temporal and link patterns observed in entry sequences, since their motivation is different from normal, human-generated blogs. In a splog, the content and link structures are typically machine-generated (possibly copied from other blogs / websites). The link structure is focused on driving traffic to a specific set of affiliate websites. To capture such differences, we introduce new features, namely, temporal regularity and link regularity, which are described in the following subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baseline features</head><p>We shall now discuss the content based features used in this work -these will serve as the baseline feature set as they are widely used in splog detection. We use a subset of the content features presented in <ref type="bibr" coords="6,474.47,340.74,11.58,9.57" target="#b9">[7]</ref>. These features are used to distinguish between two classes of blogs -normal and splogs, based on the statistical properties of the content.</p><p>In this work we extract features from five different parts of a blog: (1) tokenized URLs, (2) blog and post titles, (3) anchor text, (4) blog homepage content and (5) post content. For each category we extract the following features: word count (w c ), average word length (w l ) and a vector containing the word frequency distribution (w f ). In this work, each content category is analyzed separately from the rest for computational efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">feature selection using Fisher linear discriminant analysis (LDA)</head><p>We need to reduce the length of the vector w f as the total number of unique terms (excluding words containing digits) is greater than 100,000 (this varies per category, and includes non-traditional usage such as "helloooo"). This can easily lead to over fitting the data. Secondly, the distribution of the words is long-tailed -i.e. most of the words are rarely used.</p><p>We expect good feature subsets contain features highly correlated with (predictive of) the class, but uncorrelated with each other. The objective of Fisher LDA is to enable us to determine discriminative features while preserving as much of the class discrimination as possible. The solution is to compute the optimal transformation of the feature space based on a criterion that minimizes the within-class scatter (of the data set) and maximizes the between-class scatter simultaneously. This criterion can also be used as a separability measure for feature selection. We use the trace criteria, J = tr(S w -1 S b ) where S w denotes the within-class scatter and S b denotes the between-class scatter matrix. This criterion computes the ratio of between-class variance to the within-class variance in terms of the trace of the product (the trace is just the sum of eigenvalues of S w -1 S b ). We select the top k eigenvalues to determine the key dimensions of the w f vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Temporal regularity</head><p>Temporal regularity captures consistency in timing of content creation (structural regularity), and similarity between contents (content regularity). Content regularity is given by the autocorrelation of the content, derived from computing a similarity measure on the baseline content feature vectors. We define a similarity measure based on the histogram intersection distance. Structural regularity is given by the entropy of the post time difference distribution. A splog will have low entropy, indicating machine generated content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Temporal Content Regularity (TCR):</head><p>We use the autocorrelation of the content to estimate the TCR value. Intuitively, the autocorrelation function (conventionally depicted as R(τ)) of a time series is an estimate of how a future sample is dependent on a current sample. A noise like signal will have a sharp auto-correlation function, while a highly coherent signal's autocorrelation function will fall off gradually. Since splogs are usually finally motivated, we conjecture that their content will be highly similar over time. However human bloggers will tend to post over a diverse set of topics, leading to a sharper autocorrelation function. We define TCR as a self-similarity measure of content and compute it by auto-correlation. We compute the discrete time autocorrelation function R(k) for the posts. The posts are time difference normalized -i.e. we are only interested in the similarity between the current post and a future post in terms of the number of posts in between (e.g. will the post after next be related to the current post), ignoring time. This is a simplifying assumption, but is useful when many posts do not have the time meta data associated with them. The autocorrelation function is defined as follows:</p><p>( ) 1 ( ( ), (</p><p>)),</p><formula xml:id="formula_1" coords="7,205.86,600.27,200.27,53.92">( ) ( ) ( ( ), ( )) 1 , ( ) ( ) f f f f R k d p l p l k w l w l k d p l p l k E w l w l k = - + ⎛ ⎞ ∩ + ⎜ ⎟ + -⎜ ⎟ ∪ + ⎝ ⎠</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;1&gt;</head><p>Where E is the expectation operator, R(k) is the expected value of the autocorrelation between the current l th post and the (l+k) th post; d is the dissimilarity measure, | | is the cardinality operator, and ∪, ∩ refer to the familiar union and intersection operators. We use the autocorrelation vector R(k) as a feature to discriminate between splogs and normal blogs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Temporal Structural Regularity (TSR):</head><p>We estimate TSR of a blog by computing the entropy of the post time difference distribution. In order to estimate the distribution, we use hierarchical clustering on the post time difference values from a blog.  The temporal structure of post time interval can be discovered by clustering close post intervals. We use hierarchical clustering method with single link merge criteria on the post interval difference values. The original dataset is initialized into N clusters for N data points. Two clusters are merged into one if the distance (linkage) between the two is the smallest amongst all pair wise cluster distances. We use the average variance stopping criteria for clustering. Once the clusters are determined, we compute cluster entropy as a measure of TSR:</p><formula xml:id="formula_2" coords="8,238.68,561.86,319.33,59.80">1 max log , , 1 , M i e i i i i e n B p p p N B TSR B = = - = = - ∑ &lt;2&gt;</formula><p>where B e is the blog entropy, B max is the maximum observed entropy, N is the total number of posts, n i and p i are the number of posts and the probability of the i th cluster respectively, and M is the number of clusters. Note that for some blogs including normal or splogs, post time is not available as part of the post metadata. We treat such cases as missing data. And if a blog does not have post time information, we do not use TSR as a feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Link regularity estimation</head><p>Link regularity (LR) measures consistency in target websites pointed by a blog. We expect that a splog will exhibit more consistent behavior since the main intent of such splogs is to drive traffic to affiliate websites. Secondly we conjecture that there will be a significant portion of links that will be targeted to affiliated websites rather than normal blogs / websites. Importantly these affiliate websites will not be authoritative and we do not expect normal bloggers to link to such websites.</p><p>We analyze the splog linking behavior using the HITS algorithm <ref type="bibr" coords="9,349.07,162.70,11.56,9.60" target="#b6">[4]</ref>. The intuition is that splogs target focused set of websites, while normal blogs usually have more diverse targeting websites. We use HITS with out-link normalization to compute hub scores. The normalized hub score for a blog is a useful indicator of the blog being a splog. We put blogs and their linking websites on two sides of a bi-partite graph to construct an adjacency matrix A, where A ij =1 indicates there is a hyperlink from blog b i to website w j . In the original HITS algorithm, good hubs and good authorities are identified by the mutually reinforcing relationship: a=A T h, h=Aa, where a is the authority score, h is the hub score and A is the adjacency matrix. A blog with divergent out-links to authoritative websites will obtain a higher hub score. To suppress this effect and on the other side reinforce the influence of blogs with focused targets, we normalize A by out-degrees of blogs and then compute hub scores for blogs as LR.</p><p>Our splog detector combines these new features (TCR, TSR, LR) with traditional content features into a large feature vector. We then use standard machine learning techniques (SVM classifier with a radial basis function kernel) to classify each blog into two classes: splog or normal blog.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">DATA-PREPROCESSING AND GROUND TRUTH DEFINITION</head><p>We have made significant efforts to pre-process the TREC-Blog dataset and to establish ground truth for training and testing. Our major contributions are summarized as follows: Through the interface as shown in Figure <ref type="figure" coords="10,257.64,471.70,4.13,9.60" target="#fig_8">7</ref>, an annotator can browse the blog homepage and entries that have been downloaded in the TREC-Blog dataset, or visit the blog site directly online, in order to assign one of the following five labels: (N) Normal, (S) Splog, (B) Borderline, (U) Undecided, and (F) Foreign Language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Disagreement among annotators:</head><p>We performed a pilot study to investigate how different annotators identify splogs. We presented a set of 60 blogs to a group of 6 annotators, asking them to assign each blog to one of the five labels. One interesting result is that the annotators have agreement on normal blogs but have varying opinions on splogs (S/B/U), which suggests that splog detection is not trivial even for humans. We plan to conduct further intensive user studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>Ground truth: As of August 24, 2006, we have labeled 9240 blogs by using our annotation tool. The 9240 blogs are selected using random sampling as well as stratified sampling methods. Among these 9240 blogs, 7905 are labeled as normal blogs, 525 are labeled as splogs, and the rest are borderline/undecided/foreign. The annotated splog percentage is lower than what has been reported because (1) some known splogs are prefiltered from the TREC dataset, and (2) we have selected to examine the 43.6K subset of blogs that have both homepages and entries downloaded.</p><p>Using the annotation tool to generate ground truth, we built a baseline splog detector and our detector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EXPERIMENTAL RESULTS</head><p>In this section, we present the annotation results. We manually labeled 7905 normal blogs and 525 splogs. We decided to create a symmetric set for evaluation containing 525 splogs and 525 normal blogs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Offline (Traditional)</head><p>In the traditional offline task, we used all the 1050 samples for evaluation. We used a five fold cross-validation technique to evaluate the performance of the splog detector. The results show that the proposed classifier and the new temporal and structural features work well together. In Table <ref type="table" coords="11,363.35,167.02,4.12,9.60" target="#tab_0">2</ref>, we summarize the results of the offline detection. The table shows the comparison between content features of different dimensionality against the combination of the same feature with the regularity features (TCR, TSR, LR). We use four measures -AUC (area under the ROC curve, also ref. Figure <ref type="figure" coords="11,230.86,205.18,3.97,9.60" target="#fig_9">8</ref>), accuracy, precision and recall. The results indicate that the proposed feature set combines well with the traditional content based features, however the largest gains occur when the dimensionality of the content features is low.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Online (Proposed)</head><p>In the online evaluation framework, we are interested in the rate understanding the temporal effects in the splog classifier performance. In order to do this we create a training set B 0 and testing sets B 1 -B 7 . In the TREC dataset the crawler discovers new blogs every day, but refreshes the feed only every week. Due to this refresh anomaly, we test the data "weekly" as there is no intermediate download available for the blogs. The training sets B 1 -B 7 refer to the blogs that were discovered on day i where 1 ≤i ≤7. We use 400 blogs for training (B 0 ), and 360 blogs for testing (B 1 -B 7 ). The remaining 290 blogs were discovered after the 1 st week and are not part of the testing set. We now introduce some notation for clarity:   The results for the online evaluation scheme are shown in Figure <ref type="figure" coords="13,357.41,679.12,9.17,9.60" target="#fig_11">10</ref>. They show the plot of P(i,i) against the weekly index i, with the metrics AUC (area under the ROC curve) and the accuracy metrics. The plot shows the result of testing the classifier on the data (testing sets B 1 -B 7 ) collected after the i th week, with the classifier being retrained on B 0 , with additional data for the set B 0 . They indicate that the utility of adding the structural regularity features in on-line detection. In the absence of enough content, these features play a critical role in discriminating between splogs and normal blogs.</p><formula xml:id="formula_3" coords="12,90.00,606.88,9.35,10.23">t 1 ,</formula><formula xml:id="formula_4" coords="13,199.50,143.57,278.79,207.96">B 0 B 0 B 2 B 3 B k B 1 B 2 B 3 B k t 1 t 2 B k B 1 B 2 B 3 B k t n … … … … … … … … P 1 P 2 P n G G G</formula><p>It is striking to compare the results as shown in Figure <ref type="figure" coords="14,297.77,120.22,11.00,9.60" target="#fig_11">10</ref> against the results for offline testing as shown in Table <ref type="table" coords="14,54.00,132.94,5.50,9.60" target="#tab_0">2</ref> and Figure <ref type="figure" coords="14,113.14,132.94,4.13,9.60" target="#fig_9">8</ref>. They indicate that the information provided by the structural information is complementary to the information in the content -this is evidenced by the jump in the AUC and the accuracy values for the corresponding week. Importantly the contribution to the results in the online case due to the regularity features is significant. Not only is there a clear improvement for classifiers C i, base-n+R over the corresponding classifiers C i, base-n for all weeks, but also the difference is high for the low dimensional features.</p><p>The explanation for the significant difference is as follows. In online tests when in the first week there is not enough content to train the classifier based on content analysis alone, and hence the regularity features become very important. Over time, the training data available to the classifier increases (i.e. the blogs in the training set B 0 have more entries over time) hence making the decision surface more stable. Additionally, we note that the content features that we have extracted are statistical in nature. Hence the feature vector corresponding to the content of both the training data and test data begin to stabilize only after a sufficient number of posts in each blog. Note also that over time the combination of both baseline and regularity features shows less fluctuation than the baseline features alone (ref. Figure <ref type="figure" coords="14,225.96,292.60,8.70,9.60" target="#fig_11">10</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUDING REMARKS</head><p>In this paper we analyze the splog detection problem as an important open task for TREC-Blog track. A splog is significantly different from web spam, and thus new online detection tasks are identified. The new task measures how quickly a detector can identify splogs -this is important as temporal dynamics are key distinguishing features of a blog from traditional web pages. We identify new features based on temporal content and structural regularity as well as link regularity. We also provide a set of ground truth labeled through our annotation tool. Our experimental results on both the offline and the online tasks are excellent and validate the importance of the both the proposed online task as well as the addition of regularity based features to traditional content features in such tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,54.00,653.22,504.08,9.57;2,54.00,666.12,503.99,9.57;2,54.00,679.02,75.12,9.57"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Splogs use different schemes to achieve spamming. "B" represents a blog, "S" represents a splog, and "W" refers to an affiliate site. There is usually a profitable mechanism (Ads/ppc) in the splog or affiliated site(s).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,54.00,451.14,503.96,9.57;4,54.00,464.04,503.96,9.57;4,54.00,476.94,300.96,9.57"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Blogs are discovered and downloaded over time. Similarly, the amount of entries downloaded grows over time. The gray area represents blog data that have been downloaded, and the dashed border and arrows show the downloading process continuing over time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,175.02,604.26,261.96,9.57"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Online time-sensitive evaluation performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="7,54.00,472.50,504.05,9.57;7,54.00,485.40,503.94,9.57;7,54.00,498.30,504.06,9.57;7,54.00,511.20,135.92,9.57"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The figure shows the difference in the autocorrelation function between a splog and a normal blog. Notice that auto-correlation function for a splog is very high and nearly constant, while the values for a normal blog are relatively low and fluctuate. These graphs have been derived from a splog and a normal blog from the TREC dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="8,131.22,252.32,5.43,9.06;8,201.72,252.32,10.71,9.06;8,275.22,252.32,10.65,9.06;8,348.72,252.32,10.65,9.06;8,422.22,252.32,10.65,9.06;8,496.44,252.32,10.65,9.06;8,125.22,244.04,5.43,9.06;8,125.22,216.32,5.43,9.06;8,120.00,189.32,10.65,9.06;8,120.00,161.54,10.65,9.06;8,120.00,134.54,10.65,9.06;8,263.22,265.04,105.96,9.06;8,104.78,206.63,9.06,13.21;8,104.78,195.41,9.06,7.93;8,104.78,168.46,9.06,23.66;8,242.22,123.32,150.13,9.06;8,131.22,409.04,5.43,9.06;8,177.00,409.04,5.43,9.06;8,222.72,409.04,5.43,9.06;8,269.22,409.04,5.43,9.06;8,314.94,409.04,5.43,9.06;8,360.72,409.04,5.43,9.06;8,407.22,409.04,5.43,9.06;8,452.94,409.04,5.43,9.06;8,499.44,409.04,5.43,9.06;8,125.22,400.76,5.43,9.06;8,125.22,373.04,5.43,9.06;8,120.00,346.04,10.65,9.06;8,120.00,319.04,10.65,9.06;8,120.00,292.04,10.65,9.06;8,269.94,421.76,92.52,9.06;8,104.78,363.35,9.06,13.21;8,104.78,352.13,9.06,7.93;8,104.78,325.18,9.06,23.66;8,228.72,280.76,177.13,9.06"><head></head><label></label><figDesc>posts post interval distribution for a normal blog</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="8,54.00,445.44,503.98,9.57;8,54.00,458.34,504.03,9.57;8,54.00,471.24,211.14,9.57"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The figure shows the differences in the temporal regularity between a splog and a normal blog. A splog posts with a post time of 20 minutes, while a normal blog has post time interval that is highly varied and ranges to several hours to nearly a week.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="9,54.00,480.78,504.00,9.57;9,54.00,493.68,503.99,9.57;9,54.00,506.58,291.66,9.57"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Normal blogs tend to link to authoritative websites while splogs frequently link to affiliate websites that are not authorities. The thickness of the arrow from the splog indicates the frequency with which the splog links to an non-authoritative, affiliate website.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="10,173.82,452.04,264.30,9.57"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Splog Annotation Tool to view and label blogs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9" coords="12,54.00,460.44,503.94,9.57;12,54.00,473.34,212.71,9.57"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: The plot of the ROC curves for different values of the baseline feature size, base-n + R as well as the ROC curve due to the new features alone.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10" coords="13,54.00,370.62,381.47,9.57;13,435.54,374.71,3.51,6.12;13,442.62,370.62,115.40,9.57;13,54.00,383.52,102.54,9.57;13,156.54,387.61,3.51,6.12;13,160.08,383.52,10.98,9.57;13,171.06,387.61,3.51,6.12;13,174.60,383.52,383.44,9.57;13,88.57,396.42,193.96,9.57;13,282.54,400.51,3.51,6.12;13,286.08,396.42,10.98,9.57;13,297.06,400.51,3.51,6.12;13,300.60,396.42,257.34,9.57;13,54.00,406.74,179.81,12.15;13,233.82,406.74,158.03,12.80;13,391.86,406.93,6.24,6.12;13,400.86,409.32,26.54,9.57"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: The figure illustrates the online testing framework. The training set B 0 is partitioned weekly, as are the testing sets B 1 -B 7 . At the end of each week, the splog detector is re-trained to include the latest labeled data and is then tested on blogs B 1 -B 7 . The test blogs have additional downloaded entries for the latest week as well. The symbols P i refer to testing at the end of the i th week.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11" coords="13,54.00,633.66,503.92,9.57;13,54.00,646.56,503.92,9.57;13,54.00,659.46,184.70,9.57"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: The figures for the online experiments show impact of adding the structural features in the online evaluation. In the absence of content data, the regularity features provide a significant boost to the both the AUC and the accuracy results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="11,54.00,250.62,503.95,255.52"><head>Table 2 : The table shows a comparison of the baseline content scheme against the combination of baseline (designated as base-n, where n is the dimension of the baseline feature) with temporal and link-structure features (designated as R). The table indicates that the improvement due to the non-baseline features is smaller with increase in the number of dimensions to the baseline features.</head><label>2</label><figDesc></figDesc><table coords="11,171.18,310.74,263.06,195.40"><row><cell>Feature</cell><cell>AUC</cell><cell cols="2">accuracy precision</cell><cell>recall</cell></row><row><cell>base-253</cell><cell>0.966</cell><cell>0.915</cell><cell>0.923</cell><cell>0.907</cell></row><row><cell>R+base-253</cell><cell>0.974</cell><cell>0.919</cell><cell>0.918</cell><cell>0.920</cell></row><row><cell>base-127</cell><cell>0.957</cell><cell>0.893</cell><cell>0.899</cell><cell>0.886</cell></row><row><cell>R+base-127</cell><cell>0.968</cell><cell>0.925</cell><cell>0.931</cell><cell>0.918</cell></row><row><cell>base-64</cell><cell>0.938</cell><cell>0.874</cell><cell>0.885</cell><cell>0.861</cell></row><row><cell>R+base-64</cell><cell>0.948</cell><cell>0.908</cell><cell>0.918</cell><cell>0.895</cell></row><row><cell>base-32</cell><cell>0.895</cell><cell>0.834</cell><cell>0.837</cell><cell>0.831</cell></row><row><cell>R+base-32</cell><cell>0.921</cell><cell>0.870</cell><cell>0.883</cell><cell>0.851</cell></row><row><cell>R</cell><cell>0.814</cell><cell>0.696</cell><cell>0.860</cell><cell>0.469</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="12,90.00,606.88,468.07,108.39"><head></head><label></label><figDesc>(T r (t 1 ), T e (t 2 )) or P(t 1 , t 2 ): the performance of classifier trained on T r (t 1 ), i.e. C 1 and tested on T e (t 2 ), or P(t 1 , t 2 ). For example P(1, 3) denotes the performance of classifier C 1 trained on the 1 st week training set and tested on the 3 rd week testing set.</figDesc><table coords="12,90.00,606.88,468.03,75.30"><row><cell>Training set</cell><cell>B 0</cell></row><row><cell cols="2">t 2 , …, t n : testing period, week 1, 2, …, 7. T r (t) denotes the training set blog B 0 data downloaded until time t. T r (1) would denote the data for the blogs corresponding the end of week 1. T e (t): denotes the training set blog (B 1 , B 2 , …, B 7 which are discovered in week 1) data downloaded until Testing time t. Note that T B 1 set</cell></row></table><note coords="12,170.88,676.69,2.73,6.12;12,173.64,671.55,15.18,11.00;12,188.82,676.69,3.12,6.12;12,191.94,671.55,17.33,11.00;12,90.00,692.32,17.70,9.60;12,107.70,696.43,2.73,6.12;12,110.46,692.32,38.59,9.60;12,149.04,696.43,1.95,6.12;12,151.02,692.32,116.10,9.60;12,267.06,696.43,2.73,6.12;12,269.82,692.32,24.56,9.60;12,294.36,696.43,7.62,6.12;12,306.06,692.32,252.01,9.60;12,90.00,705.04,47.22,9.60;12,137.22,709.15,35.29,6.12;12,175.26,705.04,102.29,9.60;12,277.50,709.15,3.51,6.12;12,283.80,705.04,270.64,9.60;13,90.00,75.04,5.50,9.60"><p>r ∩T e = φ. C(T r (t)) or C t : a classifier trained on T r (t). C t,F denotes the classifier is trained using feature set F. For example C 1, base32+R denotes the classifier C 1 using feature set base32+R and where R = &lt;TCR, TSR, LR&gt;. P</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="10,59.28,711.94,215.74,7.85"><p>http://www.public.asu.edu/~ylin56/project/splog_detection/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,58.14,75.28,502.65,9.60;10,72.00,88.00,486.00,9.60;10,72.00,100.72,486.03,9.60;10,72.00,113.44,144.23,9.60" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="10,72.00,75.28,483.68,9.60;10,191.76,88.00,366.24,9.60;10,72.00,100.72,486.03,9.60;10,72.00,113.44,139.99,9.60">totaling 77 days. After removing duplicate feeds and feeds without homepage or permalinks, we have about 43.6K unique blogs. We focus our analysis on this subset of blogs having homepage and at least one entry</title>
		<imprint>
			<date type="published" when="2005-02-21">2005 to Feb. 21, 2006</date>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
	<note>Pre-processing: The TREC-Blog 2006 dataset is a crawl of 100,649 feeds collected over 11 weeks, from Dec</note>
</biblStruct>

<biblStruct coords="10,58.13,132.40,499.83,9.60;10,72.00,145.12,338.18,9.60;10,410.16,144.38,3.00,5.23;10,413.16,145.12,144.87,9.60;10,72.00,157.84,438.49,9.60" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="10,72.00,132.40,485.96,9.60;10,72.00,145.12,338.18,9.60;10,410.16,144.38,3.00,5.23;10,413.16,145.12,52.46,9.60">Annotation tool: We have developed a user-friendly interface (Figure 7) for annotators to label the TREC-Blog dataset. The detailed description of the tool is available at our webpage 1 . Essentially</title>
		<imprint/>
	</monogr>
	<note>in the interface, the content of the blogs and their contents are fetched from the database and presented to the annotator</note>
</biblStruct>

<biblStruct coords="14,58.50,438.71,92.18,10.46" xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,76.98,463.60,254.21,9.60" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><surname>Wikipedia</surname></persName>
		</author>
		<ptr target="http://en.wikipedia.org/wiki/Splog" />
		<title level="m" coord="14,127.13,463.60,46.83,9.60">Spam blog</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,76.98,479.32,472.57,9.60;14,76.98,492.04,451.83,9.60" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Gyöngyi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Berkhin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hector</forename><surname>Garcia-Molina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pedersen</surname></persName>
		</author>
		<title level="m" coord="14,427.56,479.32,121.99,9.60;14,76.98,492.04,383.26,9.60">Link Spam Detection Based on Mass Estimation, 32nd International Conference on Very Large Data Bases (VLDB)</title>
		<meeting><address><addrLine>Seoul, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,76.98,507.76,434.33,9.60;14,76.98,520.48,446.81,9.60;14,76.98,533.20,35.72,9.60" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="14,342.84,507.76,163.62,9.60">Combating web spam with TrustRank</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Gyöngyi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Garcia-Molina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,76.98,520.48,375.62,9.60">Proceedings of the 30th International Conference on Very Large Data Bases (VLDB)</title>
		<meeting>the 30th International Conference on Very Large Data Bases (VLDB)<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,77.00,549.16,452.91,9.60" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="14,191.22,549.16,224.40,9.60">Authoritative sources in a hyperlinked environment</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,423.12,549.16,34.83,9.60">J. ACM</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="604" to="632" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,76.98,564.88,433.69,9.60;14,76.98,577.60,480.71,9.60" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="14,158.46,564.88,347.45,9.60">Welcome to the Splogosphere: 75% of new pings are spings (splogs) permalink</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kolari</surname></persName>
		</author>
		<ptr target="http://ebiquity.umbc.edu/blogger/2005/12/15/welcome-to-the-splogosphere-75-of-new-blog-posts-are-spam/" />
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,76.98,593.32,471.40,9.60;14,76.98,606.04,471.42,9.60;14,76.98,618.76,57.19,9.60" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="14,353.04,593.32,195.34,9.60;14,76.98,606.04,41.06,9.60">Detecting Spam Blogs: A Machine Learning Approach</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kolari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Java</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Finin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Oates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,125.93,606.04,369.02,9.60">Proceedings of the 21st National Conference on Artificial Intelligence (AAAI 2006)</title>
		<meeting>the 21st National Conference on Artificial Intelligence (AAAI 2006)<address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-07">2006. July 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,77.00,634.48,452.13,9.60;14,76.98,647.20,441.59,9.60;14,76.98,659.92,93.37,9.60" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="14,373.80,634.48,155.32,9.60;14,76.98,647.20,69.66,9.60">Detecting spam web pages through content analysis</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ntoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Najork</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Manasse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fetterly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,153.71,647.20,308.43,9.60">Proceedings of the 15th International Conference on World Wide Web</title>
		<meeting>the 15th International Conference on World Wide Web<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-05">2006. May 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,76.98,675.64,464.51,9.60" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><surname>Umbria</surname></persName>
		</author>
		<ptr target="http://www.umbrialistens.com/files/uploads/umbria_splog.pdf" />
		<title level="m" coord="14,149.28,675.64,112.80,9.60">SPAM in the blogosphere</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
