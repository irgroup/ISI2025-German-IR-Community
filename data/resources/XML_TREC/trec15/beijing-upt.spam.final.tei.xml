<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,207.54,117.23,208.43,12.58">BUPT at TREC 2006: Spam Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,198.06,155.34,42.61,9.02"><forename type="first">Zhen</forename><surname>Yang</surname></persName>
							<email>yangzhen@pris.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Engineering</orgName>
								<orgName type="laboratory">PRIS Lab</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,248.07,155.34,29.12,9.02"><forename type="first">Weiran</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Engineering</orgName>
								<orgName type="laboratory">PRIS Lab</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Information Engineering</orgName>
								<orgName type="laboratory">PRIS Lab</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,284.66,155.34,33.18,9.02"><forename type="first">Bo</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Engineering</orgName>
								<orgName type="laboratory">PRIS Lab</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,391.62,155.34,33.79,9.02"><forename type="first">Jun</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Engineering</orgName>
								<orgName type="laboratory">PRIS Lab</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,207.54,117.23,208.43,12.58">BUPT at TREC 2006: Spam Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A7EF4C8EB7D88B78332600E3A694DB63</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This report summarizes our participation in the TREC 2006 spam track, in which we consider the use of Bayesian models for the spam filtering task. Firstly, our anti-spam filter, Kidult, is briefly introduced. And then we try to use weighted adjustment of separating hyperplane and selective classifiers ensemble to improve the filtering performance. Finally, we summarize the relevant results from the official evaluation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In 2005, a new track on spam filtering was introduced to TREC, whose goal was to provide a standard evaluation of current and proposed spam filtering approaches. "The 2006 track reprises the 2005 experiments with new filters and data, and also investigate delayed feedback and active learning. [1]" There are two tasks: 1. Online filtering -enhancement to TREC 2005 task; 2. Active learning -completely new task.</p><p>In this year, we focus on the online filtering task. For the pilot task, active learning, the only difference is that the "run.sh" is replaced by the active learning shell "active.cpp" with random selection in the jig. So the remainder of this paper is structured around online filtering task. Section 2 outlines an briefly overview of the "kidult" anti-spam framework. Some improvements are proposed in Section 3. In Section 4, we summarize the relevant results from the official evaluation. The major conclusions that can be drawn from the evaluation are presented in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Overview</head><p>The "kidult" is an anti-spam solution with self-dependence intellectual property, which is developed by Pris Lab of Beijing University of Posts and Telecommunications. The resulting technology of "kidult" has been successfully released in our TREC 2005 and TREC 2006 spam track system <ref type="bibr" coords="1,393.11,566.22,10.63,9.02" target="#b6">[2]</ref>.</p><p>The processing procedure of the "kidult" system is same as the general processing framework of TREC 2006 spam track. Our system uses Bayesian models for email classification. The Bayesian classifier is a probability based approach, which is often used in text classification applications and experiments for its simplicity and effectiveness. The following subsections describe our methods in greater detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preprocessing</head><p>Some common or often proposed initial transformations are: lookalike transformations, HTML deobfuscation, MIME normalization, character set folding, case folding, word stemming, stop words list, feature selection <ref type="bibr" coords="2,85.08,139.38,10.64,9.02" target="#b7">[3]</ref>. Discussed in our 2005 spam track report <ref type="bibr" coords="2,269.81,139.38,11.72,9.02" target="#b6">[2]</ref> and CRM114's notes <ref type="bibr" coords="2,373.52,139.38,10.64,9.02" target="#b8">[4]</ref>, it would be far better if the learning machine itself either made these transformations automatically or used all the features. In this literature, in this work, we only use HTML deobfuscation and MIME normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Chinese Word Segmentation</head><p>Usually, the basic unit for text processing is word. It is natural for English, but for Chinese language text, words are not demarcated in a sentence. Thus, word segmentation must be performed first in most natural language processing (NLP) applications, which is necessary but time-consuming. We adopted a POC-NLW based HMM segmenter, as described in <ref type="bibr" coords="2,247.95,254.34,10.63,9.02" target="#b9">[5]</ref>, to implement the preprocessing of the context of an email. However, in order to meet the constraints on processing time, only a simplest segmentation model was used, which was a purely character-level tagger based on the POC-NLW template without any word-level information. This model only need to load fewest features and the loading can be accomplished in far less than one second, while other more complex models cost a few seconds on feature loading. However, this simplification may lead to decay on the overall performance. As presented in <ref type="bibr" coords="2,367.70,312.84,10.65,9.02" target="#b9">[5]</ref>, detailed experimental results show that such a simplified model performs much worse than those complex ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Tokenization</head><p>Usually, the word is used as the basic processing unit. The basic idea is to break of the input text stream into a series of tokens. The boost [6] Tokenizer package provides a flexible and easy to use way to break of a string or other character sequence into a series of tokens, by which we can choose how the string gets broken up using different Tokenizer function. In this work, we break up the input text string based on a superset of comma separated value lines (such as space, punctuation, customize escaped list separator and offset separator).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Naive Bayes Spam Filtering Framework</head><p>The Bayesian classifier is a probability based approach, which is often applied to text categorizations tasks. For spam detection, suppose each email instance M is described by a conjunction of word attribute values 1 2 , ,..., n w w w &lt; &gt; . And L is the number of target classes ( , 1,...,</p><formula xml:id="formula_0" coords="2,338.76,519.30,49.60,11.33">i C i L =</formula><p>). The basic concept of Bayesian classifier is to find whether an e-mail is spam or not by looking at which words are found and which words are absent from the message. In the literature, the Bayesian approach to the new email is to assign the most probable target label: (1)</p><p>To makes the estimation of parameters tractable, the Naive Bayes assumption is used, which suppose that the attribute values are conditionally independently, then arg max ( ) ( | )</p><formula xml:id="formula_1" coords="2,215.70,647.44,304.34,19.69">NB i k i i L k H P C P w C ∈ = ∏ . (<label>2</label></formula><formula xml:id="formula_2" coords="2,520.04,648.06,3.91,9.02">)</formula><p>For the situation of spam detection, attribute values 1 2 , ,..., n w w w &lt; &gt; is the words in one email message (for Chinese corpus, word segmentation is needed), where L is the number of target classes C i (e.g. C + spam/C - ham). In practice，log-likelihood is computed as following:</p><formula xml:id="formula_3" coords="3,139.20,157.32,380.84,23.51">score(M)= log ( ) log ( | ) (log ( ) log ( | )) k k k k P C P w C P C P w C + + - - + - + ∑ ∑ . (<label>3</label></formula><formula xml:id="formula_4" coords="3,520.04,161.88,3.91,9.02">)</formula><p>Therefore, if score(M) &gt; 0, the email will be assigned to C+, and C-otherwise. In our experiments, n-gram model shows good performance. But with the increase of n, n-gram suffered from data sparseness and realtime limitation, which makes higher order model cannot be used in our submitted systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Add-One Smoothing Algorithm and Kill-One Strategy</head><p>The statistical approaches for spam filtering are often Bayesian and several distribution models (such as multi-variants Bernoulli model, Poisson Naive Bayes model, and the multinomial model) are assumed. The difference between these models is the ways of calculating P(w k |C i ). In this work, multinomial model is used for its superior performance <ref type="bibr" coords="3,199.98,305.64,10.63,9.02" target="#b10">[7]</ref>.</p><p>One benefit of the multinomial approach is the number of available smoothing methods to handle unhappened tokens. In Bayesian models, according to the principles of symmetry, the tokens have no other characteristics in addition to the number of token. Then token k with the same counter has the same probability value. Suppose r n is the number of special token occurred as often as r in training corpus. N is the total number of tokens, then:</p><formula xml:id="formula_5" coords="3,260.64,380.76,263.32,23.51">r r r n N ⋅ = ∑<label>(3)</label></formula><p>Based on the Maximum Likelihood (ML) estimation model, the number of k w in training corpus is ( )</p><formula xml:id="formula_6" coords="3,94.08,429.13,132.80,12.29">k N w r = . Then ( ) / r ML k P w r N =</formula><p>, subject to:</p><formula xml:id="formula_7" coords="3,252.06,446.76,271.90,23.52">( ) 1 r r ML k r n P w = ∑ (4)</formula><p>For simplicity we use add-one formula for smoothing <ref type="bibr" coords="3,319.89,480.12,10.64,9.02" target="#b11">[8]</ref>, which use the r=1 to estimate the unhappened token:</p><formula xml:id="formula_8" coords="3,252.00,509.53,271.96,12.29">0 1 1/ ML ML P P N = =<label>(5)</label></formula><p>On one hand, for our preprocessing strategy, many insignificant and meaningless tokens are often produced, which increase the system load. By using the add-one smoothing algorithm, we can discard the tokens with r=1, which doesn't decreasing the filtering performance. It is so-called kill-one strategy. In practice, the tokens with r=1~3 are usually discarded. On the other hand, tokens' discarding is triggered by setting conditions (such as run time limitation, memory). The effection on precision of our system still needs to be observed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Improvements</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Weighted Adjustment of Separating Hyperplane</head><p>In our 2005 spam track, we discussed some improvements based on separating hayperplane weighted adjustment <ref type="bibr" coords="4,107.58,150.42,10.64,9.02" target="#b6">[2]</ref>. The official evaluation results of TREC 2005 show that the modification is effective. So in the 2006 track, we reprise the 2005 methods with new tasks and data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Selective Classifiers Ensemble</head><p>Last year, we discuss the Bagging-based method for spam filtering. In this year, we use selective ensemble to improve the performance of classifying. After analysis of the relationship between the ensemble and its component, some researchers <ref type="bibr" coords="4,189.06,241.98,12.27,9.02" target="#b12">[9,</ref><ref type="bibr" coords="4,201.33,241.98,12.27,9.02" target="#b13">10,</ref><ref type="bibr" coords="4,213.60,241.98,12.27,9.02" target="#b14">11]</ref> reveal that it may be better to ensemble many instead of all of the classifiers at hand. Selective classifiers ensemble is thought an improved method for Bagging aggregate, in which mutual information weighted method is widely used <ref type="bibr" coords="4,296.87,265.38,11.79,9.02" target="#b12">[9,</ref><ref type="bibr" coords="4,308.66,265.38,11.79,9.02" target="#b13">10,</ref><ref type="bibr" coords="4,320.45,265.38,11.79,9.02" target="#b14">11]</ref>. For this year's track, we discuss two aggregate strategies: 1) selective ensemble based on mutual information of each classifier; 2) selective ensemble based on mutual information sharing with the optimal classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we report the relevant results from the official evaluation. The basic statistics for these datasets are given as following: MrX2 (9032 ham, 40135 spam), SB2 (9274 ham, 2751 spam). The performance of "kidult" anti-spam solution is given in Table <ref type="table" coords="4,278.23,377.88,4.46,9.02" target="#tab_0">1</ref>-Table <ref type="table" coords="4,312.09,377.88,3.77,9.02">2</ref>. Results are included for 2 corpora, with immediate feedback, delayed feedback, and active learning as denoted by the run tag suffix: x2 (MrX2 corpus, immediate feedback), x2d (MrX2 corpus, delayed feedback), x2a (MrX2 corpus, active learning), b2 (SB2 corpus, immediate feedback), b2d (SB2 corpus, delayed feedback), b2a (SB2 corpus, active learning). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,140.88,436.53,309.86,46.74"><head>Table 1 .</head><label>1</label><figDesc>Immediate/delay feedback results</figDesc><table coords="4,140.88,453.57,309.86,29.70"><row><cell>Run tag</cell><cell>Ham Misc%</cell><cell>Spam Misc%</cell><cell>Lam%</cell><cell>(1-ROCA)%</cell></row><row><cell>KB3S1x2</cell><cell>9.90</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>(9.29-10.54)</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,140.88,529.41,35.50,8.10;4,199.42,529.41,20.25,8.10;4,199.38,539.97,45.05,8.10" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Kb9s</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997-10">4x2 10.32 (9.70-10.97</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,136.74,330.99,36.97,8.10;5,136.74,341.55,49.66,8.10" xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Kb3a</surname></persName>
		</author>
		<imprint>
			<date>1x2 Teach=25600</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,136.74,374.19,37.45,8.10;5,136.74,384.75,49.66,8.10" xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Basa</surname></persName>
		</author>
		<imprint>
			<date>2x2 Teach=25600</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,136.74,417.39,36.97,8.10;5,136.74,427.95,49.66,8.10" xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Kb9a</surname></persName>
		</author>
		<imprint>
			<date>3x2 Teach=25600</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,136.74,460.59,36.97,8.10;5,136.74,471.15,49.66,8.10" xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Weia</surname></persName>
		</author>
		<imprint>
			<date>4x2 Teach=25600</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,136.74,546.99,37.45,8.10;5,136.74,557.55,45.16,8.10;5,206.34,546.99,15.77,8.10;5,206.34,557.55,40.55,8.10" xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Basa</surname></persName>
		</author>
		<imprint>
			<date>2b2 Teach=6400 2.61 (1.58-4.05</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.46,379.23,438.66,8.10;6,96.42,389.79,430.69,8.10;6,96.42,400.35,24.00,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,280.49,379.23,246.64,8.10;6,96.42,389.79,229.57,8.10">PRIS Kidult Anti-SPAM Solution at the TREC 2005 Spam Track: Improving the Performance of Naive Bayes for Spam Detection</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">N</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,332.04,389.79,195.07,8.10">Proceedings of Fourteenth Text REtrieval Conference</title>
		<meeting>Fourteenth Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,91.80,410.91,435.37,8.10;6,96.42,421.47,174.61,8.10" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yerazunis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chhabra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Siefkes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Assis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gunopulos</surname></persName>
		</author>
		<ptr target="http://crm114.sourceforge.net/UnifiedFilters.pdf" />
		<title level="m" coord="6,376.66,410.91,147.25,8.10">A Unified Model of Spam Filtration</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.46,432.03,438.65,8.10;6,96.42,442.59,242.17,8.10" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Assis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yerazunis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Siefkes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chhabra</surname></persName>
		</author>
		<title level="m" coord="6,285.44,432.03,241.67,8.10;6,96.42,442.59,215.83,8.10">CRM114 versus Mr. X: CRM114 Notes for the TREC 2005 Spam Trac. Proceedings of Fourteenth Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.46,453.15,438.67,8.10;6,96.42,463.71,255.47,8.10" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,237.42,453.15,195.40,8.10">POC-NLW Template for Chinese Word Segmentation</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,439.34,453.15,87.78,8.10;6,96.42,463.71,195.40,8.10">Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the Fifth SIGHAN Workshop on Chinese Language Processing</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.46,484.83,438.64,8.10;6,96.42,495.39,125.50,8.10" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,237.83,484.83,190.44,8.10">Text Filtering by Boosting Naive Bayes Classifiers</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">Y</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,446.10,484.83,81.00,8.10;6,96.42,495.39,99.18,8.10">SIGIR Conference on Research and Development</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.46,505.95,438.66,8.10;6,96.42,516.51,309.69,8.10" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,197.87,505.95,302.73,8.10">Improving Multiclass Pattern Recognition by the Combination of Two Strategies</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Nicolas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Domingo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,507.59,505.95,19.52,8.10;6,96.42,516.51,211.95,8.10">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1001" to="1006" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.46,527.07,438.66,8.10;6,96.42,537.63,78.85,8.10" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="6,225.61,527.07,301.51,8.10;6,96.42,537.63,21.01,8.10">Ensembling Neural Networks: Many Could Be Better Than All. Artificial Intelligence</title>
		<author>
			<persName coords=""><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="239" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,92.60,548.19,434.55,8.10;6,96.42,558.75,228.74,8.10" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z.-Q</forename><surname>Chen</surname></persName>
		</author>
		<title level="m" coord="6,271.11,548.19,256.04,8.10;6,96.42,558.75,159.59,8.10">Selectively Ensembling Neural Classifiers. Proceedings of the International Joint Conference on Neural Networks</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1411" to="1415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,92.59,569.31,434.53,8.10;6,96.42,579.87,173.16,8.10" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="6,176.66,569.31,318.23,8.10">Cluster Ensembles -A Knowledge Reuse Framework for Combining Multiple Partitions</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Strehl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,500.58,569.31,26.54,8.10;6,96.42,579.87,113.00,8.10">Journal on Machine Learning Research</title>
		<imprint>
			<biblScope unit="page" from="583" to="617" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
