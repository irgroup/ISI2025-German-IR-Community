<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,222.16,72.35,150.95,13.28">SOPHIA in Enterprise Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,90.04,111.95,96.23,13.28"><forename type="first">Vladimir</forename><surname>Dobrynin</surname></persName>
							<email>dobrynin@top.apmath.spbu.ru</email>
							<affiliation key="aff0">
								<orgName type="institution">St Petersburg State University</orgName>
								<address>
									<addrLine>35 University avenue</addrLine>
									<postCode>198504</postCode>
									<settlement>Petrodvoretz, St Petersburg</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,195.11,111.95,52.42,13.28"><forename type="first">Son</forename><surname>Pham</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">St Petersburg State University</orgName>
								<address>
									<addrLine>35 University avenue</addrLine>
									<postCode>198504</postCode>
									<settlement>Petrodvoretz, St Petersburg</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,90.04,214.19,80.78,13.28"><forename type="first">David</forename><surname>Patterson</surname></persName>
							<email>wd.patterson@ulster.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Northern Ireland Knowledge Engineering Laboratory</orgName>
								<orgName type="institution">University of Ulster</orgName>
								<address>
									<postCode>BT37 OQB</postCode>
									<settlement>Jordanstown</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,179.06,214.19,63.44,13.28"><forename type="first">Niall</forename><surname>Rooney</surname></persName>
							<email>nf.rooney@ulster.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Northern Ireland Knowledge Engineering Laboratory</orgName>
								<orgName type="institution">University of Ulster</orgName>
								<address>
									<postCode>BT37 OQB</postCode>
									<settlement>Jordanstown</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,251.47,214.19,91.66,13.28"><forename type="first">Mykola</forename><surname>Galushka</surname></persName>
							<email>mg.galushka@ulster.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Northern Ireland Knowledge Engineering Laboratory</orgName>
								<orgName type="institution">University of Ulster</orgName>
								<address>
									<postCode>BT37 OQB</postCode>
									<settlement>Jordanstown</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,222.16,72.35,150.95,13.28">SOPHIA in Enterprise Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">50EC418F2C76A7B0BF29715F7B3A552F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>SOPHIA participated in TREC 2006 as part of the Enterprise track (Expert search task). Given a topic our task was to find an ordered list of up to 100 experts (from a predefined list of candidate experts) and for every expert create an ordered list of up to 20 support documents. Support document should prove that given person is indeed an expert in the domain presented by the topic.</p><p>We implemented 3 algorithms to solve this task which resulted in 3 runs sophiarun1, sophiarun2 and sophiarun3.</p><p>All runs are based on Contextual Document Clustering (CDC) algorithm <ref type="bibr" coords="1,443.83,455.87,13.83,13.28" target="#b0">[1,</ref><ref type="bibr" coords="1,457.66,455.87,9.22,13.28" target="#b1">2]</ref> applied to a part of W3C document corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document clustering</head><p>W3C collection contains documents of different types. In our experiments we used only two document types: www and lists. Examples of www documents are drafts and final versions of official W3C documents, slides from presentations given by W3C members and so on. Documents of lists type are e-mails. We split www documents into parts, based on 1000 word long segments and considered every part as a separate document. We didn't split mails (lists type documents).</p><p>Altogether we have 45,975 www documents before splitting and 122,751 after splitting and 198,394 documents of lists type (e-mails).</p><p>In parsing we deleted stop-words from a standard stop-list and used Porter stemming. We used the following regular expressions for tokenization: [a-z0-9-']*[a-z][a-z0-9-']*. This means that a term should contain at least one symbol from a-z, can contain symbols from 0-9 and symbol '-'. After stop-words were deleted we replaced the ''' symbol by space and deleted all symbols '-' at the beginning and end of a term.</p><p>Altogether we have 495,260 distinct terms.</p><p>CDC approach is based on scalable automatic detection of themes presented in a document corpus. A theme is represented by probability distribution of terms that occur in a narrow context. Given a term x we define probability distribution of terms that occur in same document with term x as its context. We say that this context is narrow if its entropy is relatively small.</p><p>In narrow context selection process we set 2,000 as number of narrow contexts (themes) we would like to discover in W3C corpus. We ordered terms by document frequency and skipped 90% of the most rare terms and 0.5% of the most common terms, split all other terms into 7 groups of same size and selected 286 terms with minimum context entropy from every group (giving around 2000 narrow contexts in total). We merged similar narrow contexts (with Jensen-Shannon divergence (JS) between two contexts less than 0.01) producing 938 merged contexts altogether. These merged narrow contexts are considered as cluster attractors. A documents is assigned to a cluster with minimum JS between the cluster attractor and document word probability distribution Clustering resulted in 779 non-empty clusters with size starting from 1 document (35 clusters) up to 25,648 documents. 716 clusters have size less than 1,000 documents.</p><p>Based on these generated clusters and statistics of 2 and 3-words phrases which occurred in their documents, we selected 385,070 "interesting" phrases that relate to each cluster theme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Our approach to expert search</head><p>It is difficult to determine who an expert is, based solely on an analysis of www documents. This is because usually all members of a working group are accredited as authors of a document produced by the group but maybe only a few members of the group are actually the real authors. Therefore we used www documents as background information to generate narrow contexts, to form clusters, discover interesting phrases and to estimate the relevance of a cluster to a topic. We used lists documents only to find experts and to select supporting documents from clusters relevant to the topic.</p><p>In our first run sophiarun1 we used only part of topic -its &lt;title&gt; field.</p><p>Given a topic we parsed its &lt;title&gt; field as any other document and then we used inverted index to find all documents (both www and lists types) that contained at least 2 words from topic title or 1 word if this title contains one word only. We considered such documents as relevant to the topic. Additionally if a document contained the same "interesting" phrase that we had in the topic title then we considered this document as relevant also.</p><p>The relevance score of a cluster is calculated as sum of weights of all relevant documents from the cluster. A document's weight is equal to the number of query keywords that occurs in the document plus the number of 2 and 3-word "interesting" phrases from the title that occurs in the document multiplied by 5.</p><p>Given the 5 most relevant clusters we get all mails from these clusters that were sent by a candidate expert (we have list of candidate experts with more than 1,000 persons). To calculate a mail score we used 1-JS value where JS is calculated between the mail and topic title word probability distributions. To calculate expert score we used sum of squares of mail scores sent by this expert.</p><p>Results sent to TREC is a list of up to 100 experts ordered by expert score (this score should be greater than zero ) and for every expert we present list of up to 20 mails sent by this person and ordered by mails scores (mail score should be greater than zero).</p><p>In our second run sophiarun2 we used all parts of the topic including &lt;title&gt;, &lt;description&gt; and &lt;narrative&gt; fields. We don't use here "interesting" phrases. We parsed query as before and calculated JS between the topic and centroid of every cluster. We selected 5 top clusters as relevant and identified a list of experts and support documents as in sophiarun1. The only difference is that if for a topic we had a small (less than 20) number of mails (sent by all candidate experts) presented in these 5 top clusters then we try 6 th , 7 th and so on clusters (up to 20) to get 20 or more such mails.</p><p>Our last run sophiarun3 was a mixture of two previous runs. For every topic we accumulated all mails selected in sophiarun1 or sophiarun2 and used them to recalculate scores for all experts. The idea was that for one particular topic the approach implemented in first run may be better then approach implemented in second run while for another topic reverse may be true.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Our Results</head><p>Next table presents the results for sophiarun1, sophiarun2 and sophiarun3 in terms of average Precision, R-precision, reciprocal rank, relevant retr @ 5,10, where scores are based on the ranking of candidates without regard to support documents. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Presented results show that Run 2 results are worse that Run 1 and Run 3. This means that evaluation of cluster relevance based on number of relevant documents in the cluster is more efficient than evaluation of relevance based on calculation of Jensen-Shannon divergence between cluster attractor and topic word distribution. The reason may be due to specific style of topic description writing.</p><p>In future research we suppose to concentrate on selection of most informative "interesting" words and phrases from topic descriptions and use it as query rather than use row text of topic description.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,90.04,514.12,408.24,168.43"><head></head><label></label><figDesc>Next table presents our results Run1, Run2 and Run3 when candidates retrieved with no positive support documents are considered to be irrelevant..</figDesc><table coords="3,90.04,514.12,382.65,168.43"><row><cell>Run Id</cell><cell>Map</cell><cell>R-prec</cell><cell cols="2">Recip_rank P@5</cell><cell>P@10</cell></row><row><cell cols="2">Sophiarun1 0.2248</cell><cell>0.2864</cell><cell>0.6307</cell><cell>0.4980</cell><cell>0.4306</cell></row><row><cell cols="2">Sophiarun2 0.1355</cell><cell>0.2157</cell><cell>0.4674</cell><cell>0.3347</cell><cell>0.3102</cell></row><row><cell cols="2">Sophiarun3 0.2215</cell><cell>0.2842</cell><cell>0.6178</cell><cell>0.4082</cell><cell>0.3980</cell></row><row><cell>Run Id</cell><cell>Map</cell><cell>R-prec</cell><cell cols="2">Recip_rank P@5</cell><cell>P@10</cell></row><row><cell cols="2">Sophiarun1 0.0934</cell><cell>0.1415</cell><cell>0.4646</cell><cell>0.3184</cell><cell>0.2449</cell></row><row><cell cols="2">Sophiarun2 0.0159</cell><cell>0.0408</cell><cell>0.1398</cell><cell>0.0490</cell><cell>0.0612</cell></row><row><cell cols="2">Sophiarun3 0.0757</cell><cell>0.1314</cell><cell>0.3873</cell><cell>0.2245</cell><cell>0.2061</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,108.04,207.83,397.22,13.28;4,108.04,221.63,397.20,13.28;4,108.04,235.43,222.96,13.28" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,321.76,207.83,162.75,13.28">Contextual Document Clustering</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dobrynin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Rooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,108.04,221.63,397.20,13.28;4,108.04,235.43,74.96,13.28">Proceedings of 26th European conference on Information Retrieval Research, Springer LNCS</title>
		<meeting>26th European conference on Information Retrieval Research, Springer LNCS</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">2297</biblScope>
			<biblScope unit="page" from="167" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,108.04,249.23,397.38,13.28;4,108.04,263.03,397.45,13.28;4,108.04,276.83,184.87,13.28" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,395.10,249.23,110.32,13.28;4,108.04,263.03,250.37,13.28">A scaleable document clustering approach for large document corpora</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Rooney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Galushka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dobrynin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,371.28,263.03,134.21,13.28;4,108.04,276.83,62.54,13.28">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1163" to="1175" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
