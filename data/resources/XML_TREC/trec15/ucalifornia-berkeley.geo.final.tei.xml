<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,180.78,161.71,249.69,15.15;1,184.40,183.63,242.46,15.15">BioText Team Report for the TREC 2006 Genomics Track</title>
				<funder ref="#_ypQs9RT">
					<orgName type="full">IBM</orgName>
				</funder>
				<funder ref="#_9MgJuMd">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,142.99,217.58,60.38,10.48"><forename type="first">Anna</forename><surname>Divoli</surname></persName>
							<email>divoli@ischool</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,212.08,217.58,80.32,10.48"><forename type="first">Marti</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
							<email>hearst@ischool</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,301.56,217.58,82.09,10.48"><forename type="first">Preslav</forename><forename type="middle">I</forename><surname>Nakov</surname></persName>
							<email>nakov@cs</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,393.47,217.58,74.78,10.48"><forename type="first">Ariel</forename><surname>Schwartz</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,275.65,265.28,59.95,10.48"><forename type="first">Alex</forename><surname>Ksikes</surname></persName>
							<email>alex.ksikes@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Cambridge</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,180.78,161.71,249.69,15.15;1,184.40,183.63,242.46,15.15">BioText Team Report for the TREC 2006 Genomics Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6386103C3FA3A9A0E1B412DFF859AEF5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The paper reports on the work conducted by the BioText team at UC Berkeley for the TREC 2006 Genomics track.</p><p>Our approach had three main focal points: First, based on our successful results in the TREC 2003 Genomics track <ref type="bibr" coords="1,208.48,430.89,10.91,9.57" target="#b0">[1]</ref>, we emphasized gene name recall. Second, given the structured nature of the Generic Topic Types (GTTs), we attempted to design queries that covered every part of the topics, including synonym expansion. Third, inspired by having access to the full text of documents, we experimented with identifying and weighting information depending on which section (Introduction, Results, etc.) it appeared in. Our emphasis on covering the different pieces of the query may have helped with the aspects ranking portion of the task, as we performed best on that evaluation measure.</p><p>We submitted three runs: Biotext1, Biotex-tWeb, and Biotext3. All runs were fully automatic. The Biotext1 run performed best, achieving MAP scores of .24 on aspects, .35 on documents, and .035 on passages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Biotext1: Main Run</head><p>Our first run produced results that were reranked by the other two runs. We used the open source Lucene search engine (lucene.apache.org) for indexing, querying, and producing the initial ranking of the full text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Pre-Processing of the Full Text</head><p>The pre-processing step stripped out all of the HTML markup, and identified the boundaries of the legal spans. Although we realized it might be important to convert the various Greek letters and other markup characters to plain text, we did not have time to do this conversion.</p><p>The pre-processing also attempted to identify the sections and their boundaries, using the markup in the section headings and defining a set of 16 different section types: title, references, abstract, abbreviations, conclusions, results, introduction, methods, footnotes, acknowledgments, appendix, future, cases, grants, main, not-categorized</p><p>We have not evaluated the accuracy of this analysis, and without training data it was not possible to assess how best to weight the different sections. As described below, we did make some attempts to weight spans depending on which section they came from.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Analyzing the Topic Description</head><p>As mentioned above, our main strategy was to try to maximize recall for gene and protein names, and to try to be sure that every content word in the query was represented in the retrieved documents. <ref type="foot" coords="2,171.52,307.27,4.23,6.99" target="#foot_0">1</ref>Thus, for each topic description, we identified the terms within it that might be a gene name, and developed a set of synonyms for those names. We made a distinction between strongly matched and weakly matched gene names, described below.</p><p>For each term that was not a gene name or a stop word, we attempted to match it against a term from MeSH, and produced a set of synonyms for that term as well.</p><p>Given a topic description, we created two sets of synonyms. S contained all possible variants of any gene names found in the topic description, using EntrezGene, UniProt and OMIM as resources. M contained the variants of any term in the topic description that was found to match a MeSH term.</p><p>For example, for a topic like "How do HMG and HMGB1 interact in hepatitis?", the code recognizes two gene names, HMG and HMGB1, and one MeSH term, hepatitis. <ref type="foot" coords="2,217.68,593.99,4.23,6.99" target="#foot_1">2</ref>Looking up the corresponding variants in the different data sources yields the following sets of synonym candidates (here converted to lowercase): S = {ac2 008, clb, columbus, cg10367, dkfzp686a04236, dmhmg coar, fb23c02, hmgcr, hmg, hmg1, hmg2, hmg coar, hmg alpha, hmg coa reductase, hmg3, hmgb1, hmgcoar, hmgcoarr, mgc103168, mgc103169, mgc117896, mgc117897, mgc64255, mgc93598, mgc93599, nfd1, sbp 1, hbp1, hmg 11, hmg 12, hmg 3, hmg 4, hmg 5} M = {hepatitis, hepatitides} Gene terms and MeSH labels were indexed in Lucene as separate fields and were queried using Lucene's fielded query facility. Below we describe in detail the gene name recognition and normalization, the MeSH term recognition and the query generation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Gene Name Recognition and Normalization</head><p>In our earlier Genomics Track work <ref type="bibr" coords="2,489.86,485.23,10.91,9.57" target="#b0">[1]</ref>, we developed an in-house gene recognizer and normalizer tool. This original tool looked for gene names in raw text and mapped each identified instance to one or more possible corresponding unique identifiers from the then LocusLink (which has subsequently been superseded by EntrezGene). Multiple LocusLink identifiers can be found for a given gene name, because (a) the same gene has different IDs in different organisms, and (b) the gene name itself may be ambiguous, especially for short 3-4 character names.</p><p>The original tool used a set of normaliza-tion and expansion rules in order to allow for some variations in form, including token rearrangement, and removal of whitespace, commas, parentheses, and numerals. All possible normalizations and expansions of all known Lo-cusLink gene names and their synonyms were generated offline and then matched against a normalized version of the input text using an exact, first-longest-string-matching measure. The matches were then mapped back to the original unnormalized text, and the corresponding IDs were assigned. For our participation this year, we significantly modified this tool. First, we made a clear separation between the normalization and the expansion rules. We further revised the expansion rules and split them into two subgroups: strong rules and weak rules, where the terms indicate the confidence that the resulting transformation reflects the original terms. The strong rules allow only minor changes such as:</p><p>• removal of white space (e.g., "BCL 2" → "BCL2")</p><p>• substitution of non-alpha-numerical characters with a space (e.g. "BCL-2" → "BCL2")</p><p>• concatenation of numbers to the preceding token (e.g., "BCL 2" → "BCL2").</p><p>The weak rules remove at least one alphanumeric token from the string. An example weak rule is the removal of trailing numbers e.g., "BCL 2" → "BCL".</p><p>As another example, treating a "/" as a disjunction produces two new strings: "aspartyl/asparaginyl beta-hydroxylase" → "aspartyl beta-hydroxylase" or "asparaginyl beta-hydroxylase".</p><p>Another weak rule handles parenthesized expressions, removing text before, within and/or after the parentheses. For example, "mitogen-activated protein (MAP) kinase" → "mitogen-activated protein MAP", or "mitogen-activated protein kinase", or "MAP kinase", or "mitogen-activated protein", or "MAP", or "kinase".</p><p>Unlike in the original tool, the new rules have no priorities and are applied in parallel and recursively, trying all feasible sequences. For each resulting expanded variant, we record the ID of the source gene synonym and whether a weak rule was used at least once in the derivation. For a given variant, there are multiple possible IDs, some of which used strong rules only and others that used at least one weak rule. The strong variants are meant to be very accurate and used for gene name matching, while the weak ones are suitable for query expansion, as they conflate related genes.</p><p>In our experiments, we downloaded and used the latest versions of EntrezGene, UniProt and OMIM. Because mapping among their IDs is complicated, we extracted the sets of expansion variants for each of them separately and applied each rule set in isolation.</p><p>In order to save time and storage space, we indexed information only about those genes that occurred in the TREC topics. We first ran the recognizer/normalizer over the topics and we then determined which of the IDs they mapped to for each database, using only strong transformation rules for the matching. Each gene name found in a topic was assigned an identifier, which associated it with the corresponding IDs from the different databases (e.g., bcl2 might be the identifier for BCL-2). We did the same separately for the variants found with the weak transformation rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Analysis of the Gene Transformation Strategy</head><p>Upon reflection, we think that the aggressive expansion of gene names may have negatively impacted our results. For example, looking back at the example topic "How do HMG and HMGB1 interact in hepatitis?", we can see that the set S contains a number of terms that introduce noise. Some candidates, although listed in databases as synonyms of either HMG or HMGB1, come from organisms that cannot possibly be associated with hepatitis directly. For instance HMG2 is found in Arabidopsis thaliana, a plant, and fb23c02 is found in Danio rerio (zebrafish), a fish.</p><p>We should have addressed this issue by checking which organisms are associated with the terms in set M , and then used these organisms to filter out the unrelated terms from set S. We did something similar to this in the 2003 Genomics track. This time however, we decided to keep all gene homologs, since they often offer valuable information on the gene's function across all species, but that might have hurt more than helped.</p><p>We could also have used the various fields of EntrezGene, UniProt and OMIM more carefully. In S we can see the term columbus, which comes from the description field of UniProt for the entry HBG2 HUMAN and refers to a position variant. The whole description field is: D → N (in Columbus-Ga) /FTId=VAR 003167.</p><p>Since we were aiming for high recall, we did not consider problems generated by homonyms. For instance, SBP-1 (Sterol regulatory element Binding Protein) is listed in EntrezGene as an alias for HMGB1 (High-Mobility Group Box 1), but it also stands for Sulfate-Binding Protein.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Strong vs. Weak Mapping Rules</head><p>We ran the gene recognition tool against the entire text collection, using EntrezGene, Lo-cusLink and OMIM, retaining only the matches corresponding to an ID that was recognized in some of the TREC topics. When a match was found, we included the corresponding identifier in the gene field for that document; the gene field could contain a bag of identifiers.</p><p>Each identifier name was prefixed with one of four codes: ss, sw, ws, or ww. The first letter corresponds to the gene found in the TREC topic, where s means it was derived by strong transformation rules, and w means weak rules. The second letter corresponds to what was found in the full text of the documents.</p><p>Suppose for example, that the TREC topic contained the string BCL. Strong rules map this only to BCL, but weak rules will also map it to BCL 1 (numeral removal). The IDs corresponding to BCL will be considered strong IDs and the ones mapping it to BCL 1 will be weak IDs. When indexing the full text documents, BCL would be found using strong rules, and and so this term would be marked as ssbcl.</p><p>Weak and strong labels were combined depending on the origin of the term. Finding BCL-1 in the text via a weak rule for the topic transformation, and a strong rule converting from BCL 1 to BCL-1, would result in assigning it the label wsbcl. BCL-2 will be marked as swbcl as it is derived from a weak rule for BCL.</p><p>Finally, cyclin will be marked as wwbcl as it is obtained from cyclin D1, a synonym of BCL 1, using a weak rule, and BCL 1 is derived from the topic using a weak rule.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Recognizing MeSH Terms</head><p>For marking MeSH terms, we used the same recognizer/normalizer tool as for gene names, but used MeSH terms and their synonyms rather than gene databases, and limited transformations to strong rules only. Again, only those MeSH term IDs recognized in the TREC topics were identified and indexed in Lucene for the documents of the collection. MeSH terms were stored in a separate field in the Lucene index but did not use the strength prefixes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Generating Queries</head><p>Our strategy was to issue a series of queries, starting with stricter constraints to achieve high precision, and then loosening constraints and issuing additional queries until the target number of documents (2000) was retrieved. The order of retrieved documents was retained; that is, the first set of results were kept at the top of the list, the next set appended on to the end (after removing duplicates), and so on. Only the top 1000 documents were returned to NIST for the Biotext1 run, as required by TREC rules, but the deeper set was retained for the Biotext3 run described below. (The Biotextweb run used the top 1000 documents, but reordered them.) For every query, we added the Boolean restriction "NOT section:references" to remove reference sections from consideration, as the Genomics Track guidelines stated that references were not valid results. The standard Lucene ranking algorithm was used as the rank order for the re-sults of each query.</p><p>For the first query, for a given TREC topic, we first removed stopwords and then identified the gene names and the MeSH terms that we could extract from the topic, either directly or through synonym expansion as described above. If no gene names were found, the first query was simply a query on an OR of the MeSH terms (plus the modifier removing reference sections from consideration). If gene names were found, the first query was an OR of the gene names ANDed with an OR of the MeSH terms. Some gene names are part of MeSH, so we took care not to double-count gene names within the MeSH terms.</p><p>When analyzing the TREC topic, we checked to see if more than one gene name was mentioned in the topic. If so, we found a different set of synonyms for each gene name. For each gene in the topic, we weighted its synonyms depending on what kind of gene synonym it was. We boosted genes labeled ss by 100, those labeled sw by 20, those labeled ws by 10 and those labeled ww by 5. (These weights were entirely ad hoc; a training set would have been a great aid for setting these weights.) The weighted synonyms for each gene were combined into an OR; if the original topic contained more than one gene, we combined the disjuncts for each gene with an AND.</p><p>The second query took into account the fact that some non-gene and non-MeSH terms in the query might be useful for ranking. It built one part which was an OR of all of the topic terms that were neither stopwords nor gene names. It then ANDed these terms with the original gene part of the query, if gene names were found.</p><p>The third query started with the original gene part of the query, and if it contained an AND (meaning we detected more than one gene name in the original TREC topic) we replaced this AND with an OR, thus relaxing the requirement that every gene from the topic appear in the retrieved documents. Note that for most topics, this query would not be run since we assume most contained only one query.</p><p>The fourth query was an OR of the prior parts: the gene part of the query, the MeSH part of the query, and the other-query-words part of the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">BiotextWeb: Using Web Statistics</head><p>The BiotextWeb run was inspired by <ref type="bibr" coords="6,257.83,335.06,10.91,9.57" target="#b2">[3]</ref>, who use the Web as an external thesaurus in order to supplement the topic descriptions, thus achieving notable improvements on the TREC 2004 Robust Track. The BiotextWeb run took the output of the previous run (up to 1000 documents) and reranked the documents using statistics derived from the Web. It tried to identify which verbs and noun compounds were associated with the important entities in the target question.</p><p>So for the example topic "How do HMG and HMGB1 interact in hepatitis?" for each pair (s, m), s ∈ S, m ∈ M , we generate a query using the Google search engine to determine which terms are associated with these query terms. Sample generated queries are: "ac2 008" AND "hepatitis" "clb" AND "hepatitis" ... If the topic is missing a gene or a MeSH term, we generated Google queries for only those entities that were present. We collected all returned snippets for all queries (Google returns up to 1000 results per query), sentence-split and POS-tagged them using OpenNLP tools (opennlp.sourceforge.net), and collected all word n-grams (n = 1, 2, . . . , 6). For the unigrams, we collected separately the verbs and the non-verbs, and for n = 2, 3, . . . , 6 the part-of-speech was limited to adjectives (JJ), nouns (N), numbers (CD), foreign words (FW), list elements (LS), and symbols (SYM). The words were normalized using WordNet <ref type="bibr" coords="6,524.70,518.72,10.91,9.57" target="#b1">[2]</ref>. Table <ref type="table" coords="6,344.86,532.27,5.45,9.57" target="#tab_0">1</ref> shows the most frequent non-verb unigrams, bigrams and trigrams, and Table <ref type="table" coords="6,511.13,545.82,5.45,9.57" target="#tab_2">2</ref>   are considered as regular n-grams in this formula), W n is the set of all different n-grams extracted from the Web for the given topic, c(w) is the frequency of the word w in the target document, and f (w) is the frequency of w in the Google snippets. Surprisingly, the BiotextWeb run performed rather poorly as compared to Biotext1. After the evaluation, we analyzed the results and surmise the following reasons for this. The score computed totally ignored the original ranking, that is, the documents containing actual topic entities (genes and MeSH terms) or terms were not given any preference. For example, Table <ref type="table" coords="7,291.17,566.87,5.45,9.57" target="#tab_0">1</ref> shows that, everything else being equal, a document containing the non-query term virus is as good as one containing the query term hepatitis. In fact, the former would be even better, as the term virus is almost 7 times more frequent on the Web than hepatitis, and therefore will be weighted more highly in the formula. Another problem is the exponential growth of the weight of the n-gram for longer n-grams: we used e 2n , while in the BLEU score <ref type="bibr" coords="7,440.58,160.39,11.52,9.57" target="#b3">[4]</ref> (which partly inspired this formula) the weight is given by 1 n . That is, it actually decreases, since in BLEU the longer n-grams contain several shorter ngrams for which they will be given extra weight. Finally, as mentioned above, some of the synonyms of the named entities are ambiguous words, which are likely to refer to non-related notions when used in a web query, as seen in columbus in set S above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Biotext3: Passage Ranking</head><p>This run was intended to address the passage extraction portion of the task by honing in on the best sentences. For each potentially relevant legal text span, the algorithm examined different combinations of passage lengths to determine which would be the best subset to return. The algorithm began with the top 2000 documents retrieved for the Biotext1 run and attempted to extract and rank the best subparts of the best spans.</p><p>First, to determine which features might be useful, we made up several queries in the GTT (Generic Topic Type) format, and hand-labeled documents with our own relevance judgements. We also wrote code to identify which sentences were from which sections, and by examining our internally built relevance judgements, we came up with a scoring system for passages that promoted sentences from the Abstract, Introduction, Conclusions sections, and to a lesser degree from the Results section, and demoted sentences from Footnotes, References, Appendices, Abbreviation Lists, Acknowledgements, and Methods sections. We also tried to deter-mine in advance (without looking at any TREC topics) which subtrees of MeSH were most appropriate for each GTT, and assigned weights to the subtrees accordingly. Unfortunately, due to the lack of training data, these weights had to be set in an ad hoc manner.</p><p>For the Biotext1 run we had labeled gene synonyms as strong or weak and MeSH labels extracted from the text as strong or weak indicators for query terms. In the reranking step, we gave more weight to occurrences of strong gene names and MeSH labels than to weak ones. The GTT-based MeSH subtree weighting was also incorporated into the scoring of MeSH terms found within the text passage. Again, the scores combination methods were ad hoc.</p><p>Unfortunately, just before submission of this run, we realized that our code that had removed the HTML markup for documents did not properly align the sentence text with the original position information. Therefore, all of our character location calculations were off and we couldn't return precise span information. We then had to adjust the code to return full legal spans, and may have introduced an error at this point. This algorithm was quite complex and we have not yet assessed its behavior to determine why the output was so much weaker than for our base run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Future Work</head><p>We look forward to next year's track, which will build on the dataset developed in the judging process for this year's track. Full text documents are an interesting challenge, and we believe that future bioscience journal search engines will be built on these rather than on the traditional PubMed abstracts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,314.62,131.94,224.63,217.75"><head>Table 1 :</head><label>1</label><figDesc>The most frequent non-verb unigrams, bigrams and trigrams found from Web queries for the example topic.</figDesc><table coords="6,320.60,131.94,212.86,168.31"><row><cell cols="2">Non-verbs 2-grams</cell><cell>3-grams</cell></row><row><cell>hepatitis</cell><cell>hepatitis b</cell><cell>hepatitis b virus</cell></row><row><cell>virus</cell><cell>hepatitis c</cell><cell>coa reductase inhibitor</cell></row><row><cell>hmg</cell><cell>coa reductase</cell><cell>hepatitis c virus</cell></row><row><cell>coa</cell><cell>b virus</cell><cell>high mobility group</cell></row><row><cell>reductase</cell><cell cols="2">reductase inhibitor b virus x</cell></row><row><cell>protein</cell><cell>c virus</cell><cell>mobility group box</cell></row><row><cell>inhibitor</cell><cell>mobility group</cell><cell>hmg coa reductase</cell></row><row><cell>clb</cell><cell>high mobility</cell><cell>group box 1</cell></row><row><cell>hmgb1</cell><cell>virus x</cell><cell>virus cellular receptor</cell></row><row><cell>high</cell><cell>hmg coa</cell><cell>mobility group protein</cell></row><row><cell>group</cell><cell>group box</cell><cell>cellular receptor 1</cell></row><row><cell>mobility</cell><cell>chronic hepatitis</cell><cell>virus x interact</cell></row><row><cell>hmg1</cell><cell>box 1</cell><cell>c virus core</cell></row><row><cell>columbus</cell><cell>virus cellular</cell><cell>hepatitis b surface</cell></row><row><cell>box</cell><cell>cellular receptor</cell><cell>hepatitis delta antigen</cell></row><row><cell>chronic</cell><cell>hepatitis delta</cell><cell>box transcription factor</cell></row><row><cell>antigen</cell><cell>group protein</cell><cell>chronic hepatitis c</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,72.00,312.03,224.62,36.67"><head>Table 2 :</head><label>2</label><figDesc>The most frequent verbs and tetragrams found from Web queries for the example topic.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,88.59,619.20,208.04,7.86;2,72.00,630.16,224.62,7.86;2,72.00,641.12,177.50,7.86"><p>Since gene names and protein names are often interchangeable, below when we refer to gene names we implicitly mean gene and/or protein names.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,84.44,650.31,3.65,5.24;2,88.59,652.08,208.04,7.86;2,72.00,663.04,175.29,7.86"><p><ref type="bibr" coords="2,84.44,650.31,3.65,5.24" target="#b1">2</ref> We developed a small number of topics of our own and used them during system development.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements: This work was supported in part by <rs type="funder">NSF</rs> <rs type="grantNumber">DBI-0317510</rs> and by an <rs type="funder">IBM</rs> <rs type="grantName">UIMA grant</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_9MgJuMd">
					<idno type="grant-number">DBI-0317510</idno>
				</org>
				<org type="funding" xml:id="_ypQs9RT">
					<orgName type="grant-name">UIMA grant</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,331.60,219.11,207.65,9.57;8,331.59,232.66,207.65,9.57;8,331.59,246.21,207.65,9.57;8,331.59,259.76,163.81,9.57" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,398.05,232.66,141.20,9.57;8,331.59,246.21,117.03,9.57">Biotext team report for the trec 2003 genomics track</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Bhalotia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,471.97,246.21,67.28,9.57;8,331.59,259.76,30.97,9.57">Proceedings of TREC</title>
		<meeting>TREC<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,331.60,282.28,207.65,9.57;8,331.59,295.83,168.95,9.57" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,422.17,282.28,117.07,9.57;8,331.59,295.83,76.93,9.57">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,331.60,318.34,207.65,9.57;8,331.59,331.89,207.65,9.57;8,331.59,345.44,207.66,9.57;8,331.59,358.99,207.65,9.57;8,331.59,372.54,82.60,9.57" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,409.34,331.89,129.90,9.57;8,331.59,345.44,104.47,9.57">Trec 2004 robust track experiments using pircs</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Grunfeld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Dinstl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,467.25,345.44,72.00,9.57;8,331.59,358.99,87.22,9.57">13th Text REtrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,331.60,395.05,207.65,9.57;8,331.59,408.60,207.65,9.57;8,331.59,422.15,207.65,9.57;8,331.59,435.70,207.65,9.57;8,331.59,449.25,207.65,9.57;8,331.59,462.80,207.65,9.57;8,331.59,476.35,207.65,9.57;8,331.59,489.90,19.40,9.57" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,391.88,408.60,147.37,9.57;8,331.59,422.15,159.59,9.57">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W.-J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,516.77,422.15,22.47,9.57;8,331.59,435.70,207.65,9.57;8,331.59,449.25,207.65,9.57;8,331.59,462.80,16.45,9.57">ACL &apos;02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics</title>
		<meeting><address><addrLine>Morristown, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
