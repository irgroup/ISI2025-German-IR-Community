<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,140.70,56.74,330.70,20.82;1,173.10,89.54,265.89,20.82">OSBFLua A text classification module for Lua The importance of the training method</title>
				<funder ref="#_x4Rm6hc">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,270.10,153.96,71.85,16.87"><forename type="first">Fidelis</forename><surname>Assis</surname></persName>
						</author>
						<title level="a" type="main" coord="1,140.70,56.74,330.70,20.82;1,173.10,89.54,265.89,20.82">OSBFLua A text classification module for Lua The importance of the training method</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A48188D247D4E36D51136530421E926C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>OSBFLua is a C module for the Lua language which implements a Bayesian classifier enhanced with Orthogonal Sparse Bigrams OSB for feature extraction and Exponential Differential Document Count EDDC -for feature selection. These two techniques, combined with the new training method introduced for TREC 2006 produce a highly accurate filter, yet very fast and economic in resources. OSBFLua is an Open Source Software available from http://osbf lua.luaforge.net. spamfilter.lua is a productionclass antispam filter available in the same package.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The importance of feature extraction and feature selection is well known in tokenbased text classifiers. To address these points, OSBFLua uses the techniques Orthogonal Sparse Bigrams (OSB) <ref type="bibr" coords="1,504.00,417.61,51.34,14.46;1,56.70,432.11,43.60,14.46" target="#b2">[Siefkes et al. 2004]</ref> and Exponential Differential Document Count (EDDC) <ref type="bibr" coords="1,377.10,432.11,87.43,14.46" target="#b0">[Assis et al. 2005]</ref>, respectively. The reading of the last reference is specially recommended for better understanding of this paper.</p><p>A third point, which is the subject of this paper, proved to deserve equal attention during the experiments for TREC 2006: the training method. The new training method introduced for TREC 2006, despite its simplicity, is the main factor responsible for the improvement in classification performance reached by OSBFLua, from the version presented in MIT Spam Conference 2006 to the present one submitted to TREC 2006 Spam Track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Basic training methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistic classifiers build their predicting models learning by examples. A basic training method is to</head><p>start with an empty model, classify each new sample and train it in the right class if the classification is wrong. This is known as Train On Error -TOE <ref type="bibr" coords="1,287.90,636.81,75.06,14.46" target="#b3">[Yerazunis 2005</ref>]. An improvement to this method is to train also when the classification is right but the score is near the boundary, that is, Train On or Near Error TONE. This method is also called Thick Threshold <ref type="bibr" coords="1,353.60,665.71,140.26,14.46">Training [Siefkes et al. 2004</ref><ref type="bibr" coords="1,493.86,665.71,61.51,14.46;1,56.70,680.11,20.66,14.46" target="#b3">] [Yerazunis 2005</ref>].</p><p>The advantage of TONE over TOE is that it accelerates the learning process by exposing the filter to additional difficult (hardtoclassify) samples in the same period. Pure TONE was the training method used by OSBFLua before TREC 2006.</p><p>3 The new training method TONE with Header Reinforcement TONE with Header Reinforcement TONEHR -can be seen as an extension to TONE that adds a mechanism similar to white/black listing, in a sense that it uses information present in the header of the message for the hardtoclassify and hardtolearn cases. Contrarily to normal white/black listing though, which is typically manual, Header Reinforcement HR is an entirely automatic process, from the detection of the cases where it applies to the selection of the most interesting features in the header to be considered. HR extends TONE in the following way: after a message is trained as in TONE, the new score is calculated and the training is repeated, now using only the header of the message, while all three conditions below hold: the new score remains near the boundary; the absolute value of the variation of the score is less than a defined value; the number of repetitions is less than the maximum allowed.</p><p>The first condition is used to detect when HR applies, and then, together with the third and fourth, to avoid over training, which would result in bad score calibration. The limit values for these conditions were found experimentally and are documented in spamfilter_commands.lua source code, available in OSBFLua package. The code used for TREC evaluation is basically the same, but stripped down to the minimum necessary for the TREC runs.</p><p>The interesting aspect of this controlled repeated training, using only the header, is that instead of just two "colors", black and white, we get many more gradations between those extremes, producing better calibrated scores and, as a result, an improved area under the ROC curve. Another interesting characteristic is that it uses the normal training function already available in the filter and takes advantage of EDDC ability to automatically select, among the features present in the header, the most significant ones for classification.</p><p>Table <ref type="table" coords="2,86.90,596.51,6.00,14.46">1</ref> shows the evolution of OSBF from TREC 2005 <ref type="bibr" coords="2,333.20,596.51,89.50,14.46" target="#b0">[Assis et al. 2005]</ref> to the present version, and the improvement due to TONEHR. The measurements were done against the TREC 2005 Full corpus.  The different combinations of thick threshold ranges and token delimiters were intended as an extra experiment to confirm the reduction in false positives induced by the asymmetric ranges in the table, without significant variation in global accuracy. As already observed during experiments, the results of TREC 2006 evaluation revealed the same behavior on both, public and private corpora, confirming that asymmetric ranges can be used for false positive reduction. This is useful since many users of spam filters will consider the cost of misclassifying a ham message as spam higher than the cost of misclassifying a spam message.</p><p>All four packages were configured with two fixedsize databases, 46MB (4M buckets) each, one for spam and another for nonspam, totalizing 92MB. In practice we don't need such a large database, though. The default value in spamfilter.lua is only 1.1MB (92k buckets) per database, but the accuracy is still very good for practical purposes.  The submitted packages are available at http://osbflua.luaforge.net/TREC2006/, for easy reproduction of the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">The ROC curve</head><p>The area under the ROC curve (AUC), or its complement (1ROCA)%, is the main metric for ranking classifiers that has been used in TREC Spam Track. While it is a good measurement of the overall performance, it is not enough to assess classifiers when the ROC curves cross each other. For instance, low ham misclassification percentage (hm%) <ref type="bibr" coords="4,292.80,513.41,99.63,14.46" target="#b2">[CORMACK, G. 2006]</ref>, is more important than spam misclassification percentage (sm%) in spam filtering. hm% greater than 1%, to use a conservative value, is simply unacceptable. On the other hand, sm% greater than 10% is very poor for an antispam filter. So, the area restricted to the acceptable operation region, for instance where sm% &lt; 10% and hm% &lt; 1%, or even a more restricted one, considering the accuracy of present day spam filters, would be more appropriate when the ROC curves intersect.</p><p>Figure <ref type="figure" coords="4,91.30,614.61,6.00,14.46">1</ref> shows ROC curves for the three versions listed in Table <ref type="table" coords="4,373.30,614.61,4.15,14.46">1</ref>. TREC 2006 curve exhibits the best (1ROCA)% value and is not intersected by any other, so it is clearly the best of the three classifiers. Because the other two curves intersect, the better (1ROCA)% value of the version presented in MIT Spam Conference 2006 is not enough to tell if it is the best of the two. But a visual inspection shows that it dominates TREC 2005 version during most of the region where hm% is less than 1%, and confirms that it is the second best.</p><p>Figure <ref type="figure" coords="5,207.60,373.61,6.00,14.46">1</ref> -ROC curves for the three versions in Table <ref type="table" coords="5,432.60,373.61,6.00,14.46">1</ref> 6 TREC 2006 results  Training methods play an important role for the accuracy of adaptive antispam filters, side by side with techniques for feature extraction, feature selection and weighting for tokenbased filters, and deserve the same attention.</p><p>A training method for statistic antispam filters was introduced, TONEHR, with experimental results that demonstrate its great contribution to the overall accuracy of OSBFLua. The author has no knowledge of a similar training method in the literature and believes that it is new, despite its simplicity. I want also to thank William Yearazunis for creating the CRM114 project, which motivated me to dedicate time to antispam filters.</p><p>Finally, a special thanks to Christian Siefkes, for his time in reviewing this paper thoroughly and making many helpful and inspired comments and contributions to the text.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" coords="5,114.00,71.10,383.95,287.95"><head></head><label></label><figDesc></figDesc><graphic coords="5,114.00,71.10,383.95,287.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,56.70,88.42,498.50,369.59"><head></head><label></label><figDesc>Four OSBFLua packages were submitted to TREC, differing only in the configuration of the thick threshold range and in the token delimiters used. The packages and their configurations are shown in Table2:</figDesc><table coords="3,56.70,88.42,423.80,369.59"><row><cell></cell><cell>Version</cell><cell cols="2">Training</cell><cell>(1-ROCA)%</cell></row><row><cell></cell><cell></cell><cell cols="2">method</cell></row><row><cell>TREC 2005</cell><cell></cell><cell></cell><cell>TONE</cell><cell>0.019 *</cell></row><row><cell cols="2">MIT Spam Conference 2006</cell><cell></cell><cell>TONE</cell><cell>0.016 **</cell></row><row><cell>TREC 2006</cell><cell></cell><cell cols="2">TONE-HR</cell><cell>0.010</cell></row><row><cell cols="4">(*) Extra evaluation, by Prof. Gordon Cormack (**) Better EDDC tuning</cell></row><row><cell cols="4">Table 1 -Evolution of OSBFLua</cell></row><row><cell cols="2">4 The packages submitted to TREC 2006</cell><cell></cell></row><row><cell>Package</cell><cell cols="2">Thick threshold range</cell><cell>Token delimiter regex</cell></row><row><cell>oflS1F</cell><cell>[15, 25]</cell><cell></cell><cell>\s</cell></row><row><cell>oflS2F</cell><cell>[15, 25]</cell><cell></cell><cell>[\s.@:/]</cell></row><row><cell>oflS3F</cell><cell>[20, 20]</cell><cell></cell><cell>\s</cell></row><row><cell>oflS4F</cell><cell>[20, 20]</cell><cell></cell><cell>[\s.@:/]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,56.70,472.91,498.63,144.46"><head>Table 2 -</head><label>2</label><figDesc>Packages submitted to TREC 2006The thick threshold ranges indicate the score region where reinforcement training is needed and the asymmetric range was set so that more good messages, proportionally to spam, were used for reinforcements. Scores in OSBFLua indicate "hamminess", rather than "spamminess" as expected by TREC scripts, that is, negative values indicate spam while non negative indicate ham. This explains the positive shift applied to the thick threshold range to reduce false positives. A conversion internal to the filter was implemented for compatibility with the values expected by TREC evaluation scripts.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,56.70,143.71,498.30,163.40"><head></head><label></label><figDesc>Table 3 compares (1ROCA)% values for small and large databases on the three public corpora: TREC 2005 Full, TREC 2006 English and TREC 2006 Chinese. Even with only 2.2 MB total database, the only significant change was on the full corpus, but still keeping a low value, comparable to the best in TREC 2005 Spam Track.</figDesc><table coords="4,135.50,233.18,340.93,73.93"><row><cell>Database size</cell><cell>Full</cell><cell>(1ROCA)% Public English</cell><cell>Public Chinese</cell></row><row><cell>2.2 MB</cell><cell>0.022</cell><cell>0.058</cell><cell>0.003</cell></row><row><cell>92.0 MB</cell><cell>0.010</cell><cell>0.054</cell><cell>0.003</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,181.30,322.01,249.47,14.46"><head>Table 3 -</head><label>3</label><figDesc>(1ROCA)% for small and large databases</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,56.70,449.51,498.50,252.46"><head>Table 4 -</head><label>4</label><figDesc>Table4shows the best filter for each of the top 5 teams, ranked by its (1ROCA)% value on the immediate feedback run against the Aggregate pseudocorpus [CORMACK,G. 2006]. OSBFLua (oflS1) was the best overall and also the best on each of the four corpora used for the tests, except on the Chinese one, where it was the second best. TREC 2006 results (1ROCA)% Since the tokenization done by present OSBFLua code is more suitable for occidental languages, its good result on the Chinese corpora was unexpected by the author. It depends on special delimiter characters (whitespace and possibly others) to split a text into tokens (words), but Chinese and other oriental languages do not generally use whitespace to separate tokens. This result can probably be credited to the new training method, because it makes special use of the header of the message, which is mostly independent of the language.Table5shows the results of the four OSBFLua variants in the immediate feedback run. oflS1F and oflS3F were the first and second best with respect to (1ROCA)%, but the variations are not statistically significant.</figDesc><table coords="5,113.80,538.98,379.70,131.29"><row><cell>Filter</cell><cell>Aggregate</cell><cell>TREC06</cell><cell>TREC06</cell><cell>MrX2</cell><cell>SB2</cell></row><row><cell></cell><cell></cell><cell>English</cell><cell>Chinese</cell><cell></cell><cell></cell></row><row><cell>oflS1</cell><cell>0.0295</cell><cell>0.0540</cell><cell>0.0035</cell><cell>0.0363</cell><cell>0.1300</cell></row><row><cell>tufS2</cell><cell>0.0370</cell><cell>0.0602</cell><cell>0.0031</cell><cell>0.0691</cell><cell>0.3379</cell></row><row><cell>ijsS1</cell><cell>0.0488</cell><cell>0.0605</cell><cell>0.0083</cell><cell>0.0809</cell><cell>0.1633</cell></row><row><cell>CRMS3</cell><cell>0.0978</cell><cell>0.1136</cell><cell>0.0105</cell><cell>0.1393</cell><cell>0.2983</cell></row><row><cell>hubS3</cell><cell>0.1674</cell><cell>0.1564</cell><cell>0.0353</cell><cell>0.2102</cell><cell>0.6225</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,56.70,380.41,400.79,58.98"><head>Table 5 -</head><label>5</label><figDesc>Results of the four OSBFLua variants (1ROCA)%</figDesc><table coords="6,56.70,423.78,74.07,15.61"><row><cell>7 Conclusions</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>I want to thank many people who have been contributing to the improvement of OSBFLua, by testing, packaging, mirroring and making useful suggestions and contributions. Among them, <rs type="person">Alessandro Martins</rs>, <rs type="person">Cassiano Aquino</rs>, <rs type="person">Marcus Maciel</rs>, <rs type="person">Pavel Kolar</rs> and <rs type="person">Steve Pellegrin</rs>.</p><p>I want to thank the <rs type="institution">Luaforge team</rs> for hosting the <rs type="projectName">OSBFLua</rs> project and <rs type="person">André Carregal</rs> for his support with the questions related to this hosting.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_x4Rm6hc">
					<orgName type="project" subtype="full">OSBFLua</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,56.70,203.21,498.50,14.46;7,56.70,217.61,498.60,14.46;7,56.70,232.11,252.90,14.46" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,347.90,203.21,207.30,14.46;7,56.70,217.61,136.97,14.46">CRM114 versus Mr. X: CRM114 Notes for the TREC 2005 Spam Track</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Assis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yerazunis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Siefkes</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Chhabra S</surname></persName>
		</author>
		<ptr target="http://trec.nist.gov/pubs/trec14/papers/crm.spam.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="7,216.20,217.61,333.70,14.33">The Fourteenth Text REtrieval Conference -TREC Spam Track 2005</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,56.70,262.21,498.44,14.46;7,56.70,276.61,498.70,14.46;7,56.70,291.11,349.50,14.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,347.50,262.21,207.64,14.46;7,56.70,276.61,349.79,14.46">Exponential Differential Document Count: A Feature Selection Factor for Improving Bayesian Filters Accuracy</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Assis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yerazunis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Siefkes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chhabra</surname></persName>
		</author>
		<ptr target="http://osbflua.luaforge.net/papers/osbfeddc.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="7,434.50,276.61,115.66,14.33">2006 Spam Conference</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,56.70,320.01,496.44,14.46;7,56.70,334.41,378.04,14.46;7,56.70,363.31,493.23,14.46;7,56.70,377.81,472.13,14.46;7,56.70,392.21,468.60,14.33;7,56.70,406.71,380.40,14.46" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,149.60,320.01,164.67,14.46;7,338.90,363.31,211.03,14.46;7,56.70,377.81,191.06,14.46">Combining Winnow and Orthogonal Sparse Bigrams for Incremental Spam Filtering</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Siefkes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Assis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chhabra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yerazunis</surname></persName>
		</author>
		<ptr target="http://page.mi.fuberlin.de/~siefkes/papers/winnowspam.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="7,335.70,320.01,217.44,14.46;7,56.70,334.41,231.53,14.46;7,268.20,377.81,260.63,14.33;7,56.70,392.21,462.36,14.33">European Conference on Machine Learning (ECML) / European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)</title>
		<imprint>
			<date type="published" when="2004-09">2006. 2004. September 2004</date>
		</imprint>
	</monogr>
	<note>NIST Special Publication: The Fifteenth Text REtrieval Conference Proceedings (TREC 2006)</note>
</biblStruct>

<biblStruct coords="7,56.70,435.71,498.43,14.46;7,56.70,450.21,498.14,14.46;7,56.70,464.61,143.00,14.46" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,157.90,435.71,397.23,14.46;7,56.70,450.21,231.53,14.46">CRM114 Revealed -Or How I learned To Stop Worrying and Trust My Automatic Monitoring Systems ; this is the complete</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Yerazunis</surname></persName>
		</author>
		<ptr target="http://crm114.sourceforge.net" />
	</analytic>
	<monogr>
		<title level="j" coord="7,296.50,450.21,42.90,14.46">CRM</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
