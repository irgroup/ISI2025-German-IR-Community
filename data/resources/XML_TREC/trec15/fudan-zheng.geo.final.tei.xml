<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,86.26,88.81,424.47,15.06;1,189.21,106.74,218.49,15.06">Using Profile Matching and Text Categorization for Answer Extraction in TREC Genomics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,55.44,155.82,73.57,10.46"><forename type="first">Haiqing</forename><surname>Zheng</surname></persName>
							<email>hayden.zheng@gamil.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<address>
									<addrLine>Fudan Univerisity 220 Handan Road</addrLine>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,55.44,201.05,46.52,10.46"><forename type="first">Chen</forename><surname>Lin</surname></persName>
							<email>cheyenne.lin@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<address>
									<addrLine>Fudan Univerisity 220 Handan Road</addrLine>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,55.44,320.60,53.07,10.46"><forename type="first">Junyu</forename><surname>Niu</surname></persName>
							<email>jyniu@fudan.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<address>
									<addrLine>Fudan Univerisity 220 Handan Road</addrLine>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,86.26,88.81,424.47,15.06;1,189.21,106.74,218.49,15.06">Using Profile Matching and Text Categorization for Answer Extraction in TREC Genomics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">19915417C5B18362E5837F8A0F7E667E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>TREC'06 genomics track was focusing on text mining and passage retrieval. WIM lab participated in this year's TREC genomics track. Our system consists of five parts: preprocessing, sentence generation, document retrieval, answer extraction and answer fusion. And we developed two different method: a automated profile matchingbased method and a text categorizationbased method to do the text mining, we will compare the performances between those two methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>TREC genomics track is always focusing on the text processing in biomedical fields. And this year's task was mainly trying to find a specific passage for one query, here, the query was propose in a natural language way and the passages were composed by two or more short sentences which close to each other. And there is also some measurements about grouping the submitted passages into several different aspects. <ref type="bibr" coords="1,81.81,662.16,57.90,10.46" target="#b3">(Hersh, 2006)</ref> Appearing in Proceedings of the 2006 Text Retrieval Conference <ref type="bibr" coords="1,86.60,702.46,55.79,9.41">(TREC 2006)</ref> We are going to give an introduction to our genomic text mining system. Firstly, we will give a brief overview of our system, and then will give a more detailed description of each part. And the result also be given in the next part. At last, we do some conclusion to this year's track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">System Overview</head><p>Our system is mainly contains 5 parts: preprocessing, sentence generation, document retrieval, text mining and answer fusion. The architecture of our system is below:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Preprocessing &amp; Sentence Generation</head><p>The corpus of TREC 2006 is the electronic edition paper from Highwire press. And the submitted result should give the displacement of the start offset and the length of the relevant passages.</p><p>We firstly remove all the structure labels of the html and the information have nothing to do with the main part. After this, we convert the html format files into pure text.</p><p>Then we parsed all the text files, for the submitted results should give out the offsets of the paragraphs. We simply treated dot as the separates of the sentences. And for convenience, we also saved the start displace- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Query Expansion</head><p>The topics of this year's TREC genomics is the same as the last year-generic topic templates (GTTs) which are derived from an analysis of the topics from the 2004 track and other known biologist information needs. <ref type="bibr" coords="2,82.46,491.40,58.64,10.46" target="#b3">(Hersh, 2006)</ref> There're for types of this year's topics:</p><p>(1) Information describing the role(s) of one or more genes involved in a given disease.</p><p>(2)Information describing the role of a gene in a specific biological process.</p><p>(3)Information describing interactions (e.g., promote, suppress, inhibit, etc.) between two or more genes in the function of an organ or in a disease.</p><p>(4)Information describing one or more mutations of a given gene and its biological impact.</p><p>There're a lot entity names such as gene names, protein names, and disease names in the topics. And there are a lot of synonyms and abbreviations of the entity names, so for the initial topics query expansion is badly needed in this task.</p><p>Firstly, we picked out all the entity names, and get the synonyms from the PubMed databases. All the synonyms and its different abbreviations are expanded as the new input query for the retrieval system. Secondly, for some words which seem not belong to the biology field such as 'effect', 'migrate' etc. We used word-net to find out the synonyms and also put them into the initial query <ref type="bibr" coords="2,422.44,158.22,72.22,10.46" target="#b7">(Voorhees, 1994)</ref>.</p><p>Based on the two query expansion steps we mentioned before, the new query was formed which contains more information which could help the performance of the document retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Document Retrieval</head><p>For document retrieval we took the widely used Lemur toolkits as our search engine. The Indri query language, based on the Inquery query language, can handle both simple keyword queries and also complex queries. Such a query language sets Indri apart from many other available search engines. It allows complex phrase matching, synonyms, weighted expressions, Boolean filtering, numeric (and dated) fields, and the extensive use of document structure (fields), among others. Taken topic 166: What is the role of Transforming growth factor-beta1 (TGF-beta1) in cerebral amyloid angiopathy (CAA) ?</p><p>we transformed it into the normalized query form such as : #weight(2.0#1(Transforming growth factor beta) #1(TGF beta) Tgfb Tgfb-1 2.0 #1(Cerebral Amyloid Angiopathy)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Answer Extraction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Profile-based mining</head><p>One of the most popular method using in answer extraction is the profile-based methods. In TREC QA a lot profiles had been developed either manually or automatically to find out the most fit sentences to the profiles for different types of questions.</p><p>In this year's genomics track, we developed a profile based method to extract the most proper passages for each topic in automatic way. Firstly, we did a sentence-level retrieval to find out the most relevant sentences, and then we used a parsing tools to parse all the topics and also the submitted rank first N sentences by last step. And we checked the similarity between the sentences and the topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Sentence retrieval</head><p>After the document retrieval step, we got the ranked document list. But this year's task is trying to extract the most relevant paragraphs, which means that we should measure the relevance of each single sentences <ref type="bibr" coords="3,81.48,135.03,96.61,10.46" target="#b6">(Stefanie Tellex, 2003)</ref>.</p><p>In this step we calculate the score of each sentence which indicates if the sentence is tightly related to the given query. The original algorithm was proposed in <ref type="bibr" coords="3,55.44,188.83,91.54,10.46" target="#b0">(A Ittycheriah, 2000)</ref>. The score is composed of four parts, (1) match score: The sum of the scores for each matched word (which means the word appeared in the query expansions) in the sentence using formula:</p><formula xml:id="formula_0" coords="3,55.44,247.91,166.78,15.77">S match = matchwords i=1 tf i × (log 10 N dfi )</formula><p>(2) mismatch score: The sum of the scores for each mismatched word (which means the word misses in the query expansions)) in the sentence using formula as:</p><formula xml:id="formula_1" coords="3,55.44,314.96,180.43,15.77">S match = mismatchwords i=1 tf i × (log 10 N dfi )</formula><p>(3) score for cluster Compute the number of words that appeared adjacently in both query and sentences.</p><p>(4) score for dispersion Compute the number of words that appear between the match words.</p><p>Each score has a weight ((1) and ( <ref type="formula" coords="3,207.57,396.44,4.24,10.46">3</ref>) are positive and ( <ref type="formula" coords="3,59.68,408.40,4.24,10.46">2</ref>) and (4) are negative) and we add them together to get a final score for each sentence. Score sen = αS match + βS clu -γS mis -δS dipersion There are several aspects to be considered (a) When a word repeat several times in one single sentence, it's score for match should decline each time when the score is added. (b)When the disease name and gene name in the query expansions appear at the same time in the candidate sentence, the sentence should have some bonus score, for it is more likely to indicate the relationships between the gene and the disease.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Parsing</head><p>Mini-par <ref type="bibr" coords="3,91.83,588.23,29.60,10.46">(Lin, )</ref> was used as parsing tool in the experiment which was is a broad-coverage efficient parser for the English language. We here use it to parse all the topics and the return sentences by sentence retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">Profile matching</head><p>In order to find out the most relevant passage to the query, we should find the most proper sentences which have the similar grammatical structure to the query and also using the term relationship information to extract the exact passage <ref type="bibr" coords="3,419.37,68.55,71.69,10.46" target="#b2">(Hang Cui, 2005)</ref>. So we decided using a parsing tool to parse all the queries and find out their grammatical structure. Based on the query's structure, we can construct the profile of each topic.</p><p>By using external tools 'minipar', sentence in English can be converted into tree-like structure. Compared with POS tagging, these works go steps forward to the sentence parsing by approaching semantic level.</p><p>On applying tree-like structure to QA system, we have to find a suitable critical function to evaluate the similarity between two English sentences. We construct this function base on gene-node-relation algorithm, described as follow: A1: parsing the question sentence into POS tree, splitting gene1, gene2 into word token. A2: finding the enclosure of gene1 &amp; gene2 in the POS tree A3: if enclosure(gene1) and enclosure(gene2) are connective, return false; A4: finding the co-parent node of two enclosures, named as COP A5:ensuring the dependency relationship; A6: getting the shortest connectivity path between two enclosures (crossing COP) named SCP A7: for each answer-candidate, calculate the COP, TYPE, SCP, comparing them with that of questions, then matching the similarity mark. PS1: matching TYPEs if equals, mark++; else mark-; PS2: matching COP if equals, mark++; else mark-; PS3: matching CSP finding the topest prep in the CSP, and then comparing the prep between them, if equals or both-NULL, mark++; else mark-;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Text Categorization-based Extraction</head><p>For the returned 1000 documents for each topic, we implemented a text categorization based method for each one.</p><p>Firstly, we parsed all the the returned relevant documents, and all those documents are divided into tens of thousands of sentences. We then using the Lemur toolkits to index them. Then we input the queries used the retrieval step, and get to first N sentences as the relevant ones.</p><p>We supposed that the information relevant to the topic is no only just in the keywords which presented in the query but also in the context of each related passages. And a lot text mining methods didn't consider the context of the relevant answers.</p><p>Then, we use a SVM-light(support vector machine) classifier <ref type="bibr" coords="4,96.98,68.55,68.64,10.46" target="#b4">(Joachims, 1999)</ref> to find the relevant answers to the topic. The methods we took will be in described details next: 1) we picked up the ranked first n p as the positive samples for a certain topic t i to the classifier; and the last ranked n n as the negative samples. and the left N -n p -n n are the unlabeled data which should be classified. And the idea could be very easily understand, for the most relevant sentences to one topic, it can be regarded as the same class of the topic; 2)the weighting method we used here is a tf*idf based method: in the jth sentence, term t i has the weight as: weight(t i , j )=stf(t i , j )* sidf (ti)  idf (ti) /(LENGTH(j)) in which stf(t i , j ) is the number term t i exits in the jth sentence, and sidf(t i ) is the number sentences in which term t i exits in the N sentences, LENGTH(j) stands for the length of sentence j.</p><p>After classifying the unlabeled data, every sentence got a score, and for each topic tp i , we defined a threshold TH i , for those sentences whose score is greater that this threshold TH i , it will be regarded as a relevant sentence and would be returned as a relevant answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Answer Fusion</head><p>The two text mining systems were returning the separated sentences each with a score. So, we must combine the sentences in the neighborhood into a single passage.</p><p>Here, for the thousands of sentences returned by mining step, we check each sentence's SenId which was assigned in the preprocessing step. If sentence i and sentence j are closed to each other, and i has the score S i , and j has the score S j , the fused passage which consisted of i and j will have the score as S ( pasg)= </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results and Analysis</head><p>We have submitted three runs of this years TREC genomics: trecgen1, trecgen2 and trecgen3. The first two runs are based on the text categorization method, and the last one is based on the profile matching method. The differences between the first two runs are the numbers of the positive samples and the negative samples are not the same, trecgen2 was with fewer samples used for categorization. This year's TREC's evaluation is based on three different levels of retrieval performance: passage retrieval, aspect retrieval, and document retrieval. And each of these provides insight into the overall performance for a user trying to answer the given topic questions. Based on this year's protocol, each level would be measured by some variant of mean average precision (MAP).</p><p>The passage-level retrieval performance was using character-based MAP, while the aspect-level retrieval performance was using aspect-based MAP and the document-level retrieval performance was using document-based MAP.</p><p>Fig2, fig3 and fig4 are our submitted runs distribution, from which we can see that the first two runs( trecgen1 and trecgen2) are no performs as good as the trec- gen3, which seems that the swallow natural language processing will helps us improve the results. But we can also see that there's no relevant topic for few topic, and we checked out that has lot to do with the initial document level retrieval. For the first step of document level retrieval can not return relevant results, so the next steps can not get a good result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Further Work</head><p>Text mining, especially in the bio-medical field is now really a new and hot research area(Aaron M. <ref type="bibr" coords="5,259.02,426.97,30.45,10.46;5,55.44,438.92,22.14,10.46" target="#b1">Cohen, 2005)</ref>. For the fast increasing bio-medical articles, it will help researchers to find out the useful information which maybe hide deeply in the literatures, and this will save a lot of energy and time for them avoiding to do the same experiments that have had been done. And this year's track has provide a good example for this kind of work. Finding out the most relevant passages to the query and giving the aspect of this passage, which seems very closely to the requirement of real world.</p><p>In out experiment, we have done a lot on finding the most relevant passages, but few work has done about the aspects. In the next experiments, we are planning to use some text clustering methods to cluster the relevant passages in to some smaller sets while the passages in the same set maybe providing the same aspect answer to a certain topic.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,90.20,360.71,164.45,9.41;2,55.44,67.13,232.50,268.32"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The architecture of the system</figDesc><graphic coords="2,55.44,67.13,232.50,268.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,264.96,502.37,19.72,7.32;4,273.24,510.85,3.97,7.32;4,286.67,504.88,2.77,10.46;4,55.44,516.83,128.67,10.46;4,184.10,520.87,2.82,7.32;4,190.52,516.83,98.90,10.46;4,55.44,528.79,155.50,10.46;4,210.93,532.82,2.82,7.32;4,214.25,528.79,26.95,10.46;4,241.20,532.82,3.30,7.32;4,245.40,528.79,44.03,10.46;4,55.44,547.04,78.53,10.46;4,133.98,551.38,3.11,7.32;4,137.59,547.04,19.71,10.46;4,157.29,551.08,2.82,7.32;4,160.61,547.04,11.63,10.46;4,183.94,540.19,2.93,5.23;4,183.94,548.19,2.66,5.23;4,187.67,542.76,13.29,7.32;4,175.21,553.02,23.96,7.32;4,202.15,547.04,2.77,10.46;4,55.44,560.69,52.57,10.46;4,108.01,564.72,2.82,7.32;4,111.32,560.69,178.13,10.46;4,55.44,572.64,54.96,10.46"><head></head><label></label><figDesc>generally, if a passage pasg i was consist of sentence from i• • •j, and which has the score s i , • • •, s j , the score of the passage is s ( pasg i )= j i (st) |pasgi| , where |pasg i | stands for the number of sentences in this passage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,307.44,266.42,233.96,9.41;4,307.44,277.38,27.69,9.41;4,307.44,300.04,234.00,156.14"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The document-level MAP of TREC 2006 Genomics</figDesc><graphic coords="4,307.44,300.04,234.00,156.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,55.44,257.46,232.84,9.41;5,55.44,67.06,234.00,165.15"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The aspect-level MAP of TREC 2006 Genomics</figDesc><graphic coords="5,55.44,67.06,234.00,165.15" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,55.44,682.68,234.01,10.46;5,65.40,694.64,224.04,10.46;5,65.40,706.59,224.06,10.46;5,317.40,68.55,19.52,10.46" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,190.98,682.68,98.47,10.46;5,65.40,694.64,131.78,10.46">Ibm&apos;s statistical question answering system-trec 11</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Ittycheriah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,209.36,694.64,80.08,10.46;5,65.40,706.59,155.09,10.46">Proceedings of the Eleventh Text Retrieval Conference</title>
		<meeting>the Eleventh Text Retrieval Conference<address><addrLine>Gaitherburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,307.44,88.48,234.06,10.46;5,317.40,100.44,224.06,10.46;5,317.40,112.39,73.21,10.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,459.00,88.48,82.50,10.46;5,317.40,100.44,135.99,10.46">A survey of current work in biomedical text mining</title>
		<author>
			<persName coords=""><forename type="first">Aaron</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,463.50,100.44,77.96,10.46;5,317.40,112.39,26.60,10.46">Briefs in Bioinfomatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="57" to="71" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,307.44,132.32,234.04,10.46;5,317.40,144.27,224.10,10.46;5,317.40,156.23,224.05,10.46;5,317.40,168.18,224.07,10.46;5,317.40,180.14,85.29,10.46" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,489.55,132.32,51.93,10.46;5,317.40,144.27,219.52,10.46">Generic soft pattern model for definitional question answering</title>
		<author>
			<persName coords=""><forename type="first">Hang</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T.-S</forename><forename type="middle">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,317.40,156.23,224.05,10.46;5,317.40,168.18,80.06,10.46">Proceedings of the 28th Annual International ACM-SIGIR Conference</title>
		<meeting>the 28th Annual International ACM-SIGIR Conference<address><addrLine>Salvador, Brazil</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="384" to="391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,307.44,200.06,28.04,10.46;5,350.94,200.06,53.31,10.46;5,437.63,200.06,103.81,10.46;5,317.40,212.02,21.26,10.46;5,366.57,212.02,33.50,10.46;5,429.85,212.02,44.83,10.46;5,504.46,212.02,36.98,10.46;5,317.40,223.97,209.71,10.46" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="5,437.63,200.06,103.81,10.46;5,317.40,212.02,21.26,10.46;5,366.57,212.02,33.50,10.46">Trec 2006 genomics track protocol</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hersh</surname></persName>
		</author>
		<ptr target="http://ir.ohsu.edu/genomics/2006protocol.html" />
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="5,307.44,243.90,234.04,10.46;5,317.40,255.85,224.07,10.46;5,317.40,267.81,200.34,10.46" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="5,408.74,243.90,132.74,10.46;5,317.40,255.85,224.07,10.46;5,317.40,267.81,62.76,10.46">Making large-scale svm learning practical. advances in kernel methods -support vector learning</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>MIT-Press</publisher>
			<pubPlace>Cambridge, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,307.44,287.73,234.00,10.46;5,317.40,299.69,224.04,10.46;5,317.40,311.64,70.98,10.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,344.89,287.73,176.74,10.46">Dependency-based evaluation of minipar</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,317.40,299.69,219.36,10.46">Workshop on the Evaluation of Parsing Systems</title>
		<meeting><address><addrLine>Granada, Spain</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,307.44,331.57,234.04,10.46;5,317.40,343.52,224.07,10.46;5,317.40,355.48,224.04,10.46;5,317.40,367.43,224.04,10.46;5,317.40,379.39,166.14,10.46" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,499.12,331.57,42.36,10.46;5,317.40,343.52,224.07,10.46;5,317.40,355.48,80.71,10.46">Quantitative evaluation of passage retrieval algorithms for question answering</title>
		<author>
			<persName coords=""><forename type="first">Stefanie</forename><surname>Tellex</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Boris</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,406.89,355.48,134.55,10.46;5,317.40,367.43,167.62,10.46">Proceedings of the 26th Annual International ACM-SIGIR Conference</title>
		<meeting>the 26th Annual International ACM-SIGIR Conference<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="41" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,307.44,399.31,234.04,10.46;5,317.40,411.27,224.04,10.46;5,317.40,423.22,224.07,10.46;5,317.40,435.18,224.05,10.46;5,317.40,447.14,171.02,10.46" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,411.18,399.31,130.30,10.46;5,317.40,411.27,77.67,10.46">Query expansion using lexicalsemantic relations</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,404.82,411.27,136.62,10.46;5,317.40,423.22,224.07,10.46;5,317.40,435.18,188.13,10.46">Proceedings of the 17th Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 17th Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>ACM/Springer</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="61" to="69" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
