<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.99,104.92,417.17,15.06;1,181.59,122.86,232.02,15.06">Robust Pseudo Feedback Estimation and HMM Passage Extraction: UIUC at TREC 2006 Genomics Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,207.46,162.75,46.43,12.55"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign Urbana</orgName>
								<address>
									<postCode>61801</postCode>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,261.58,162.75,32.20,12.55"><forename type="first">Xin</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign Urbana</orgName>
								<address>
									<postCode>61801</postCode>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,302.42,162.75,85.32,12.55"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign Urbana</orgName>
								<address>
									<postCode>61801</postCode>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.99,104.92,417.17,15.06;1,181.59,122.86,232.02,15.06">Robust Pseudo Feedback Estimation and HMM Passage Extraction: UIUC at TREC 2006 Genomics Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7F1AF921B03A1242C9DDC5D16C8E3FBF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The University of Illinois at Urbana-Champaign (UIUC) participated in TREC 2006 Genomics Track. Our focus this year was to apply two language modeling techniques for information retrieval that have been proposed recently by our group <ref type="bibr" coords="1,91.72,320.14,10.79,10.46" target="#b3">[4,</ref><ref type="bibr" coords="1,105.05,320.14,7.19,10.46" target="#b0">1]</ref>. These two techniques have been shown to be effective for general English text. It is not clear, though, how they perform on text in special domains such as the biomedical domain. We therefore tested their effectiveness for this year's genomics task.</p><p>First, we tried to improve the pseudo relevance feedback mechanism in the retrieval model by applying a recently proposed regularized estimation method <ref type="bibr" coords="1,243.22,403.84,10.58,10.46" target="#b3">[4]</ref>. In the KL-divergence retrieval framework, pseudo relevance feedback documents can be used to better estimate the query model <ref type="bibr" coords="1,77.86,439.70,10.58,10.46" target="#b4">[5]</ref>. While in the original proposed method <ref type="bibr" coords="1,254.92,439.70,10.58,10.46" target="#b4">[5]</ref>, this estimation involved two parameters that need to be empirically set, recent work showed that a more robust, regularized estimation method that involves less parameter tuning can be effective <ref type="bibr" coords="1,137.18,487.52,10.58,10.46" target="#b3">[4]</ref>. We therefore applied this estimation method to this year's genomics task to see whether it can improve the pseudo relevance feedback mechanism in biomedical information retrieval as well. Second, since this year's task is defined as passage retrieval rather than document retrieval, a challenge is how to extract coherent and relevant passages from whole documents. Previously, we proposed a hidden Markov model (HMM)-based passage extraction method that was shown to be effective in the general English domain <ref type="bibr" coords="1,162.95,595.12,10.58,10.46" target="#b0">[1]</ref>. We applied this method to this year's genomics task to see whether this method is also effective for biomedical text.</p><p>Besides the two language modeling techniques, we also tested the use of user relevance feedback for retrieval, to see how much human interaction can help improve the performance. We obtained some manual judgments from two domain experts, and used them in the two interactive runs.</p><p>Our experiment results showed that the regularized estimation method for pseudo relevance feedback performed similarly to the original estimation method when both methods were under the optimal parameter setting, and outperformed the original estimation method when both methods were under the default parameter setting. Because in reality we do not know the optimal parameter setting, the regularized estimation method is thus more robust than the original estimation method. Our experiment results also showed that the HMM-based passage extraction method outperformed a baseline method that returns whole paragraphs as passages. However, our HMM-based passage extraction method tends to return relatively long and coherent passages, which may not be optimal for the genomics task this year, because in this task the information need is more specific. Finally, our experiment results showed that user relevance feedback was very effective, as we expected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Robust Feedback Estimation</head><p>This year's task was defined as a passage retrieval task, where legal passages must be within single paragraphs from the full-text articles. Since the relevant passages are querydependent, they can be of variable length and their boundaries cannot be determined without considering the specific query. We thus divided the task into two steps. For each query, we first retrieved the top 1000 paragraphs using the KL-divergence retrieval method. Then from each of the 1000 paragraphs, we extracted a relevant passage using our HMM-based passage extraction method. We assumed that there was only a single relevant passage within a relevant paragraph for a given query. Although this assumption may not hold in all cases, it is a relatively reasonable assumption, and can greatly simplify the task.</p><p>In the rest of this section, we will discuss the paragraph retrieval subtask, and focus on the pseudo relevance feedback mechanism. Then in Section 3, we will discuss the passage extraction subtask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The KL-Divergence Retrieval Model</head><p>The first subtask is paragraph retrieval, for which we could use any existing document retrieval method. In our experiments, we used the KL-divergence retrieval model, which was first proposed in <ref type="bibr" coords="2,163.66,134.01,10.58,10.46" target="#b1">[2]</ref>. In this model, queries and documents are all represented by unigram language models, which are essentially word probably distributions. Assuming that these language models can be appropriately estimated, KL-divergence retrieval model scores a document D with respect to a query Q by computing the Kullback-Leibler divergence between the query language model θ Q and the document language model θ D as follows:</p><formula xml:id="formula_0" coords="2,74.35,237.20,167.85,28.51">D(θ Q θ D ) = w∈V p(w|θ Q ) log p(w|θ Q ) p(w|θ D ) ,</formula><p>where V is the set of all words in the vocabulary. In practice, for the sake of efficiency, we often truncate the query language model θ Q and use only a certain number of words with the highest probabilities to score documents. In our experiments, we set this number to 50. What remains to be solved is how to appropriately estimate the query language model θ Q and the document language model θ D . θ D is estimated from the document D, and is usually smoothed with a background language model θ B , which is estimated from the whole document collection as follows:</p><formula xml:id="formula_1" coords="2,100.89,411.09,110.80,27.09">p(w|θ B ) = D∈C c(w, D) D∈C |D|</formula><p>, where C is the document collection, c(w, D) is the number of occurrences of word w in document D, and |D| is the length of document D. One of the most effective smoothing methods is the Dirichlet prior smoothing method, as shown below:</p><formula xml:id="formula_2" coords="2,89.10,511.49,138.33,24.03">p(w|θ D ) = c(w, D) + µp(w|θ B ) |D| + µ ,</formula><p>where µ is a parameter that controls the degree of smoothing, and is usually set empirically. In our experiments, we used the Dirichlet prior smoothing method, and set µ to 1000 based on our preliminary experiments with the queries and documents from TREC 2005 Genomics Track. Estimation of the query language model is more complicated. The simplest way to estimate the query language model is to use only the query. θ Q can thus be estimated as follows:</p><formula xml:id="formula_3" coords="2,93.94,657.35,128.67,24.03">p(w|θ Q ) = p(w|Q) = c(w, Q) |Q| ,</formula><p>where c(w, Q) is the number of occurrences of word w in query Q, and |Q| is the length of query Q. However, since queries are usually very short, they can hardly capture the user's information need completely. Several methods have been proposed to improve the estimation of the query language model <ref type="bibr" coords="2,362.54,109.54,10.79,10.46" target="#b1">[2,</ref><ref type="bibr" coords="2,375.82,109.54,7.47,10.46" target="#b2">3,</ref><ref type="bibr" coords="2,385.78,109.54,7.19,10.46" target="#b4">5]</ref>.</p><p>In <ref type="bibr" coords="2,331.43,121.50,10.58,10.46" target="#b4">[5]</ref>, the query language model is estimated as follows. First, we assume there is a set F of feedback documents for the query. These documents can be obtained either from the user explicitly or from the top-ranked documents after the first round of retrieval, in which case they are considered pseudo relevance feedback. We then assume that these feedback documents are generated from a two-component mixture model, where one component is the background language model θ B , and the other component is a topic language model θ T that is related to the query Q. The log likelihood of generating the feedback documents is thus</p><formula xml:id="formula_4" coords="2,322.74,262.90,218.46,38.71">log p(F|θ T ) = D∈F w∈V c(w, D)((1 -α)p(w|θ B ) + αp(w|θ T )),</formula><p>where α is an interpolation parameter that controls the degree to which a feedback document is generated from the topic language model, and is usually empirically set. As proposed in <ref type="bibr" coords="2,359.81,346.82,10.58,10.46" target="#b4">[5]</ref>, the topic language model θ T can be estimated by fixing θ B and α, and maximizing the log likelihood log p(F|θ T ) using the E-M algorithm. Once θ T is estimated, the query language model θ Q is computed as a linear interpolation of the original query language model and the topic language model, as shown below:</p><formula xml:id="formula_5" coords="2,335.11,428.44,163.82,11.36">p(w|θ Q ) = (1 -λ)p(w|Q) + λp(w|θ T ),</formula><p>where λ is another parameter to control the degree to which we trust the estimated topic language model, and is again usually set empirically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Regularized Estimation of the Mixture Models for Feedback Documents</head><p>The above method to estimate the query language model from the feedback documents involves two parameters, α and λ, that need to be empirically set. It has been shown that although the method can perform well, it is sensitive to the setting of both α and λ <ref type="bibr" coords="2,403.15,583.75,10.58,10.46" target="#b4">[5]</ref>. To address this problem, in <ref type="bibr" coords="2,531.01,583.75,10.58,10.46" target="#b3">[4]</ref>, the authors proposed a regularized estimation method.</p><p>First, the authors pointed out that the parameter α should be document-specific because different feedback documents may contain different amount of relevant information. The log likelihood of the feedback documents thus becomes</p><formula xml:id="formula_6" coords="2,318.83,677.33,232.83,38.70">log p(F|Λ) = D∈F w∈V c(w, D)((1 -α D )p(w|θ B ) + α D p(w|θ T )),</formula><p>where Λ = {θ T , {α D } D∈F } is the set of parameters. θ B can still be fixed as before, but both θ T and α D 's are now estimated from the data.</p><p>Second, the authors proposed to use a prior for the topic language model. Previously, there was no constraint imposed on the topic language model. However, the topic language model is expected to be close to the original query language model. The authors therefore proposed to construct a conjugate Dirichlet prior for the topic language model from the original query language model. Formally, the prior states that</p><formula xml:id="formula_7" coords="3,96.62,214.39,123.31,23.34">p(θ T ) ∝ w∈V p(w|θ T ) µp(w|Q) ,</formula><p>where µ is a parameter that indicates the confidence on the prior. The authors did not impose any prior on the parameter α D 's. As a result, the prior for all the parameters is</p><formula xml:id="formula_8" coords="3,80.13,291.38,156.28,23.34">p(Λ) ∝ p(θ T ) ∝ w∈V p(w|θ T ) µp(w|Q) .</formula><p>Using maximum a posterior (MAP) estimation, the parameters Λ = {θ T , {α D } D∈F } can be estimated as follows:</p><formula xml:id="formula_9" coords="3,104.69,353.80,108.14,20.75">Λ = arg max Λ p(F|Λ)p(Λ).</formula><p>It can be shown that this MAP estimation can be implemented by modifying the M-step in the E-M algorithm. The updating formulas for the E-M algorithm thus become the following: E-step:</p><formula xml:id="formula_10" coords="3,62.07,451.49,209.46,159.96">p(Z w,D = 1) = α (n) D p (n) (w|θ T ) α (n) D p (n) (w|θ T ) + (1 -α (n) D )p(w|θ B ) . M-step: α (n+1) D = w∈V p(Z w,D = 1)c(w, D) w∈V c(w, D) , p (n+1) (w|θ T ) = µp(w|Q) + D∈F p(Z w,D = 1)c(w, D) µ + w ∈V D∈F p(Z w ,D = 1)c(w , D) .</formula><p>In this model, the parameter µ can be manually set, but the authors observed two problems with a fixed value of µ.</p><p>(1) µ should be dependent on the amount of relevant information accumulated from the feedback documents, which is not know beforehand. (2) On the one hand, µ needs to be set to a large value in order for the topic language model θ T to stay close to the original query language model; otherwise, θ T could be easily drifted away to fit the popular topic(s) in the feedback documents. On the other hand, setting µ to a large value would prevent θ T from picking up from the feedback documents those query-related words that do not occur in the query. To solve this dilemma, the authors then proposed to use a regularized estimation method in which the parameter µ is initially set to a large value, and gradually decreased during the E-M iterations. This allows the topic language model θ T to start from a model very close to the original query model, and then gradually deviate from the original query model to fit the data, i.e. the feedback documents. The authors introduced a parameter η to control when to stop the E-M iteration. Define</p><formula xml:id="formula_11" coords="3,339.85,229.75,154.36,21.77">r = w ∈V D∈F c(w , D)p(Z w ,D = 1),</formula><p>the E-M iterations will stop when µη ≤ r.</p><p>We applied this new method in our experiments to incorporate either pseudo relevance feedback or user relevance feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">HMM Passage Extraction</head><p>As we have discussed in Section 2, the second subtask is passage extraction. Since the relevant passages are queryspecific, the passage boundaries should be determined dynamically based on the specific query. In our experiments, we applied a hidden Markov model (HMM)-based passage extraction method, which we proposed in <ref type="bibr" coords="3,477.16,414.80,10.58,10.46" target="#b0">[1]</ref>. This method has been shown to be effective on some general English corpora.</p><p>The intuition behind this method is that a relevant document containing a relevant passage and some non-relevant parts can be seen as a sequence of words generated from a linear hidden Markov model, where the relevant passage is generated from a relevance state that emits words according to a relevance language model (i.e. a relevance word probability distribution), and the non-relevant parts are generated from a number of background states that emits words according to a background language model. If the emission probabilities and the transition probabilities of the hidden Markov model are set appropriately, given a document, we can decode this sequence of words and find the sequence of states that have generated this word sequence with the highest probability. This state sequence tells us which words are generated from the relevance state and thus which part of the document belongs to the relevant passage.</p><p>Figure <ref type="figure" coords="3,351.54,642.93,4.98,10.46">1</ref> shows the actual hidden Markov model we used. R is the relevance state, which has an emission probability distribution (i.e. the relevance language model) highly related to the query we consider. For example, this language model can be set to the original query language model as defined in Section 2. B 1 and B 3 are background states that generate the non-relevant text before and after the relevant passage in the document. B 2 is a background state for smoothing because a relevant passage also contains words that are not in the query. Words generated by state R and state B 2 are all considered inside the relevant passage. The emission probability distribution at states B 1 , B 2 and B 3 is estimated by the whole document collection, as in Section 2.</p><p>The transition probabilities in the hidden Markov model can affect the length of the relevant passage. For example, large transition probabilities from R to R, from B 2 to B 2 , and between R and B 2 would result in a relatively long relevant passage. Since passage length is query-dependent, these transition probabilities should not be manually fixed. What we proposed to do is to estimate these transition probabilities for each document by unsupervised learning. In another word, we try to find the transition probabilities that can maximize the likelihood of the document (word sequence) using the Baum-Welch algorithm, which is essentially an EM algorithm.</p><p>This HMM-based passage extraction also allows using relevance feedback to improve the estimation of the relevance language model at state R. Instead of using the original query language model, we can set the relevance language model at state R to a feedback language model θ F , where θ F is estimated from the relevant passage extracted from the same document after a first round of passage extraction. Figure <ref type="figure" coords="4,403.28,109.54,4.98,10.46">2</ref> illustrates this idea. Starting from a conservative relevance language model at state R, we can obtain a short and presumably accurate relevant passage. There may be relevant text surrounding this short, accurate passage. Let this starting short passage be P . We can then set the relevance language model at state R to</p><formula xml:id="formula_12" coords="4,352.90,189.68,128.25,24.03">p(w|θ R ) = p(w|P ) = c(w, P ) |P | ,</formula><p>where c(w, P ) is the number of occurrences of word w in P , and |P | is the length of P . In this way, state R can now attract not only query words but also query-related words that are seen in the starting passage. The passage boundary can thus be extended to the natural topical boundary.</p><p>In our experiments, we applied our HMM-based passage extraction method, where we used paragraphs as documents. However, since learning the transition probabilities for each paragraph individually would be too timeconsuming, we first trained the HMM on a sample of paragraphs, and used the average transition probabilities learned from these paragraphs for all paragraphs. Again, to save time, for state R, we simply used the original query language model. But we extended the extracted passage to the nearest sentence boundary at both ends.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">User Relevance Feedback</head><p>Besides the two language modeling techniques shown above, we also experimented with user relevance feedback, in order to see how much true relevance feedback can help improve the performance compared with pseudo relevance feedback.</p><p>To obtain user relevance feedback, we first used KLdivergence retrieval method to retrieve top 10 paragraphs for each query. We then asked two domain experts to judge the relevance of these top 10 paragraphs for each query. The paragraphs that were judged to be relevant were then used for feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Official Runs</head><p>We submitted three official runs, including an automatic run, UIUCauto, and two interactive runs, UIUCinter and UIUCinter2. For all three runs, we first retrieved 1000 paragraphs using the KL-divergence retrieval model. Then from each retrieved paragraph, we used the HMM-based passage extraction method to extract the most relevant passage. In UIUCauto, we used pseudo relevance feedback with the regularized estimation of the feedback mixture models, as discussed in Section 2. The top 10 documents for each query were used for pseudo relevance feedback. We used the default parameter η = 1.</p><p>In UIUCinter and UIUCinter2, we used user relevance feedback. In UIUCinter, the feedback mechanism was the same as in UIUCauto, that is, we also used the regularized feedback estimation method with η = 1. In UIUCinter2, we used the original feedback estimation method as proposed in <ref type="bibr" coords="5,60.91,277.64,10.58,10.46" target="#b4">[5]</ref>. We manually set the two parameters λ = 0.75 and α = 0.5. λ was set to a value greater than the default value 0.5 because we believe we should trust these true relevance feedback documents more.</p><p>Table <ref type="table" coords="5,86.43,326.04,4.98,10.46" target="#tab_0">1</ref> shows the performance of the three official runs. As we can see, using user relevance feedback performed better than using pseudo relevance feedback, which is not surprising. However, using the original feedback estimation method (UIUCinter2) performed better than using the regularized estimation method (UIUCinter). Because we used the default parameter value for the regularized estimation method but non-default parameter values for the original estimation method, we could not directly draw any conclusion from the comparison between UIUCinter and UIUCinter2.</p><p>In order to study compare the regularized feedback estimation method with the original estimation method under the same setting, and to evaluate the HMM-based passage extraction method, we ran a number of diagnostic experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Pseudo Relevance Feedback</head><p>First, we compared the performance of using pseudo relevance feedback with that of using no feedback. We show this comparison in Table <ref type="table" coords="5,149.44,571.20,3.74,10.46" target="#tab_1">2</ref>. In the baseline method, we used the KL-divergence retrieval method and a Dirichlet prior for smoothing with µ = 1000. No feedback was used in the baseline method. We then used the original feedback estimation method to incorporate pseudo relevance feedback. The top 10 documents for each query were used. Similarly, we used the regularized feedback estimation method with the top 10 documents for each query. For both feedback methods, we show the performance of two settings in the table: a default parameter setting, and an optimal parameter setting obtained by parameter tuning. Note that the regularized estimation method with the default parameter setting  corresponds to the official run UIUCauto.</p><p>We can see from Table <ref type="table" coords="5,421.68,399.97,4.98,10.46" target="#tab_1">2</ref> that using pseudo relevance feedback with both estimation methods outperformed the baseline method. When the parameters were set to the optimal values, the two estimation methods performed similarly. But when the parameters were set to the default values, the regularized estimation method outperformed the original estimation method. Since in reality we cannot tune the parameters, the regularized estimation method is more robust than the original estimation method in practice.</p><p>To see how the number of pseudo relevance feedback documents affects the performance and how sensitive the two estimation methods are to this number, we tried a set of different numbers of feedback documents. The optimal parameter setting for each estimation method was used. Table <ref type="table" coords="5,323.93,571.20,4.98,10.46" target="#tab_2">3</ref> shows the results. We can see from the table that using more feedback documents decreased the performance. When the number of feedback documents was relatively small (under 50), the performance of the regularized estimation method did not decrease as much as the original estimation method. But for larger number of feedback documents (100 and above), the regularized estimation method performed worse than the original estimation method. Overall, it is not clear whether the original estimation method is more sensitive to the number of feedback documents than the regularized estimation method. This is different from what was found in <ref type="bibr" coords="5,384.57,702.71,10.58,10.46" target="#b3">[4]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">HMM-based Passage Extraction</head><p>To see the effectiveness of the HMM-based passage extraction method, we compared with a baseline method which returns whole paragraphs as passages. Recall that we treated paragraphs as documents and used KL-divergence method to retrieve paragraphs before we extracted the relevant passages within each retrieved paragraph. Therefore, this baseline method simply excluded the passage extraction step. For each of UIUCauto, UIUCinter and UIUCin-ter2, we applied this baseline method. Table <ref type="table" coords="6,237.68,367.27,4.98,10.46" target="#tab_3">4</ref> shows the comparison between the two methods. We can see that the HMM-based passage extraction method outperformed the baseline method in all three cases.</p><p>However, compared with the true relevant passages, the passages extracted by the HMM-based method were still far from optimal. In Table <ref type="table" coords="6,161.49,439.70,3.74,10.46" target="#tab_4">5</ref>, we list the maximum length (MAX), minimum length (MIN), average length (AVG) and the standard deviation of the length for three kinds of passages. The first kind of passages are the true relevant passages. The second are the passages that are returned by the HMM-based method and that overlap with some true relevant passages. We only consider these overlapping passages because we do not want the retrieval performance to affect this analysis. The third kind of passages are whole paragraphs that overlap with some true relevant passages. As we can see from the table, the passages extracted by the HMM-based method are much longer than the true relevant passages on average. To see why our passages are in general longer, we examined some passages. Table <ref type="table" coords="6,281.38,595.12,4.98,10.46">6</ref> shows such an example. We can see that in this example, our passage has two more sentences than the true passage. This is because the last sentence in our passage contains the word "diseases", which is a query word. Our passage indeed represents a coherent piece of text, which is exactly what the HMM-based method tries to do. However, such kind of passages may be at a coarser granularity than what the genomics task desires. The passages extracted by the HMM-based method can be seen as upper bounds for the true passages. One way to modify the HMM method to fit this task is maybe to use the document language model as the background model in the HMM structure. This change would make it easier for the HMM to distinguish a query-related region and the background regions in the document. We experimented with this idea, and found it helpful in a few cases. However, further investigation is needed to understand the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">User Relevance Feedback</head><p>Finally, we show the effect of using user relevance feedback. Similar to pseudo relevance feedback, we also used the two estimation method to estimate a topical language model from the feedback documents. The only different is that here we used true relevance feedback documents from domain experts. Some topics had no true relevant documents among the top-10 retrieved documents, so for these topics, we did not use any feedback. Table <ref type="table" coords="6,483.82,521.21,4.98,10.46" target="#tab_5">7</ref> shows the results. We can see that true relevance feedback is indeed more effective than the pseudo relevance feedback. The optimal parameter values reflect the fact that we should trust the true relevance feedback documents more than the pseudo relevance feedback documents. However, in reality, we still do not know the optimal parameter values. If we choose to use the default parameter setting, the regularized estimation method can still outperform the original estimation method, as shown in the table.</p><p>The regularized estimation method with default parameter setting in Table <ref type="table" coords="6,397.94,654.90,4.98,10.46" target="#tab_5">7</ref> should correspond to UIUCinter. However, in UIUCinter, we made a mistake by using the results from UIUCauto for those topics that did not get any judged relevant documents. As a result, UIUCinter performed worse than it should be.</p><p>Prion diseases, which include Creutzfeldt-Jacob disease in humans, mad cow disease in cattle, and scrapie in sheep, involve the misfolding of the benign cellular prion protein (PrP C) 1 to the infectious disease-causing scrapie isoform PrP Sc. The prion protein (PrP C) is a copper-binding cell surface glycoprotein. The role of copper in the normal function of PrP, as well as in prion diseases, has been the subject of a number of excellent reviews. The mature cellular form of PrP consists of residues 23 to 231 and is tethered to the cell surface via a glycosylphosphatidylinositol anchor at the C terminus. There are now a number of NMR solution structures of copper-free mammalian PrPs. A crystal structure of PrP C has also been published; this structure is dimeric involving domain swapping of the monomeric form. Table <ref type="table" coords="7,73.07,174.63,3.32,8.37">6</ref>. A passage example. The whole paragraph is a single paragraph from the original article. The words in italic type are inside the passage extracted by the HMM-based method. Words in bold type are inside the true passage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Summary</head><p>In summary, in this year's Genomics Track, we focused on testing the effectiveness of two language modeling techniques for information retrieval on biomedical text. The general observation is that the two techniques are still effective to some degree on biomedical text. The regularized feedback estimation method is more robust than the original feedback estimation method because it needs less parameter tuning. The HMM-based passage extraction method can outperform paragraph-based passages. However, since the HMM-based method is not designed to extract short passages with very specific information, it needs some modification in order to fit this task. Finally, user relevance feedback is very effective.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,82.54,186.09,171.43,8.37"><head>Figure 1 .Figure 2 .</head><label>12</label><figDesc>Figure 1. A 5-state HMM for passage extraction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,65.87,72.47,204.73,65.90"><head>Table 1 .</head><label>1</label><figDesc>Results of the three official runs.</figDesc><table coords="5,65.87,72.47,204.73,49.52"><row><cell></cell><cell cols="3">Doc MAP Psg MAP Asp MAP</cell></row><row><cell>UIUCauto</cell><cell>0.3842</cell><cell>0.04864</cell><cell>0.2407</cell></row><row><cell>UIUCinter</cell><cell>0.4176</cell><cell>0.05906</cell><cell>0.2976</cell></row><row><cell>UIUCinter2</cell><cell>0.4243</cell><cell>0.06038</cell><cell>0.2900</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,308.87,153.92,236.30,158.33"><head>Table 2 .</head><label>2</label><figDesc>Pseudo relevance feedback using two feedback estimation methods (#Doc = 10).</figDesc><table coords="5,357.66,191.81,138.66,120.44"><row><cell></cell><cell cols="2">Doc MAP</cell></row><row><cell>#Doc</cell><cell>Original</cell><cell>Regularized</cell></row><row><cell></cell><cell cols="2">Estimation Estimation</cell></row><row><cell>10</cell><cell>0.3943</cell><cell>0.3942</cell></row><row><cell>20</cell><cell>0.3879</cell><cell>0.3934</cell></row><row><cell>30</cell><cell>0.3811</cell><cell>0.3801</cell></row><row><cell>50</cell><cell>0.3709</cell><cell>0.3725</cell></row><row><cell>100</cell><cell>0.3563</cell><cell>0.3473</cell></row><row><cell>150</cell><cell>0.3547</cell><cell>0.3523</cell></row><row><cell>200</cell><cell>0.3521</cell><cell>0.3465</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,308.87,320.26,236.30,36.77"><head>Table 3 .</head><label>3</label><figDesc>Pseudo relevance feedback using two feedback estimation methods with different numbers of feedback documents. For the original estimation method, λ = 0.8 and α = 0.8. For the regularized estimation method, η = 3.0.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,50.11,72.47,236.30,151.13"><head>Table 4 .</head><label>4</label><figDesc>Comparison between whole paragraphs as passages and passages extracted by the HMM-based method.</figDesc><table coords="6,82.85,72.47,170.76,125.23"><row><cell></cell><cell></cell><cell>Psg MAP</cell></row><row><cell></cell><cell>Paragraph</cell><cell>0.03753</cell></row><row><cell>UIUCauto</cell><cell>HMM Passage</cell><cell>0.04864</cell></row><row><cell></cell><cell>Rel. Impr.</cell><cell>29.6%</cell></row><row><cell></cell><cell>Paragraph</cell><cell>0.04481</cell></row><row><cell cols="2">UIUCinter HMM Passage</cell><cell>0.05906</cell></row><row><cell></cell><cell>Rel. Impr.</cell><cell>31.8%</cell></row><row><cell></cell><cell>Paragraph</cell><cell>0.04580</cell></row><row><cell cols="2">UIUCinter2 HMM Passage</cell><cell>0.06038</cell></row><row><cell></cell><cell>Rel. Impr.</cell><cell>31.8%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,312.63,72.47,228.78,156.17"><head>Table 5 .</head><label>5</label><figDesc>Some statistics of the length of three kinds of passages.</figDesc><table coords="6,323.05,72.47,207.86,156.17"><row><cell></cell><cell cols="2">MAX MIN</cell><cell>AVG</cell><cell>STD</cell></row><row><cell>True Psg</cell><cell>6928</cell><cell>27</cell><cell>399.8</cell><cell>489.4</cell></row><row><cell>HMM Psg</cell><cell>6955</cell><cell>34</cell><cell cols="2">1525.8 949.7</cell></row><row><cell>Paragraph</cell><cell>8670</cell><cell>60</cell><cell cols="2">2105.4 1136.8</cell></row><row><cell></cell><cell>Method</cell><cell></cell><cell></cell><cell>Doc MAP</cell></row><row><cell></cell><cell>Baseline</cell><cell></cell><cell></cell><cell>0.3484</cell></row><row><cell>Original</cell><cell cols="3">Def (λ = 0.5, α = 0.5)</cell><cell>0.3986</cell></row><row><cell cols="4">Estimation Opt (λ = 0.9, α = 0.9)</cell><cell>0.4511</cell></row><row><cell>Regularized</cell><cell cols="3">Def (η = 1.0)</cell><cell>0.4261</cell></row><row><cell>Estimation</cell><cell cols="3">Opt (η = 6.0)</cell><cell>0.4509</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,308.87,236.65,236.30,17.84"><head>Table 7 .</head><label>7</label><figDesc>User relevance feedback using two feedback estimation methods.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7">Acknowledgments</head><p>We thank <rs type="person">Xu Ling</rs> for judging the results to provide user relevance feedback. We thank <rs type="person">Matt J. Wood</rs> and <rs type="person">Fabien Campagne</rs> for providing a sentence locator tool. We also thank <rs type="person">Martijn Schuemie</rs> for the parsed HTML documents.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="7,66.71,528.30,219.55,9.41;7,66.71,539.25,219.60,9.41;7,66.71,550.22,153.96,9.41" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,142.45,528.30,143.81,9.41;7,66.71,539.25,101.12,9.41">Extraction of coherent relevant passages using hidden markov models</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,174.63,539.25,111.68,9.41;7,66.71,550.22,69.94,9.41">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="295" to="319" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,66.71,561.15,219.55,9.41;7,66.71,572.11,219.55,9.41;7,66.71,583.07,219.55,9.41;7,66.71,594.03,219.55,9.41;7,66.71,604.98,90.50,9.41" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,158.91,561.15,127.36,9.41;7,66.71,572.11,202.77,9.41">Document language models, query models, and risk minimization for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,66.71,583.07,219.55,9.41;7,66.71,594.03,219.55,9.41;7,66.71,604.98,64.22,9.41">Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR&apos;01)</title>
		<meeting>the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR&apos;01)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,66.71,615.92,219.55,9.41;7,66.71,626.88,219.58,9.41;7,66.71,637.83,219.55,9.41;7,66.71,648.80,112.30,9.41" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,171.27,615.92,115.00,9.41;7,66.71,626.88,9.15,9.41">Relevance-based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,96.33,626.88,189.96,9.41;7,66.71,637.83,219.55,9.41;7,66.71,648.80,86.02,9.41">Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieal (SIGIR&apos;01)</title>
		<meeting>the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieal (SIGIR&apos;01)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,66.71,659.73,219.55,9.41;7,66.71,670.69,219.62,9.41;7,66.71,681.64,219.55,9.41;7,66.71,692.61,219.65,9.41;7,66.71,703.56,20.17,9.41" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,141.26,659.73,145.00,9.41;7,66.71,670.69,146.58,9.41">Regularized estimation of mixture models for robust pseudo-relevance feedback</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,232.22,670.69,54.11,9.41;7,66.71,681.64,219.55,9.41;7,66.71,692.61,215.77,9.41">Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR&apos;06)</title>
		<meeting>the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR&apos;06)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,325.46,212.93,219.55,9.41;7,325.46,223.89,219.62,9.41;7,325.46,234.85,219.55,9.41;7,325.46,245.80,156.36,9.41" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,408.65,212.93,136.36,9.41;7,325.46,223.89,151.69,9.41">Model-based feedback in the language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,491.92,223.89,53.17,9.41;7,325.46,234.85,219.55,9.41;7,325.46,245.80,129.69,9.41">Proceedings of the 10th ACM International Conference on Information and Knowledge Management (CIKM&apos;01)</title>
		<meeting>the 10th ACM International Conference on Information and Knowledge Management (CIKM&apos;01)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
