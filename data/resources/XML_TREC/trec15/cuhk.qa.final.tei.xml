<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,80.40,81.14,450.65,12.91">Using Semantic Relations with World Knowledge for Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,239.16,129.45,57.06,10.76"><forename type="first">Ka</forename><forename type="middle">Kan</forename><surname>Lo</surname></persName>
							<email>kklo@se.cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Systems Engineering and Engineering Management</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,325.35,129.45,47.36,10.76"><forename type="first">Wai</forename><surname>Lam</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Systems Engineering and Engineering Management</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,80.40,81.14,450.65,12.91">Using Semantic Relations with World Knowledge for Question Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5CFA2E2E35230C703832BC7E149DF16D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Two research directions are to be explored in realizing our group's TREC QA system in 2006. The first one is to investigate the possibilities of applying linguistically sophisticated grammatical framework in tackling the realworld natural language processing task such as question answering. The other is to exploit the possible world's entities and relations as described in online encyclopedia in adding redundancy and hidden relations as those contained in the TREC corpus where the entities and relations are only implicitly mentioned and related. Our focus is on the factoid and list question as these two types of questions benefit greatly from our proposed method. We do include an experimental component in handling the "other" question type.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction and Previous Work</head><p>Current approaches in QA task have applied natural language processing or computational linguistic techniques in various ways. Earlier works, while not using the precise language methodologies, shed some lights on the inherent complexity of the language task. Simple regular expressions have been a common practice in matching the particular question patterns to an answer type. Though some successes have been achieved in the earlier phase of QA, as the complexity of the tasks increases and the relationships between the question and answer share far less similarities in the surface order of the words, the performance of this method quickly declines in tackling more real-world type questions.</p><p>Later approach in applying natural language processing method requires more sophisticated grammar approach in capturing the syntactic relations between the entities in a sentence. One example is the use of dependency grammar as in Minipar. This type of grammatical framework is chosen because of the rather simplicity of the backbone describing the different linguistic phenomena and efficient mechanism in parsing. The relatively high efficiency in parsing is critical to the realworld natural language task as several thousands of documents have to be processed in a short time interval. In addition, instead of pure part-of-speech information as obtained by probabilistic CFG parser, the Minipar produces a more detailed analysis about the dependency relations that benefits greatly in the answer extractions.</p><p>In our approach, we use a more linguistically sophisticated grammar to analyze the candidate sentences to look for potential answers. The potential to use more detailed analysis of natural language sentences is explored. Based on this analysis, the sentences are broken into more detailed syntactic and semantic description for facilitating the answer extraction process.</p><p>Besides the adoption of more complex grammatical framework, the possibilities of using external resources are also explored. Current approaches in QA have also made use of the external resources to improve the redundancy of the potential answers. Some systems make use of a search engine to expand the queries to the TREC corpus and to extract a relevant set of documents from web for answer extraction. Other approach involved using WordNet or FrameNet to provide ontological relations between entities within the corpus. WordNet and FrameNet are chosen because of the very detail analysis of the senses of different words and the relationships between different senses. More details relations such as hypernyms, hyponyms, and synonyms to compile a network of relations of words for question processing and answer extractions. Some other approaches also used the ontology dictionary and online encyclopedia to improve the redundancy of the answers.</p><p>In our approach, we choose the online encyclopedia as a major source of external resources. Besides improving redundancy of the answers by providing by a larger set of relevant documents, the inter-relationships between the relevant documents are also extracted for the analysis of questions and answer extraction.</p><p>The rest of the paper is organized as follows. In Section 2, we discuss the architecture of the QA system. In Section 3 we detail the method of using grammatical framework to analyze the candidate sentences and answer extractions. Section 4 describes the usage of the external resources in providing a more inter-relationships among entities. Section 5 describes the definitional question processing. Section 6 gives the conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head><p>The general architecture of the system is given in figure <ref type="figure" coords="2,293.51,259.94,5.03,8.97" target="#fig_0">1</ref> The various components of the QA system are described in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Indexing</head><p>The major document resources used in the QA system are the TREC corpus and the Wikipedia corpus. The indexes for these two resources are built up using the LEMUR toolkit. The Wikipedia corpus, which is obtained in May, is first transformed into the TREC corpus format and the extra tags within the corpus are removed to facilitate the parsing of the documents by the LEMUR parsers. A total of 2GB and 3.5GB indexes were built for these two corpora respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Question Preprocessing and Query Expansion</head><p>The question preprocessing phase involves question rewriting and question classification. These two operations use rule-based approach to substitute missing or inadequate information into the questions and classify the questions into one of the sixty-two different types of questions for further processing. For the question preprocessing, some common tasks to be performed are: 1PE. Pronoun matching, 2. Term Expansion, 3. Event-type question special processing and so on. These operations increase the recall of the retrieved document sets in the later and the precision of the candidate sentence extractions. The question is also classified based on whether the question is asking for a person, corporate, time, geographical location such as countries or cities,... , natural places such as hills, seas, lakes,... , time whether year, month, day, date, basic items or description such as profession, colors,... , and special type such as reasons, causes,... The query expansion phase expands the questions to a more detailed query. In expanding the query, we use the search engine API. The preprocessed question is tokenized and fed to the search engine. The top 10 results are retrieved. The texts in the top results are extracted and form a candidate set of terms.</p><p>Besides using the web resources, the preprocessed question is also fed to the index of Wikipedia resource. The texts from the retrieved top 10 documents are extracted. Only terms with external linkages are extracted and merged with the previous set of terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Document Retrieval</head><p>The combined set of terms is ranked on the co-occurrence value of terms. Only the terms in the top 50% of the cooccurrence value is used in document retrieval.</p><p>The expanded query is fed into the document retrieval based on the LEMUR index. In retrieving the documents, we select the top 100 documents for each question in each series. For the Wikipedia data set, the top 10 documents extracted are passed on to the next phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Candidate Answer Sentences Processing</head><p>Quite a number of tasks are performed in this phase before the real matching process. The retrieved documents from both indexes are segmented into sentences. Named entity recognition is performed on both document sets to discover the special entities. For the Wikipedia data set, we also make use of the links to determine the potential candidates for entities.</p><p>The extracted set of sentences, typically from two thousands to sixteen thousands, is then ranked based on the word density ranking method.</p><p>The final set of fifty sentences are extracted with their respective previous one and next sentences extracted. Thus, a total of fifty core sentences and one hundred peripheral sentences are extracted for answer extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Wikipedia data processing</head><p>The extracted 10 documents from Wikipedia are processed based on Section 4. The result is a network of inter-relationship between different entities that may be the final answer in a candidate question. Sometimes, the 10 documents are not closely inter-related with each others. Extracted documents are extracted and processed to fill up the missing links.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Answer extraction</head><p>The fifty core extracted sentences and the one hundred peripheral sentences from the Candidate Answer Sentences processing are passed to the extraction module. In this module, the question and candidate answers are parsed, the semantic relations are obtained. The semantic relations between the questions and the answer sentences are then compared based on the level of consistency as well as the linkages from the Wikipedia. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">List Question Processing</head><p>The list question processing module uses the same answer extraction as the normal factoid questions, i.e. using different phases such as question preprocessing, query expansion, candidate answer sentences processing and answer extraction, with an additional mechanism to select the highest ranked list of answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8">Definition Question Processing</head><p>We also use an experimental definition question processing mechanism in handling the definitional questions. Due to the incompatibility of the current design of our QA system to this type of question, we are trying to get some experiences in dealing with the definitional question in this year's QA task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Extracting answers for factoid question and list questions</head><p>The goal of this task is to extract the best answers from the corpus to answer the question. The actual operations of our QA system require this task to be integrated with the tasks of the Wikipedia data processing. For ease of demonstration, we concentrate on the use of grammatical framework in this section. The PET parser (0; 0), which uses the English Resource Grammar (0) as the source of lexicons, does not have a wide coverage in covering most of the lexical items in the texts. We thus have to modify the original PET parser a little bit and populate the lexicon system with a larger set of lexicons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Parsing</head><p>To populate the lexicon, the first problem we need to solve is the multiword expression. The first approach to deduce the basic syntactic type of a particular chunk of words is the use of a named entity tagger to discover a chunk of words as well as whether a particular chunk of words belong to the class of person, location, organization, time and currency. These chunk of words are then stored as a single unit for later processing. The other approach is to check the particular words expression against the Wikipedia to discover whether a particular chunk of words are belonging to some real world entities. This reduces the burden of the further grammatical processing.</p><p>Consider the question q141.5:</p><p>Who is Warren Moon's agent? Instead, Moon flew to Los Angeles, where he huddled with his agent, Leigh Steinberg, who has apparently convinced Moon that the Seahawks owe him a ton of career-ending cash.</p><p>The named entity tagger discovers that the answer "Leigh Steinberg" is of the type "person" and the Wikipedia can locate this entry as a chunk of words.</p><p>Using the named entity tagger sometimes fails to find the entire name which may be very important in the final answer selection process. For example in question q153.3:</p><p>What was Hitchcock's first movie? #NYT19990808.0091#Then there's the TV anthology series, "Alfred Hitchcock Presents," which ran between 1955 and 1965 (" Gooood evening, laaadies and gen-tell-men"). # Prev: #1#NYT19990808.0091#Books? During the past two decades, Hitchcock has become the filmmaker most written about, a publishing phenomenon second only to Princes Di and the Kennedys biographies, memoirs, critical studies, trivia and quiz books, chronicles of the making of "Psycho" and "Vertigo."# Next: #0#NYT19990808.0091#It has been regularly in syndication ever since, engendering its own books, fan following and Web sites. #</p><p>The phrase "Alfred Hitchcock Presents", which is an answer to the question, cannot be detected by the name entity tagger. However, the chunk is detected with the external resources. Besides the entities expansion, there are other words that both resources cannot cover. In this case, WordNet is consulted to find the relevant sense to be used in the parsing process. The expanded lexicon system is then used for parsing. The resulting parse tree and the semantic representation is given below figure <ref type="figure" coords="4,293.51,497.66,5.03,8.97" target="#fig_1">2</ref> and figure <ref type="figure" coords="4,114.43,509.66,5.03,8.97">3</ref> for the example sentence "What position did Moon play in professional football?" from q141.1.</p><p>The most important data structure that the questions and the answers are compared is the semantic representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Semantic Ranking</head><p>From the semantic representation, each word consists of a list of argument roles, namely ARG0, ARG1 and ARG2. Though, we performed some experiments on the possibilities of using other parameters to further improve the accuracy of the extraction process and with improvements in the results, however, the overall experimental perfor- mance is not as high as expected and considerable computational overhead is added to the extraction process. We thus neglect these parameters and focus on the argument role to do the extraction.</p><p>Based on the similarity between the argument roles, the core and peripheral sentences are ranked for answer projection and extraction.</p><p>Similar strategies are also used to rank the sentences from the Wikipedia data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Answer Projection and extractions</head><p>A set of answer nuggets are obtained from the major corpus and the Wikipedia data set. The answer set is extracted based on whether the nuggets match the entity type expected by the questions, the consistency between the nuggets obtained from the major corpus and the Wikipedia data set and the consistency of the argument roles filled by a particular name entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Uses of external resources for better answer extraction</head><p>In addition to the grammatical process, we also try to process the external resources systematically to help us project the answer back to the corpus. The only external resources that we processed in this year's QA task are the Wikipedia. The link structure between the Wikipedia actually provides a projection of the world event. Though the total world projected by the Wikipedia sometimes cannot match precisely to the world projected by the text in the TREC corpus, the systematic use of this type of resource can provide a better estimation and some hidden facts in the TREC corpus that may be critical in obtaining a more accurate answer. Though the 3 sentences fragment do say something about Janet Reno in 1993, however, the relations between Janet Reno, the year 1993 and the position she had were unclear. However, following our link algorithm on this entry text, the relations between "Janet Reno", "1993", "Attorney General" are related in this way: "Attorney General" "United States Attorney General "Janet Reno <ref type="bibr" coords="5,370.02,181.58,63.51,8.97">March 12, 1993</ref><ref type="bibr" coords="5,435.81,181.58,31.15,8.97;5,319.20,193.46,34.98,8.97">January 20, 2001</ref> Bill Clinton" Thus, the question and candidate answers and the world can be linked up for more accurate answer extraction.</p><p>The process of systematic extraction is as follows: From the question and candidate answer sentences, a set of entities are extracted by the earlier result of name entity tagger and Wikipedia lookup. The links are then traced based on the link index we build up for the Wikipedia text. The potential answer sets are those entries with forward and backward links connected, i.e. a cycle is formed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Definitional Question Processing</head><p>Since the method we used for the factoid and list questions seem to be not applicable to the definitional type question, we just use the simple terms matching process and redundancy removal to extract the definitional sentences. A set of 500 documents are retrieved based on the question series to the TREC document index. The sentences within the 500 documents are then processed to discover a set of commonly co-occurring set of words. A vector is formed based on the set of words with the highest co-occurrence. This approach, using a set of commonly co-occurring words or centroid words is described in (0). The set of sentences within the 500 documents are ranked based on the centroid word using simple vector matching approach. These sets of sentences are then compared against the list of sentences that are extracted for factoid and list answer extraction based on the vectorbased matching. The redundancy sentences, which have a high similarity measures with the answer extraction sentences are removed. The top-N sentences, after the removal process, will be extracted as the definitional sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have described our approach in our new QA system. It includes using more sophisticated grammatical framework, the projection and mapping of the real world onto the TREC corpus and a currently rather simple approach in the definitional question processing system. The current approach, which is still quite immature, has a lot of rooms for improvements. The current procedure in extrapolating the lexicon is not adequate and misses a lot of analytical details for further parsing process. Better approach in extrapolating the lexicon is needed. Current approach in using the world resources and projection back to the TREC corpus is insufficient and there is still a large error in tracing the link structure. More robust link relation extraction procedure is expected for better projection onto the TREC corpus. The definitional question processing, which is very primitive in the current approach, has to be upgraded substantially for future QA system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,208.20,370.70,195.51,8.97;3,50.88,72.27,509.84,283.29"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: General Architecture of the QA system</figDesc><graphic coords="3,50.88,72.27,509.84,283.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,364.32,348.62,124.55,8.97;4,313.20,106.66,226.77,226.77"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Syntactic parse result</figDesc><graphic coords="4,313.20,106.66,226.77,226.77" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,72.00,247.34,226.66,8.97;6,81.96,258.38,65.43,8.97" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="6,136.97,247.34,161.69,8.97;6,81.96,258.38,61.41,8.97">Trec2003 qa at bbn: Answering definitional questions</title>
		<author>
			<persName coords=""><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ana</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,277.22,227.05,8.97;6,81.96,288.26,216.57,8.97;6,81.96,299.18,206.34,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,151.85,277.22,147.20,8.97;6,81.96,288.26,165.35,8.97">Pet. a platform for experimentation with efficient hpsg processing techniques</title>
		<author>
			<persName coords=""><forename type="first">Ulrich</forename><surname>Callmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,256.95,288.26,41.58,8.97;6,81.96,299.18,123.05,8.97">Journal of Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="99" to="108" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,318.14,165.18,8.97;6,258.90,318.14,39.91,8.97;6,81.96,329.06,216.79,8.97;6,81.96,339.98,216.71,8.97;6,81.96,351.02,216.92,8.97;6,81.96,361.94,197.96,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,258.90,318.14,39.91,8.97;6,81.96,329.06,216.79,8.97;6,81.96,339.98,158.14,8.97">An open source grammar development environment and broadcoverage English grammar using HPSG</title>
		<author>
			<persName coords=""><forename type="first">Ann</forename><surname>Copestake</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dan</forename><surname>Flickinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,262.48,339.98,36.19,8.97;6,81.96,351.02,216.92,8.97;6,81.96,361.94,102.67,8.97">Proceedings of the 2nd International Conference on Language Resources and Evaluation</title>
		<meeting>the 2nd International Conference on Language Resources and Evaluation<address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,380.90,226.55,8.97;6,81.96,391.82,216.70,8.97;6,81.96,402.74,216.72,8.97;6,81.96,413.78,216.72,8.97;6,81.96,424.70,207.57,8.97" xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Berthold</forename><surname>Crysmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anette</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernd</forename><surname>Kiefer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gunter</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jakub</forename><surname>Piskorski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ulrich</forename><surname>Schafer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Melanie</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hans</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Feiyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Markus</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hans-Ulrich</forename><surname>Krieger</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
