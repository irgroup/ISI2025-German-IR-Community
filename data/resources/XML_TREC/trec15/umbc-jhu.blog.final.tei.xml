<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,183.36,113.20,239.70,12.91;1,423.24,110.37,5.03,9.96">The BlogVox Opinion Retrieval System *</title>
				<funder ref="#_M7NHE4f">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_69zhA5q">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder>
					<orgName type="full">IBM</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,106.68,138.23,62.66,10.76"><forename type="first">Akshay</forename><surname>Java</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>Baltimore County</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,177.39,138.23,75.04,10.76"><forename type="first">Pranam</forename><surname>Kolari</surname></persName>
							<email>kolari1@cs.umbc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>Baltimore County</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,260.34,138.23,49.18,10.76"><forename type="first">Tim</forename><surname>Finin</surname></persName>
							<email>finin@cs.umbc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>Baltimore County</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,317.56,138.23,73.99,10.76"><forename type="first">Anupam</forename><surname>Joshi</surname></persName>
							<email>joshi@cs.umbc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>Baltimore County</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,416.62,138.23,88.37,10.76"><forename type="first">Justin</forename><surname>Martineau</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>Baltimore County</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,272.76,183.52,66.54,8.97"><forename type="first">James</forename><surname>Mayfield</surname></persName>
							<email>james.mayfield@jhuapl.edu</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Applied Physics Laboratory</orgName>
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,183.36,113.20,239.70,12.91;1,423.24,110.37,5.03,9.96">The BlogVox Opinion Retrieval System *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0342D7778E54E91FA161C216AAE2F1BD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The BlogVox system retrieves opinionated blog posts specified by ad hoc queries. BlogVox was developed for the 2006 TREC blog track by the University of Maryland, Baltimore County and the Johns Hopkins University Applied Physics Laboratory using a novel system to recognize legitimate posts and discriminate against spam blogs. It also processes posts to eliminate extraneous non-content, including blog-rolls, link-rolls, advertisements and sidebars. After retrieving posts relevant to a topic query, the system processes them to produce a set of independent features estimating the likelihood that a post expresses an opinion about the topic. These are combined using an SVM-based system and integrated with the relevancy score to rank the results. We evaluate BlogVox's performance against human assessors. We also evaluate the individual splog filtering and non-content removal components of BlogVox.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Blog posts contain noisy, ungrammatical and poorly structured text. This makes open-domain, opinion retrieval for blogs challenging. In addition any text analytics system that deals with blogs must address two key issues: (i) detecting and eliminating spam blogs and spam comments and (ii) eliminating noise from link-rolls and blog-rolls.</p><p>The BlogVox system was developed by the University of Maryland, Baltimore County and the Johns Hopkins University Applied Physics Laboratory to perform the opinion retrieval task defined by the 2006 TREC Blog Track. In this task, a user enters a query for a topic of interest (e.g., March of the Penguins) and expects to see a list of blog posts that express an opinion (positive or negative) about the topic. The results are ranked by the likelihood that they are expressing an opinion about the given topic. The approach used in BlogVox has several interesting features. Two techniques are used to eliminate spurious text that might mislead the judgment of both relevance and opinionatedness. First, we identify posts from spam blogs using a machinelearning based approach and eliminate them from the collection. Second, posts are "cleaned" before being indexed to eliminate extraneous text associated with navigation links, blog-rolls, link-rolls, advertisements and sidebars. After retrieving posts relevant to a topic query, the system applies a set of scoring modules to each producing a vector of features estimating the likelihood that a post expresses an opinion about the topic. These are combined using an SVMbased system and integrated with the overall relevancy score to rank the results.</p><p>Opinion extraction and sentiment detection have been previously studied for mining sentiments and reviews in domains such as consumer products <ref type="bibr" coords="1,455.83,337.00,97.41,8.97;1,319.56,347.92,46.25,8.97" target="#b0">(Dave, Lawrence, &amp; Pennock 2003)</ref> or movies <ref type="bibr" coords="1,412.92,347.92,145.01,8.97" target="#b16">(Pang, Lee, &amp; Vaithyanathan 2002;</ref><ref type="bibr" coords="1,319.56,358.96,80.41,8.97" target="#b1">Gilad Mishne 2006)</ref>. More recently, blogs have become a new medium through which users express sentiments. Opinion extraction has thus become important for understanding consumer biases and is being used as a new tool for market intelligence <ref type="bibr" coords="1,384.05,402.76,82.34,8.97" target="#b2">(Glance et al. 2005;</ref><ref type="bibr" coords="1,469.15,402.76,88.82,8.97" target="#b15">Nigam &amp; Hurst 2004;</ref><ref type="bibr" coords="1,319.56,413.68,96.21,8.97" target="#b12">Liu, Hu, &amp; Cheng 2005)</ref>.</p><p>Blog posts contain noisy, ungrammatical and poorly structured text. This makes open-domain, opinion retrieval for blogs challenging. In addition any text analytics system that deals with blogs must address two larger issues: (i) detecting and eliminating posts from spam blogs (commonly known as splogs) and spam comments and (ii) eliminating irrelevant text and links that are not part of the post's content.</p><p>Recently, Spam blogs, or splogs have received significant attention, and techniques are being developed to detect them. <ref type="bibr" coords="1,319.56,536.68,180.52,8.97">Kolari, et al. (Kolari, Finin, &amp; Joshi 2006)</ref> have recently discussed the use of machine learning techniques to identify blog pages (as opposed to other online resources) and to categorize them as authentic blogs or spam blogs (splogs). <ref type="bibr" coords="1,319.56,580.48,116.50,8.97">(Kolari, Java, &amp; Finin 2006)</ref> extends this study by analyzing a special collection of blog posts released for the Third Annual Workshop on the Weblogging Ecosystem held at the 2006 World Wide Web Conference. Their findings on spam blogs confirms the seriousness of the problem, the most recent data shows about 64% of "pings" collected from the most popular ping-server for English blogs are from splogs.</p><p>Blog posts are complex documents and consist of a core containing the post's real content surrounded by an array of extraneous and irrelevant text, images and links. This "noise" includes links to recent posts, navigational links, advertisements and other Web 2.0 features such as tag rolls, blog rolls, Technorati tags, Flickr links and often accounts for 75% or more of the post's size. The presence of this extra material can make it difficult for text mining tools to narrow down and focus on the actual content of a blog post. Moreover, these features may also reduce search index quality. Discounting for such noise is especially important when indexing blog content. Blog posts are complex documents and consist of a core containing the post's real content surrounded by an array of extraneous and irrelevant text, images and links. This "noise" includes links to recent posts, navigational links, advertisements and other Web 2.0 features such as tag rolls, blog rolls, Technorati tags, Flickr links and often accounts for 75% or more of the post's size. The presence of this extra material can make it difficult for text mining tools to narrow down and focus on the actual content of a blog post. Moreover, these features may also reduce the quality of the search index. Discounting for such noise is especially important when indexing blog content.</p><p>The paper is organized as follows: first we give a brief overview of the 2006 TREC Blog Track, and its associated dataset in section . Then we describe our system, BlogVox, in Section . The next three sections explain how BlogVox works. In Section we explain how we deal with splogs. Following that we describe in Section a simple, yet effective, heuristic for cleaning the blog post to remove any extraneous links and other features. Then we explain how BlogVox scores posts for opinion ranking in Section . We present the TREC results along with an evaluation of the post cleaning and splog filtering techniques in Section . Finally, we discuss our results in Section and conclusions in Section .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The TREC Blog Track</head><p>The 2006 TREC Blog track, organized by NIST, asked participants to implement and evaluate a system to do "opinion retrieval" from blog posts. Specifically, the task was defined as follows: build a system that will take a query string describing a topic, e.g., "March of the Penguins", and return a ranked list of blog posts that express an opinion, positive or negative, about the topic.</p><p>For training and evaluation, NIST provided a dataset of over three million blogs drawn from about 80 thousand blogs. The TREC dataset consisted of a set of XML formatted files, each containing blog posts crawled on a given date. The entire collection consisted of over 3.2M posts from 100K feeds <ref type="bibr" coords="2,125.67,551.20,110.36,8.97" target="#b13">(Macdonald &amp; Ounis 2006)</ref>. These posts were parsed and stored separately for convenient indexing, using the HTML parser tool 1 . Non-English blogs were ignored in addition to any page that failed to parse due to encoding issues.</p><p>In order to make the challenge realistic NIST explicitly included 17,969 feeds from splogs, contributing to 15.8% of the documents. There were 83,307 distinct homepage URLs present in the collection, of which 81,014 could be processed. The collection contained a total of 3,214,727 permalinks from all these blogs.</p><p>TREC 2006 Blog Track participants built and trained their systems to work on this dataset. Entries were judged upon an automatic evaluation done by downloading and running, 1 http://htmlparser.sourceforge.net/ without further modification to their systems, a set of fifty test queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BlogVox Design</head><p>Compared to domain-specific opinion extraction, identifying opinionated documents about a randomly chosen topic from a pool of documents that are potentially unrelated to the topic is a much more difficult task. Our goal for this project was to create a system that could dynamically learn topic sensitive sentiment words to better find blog posts expressing an opinion about a specified topic. After cleaning the TREC 2006 Blog Track dataset in the pre-indexing stage, blog posts are indexed using Lucene, an open-source search engine. Given a TREC query BlogVox retrieves a set of relevant posts from the Lucene index and sends the posts to the scorers. Using a SVM BlogVox ranks each document based upon the score vector generated for the document by the set of scorers show in Figure <ref type="figure" coords="2,423.37,265.12,3.77,8.97" target="#fig_0">2</ref>. Section explains how the individual scorers, some of which employ learning algorithms, function.  We tuned Lucene's scoring formula to perform document length normalization and term specific boosting 2 . Lucene internally constructs an inverted index of the documents by representing each document as a vector of terms. Given a query term, Lucene uses standard Term Frequency (TF) and Inverse Document Frequency (IDF) normalization to compute similarity. We used the default parameters while searching the index. However, in order to handle phrasal queries such as "United States of America" we reformulate the original query to boost the value of exact matches or proximity-based matches for the phrase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Identifying and Removing Spam</head><p>Two kinds of spam are common in the blogosphere (i) spam blogs or splogs, and (ii) spam comments. We first discuss spam blogs, approaches on detecting them, and how they were employed for BlogVox.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem of Spam Blogs</head><p>Splogs are blogs created for the sole purpose of hosting ads, promoting affiliate sites (including themselves) and getting new pages indexed. Content in splogs is often autogenerated and/or plagiarized, such software sells for less than 100 dollars and now inundates the blogosphere both at ping servers (around 75% <ref type="bibr" coords="3,161.03,326.44,49.30,8.97" target="#b11">(Kolari 2005</ref>)) that monitor blog updates, and at blog search engines (around 20%, <ref type="bibr" coords="3,263.85,337.36,28.53,8.97;3,54.00,348.40,50.46,8.97">(Kolari et al. 2006b</ref>)) that index them. Spam comments pose an equally serious problem, where authentic blog posts feature auto-generated comments that target ranking algorithms of popular search engines. A popular spam comment filter 3 estimates the amount of spam detected to be around 93%.</p><p>Figure <ref type="figure" coords="3,93.57,403.48,5.03,8.97">3</ref> shows a splog post indexed by a popular blog search engine. As depicted, it features content plagiarized from other blogs (ii), displays ads in high paying contexts (i), and hosts hyperlinks (iii) that create link farms. Scores of such pages now pollute the blogosphere, with new ones springing up every moment. Splogs continue to be a problem for web search engines, however they present a new set of challenges for blog analytics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Detecting Splogs</head><p>Splogs are well understood to be a specific instance of the more general spam web-pages <ref type="bibr" coords="3,205.87,528.16,86.54,8.97;3,54.00,539.08,52.83,8.97" target="#b3">(Gyöngyi &amp; Garcia-Molina 2005)</ref>. Though offline graph based mechanisms like TrustRank <ref type="bibr" coords="3,98.35,550.00,174.71,8.97" target="#b4">(Gyöngyi, Garcia-Molina, &amp; Pedersen 2004</ref>) are sufficiently effective for the Web, the blogosphere demands new techniques. The quality of blog analytics engines is judged not just by content coverage, but also by their ability to quickly index and analyze recent (non-spam) posts. This requires that fast online splog detection/filtering (Kolari, Finin, &amp; Joshi 2006) <ref type="bibr" coords="3,152.34,615.76,107.35,8.97" target="#b17">(Salvetti &amp; Nicolov 2006)</ref> be used prior to indexing new content.</p><p>We employ statistical models to detecting splogs as described by <ref type="bibr" coords="3,99.30,649.00,84.74,8.97">(Kolari et al. 2006b)</ref>, based on supervised machine learning techniques, using content local to a page, enabling fast splog detection. These models are based solely on blog home-pages, and are based on a training set of 700 blogs and 700 splogs. Statistical models based on local blog 3 http://akismet.com </p><formula xml:id="formula_0" coords="3,425.09,147.26,93.35,96.77">(i) (ii) (iii)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Identifying Post Content</head><p>Most extraneous features in blog post are links. We describe two techniques to automatically classify the links into content-links and extra-links. Content links are part of either the title or the text of the post. Extra links are not directly related to the post, but provide additional information such as: navigational links, recent entries, advertisements, and blog rolls. Differentiating the blog content from its chaff is further complicated by blog hosting services using different templates and formats. Additionally, users host their own blogs and sometimes customize existing templates to suit their needs.</p><p>Web page cleaning techniques work by detecting common structural elements from the HTML Document Object Model (DOM) <ref type="bibr" coords="4,117.07,233.68,68.09,8.97">(Yi &amp; Liu 2003;</ref><ref type="bibr" coords="4,188.52,233.68,81.61,8.97" target="#b19">Yi, Liu, &amp; Li 2003)</ref>. By mining for both frequently repeated presentational components and content in web pages, a site style tree is constructed. This tree structure can be used for data cleaning and improved feature weighting. Finding repeated structural components requires sampling many web pages from a domain. Although blogs from the same domain can share similar structural components, they can differ due to blogger customization. Our proposed technique does not require sampling and works independently on each blog permalink.</p><p>Instead of mining, we used a simple general heuristic. Intuitively extraneous links tend to be tightly grouped containing relatively small amounts of text. Note that a typical blog post has a complex DOM tree with many parts, only one of which is the content of interest in most applications. • Average length of the text bearing nodes between a and b is less than some threshold.</p><p>• b is the nearest link node to a.</p><p>The average text ratio between the links, α avgT ext was heuristically set to 120 characters and a window size, θ dist of 10 tags was chosen. The Algorithm 1 provides a detailed description of this heuristic.</p><p>Next we present a machine learning approach to the link classification problem. From a large collection of blog posts, a random sample of 125 posts was selected. A human evaluator judged a subset of links (approximately 400) from these posts. The links were manually tagged either content-links or extra-links. Each link was associated with a set of features. this feature set an SVM model was trained<ref type="foot" coords="5,234.84,378.16,3.48,6.28" target="#foot_1">4</ref> to recognize links to eliminate. The first set of features (1-7) was based on the tag information. The next set of features (8-9) was based on position information and the final set of features (10-13) consisted of word-based features. Using features (1-7) yields a precision of 79.4% and recall of 78.39%, using all our features (1-13) yields a precision of 86.25% and recall of 94.31% under 10-fold cross validation. We compared the original baseline heuristic against human evaluators. The average accuracy for the baseline heuristic is about 83% with a recall of 87%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scoring</head><p>To improve the quality of opinion extraction results, it is important to identify the title and content of the blog post because the scoring functions and the Lucene indexing engine can not differentiate between text present in the links and sidebars from text present in content of the blog post. Thus, a post which has a link to a recent post titled 'Why I love my iPod' would be retrieved as an opinionated post even if the post content is about some other topic. This observation lead to the development of our first scorers.</p><p>As shown in figure <ref type="figure" coords="5,139.83,628.60,3.77,8.97" target="#fig_0">2</ref>, a number of heuristics are employed to score the results based on the likelihood that it contains an opinion about the query terms. These scorers work by using both document level and individual sentence level features. Some of the scoring heuristics were supported by a hand-crafted list of 915 generic postive and 2712 negative sentiment words.</p><p>The following is a brief description of each scoring function:</p><p>Query Word Proximity Scorer finds the average number of sentiment terms occurring in the vicinity of the query terms using a window size of 15 words before and after the query terms. If the query is a phrasal query, the presence of sentiment terms around the query was weighted twice.</p><p>Parametrized Proximity Scorer was similar to the Query Word Proximity Scorer. However, we used a much smaller dictionary which was divided into two subsets: highly polar sentiment words, and the relatively less polar words. We used parameters to specify the window of text to search for sentiment words (five and fifteen), and to boost sentiment terms around phrase queries (one and three). This resulted in a total of eight scorers.</p><p>Positive and Negative Scorers counted the number of sentiment words (positive, negative) in the entire post.</p><p>Lucene Relevance Score was used to find how closely the post matches the query terms.</p><p>We also experimented with other scoring functions, such as adjective word count scorer. This scorer used an NLP tool to extract the adjectives around the query terms. However, this tool did not perform well mainly due to the noisy and ungrammatical bsentences present in blogs.</p><p>Once the results were scored by these scoring modules, we used a meta-learning approach to combine the scores using SVMs. Our SVMs were trained using a set of 670 samples of which 238 were positive (showed a sentiment) and the rest were negative. Using the polynomial kernel with degree gave the best results with precision of 80% and recall of 30%. The model was trained to predict the probability of a document expressing opinion. This value was then combined with the Lucene relevance score to produce final runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation</head><p>The opinion extraction system provides a testbed application for which we evaluate different data cleaning methods. There are three criteria for evaluation: i) improvements in opinion extraction task with and without data cleaning ii) performance evaluation for splog detection iii) performance of the post content identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Splog Detection Evaluation</head><p>Our automated splog detection technique identified 13,542 blogs as splogs. This accounts for about 16% of the identified homepages. The total number of splog permalinks is 543,086 or around 16% of the collection, which is very close to the 15.8% explicitly included by NIST. While the actual list of splogs are not available for comparison, the current estimate seem to be close. To prevent the possibility of splogs skewing our results permalinks associated with splogs were not indexed.</p><p>Given a search query, we would like to estimate the impact splogs have on search result precision. Figure <ref type="figure" coords="5,525.35,669.40,5.03,8.97" target="#fig_2">5</ref> shows the distribution of splogs across the 50 TREC queries. The quantity of splogs present varies across the queries since splogs are query dependent. For example, the topmost spammed query terms were 'cholesterol' and 'hybrid cars'. Such queries attract a target market, which advertiser can exploit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Distribution of Splogs that appear in TREC queries (Each line represents a query)</head><p>The description of the TREC data <ref type="bibr" coords="6,206.02,421.00,86.30,8.97;6,54.00,431.92,23.48,8.97" target="#b13">(Macdonald &amp; Ounis 2006)</ref> provides an analysis of the posts from splogs that were added to the collection. Top informative terms include 'insurance', 'weight', 'credit' and such. Figure <ref type="figure" coords="6,243.01,453.76,5.03,8.97" target="#fig_3">6</ref> shows the distribution of splogs identified by our system across such spam terms. In stark contrast from Figure <ref type="figure" coords="6,226.73,475.72,5.03,8.97" target="#fig_2">5</ref> there is a very high percentage of splogs in the top 100 results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Post Cleaning Evaluation</head><p>In BlogVox data cleaning improved results for opinion extraction. Figure <ref type="figure" coords="6,124.85,537.16,5.03,8.97">7</ref> highlights the significance of identifying and removing extraneous content from blog posts. For 50 TREC queries, we fetched the first 500 matches from a Lucene index and used the baseline data cleaning heuristic. Some documents were selected only due to the presence of query terms in sidebars. Sometimes these are links to recent posts containing the query terms, but can often be links to advertisements, reading lists or link rolls, etc. Reducing the impact of sidebar on opinion rank through link elimination or feature weighing can improve search results.</p><p>Table <ref type="table" coords="6,89.25,647.44,5.03,8.97" target="#tab_3">3</ref> shows the performance of the baseline heuristic and the SVM based data cleaner on a hand-tagged set of 400 links. The SVM model outperforms the baseline heuristic. The current data cleaning approach works by making a decision at the individual HTML tag level; we are currently working on automatically identifying the DOM subtrees that correspond to the sidebar elements. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Distribution of Splogs that appear in 'spam contexts' indentified in TREC</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Trec Submissions</head><p>The core BlogVox system produces results with two measures. The first is a relevance score ranging from 0.0 to 1.0, which is the value returned by the underlying Lucene query system. The second was a measure of opinionatedness, which was a real number greater than 0.0. We produced the sim numbers for each of the runs from a weighted average of the two numbers after normalizing them using the standard Z-normalization technique.</p><p>The baseline run was exectuted on the uncleaned dataset using a selection of what we anticipated to be the seven best scorer features and with an equal weighting for relevance and opinionatedness. This run was also the best performing run amongst our official runs. Runs two through five were made on the semi-cleaned dataset and using a larger set of eleven scorer features. After normalizing the result scores, we used weights of (1,1), (1,2), (1,3) and (2,1).</p><p>Figure <ref type="figure" coords="6,359.01,592.60,5.03,8.97">8</ref> shows the results from the TREC submissions for opinion retrieval. Figure <ref type="figure" coords="6,432.59,603.64,5.03,8.97" target="#fig_4">9</ref> shows the results for the topic relevance. The Mean Average Precision (MAP) for opinion retrieval of the original TREC submissions was 0.0764 and the R-Prec was around 0.1307. The MAP for topic relevance was about 0.1288 with an R-Prec of 0.1805. After inspection of the code, it appeared that this may have been due to a minor bug in the original code that was used for the official run. Upon correcting this and re-executing the run, we found that the MAP for opinion task was about 0.128 and for retrieval was about 0.1928. A final run was performed by running the queries against an index recreated by clean-  for these these runs. We think that the retrieval performance could be improved by using the following approaches: use of query expansion modules, applying relevance feedback and using the description and narrative fields from the TREC queries to formulate the final Lucene query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>For TREC runs, we used an index on blog posts that had not been cleaned for all of the runs. For run one we evaluated these uncleaned posts using a complement of seven heuristics. For runs two through five, we retrieved a fixed number of post ids using the index of uncleaned data and then cleaned the resulting posts "on the fly". A larger set of eleven heuristic scoring functions was used for these runs. After cleaning a post, we did a heuristic check to ensure that at least some of the query terms remained. If not, the post was discarded. We believe that this ad hoc approach significantly lowered our precision scores for these runs due to at least three reasons. First, the relevance scores were computed by Lucene on the uncleaned posts and were not accurate for the cleaned versions since the term frequencies for both the collection and for each document were altered. Second, discarding many of the posts after the cleaning reduced the number of available results, already low due to the impending deadline. Finally, the cleaned posts were in many cases likely to be less relevant that their scores would indicate due to the removal of query words.</p><p>Manual inspection of some of the results showed that there were a number of matches that were due to the presence of the query terms in extraneous links. In order to verify the effectiveness of cleaning we created a new index using only the cleaned versions of the posts. We find that using this cleaner index improved not only retrieval results but also effective mean average precision for opinion retrieval. As can be observed from Figure <ref type="figure" coords="8,452.84,691.24,8.38,8.97" target="#fig_5">10</ref>, in almost all the cases the mean average precision for the runs on cleaned data outperform those on unclean data. The queries for which data cleaning made a significant improvement were "larry summers", "bruce bartlett", "Fox News Report" and "zyrtec". Comparing these with Figure <ref type="figure" coords="9,170.99,534.52,5.03,8.97">7</ref> indicates that these were also queries that contained a higher number of matches that had the terms exclusively in the sidebar. On the other hand for queries like 'audi', 'oprah' and 'colbert report' the cleaned runs had a lower precision possibly due to the strict thresholds for cleaning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We developed the BlogVox system as an opinion retrieval system for blog posts as part of the 2006 TREC Blog Track. This task requires processing an ad hoc queries representing topics and retrieving posts that express an opinion about them. Our initial experiments with the blog post collection revealed two problems: the presence of spam blogs and the large amounts of extra, non-content text in each posts. We identified posts from spam blogs using a machinelearning based approach and eliminated them from the col-lection. The remaining posts were "cleaned" before being indexed to eliminate extraneous text associated with navigation links, blog-rolls, link-rolls, advertisements and sidebars. After retrieving posts relevant to a topic query, the system applies a set of scoring modules to each producing a vector of features estimating the likelihood that a post expresses an opinion about the topic. These are combined using an SVMbased system and integrated with the overall relevancy score to rank the results.</p><p>Our evaluation of the BlogVox results showed that both splog elimination and post cleaning significantly increased the performance of the system. The overall performance as measured by the mean average precision and R-precision scores showed that the system worked well on most of the fifty test queries. We believe that the system can be improved by increasing the accuracy of the post-cleaning and refining the opinion scorers. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,319.56,632.20,238.29,8.97;2,319.56,643.12,238.51,8.97;2,319.56,654.16,104.75,8.97"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: After relevant posts are retrieved, they are scored by various heuristics and an overall measure of oinionatedness computed by a SVM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,54.00,607.48,238.28,8.97;4,54.00,618.52,238.40,8.97;4,54.00,629.44,238.31,8.97;4,54.00,640.36,97.43,8.97;4,56.28,410.70,236.16,177.11"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: A typical blog post containing navigational links, recent posts, advertisements, and post content with additional links in it. Highlighted links are eliminated by the approximation heuristic.</figDesc><graphic coords="4,56.28,410.70,236.16,177.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,54.00,337.84,238.30,8.97;6,54.00,348.88,238.39,8.97;6,54.00,359.80,53.33,8.97"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The number of splogs in the top x results for 50 TREC queries. Top splog queries include "cholesterol" and "hybrid cars"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,319.56,337.72,238.30,8.97;6,319.56,348.64,238.29,8.97;6,319.56,359.56,229.61,8.97"><head>Figure 6 :</head><label>6</label><figDesc>Figure6: The number of splogs in the top x results of the TREC collection for 28 highly spammed query terms. Top splog queries include 'pregnancy', 'insurance', 'discount'</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="8,69.12,475.60,473.42,8.97"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Mean average Precision (for topic relevance) of original TREC submission UABas11, updated runs and clean index runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="9,86.04,475.60,439.49,8.97"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Difference of MAP from Median for original TREC submission UABas11, updated runs and clean index runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="10,54.00,246.04,238.15,8.97;10,54.00,256.68,163.69,8.07"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Precision Recall curves for original TREC submission UABas11, updated runs and clean index runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,319.56,286.60,238.52,435.57"><head>Table 1 :</head><label>1</label><figDesc>Figure 3: A typical splog, plagiarizes content (ii), promotes other spam pages (iii), and (i) hosts high paying contextual advertisements SVM</figDesc><table coords="3,319.56,338.92,238.39,328.41"><row><cell cols="4">Feature Precision Recall F1</cell></row><row><cell>words</cell><cell>.887</cell><cell>.864</cell><cell>.875</cell></row><row><cell>urls</cell><cell>.804</cell><cell>.827</cell><cell>.815</cell></row><row><cell cols="2">anchors .854</cell><cell>.807</cell><cell>.830</cell></row><row><cell>Comment spam</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Comment spam occurs when a user posts spam inside a blog</cell></row><row><cell cols="4">comment. Comment spam is typically managed by indi-</cell></row><row><cell cols="4">vidual bloggers, through moderating comments and/or us-</cell></row><row><cell cols="4">ing comment spam detection tools (e.g. Akismet) on blog-</cell></row><row><cell cols="4">ging platforms. Comment spam and splogs share a common</cell></row><row><cell cols="4">purpose. They enable indexing new web pages, and pro-</cell></row><row><cell cols="4">moting their page rank, with each such page selling online</cell></row></table><note coords="3,373.15,395.16,184.72,8.07;3,319.56,405.12,238.19,8.07;3,319.56,415.08,147.15,8.07;3,319.56,458.32,238.29,8.97;3,319.56,469.36,238.52,8.97;3,319.56,480.28,238.52,8.97;3,319.56,491.20,238.27,8.97;3,319.56,502.24,238.44,8.97;3,319.56,513.16,238.28,8.97;3,319.56,524.08,238.27,8.97;3,319.56,535.12,120.33,8.97;3,319.56,669.40,238.26,8.97;3,319.56,680.32,238.16,8.97;3,319.56,691.24,238.51,8.97;3,319.56,702.28,238.27,8.97;3,319.56,713.20,50.21,8.97"><p><p><p><p><p><p><p><p>Models with 19000 word features and 10000 each of URL and anchor text features (ranked using Mutual Information) can be quite effective for splog detection.</p>features perform well on spam blog detection. See Table</p>1</p>. The bag-of-words based features slightly outperforms bag-of-outgoingurls (URL's tokenized on '/') and bag-ofoutgoinganchors. Additional results using link based features are slightly lower that local features, but effective nonetheless. Interested readers are referred to</p>(Kolari et al.  2006b)  </p>for further details. Therefore, BlogVox used only local features to detect splogs. merchandise or hosting context specific advertisements. Detecting and eliminating comment spam</p><ref type="bibr" coords="3,477.30,680.32,80.43,8.97;3,319.56,691.24,56.69,8.97" target="#b14">(Mishne, Carmel, &amp; Lempel 2005)</ref> </p>depends largely on the quality of identifying comments on a blog post, part of which is addressed in the next section.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,347.61,713.20,210.24,8.97"><head>Table 2 :</head><label>2</label><figDesc>Table 2 summarizes the main features used. Using Features used for training an SVM for classifying links as content links and extra links.</figDesc><table coords="5,60.00,75.28,226.72,246.09"><row><cell cols="2">ID Features</cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>Previous Node</cell><cell></cell><cell></cell></row><row><cell>2</cell><cell>Next Node</cell><cell></cell><cell></cell></row><row><cell>3</cell><cell>Parent Node</cell><cell></cell><cell></cell></row><row><cell>4</cell><cell>Previous N Tags</cell><cell></cell><cell></cell></row><row><cell>5</cell><cell>Next N Tags</cell><cell></cell><cell></cell></row><row><cell>6</cell><cell>Sibling Nodes</cell><cell></cell><cell></cell></row><row><cell>7</cell><cell>Child Nodes</cell><cell></cell><cell></cell></row><row><cell>8</cell><cell cols="2">Depth in DOM Tree</cell><cell></cell></row><row><cell>9</cell><cell cols="2">Char offset from page start</cell><cell></cell></row><row><cell cols="3">10 links outside the blog?</cell><cell></cell></row><row><cell cols="3">11 Anchor text words</cell><cell></cell></row><row><cell cols="3">12 Previous N words</cell><cell></cell></row><row><cell cols="2">13 Next N words</cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell></cell><cell cols="3">Precision Recall F1</cell></row><row><cell cols="2">baseline heuristic</cell><cell>0.83</cell><cell>0.87</cell><cell>0.849</cell></row><row><cell cols="3">svm cleaner (tag features) 0.79</cell><cell>0.78</cell><cell>0.784</cell></row><row><cell cols="3">svm cleaner (all features) 0.86</cell><cell>0.94</cell><cell>0.898</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,54.00,333.88,238.31,18.71"><head>Table 3 :</head><label>3</label><figDesc>Data</figDesc><table /><note coords="5,113.12,334.56,179.20,8.07;5,54.00,344.52,63.57,8.07"><p>cleaning with DOM features on a training set of 400 HTML Links.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,54.00,129.61,503.98,592.55"><head>Table 4 :</head><label>4</label><figDesc>Mean average precision (for opinion) of original TREC submission UABas11 ,updated runs and clean index runs. The results for the opinion and topic relevance performance of different runs ing all the posts using heuristics described in Section . Table4summarizes the results obtained. We find that cleaning significantly improved both opinion and retrieval scores of our system. Figure11compares the precision recall curves</figDesc><table coords="7,239.95,129.61,131.55,7.17"><row><cell>Mean Average Precision for Opinion</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,335.64,713.88,169.08,8.07"><p>http://lucene.apache.org/java/docs/scoring.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="5,70.08,714.36,156.53,7.05"><p>http://svmlight.joachims.org/</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>* Partial support was provided by an <rs type="funder">IBM</rs> Fellowship and by <rs type="funder">NSF</rs> awards <rs type="grantNumber">ITR-IIS-0326460</rs> and <rs type="grantNumber">TR-IDM-0219649</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_M7NHE4f">
					<idno type="grant-number">ITR-IIS-0326460</idno>
				</org>
				<org type="funding" xml:id="_69zhA5q">
					<idno type="grant-number">TR-IDM-0219649</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,59.04,306.88,233.33,8.97;10,59.04,317.92,233.12,8.97;10,59.04,328.84,190.81,8.97" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="10,262.88,306.88,29.49,8.97;10,59.04,317.92,233.12,8.97;10,59.04,328.84,104.93,8.97">Mining the peanut gallery: opinion extraction and semantic classification of product reviews</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Pennock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>WWW</publisher>
			<biblScope unit="page" from="519" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,59.04,343.48,233.37,8.97;10,59.04,354.52,233.24,8.97;10,59.04,365.44,233.38,8.97;10,59.04,376.36,54.54,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,177.94,343.48,114.48,8.97;10,59.04,354.52,71.25,8.97">Predicting movie sales from blogger sentiment</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">G</forename><surname>Gilad Mishne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,153.97,354.52,138.31,8.97;10,59.04,365.44,201.60,8.97">AAAI 2006 Spring Symposium on Computational Approaches to Analysing Weblogs</title>
		<imprint>
			<publisher>AAAI-CAAW</publisher>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,59.04,391.12,233.39,8.97;10,59.04,402.04,233.21,8.97;10,59.04,413.08,202.41,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,190.85,402.04,101.40,8.97;10,59.04,413.08,120.39,8.97">Deriving marketing intelligence from online discussion</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">S</forename><surname>Glance</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hurst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Stockton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tomokiyo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,197.71,413.08,17.62,8.97">KDD</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="419" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,59.04,427.72,233.21,8.97;10,59.04,438.64,233.25,8.97;10,59.04,449.68,135.20,8.97" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,232.68,427.72,59.57,8.97;10,59.04,438.64,24.85,8.97">Web spam taxonomy</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Gyöngyi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Garcia-Molina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,108.89,438.64,183.39,8.97;10,59.04,449.68,130.38,8.97">First International Workshop on Adversarial Information Retrieval on the Web</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,59.04,464.32,233.46,8.97;10,59.04,475.36,233.40,8.97;10,59.04,486.28,233.25,8.97;10,59.04,497.20,166.31,8.97" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,59.04,475.36,163.71,8.97">Combating web spam with TrustRank</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Gyöngyi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Garcia-Molina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,256.25,475.36,36.19,8.97;10,59.04,486.28,233.25,8.97;10,59.04,497.20,40.22,8.97">Proceedings of the 30th International Conference on Very Large Databases</title>
		<meeting>the 30th International Conference on Very Large Databases</meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="576" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,59.04,511.96,233.32,8.97;10,59.04,522.88,104.16,8.97" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Hatcher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Gospodnetić</surname></persName>
		</author>
		<title level="m" coord="10,221.88,511.96,66.38,8.97">Lucene in Action</title>
		<imprint>
			<publisher>Manning Publications Co</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,59.04,537.64,233.36,8.97;10,59.04,548.56,233.35,8.97;10,59.04,559.48,233.25,8.97;10,59.04,570.52,233.36,8.97;10,59.04,581.44,204.24,8.97" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,138.25,548.56,154.15,8.97;10,59.04,559.48,43.05,8.97">BlogVox: Separating Blog Wheat from Blog Chaff</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Java</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kolari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Finin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Martineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,122.21,559.48,170.08,8.97;10,59.04,570.52,233.36,8.97;10,59.04,581.44,199.89,8.97">Proceedings of the Workshop on Analytics for Noisy Unstructured Text Data, 20th International Joint Conference on Artificial Intelligence (IJCAI-2007)</title>
		<meeting>the Workshop on Analytics for Noisy Unstructured Text Data, 20th International Joint Conference on Artificial Intelligence (IJCAI-2007)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,59.04,596.08,233.36,8.97;10,59.04,607.12,233.25,8.97;10,59.04,618.04,228.70,8.97" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="10,149.04,607.12,143.25,8.97;10,59.04,618.04,52.92,8.97">Blog Track Open Task: Spam Blog Classification</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kolari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Java</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Finin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Martineau</surname></persName>
		</author>
		<idno>. TREC 2006 Blog Track</idno>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="10,59.04,632.80,233.26,8.97;10,59.04,643.72,233.25,8.97;10,59.04,654.64,233.22,8.97;10,59.04,665.68,140.61,8.97" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,91.51,643.72,200.79,8.97;10,59.04,654.64,25.57,8.97">Detecting Spam Blogs: A Machine Learning Approach</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kolari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Java</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Finin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Oates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,102.30,654.64,189.96,8.97;10,59.04,665.68,84.87,8.97">Proceedings of the 21st National Conference on Artificial Intelligence</title>
		<meeting>the 21st National Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,59.04,680.32,233.27,8.97;10,59.04,691.24,233.25,8.97;10,59.04,702.28,233.37,8.97;10,59.04,713.20,217.78,8.97" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,236.07,680.32,56.24,8.97;10,59.04,691.24,215.93,8.97">SVMs for the Blogosphere: Blog Identification and Splog Detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kolari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Finin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,59.04,702.28,233.37,8.97;10,59.04,713.20,159.00,8.97">Proceedings of the AAAI Spring Symposium on Computational Approaches to Analysing Weblogs</title>
		<meeting>the AAAI Spring Symposium on Computational Approaches to Analysing Weblogs</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,324.48,75.16,233.34,8.97;10,324.48,86.08,233.34,8.97;10,324.48,97.12,233.35,8.97;10,324.48,108.04,165.17,8.97" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,484.47,75.16,73.35,8.97;10,324.48,86.08,52.65,8.97">Characterizing the Splogosphere</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kolari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Java</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Finin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,395.06,86.08,162.75,8.97;10,324.48,97.12,233.35,8.97;10,324.48,108.04,160.79,8.97">Proceedings of the 3rd Annual Workshop on Weblogging Ecosystem: Aggregation, Analysis and Dynamics, 15th World Wid Web Conference</title>
		<meeting>the 3rd Annual Workshop on Weblogging Ecosystem: Aggregation, Analysis and Dynamics, 15th World Wid Web Conference</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,324.48,121.72,233.35,8.97;10,324.48,132.64,233.58,8.97;10,324.48,143.68,22.88,8.97;10,364.28,144.84,194.32,7.05;10,324.48,155.76,22.06,7.05" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="10,388.95,121.72,168.88,8.97;10,324.48,132.64,95.09,8.97">Welcome to the splogosphere: 75% of new pings are spings(splogs)</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kolari</surname></persName>
		</author>
		<ptr target="http://ebiquity.umbc.edu/blogger/?p=429" />
		<imprint>
			<date type="published" when="2005-12">2005. December-2005</date>
			<biblScope unit="volume">22</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,324.48,168.28,233.46,8.97;10,324.48,179.20,233.25,8.97;10,324.48,190.12,233.35,8.97;10,324.48,201.16,233.27,8.97;10,324.48,212.08,23.49,8.97" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,485.07,168.28,72.87,8.97;10,324.48,179.20,185.96,8.97">Opinion observer: analyzing and comparing opinions on the web</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,532.89,179.20,24.84,8.97;10,324.48,190.12,233.35,8.97;10,324.48,201.16,65.43,8.97">WWW &apos;05: Proceedings of the 14th international conference on World Wide Web</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="342" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,324.48,225.76,233.46,8.97;10,324.48,236.68,233.49,8.97;10,324.48,247.72,233.37,8.97;10,324.48,258.64,186.25,8.97" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="10,487.59,225.76,70.36,8.97;10,324.48,236.68,229.68,8.97">The trec blogs06 collection: Creating and analyzing a blog test collection</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<idno>TR-2006-224</idno>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Glasgow</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech Report</note>
</biblStruct>

<biblStruct coords="10,324.48,272.32,233.47,8.97;10,324.48,283.24,233.48,8.97;10,324.48,294.28,233.49,8.97;10,324.48,305.20,165.91,8.97" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,521.28,272.32,36.67,8.97;10,324.48,283.24,182.06,8.97">Blocking blog spam with language model disagreement</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mishne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Carmel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Lempel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,525.71,283.24,32.26,8.97;10,324.48,294.28,233.49,8.97;10,324.48,305.20,98.38,8.97;10,440.39,305.20,45.47,8.97">AIRWeb &apos;05 -1st International Workshop on Adversarial Information Retrieval on the Web</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>WWW 2005</note>
</biblStruct>

<biblStruct coords="10,324.48,318.88,233.34,8.97;10,324.48,329.80,233.26,8.97;10,324.48,340.72,146.12,8.97" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,452.82,318.88,105.00,8.97;10,324.48,329.80,29.04,8.97">Towards a robust metric of opinion</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,371.45,329.80,186.29,8.97;10,324.48,340.72,121.32,8.97">Exploring Attitude and Affect in Text: Theories and Applications, AAAI-EAAT</title>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,324.48,354.40,233.32,8.97;10,324.48,365.44,233.47,8.97;10,324.48,376.36,130.53,8.97" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,508.78,354.40,49.01,8.97;10,324.48,365.44,229.35,8.97">Thumbs up? sentiment classification using machine learning techniques</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,335.27,376.36,94.59,8.97">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,324.48,390.04,233.34,8.97;10,324.48,400.96,233.37,8.97;10,324.48,412.00,233.46,8.97;10,324.48,422.92,233.37,8.97;10,324.48,433.84,233.36,8.97;10,324.48,444.88,108.47,8.97" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,459.65,390.04,98.17,8.97;10,324.48,400.96,233.37,8.97;10,324.48,412.00,25.57,8.97">Weblog classification for fast splog filtering: A url language model segmentation approach</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Salvetti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Nicolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,370.50,412.00,187.44,8.97;10,324.48,422.92,233.37,8.97;10,324.48,433.84,25.57,8.97">Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers</title>
		<meeting>the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers<address><addrLine>New York City, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="137" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,324.48,458.56,233.36,8.97;10,324.48,469.48,233.47,8.97;10,324.48,480.40,233.38,8.97;10,324.48,491.44,67.70,8.97" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,443.14,458.56,114.70,8.97;10,324.48,469.48,131.89,8.97">Web page cleaning for web mining through feature weighting</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<idno>IJCAI-03</idno>
	</analytic>
	<monogr>
		<title level="m" coord="10,474.05,469.48,83.90,8.97;10,324.48,480.40,233.38,8.97;10,324.48,491.44,21.36,8.97">Proceedings of Eighteenth International Joint Conference on Artificial Intelligence</title>
		<meeting>Eighteenth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,324.48,505.00,233.39,8.97;10,324.48,516.04,233.48,8.97;10,324.48,526.96,233.39,8.97;10,324.48,537.88,184.32,8.97" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="10,470.95,505.00,86.91,8.97;10,324.48,516.04,161.47,8.97">Eliminating noisy information in web pages for data mining</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,508.47,516.04,49.49,8.97;10,324.48,526.96,233.39,8.97;10,324.48,537.88,130.48,8.97">Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page">2003</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
