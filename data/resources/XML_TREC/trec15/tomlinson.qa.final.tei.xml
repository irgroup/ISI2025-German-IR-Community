<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">18B3DF55EB3ADACDD891A66DAB4FDECC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question Answering by Diggery at TREC-2006</head><p>Stan <ref type="bibr" coords="1,270.84,118.09,98.67,11.16;1,259.20,133.40,93.67,10.00">Tomlinson, Ph.D. stan@tomlinson.com</ref> Diggery is a research and software project, investigating the extraction of concepts from well-written documents, with the idea of automating factoid search. The project is in its early to middle phases, and all information presented herein should be taken in light that this research is based on young software using new algorithms.</p><p>In January 2006, after significant tuning, the software could answer a few simple questions from small texts. Six months later, in July 2006, the first real exercise of the software on a nontrivially sized corpora was made for the TREC QA submission, and the software answered a few questions correctly. For this submission, only factoid questions were attempted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview of Methods</head><p>The software, as implemented for TREC 2006, has three main components: indexing the words in the corpora, extracting concepts from source text for a particular topic, and answering questions from the extracted concepts.</p><p>A simple index engine was built that indexed, by sentence and document, the words in the corpora. For each question topic, the sentences which have the topic words were identified, and those sentences were passed to the concept extractor.</p><p>The concept extractor parses a source sentence and produces an intermediate syntactic tree. The constituent parts of the syntactic tree are compiled into concepts. If it is necessary to resolve anaphora, additional source sentences are parsed.</p><p>To answer a question, the question is parsed using the same underlying parser engine that is used to produce concepts.</p><p>Using a computationally attractive algorithm, answers are derived.</p><p>The English parser is built with a handcrafted non-deterministic context-free grammar and a custom compiler-compiler. The resulting parser supports statistical modeling. To handle anaphora in the QA questions, the parser's standard anaphora resolver was modified to utilize the topic words as a potential target.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Run</head><p>For the TREC 2006 run, indexing was only rudimentarily optimized. It took about 5 days to index the entire corpora. For each topic, it typically would take between 2 and 7 minutes to look up in the index the documents that contain the topic, parse the sentences from the source documents, and perform the concept extraction. The query system would then be asked the questions. It would typically take under a minute to answer all the questions in a topic group. The system was reset, and the next topic was started.</p><p>The QA run, along with the research and software development, was performed on a mid-speed Pentium-class PC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Results</head><p>By my count, the software answered 9 out of 567 questions, 5 of them correctly (the judges count was both higher and lower, higher because some NIL answers were counted as correct, and lower because of non-specificity). Five correct is not an earth-shattering result. However, that it answered any questions correctly demonstrates the basic end-to-end framework is minimally functional, and provides a small proof-ofconcept for the algorithms on a larger corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Future Directions</head><p>Obviously, Diggery will need significant improvement before it even begins to approach alpha-level performance.</p><p>The vast majority of development time prior to submission was used creating building blocks, such as a dictionary, a parser, a grammar, the extractor components, an inference engine, anaphora resolution, the answer algorithm components, and test platforms. These blocks were required before any substantial testing of the extraction and answering algorithms could be performed, and, although there remain large issues to be addressed, they are now stable. Some of the building-block issues are: the grammar used by the parser needs to be improved; the inference engine needs more rules; a database of common knowledge needs to be incorporated; anaphora resolution needs improvements; a noun-reference resolver will improve accuracy; an ellipsis resolver needs to be built; although dates, times, and verb tenses are accurately extracted from source sentences and queries, the information is not currently used when answering a question; speed increases are desirable.</p><p>Many of these issues can now be put on the back burner while the core research proceeds.</p><p>Concept extraction and answer algorithm routines will be the primary focus of the research this next year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>The dearth of correct answers should not yet be perceived as an accurate indicator of future performance. As this short paper is being written, continued improvements are being made, and give hope that the algorithms will ultimately produce a robust system for accurately finding factoids and other information.</p></div>		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
