<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.66,154.89,465.94,15.11;1,191.06,176.81,229.15,15.11">Concept Recognition, Information Retrieval, and Machine Learning in Genomics Question-Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,111.85,209.29,106.32,10.48"><forename type="first">J</forename><forename type="middle">Gregory</forename><surname>Caporaso</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Computational Pharmacology</orgName>
								<orgName type="institution">University of Colorado Health Sciences Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,247.58,209.29,144.32,10.48;1,425.91,209.29,47.47,10.48"><forename type="first">William</forename><forename type="middle">A Hyunmin</forename><surname>Baumgartner</surname><genName>Jr</genName></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Computational Pharmacology</orgName>
								<orgName type="institution">University of Colorado Health Sciences Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,477.29,209.29,22.10,10.48;1,103.08,223.24,40.97,10.48"><forename type="first">Zhiyong</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Computational Pharmacology</orgName>
								<orgName type="institution">University of Colorado Health Sciences Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,147.95,223.24,13.82,10.48;1,189.69,223.24,38.12,10.48"><forename type="first">Helen</forename><forename type="middle">L</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Computational Pharmacology</orgName>
								<orgName type="institution">University of Colorado Health Sciences Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,237.00,223.24,41.85,10.48;1,306.78,223.24,24.07,10.48"><forename type="first">Olga</forename><surname>Johnson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Computational Pharmacology</orgName>
								<orgName type="institution">University of Colorado Health Sciences Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,334.74,223.24,56.58,10.48;1,419.24,223.24,27.64,10.48"><forename type="first">Anna</forename><surname>Medvedeva</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Computational Pharmacology</orgName>
								<orgName type="institution">University of Colorado Health Sciences Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,450.78,223.24,57.40,10.48;1,86.72,237.18,42.59,10.48"><forename type="first">Lynne</forename><forename type="middle">M</forename><surname>Lindemann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Computational Pharmacology</orgName>
								<orgName type="institution">University of Colorado Health Sciences Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,140.21,237.18,18.37,10.48;1,183.72,237.18,58.69,10.48"><forename type="first">Elizabeth</forename><forename type="middle">K</forename><surname>Fox</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Computational Pharmacology</orgName>
								<orgName type="institution">University of Colorado Health Sciences Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,252.49,237.18,31.54,10.48;1,309.17,237.18,66.17,10.48"><forename type="first">K</forename><forename type="middle">Bretonnel</forename><surname>White</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Computational Pharmacology</orgName>
								<orgName type="institution">University of Colorado Health Sciences Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,379.23,237.18,32.52,10.48;1,436.91,237.18,47.95,10.48"><forename type="first">Lawrence</forename><surname>Cohen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Computational Pharmacology</orgName>
								<orgName type="institution">University of Colorado Health Sciences Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,488.77,237.18,35.77,10.48"><surname>Hunter</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Computational Pharmacology</orgName>
								<orgName type="institution">University of Colorado Health Sciences Center</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.66,154.89,465.94,15.11;1,191.06,176.81,229.15,15.11">Concept Recognition, Information Retrieval, and Machine Learning in Genomics Question-Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">448B72D269120AB33883CDD7EED0CFAC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>TREC Genomics 2006 presented a genomics question-answering challenge with questions on twenty-seven topics, and a corpus of 162,259 full-text biomedical journal articles from which to derive answers. Questions were formulated from actual information needs of biomedical researchers, and performance was based on human evaluation of the answers. The University of Colorado approach to this task involved three key components: semantic analysis, document zoning, and a promiscuous retrieval approach followed by pruning by classifiers trained to identify near-misses.</p><p>We began by parsing the document HTML, splitting it into paragraph-length passages and classifying each passage with respect to a model of the sections (zones) of scientific publications. We filtered out certain sections, and built a search index for these passages using the Lemur system. Next, for each query, we semi-automatically created a set of expansions using ontological resources, including MeSH and the Gene Ontology. This expansion included not only synonyms, but terms related to concepts that were both more specific and (in some cases) more general than the query. We searched the passage collection for these expanded queries using the Indri search engine from the Lemur package, with pseudo-relevance feedback. We also tried expanding the retrieved pas-sages by adding passages that had a small cosine distance to the initial retrievals in an LSA-defined vector space. Our final step was to filter this expanded retrieval set with document classifiers whose input features included word stems and recognized concepts. Three separate runs were constructed using varying components of the above set, allowing us to explore the utility of each. The system produced the best result for at least one query in each of the three evaluations (document, passage and aspect diversity).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The University of Colorado approach to the 2006 TREC Genomics involved three key components: semantic analysis, document zoning, and a promiscuous retrieval style followed by pruning by classifiers trained to identify near-misses. Each of these components made a significant contribution to our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic Analysis</head><p>Our approach to QA (and NLP generally) is to develop methods for detecting expression of particular conceptual or ontological entities, regardless of how they are expressed in the text. We took several complementary approaches to recognition of such entities for this task. First, our query expansion step used on-1 tological resources such as MeSH and the Gene Ontology <ref type="bibr" coords="2,103.46,139.92,10.52,8.74" target="#b1">[2]</ref> to add conceptually related terms to the query. Not all such terms were synonyms; the goal was to do a broad retrieval of all documents that mentioned any concept related to the query. Second, we generated conceptual features for input to the pruning discriminators that were trained to distinguish among relevant documents and near-misses. We used conceptual features for recognizing generally important molecular biological concepts with many forms of expression (e.g. mutations), and for certain elements of the aforementioned ontological resources. Finally, we experimented with the Latent Semantic Analysis <ref type="bibr" coords="2,113.25,283.38,10.52,8.74" target="#b7">[8,</ref><ref type="bibr" coords="2,128.38,283.38,7.75,8.74" target="#b8">9,</ref><ref type="bibr" coords="2,140.73,283.38,12.73,8.74" target="#b13">14]</ref> approach to generate additional 'semantic' features for the discriminators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document Zoning</head><p>One of our early observations in preparing for this task was that many irrelevant retrievals were coming from particular document sections. For example, it was common to retrieve a citation to another document because its title was related to the query. Although the collection is diverse with respect to the way articles are divided into sections, the scientific publication idiom allows us to define generic document zones that should be ignored for the purposes of this task. Not only should the 'literature cited' section be ignored, but tables of abbreviations, acknowledgments, glossaries, and many generic document zones should be as well. Due to the diversity of document formats and section naming conventions, substantial development efforts had to be devoted to document zoning (see below). It is interesting to note that focusing NLP efforts on document zoning demonstrated value in many NLP applications <ref type="bibr" coords="2,72.00,558.35,15.50,8.74" target="#b11">[12,</ref><ref type="bibr" coords="2,90.82,558.35,12.73,8.74" target="#b12">13,</ref><ref type="bibr" coords="2,106.87,558.35,11.63,8.74" target="#b17">18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Promiscuity and Pruning</head><p>Our semantic query expansion methods are good for increasing recall, by retrieving potential responses that mention topics related to the query. However, this promiscuous query expansion also produces many documents that have only a tangential relationship to the query. What counts as a relevant response to a complex query like the ones in the Genomics task has to be defined in terms of the proper combinations of semantic contents. The presence of one or another semantic feature alone is not adequate to capture relevance; interactions among semantic features must be used. The sorts of interactions among semantic features that define relevance for any particular query can be quite complex, so we took an empirical approach to defining them. The semantic features of the documents retrieved in the promiscuous phase where used to train classifiers. We used human relevance judgments on a small sample of the training data to train the classifiers, hence our 'interactive' classification. (In one run, we omitted this step, putting us in the 'manual' class.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>The University of Colorado team approached this task by generating a candidate result set which was subsequently expanded (to improve recall) and then pruned (to improve precision). First, we converted questions into term-expanded queries. These queries were passed to the Indri search engine from the Lemur project <ref type="bibr" coords="2,377.74,426.23,14.61,8.74" target="#b14">[15]</ref>, which was indexed on all paragraphs from the document collection. Query results were zone-filtered to remove results from the document sections we considered likely to be entirely irrelevant. (We would have removed the paragraphs from the index completely given time, but instead used query constraints to rule out certain document sections. The particular sections ruled out could therefore be adjusted experimentally.) Pseudo-relevance feedback <ref type="bibr" coords="2,350.79,533.82,15.50,8.74" target="#b9">[10]</ref> on the top five returned documents was employed to expand search results. The collection of documents was again expanded from a pool of zone-filtered documents using latent semantic analysis. In a final, false-positive-eliminating step, we used naive Bayesian classifiers <ref type="bibr" coords="2,441.75,593.60,15.50,8.74" target="#b19">[20]</ref> trained on humanlabeled data with features including word stems and detected semantic concepts <ref type="bibr" coords="2,432.20,617.51,15.50,8.74" target="#b18">[19,</ref><ref type="bibr" coords="2,451.02,617.51,7.75,8.74" target="#b4">5,</ref><ref type="bibr" coords="2,462.09,617.51,11.63,8.74" target="#b10">11]</ref>.</p><p>We submitted a total of three runs which were generated using different components of our system. In the following sections we provide details on the individual components, and then describe how they were used to generate our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query preprocessing</head><p>Our first step in generating results for each topic involved converting the question into a query to be passed to our search engine. We chose to treat the different question templates identically, and focus our query processing efforts on expanding key terms to include synonyms which were likely to be important for system recall.</p><p>Query expansion was performed using Online Mendelian Inheritance in Man (OMIM) <ref type="bibr" coords="3,244.48,277.40,10.51,8.74" target="#b0">[1]</ref> and Information Hyperlinked over Proteins (iHOP) <ref type="bibr" coords="3,260.78,289.35,10.52,8.74" target="#b5">[6]</ref> to expand gene names to synonym lists. Semi-automated review of Medical Subject Headings (MeSH) terms was performed to expand terms involving biological processes, anatomy, and diseases to synonym lists. For general terms we similarly used the Gene Ontology to add more specific terms (e.g. liver development was expanded to include bile secretion and vitamin A synthesis). We additionally consulted with a resident ontological engineer to identify related concepts and to expand to appropriate broader terms (e.g. expanding cell growth to include proliferation and tumor ). Abbreviations which seemed likely to lead to many false positives (e.g. AD for Alzheimer's disease) were dropped from the expanded queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document preprocessing</head><p>According to the task definition, retrieved text spans could not cross HTML paragraph tags. In the first step of our work, we therefore built an HTML parser, split each full-text document on paragraph tags, recorded the original text spans and document sections, and assigned a unique identifier to each paragraph. Subsequent steps operated on the paragraph level, treating each as an independent document.</p><p>During this process HTML tags were stripped from each of the paragraphs, and the containing document section was recorded for each paragraph. Document sections were extracted by recognizing section headings in the html document, and associating all paragraphs contained between two section headings with the preceding section heading. We attempted to ignore subheadings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Concept recognition</head><p>We were interested in using semantic features both in indexing our search engine, and as potential features for machine-learning-based classifiers. We differentiate semantic features from surface-level features on the basis that surface-level features (e.g. words, word bigrams) represent language that are used to represent an idea, while semantic conceptual features represent an attempt to identify the underlying meaning being presented. For example, one semantic concept that we are interested in recognizing is point mutation. Given the sentence: "To understand the role of active site residues in the protein's function, we performed functional assays on the A42G, Y56F, and S57A variants", if simply using tokens as features, the fact that there is a reoccurring mention of protein point mutations cannot be represented. However, a simple regular-expression-based pattern match for identifying point mutations in text <ref type="bibr" coords="3,463.47,432.75,10.52,8.74" target="#b6">[7,</ref><ref type="bibr" coords="3,476.93,432.75,11.62,8.74" target="#b16">17]</ref>, recognizes the same concept, a point mutation, three times.</p><p>We were interested in recognizing several different semantic feature types. First, we wanted to recognize mentions of point mutations, as described above. For these we used the regular expressions of <ref type="bibr" coords="3,489.88,498.57,10.51,8.74" target="#b6">[7,</ref><ref type="bibr" coords="3,504.01,498.57,11.63,8.74" target="#b16">17]</ref>, and additional patterns which are under development by the Center for Computational Pharmacology [Caporaso, unpublished work]. Next, we recognized disease and organ names as concepts by matching strings of text to MeSH identifiers from MeSH's disease and organ branches. When multiple MeSH identifiers could be mapped to the same text string, the longest exact match was selected. (For example, the text string type 1 diabetes could be mapped to MeSH identifiers for Diabetes or Type 1 Diabetes. In such cases, we selected the latter.) We additionally tried to recognize the concepts protein transport and biological process regulation by normalizing from verbs which are indicative of these concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Zone filtering and document section normalization</head><p>Paragraphs were disallowed from document sections considered likely to be irrelevant: the References, Acknowledgments, Abbreviations, Disclosures, Grants, Glossary, Table of Contents, and Materials and Methods sections. Review of training data suggested that hits from these sections would likely be false positives. We considered a section such as Abbreviations, for example, to be particularly dangerous because it was likely to contain many important terms, but would not be relevant to a query. Probably our most surprising decision, to ignore Material and Methods sections, was based on the observation that these sections, which comprise a large portion of the corpus, often didn't contain information that was relevant to the queries presented.</p><p>We additionally included a length filtering step to disallow paragraphs which seemed to be the result of format errors in the original html files. In this step we eliminated paragraphs from our result sets which contained less than ten or greater than ten-thousand words. Paragraphs with less than ten words were often blocks of text contained within HTML paragraph tags, but which were not actually article paragraphs. Likewise, paragraphs containing more than ten-thousand words seemed to be the result of missing paragraph tags. A paragraph of greater than ten-thousand words would likely not be relevant to a query (in whole) and mistakenly returning one of these would be disastrous for system precision.</p><p>Successful zone-filtering of our corpus required normalization of section headings due to spelling and stylistic variations in the naming of sections. We compiled a list of the section headings we were able to extract ranked by their occurrence, and manually identified important normalization steps. In the most extreme example of spelling variations in the corpus, we found twelve variations in the spelling of acknowledgments which appeared at least twice. (Merriam-Webster's dictionary recognizes both acknowledgments and acknowledgements to be valid spellings.) Additionally, variations in section naming conventions were normalized to what we considered to be the section type. For example, we normalized sections referred to as References, Citations, List of works cited, and Suggested reading (among others) to a single type: refer, the Porter stemmer output of references, the most common of these variations.</p><p>We developed an algorithm for normalizing section headings based on manual analysis of a ranked listing of section headings occurring in the TREC corpus. The first step in this process involved converting the section heading to lowercase, replacing nonalphabetic characters with a single whitespace, removing leading and trailing whitespaces, and then applying the Porter stemmer <ref type="bibr" coords="4,446.98,259.66,15.49,8.74" target="#b15">[16]</ref> algorithm to all words. Next, two pattern matching steps were applied. First, an exact match was used to collapse the most common section headings to what we considered to be the section type. For example, in this stage we converted sections called Experimental procedures, Methods, and Study design to the type matmeth, on the basis that these sections generally discuss materials and methods used in the study. Last, we applied a non-exact pattern match step. This involved searching remaining unnormalized section headings for terms suggestive of specific section types. For example, if a section heading contained the term method, material, cell culture, or plasmid, we converted the section heading to matmeth. This inexact pattern matching allowed us to collapse many of the less commonly occurring section heading to underlying concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Information Retrieval</head><p>We employed a probabilistic approach for the nonpromiscuous document retrieval portion of our system using the Indri search engine from the Lemur project <ref type="bibr" coords="4,339.20,546.39,16.34,8.74" target="#b14">[15]</ref>. A domain expert generated the queries used for retrieval by weighting the terms and synonyms in each of the expanded queries. We experimented with both the #combine and #band operators for combining query terms. Before submission to the search engine, each query was fitted with constraints to rule out document sections that were deemed irrelevant in our document zoning analysis. Porter stemming and stop word removal were utilized during both indexing and querying. Conceptual features were integrated into the index, although our final queries did not utilize these. The top five documents were used for pseudo-relevance feedback and we allowed up to one thousand documents to be returned from each Indri query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Latent semantic analysis</head><p>To expand our result sets beyond what was achieved with Indri, query expansion, and pseudo-relevance feedback, we experimented with the sparseSVD (las2 algorithm), a C++ wrapper of the original SVD-PACKC package <ref type="bibr" coords="5,146.06,259.37,9.96,8.74" target="#b3">[4]</ref>, to perform latent semantic analysis (LSA). We ran sparseSVD over the 5,350,887 paragraphs of our zone-filtered corpus, beginning with a total of 86,118 word stems (i.e. a roughly 5million-paragraph x 86-thousand-word matrix). The word stems were reduced by SSVD to 200 features, which resulted in 5,350,887 length two-hundred document vectors. We used these vectors to expand our results by finding documents similar to those output by Indri which were not already in the result set. Similar documents were identified by computing the cosine of each Indri-produced document vector against all other document vectors, following the document similarity used in <ref type="bibr" coords="5,153.40,414.78,9.97,8.74" target="#b2">[3]</ref>, and returning the documents which yielded a cosine value greater than 0.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevance classification</head><p>In our final processing step, we applied naive Bayesian classifiers to retrieved paragraphs in an effort to eliminate false positives. Our classifiers were trained on a per-topic basis from human relevance judgements on selected paragraphs from the corpus.</p><p>Training corpora were developed for each topic by manually annotating positive and negative passages from results of simple Indri or grep queries. A group of four relevance judges reviewed possible answers for relevancy to be used for training. The judges were each assigned answer sets for six or seven topics. Judges reviewed at least 20 answers for each topic and marked the answer "not relevant," "definitely relevant," or "possibly relevant." Judges also noted the exact text span that included the answer, terms which might be useful in refining the initial Indri queries, and document sections which yielded high numbers of false positive results. Query expansion and zone-filtering were adjusted based on this information. Due to very limited annotation resources, these training sets generally contained only around 100 passages, with size varying with the number of query results.</p><p>During classifier optimization, we experimented with varied features types to identify those best suited to the task at hand. Feature types included features such as stemmed words and bigrams, and the various conceptual feature discussed above. We additionally compared performance of naive Bayes and Support Vector Machine classifiers, optimizing parameters for both. We found naive Bayes with kernel estimation to be best for this task.</p><p>Our best Weka <ref type="bibr" coords="5,388.29,308.27,15.50,8.74" target="#b19">[20]</ref> classifiers were constructed using word stems and DMAP-like concept matches as features. Feature selection was applied in two steps. First we removed stems which appeared in less than ten documents or more than fifty percent of the documents in the zone-filtered corpus, on the basis that these features would be too common or uncommon to be useful. Next, we calculated information gain (IG) for all remaining features and excluded features with information gain scores less than 0.001. (Most or all of the features eliminated by our first feature selection step would have been eliminated by IG selection, but pruning common and uncommon stems first greatly reduced IG compute time.) We used Weka's implementation of information gain, and optimization was performed to determine the optimal cut-off threshold using 10-fold cross validation of training data.</p><p>One classifier was constructed per topic, and these were applied to remove false positives before generating our submissions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We submitted three total runs, each of which included different components of our system. Our first run, uchsc1, utilized our full system. Expanded queries were sent to Indri and expanded with latent semantic analysis. LSA results were filtered with naive Bayes classifiers on a per-topic basis. In our second run, uchsc2, a looser set of queries were sent to Indri, but not expanded with LSA. Instead, the Indri results were pruned by the classifiers, and results submitted. In our last run, uchsc3, our first (strict) set of expanded queries were passed to Indri, and and those results were used without pruning by the classifiers. We categorized our first two runs as interactive (due to their reliance on manual annotation of training data for the pruning classifiers), and our third run, which did not use these classifiers, as manual. All runs were zone-filtered. Our systems performed well, with each of our runs scoring above mean on all three mean average precision (MAP) metrics. (Table <ref type="table" coords="6,209.18,486.62,4.43,8.74" target="#tab_0">1</ref>) Each of our three submissions achieved the maximum of each of the three MAP scores for at least one topic. An interesting feature of our system performances is that we do well in topics where the median scores were low. (Figure <ref type="figure" coords="6,108.53,546.39,4.43,8.74">1</ref>) A possible explanation for this result is that in topics where few groups were able to identify relevant passages our systems were far more sensitive, essentially allowing us to set the gold standard. For example, in topic 170 we achieved perfect document MAP, returning passages from 806 different documents, while the median was 7 percent. For our system to achieve perfect document MAP (in a nontrivial situation) it seems likely that most of the relevant documents must have come from our submission, and were missed in submissions of other groups.</p><p>We achieved the highest aspect diversity MAP for topic 170, the highest document MAP for topics 164, 170, 177, and 184, and the highest passage MAP for topics 161, 164, 170, and 174. (These comparisons are made against all runs classified as manual or interactive.) In situations where one of our runs outperformed the other two it was usually our second run (uchsc2) which did the best. However, in most cases, our three runs performed similarly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Section name normalization</head><p>Inherent ambiguity in section headings makes their normalization difficult. For example, it is often unclear what information differences exist between Results, Conclusions, and Discussion sections. In the TREC corpus, in addition to finding instances of sections named each of these terms, we found instances of all three pairwise combinations of these terms (e.g. Results and Discussion), and sections named some variation of all three terms combined (e.g. Results, Discussion, and Conclusions). To avert this issue, we converted all section headings containing any of the (stemmed) terms results, discussions, or conclusions to the single type resdisconc. However it is not clear that this is the best approach, or that a similar approach for other cases would be best. For example, is there enough difference in Background sections versus Introduction sections to warrant these being normalized to different types? For the purposes of TREC we considered these to be synonymous, but we feel that this could be argued either way.</p><p>Our work on normalization of section headings for TREC is crude, however we think that an accurate and general tool for zoning biomedical documents could be very useful in biomedical language processing. Our lab is currently exploring techniques for achieving this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Utility of latent semantic analysis</head><p>The utility of LSA is not apparent when comparing mean average precision scores between runs, but in-Figure <ref type="figure" coords="7,104.77,620.07,3.88,8.74">1</ref>: Performance in passage, document, and aspect diversity mean average precision. For (A) passage, (B) document, and (C) aspect diversity mean average precision, we present our best run compared with the median and best scores for the interactive/manual runs. Topics are sorted by median to illustrate that we often performed well in topics where the median performance was lowest. While we present our best run for each topic it should be noted that in most topics our three runs achieved equal performances. Also note that because the topics (x-axes) are sorted by median, and for each MAP that sort differs, the columns are not directly comparable between graphs.  <ref type="table" coords="9,159.60,187.74,4.43,8.74" target="#tab_1">2</ref>) (The most direct comparison is between runs uchsc1 and uchsc2, although in addition to LSA not being applied in uchsc2, Indri queries were slightly further expanded than in uchsc1. The expanded queries increased the number of hits from the search engine, so increases in the number of results due to LSA are understated.) Since the performance metrics used to judge submissions in this task do not highlight recall it is difficult for us to gauge the utility of LSA -without manually reviewing the results we cannot determine the relevance of the additional documents. However, based our observations in TREC, we expect that LSA would likely be beneficial in similar tasks where recall is important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantics and inference</head><p>We thought it interesting to note that while the goldstandard annotators were instructed not to make any inferences when judging relevance, our best results required use of semantically related but not synonymous terms in our query expansion, clearly a sort of inference. The value of concept recognizers in the pruning step can also be seen as a demonstration of the value of (computational) inference even in this (human) inference-constrained task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" coords="7,147.22,124.80,316.80,480.15"><head></head><label></label><figDesc></figDesc><graphic coords="7,147.22,124.80,316.80,480.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,72.00,264.02,228.64,169.91"><head>Table 1 :</head><label>1</label><figDesc>Performance compared to means. Our first two runs, uchsc1 and uchsc2, were interactive runs. Our third run, uchsc3, was a manual run. All of our runs out-performed the means for each of the three performance metrics.</figDesc><table coords="6,88.70,323.57,191.92,110.36"><row><cell>Run</cell><cell cols="3">Aspect Document Passage</cell></row><row><cell></cell><cell>MAP</cell><cell>MAP</cell><cell>MAP</cell></row><row><cell>uchsc1</cell><cell>0.250</cell><cell>0.406</cell><cell>0.055</cell></row><row><cell>uchsc2</cell><cell>0.247</cell><cell>0.419</cell><cell>0.056</cell></row><row><cell>interactive</cell><cell></cell><cell></cell><cell></cell></row><row><cell>mean</cell><cell>0.193</cell><cell>0.326</cell><cell>0.044</cell></row><row><cell>uchsc3</cell><cell>0.247</cell><cell>0.404</cell><cell>0.054</cell></row><row><cell>manual</cell><cell></cell><cell></cell><cell></cell></row><row><cell>mean</cell><cell>0.132</cell><cell>0.277</cell><cell>0.027</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,72.00,193.46,467.25,409.22"><head>Table 2 :</head><label>2</label><figDesc>Comparison of UCHSC runs. For our three runs we present the number of documents (#d) and the number of passage (#p) returned, and the passage, document, and aspect MAP achieved by each. submissions illustrates that its application often greatly increases the number of retrieved results. For example, in topic 170, applying LSA increases the number of passages we return from 384 to 850, and the number of documents we return from 249 to 806. (Table</figDesc><table coords="8,98.32,229.17,414.61,373.50"><row><cell>Topic</cell><cell>uchsc1</cell><cell>uchsc2</cell><cell>uchsc3</cell><cell cols="2">Passage MAP Document MAP</cell><cell>Aspect MAP</cell></row><row><cell></cell><cell cols="3">(#d/#p) (#d/#p) (#d/#p)</cell><cell>(uchsc1/2/3)</cell><cell>(uchsc1/2/3)</cell><cell>(uchsc1/2/3)</cell></row><row><cell>160</cell><cell>341/802</cell><cell>272/830</cell><cell cols="2">222/682 0.05/0.05/0.05</cell><cell>0.77/0.79/0.77</cell><cell>0.16/0.16/0.16</cell></row><row><cell>161</cell><cell>967/1000</cell><cell>84/108</cell><cell>25/29</cell><cell>0.09/0.10/0.09</cell><cell>0.66/0.73/0.66</cell><cell>0.60/0.60/0.60</cell></row><row><cell>162</cell><cell>439/478</cell><cell>24/53</cell><cell>12/37</cell><cell>0.03/0.03/0.03</cell><cell>0.29/0.29/0.29</cell><cell>0.17/0.17/0.17</cell></row><row><cell>163</cell><cell>48/1000</cell><cell>26/1000</cell><cell>16/958</cell><cell>0.03/0.03/0.03</cell><cell>0.46/0.46/0.46</cell><cell>0.07/0.07/0.07</cell></row><row><cell>164</cell><cell>48/50</cell><cell>26/31</cell><cell>16/17</cell><cell>0.26/0.26/0.26</cell><cell>0.69/0.69/0.69</cell><cell>0.54/0.54/0.54</cell></row><row><cell>165</cell><cell>3/3</cell><cell>4/4</cell><cell>3/3</cell><cell>0.05/0.05/0.05</cell><cell>0.17/0.17/0.17</cell><cell>0.48/0.48/0.48</cell></row><row><cell>166</cell><cell>8/14</cell><cell>8/14</cell><cell>8/14</cell><cell>0.00/0.00/0.00</cell><cell>0.09/0.09/0.09</cell><cell>0.07/0.07/0.07</cell></row><row><cell>167</cell><cell>132/404</cell><cell>169/481</cell><cell cols="2">132/404 0.16/0.16/0.16</cell><cell>0.67/0.69/0.67</cell><cell>0.32/0.33/0.32</cell></row><row><cell>168</cell><cell>301/633</cell><cell>172/616</cell><cell>65/394</cell><cell>0.10/0.10/0.10</cell><cell>0.84/0.85/0.84</cell><cell>0.27/0.27/0.27</cell></row><row><cell>169</cell><cell cols="2">681/1000 678/1000</cell><cell cols="2">674/993 0.02/0.02/0.02</cell><cell>0.07/0.07/0.07</cell><cell>0.05/0.05/0.05</cell></row><row><cell>170</cell><cell>806/850</cell><cell>249/384</cell><cell>8/41</cell><cell>0.11/0.11/0.11</cell><cell>1.00/1.00/1.00</cell><cell>0.83/0.83/0.83</cell></row><row><cell>171</cell><cell>36/36</cell><cell>186/204</cell><cell>1/1</cell><cell>0.01/0.01/0.01</cell><cell>0.03/0.03/0.03</cell><cell>0.38/0.38/0.38</cell></row><row><cell>172</cell><cell>691/1000</cell><cell>561/880</cell><cell cols="2">536/841 0.00/0.00/0.00</cell><cell>0.21/0.22/0.21</cell><cell>0.01/0.01/0.01</cell></row><row><cell>173</cell><cell>30/33</cell><cell>98/118</cell><cell>1/4</cell><cell>no results</cell><cell>no results</cell><cell>no results</cell></row><row><cell>174</cell><cell>306/330</cell><cell>249/548</cell><cell>50/74</cell><cell>0.16/0.17/0.16</cell><cell>0.46/0.50/0.46</cell><cell>0.85/0.85/0.85</cell></row><row><cell>175</cell><cell>22/23</cell><cell>22/25</cell><cell>7/8</cell><cell>0.05/0.05/0.05</cell><cell>0.37/0.37/0.37</cell><cell>0.39/0.39/0.39</cell></row><row><cell>176</cell><cell>925/1000</cell><cell>286/345</cell><cell>10/26</cell><cell>0.01/0.01/0.01</cell><cell>0.13/0.18/0.13</cell><cell>0.06/0.06/0.06</cell></row><row><cell>177</cell><cell>3/4</cell><cell>34/41</cell><cell>3/4</cell><cell>0.08/0.08/0.08</cell><cell>1.00/1.00/1.00</cell><cell>0.58/0.58/0.58</cell></row><row><cell>178</cell><cell>474/976</cell><cell>430/1000</cell><cell cols="2">377/874 0.00/0.00/0.00</cell><cell>0.02/0.02/0.02</cell><cell>0.01/0.01/0.01</cell></row><row><cell>179</cell><cell>313/339</cell><cell>112/155</cell><cell>24/34</cell><cell>0.00/0.00/0.00</cell><cell>0.02/0.02/0.02</cell><cell>0.03/0.03/0.03</cell></row><row><cell>180</cell><cell>564/577</cell><cell>61/82</cell><cell>11/13</cell><cell>no results</cell><cell>no results</cell><cell>no results</cell></row><row><cell>181</cell><cell>309/486</cell><cell>396/727</cell><cell cols="2">211/386 0.11/0.12/0.11</cell><cell>0.62/0.70/0.62</cell><cell>0.12/0.13/0.12</cell></row><row><cell>182</cell><cell cols="2">415/1000 392/1000</cell><cell cols="2">372/950 0.00/0.00/0.00</cell><cell>0.19/0.19/0.19</cell><cell>0.01/0.01/0.01</cell></row><row><cell>183</cell><cell>0/0</cell><cell>0/0</cell><cell>0/0</cell><cell>0.00/0.00/0.00</cell><cell>0.00/0.00/0.00</cell><cell>0.00/0.00/0.00</cell></row><row><cell>184</cell><cell>200/233</cell><cell>18/47</cell><cell>6/33</cell><cell>0.02/0.02/0.02</cell><cell>0.83/0.83/0.83</cell><cell>0.14/0.14/0.14</cell></row><row><cell>185</cell><cell>11/11</cell><cell>26/29</cell><cell>4/4</cell><cell>0.02/0.02/0.02</cell><cell>0.21/0.21/0.15</cell><cell>0.20/0.13/0.13</cell></row><row><cell>186</cell><cell>555/893</cell><cell>453/831</cell><cell cols="2">380/709 0.03/0.03/0.03</cell><cell>0.35/0.36/0.35</cell><cell>0.11/0.11/0.11</cell></row><row><cell>187</cell><cell>128/160</cell><cell>117/174</cell><cell>14/36</cell><cell>0.02/0.02/0.02</cell><cell>0.44/0.44/0.44</cell><cell>0.03/0.03/0.03</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We would like to thank <rs type="person">Xiangyu Jin</rs> for helpful discussion regarding probabilistic information retrieval.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="9,92.48,609.59,208.17,8.74;9,92.48,621.54,77.63,8.74" xml:id="b0">
	<analytic>
	</analytic>
	<monogr>
		<title level="m" coord="9,271.03,609.59,29.62,8.74;9,92.48,621.54,19.74,8.74">OMIM (TM)</title>
		<imprint>
			<date type="published" when="2006-07">July 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,92.48,642.03,208.16,8.74;9,92.48,653.99,208.17,8.74;9,92.48,665.94,208.17,8.74;9,331.08,127.96,208.17,8.74;9,331.08,139.92,208.17,8.74;9,331.08,151.87,208.17,8.74;9,331.08,163.83,208.16,8.74;9,331.08,175.78,208.16,8.74;9,331.08,187.74,133.43,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,331.08,163.83,208.16,8.74;9,331.08,175.78,175.90,8.74">Gene ontology: tool for the unification of biology. The Gene Ontology Consortium</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ashburner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">A</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Botstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Dolinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">S</forename><surname>Dwight</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">T</forename><surname>Eppig</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">P</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Issel-Tarver</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kasarskis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Matese</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">E</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ringwald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">M</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sherlock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,523.44,175.78,15.80,8.74;9,331.08,187.74,23.79,8.74">Nat Genet</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="29" />
			<date type="published" when="2000-05">May 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,331.08,208.66,208.18,8.74;9,331.08,220.61,208.17,8.74;9,331.08,232.57,208.17,8.74;9,331.08,244.52,205.01,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,456.86,208.66,82.39,8.74;9,331.08,220.61,50.99,8.74">Topic-based vector space model</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kuropka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,404.37,220.61,134.88,8.74;9,331.08,232.57,208.17,8.74;9,331.08,244.52,18.31,8.74">Proceedings of the 6th International Conference on Business Information Systems</title>
		<meeting>the 6th International Conference on Business Information Systems<address><addrLine>Colorado Springs</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-07">July 2003</date>
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,331.08,265.44,208.17,8.74;9,331.08,277.40,208.17,8.74;9,331.08,289.36,208.16,8.74;9,331.08,301.31,22.70,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,395.94,265.44,143.31,8.74;9,331.08,277.40,56.76,8.74">Large-scale sparse singular value computations</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Berry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,405.60,277.40,133.65,8.74;9,331.08,289.36,119.59,8.74">The International Journal of Supercomputer Applications</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13" to="49" />
			<date type="published" when="1992">Spring 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,331.08,322.23,208.17,8.74;9,331.08,334.19,208.17,8.74;9,331.08,346.14,22.70,8.74" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="9,408.74,322.23,130.51,8.74;9,331.08,334.19,29.63,8.74">Building embedded conceptual parsers</title>
		<author>
			<persName coords=""><forename type="first">Will</forename><surname>Fitzgerald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>Northwestern University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="9,331.08,367.06,208.17,8.74;9,331.08,379.02,208.16,8.74;9,331.08,390.97,44.69,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,470.24,367.06,69.00,8.74;9,331.08,379.02,121.40,8.74">A gene network for navigating the literature</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Valencia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,461.82,379.02,43.47,8.74">Nat Genet</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2004-07">July 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,331.08,411.90,208.17,8.74;9,331.08,423.85,208.17,8.74;9,331.08,435.81,208.17,8.74;9,331.08,447.76,208.16,8.74;9,331.08,459.72,208.17,8.74;9,331.08,471.67,22.70,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,365.95,423.85,173.30,8.74;9,331.08,435.81,208.17,8.74;9,331.08,447.76,208.16,8.74;9,331.08,459.72,37.96,8.74">Automated extraction of mutation data from the literature: application of MuteXt to G protein-coupled receptors and nuclear hormone receptors</title>
		<author>
			<persName coords=""><forename type="first">Florence</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anthony</forename><forename type="middle">L</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fred</forename><forename type="middle">E</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,381.28,459.72,62.71,8.74">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="557" to="568" />
			<date type="published" when="2004-03">Mar 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,331.08,492.59,208.17,8.74;9,331.08,504.55,208.16,8.74;9,331.08,516.50,208.17,8.74;9,331.08,528.46,170.84,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,405.51,504.55,133.73,8.74;9,331.08,516.50,208.17,8.74;9,331.08,528.46,20.11,8.74">Hierarchical structures induce long-range dynamical correlations in written texts</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Lacalle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Dorow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Eckmann</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Moses</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,359.63,528.46,23.95,8.74">PNAS</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="7956" to="7961" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,331.08,549.38,208.17,8.74;9,331.08,561.34,208.17,8.74;9,331.08,573.29,208.16,8.74;9,331.08,585.25,180.12,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,516.39,549.38,22.86,8.74;9,331.08,561.34,208.17,8.74;9,331.08,573.29,108.63,8.74">From paragraph to graph: latent semantic analysis for information visualization</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Laham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Derr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,452.36,573.29,86.89,8.74">Proc Natl Acad Sci</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5214" to="5219" />
			<date type="published" when="2004-04">April 2004</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
	<note>Suppl</note>
</biblStruct>

<biblStruct coords="9,331.09,606.17,208.16,8.74;9,331.08,618.12,208.16,8.74;9,331.08,630.08,208.17,8.74;9,331.08,642.03,208.17,8.74;9,331.08,653.99,208.16,8.74;9,331.08,665.94,126.19,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,496.22,606.17,43.03,8.74;9,331.08,618.12,97.63,8.74">Relevance based language models</title>
		<author>
			<persName coords=""><forename type="first">Victor</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bruce</forename><forename type="middle">W</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,450.50,618.12,88.75,8.74;9,331.08,630.08,208.17,8.74;9,331.08,642.03,208.17,8.74;9,331.08,653.99,88.92,8.74">SIGIR &apos;01: Proceedings of the 24th annual international ACM SI-GIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,92.47,127.96,208.17,8.74;10,92.48,139.92,169.24,8.74" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="10,180.35,127.96,120.29,8.74;10,92.48,139.92,12.22,8.74">Direct memory access parsing</title>
		<author>
			<persName coords=""><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Martin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
		<respStmt>
			<orgName>Yale University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="10,92.47,157.93,208.18,8.74;10,92.48,169.89,208.16,8.74;10,92.48,181.85,208.17,8.74;10,92.48,193.80,208.16,8.74;10,92.48,205.76,208.16,8.74;10,92.48,217.71,22.70,8.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,208.21,157.93,92.44,8.74;10,92.48,169.89,208.16,8.74;10,92.48,181.85,15.94,8.74">Zone identification in biology articles as a basis for information extraction</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Mizuta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Collier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,132.97,181.85,167.68,8.74;10,92.48,193.80,208.16,8.74;10,92.48,205.76,144.11,8.74">Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications</title>
		<meeting>the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="29" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,92.47,235.73,208.17,8.74;10,92.48,247.69,208.17,8.74;10,92.48,259.64,208.16,8.74;10,92.48,271.60,208.16,8.74;10,92.48,283.55,22.70,8.74" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,92.48,247.69,208.17,8.74;10,92.48,259.64,208.16,8.74;10,92.48,271.60,19.49,8.74">A baseline feature set for learning rhetorical zones using full articles in the biomedical domain</title>
		<author>
			<persName coords=""><forename type="first">Tony</forename><surname>Mullen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yoko</forename><surname>Mizuta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nigel</forename><surname>Collier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,119.51,271.60,103.00,8.74">SIGKDD Explor. Newsl</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="52" to="58" />
			<date type="published" when="2005-06">June 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,92.47,301.57,208.17,8.74;10,92.48,313.53,208.17,8.74;10,92.48,325.48,208.17,8.74;10,92.48,337.44,208.17,8.74;10,92.48,349.39,22.70,8.74" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="10,267.78,313.53,32.87,8.74;10,92.48,325.48,208.17,8.74;10,92.48,337.44,102.27,8.74">Analyzing Entities and Topics in News Articles Using Statistical Topic Models</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chaitanya</forename><surname>Chemudugunta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Padhraic</forename><surname>Smyth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Steyvers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006-01">January 2006</date>
			<biblScope unit="volume">3975</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,92.47,367.41,208.17,8.74;10,92.48,379.37,208.17,8.74;10,92.48,391.32,58.95,8.74" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,245.90,367.41,54.74,8.74;10,92.48,379.37,98.71,8.74">Experiments using the lemur toolkit</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Ogilvie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><forename type="middle">P</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,211.92,379.37,88.73,8.74;10,92.48,391.32,28.82,8.74">Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,92.47,409.34,208.17,8.74;10,92.48,421.30,131.74,8.74" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,155.43,409.34,141.05,8.74">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,92.48,421.30,34.40,8.74">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,92.47,439.31,208.17,8.74;10,92.48,451.27,208.16,8.74;10,92.48,463.22,208.16,8.74;10,92.48,475.18,208.17,8.74;10,92.48,487.14,205.79,8.74" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,146.93,463.22,153.71,8.74;10,92.48,475.18,201.69,8.74">Automatic extraction of mutations from Medline and cross-validation with OMIM</title>
		<author>
			<persName coords=""><forename type="first">Dietrich</forename><surname>Rebholz-Schuhmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephane</forename><surname>Marcel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sylvie</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ralf</forename><surname>Tolle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Georg</forename><surname>Casari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Harald</forename><surname>Kirsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,92.48,487.14,70.75,8.74">Nucl. Acids Res</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="135" to="142" />
			<date type="published" when="2004-01">January 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,92.47,505.15,208.18,8.74;10,92.48,517.11,208.16,8.74;10,92.48,529.06,208.17,8.74;10,92.48,541.02,208.17,8.74;10,92.48,552.98,154.92,8.74" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,173.61,517.11,127.03,8.74;10,92.48,529.06,208.17,8.74;10,92.48,541.02,119.30,8.74">Rule-based extraction of experimental evidence in the biomedical domain: the kdd cup 2002 (task 1)</title>
		<author>
			<persName coords=""><forename type="first">Yizhar</forename><surname>Regev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michal</forename><surname>Finkelstein-Landau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ronen</forename><surname>Feldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,224.49,541.02,76.16,8.74;10,92.48,552.98,26.62,8.74">SIGKDD Explor. Newsl</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="90" to="92" />
			<date type="published" when="2002-12">December 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,92.47,570.99,208.17,8.74;10,92.48,582.95,208.17,8.74;10,92.48,594.90,208.17,8.74;10,92.48,606.86,22.70,8.74" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="10,210.36,570.99,90.28,8.74;10,92.48,582.95,208.17,8.74;10,92.48,594.90,34.50,8.74">From conceptual analyzer to Direct Memory Access Parsing: an overview</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Riesbeck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Ellis Horwood Limited</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,92.47,624.88,208.18,8.74;10,92.48,636.83,208.17,8.74" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="10,241.18,624.88,59.47,8.74;10,92.48,636.83,203.89,8.74">Data Mining: Practical machine learning tools and techniques</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,92.48,648.79,208.17,8.74;10,92.48,660.74,22.70,8.74" xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Morgan</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">San</forename><surname>Francisco</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
