<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,185.28,98.63,232.44,15.51;1,201.84,120.59,199.45,15.51">Reconstructing DIOGENE: ITC-irst at TREC 2006</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,139.44,153.97,56.57,9.96"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
							<email>negri@itc.it</email>
							<affiliation key="aff0">
								<orgName type="department">Centro per la Ricerca Scientifica e Tecnologica</orgName>
								<orgName type="institution">ITC-irst</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,203.64,153.97,71.83,9.96"><forename type="first">Milen</forename><surname>Kouylekov</surname></persName>
							<email>kouylekov@itc.it</email>
							<affiliation key="aff0">
								<orgName type="department">Centro per la Ricerca Scientifica e Tecnologica</orgName>
								<orgName type="institution">ITC-irst</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,283.34,153.97,77.41,9.96"><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
							<email>magnini@itc.it</email>
							<affiliation key="aff0">
								<orgName type="department">Centro per la Ricerca Scientifica e Tecnologica</orgName>
								<orgName type="institution">ITC-irst</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,368.81,153.97,94.82,9.96"><forename type="first">Bonaventura</forename><surname>Coppola</surname></persName>
							<email>coppolab@itc.it</email>
							<affiliation key="aff0">
								<orgName type="department">Centro per la Ricerca Scientifica e Tecnologica</orgName>
								<orgName type="institution">ITC-irst</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,185.28,98.63,232.44,15.51;1,201.84,120.59,199.45,15.51">Reconstructing DIOGENE: ITC-irst at TREC 2006</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DF6D07DC8ACFBF191C6B6792992C9D6F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our participation in the TREC 2006 QA task is the first step on the way of developing a new and improved DIOGENE system. The leading principles of this re-engineering activity are: i) to create a modular architecture, based on a pipeline of modules which share common I/O formats, open to the insertion/substitution of new components; ii) to allow for the capability of configuring the settings of the different modules with external configuration files; iii) to provide the capability of performing fine-grained evaluation cycles over the individual processing modules which compose a QA system. Another long-term objective of our work on QA, is to make the core components of the system freely available to the QA community for research purposes. This paper overviews the work done up to date to achieve these objectives, focusing on the description of a prototype module designed to handle the anaphoric questions often contained into TREC QA series. Preliminar evaluation results of the new module are presented, together with those achieved by DIOGENE at TREC 2006.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This year the ITC-irst activity on Question Answering (QA) has been concentrated on system re-engineering. Our objective is to transform our DIOGENE QA system into a more modular architecture whose basic components are completely separated, easily testable with rapid turnaround of controlled experiments, and easily replaceable with new implementations. In this direction, our long-term ambition is to make all these components (or even the entire system) freely available in the future to the QA community for research purposes.</p><p>Up to date we are halfway in our roadmap, and unfortunately the results of our participation in TREC 2006 reflect this situation. While most of the original system's components are now separated from each other, the work done to improve their performance has not led to concrete results yet. Moreover, as it emerged from the analysis achieved by our TREC 2006 submitted run, a number of bugs still affect the overall system's behavior.</p><p>Besides the effort in the modularity direction, the main directions of improvement pursued this year concern all the basic component of the architecture of DIOGENE.</p><p>As for Question Processing, the first version of a module to handle follow-up questions has been implemented. Such module, on which this paper is focused, is in charge of tracking the correct referent of anaphoric questions contained into a TREC series.</p><p>As for Document Retrieval, this year's novelty is the substitution of the MG search engine <ref type="bibr" coords="1,90.00,636.25,15.49,9.96" target="#b9">[10]</ref> with Lucene <ref type="bibr" coords="1,165.72,636.25,9.91,9.96" target="#b2">[3]</ref>, an open-source, cross-platform search engine, which allows for customizable document ranking schemes. The many advantages of Lucene now do enable us to implement more refined strategies for indexing, ranking, and querying the target document collection.</p><p>As for Answer Extraction, we improved the candidate answers selection process by developing a more effective way to handle "generic" factoid questions (i.e. questions whose expected answer type does not belong to the six broad named entity categories currently handled by DIO-GENE). Generic questions are now handled extracting, as possible answer candidates, all the hyponyms of the question focus that are found in the text passages returned by the search engine. For instance, given the question Q:"What instrument did Jimi Hendrix play?", the answer extraction module will select "guitar" as a possible answer candidate as it is an hyponym of "instrument", which is the focus of the question.</p><p>As for Answer Validation (AV), new strategies to select the best answer among a set of possible candidates have been implemented. Besides our well tested statistical approach to the problem, described in <ref type="bibr" coords="2,188.17,156.97,10.00,9.96" target="#b5">[6]</ref>, we plan to include in our AV package a new method based on textual entailment recognition, allowing the user for experimentations with different AV settings (see <ref type="bibr" coords="2,499.67,168.97,10.00,9.96" target="#b3">[4]</ref>, <ref type="bibr" coords="2,90.00,180.85,10.00,9.96" target="#b4">[5]</ref>, and <ref type="bibr" coords="2,126.01,180.85,10.45,9.96" target="#b6">[7]</ref> for further details) .</p><p>Since the improvements on document retrieval, answer extraction, and answer validation have already been documented in previous works, the rest of this paper concentrates on the newest extension of the system (i.e. the improved question processing component), specifically designed for this year's participation in TREC. A preliminary solution to the problem of tracking the questions' referent in a QA series is reported, together with the evaluation results achieved both by the implemented module (over the TREC 2005 test set), and the overall DIOGENE system (in the TREC 2006 Main QA task).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dealing with QA series</head><p>In the framework of the main evaluation campaigns (i.e. TREC<ref type="foot" coords="2,380.64,318.57,3.97,4.77" target="#foot_0">1</ref> , CLEF<ref type="foot" coords="2,418.92,318.57,3.97,4.77" target="#foot_1">2</ref> , and NTCIR<ref type="foot" coords="2,483.72,318.57,3.97,4.77" target="#foot_2">3</ref> ), the complexity of the input questions is constantly increasing. Adhering to the roadmap for QA research <ref type="bibr" coords="2,128.75,343.21,9.91,9.96" target="#b0">[1]</ref>, for instance, the test set of the TREC QA task moved from a list of simple isolated factoid questions <ref type="bibr" coords="2,165.84,355.21,73.58,9.96">(TREC 2000 and</ref><ref type="bibr" coords="2,242.05,355.21,22.31,9.96" target="#b0">2001)</ref>, to the heterogeneous question typologies used in the last editions. Since 2004 <ref type="bibr" coords="2,180.73,367.21,10.00,9.96" target="#b7">[8]</ref>, systems participating in TREC are presented with "factoid", "list", and "other" questions grouped into series. Each series has the target of a definition associated with it (including people, organizations, events, and other entities), which provides the initial context of the session. Each question in a series asks for additional information either about the target, or about the context originated by answers to the preceding questions in the session. The main objective of this evaluation setting is to provide an abstraction of an information dialog in which the user is trying to define the target. In a real-world scenario, in fact, questions are not asked in isolation, but rather in a cohesive manner that often involves a sequence of related questions to meet the users information needs.</p><p>One of the complexity factors in the proposed evaluation scenario is related to the presence of anaphoric expressions within the input questions. These may refer either to the target of the series, or to the answer given to a previous question. The example reported in Figure <ref type="figure" coords="2,436.57,498.73,4.98,9.96">1</ref> provides a clear picture of the situation. While some questions in the series (i.e. questions 136.1, 136.4, 136.6, and 136.7) are non anaphoric and relatively easy to handle, others (i.e. questions 136.2, 136.3, 136.5) show a shift of the referent, realized by means of anaphoric expressions (i.e. the pronouns "his" and "he", and the nominal construct "this person"), which makes them more difficult to manage. In this framework, where question interpretation has to be situated in a particular context as the QA session proceeds, anaphora resolution and referent tracking capabilities emerge as key features of a QA system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Our approach</head><p>In the past TREC editions the typical approach to anaphoric questions was a simple rewriting procedure, based on the substitution of question's pronouns with the target of the series <ref type="bibr" coords="2,499.67,640.57,10.00,9.96" target="#b7">[8]</ref>. Following this approach, once the input has been transformed into a question whose interpretation target id="136" text="Shiite"</p><p>• q id="136.1" Who was the first Imam of the Shiite sect of Islam?</p><p>• q id="136.2" Where is his tomb?</p><p>• q id="136.3" What was this person's relationship to the Prophet Mohammad?</p><p>• q id="136.4" Who was the third Imam of Shiite Muslims?</p><p>• q id="136.5" When did he die?</p><p>• q id="136.6" What portion of Muslims are Shiite?</p><p>• q id="136.7" What Shiite leaders were killed in Pakistan?</p><p>• q id="136.8" Other Figure <ref type="figure" coords="3,212.41,312.01,3.90,9.96">1</ref>: A series from the TREC-2005 main QA task.</p><p>does not depend on the surrounding context, the analysis is carried out in the same way as it is done with non-anaphoric questions. Unfortunately, this solution is no longer feasible under the conditions of a "natural" dialogue-like series. In this situation (as it is reflected by the TREC 2005 and 2006 test sets), we must take into account that:</p><p>1. The target may be a complex or vague concept, which is not easy to describe with a single noun or named entity (e.g. "Russian submarine Kursk sinks", "France wins World Cup in soccer", "first 2000 Bush-Gore presidential debate");</p><p>2. Follow-up questions do not necessarily refer to the series target, but also to answers given to previous questions.</p><p>On the one side, the complexity of the target makes the question reformulation procedure a hard and error-prone task (consider, for instance, the target/question pair: T="Plane clips cable wires in Italian resort", Q= "When did the accident occur?"). On the other side, as the series proceeds, a mechanism to track the actual referent of each question becomes necessary.</p><p>In light of these considerations, our solution adopts a bag-of-words approach which gets round the question reformulation problem, still remaining capable to track the referent as a series proceeds. The underlying assumption is that combining the right keywords to search the document collection is safer that trying to rewrite the input question in a "complete" form. In practice, once the referent of an input question has been chosen (between the target and the answer to an earlier question), its terms are combined with the question keywords into a query to the document collection. In case of reference shifts, a new referent remains valid until a non-anaphoric question is found. Following this idea, our question processing component carries out the analysis of each question (i.e. answer type recognition, keywords extraction, keywords expansion, query composition) as it is (i.e. without resolving anaphora), leaving to the document retrieval component the task of finding the best matching text portions.</p><p>Adopting this approach the problem of dealing with anaphoric questions in a TREC-like QA series is "reduced" to the problem of finding the right referent of each question. The next section describes how this task is accomplished by means of a classifier opportunely trained. q i-1 -contains-LifeForms (0, 1): set to 1 if q i-1 contains at least one WordNet hyponym of "life form". q i-1 -first-LifeForm-position (integer): position of the first hyponym of "life form" in q i-1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Evaluation</head><p>A preliminary experiment has been carried out to evaluate the viability of the proposed solution. For this purpose, our classifier has been trained using a decision tree algorithm (namely the Weka J48 algorithm <ref type="bibr" coords="5,155.53,167.41,10.31,9.96" target="#b8">[9]</ref>). At first glance, the results of this evaluation are encouraging. The 10-fold cross-validation over the training set resulted in fact in 505 out of 530 instances correctly classified (corresponding to an accuracy of 95.28%). However, as can be observed from the confusion matrix reported in Table <ref type="table" coords="5,166.21,203.29,3.90,9.96" target="#tab_0">1</ref>, the performance over the three classes is not uniform, reflecting the unbalanced distribution of the examples in the training. In particular, unsurprisingly, only 4 instances out of 16 (25%) of the class less represented in the training set (Type2 ) are correctly recognized. Apart from these very preliminary results, further conclusions on the suitability of our approach to TREC-like QA series will be drawn after a thorough analysis of the results of our run submitted to TREC 2006. Even though, as foreseen, the overall performance of the system (see Table <ref type="table" coords="5,493.89,364.57,4.46,9.96" target="#tab_1">2</ref>) is rather poor, the possibility of separately evaluating the behavior of each single module will provide us with additional evidence about the effectivenes of our approach. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Conclusions</head><p>DIOGENE, the QA system developed at ITC-irst, is currently subject to an heavy re-implementation process. This activity aims at creating a more modular system, easier to modify and evaluate under different parameters settings, and open for a future distribution for research purposes.</p><p>In this paper we reported the main improvement directions we are pursuing, and described one of the newest modules specifically designed to participate in TREC 2006. Such module is in charge of determining the correct referent of anaphoric questions in a TREC-like QA series. One of the specific issues raised by follow-up questions, in fact, is to track the target shifts that often occur as the series proceeds. Focusing on this problem, we presented a very preliminary experiment with a classifier trained over the TREC 2005 question set.</p><p>We also reported the results achieved at TREC 2006. As foreseen, the evaluation reflects the work-in-progress situation and, unfortunately, the impact of a number of bugs which was not worth describing here.</p><p>In the next future, after a thorough error analysis, the re-implementation process will continue following the criteria mentioned above. As for the question analysis component, since there is still room for improvement, future developments will follow two complementary directions. More precisely: i) a more accurate feature selection, trying to find a set of more discriminative features; and ii) learning the model from a larger set of training examples (e.g. including the TREC 2006 series), trying to balance the number of examples of the question typologies we want to deal with.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,228.72,250.45,145.50,68.88"><head>Table 1 :</head><label>1</label><figDesc>Confusion matrix</figDesc><table coords="5,228.72,250.45,145.50,46.92"><row><cell></cell><cell cols="3">Type0 Type1 Type2</cell></row><row><cell>Type0</cell><cell>82</cell><cell>12</cell><cell>0</cell></row><row><cell>Type1</cell><cell>0</cell><cell>344</cell><cell>1</cell></row><row><cell>Type2</cell><cell>0</cell><cell>12</cell><cell>4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,189.60,411.13,223.98,132.72"><head>Table 2 :</head><label>2</label><figDesc>DIOGENE at TREC 2006    </figDesc><table coords="5,189.60,411.13,223.98,110.88"><row><cell cols="2">Statistics over 403 questions</cell></row><row><cell>Number wrong (W)</cell><cell>325</cell></row><row><cell>Number unsupported (U)</cell><cell>10</cell></row><row><cell>Number inexact (X)</cell><cell>12</cell></row><row><cell>Number locally correct (L)</cell><cell>2</cell></row><row><cell>umber globally right (R)</cell><cell>54</cell></row><row><cell>Accuracy</cell><cell>0.134</cell></row><row><cell cols="2">Precision of recognizing no answer 7/114 = 0.061</cell></row><row><cell>Recall of recognizing no answer</cell><cell>7/17 = 0.412</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.24,671.58,71.52,7.97"><p>http://trec.nist.gov</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,105.24,681.18,116.02,7.97"><p>http://www.clef-campaign.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,105.24,690.66,113.75,7.97"><p>http://research.nii.ac.jp/ntcir/</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Question referent selection</head><p>Training corpus. To develop our referent tracking module, a training corpus has been manually annotated starting from the test set of the TREC 2005 main QA task (75 series, for a total of 530 questions).</p><p>Each question q i , in a series S having T as a target, has been classified with respect to the three typologies we want to deal with, namely: Type0 : non anaphoric questions; Type1 : anaphoric questions referring to T ; Type2 : anaphoric questions referring to the answer given to the preceding question in S (referred to as q i-1 ).</p><p>Unfortunately, the distribution over the three typologies in the training corpus is rather unbalanced, with 129 questions assigned to Type0, 385 assigned to Type1, and only 16 assigned to Type2. Even though this unbalanced distribution is likely to reflect a real-world situation, the possible impact on the learning process should not be neglected. In fact, unless very discriminative features will be selected, the large amount of Type1 questions will probably influence the classifier's performance, determining a bias towards this class.</p><p>Learning features. A classifier has been trained considering the following features of the target T, the current question q i , and the previous question q i-1 in a series S :</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• T features:</head><p>T-has-verbs (0, 1): set to 1 if T contains at least one verb, 0 otherwise. T-capitalized (0, 1): set to 1 if all the words in T are capitalized.</p><p>T-contains-LifeForms (0, 1): set to 1 if T contains at least one hyponym of "life form" in WordNet <ref type="bibr" coords="4,157.81,378.61,10.00,9.96" target="#b1">[2]</ref>.</p><p>T-first-LifeForm-position (integer): position of the first hyponym of "life form" in T.</p><p>• q i Features:</p><p>q i -number-in-Session (integer): q i position in S. q i -Type (1,..., 3): factoid=1, list=2, other=3. q i -StartsWith (0,..., 7): "who"=0, "where"=1, "when"=2, "which"=3, "what"=4 "how+adj"=5, "how+verb"=6 other=7.</p><p>q i -contains-Target-tokens (0, 1): set to 1 if q i contains at least one token present in T. q i -contains-Target-lemmas (0, 1): set to 1 if q i contains at least one lemma of a term in T.</p><p>q i -contains-prons (0, 1): set to 1 if q i contains at least one pronoun. q i -contains-pers-prons (0, 1): set to 1 if q i contains at least one personal pronoun. q i -contains-ThisPlusTargetWord (0, 1): set to 1 if q i contains the word "this" followed by a term present in T.</p><p>q i -contains-ThisPlusWord (0, 1): set to 1 if q i contains the word "this" followed by any term non present in T.</p><p>q i -contains-ThisPlusQ1Noun (0, 1): set to 1 if q i contains at least one noun present in q i-1 . q i -contains-LifeForms (0, 1): set to 1 if q i contains at least one hyponym of "life form" in WordNet.</p><p>q i -first-LifeForm-position (integer): position of the first hyponym of "life form" in q i .</p><p>• q i-1 Features:</p><p>q i-1 -Type (1,..., 3): factoid=1, list=2, other=3. q i-1 -StartsWith (0,..., 7): "who"=0, "where"=1, "when"=2, "which"=3, "what"=4 "how+adj"=5, "how+verb"=6 other=7.</p><p>q i-1 -contains-pers-pron (0, 1): set to 1 if q i-1 contains at least one personal pronoun.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="6,110.52,235.69,402.58,9.96;6,110.52,247.57,402.52,9.96;6,110.52,259.57,402.51,9.96;6,110.52,271.57,402.73,9.96;6,110.52,283.45,402.25,9.96;6,110.52,295.45,76.69,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,490.69,259.57,22.34,9.96;6,110.52,271.57,402.73,9.96;6,110.52,283.45,145.41,9.96">Ellen Voorhees, and Ralph Weishedel. Issues, Tasks and Program Structures to Roadmap Research in Question &amp; Answering (Q&amp;A)</title>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vinay</forename><surname>Chaudhri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sanda</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Israel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Jacquemin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steve</forename><surname>Maiorano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">George</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dan</forename><surname>Moldovan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bill</forename><surname>Ogden</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Prager</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amit</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rohini</forename><surname>Shrihari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tomek</forename><surname>Strzalkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,282.36,283.45,230.42,9.96;6,110.52,295.45,45.58,9.96">Document Understanding Conferences Roadmapping Documents</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.52,315.37,360.84,9.96" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="6,205.92,315.37,181.17,9.96">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName coords=""><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.53,335.29,402.58,9.96;6,110.52,347.29,96.48,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,272.28,335.29,74.60,9.96">Lucene in Action</title>
		<author>
			<persName coords=""><forename type="first">Erik</forename><surname>Hatcher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Otis</forename><surname>Gospodnetic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,367.44,335.29,59.45,9.96">Action series)</title>
		<imprint>
			<publisher>Manning Publications</publisher>
			<date type="published" when="2004-12">December 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.53,367.21,402.48,9.96;6,110.52,379.09,198.52,9.96" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Milen</forename><surname>Kouylekov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<title level="m" coord="6,298.68,367.21,214.33,9.96;6,110.52,379.09,81.55,9.96">Proceedings of PASCAL Workshop on Recognizing Textual Entailment</title>
		<meeting>PASCAL Workshop on Recognizing Textual Entailment<address><addrLine>Southampton, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.53,399.01,402.48,9.96;6,110.52,411.01,177.49,9.96" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Milen</forename><surname>Kouylekov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<title level="m" coord="6,298.68,399.01,214.33,9.96;6,110.52,411.01,81.55,9.96">Proceedings of PASCAL Workshop on Recognizing Textual Entailment</title>
		<meeting>PASCAL Workshop on Recognizing Textual Entailment<address><addrLine>Venezia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.53,430.93,402.62,9.96;6,110.52,442.93,402.50,9.96;6,110.52,454.81,402.56,9.96;6,110.52,466.81,93.74,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,417.96,430.93,95.19,9.96;6,110.52,442.93,204.82,9.96">Is it the right answer? exploiting web redundancy for answer validation</title>
		<author>
			<persName coords=""><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roberto</forename><surname>Prevete</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hristo</forename><surname>Tanev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,345.36,442.93,167.66,9.96;6,110.52,454.81,260.94,9.96">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, ACL-2002</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics, ACL-2002<address><addrLine>Philadelphia (PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-07">July 2002</date>
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.53,486.73,402.71,9.96;6,110.52,498.73,402.38,9.96;6,110.52,510.61,125.91,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,476.66,486.73,36.57,9.96;6,110.52,498.73,283.31,9.96">Towards Entailment-based Question Answering: ITC-irst at CLEF 2006</title>
		<author>
			<persName coords=""><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Milen</forename><surname>Kouylekov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bonaventura</forename><surname>Coppola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,420.48,498.73,92.43,9.96;6,110.52,510.61,22.71,9.96">CLEF-2006 Working Notes</title>
		<meeting><address><addrLine>Alicante, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.53,530.53,402.28,9.96;6,110.52,542.53,78.61,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,186.13,530.53,248.70,9.96">Overview of the TREC 2004 Question Answering Track</title>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,459.96,530.53,52.85,9.96;6,110.52,542.53,47.97,9.96">TREC 2004 Proceedings</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.53,562.45,402.48,9.96;6,110.52,574.45,111.52,9.96" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="6,245.28,562.45,263.45,9.96">Data Mining: Practical machine learning tools and techniques</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.53,594.37,402.32,9.96;6,110.52,606.25,390.54,9.96" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="6,346.56,594.37,166.29,9.96;6,110.52,606.25,246.57,9.96">The second edition of Managing Gigabytes: Compressing and Indexing Documents and Images</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alistair</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Timothy</forename><forename type="middle">C</forename><surname>Bell</surname></persName>
		</author>
		<imprint>
			<publisher>Morgan Kaufmann Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
