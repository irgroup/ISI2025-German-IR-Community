<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,125.63,84.91,360.74,12.91;1,166.07,103.20,279.86,9.82">Multiple Ranking Strategies for Opinion Retrieval in Blogs The University of Amsterdam at the 2006 TREC Blog Track</title>
				<funder ref="#_Qx4wUZT">
					<orgName type="full">Netherlands Organization for Scientific Research (NWO)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,271.29,134.18,69.42,10.76"><forename type="first">Gilad</forename><surname>Mishne</surname></persName>
							<email>gilad@science.uva.nl</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,125.63,84.91,360.74,12.91;1,166.07,103.20,279.86,9.82">Multiple Ranking Strategies for Opinion Retrieval in Blogs The University of Amsterdam at the 2006 TREC Blog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F71333779177224DCDC509DCCA5F0F8A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe our participation in the Opinion Retrieval task at TREC 2006. Our approach to identifying opinions in blog post consisted of scoring the posts separately on various aspects associated with an expression of opinion about a topic, including shallow sentiment analysis, spam detection, and link-based authority estimation. The separate approaches were combined into a single ranking, yielding significant improvement over a content-only baseline.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The task in the Blog Track introduced in TREC this year was opinion retrieval: identifying and ranking blog posts expressing an opinion regarding a given topic. Our approach to this task was to identify different components which indicate such an opinionated expression, rank the blog posts according to each of these separately, and combine these partial relevance scores to a final one. This allows us to break down the opinion retrieval task to a number of simpler subproblems, which we treat as independent.</p><p>We proceed by describing the components of opinionated relevance we identified, how a score was calculated for each, and how the final score was derived.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Opinion Retrieval Components</head><p>We identify three different aspects indicating that a blog post expresses an opinion about a topic: topical relevance, opinion expression, and post quality. The first aspect, topical relevance, is the degree to which the post deals with the given topic; this is similar to relevance as defined for ad-hoc retrieval tasks such as many of the traditional TREC tasks. The second aspect, opinion expression, refers to identifying, given a "topically-relevant" blog post, whether it contains an opinion about topic: to what degree it contains subjective information about it. Finally, post quality is an estimation of the (query-independent) quality of a blog post, under the assumption that higher-quality posts are more likely to contain meaningful opinions and are preferred by users.</p><p>Note that a relevant blog post, as defined in the opinion retrieval track, does not necessarily have high topical relevance, or high post quality: a document is relevant if it contains an opinion about the target, even if the target is not the main topic of the document and the opinion is expressed only in passing. However, cursory examination of posts containing opinions about various targets shows that in the majority of the cases, the target is also the main topic; an in-depth analysis to examine the degree to which this assumption holds is planned for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topical relevance</head><p>To estimate the ad-hoc relevance score of a blog post given a topic, we used a straightforward retrieval approach, enhanced by a few heuristics. As the basic relevance score, we use a language modeling based retrieval method shown to achieve same-or-better scores when compared to topperforming retrieval algorithms <ref type="bibr" coords="1,452.57,328.04,10.58,8.97" target="#b4">(5)</ref>. The TREC Blogs06 corpus contains separate collections of the post feeds, permalink HTML pages, and blog home pages <ref type="bibr" coords="1,510.03,349.96,10.58,8.97" target="#b8">(9)</ref>. For our experiments, we used the text appearing in the feed part of the collection, except where the feed was a partial content one -in which case, the text was extracted from the appropriate HTML page (similar to (4)). The blog home pages were not used. Standard tokenization and English Snowball stemming were applied; anchor text was extracted and added to the text of the linked post.</p><p>We experimented with a number of simple techniques for improving the retrieval achieved with plain language modeling ranking. The first is blind relevance feedback in the language modeling framework as proposed by <ref type="bibr" coords="1,508.24,471.10,15.27,8.97" target="#b14">(15)</ref>. Essentially, this method adds terms to the original query by comparing the language model of the top-retrieved documents with the model of the entire collection, adding terms which are indicative of these top-retrieved documents. As with other query expansion methods, this type of relevance feedback is known to increase recall at the expense of precision; since topical relevance is only one component in our system, we decided in favor of using it, hypothesising that other retrieval components will balance the precision drop. However, to prevent exsessive topic drift, we limited the number of added terms to 3; examples of terms added to real topics are shown in Table <ref type="table" coords="1,397.03,602.61,3.74,8.97" target="#tab_0">1</ref>. The next heuristic we applied to improve topical relevance was usage of term proximity. Recent work has shown that, contrary to previous results, taking proximity into account improves retrieval substantially <ref type="bibr" coords="2,184.85,72.69,15.27,8.97" target="#b9">(10)</ref>, in particular in webtype documents such as the ones in our collection <ref type="bibr" coords="2,260.03,83.65,15.27,8.97" target="#b10">(11)</ref>. In particular, we used the method described in <ref type="bibr" coords="2,233.12,94.61,16.60,8.97" target="#b10">(11)</ref> where every word n-gram (n &gt; 1) of the topic is used as a query term, boosting the score of documents which match phrases appearing in the topic.</p><p>The final technique we employed in the framework of topical relevance was usage of the temporal properties of the collection. According to a study of a blog search engine log <ref type="bibr" coords="2,93.89,171.96,15.27,8.97" target="#b11">(12)</ref>, a substantial amount of blog queries are recency queries -queries which favor recent documents, rather than having an even distribution of relevance. Since the blogspace is a highly dynamic domain, many queries are related to current events -possibly, to evaluate how bloggers react to these events. Consequently, it seems useful to assign a higher relevance to blog posts which were "recent" at the time the query was issued, as described in ( <ref type="formula" coords="2,281.92,248.68,3.53,8.97">8</ref>). However, as TREC topics are not distributed with an accompanying query issue time, we use the following method to estimate it. First, we use a plain topical relevance model to retrieve the top 100 blog posts which are relevant for a query. Since every post in the corpus has an associated timestamp, we can now observe the distribution of dates in these top-100 posts. We adopt a simple approach and assume that the query was issued in the top-occurring date. <ref type="foot" coords="2,227.21,334.77,3.49,6.28" target="#foot_0">1</ref> Table <ref type="table" coords="2,260.03,336.35,4.98,8.97" target="#tab_2">2</ref> shows some "query issue dates" derived using this approach, with an accompanying post-analysis.</p><p>Once we have the estimated query issue date, we use a linear combination of a document's retrieval rank with its recency rank to boost the scores of posts published close to the time of the query date. This method has been described in <ref type="bibr" coords="2,64.20,413.70,10.58,8.97" target="#b7">(8)</ref>, and shown to improve retrieval performance substantially for recency queries. Note that not all queries are indeed recency ones -for example, the last query in Table <ref type="table" coords="2,278.55,435.62,4.98,8.97" target="#tab_2">2</ref> is not necessarily time-related; identifying these queries is relatively simple, as the distribution of dates in the top results does not contain peaks. For the experiments reported here, we treated all queries as recency ones, and intend to address the identification of the non-recency ones in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Opinion expression</head><p>Sentiment analysis is an area of research dealing with the extraction and characterization of emotions, opinions, and other non-factive aspects of text; work in this domain in recent years is plentiful (e.g., <ref type="bibr" coords="2,161.97,562.17,14.94,8.97" target="#b16">(17)</ref>). Within this area, a key task is sentiment classification -identifying positive and negative opinions towards a given topic; this task has also been previously investigated at the Novelty track at TREC <ref type="bibr" coords="2,254.56,595.05,15.27,8.97" target="#b17">(18)</ref>.</p><p>Broadly speaking, there are two approaches to sentiment classification: lexicon-based methods and machine learning approaches. Lexical method first construct a dictionary of terms indicating sentiment (often, lists of "positive" and "negative" words); sometimes, words are associated with weights. The sentiment of a given text is then derived by the occurrence of words from this dictionary in the text, e.g., by summing their weights. There are various ways of building the sentiment dictionary, including pattern-based (16), using WordNet (6), co-occurrence statistics <ref type="bibr" coords="2,497.86,94.61,16.60,8.97" target="#b19">(20)</ref> and more. Machine learning methods train a classifier using a set of annotated texts containing sentiment, typically employing features such as n-grams of words, part-of-speech tags, and logical forms <ref type="bibr" coords="2,374.84,138.45,10.79,8.97" target="#b2">(3,</ref><ref type="bibr" coords="2,388.12,138.45,11.83,8.97" target="#b13">14)</ref>.</p><p>We view the ranking of blog posts for opinion expression as a sentiment classification task, and approach it with a lexicon-based method. The lexicon we use is the General Inquirer <ref type="bibr" coords="2,346.35,182.89,15.27,8.97" target="#b18">(19)</ref>, a large-scale, manually-constructed lexicon assigning a wide range of categories to more than 10,000 English words. Among the categories assigned are Osgood's semantic dimensions and emotional categories. The following word categories are used as indicators of the existence of an opinion in the text: the two valence categories, Positive and Negative; the emotional categories, Pleasure, Pain, Feel, Arousal, EMOT, Virtue, and Vice; the pronoun categories, Self, Our, and You; the adjective categories, IPadj (relational adjectives) and IndAdj (independent adjectives); and the Respect category. <ref type="foot" coords="2,421.07,290.91,3.49,6.28" target="#foot_1">2</ref>For each post, we calculate two sentiment-related values using the words appearing in each of these categories: a "post opinion level" and a "feed opinion level." In both cases, the opinion level is the number of occurrences of words from any of these categories, normalized by the total number of words: the difference is the text used for counting the occurrences. For the post opinion level, we extract all "topical sentences" from the post, using them as the text to count the opinion-bearing words in. Topical sentences, in our approach, are all sentences containing the topic verbatim, as well as the sentences immediately surrounding them. This is done to focus the search for opinion-bearing words to parts of the post which are likely to refer directly to the topic, rather than the post in its entirety. For the second value, the feed opinion level, we use the entire feed to which the post belongs; this is a static, topic-independent score per feed, estimating the degree to which it contains opinions (about any topic). The intuition here is that feeds containing a fair amount of opinions are more likely to express an opinion in any of their given posts; since the amount of text in a feed is typically substantially larger than that of a single post, and since lexical methods such as the one we use work better on longer texts, this may yield a more robust measurement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Post quality</head><p>Finally, the third set of rankings we use for determining relevance for the opinion retrieval task concerns the "quality" of the blog post. In particular, we are interested in filtering spam posts, and in incorporating the degree of authority assigned to a post (and its feed) into the final retrieval score. While posts containing opinions do not necessarily have high authority, we hypothesized that, given two posts  with similar opinions, a searcher will prefer the one with higher authority. For this, we calculate separate spam and authority scores, both of which are query-independent.</p><p>Link-based Authority. Estimating the authority of documents in a hyperlinked environment using an analysis of the link structure is known to be an effective approach (e.g., PageRank, HITS). We follow Upstill et al. <ref type="bibr" coords="3,223.64,201.66,15.27,8.97" target="#b20">(21)</ref>, which show that the inbound link degree is a good approximation of more complex approaches such as PageRank. To this end, we use both the log of the inbound link degree of a post p (discarding links from other posts which belong to the same feed as p) and the inbound link degree of p's feed (again, discarding intra-feed links) as a crude estimation of the post's authority.</p><p>Spam Likelihood. Spam blogs are an increasing nuisance in the blogspace <ref type="bibr" coords="3,126.87,299.35,10.58,8.97" target="#b6">(7)</ref>, and the TREC collection is no exception. Some spamming techniques result in high topical retrieval scores for certain queries on spam blog posts; to address this, we employed a relatively simple spam filtering mechanism, in which a "spam likelihood" score was assigned to each feed using two independent methods. First, we used a machine-learning approach which has been shown to be effective for spam detection in this domain <ref type="bibr" coords="3,77.05,387.69,10.58,8.97" target="#b6">(7)</ref>. We created a training set of spam and non-spam feeds using two naive assumptions: The first assumption is that a feed from the domain blogspot.com, and with a domain name exceeding 35 characters, is a spam blog. Sample domains which are judged as spam using this rule are casino-hotel-in-windsor-poker.blogspot.com or weightloss7666resources.blogspot.com. The second naive assumption is that a feed from the domains livejournal.com or typepad.com is not spam. While both assumptions are crude, we found that they achieve very high precision (at the expense of low recall). 3  Our training collection was created by randomly sampling 500 feeds which meet the "spam assumption", and 500 feeds which meet the "non-spam" one; this provided us with a relatively high-quality, if biased, collection. We then trained an SVM on this set, and used its prediction scores on the entire collection as one evidence for the likelihood of a given feed to be spam.</p><p>Our second spam detection method follows one of the techniques used by Ntoulas et. al <ref type="bibr" coords="3,197.34,596.58,15.27,8.97" target="#b12">(13)</ref>, namely, text-level compressibility. Many spam blogs use keyword stuffing -a high concentration of certain words, aimed at obtaining high relevance scores from search engines for these keywords. 3 Our assumptions are based on the popularity of Blogspot among spammers due to easy automation of posting at the time of collecting the Blogs06 corpus, and a relatively low level of spam in TypePad (a platform requiring payment) and LiveJournal.</p><p>Keywords and phrases are often repeated dozens and hundreds of times in the same blog "post", and across posts in the spammy feed; this results in very high compression ratios for these feeds, much higher than those obtained with non-spam feeds. Using the same collection as used for training the SVM, we calculated the distribution of compression ratios of both spam and non-spam feeds (which differed substantially); all feeds in the corpus were then assigned a likelihood of being drawn from each of these distributions.</p><p>The final spam likelihood estimate is a product of the SVM prediction and the compressibility prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Combination</head><p>Combining retrieval scores assigned by different methods to the same set of documents is a common task in IR, particularly in web domains (see, e.g., <ref type="bibr" coords="3,454.17,296.38,10.46,8.97" target="#b1">(2)</ref>). We adopt one of the standard methods used in this scenario -computing the final retrieval score as a linear combination of the various partial scores. More concretely, the score is calculated as follows. First, we retrieve the top-1000 posts using topical relevance, language-modeling retrieval only. These 1000 posts are then scored also using the other methods we described (such as link indegree, post opinion level, and so on). Each of these methods, as well as the plain language-modeling similarity, has a (static) associated weight; the final score is a linear combination of the scores assigned by the methods, multiplied by their respective weights.</p><p>Model Weighting. Clearly, the performance of such a linear combination approach depends to a large extent on the weight assigned to each component. Optimizing the weights requires training data; but, as this is the first run of the opinion retrieval task at TREC, such data was not available. We therefore decided to create partial relevance scores by assessing a limited number of the top-ranking documents retrieved using a small set of 10 training topics we developed. <ref type="foot" coords="3,341.36,521.94,3.49,6.28" target="#foot_2">4</ref> We retrieved the top-50 posts for each of these topics, using plain language-modeling ranking, and judged their relevance according to the assessor guidelines used at TREC. Weights of the linear combination were then optimized, where the value to maximize was the bpref score of the combined ranking; bpref was used as it was shown to be more stable to partial judgment scores (1) -which is most probably the case we are facing, given our limited assessment effort. The final weights used are shown in Table <ref type="table" coords="3,539.32,611.19,3.74,8.97" target="#tab_3">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Submissions and Results</head><p>We submitted 5 runs, as follows: The assumption that posts with higher link-authority will be preferred by users turned out to be incorrect: examining the qrels, the average link indegree of relevant posts (2.4) was lower than that of non-relevant ones (4.2); indeed usage of link-based authority scores decreased the accuracy of the baseline. All other methods we used improved the baseline to varying extents, and the combination of all methods (optimized for our small training set) yielded an improvement of 24% to MAP and 18% to R-Precision. Of all components, the one contributing most to the improvement was the shallow sentiment-based opinion expression module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>We presented our approach to opinion retrieval in blogs, consisting of combining topical retrieval with a number of aspects we view as contributing to relevancy for this task, including shallow sentiment analysis, spam detection, and link-based authority. While some approaches, most notably the sentiment analysis, contributed to significant improvements over topical retrieval alone, other approaches such as link-based ones degraded performance. Overall, the combination of all approaches substantially improved topicalrelevance retrieval only. In future work, we intend to examine more closely the contribution of each component to accuracy, as well as explore different combinations of the components.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="1,321.24,623.54,235.02,59.31"><head>Table 1 :</head><label>1</label><figDesc>Examples of terms added with relevance feedback</figDesc><table coords="1,325.67,623.54,226.16,38.36"><row><cell>Topic</cell><cell>Added terms</cell></row><row><cell cols="2">859. letting india into the club? nuclear, times, friedman</cell></row><row><cell>867. cheney hunting</cell><cell>vice, dick, accident</cell></row><row><cell>896. global warming</cell><cell>climate, change, greenhouse</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,203.31,92.02,205.38,8.97"><head>Table 2 :</head><label>2</label><figDesc>Examples of estimated "query issue dates"</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,54.00,40.68,238.50,333.09"><head>Table 3 :</head><label>3</label><figDesc>Component weights Same as UAmsB06Base, with opinion reranking -both at the feed level and the post level.• UAmsB06All: All components used: link indegrees, spam detection, opinion expression (feed and post), time models, and phrase-level reranking. The retrieval scores for these runs are shown in Table4.</figDesc><table coords="4,54.00,40.68,238.50,333.09"><row><cell>Component</cell><cell></cell><cell></cell><cell>Weight</cell></row><row><cell cols="4">Content-based retrieval (with query expansion) 1.00</cell></row><row><cell>Recency score</cell><cell></cell><cell></cell><cell>0.03</cell></row><row><cell>Post opinion level</cell><cell></cell><cell></cell><cell>0.10</cell></row><row><cell>Feed opinion level</cell><cell></cell><cell></cell><cell>0.45</cell></row><row><cell>Link-based authority</cell><cell></cell><cell></cell><cell>0.01</cell></row><row><cell>Spam likelihood</cell><cell></cell><cell></cell><cell>0.90</cell></row><row><cell>Phrase matching score</cell><cell></cell><cell></cell><cell>0.05</cell></row><row><cell cols="4">• UAmsB06Base: A baseline run, consisting of language</cell></row><row><cell cols="4">modeling based retrieval using the terms appearing in the</cell></row><row><cell cols="4">title field of the query, with blind relevance feedback as</cell></row><row><cell>described in Section .</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">• UAmsB06L: Same as UAmsB06Base, with link-</cell></row><row><cell>indegree reranking.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">• UAmsB06S: Same as UAmsB06Base, with spam-</cell></row><row><cell>detection.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>• UAmsB06O: Run</cell><cell>MAP</cell><cell>R-Prec</cell><cell>bpref</cell></row><row><cell cols="4">UAmsB06Base 0.1449 0.2357 0.2393</cell></row><row><cell>UAmsB06L</cell><cell cols="3">0.1417 0.2269 0.2375</cell></row><row><cell>UAmsB06S</cell><cell cols="3">0.1523 0.2448 0.2485</cell></row><row><cell>UAmsB06O</cell><cell cols="3">0.1596 0.2573 0.2509</cell></row><row><cell>UAmsB06All</cell><cell cols="3">0.1795 0.2771 0.2625</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,106.25,385.76,134.00,8.97"><head>Table 4 :</head><label>4</label><figDesc>Scores of submitted runs</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,70.14,661.78,222.36,8.07;2,54.00,671.74,238.50,8.07;2,54.00,681.70,207.21,8.07"><p>In practice, we employ some additional heuristics here, such as working with windows of a few days rather than a single daymostly to account for differences in time zones and so on.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,335.64,671.74,222.36,8.07;2,319.50,681.70,187.66,8.07"><p>A complete list of the General Inquirer categories is given at http://www.wjh.harvard.edu/∼inquirer/homecat.htm</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="3,335.64,661.78,222.36,8.07;3,319.50,671.74,238.50,8.07;3,319.50,681.70,144.90,8.07"><p>The topics were "Windows Vista," "Hurricane Katrina," "Oscar," "Pepsi," "oil prices," "iPod Nano," "EU Constitution," "Katie Holmes," "Lebanon," and " Paris Riots."</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. Thanks to <rs type="person">Breyten Ernsting</rs> for help in processing the collection. This work was supported by the <rs type="funder">Netherlands Organization for Scientific Research (NWO)</rs> under project number <rs type="grantNumber">220-80-001</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Qx4wUZT">
					<idno type="grant-number">220-80-001</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,341.08,104.35,216.92,8.07;4,341.08,114.31,160.86,8.07" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,466.59,104.35,91.41,8.07;4,341.08,114.31,82.95,8.07">Retrieval evaluation with incomplete information</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,440.69,114.31,35.29,8.07">SIGIR &apos;04</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,126.14,216.92,8.07;4,341.08,136.11,216.92,8.07;4,341.08,146.07,36.61,8.07" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,542.56,126.14,15.44,8.07;4,341.08,136.11,177.13,8.07">Relevance weighting for query independent evidence</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,535.59,136.11,22.41,8.07;4,341.08,146.07,10.65,8.07">SIGIR &apos;05</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,157.90,216.92,8.07;4,341.08,167.87,216.92,8.07;4,341.08,177.83,159.41,8.07" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="4,516.76,157.90,41.24,8.07;4,341.08,167.87,216.92,8.07;4,341.08,177.83,81.50,8.07">Mining the peanut gallery: opinion extraction and semantic classification of product reviews</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Pennock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>In WWW &apos;03</note>
</biblStruct>

<biblStruct coords="4,341.08,189.66,216.92,8.07;4,341.08,199.63,216.92,8.07;4,341.08,209.59,92.73,8.07" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,391.16,189.66,145.68,8.07">Indexing Weblogs One Post at a Time</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Glance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,341.08,199.63,216.92,8.07;4,341.08,209.59,66.29,8.07">AAAI Spring Symposium on Computational Approaches to Analysing Weblogs</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,221.42,216.92,8.07;4,341.08,231.39,147.28,8.07" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="4,393.65,221.42,164.35,8.07;4,341.08,231.39,22.33,8.07">Using Language Models for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001-01">Jan. 2001</date>
			<pubPlace>Enschede</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="4,341.08,243.22,216.92,8.07;4,341.08,253.18,183.92,8.07" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,441.59,243.22,116.42,8.07;4,341.08,253.18,101.32,8.07">Automatic detection of opinion bearing words and sentences</title>
		<author>
			<persName coords=""><forename type="first">S.-M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,459.00,253.18,39.23,8.07">IJCNLP-05</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,265.02,216.92,8.07;4,341.08,274.98,216.92,8.07;4,341.08,284.94,216.92,8.07;4,341.08,294.90,44.00,8.07" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,459.21,265.02,98.80,8.07;4,341.08,274.98,147.23,8.07">SVMs for the Blogosphere: Blog Identification and Splog Detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kolari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Finin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,510.99,274.98,47.01,8.07;4,341.08,284.94,216.92,8.07;4,341.08,294.90,17.98,8.07">AAAI Spring Symposium on Computational Approaches to Analysing Weblogs</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,306.74,216.92,8.07;4,341.08,316.70,61.27,8.07" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,434.13,306.74,105.36,8.07">Time-based language models</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,341.08,316.70,35.30,8.07">CIKM &apos;03</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,328.54,216.92,8.07;4,341.08,338.50,216.92,8.07;4,341.08,348.46,73.47,8.07" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="4,440.65,328.54,117.36,8.07;4,341.08,338.50,147.40,8.07">The trec blogs06 collection: Creating and analysing a blog test collection</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<idno>TR-2006-224</idno>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="4,341.08,360.30,216.92,8.07;4,341.08,370.26,156.11,8.07" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="4,447.90,360.30,110.10,8.07;4,341.08,370.26,78.03,8.07">A markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,435.93,370.26,35.29,8.07">SIGIR &apos;05</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,382.09,216.92,8.07;4,341.08,392.05,143.93,8.07" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="4,442.94,382.09,115.06,8.07;4,341.08,392.05,62.45,8.07">Boosting Web Retrieval through Query Operations</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mishne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,420.25,392.05,38.30,8.07">ECIR 2005</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,403.89,216.92,8.07;4,341.08,413.85,42.59,8.07" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="4,443.02,403.89,79.10,8.07">A study of blog search</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mishne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,538.08,403.89,19.92,8.07;4,341.08,413.85,16.14,8.07">ECIR 2006</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,425.69,216.92,8.07;4,341.08,435.65,216.92,8.07;4,341.08,445.61,42.59,8.07" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="4,544.56,425.69,13.44,8.07;4,341.08,435.65,176.46,8.07">Detecting spam web pages through content analysis</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ntoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Najork</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Manasse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fetterly</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,457.45,216.92,8.07;4,341.08,467.41,216.92,8.07;4,341.08,477.37,74.22,8.07" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="4,490.95,457.45,67.05,8.07;4,341.08,467.41,200.39,8.07">Thumbs up? Sentiment classification using machine learning techniques</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,341.08,477.37,47.77,8.07">EMNLP 2002</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,489.21,216.92,8.07;4,341.08,499.17,216.92,8.07;4,341.08,509.13,194.04,8.07" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="4,391.90,489.21,148.79,8.07">Language models for relevance feedback</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,341.08,499.17,216.92,8.07;4,341.08,509.13,168.12,8.07">Advances in Information Retrieval: Recent Research from the Center for Intelligent Information Retrieval</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,520.96,216.92,8.07;4,341.08,530.93,216.92,8.07;4,341.08,540.89,42.59,8.07" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="4,485.55,520.96,72.45,8.07;4,341.08,530.93,164.45,8.07">Learning subjective nouns using extraction pattern bootstrapping</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,528.60,530.93,29.40,8.07;4,341.08,540.89,16.14,8.07">CoNLL-2003</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,552.72,216.92,8.07;4,341.08,562.69,216.92,8.07;4,341.08,572.65,120.52,8.07" xml:id="b16">
	<analytic>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Shanahan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,486.55,552.72,71.45,8.07;4,341.08,562.69,154.13,8.07">Computing Attitude and Affect in Text: Theory and Applications</title>
		<title level="s" coord="4,501.07,562.69,56.93,8.07;4,341.08,572.65,55.33,8.07">The Information Retrieval Series</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,584.48,216.92,8.07;4,341.08,594.45,95.37,8.07" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="4,444.56,584.48,113.44,8.07;4,341.08,594.45,32.49,8.07">Overview of the trec 2003 novelty track</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,389.87,594.45,19.33,8.07">TREC</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,606.28,216.92,8.07;4,341.08,616.24,216.92,8.07;4,341.08,626.21,87.91,8.07" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="4,513.25,606.28,44.75,8.07;4,341.08,616.24,191.57,8.07">The General Inquirer: A Computer Approach to Content Analysis</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Dunphy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ogilvie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966">1966</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,638.04,216.92,8.07;4,341.08,648.00,216.92,8.07;4,341.08,657.97,125.24,8.07" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="4,462.63,638.04,95.37,8.07;4,341.08,648.00,213.42,8.07">Measuring praise and criticism: Inference of semantic orientation from association</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">D</forename><surname>Turney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,341.08,657.97,75.77,8.07">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,341.08,669.80,216.92,8.07;4,341.08,679.76,204.74,8.07" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="4,500.12,669.80,57.89,8.07;4,341.08,679.76,126.25,8.07">Predicting fame and fortune: Pagerank or indegree?</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Upstill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,480.81,679.76,37.86,8.07">ADCS2003</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
