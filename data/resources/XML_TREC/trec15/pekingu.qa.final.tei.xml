<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,161.30,85.86,272.71,19.93">Tianwang at TREC-2006 QA Track</title>
				<funder ref="#_Cf7t9Tv">
					<orgName type="full">PRC Ministry of Education</orgName>
				</funder>
				<funder ref="#_KWxdpN6">
					<orgName type="full">NSFC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,260.40,113.44,29.55,11.62"><forename type="first">Jing</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Engineering and Computer Science</orgName>
								<orgName type="laboratory">Network and Distribution System Laboratory</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,296.90,113.44,38.05,11.62"><forename type="first">Yuan</forename><surname>Liu</surname></persName>
							<email>liuyuan@net.pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Engineering and Computer Science</orgName>
								<orgName type="laboratory">Network and Distribution System Laboratory</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,161.30,85.86,272.71,19.93">Tianwang at TREC-2006 QA Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CC80D7CBC1C7204D351D5BC6782CD8C7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the architecture and implementation of Tianwang QA system2006, which works for the TREC QA Main task this year. The main improvement is: 1. add one well founded knowledge source from Web -Wikipedia, and employ some natural language processing technologies to extract high quality answers; 2. design and implement a new translation algorithm in query generation. The results show that fine organized knowledge source is effective in answering all three types of questions. And such query generation algorithm can be benefit from both Frequent Asked Questions on Web and past TREC QA data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>As the second time participating in TREC QA task, we reuse the system developed last year <ref type="bibr" coords="1,489.11,363.04,12.08,11.62" target="#b0">[1]</ref>. As many other researchers pointed out, knowledge source performs well in Question Answering task, we experiment the effectiveness of this approach. However, different from Web knowledge, which is large in quantity and high in duplication, knowledge from a source maybe high in quality but limited in quantity. So we have design a different strategy to extract answers. Another improvement is in query generation. Last year, we designed a iterative approach to generate Boolean queries. However, both the number of iteration and the loosing/contraction strategy is not established. We build a translation model to generate query this year, collaborating with the approach last year. This paper is organized as below: In section 2, the overview of Tianwang QA system2006 is described. In section 3, the detail processing technology is described. The query generation and use of Wikipedia are described in section 4 and section 5, separately. In section 6, we give the conclusion and future work in this field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">System Overview</head><p>The system is similar to that of last year. However, because we are lack of high quality Knowledge Base source and Frequent Asked Question data source, we replace them with another type of knowledge source -Wikipedia. So, there are five modules in our system: data processing, question analysis, answer extractor and answer integration/validation, as Figure <ref type="figure" coords="1,420.00,643.84,5.25,11.62">1</ref> shows. We can see clearly from the figure that the system includes two parts: offline part and online part. The offline part preprocesses the collection dataset and index them, generating inverted files for searching online. Unlike the system last year, we do not put a lot of work such as crawling KB and FAQ data and indexing them in offline part. The reason for this is two-folded: first of all, the knowledge base of Wikipedia contains large quantity of pages, most of which are not useful in this Figure1: Tianwang QA System 2006 infrastructure TREC task, and crawling them is time-consuming; another reason is the data source (web site) has supplied good interface for accessing the information online. Most of modules are similar to those of last year, except query generation and knowledge source modules. The detail of processing is described below, in section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Question Answering Processing</head><p>In question answering processing, question classification is the first step. The architecture of categories follows a two-layered question taxonomy, containing 6 coarse grained and 50 fine grained categories. Each coarse grained category contains a non-overlapping set of fine grained categories. As we did last year, we use the SVM method with one against all strategy and bag of words feature to perform the classification <ref type="bibr" coords="2,265.12,519.04,15.61,11.62" target="#b9">[10]</ref>. Each question is labeled with only one category with maximum probability. The training database is provided by UIUC, which contains 5,500 labeled questions <ref type="bibr" coords="2,127.06,550.24,12.35,11.62" target="#b8">[9]</ref>. Because the training data does not fit to QA-test-set this year, precision is not so good as last year and then constraint the performance of later modules.</p><p>Then the candidate relative passages are retrieved from both collection and Web resources. Web sources are important to QA task, so we choose search engine and Wikipedia as our source candidates. Three search engine are selected, including Google, Yahoo! and MSN. For each question, we select key words from it and forward them to the search engine, and then store the result for future use. Wikipedia is a more important source, the content of it is thought to be more confident than other web pages. We use the "target" as the basic element to retrieve page, and then make fine analyses to it, described in section 5.</p><p>At last, we should extract answer to each question. High weight is assigned to the result extracted from Wikipedia. If the result from Wikipedia is existed , the result will be returned immediately. If not, then we try to extract answer from TREC document passages and search engine snippets. We label entities in these contents. The entity type include GATE entities and some predefined entity type. We assign each entity a score and rank the entities according to the scores.</p><p>The score computation is similar to <ref type="bibr" coords="3,248.80,82.24,10.97,11.62" target="#b8">[9]</ref>. It mainly based on its frequency of occurrences in the documents and snippets. Then we check whether the type of the highly ranked entity's type matches the question's category. In most cases, the matching is boolean. But there are some exceptions. Some types of question such as TIME/YEAR/DATE can match with a ranked list of answer types.</p><p>However, the answer extracted from other information sources, may not be located in the AQUAINT data source, leading to unsupported result, so we should filter them to avoid such errors. If a entity is filtered, the next candidate entity is validated. The processing continues until a candidate answer is validated to be appear in suitable passage or no more candidate answer in the set. In the second situation, a NIL will be given. For list questions, the first 5 entities are taken as answers default; for factoid questions, the first entity is as the answer and for definition questions, we implement a simple summary algorithm to summarize the main ideas of top 5 passages retrieved by passage retrieval sub-module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Translation Model for Query Generation</head><p>Translation model is a famous module in the field of machine translation <ref type="bibr" coords="3,421.79,300.64,11.67,11.62" target="#b1">[2]</ref>[3], employed to represent the relation of query and text content in Information Retrieval <ref type="bibr" coords="3,426.95,316.24,12.45,11.62" target="#b3">[4]</ref> and Question Answering <ref type="bibr" coords="3,132.90,331.84,14.30,11.62" target="#b4">[5]</ref> these years. Because we can get the question and answer data in past TREC QA tasks. What is more, we also can make use of FAQ data we crawled last year. All these data are training data for building a translation model.</p><p>First of all, we extract most frequently words in questions, removing some stop words and question type words such as what, which, when, etc. Then we need to calculate the transferring probability from one of these terms to another, which is useful to generate the queries. The probability is described as: J . Obviously, it is a process of iteration. The possibility of transforming can be thought to be a possibility of appearance of term t in relative passage when term s appears in question. Therefore, it's rational to take a term with high transforming possibility as query term.</p><formula xml:id="formula_0" coords="3,112.80,443.50,280.20,64.55">1 1 1 2 ( | ) ( | , ) ( | ) ( | , ) #( , ) #( , ) ( | ) ( | ) ( | ) N i i i i i n P t</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Wikipedia as Knowledge Source</head><p>The Knowledge base and FAQ perform not so well last year because the data is too sparse, so they can only answer questions in limited domain. Wikipedia, which is a popular knowledge source in Web <ref type="bibr" coords="3,114.07,721.84,13.57,11.62" target="#b5">[6]</ref> <ref type="bibr" coords="3,127.64,721.84,13.57,11.62" target="#b6">[7]</ref>, supplies much more knowledge than the knowledge source we employed last year. We can see it can cover more than half targets in QA task each year. Therefore, it is a good choice to use it.</p><p>Though we may be sure the answer exists in Wikipedia articles, it's difficult to extract them . Because the duplication is not as high as in web, the approach of simply counting named entities we employed last year will not effective. Instead, we use some NLP technologies to help finding right answers. For this, we count the frequency of question types in past TREC QA tasks, select the frequency asked question type, and construct answer patterns for them, according to <ref type="bibr" coords="4,441.60,144.64,10.97,11.62" target="#b7">[8]</ref>. So we may match the exact answer in Wikipedia by these patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Work</head><p>The main improvement of Tianwang QA system 2006 is to refine the process of query generation and extend the knowledge source. The results show the accuracy (MAE) is similar to last year, though the question is declared to become more difficult (time dependent questions). However, the rate unsupported answers increases this year. Some other particulars also found this problem. The main reason of such increase may be that though answers can be found in knowledge source effective, we are lack of a good approach to validate it in document itself.</p><p>There are much more work to do in future. First of all, the approaches should be measured carefully in quantity way in next step. What is more, we would like to focus on some new task such as CiQA next year. It is also very interesting for us to answer more than factoid questions, such as questions about subjective feeling and features of a data set.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" coords="2,90.00,84.80,414.85,255.50"><head></head><label></label><figDesc></figDesc><graphic coords="2,90.00,84.80,414.85,255.50" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7.">Acknowledgments</head><p>This work described therein is supported in part by <rs type="funder">PRC Ministry of Education</rs> grant <rs type="grantNumber">20030001076</rs> and by <rs type="funder">NSFC</rs> grant <rs type="grantNumber">60435020</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Cf7t9Tv">
					<idno type="grant-number">20030001076</idno>
				</org>
				<org type="funding" xml:id="_KWxdpN6">
					<idno type="grant-number">60435020</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,102.50,457.48,302.85,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,171.41,457.48,119.52,9.96">Tianwang at TREC-2006 QA Track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,310.10,457.48,91.28,9.96">Proceeding of TREC 2005</title>
		<meeting>eeding of TREC 2005</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,104.60,473.08,400.67,9.96;4,90.00,488.68,309.65,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,501.36,473.08,3.91,9.96;4,90.00,488.68,147.73,9.96">A statistical approach to machine translation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cocke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Jelinek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Roossin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,246.50,488.68,90.23,9.96">Computaional Linguistics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="79" to="85" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,102.80,504.28,402.19,9.96;4,90.00,519.88,246.85,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,325.59,504.28,179.40,9.96;4,90.00,519.88,73.48,9.96">The mathematics of statistical mechine translation: Parameter estimation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">Della</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,172.70,519.88,92.73,9.96">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="311" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,102.80,535.48,401.80,9.96;4,90.00,551.08,305.10,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,219.67,535.48,158.58,9.96">Information retrieval as statistical translation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,398.30,535.48,106.30,9.96;4,90.00,551.08,263.85,9.96">Proceeding of the 1999 ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>eeding of the 1999 ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="222" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,103.50,566.68,401.49,9.96;4,90.00,582.28,415.35,9.96;4,90.00,597.88,102.25,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,257.50,566.68,230.42,9.96">Finding similar questions in large question and answer archives</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jiwoon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">Joon</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,90.00,582.28,376.24,9.96">Proceedings of the 14th ACM international conference on Information and knowledge management</title>
		<meeting>the 14th ACM international conference on Information and knowledge management<address><addrLine>Bremen; Germany</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,102.90,613.48,401.59,9.96;4,90.00,629.08,43.75,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,244.09,613.48,189.78,9.96">External Knowledge Sources for Question Answering</title>
		<author>
			<persName coords=""><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">Y</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,454.70,613.48,49.79,9.96;4,90.00,629.08,21.69,9.96">Proceeding of TREC</title>
		<meeting>eeding of TREC</meeting>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,104.90,644.68,399.89,9.96;4,90.00,660.28,145.95,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,318.94,644.68,185.85,9.96;4,90.00,660.28,33.58,9.96">TREC 2003 QA at BBN: Answering Definitional Questions</title>
		<author>
			<persName coords=""><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ana</forename><surname>Licuanan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,140.70,660.28,73.29,9.96">Proceeding of TREC</title>
		<meeting>eeding of TREC</meeting>
		<imprint>
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,104.90,675.88,400.40,9.96;4,90.00,691.48,250.05,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,291.04,675.88,214.26,9.96;4,90.00,691.48,22.78,9.96">Learning surface text patterns for a Question Answering system</title>
		<author>
			<persName coords=""><forename type="first">Deepak</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,132.10,691.48,140.85,9.96">Proceedings of the 40th ACL conference</title>
		<meeting>the 40th ACL conference<address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,102.50,707.08,381.50,9.96;4,90.00,722.68,169.25,9.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="4,174.69,707.08,104.81,9.96">Learning Question Classifiers</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,297.90,707.08,186.10,9.96;4,90.00,722.68,142.99,9.96">Proceedings of the 19th International Conference on Computational Linguistics (COLING&apos;02)</title>
		<meeting>the 19th International Conference on Computational Linguistics (COLING&apos;02)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,107.10,738.28,398.19,9.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="4,219.19,738.28,191.60,9.96">Question Classification using support vector machines</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,431.20,738.28,74.09,9.96">Proceeding of SIGIR</title>
		<meeting>eeding of SIGIR</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
