<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,109.20,131.66,378.05,14.47">DUTIR at TREC 2006: Genomics and Enterprise Tracks</title>
				<funder ref="#_SuC47Au">
					<orgName type="full">Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,117.36,155.49,57.49,10.58"><forename type="first">Zhihao</forename><surname>Yang</surname></persName>
							<email>yangzh@dlut.edu.cn</email>
						</author>
						<author>
							<persName coords="1,182.87,155.49,55.71,10.58"><forename type="first">Hongfei</forename><surname>Lin</surname></persName>
							<email>hflin@dlut.edu.cn</email>
						</author>
						<author>
							<persName coords="1,245.49,155.49,53.15,10.58"><forename type="first">Yanpeng</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName coords="1,305.72,155.49,54.18,10.58"><forename type="first">Linhong</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName coords="1,367.86,155.49,33.48,10.58"><forename type="first">Yu</forename><surname>Pan</surname></persName>
							<email>panyu_yu@yahoo.com.cn</email>
						</author>
						<author>
							<persName coords="1,424.26,155.49,54.59,10.58"><forename type="first">Baoyan</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Dalian University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">LingGong Road Shahekou District</orgName>
								<address>
									<postCode>116023</postCode>
									<settlement>Dalian</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,109.20,131.66,378.05,14.47">DUTIR at TREC 2006: Genomics and Enterprise Tracks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">03FAAF11C90FC23A02CE16E655D1B3C4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the techniques we applied for the two TREC 2006 tracks, i.e., Genomics and Enterprise track. For the Genomics Track, we used a Rocchio relevance feedback method to expand the terms and then performed passage retrieval by building dual index and using half overlapped windows passages. Several approaches to merge the results and rerank the passages are presented. For the Enterprise track, we stripped the non-letter character from documents and query, built the index by indri or lemur and established expert document pools.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This is the second time that DUTIR (Information Retrieval laboratory of DaLian University of Technology) participated in TREC tracks. This time we took part in Genomics and Enterprise tracks. This year's Genomics Track has a new single task that focuses on retrieval of passages (from part to sentence to paragraph in length) with linkage to the source document. For most information seekers, especially users of the biomedical literature, desire is a system that attempts to answer questions but put them in context while providing supporting information and linking to original sources. There are three levels of MAP used to measure the retrieval performance: passage level, aspect level, and document level.</p><p>Passage level -Precision will be computed as the fraction of characters overlapping with the gold standard passages divided by the total number of characters included in all nominated passages from this system for the topic up until that point.</p><p>Aspect level -This measure is used to normalize passages on the same answer, for most users prefer passages with different aspects. For each submitted run, the ranked passages will be transformed to two types of values, either the aspect of the gold standard or not-relevant. Document level -Any PMID that has a passage associated with a topic ID in the set of gold standard passages will be considered a positive document for that topic.</p><p>Most of 2006's topics are derived from 2005's. For the topics that are the same we applied a Rocchio relevance feedback <ref type="bibr" coords="1,270.00,701.97,13.76,10.58" target="#b0">[1]</ref> method to expand query terms. Also in our run DUTgen3 a SVM classifier trained by 2005's gold standard was used to rerank the passages. According the 2006 track protocol all our three runs should be classified as interactive runs. We also experimented with 4 different kinds of passage ranking schemes.</p><p>As to Enterprise track we participated in both the Discussion task (DS) and Expert task (EX). The discussion search task is to search for messages pro and con in an argument or discussion regarding to a topic and the expert search is to look for a person or multiple people who were experts on a subject.</p><p>The following sections report our proposed methods and the results for Genomics and Enterprise tracks in turn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Genomics Track</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preprocessing</head><p>The documents for this task are full-text biomedical corpus in HTML format which come from Highwire Press (http://www.highwire.org/). Our first step was to remove all the HTML tags and some other sections we thought that should not appear in the final retrieved passages including titles, authors and organizations, keywords, all texts within the HTML tags "&lt;TABLE" and "&lt;/TABLE", acknowledgements and references etc.</p><p>Many gene names and other biomedical named entities contain Greek letters or other non-English tokens, while most of that letters in this corpus appear as pictures. For example, the Greek letter "α" in the HTML text is denoted as the following labels: &lt;IMG SRC="/math/alpha.gif" ALT="{alpha}"&gt;. We replaced all the pictures in the ""/math/" directory by the tokens in the "ATL" fields. Again some HTML tokens in the format like "&amp;#…;" are replaced by corresponding strings that should appear in the MEDLINE record (http://www.ncbi.nlm.nih.gov/entrez/query/static/entities.html). As is described in the papers of the previous year's participants <ref type="bibr" coords="2,306.66,489.33,13.42,10.58" target="#b1">[2]</ref>[3], when using single terms as query, removing dash and some other tokens in the data set will enhance the retrieval performance. So we replaced all the non-digit and non-alphabetic tokens in the data collection by a white-space. At the same time we used simple rules to recognize the boundary of a sentence and tagged the offset of a paragraph and its every sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query Expansion</head><p>The topics for the 2006 track are expressed as questions. First, we extracted noun phrases from each question as initial query terms by using GENIA Tagger <ref type="bibr" coords="2,446.65,611.01,12.46,10.58">[4]</ref>. Then we have tried some query expanding scheme on 2005 track data using some biomedical databases such as Entrez Gene [5] and UMLS Metathesaurus <ref type="bibr" coords="2,386.20,641.25,12.29,10.58" target="#b3">[6]</ref>, but we didn't find an effective automatic way to filter the "noizy" terms induced by synonyms expansion. But we found that using Rocchio relevance feedback based on 2005's gold standard lead to significant improvement of MAP of all topics. This year's topics are mostly identical to last year's, so for all topics from 160 to 187 except 177 and 180, a Rocchio feedback method was used to expand the terms. For every topic we selected top 20 most relevant terms by its score as expanded query in our submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Indexing and Retrieval</head><p>Passages in our experiment are defined as follow: Passage1 = (Part1, Part2) Passage2 = (Part2, Part3) Where Passage1 is a passage which consists of two parts: Part1 and Part2, and its following passage is denoted as Passage2 which is half overlapped with Passage1. A Part is composed of complete sentences:</p><formula xml:id="formula_0" coords="3,148.56,236.94,316.42,58.25">Part = (sentence1, sentence2, …, sentenceN) WordsCount (sentence1, sentence2, …, sentenceN-1) &lt; PartLength WordsCount (sentence1, sentence2, …, sentenceN) &gt;= PartLength</formula><p>Where WordsCount () is the number of words of all the sentences in one Part. For PartLength we set 30 in our submitted runs. After the results and evaluation tools were distributed we found this length was larger than the average length of passages in the gold standard.</p><p>Previous research <ref type="bibr" coords="3,195.85,367.89,13.52,10.58" target="#b4">[7]</ref> has shown that when documents are very long, methods based on passage-level retrieval can give much higher document-level MAP than document-level retrieval. Our retrieval method is also inspired by the work of York University in 2004 HARD Track <ref type="bibr" coords="3,249.36,413.49,12.29,10.58" target="#b5">[8]</ref>, which built two levels of index and combined the two results into one. In our experiment, we built two types of index with Indri <ref type="bibr" coords="3,491.79,428.61,12.71,10.58" target="#b6">[9]</ref>: paragraph-level and passage-level. Porter stemmer and Indri's stop word list were used. Each of the two types of index was ranked respectively with BM25 algorithms which parameters are adopted from Lemur's <ref type="bibr" coords="3,268.08,474.21,13.77,10.58" target="#b6">[9]</ref> default setting. Then we merged the results into one using four different methods:</p><p>Method1 -Paragraph-first scheme: paragraphs were ranked by their BM25 scores, and for every paragraph we chose the passage with the highest score。 Method2 -Passage-first scheme: rank passages according to passage scores. If two passages were overlapped, the one with higher score was selected as final result.</p><p>Method3 -Combining scheme: we combined the passage and paragraph score by giving weights to them as the following function:</p><formula xml:id="formula_1" coords="3,173.52,603.09,266.63,10.58">S = W paragraph * S paragraph + W passage * S passage</formula><p>Where W paragraph, W passage are the weights of passage and paragraph score which were set 3 and 1 separ in our submitted run DUTgen2. Then we ranked passages by the final score S, and chose passages with higher score for overlapped passages.</p><p>Method 4 -SVM reranking: in this experiment, we treated the task as a binary text classification problem. Documents of each topic were classified into two classes: relevant or irrelevant. Training data was last year's gold standard and classifier was SVMlight <ref type="bibr" coords="3,493.23,701.97,19.52,10.58" target="#b7">[10]</ref> with TFIDF term weighting scheme. First we selected top 2000 paragraphs by Method1, and then the paragraphs were reranked by the classifier. The method of passage extraction is the same as Method1. From Table1, we can see that Method1 and Method3 have better overall performances, which indicate that paragraph-first ranking (Method1) is more effective than passage-first ranking (Method2) in each of the three measures, while by combining the two results (Method3), we can get an improvement in Passage MAP but a decrease in both Aspect MAP and Document MAP. In our run DUTgen3 the weights for paragraph and passage are 3 and 1. From the results, it can be seen that the paragraph weight we have chosen is somewhat large, so there is not much difference between DUTgen1 and DUTgen2. Performance of Method4 is much lower than Method1 and Method3. That is what we have not expected. There is a large gap between its performances in the training data (2005 track data) and implement data. It indicates that for retrieval tasks it is difficult to get a higher precision applying a categorization method than the state-of-art searching algorithms such as BM25.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Enterprise track</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preprocessing</head><p>As in TREC 2005, TREC 2006 still used the W3C collection. The collection is a crawl of the public W3C (World Wide Web Consortium) sites in June 2004. It comprises 331,037 documents, retrieved via multithreaded breadth first crawling <ref type="bibr" coords="4,460.33,560.61,17.52,10.58" target="#b8">[11]</ref>. The collection contains six different types of web pages which were lists (emails), dev, www, esw, other, and people. The discussion search utilizes the emails, while the expert search utilizes the whole collection.</p><p>The documents provided by TREC are full-text articles in HTML format. To improve performance, we chose the cleaned W3C collection provided by Daqing He, who repackaged Wu's parsed w3c-lists collection, and also cleaned w3c-www, w3c-esw and w3c-people collections by removing HTML tags <ref type="bibr" coords="4,336.73,666.93,17.90,10.58">[12]</ref>. Based on this collection, we cleaned the collection further including removing the special character, such as "-", "/," etc. This could be superior to matching the "if-else" and the "if else". Moreover, considering the encoding of the text, we parsed documents in ISO-8859-1, which could promise some non-English, such as "é", to be identified correctly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Email Discussion Search</head><p>This task is to search some emails which contain a discussion about the topic, and emails could have pro or con point about given topic. The emails, about 198,275, are utilized in this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview</head><p>Firstly, we preprocessed the cleaned W3C collection, based on which an index was built by indri or lemur <ref type="bibr" coords="5,196.06,246.45,17.90,10.58">[13]</ref>. Then we processed the query topic the same way as cleaning the documents, i.e. Stripping the special character and stopping word. Ultimately, relevant documents were retrieved by indri or lemur. Figure <ref type="figure" coords="5,381.87,276.93,5.88,10.58" target="#fig_0">1</ref> depicts the framework of our retrieval system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion runs</head><p>For the discussion task, we did some experiments on TREC 2005 discussion topic, changing different ranking method and stem. Through experiments, we found the following facts: Firstly, stripping the stop-word from the field #title of the query directly was superior to composing the query by bigram method obviously. Secondly, it made results more precise to appending the field #narrative for query. Thirdly, removing non-letter character from query grew 1 percent. Fourthly, by stripping non-letter character from documents, it had a 3 percent increase in results. Finally, BM25 was superior to other ranking methods. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Result Generation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TREC topic</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query Generation Preprocess</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generate Indri index Retrieval</head><p>W3c Corpus (Email)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The detail information of our four submitted runs is displayed in Table <ref type="table" coords="6,461.77,140.13,5.88,10.58">2</ref> and the results of these runs are displayed in Table <ref type="table" coords="6,289.48,155.49,4.47,10.58" target="#tab_1">3</ref>.</p><p>Table <ref type="table" coords="6,238.56,170.85,4.96,10.58">2</ref>: Detail information of four runs In Table <ref type="table" coords="6,154.08,443.01,4.59,10.58" target="#tab_1">3</ref>, the first column is the run identifier, the second column is the mean average precision (MAP), other columns display other important factor. In terms of the MAP measure, DUTDS2 (whose query text was taken from title field, narrative field and description field.) is the lowest. DUTDS3 which ranked by Indri increased the MAP by about 7% over DUTDS1 (ranked by BM25), which is contrary to the results we obtained on the training topics (TREC 2005 discussion topics). We will explore the reasons in the next step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Expert Search</head><p>In this task participants should retrieve a list of candidate experts on a subject. This year the topics and relevance judgments are created by the participant and all 331,037 documents can be used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview</head><p>Based on the cleaned W3C collections, we created a correlative document pool for each candidate. We gained the expert list and the support document with the pool. The framework of our approach is depicted in figure <ref type="figure" coords="6,322.33,711.09,4.59,10.58" target="#fig_1">2</ref>. We collected the identity for all the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Correlative document pool generation</head><p>Firstly, we collected the identities of each candidate, including his name, email, phone, nick, personal main page and so on <ref type="bibr" coords="7,298.11,170.61,18.10,10.58" target="#b10">[14]</ref>. There were two stages in this process: automatic and manual. In the automatic stage we made several rules for identity extraction combining the technique of named identity recognition, then adjust and recruit the result in the manual stage.</p><p>After candidate identity extraction was finished, an index was built based on the cleaned W3C collections and utilized the candidate identities to query. We singled out a number of words around the candidate identity to form the correlative document pool. Using this method, a pool of 1092 correlative documents was built. We experimented with different number of word: 10, 50, 100, 200, and 300 and found that the performance was best when the number was 200. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Expert list and supporting document generation</head><p>In this process, an index was built based on the correlative pool firstly. We attempt to compose the query in several ways for each topic and introduced the query to the indri. The expert list was gained through the retrieved indri score.</p><p>Different from last year, every retrieved expert should be provided with corresponding supporting documents which can explain why the candidate is an expert in this subject. Accordingly, we dealt with the correlative document pool. We took the "document ID-candidate ID" as the supporting document ID, in this way the correlative document pool of a candidate was divided into some supporting documents <ref type="bibr" coords="8,458.20,246.45,17.90,10.58" target="#b11">[15]</ref>. Then we added the candidate identities to the original query and utilized indri to gain the supporting documents of the expert.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The detail information of our four submitted runs is displayed in Table <ref type="table" coords="8,462.24,322.29,5.88,10.58" target="#tab_3">4</ref> and the results of these runs are displayed in Table <ref type="table" coords="8,289.48,337.65,4.47,10.58" target="#tab_4">5</ref>. In Table <ref type="table" coords="8,151.20,602.37,4.47,10.58" target="#tab_4">5</ref>, the first column is the run identifier, the second column is the mean average precision (MAP), other columns display other important factor. In terms of the MAP measure, DUTEX3 is better than DUTEX1. The only difference between them is the number of words in correlative document pool. We can see that it is better when the number is 50. The performance is not consistent with the results obtained on the training topics (TREC 2005 Expert topics). DUTEX2 gains the best result in all the runs since we modified its queries by manual. So we can conclude that it is effective to apply manual interfere in the process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>In TREC 2006 we took part in Genomics and Enterprise tracks. For Genomics track, due to insufficient of training data, our methods and parameters of the experiment are mostly chose empirically. In the future, we should focus on the method that retrieves passages with more variable length. In addition, syntactic parsing, domain specific knowledge and machine learning approaches will be used to enhance the retrieval performance.</p><p>For Enterprise track, we found that structured information, such as thread structure, was not useful in the discussion search, and data preprocess such as removing special characters from W3C collection increased the MAP by about 3%. Expert search task is different from the traditional search problem. To resolve this problem, a new method which we called it correlative document pool, was applied and the result indicates the effectiveness of this method. In addition, there are many pronouns in the document and they are important to identify the expert. Therefore, it may help to improve the performance by introducing anaphora resolution technology.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,202.56,687.50,191.34,9.72"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Framework of DS track IR system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,195.36,702.86,203.80,9.72"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Framework of ES track IR system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,110.16,170.85,379.28,96.26"><head>Table1: Performance of official and unofficial runs</head><label></label><figDesc></figDesc><table coords="4,110.16,194.39,379.28,72.72"><row><cell>Method</cell><cell>Passage MAP</cell><cell cols="2">Aspect MAP Document MAP</cell><cell>Run ID</cell></row><row><cell>Method1</cell><cell cols="2">0.07066621 0.18569347</cell><cell>0.36335342</cell><cell>DUTgen1</cell></row><row><cell>Method2</cell><cell cols="2">0.05491280 0.15559669</cell><cell>0.30699291</cell><cell>DUTgen4 (unsubmitted)</cell></row><row><cell>Method3</cell><cell cols="2">0.07302423 0.16477437</cell><cell>0.36005838</cell><cell>DUTgen2</cell></row><row><cell>Method4</cell><cell cols="2">0.04467985 0.13790016</cell><cell>0.29021274</cell><cell>DUTgen3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,113.52,326.87,363.72,94.97"><head>Table 3 : Results for Discussion Search</head><label>3</label><figDesc></figDesc><table coords="6,113.52,350.15,363.72,71.69"><row><cell>Run ID</cell><cell>MAP</cell><cell>R-prec</cell><cell>Bpref</cell><cell>Reciprocal rank</cell><cell>p@10</cell></row><row><cell>DUTDS1</cell><cell>0.2252</cell><cell>0.2603</cell><cell>0.2390</cell><cell>0.4963</cell><cell>0.3087</cell></row><row><cell>DUTDS2</cell><cell>0.2166</cell><cell>0.2501</cell><cell>0.2334</cell><cell>0.4837</cell><cell>0.2913</cell></row><row><cell>DUTDS3</cell><cell>0.2808</cell><cell>0.3110</cell><cell>0.2958</cell><cell>0.6483</cell><cell>0.4022</cell></row><row><cell>DUTDS4</cell><cell>0.2714</cell><cell>0.3066</cell><cell>0.2856</cell><cell>0.5433</cell><cell>0.3826</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,116.64,353.01,375.87,118.99"><head>Table 4 : Detail information of four runs</head><label>4</label><figDesc></figDesc><table coords="8,116.64,384.47,375.87,87.53"><row><cell>Run ID</cell><cell>Index type</cell><cell>query</cell><cell>Ranking method</cell><cell>Words number</cell></row><row><cell>DUTEX1</cell><cell>Indri</cell><cell>Title</cell><cell>Indri</cell><cell>200</cell></row><row><cell>DUTEX2</cell><cell>Indri</cell><cell>Manual</cell><cell>Indri</cell><cell>200</cell></row><row><cell>DUTEX3</cell><cell>Indri</cell><cell>Title</cell><cell>Indri</cell><cell>50</cell></row><row><cell>DUTEX4</cell><cell>Indri</cell><cell>Title, Narrative</cell><cell>Indri</cell><cell>200</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,109.92,479.03,371.64,102.41"><head>Table 5 : Results for Expert Search</head><label>5</label><figDesc></figDesc><table coords="8,109.92,509.75,371.64,71.69"><row><cell>Run ID</cell><cell>MAP</cell><cell>R-prec</cell><cell>Bpref</cell><cell>Reciprocal rank</cell><cell>p@10</cell></row><row><cell>DUTEX1</cell><cell>0.3033</cell><cell>0.3343</cell><cell>0.3205</cell><cell>0.6007</cell><cell>0.4184</cell></row><row><cell>DUTEX2</cell><cell>0.3779</cell><cell>0.4175</cell><cell>0.4077</cell><cell>0.8094</cell><cell>0.5184</cell></row><row><cell>DUTEX3</cell><cell>0.3267</cell><cell>0.3662</cell><cell>0.3637</cell><cell>0.6931</cell><cell>0.4857</cell></row><row><cell>DUTEX4</cell><cell>0.2834</cell><cell>0.3392</cell><cell>0.3953</cell><cell>0.4430</cell><cell>0.3796</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This work is supported by grant from the <rs type="funder">Natural Science Foundation of China</rs> (<rs type="grantNumber">60373095</rs>). In addition, we are grateful to <rs type="person">Maoshu Ni</rs>, <rs type="person">Baodong Wu</rs>, <rs type="person">Baojin Cui</rs> for their contributions to our work.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_SuC47Au">
					<idno type="grant-number">60373095</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,123.12,474.21,385.71,10.58;9,88.08,489.33,420.62,10.58;9,88.08,504.69,211.01,10.58" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,167.05,474.21,276.53,10.58">Incremental Relevance Feedback for Information Filtering</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,451.69,474.21,57.13,10.58;9,88.08,489.33,420.62,10.58;9,88.08,504.69,95.93,10.58">Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 19th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>Zurich</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="270" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,123.62,519.81,384.84,10.58;9,88.08,534.93,420.68,10.58;9,88.08,550.05,178.86,10.58" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,281.31,519.81,227.15,10.58;9,88.08,534.93,296.52,10.58">Enhance Genomic IR with Term Variation and Expansion: Experience of the IASL Group at Genomic Track</title>
		<author>
			<persName coords=""><forename type="first">Tzong-Han</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chia-Wei</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,419.04,534.93,89.72,10.58;9,88.08,550.05,144.41,10.58">Proceedings of the 14th Text Retrieval Conference</title>
		<meeting>the 14th Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,123.86,565.41,384.60,10.58;9,88.08,580.53,334.14,10.58" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Rie</forename><surname>Kubota</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ando</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<title level="m" coord="9,289.46,565.41,219.00,10.58;9,88.08,580.53,299.90,10.58">TREC 2005 Genomics Track Experiments at IBM Watson. Proceedings of the 14th Text Retrieval Conference</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,125.28,626.13,383.43,10.58;9,88.08,638.80,236.22,13.03" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,359.51,626.13,149.21,10.58;9,88.08,641.25,30.52,10.58">The unified medical language system</title>
		<author>
			<persName coords=""><forename type="first">Dab</forename><surname>Lindberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">L</forename><surname>Humphreys</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Mccray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,126.51,641.25,78.59,10.58">Methods Inf Med</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="281" to="291" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,122.42,656.37,386.14,10.58;9,88.08,671.73,420.37,10.58;9,88.08,686.85,99.21,10.58" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,213.36,656.37,216.35,10.58">Passage Retrieval Based on Language Models</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,451.19,656.37,57.37,10.58;9,88.08,671.73,384.97,10.58">Proceedings of the 11th International Conference on Information and Knowledge Management</title>
		<meeting>the 11th International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="375" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,123.60,701.97,385.11,10.58;9,88.08,717.09,411.70,10.58" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,353.28,701.97,155.43,10.58;9,88.08,717.09,135.34,10.58">York University at TREC 2004: HARD and Genomics Tracks</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">R</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,231.15,717.09,234.42,10.58">Proceedings of the 13th Text Retrieval Conference</title>
		<meeting>the 13th Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,122.40,109.89,385.99,10.58;10,88.08,125.01,420.48,10.58;10,88.08,140.13,420.54,10.58;10,88.08,155.49,26.46,10.58" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Collins-Thompson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Larkey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">N</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ogilvie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<ptr target="http://www.cs.cmu.edu/~lemur/" />
		<title level="m" coord="10,460.02,125.01,48.54,10.58;10,88.08,140.13,261.80,10.58">The lemur toolkit for language modeling and information retrieval</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.90,170.61,379.83,10.58;10,88.08,185.73,420.30,10.58;10,88.08,200.85,82.41,10.58" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="10,193.70,170.61,315.03,10.58;10,88.08,185.73,172.13,10.58">Advances in Kernel Methods -Support Vector Learning</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<editor>B. Schölkopf and C. Burges and A. Smola</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>MIT-Press</publisher>
		</imprint>
	</monogr>
	<note>Making large-Scale SVM Learning Practical</note>
</biblStruct>

<biblStruct coords="10,129.36,216.21,379.05,10.58" xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Arjen</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>De Vries</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Ian Soboroff. Overview of the TREC-2005</note>
</biblStruct>

<biblStruct coords="10,88.08,231.33,352.12,10.58" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,88.08,231.33,75.68,10.58">Enterprise Track</title>
	</analytic>
	<monogr>
		<title level="m" coord="10,171.59,231.33,234.38,10.58">Proceedings of the 14th Text Retrieval Conference</title>
		<meeting>the 14th Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.64,276.93,379.56,10.58;10,88.08,292.05,414.98,10.58" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,460.53,276.93,47.67,10.58;10,88.08,292.05,138.45,10.58">THUIR at TREC 2005: Enterprise Track</title>
		<author>
			<persName coords=""><forename type="first">Yupeng</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yize</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,234.20,292.05,234.41,10.58">Proceedings of the 14th Text Retrieval Conference</title>
		<meeting>the 14th Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,129.12,307.17,379.69,10.58;10,88.08,322.29,344.20,10.58" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,363.11,307.17,145.71,10.58;10,88.08,322.29,66.70,10.58">CNDS Expert Finding System for TREC2005</title>
		<author>
			<persName coords=""><forename type="first">Conglei</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jing</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhifeng</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,163.66,322.29,234.19,10.58">Proceedings of the 14th Text Retrieval Conference</title>
		<meeting>the 14th Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
