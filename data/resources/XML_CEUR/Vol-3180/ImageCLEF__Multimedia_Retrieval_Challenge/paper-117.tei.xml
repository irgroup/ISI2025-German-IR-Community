<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,416.51,15.42;1,89.29,106.66,406.23,15.42">SSN MLRG at ImageCLEF 2022 Tuberculosis: Caverns Report using 3D CNN and Uniformizing Techniques</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,52.16,11.96"><forename type="first">S</forename><surname>Dheepak</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<postCode>Kalavakkam -603110</postCode>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,154.10,134.97,91.96,11.96"><forename type="first">Kavitha</forename><surname>Srinivasan</surname></persName>
							<email>kavithas@ssn.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<postCode>Kalavakkam -603110</postCode>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,416.51,15.42;1,89.29,106.66,406.23,15.42">SSN MLRG at ImageCLEF 2022 Tuberculosis: Caverns Report using 3D CNN and Uniformizing Techniques</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">BCF88D94AEF6B2B846698947E1B5B542</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Tuberculosis</term>
					<term>Computed Tomography</term>
					<term>3D CNN</term>
					<term>Uniformizing Techniques</term>
					<term>Pre-processing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Tuberculosis (TB) is a bacterial infection that mainly affects the lungs. It is a widespread chronic infectious disease, hence the analysis of Tuberculosis Computed Tomography (CT) reports has a significant impact on clinical treatment. To emphasize the importance of medical report writing, the ImageCLEF forum has introduced the Caverns Report generation task from 3D CT images this year and we participated in the same task. Due to the depth variability of the 3D CT images, we explored a pre-processing technique called Uniformizing Techniques. This pre-processing technique samples a subset of the slices using a spacing factor to equal samples from the sequence of slices to generate the desired volumetric output. The pre-processed image is fed as input to three separate binary classification networks. The results of the networks are combined to generate the report. Our team ranks the fourth position in this task and achieved a mean AUC score and min AUC score of 0.461 and 0.256, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Tuberculosis (TB) affects 10 million people and kills 1.5 million people per year around the world, despite being a preventable and curable disease. TB is a kind of bacteria called Mycobacterium tuberculosis and it most often affects the lungs. TB is spread through the air from the TB-affected people by coughing, sneezing, or spitting. If the person with AIDS/HIV got affected by TB then it has a leading cause of death and also a major contributor to antimicrobial resistance. TB bacteria are thought to infect about a quarter of the world's population. Only 5 to 15 percent of these persons will develop active tuberculosis illness <ref type="bibr" coords="1,89.29,496.34,11.58,10.91" target="#b0">[1]</ref>. The rest have tuberculosis but aren't sick, so they can't spread the disease. Currently, tuberculosis is diagnosed mostly through an extensive assessment of the patient's clinical signs, imaging data, and laboratory examination results. A chest X-ray and a CT scan are two imaging diagnostic methods. The lymphadenopathy or miliary alteration of the lung and mediastinum can be seen on a chest X-ray. It is identified that comparatively, CT scan images have high resolution to make a detailed evaluation for the detection of tuberculosis. Therefore the analysis of Tuberculosis CT reports has a significant impact on clinical treatment.</p><p>The CLEF initiative labs are organising ImageCLEF 2022 <ref type="bibr" coords="2,345.77,86.97,11.28,10.91" target="#b1">[2]</ref>, which is an evaluation campaign. This campaign includes several research projects that are open to teams from all across the world. We focus on the Tuberculosis task from the ImageCLEFmedical competition this year. Caverns Detection and Caverns Report are two sub-tasks of the ImageCLEF 2022 Tuberculosis task. We participated in the Caverns Report task, which required us to predict three binary cavern features as proposed by professional radiologists <ref type="bibr" coords="2,340.97,154.71,11.43,10.91" target="#b2">[3]</ref>. Moreover CT based Tuberculosis tasks are part of ImageCLEF from 2017 onwards for classification and prediction, where machine learning and 2D CNN approaches are adopted in the majority of papers <ref type="bibr" coords="2,450.62,181.81,11.36,10.91" target="#b3">[4,</ref><ref type="bibr" coords="2,464.71,181.81,7.57,10.91" target="#b4">5]</ref>.</p><p>The remaining part of the paper spans the following subsections. In Section 2, the Caverns Report dataset is described. The design of the proposed system is explained in Section 3. A summary of the implementation, result, and the respective evaluation of all runs is given in Section 4 and, the conclusion and future work are summarized at the end.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Dataset</head><p>The Caverns Report task dataset consists of 60 training and 16 test instances <ref type="bibr" coords="2,438.16,308.18,11.58,10.91" target="#b2">[3]</ref>. In each CT image, two versions of automatically extracted lung masks, information on cavern area location, and a cavern report are all included in the dataset. A single 3D CT image is provided for all patients, with an image size of 512√ó512 pixels and a total number of slices of roughly 100. The CT images are all saved in the NIFTI file format with the .nii.gz extension (g-zipped .nii files). Two versions of automatically extracted lung masks were provided for all CT images. The first version of segmentation produces more accurate masks, but in the most severe cases of tuberculosis, it tends to miss big abnormal lung regions <ref type="bibr" coords="2,346.81,403.03,11.58,10.91" target="#b5">[6]</ref>. On the other hand, the second segmentation provides more rough limits but is more consistent in terms of including lesion areas <ref type="bibr" coords="2,115.44,430.13,11.54,10.91" target="#b6">[7]</ref>. The cavern report has three manually labelled binary features which characterizes the cavern (s). The existence of thick walls, calcifications, and foci around the cavern are the distinguishing features. The report comes as a simple .csv file with the following columns (including the header): ID (train case id), thick_walls(binary label for the presence of thick walls around the cavern), has_calcification (binary label for the presence of calcifications around the cavern), foci_around (binary label for the presence of foci around the cavern).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">System Design</head><p>The architecture of our proposed system is shown in Fig. <ref type="figure" coords="2,355.85,556.50,5.17,10.91" target="#fig_0">1</ref> and it consists of Uniformizing Technique module and 3D Convolutional Neural Network (CNN), and we will discuss each part in detail in the following subsections. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Uniformizing Techniques</head><p>Due to the depth variability of the 3D CT images, we explore a pre-processing technique called Uniformizing Techniques <ref type="bibr" coords="3,206.34,121.08,11.53,10.91" target="#b7">[8]</ref>. To generate the desired volumetric output, this pre-processing technique samples a subset of the slices using a spacing factor to equal sample from the sequence of slices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Subset Slice Selection (SSS)</head><p>In this technique, the slices are sampled from the first, middle, and last positions of the entire volume. To achieve consistency due to depth variations, the middle slices are sampled by indexing from half of the input volume depth. The subsets are then stacked depthwise to get the desired input volume.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Even Slice Selection (ESS)</head><p>In this technique, a target depth N and a scan depth of size D are computed. The equation ùêπ = ùê∑ ùëÅ is then used to calculate a spacing factor. By maintaining the spacing factor F between the sequence of slices in the volumetric data, sampling is done at the slice level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">Spline Interpolated Zoom (SIZ)</head><p>In this technique, instead of manually selecting a subset of slices, a constant target depth size of N is pre-determined. Then, for each volume, compute its depth D and use spline interpolation <ref type="bibr" coords="3,89.29,389.38,12.69,10.91" target="#b8">[9]</ref> to zoom it along the z-axis by a factor of 1 ùê∑/ùëÅ , where the interpolant is an order of three. By reproducing the nearest pixel along with the depth or z-axis, the input volume is zoomed or squished. In the other experiments, similar procedures were employed <ref type="bibr" coords="3,405.36,417.48,16.43,10.91" target="#b9">[10,</ref><ref type="bibr" coords="3,424.52,417.48,12.32,10.91" target="#b10">11]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">3D Neural Network</head><p>The proposed 3D architecture shown in Fig <ref type="figure" coords="3,288.69,574.74,5.17,10.91" target="#fig_1">2</ref> has 17 layers, including four 3D convolutional (CONV) layers with two layers consisting of 64 filters, followed by 128 and 256 filters, all with a kernel size of 3√ó3√ó3. Following each CONV layer is a max-pooling (MAXPOOL) layer with a stride of 2 and ReLU activation, followed by batch normalization (BN) <ref type="bibr" coords="3,426.55,615.39,16.42,10.91" target="#b11">[12]</ref>. The feature extraction block is made up of four CONV-MAXPOOL-BN modules. The feature extraction block's final output is flattened and delivered to a fully connected layer with 512 neurons. We use a 60 percent effective dropout rate <ref type="bibr" coords="3,260.21,656.03,16.14,10.91" target="#b12">[13]</ref>. For the binary classification problem, the output is sent to a dense layer of two neurons with softmax activation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Implementation</head><p>In this section, the proposed system implementation is explained along with the minimum software and hardware requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">System Specification</head><p>The hardware and software required for the development of the proposed system include, (i). Intel i7 processor with NVIDIA graphics card, 4800M at 4.3GHZ clock speed, 12GB RAM, Graphical Processing Unit, and 1TB Solid State drive, (ii). Windows 10 operating system with VSCode editor, Python 3.9 package with required libraries like TensorFlow, NumPy, scipy, nibabel, pandas, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experimental Setup</head><p>In this section, the experiment setting along with the network parameters are explained. The input image is converted into 2D slices. The slices are resized to 128√ó128. The resized slices are taken as input by the uniformizing techniques module. The uniformizing techniques samples at the sampling from slice level and stack them depth-wise to produce the desired 3D volume. Fig. <ref type="figure" coords="4,89.29,332.68,4.97,10.91" target="#fig_2">3</ref> illustrates the slices of the 3D image with ID TRN_04. This image had a total of 104 slices. Fig. <ref type="figure" coords="4,89.04,346.23,5.16,10.91" target="#fig_3">4</ref> shows the slices that were sampled by applying the Subset Slice Selection. Fig. <ref type="figure" coords="4,454.32,346.23,5.16,10.91" target="#fig_4">5</ref> visualizes the slices that were sampled by applying the Even Slice Selection and Fig. <ref type="figure" coords="4,432.90,359.77,5.17,10.91" target="#fig_5">6</ref> represents the slices that were sampled by applying Spline Interpolated Zoom.    The pixel values were normalized by subtracting the minimum pixel value and dividing it by the difference between the maximum and minimum pixel values. The normalized image is then given as an input to the proposed 3D CNN model.</p><p>We used Stochastic Gradient Descent(SGD) optimizer with a learning rate of 10 6 and a momentum of 0.99. Weight is initialized using the Glorot initialization method <ref type="bibr" coords="5,466.96,366.53,18.06,10.91" target="#b13">[14]</ref> and minimizes the Mean average error <ref type="bibr" coords="5,243.12,380.08,17.82,10.91" target="#b14">[15]</ref> during training. The proposed network was trained for 100 epochs with a batch size of 2.</p><p>We divided the Caverns Report task into three separate binary prediction tasks based on the features and built a separate model for each one of them. The results from the models are combined to generate the report.</p><p>To ensure a fair comparison between the uniformizing methods, we set the desired input size of 128√ó128√ó64 for all our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results</head><p>The performace of the proposed system is evaluated using Area Under the ROC Curve (AUC) metric and the results are tabulated in Table <ref type="table" coords="5,290.03,551.75,3.78,10.91" target="#tab_0">1</ref>. There were a total of 3 runs submitted for the task. One run for each one of the uniformizing techniques. When compared to SSS and ESS, we inferred that SIZ better depicts the 3D CT when downsampled. In addition to this, ESS produces slightly better results than SSS because in ESS the sampling is done consecutively. Selecting specific slices, on the other hand, does not preserve the semantic meaning of volumetric data because it is not a proper representation of the 3D CT scan, which is also intuitive. Even though ESS downsamples the volume from a subset, the sampling is done throughout the entire volume, resulting in greater performance. In comparison to SSS, ESS enhances the likelihood of sampling the TB affected segments. Because tuberculosis can affect any portion of the lung, it's impossible to know which slices should be rejected without looking at each scan individually because the annotations are provided at the volume level rather than the slice level, retrieving data from the complete volume is critical now-a-days. In ImageCLEF 2022 Tuberculosis Caverns Report task, 4 teams participated out of 37 teams with 29 successful submissions. Among these, we have made 3 successful submissions and achieved the fourth rank. The overall ranking achieved by the teams is tabulated in Table <ref type="table" coords="6,489.51,427.61,3.74,10.91" target="#tab_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>In this paper, we proposed a framework consisting of 3D CNN and Uniformizing Techniques to generate the Tuberculosis Caverns Report. The proposed system pre-processes the input CT image using the uniformizing techniques to sample the slices of the image to generate a volume of the desired output. The generated volume is fed as input to 3 binary classifier networks. The output of the networks is combined to generate the report. The proposed framework achieved a mean Area Under the ROC curve of 0.461. In future, different 3D network architectures will be tested, and the slice selection techniques can be improved with an attempt to construct a robust deep learning model which will generate an accurate Tuberculosis CT report.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,89.29,660.86,103.24,8.93"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System Design</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,89.29,510.61,122.56,8.93;3,90.54,439.03,416.70,59.02"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: 3D Neural Network</figDesc><graphic coords="3,90.54,439.03,416.70,59.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,89.29,523.75,132.34,8.93;4,90.54,407.01,416.69,104.17"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Slices of 3D CT Image</figDesc><graphic coords="4,90.54,407.01,416.69,104.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,89.29,637.63,217.67,8.93;4,90.54,562.56,416.69,62.50"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Slices sampled using Subset Slice Selection</figDesc><graphic coords="4,90.54,562.56,416.69,62.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,89.29,159.26,210.18,8.93;5,90.54,84.19,416.69,62.50"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Slices sampled using Even Slice Selection</figDesc><graphic coords="5,90.54,84.19,416.69,62.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="5,89.29,261.18,234.29,8.93;5,90.54,186.11,416.69,62.50"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Slices sampled using Spline Interpolated Zoom</figDesc><graphic coords="5,90.54,186.11,416.69,62.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,88.99,143.07,334.87,92.72"><head>Table 1</head><label>1</label><figDesc>Test set Results</figDesc><table coords="6,171.42,172.68,252.44,63.11"><row><cell>Uniformizing Techniques</cell><cell>MEAN_AUC</cell><cell>MIN_AUC</cell></row><row><cell>Subset Slice Selection</cell><cell>0.407</cell><cell>0.205</cell></row><row><cell>Even Slice Selection</cell><cell>0.400</cell><cell>0.231</cell></row><row><cell>Spline Interpolated Zoom</cell><cell>0.461</cell><cell>0.256</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,88.99,269.44,390.38,112.88"><head>Table 2</head><label>2</label><figDesc>Ranking of ImageCLEF 2022 Tuberculosis Caverns Report task</figDesc><table coords="6,115.90,301.27,363.48,81.06"><row><cell>Participants</cell><cell>MEAN_AUC</cell><cell>MIN_AUC</cell><cell>Successful submissions</cell></row><row><cell>SDVA-UCSD</cell><cell>0.687</cell><cell>0.513</cell><cell>10</cell></row><row><cell>KDE-lab</cell><cell>0.658</cell><cell>0.317</cell><cell>11</cell></row><row><cell>KL_BP_SSN</cell><cell>0.536</cell><cell>0.413</cell><cell>5</cell></row><row><cell>SSN_Dheepak_Kavitha</cell><cell>0.461</cell><cell>0.256</cell><cell>3</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>Our profound gratitude to <rs type="institution">Sri Sivasubramaniya Nadar College</rs> <rs type="affiliation">of Engineering, Department of CSE</rs>, for allowing us to utilize the <rs type="institution">High Performance Computing Laboratory</rs> and GPU Server for the execution of this challenge successfully.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="7,112.66,111.28,394.04,10.91;7,112.66,124.83,105.35,10.91" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">H</forename><surname>Organization</surname></persName>
		</author>
		<ptr target="https://www.who.int/health-topics/tuberculosis#tab=tab_1" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">Tuberculosis</note>
</biblStruct>

<biblStruct coords="7,112.66,138.38,395.01,10.91;7,112.66,151.93,395.17,10.91;7,112.39,165.48,394.80,10.91;7,112.66,179.03,394.62,10.91;7,112.66,192.57,393.33,10.91;7,112.66,206.12,395.17,10.91;7,112.66,219.67,393.54,10.91;7,112.66,233.22,170.14,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,352.50,179.03,154.78,10.91;7,112.66,192.57,300.10,10.91">Overview of the ImageCLEF 2022: Multimedia retrieval in medical, social media and nature applications</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>M√ºller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Peteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>R√ºckert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Br√ºngel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Idrissi-Yaghir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sch√§fer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">D</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L.-D</forename><surname>≈ûtefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Deshayes-Chossart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,435.26,192.57,70.73,10.91;7,112.66,206.12,395.17,10.91;7,112.66,219.67,239.58,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction, Proceedings of the 13th International Conference of the CLEF Association (CLEF 2022)</title>
		<title level="s" coord="7,359.20,219.67,147.00,10.91;7,112.66,233.22,31.10,10.91">LNCS Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,246.77,393.33,10.91;7,112.66,260.32,393.33,10.91;7,112.14,273.87,365.75,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,341.66,246.77,164.33,10.91;7,112.66,260.32,214.54,10.91">Overview of ImageCLEFtuberculosis 2022 -CT-based Caverns Detection and Report</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>M√ºller</surname></persName>
		</author>
		<ptr target=".org&lt;http://ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="m" coord="7,354.60,260.32,115.78,10.91">CLEF2022 Working Notes</title>
		<title level="s" coord="7,478.71,260.32,27.27,10.91;7,112.14,273.87,147.97,10.91">CEUR Workshop Proceedings, CEUR-WS</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,287.42,393.33,10.91;7,112.66,300.97,393.33,10.91;7,112.66,314.52,394.51,10.91;7,112.66,330.51,144.83,7.90" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,334.91,287.42,171.08,10.91;7,112.66,300.97,228.83,10.91">Classification of lung tuberculosis using non parametric and deep neural network techniques</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kavitha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Poornima</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">S</forename><surname>Sitara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sarada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Devi</forename></persName>
		</author>
		<idno type="DOI">10.1109/ICCCSP49186.2020.9315211</idno>
	</analytic>
	<monogr>
		<title level="m" coord="7,364.48,300.97,141.51,10.91;7,112.66,314.52,260.65,10.91">4th International Conference on Computer, Communication and Signal Processing (ICCCSP)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,341.62,393.33,10.91;7,112.66,355.17,393.33,10.91;7,112.66,368.71,197.29,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,395.55,341.62,110.44,10.91;7,112.66,355.17,393.33,10.91;7,112.66,368.71,45.28,10.91">ImageCLEF 2019: A 2D Convolutional Neural Network approach for severity scoring of lung Tuberculosis using CT Images</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kavitha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nandhinee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Harshana</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S S</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Harrinei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,181.33,368.71,98.72,10.91">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,382.26,393.60,10.91;7,112.66,395.81,393.61,10.91;7,112.28,409.36,395.55,10.91;7,111.60,422.91,209.28,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,424.12,382.26,82.14,10.91;7,112.66,395.81,232.83,10.91">Efficient and fully automatic segmentation of the lungs in CT volumes</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">Dicente</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">A</forename><surname>Jim√©nez Del Toro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Depeursinge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>M√ºller</surname></persName>
		</author>
		<ptr target=".org&lt;http://ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="m" coord="7,369.69,395.81,136.58,10.91;7,112.28,409.36,217.92,10.91">Proceedings of the VISCERAL Anatomy Grand Challenge at the 2015 IEEE ISBI</title>
		<title level="s" coord="7,337.12,409.36,170.71,10.91;7,111.60,422.91,11.03,10.91">CEUR Workshop Proceedings, CEUR-WS</title>
		<meeting>the VISCERAL Anatomy Grand Challenge at the 2015 IEEE ISBI</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="31" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,436.46,393.33,10.91;7,112.66,450.01,394.53,10.91;7,112.66,463.56,263.63,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,220.70,436.46,285.29,10.91;7,112.66,450.01,105.12,10.91">ImageCLEF 2017: Supervoxels and co-occurrence for tuberculosis CT image classification</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<ptr target="org&lt;http://ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="m" coord="7,244.53,450.01,115.78,10.91">CLEF2017 Working Notes</title>
		<title level="s" coord="7,368.63,450.01,138.56,10.91;7,112.66,463.56,45.79,10.91">CEUR Workshop Proceedings, CEUR-WS.</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,477.11,393.65,10.91;7,112.66,490.66,393.33,10.91;7,112.66,504.21,235.93,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,335.75,477.11,170.56,10.91;7,112.66,490.66,206.16,10.91">Uniformizing techniques to process CT scans with 3D CNNs for tuberculosis prediction</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zunair</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,341.23,490.66,164.76,10.91;7,112.66,504.21,105.07,10.91">International Workshop on Predictive Intelligence In Medicine</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="156" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,517.76,394.53,10.91;7,112.41,531.30,22.69,10.91" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">De</forename><surname>Boor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">De</forename><surname>Boor</surname></persName>
		</author>
		<title level="m" coord="7,217.74,517.76,117.23,10.91">A practical guide to splines</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>springer-verlag</publisher>
			<date type="published" when="1978">1978</date>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,544.85,393.61,10.91;7,112.66,558.40,393.33,10.91;7,112.66,571.95,320.78,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,356.29,544.85,149.98,10.91;7,112.66,558.40,248.23,10.91">Radnet: Radiologist level accuracy using deep learning for hemorrhage detection in CT scans</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Varadarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,404.51,558.40,101.48,10.91;7,112.66,571.95,206.56,10.91">IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="281" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,585.50,393.32,10.91;7,112.66,599.05,355.84,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,171.80,585.50,50.37,10.91;7,250.55,585.50,255.43,10.91;7,112.66,599.05,206.96,10.91">CT Image Analysis for TB Severity Scoring and CT Report Generation using Autoencoded Image Features</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kazlouski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,327.98,599.05,100.80,10.91">CLEF (Working Notes)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note>ImageCLEF</note>
</biblStruct>

<biblStruct coords="7,112.66,612.60,393.33,10.91;7,112.66,626.15,395.01,10.91;7,112.41,639.70,38.81,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,200.82,612.60,305.16,10.91;7,112.66,626.15,97.96,10.91">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,232.54,626.15,198.11,10.91">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,653.25,393.32,10.91;7,112.66,666.80,364.49,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,346.89,653.25,159.09,10.91;7,112.66,666.80,211.15,10.91">Predicting tuberculosis related lung deformities from CT scan images using 3D CNN</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pattnaik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kanodia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mohanty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,348.54,666.80,98.72,10.91">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,86.97,395.17,10.91;8,112.26,100.52,393.73,10.91;8,112.66,114.06,351.87,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,205.33,86.97,302.50,10.91;8,112.26,100.52,24.53,10.91">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,160.10,100.52,345.88,10.91;8,112.66,114.06,263.86,10.91">Proceedings of the thirteenth international conference on artificial intelligence and statistics, JMLR Workshop and Conference Proceedings</title>
		<meeting>the thirteenth international conference on artificial intelligence and statistics, JMLR Workshop and Conference Proceedings</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,127.61,393.33,10.91;8,112.66,141.16,393.32,10.91;8,112.33,154.71,58.19,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,239.85,127.61,266.13,10.91;8,112.66,141.16,296.87,10.91">Advantages of the mean absolute error (MAE) over the root mean square error (RMSE) in assessing average model performance</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Willmott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Matsuura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,418.36,141.16,74.79,10.91">Climate research</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="79" to="82" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
