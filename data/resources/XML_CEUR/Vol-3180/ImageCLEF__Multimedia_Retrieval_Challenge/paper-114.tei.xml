<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,100.85,67.64,400.71,17.04;1,80.18,88.52,442.22,17.04;1,200.47,109.16,202.03,17.04">SSN CSE at ImageCLEFaware 2022: Contextual Job Search Feedback Score based on Photographic Profile using a Random Forest Regression Technique</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,72.02,141.85,68.98,10.80"><forename type="first">Aarthi</forename><surname>Nunna</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">CLEF</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,155.08,141.85,172.31,10.80"><forename type="first">Aravind</forename><forename type="middle">Kannan</forename><surname>Rathinasapabathi</surname></persName>
						</author>
						<author>
							<persName coords="1,341.40,141.85,93.38,10.80"><forename type="first">Chirag</forename><surname>Bheemaiah</surname></persName>
							<email>chiragbheemaiahpk19025@it.ssn.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of IT</orgName>
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<postCode>Kalavakkam -603110</postCode>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,498.91,141.85,37.96,10.80;1,72.02,155.29,50.60,10.80"><forename type="first">Kavitha</forename><surname>Srinivasan</surname></persName>
							<email>kavithas@ssn.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<postCode>Kalavakkam -603110</postCode>
									<country key="IN">India</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">CLEF</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,100.85,67.64,400.71,17.04;1,80.18,88.52,442.22,17.04;1,200.47,109.16,202.03,17.04">SSN CSE at ImageCLEFaware 2022: Contextual Job Search Feedback Score based on Photographic Profile using a Random Forest Regression Technique</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4E2BFD5CCC2A8F84B7A67BF146C01351</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Supervised learning</term>
					<term>Random Forest Regression Algorithm</term>
					<term>Social photographic profile-based score</term>
					<term>Pearson Correlation Coefficient</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Social networks have become increasingly popular with millions of users where the digital presence has become more crucial to a person's character judgement. Employers tend to screen through their candidates' profiles on social media to understand their personalities and infer the knowledge about the candidate's eligibility for a specific job. To address this issue, the ImageCLEF forum is conducting a task to quantify the effect of the photographic profile from 2021 onwards and we participated this year. Therefore, an algorithm was developed to score the images of a user and provide them with comprehensive feedback on the consequences of the images on their selected professions. The approach used to develop the algorithm uses Random Forest Regression which resulted in a Pearson Correlation Coefficient of 0.544.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.44" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.44" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.44" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.44" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.44" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.44" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.44" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.44" lry="841.92"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.44" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In today's world, the digital presence of humans has become more pivotal than their physical presence. With the ease of internet access, everybody is more digitally conscious than social. As a result, social networking is undoubtedly an integral part of life. Every day, millions of users upload content such as images, posts, and stories on platforms like Instagram, Twitter, Facebook, etc. The actions and posts on social media can have real-time effects on the physical world, it can even affect a person's ability to acquire a job. So, it has become crucial to learn the effects of visual media uploaded on various social platforms as explained by Van-Khoa Nguyen et al. <ref type="bibr" coords="1,232.42,510.76,11.61,9.94" target="#b0">[1]</ref>. If users are digitally responsible and disciplined when uploading various visual media, it benefits the society as a whole because their digital presence wouldn't have any adverse effects on their career and its growth.</p><p>The ImageCLEFaware 2022 is the second edition of the aware task conducted by the CLEF Initiative. The task asked participants to provide a global rating of each profile in each situation using a Likert Scale. In the edition held in 2021 <ref type="bibr" coords="1,182.95,573.91,11.43,9.94" target="#b1">[2]</ref>, 500 user profiles were provided in the dataset opposed to 1000 user profiles in this edition. This forum has taken this socially significant issue into their hands again, for the second time, and put together a dataset of various users along with the pictures they posted in an anonymized format for us to analyze the real-world effect on four selected situations, namely bank loan, accommodation, jobs as a waitress/waiter, and jobs in IT. The final objective of the task would be to integrate the model with a mobile application for users to obtain their feedback efficiently and easily.</p><p>Our team strived to develop an algorithm that provides feedback to the users that resembles feedback given by humans. The dataset used is a subset of the YFCC100M <ref type="bibr" coords="1,365.08,662.49,12.80,9.94" target="#b2">[3]</ref> dataset. It comprises various user profiles. Each profile constitutes a maximum of hundred images. A thousand user profiles were used to train our model. The objects present in the images are initially detected by a Faster-RCNN model, resulting in a confidence score for each object detected. Thus, our models have taken as input a JSON file that comprises the object detected along with its confidence score and its bounding box. We experimented with the algorithms explained in Section 3 and 4 and found Random Forest Regression to be the best performing algorithm.</p><p>The following sections of the paper are: Section 2 describes the dataset provided by ImageCLEF, the various models that were used to obtain the required outputs in Section 3, the comparison between the models and the inferences obtained are discussed in Section 4. Finally, we have summarized the findings in the conclusion and future work Section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Dataset</head><p>The dataset was given with a split of three categories, namely training, validation, and testing data by the ImageCLEF forum. The testing data was used to obtain the final output file which was submitted for evaluation. Table <ref type="table" coords="2,147.17,211.17,5.52,9.94" target="#tab_0">1</ref> provides a comprehensive understanding of the dataset and additional information about the same. The three folders are pertaining to the input files for the three respective dataset categories. The train and validation input files are used to train our various models.</p><p>The test input file was used to obtain the ground truth output file to be submitted for evaluation.</p><p>The folder contains the users' photographic profiles that comprises of each user, their respective images and the objects detected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gt_train.json, Gt_val.json</head><p>The final output ranks of each user's profile with respect to the four professions chosen.</p><p>The file comprises of each user and four values that determine how the social profile of the user would affect his/her career choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">System Design</head><p>The system design of the developed model is visually represented in Figure <ref type="figure" coords="2,419.31,651.69,4.14,9.94">1</ref>. As observed, there are multiple components that serve as the input for the model which are obtained from the dataset explained in Table <ref type="table" coords="2,104.21,676.89,5.52,9.94" target="#tab_0">1</ref> Figure <ref type="figure" coords="3,96.72,218.83,4.28,11.04">1</ref>: System Design Figure <ref type="figure" coords="3,111.60,244.77,5.52,9.94">1</ref> depicts a high-level abstraction of the proposed system design. The system takes the dataset as input, pre-processes it and then trains a model on it. The model was then evaluated based on the ground truth values and a set of performance metrics such as the Mean Absolute Error (MAE), Mean Squared Error (MSE) and Root Mean Squared Error (RMSE). On obtaining these values, the model's performance was improved by varying its input and the model's parameters.</p><p>The input data consists of the class scores which contains the score that depict the influence of an object on each profession that may be of either positive or negative value. Secondly, the user profiles along with their images and the objects within them are fed as input. However, the data was pre-processed to fit the various machine learning models. The JSON files are read into data frames for easy processing. The final inputs to the machine learning model are varied and their performance as inputs are observed and tabulated as explained in the following paragraphs.</p><p>The output JSON file contains the model's predictions of the scores that should be associated to each user's photographic profile on considering the user's images and the objects within them. The expected output given in the ground truth files are used to calculate the accuracy of the trained model using which changes to the model are performed and analyzed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Random Forest Regression</head><p>The bagging model is used by the Random Forest Algorithm <ref type="bibr" coords="3,354.62,479.80,12.80,9.94" target="#b3">[4]</ref> as visualized in Figure <ref type="figure" coords="3,474.43,479.80,4.14,9.94" target="#fig_0">2</ref>. This means that subsets of the dataset are used to train various decision trees and the final output is taken through the idea of majority voting. The concept of majority voting is also known as aggregation. Thus, through the methods of replacement and bootstrap aggregation, random forest was observed to be the best algorithm amongst its competitors XGBoost <ref type="bibr" coords="3,218.47,530.44,12.80,9.94" target="#b4">[5]</ref> and ANN.</p><p>Mentioned below are the different versions of the Random Forest model which are unique due to the input parameters that are fed to the models. The models' accuracies are measured using the error values obtained.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Model 1</head><p>In this approach, the input was defined as the 'average confidence score', along with 'average impact scores for each of the classes' for a given user. A random forest regressor was defined with the 'number of estimators' parameter ranging from 10 to 1000. This regressor was fit on 80% of the training data with the remaining being reserved for testing. A loss function of 'Mean Squared Error' was used to grade the performance of the result. The same plan of action was adopted for validation data. All the models were measured parametrically using Pearson Correlation Coefficient <ref type="bibr" coords="4,393.02,220.77,11.61,9.94" target="#b6">[7]</ref>. Figure <ref type="figure" coords="4,448.25,220.77,4.02,9.94" target="#fig_2">3</ref>, illustrates the model's performance on the training data.</p><p>The number of estimators for the regressor was decided to be 650. This regressor was then applied to the testing data which gave the following results as given in Table <ref type="table" coords="4,402.38,449.06,4.02,9.94" target="#tab_1">2</ref>. The Pearson correlation coefficient value was calculated to be 0.288. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Model 2</head><p>In addition to the confidence score and the average impact scores, the objects detected were represented using a matrix whose index represents the object and the value at the index represents the count of the object was also provided as the input.</p><p>To find the optimal number of estimators, a similar approach as the previous method was adopted. Figure <ref type="figure" coords="4,103.49,715.56,5.52,9.94" target="#fig_3">4</ref> illustrates the model's performance over the training and validation phases. The number of estimators for the regressor was decided to be 650. This regressor was then applied to the testing data which gave the following results as given in Table <ref type="table" coords="5,402.14,304.08,4.02,9.94" target="#tab_2">3</ref>. The Pearson correlation coefficient value was calculated to be 0.544. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">Model 3</head><p>Having ascertained that Random Forest Regression is the best fit model for the problem, parameter tuning was performed to optimize the model. The following parameters were considered and set with different options using grid search <ref type="bibr" coords="5,225.70,546.55,12.80,9.94" target="#b7">[8]</ref>  The options were then validated using 3-fold cross validation approach to determine the leading model. The optimal parameters retrieved were: 'bootstrap': True, 'max_depth': 50, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 2000. The Pearson correlation coefficient value was calculated to be 0.542 and Table <ref type="table" coords="5,264.34,673.29,5.52,9.94" target="#tab_4">4</ref> tabulates the metrics obtained for the same.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4.">Model 4</head><p>Like the above versions, an additional feature was added in order to improve the model's accuracy. In the dataset used for training, the objects in various images are identified along with their confidence score and the coordinates of their bounding box. With the knowledge of the coordinates, the area of the bounding box was calculated using simple geometry as they always form a rectangular shape. The area of the bounding was used as it would account for the importance weight of the object in the image along with its confidence score.</p><p>Figure <ref type="figure" coords="6,118.61,193.63,5.52,9.94" target="#fig_4">5</ref> illustrates the model's performance of training data. The Pearson correlation coefficient values was resulted as 0.519 and Table <ref type="table" coords="6,246.82,206.37,5.52,9.94" target="#tab_5">5</ref> tabulates the metrics obtained for the same. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Implementation and Results</head><p>In this section, the aforementioned machine learning models are trained, and the corresponding results are compared and analyzed using performance metrics, namely the Mean Squared Error, Mean Absolute Error and Root Mean Squared Error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">System Specification</head><p>The hardware and software specification required for the implementation the machine learning models includes, Intel i7 processor with NVIDIA MX100 2GB graphics card, 8GB RAM, 1TB disk space, Windows 11 OS, Jupyter Notebook, Python 3.7 packages with required libraries like Sklearn, Tensorflow, Numpy, Pandas, etc. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results of Machine Learning Models</head><p>Since the problem warrants a multivariate regression approach with multiple target variables, XGBoost, Artificial Neural Network, Random Forest Regression models were considered. Thorough experiments were conducted, and the results are depicted below as follows in Table <ref type="table" coords="7,442.25,143.47,4.02,9.94" target="#tab_6">6</ref>. From the above data it can be inferred that the Random Forest Regression model is well suited for the problem statement and hence was chosen as the baseline model for the given task.</p><p>The accuracies of the regression models were evaluated on the test set based on the Mean Squared Error (MSE) metric. In the first run, the 'Model 1' was trained by setting the number of estimator parameter as 650 after iterating over values in the range of <ref type="bibr" coords="7,343.31,360.24,18.38,9.94" target="#b9">[10,</ref><ref type="bibr" coords="7,361.69,360.24,22.97,9.94">1000]</ref>. This model took as input the 'average confidence score', an 'average impact scores for each of the classes.' In Run 2, 'Model 2' took in similar inputs but additionally accounts for all the images detected in a user's profile. In Run 3, 'Model 2's' hyperparameters are altered to achieve better performance. Besides the inputs which were given to 'Model 2', area of the bounding boxes of the objects detected was calculated and was used as an input. Inferring from the results tabulated in Table <ref type="table" coords="7,286.68,642.33,29.96,9.94" target="#tab_7">7Table</ref> , it is evident that the inclusion of the objects detected per user was a key factor in improving the prediction performance metrics. Furthermore, it was observed that hyperparameter tuning did not affect the performance of the model substantially.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Works</head><p>The paper aims to devise a solution for the ImageCLEFaware 2022 Task. The task aims to provide a solution to generate contextual feedback scores for a user's social profile and its influence in their job prospects. The paper describes the various models that were implemented, and their performances have been compared. It was observed that the Random Forest Regression model performed far better than the other models such as XGBoost and ANN. On inferring the same, the inputs given to the Random Forest Regression Model were tweaked and different Random Forest models were developed. These models were compared based on Mean Absolute Error, Mean Squared Error and Root Mean Squared Error. Model 2 has fared better than the other models as per the Pearson Correlation Coefficient value. This could be a direct consequence of the consideration of the objects detected being fed as an input parameter. Hence, this can be worked on further to enhance its correlation with the required output.</p><p>In the future, the dataset can be made more diverse to cover all edge cases and thus aid in developing a more robust algorithm. Other ensemble learning algorithms can be experimented to arrive at meticulous conclusions that will help improve the model's performance. Thus, fine tuning the hyper parameters of the algorithms such as epochs, learning parameters, cross-validation etc. can increase the efficiency and improve the results that are currently obtained.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,66.02,744.34,161.06,11.04;3,171.00,578.10,252.15,163.80"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Random Forest Regression</figDesc><graphic coords="3,171.00,578.10,252.15,163.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,86.18,73.10,437.43,11.04;4,72.02,87.04,451.57,9.94;4,72.02,99.76,374.62,9.94"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Random Forest Regression explains the working of Random Forest Regression which utilizes the concept of bagging. As depicted in the figure, subsets of the input data are used to train different decision trees, whose predictions are averaged to obtain the final prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,181.51,412.56,101.52,11.04;4,181.40,248.12,233.25,157.59"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Training Data</figDesc><graphic coords="4,181.40,248.12,233.25,157.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,183.91,252.91,101.52,11.04;5,181.45,88.50,233.30,157.58"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Training Data</figDesc><graphic coords="5,181.45,88.50,233.30,157.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="6,183.19,392.42,107.38,9.94;6,183.05,230.58,230.02,154.40"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Training Data</figDesc><graphic coords="6,183.05,230.58,230.02,154.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,65.06,251.23,457.90,155.81"><head>Table 1</head><label>1</label><figDesc></figDesc><table coords="2,65.06,264.43,457.90,142.61"><row><cell>Dataset description</cell><cell></cell><cell></cell></row><row><cell>File Provided</cell><cell>Data Provided</cell><cell>Observed</cell></row><row><cell>Class_scores.json</cell><cell>Each visual concept detected has a</cell><cell>Scores for visual concepts</cell></row><row><cell></cell><cell>score depicting its influence on the</cell><cell>80 and 215 are unavailable.</cell></row><row><cell></cell><cell>four professions</cell><cell></cell></row><row><cell>Prediction_train.json,</cell><cell></cell><cell></cell></row><row><cell>Prediction_val.json,</cell><cell></cell><cell></cell></row><row><cell>Prediction_test.json</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,71.06,487.70,417.28,110.67"><head>Table 2</head><label>2</label><figDesc>Model 1 Metrics    </figDesc><table coords="4,81.86,529.70,406.48,68.67"><row><cell>Metrics</cell><cell>Training Dataset</cell><cell>Validation Dataset</cell></row><row><cell>Mean Absolute Error (MAE)</cell><cell>0.36241</cell><cell>0.37192</cell></row><row><cell>Mean Squared Error (MSE)</cell><cell>0.20515</cell><cell>0.23345</cell></row><row><cell>Root Mean Squared Error (RMSE)</cell><cell>0.45294</cell><cell>0.48317</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,71.06,342.46,417.52,111.86"><head>Table 3</head><label>3</label><figDesc>Model 2 Metrics    </figDesc><table coords="5,81.62,384.48,406.96,69.84"><row><cell>Metrics</cell><cell>Training Dataset</cell><cell>Validation Dataset</cell></row><row><cell>Mean Absolute Error (MAE)</cell><cell>0.371921</cell><cell>0.328819</cell></row><row><cell>Mean Squared Error (MSE)</cell><cell>0.176763</cell><cell>0.166127</cell></row><row><cell>Root Mean Squared Error (RMSE)</cell><cell>0.407587</cell><cell>0.420433</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,71.06,698.23,417.52,111.65"><head>Table 4</head><label>4</label><figDesc>Model 3 Metrics    </figDesc><table coords="5,81.62,740.26,406.96,69.62"><row><cell>Metrics</cell><cell>Training Dataset</cell><cell>Validation Dataset</cell></row><row><cell>Mean Absolute Error (MAE)</cell><cell>0.333413</cell><cell>0.339431</cell></row><row><cell>Mean Squared Error (MSE)</cell><cell>0.185843</cell><cell>0.193637</cell></row><row><cell>Root Mean Squared Error (RMSE)</cell><cell>0.431096</cell><cell>0.440042</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,71.06,427.92,417.28,109.94"><head>Table 5</head><label>5</label><figDesc>Model 4 Metrics    </figDesc><table coords="6,81.86,468.02,406.48,69.84"><row><cell>Metrics</cell><cell>Training Dataset</cell><cell>Validation Dataset</cell></row><row><cell>Mean Absolute Error (MAE)</cell><cell>0.343690</cell><cell>0.337131</cell></row><row><cell>Mean Squared Error (MSE)</cell><cell>0.198958</cell><cell>0.189130</cell></row><row><cell>Root Mean Squared Error (RMSE)</cell><cell>0.446047</cell><cell>0.420433</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,72.02,169.37,417.18,104.90"><head>Table 6</head><label>6</label><figDesc></figDesc><table coords="7,72.02,182.57,417.18,91.70"><row><cell>Model accuracy comparisons</cell><cell></cell><cell></cell></row><row><cell>ML Models</cell><cell>Training Dataset (MSE)</cell><cell>Validation Dataset (MSE)</cell></row><row><cell>Random Forest Regression</cell><cell>0.1661</cell><cell>0.1767</cell></row><row><cell>XGBoost</cell><cell>0.1870</cell><cell>0.1966</cell></row><row><cell>Artificial Neural Network</cell><cell>0.1761</cell><cell>0.2160</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="7,72.02,449.52,427.06,157.49"><head>Table 7</head><label>7</label><figDesc>Brief description about each run</figDesc><table coords="7,94.37,492.26,404.72,114.75"><row><cell>Run Number</cell><cell>Approach</cell><cell>MSE-Training</cell><cell>MSE-Validation</cell><cell>Pearson's Correlation</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Coefficient</cell></row><row><cell>1</cell><cell>Model 1</cell><cell>0.1661</cell><cell>0.1767</cell><cell>0.288</cell></row><row><cell>2</cell><cell>Model 2</cell><cell>0.1870</cell><cell>0.1966</cell><cell>0.544</cell></row><row><cell>3</cell><cell>Model 3</cell><cell>0.1761</cell><cell>0.2160</cell><cell>0.542</cell></row><row><cell>4</cell><cell>Model 4</cell><cell>0.1989</cell><cell>0.1891</cell><cell>0.519</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6.">Acknowledgements</head><p>We express our deep gratitude towards <rs type="institution">CLEF Initiative labs</rs> for coming up with the problem statement for us to work on and giving us timely assistance. It was due to ImageCLEF 2022 Aware [9,10] that we learnt a lot during the contest, so we're forever indebted to them. We appreciate AI4Media to support this task. We are grateful to the <rs type="institution">YDSYO Team</rs> for sharing with us the anonymized dataset. We would also like to take this opportunity to thank our college, <rs type="institution">Sri Sivasubramaniya Nadar College of Engineering, Department of Computer Science and Engineering</rs> for motivating us with the opportunity to work on this task.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="8,93.41,416.66,430.44,9.94;8,93.41,429.38,204.41,9.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,402.43,416.66,121.42,9.94;8,93.41,429.38,104.97,9.94">Unveiling Real-Life Effects of Online Photo Sharing</title>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Van-Khoa Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jérôme</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Deshayes-Chossart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,210.31,429.38,60.31,9.94">IEEE WACV</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.41,442.10,430.43,9.94;8,93.41,454.82,430.32,9.94;8,93.41,467.56,430.37,9.94;8,93.41,480.28,430.44,9.94;8,93.41,492.65,430.58,10.05;8,93.41,505.48,430.80,9.94;8,93.41,518.20,430.80,9.94;8,93.41,530.68,430.81,9.94;8,93.41,543.43,430.82,9.94;8,93.41,556.15,429.14,9.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,444.89,505.48,79.32,9.94;8,93.41,518.20,430.80,9.94;8,93.41,530.68,54.56,9.94">Overview of the ImageCLEF 2021: Multimedia Retrieval in Medical, Nature, Internet and Social Media Applications</title>
		<author>
			<persName coords=""><forename type="first">Bogdan</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Renaud</forename><surname>Péteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Asma</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mourad</forename><surname>Sarrouti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sadid</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Serge</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Obioma</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Janadhip</forename><surname>Jacutprakart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christoph</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Raul</forename><surname>Berari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrei</forename><surname>Tauteanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dimitri</forename><surname>Fichou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Brie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liviu</forename><surname>Daniel Ştefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Gabriel Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jon</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hassan</forename><surname>Moustahfid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jérôme</forename><surname>Deshayes-Chossart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,177.19,530.68,342.84,9.94;8,93.41,543.43,426.08,9.94">Proceedings of the 12th International Conference of the CLEF Association (CLEF 2021)</title>
		<title level="s" coord="8,186.79,556.15,221.71,9.94">Springer Lecture Notes in Computer Science LNCS</title>
		<meeting>the 12th International Conference of the CLEF Association (CLEF 2021)<address><addrLine>Bucharest, Romania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">September 21-24, 2021</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="8,93.41,568.63,429.92,9.94;8,93.41,581.24,429.90,10.05;8,93.41,594.07,189.51,9.94" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="8,216.80,581.24,239.02,10.04">YFCC100M: The New Data in Multimedia Research</title>
		<author>
			<persName coords=""><forename type="first">Bart</forename><surname>Thomee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">A</forename><surname>Shamma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gerald</forename><surname>Friedland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><surname>Elizalde</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karl</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><surname>Poland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Damian</forename><surname>Borth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.1503.01817</idno>
		<ptr target="https://doi.org/10.48550/arXiv.1503.01817" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.41,606.55,40.66,9.94;8,149.57,606.55,9.24,9.94;8,174.31,606.55,37.14,9.94;8,226.90,606.55,34.40,9.94;8,276.58,606.55,38.50,9.94;8,330.36,606.55,39.59,9.94;8,385.34,606.55,13.80,9.94;8,414.65,606.55,22.08,9.94;8,451.85,606.55,32.04,9.94;8,499.39,606.55,24.93,9.94;8,93.41,619.03,186.64,9.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,174.31,606.55,37.14,9.94;8,226.90,606.55,30.10,9.94">Random Forests</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<idno type="DOI">10.1023/A:1010933404324</idno>
		<ptr target="https://doi.org/10.1023/A:1010933404324" />
	</analytic>
	<monogr>
		<title level="j" coord="8,276.58,606.55,38.50,9.94;8,330.36,606.55,39.59,9.94">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.41,631.77,430.54,9.94;8,93.41,644.49,430.28,9.94;8,93.41,657.21,39.48,9.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,255.40,631.77,178.79,9.94">Xgboost: A scalable tree boosting system</title>
		<author>
			<persName coords=""><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,458.09,631.77,65.86,9.94;8,93.41,644.49,389.62,9.94">Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining</title>
		<meeting>the 22nd acm sigkdd international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.41,669.69,25.54,9.94;8,140.69,669.69,39.95,9.94;8,202.63,669.69,37.38,9.94;8,261.94,669.69,27.28,9.94;8,311.16,669.69,51.70,9.94;8,384.62,669.69,37.38,9.94;8,443.69,669.69,33.22,9.94;8,498.91,669.69,24.90,9.94;8,93.41,682.41,290.51,9.94" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,202.63,669.69,37.38,9.94;8,261.94,669.69,27.28,9.94;8,311.16,669.69,47.00,9.94">Random Forest Regression</title>
		<author>
			<persName coords=""><forename type="first">Afroz</forename><surname>Chakure</surname></persName>
		</author>
		<ptr target="https://miro.medium.com/max/1400/0*f_qQPFpdofWGLQqc.png" />
	</analytic>
	<monogr>
		<title level="j" coord="8,384.62,669.69,37.38,9.94;8,443.69,669.69,29.07,9.94">Medium Article</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.41,695.02,429.27,10.05;8,93.41,707.61,280.63,9.94" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kirch</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4020-5614-7_2569</idno>
		<ptr target="https://doi.org/10.1007/978-1-4020-5614-7_2569" />
		<title level="m" coord="8,138.04,695.02,288.65,10.04">Pearson&apos;s Correlation Coefficient. Encyclopedia of Public Health</title>
		<meeting><address><addrLine>Dordrecht</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.41,720.25,430.39,10.04;8,93.41,732.97,369.78,10.05" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="8,292.47,720.25,231.33,10.04;8,93.41,732.97,111.03,10.05">Grid Search, Random Search, Genetic Algorithm: A Big Comparison for NAS</title>
		<author>
			<persName coords=""><forename type="first">Petro</forename><surname>Liashchynskyi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pavlo</forename><surname>Liashchynskyi</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.1912.06059</idno>
		<ptr target="https://doi.org/10.48550/arXiv.1912.06059" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,93.41,73.60,431.27,9.94;9,93.41,86.32,431.02,9.94;9,93.41,99.04,430.88,9.94;9,93.41,111.41,431.04,10.05;9,93.41,124.27,431.04,9.94;9,93.41,136.99,430.46,9.94;9,93.41,149.47,430.86,9.94;9,93.41,162.19,430.65,9.94;9,93.41,174.91,197.45,9.94" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,396.62,124.27,127.83,9.94;9,93.41,136.99,351.24,9.94">Overview of the ImageCLEF 2022: Multimedia Retrieval in Medical, Social Media and Nature Applications</title>
		<author>
			<persName coords=""><forename type="first">Bogdan</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Renaud</forename><surname>Péteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Johannes</forename><surname>Rückert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Asma</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christoph</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Louise</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Raphael</forename><surname>Brüngel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ahmad</forename><surname>Idrissi-Yaghir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Serge</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liviu-Daniel</forename><surname>Ștefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Gabriel Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jérôme</forename><surname>Deshayes-Chossart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jon</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,464.66,136.99,59.21,9.94;9,93.41,149.47,430.86,9.94;9,93.41,162.19,197.79,9.94">Proceedings of the 13th International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="9,325.36,162.19,198.70,9.94;9,93.41,174.91,24.84,9.94">Springer Lecture Notes in Computer Science LNCS</title>
		<meeting>the 13th International Conference of the CLEF Association (CLEF<address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022-09-05">2022. September 5-8, 2022</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="9,93.41,191.47,430.90,9.94;9,93.41,203.97,430.68,9.94;9,93.41,216.69,431.00,9.94;9,93.41,229.41,430.66,9.94;9,93.41,242.13,94.91,9.94" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,93.41,203.97,430.68,9.94;9,93.41,216.69,136.97,9.94">Overview of the ImageCLEF 2022 Aware Task in Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jérôme</forename><surname>Deshayes-Chossart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bogdan</forename><surname>Ionescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,238.99,216.69,285.41,9.94;9,93.41,229.41,86.24,9.94">Proceedings of the 13th International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="9,215.58,229.41,187.94,9.94">Lecture Notes in Computer Science LNCS</title>
		<meeting>the 13th International Conference of the CLEF Association (CLEF<address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022-09-05">2022. September 5-8, 2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
