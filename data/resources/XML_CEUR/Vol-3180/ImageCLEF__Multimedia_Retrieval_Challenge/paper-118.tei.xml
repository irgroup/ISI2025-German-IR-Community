<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.69,84.74,417.24,15.42;1,89.29,106.66,272.61,15.42">A Late Fusion Framework with Multiple Optimization Methods for Media Interestingness</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,71.60,11.96"><forename type="first">Maria</forename><surname>Shoukat</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Systems Engineering</orgName>
								<orgName type="institution">University of Engineering and Technology</orgName>
								<address>
									<settlement>Peshawar</settlement>
									<country key="PK">Pakistan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,173.54,134.97,79.57,11.96"><forename type="first">Khubaib</forename><surname>Ahmad</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Systems Engineering</orgName>
								<orgName type="institution">University of Engineering and Technology</orgName>
								<address>
									<settlement>Peshawar</settlement>
									<country key="PK">Pakistan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,265.75,134.97,52.54,11.96"><forename type="first">Naina</forename><surname>Said</surname></persName>
							<email>nainasaid@uetpeshawar.edu.pk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Systems Engineering</orgName>
								<orgName type="institution">University of Engineering and Technology</orgName>
								<address>
									<settlement>Peshawar</settlement>
									<country key="PK">Pakistan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,330.94,134.97,64.86,11.96"><forename type="first">Nasir</forename><surname>Ahmad</surname></persName>
							<email>n.ahmad@uetpeshawar.edu.pk</email>
						</author>
						<author>
							<persName coords="1,89.29,148.92,135.44,11.96"><forename type="first">Mohammed</forename><surname>Hasanuzzaman</surname></persName>
							<email>mohammed.hasanuzzaman@mtu.ie</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Systems Engineering</orgName>
								<orgName type="institution">University of Engineering and Technology</orgName>
								<address>
									<settlement>Peshawar</settlement>
									<country key="PK">Pakistan</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Munster Technological University</orgName>
								<address>
									<settlement>Cork</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,255.73,148.92,69.63,11.96"><forename type="first">Kashif</forename><surname>Ahmad</surname></persName>
							<email>kashif.ahmad@mtu.ie</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Munster Technological University</orgName>
								<address>
									<settlement>Cork</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.69,84.74,417.24,15.42;1,89.29,106.66,272.61,15.42">A Late Fusion Framework with Multiple Optimization Methods for Media Interestingness</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">2307423F921C13869BCB826FA03C76CE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Media Interestingness</term>
					<term>Late Fusion</term>
					<term>PSO</term>
					<term>Genetic Algorithms</term>
					<term>Nelder Mead</term>
					<term>Trust Region Contrainted optimization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The recent advancement in Multimedia Analytical, Computer Vision (CV), and Artificial Intelligence (AI) algorithms resulted in several interesting tools allowing an automatic analysis and retrieval of multimedia content of users' interests. However, retrieving the content of interest generally involves analysis and extraction of semantic features, such as emotions and interestingness-level. The extraction of such meaningful information is a complex task and generally, the performance of individual algorithms is very low. One way to enhance the performance of the individual algorithms is to combine the predictive capabilities of multiple algorithms using fusion schemes. This allows the individual algorithms to complement each other, leading to improved performance. This paper proposes several fusion methods for the media interestingness score prediction task introduced in CLEF Fusion 2022. The proposed methods include both a naive fusion scheme, where all the inducers are treated equally and a merit-based fusion scheme where multiple weight optimization methods are employed to assign weights to the individual inducers. In total, we used six optimization methods including a Particle Swarm Optimization (PSO), a Genetic Algorithm (GA), Nelder-Mead, Trust Region Constrained (TRC), and Limited-memory Broyden-Fletcher-Goldfarb-Shanno Algorithm (LBFGSA), and Truncated Newton Algorithm (TNA). Overall better results are obtained with PSO and TNA achieving 0.109 mean average precision @10. The task is complex and generally, scores are low. We believe the presented analysis will provide a baseline for future research in the domain.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In the modern world, thanks to social media and other multimedia content sharing platforms, we have access to a huge amount of multimedia content. However, accessing multimedia content of interest generally involves processing, analyzing, and filtering a huge amount of data. Filtering and retrieval of multimedia content of interest require specialized tools to analyze and extract semantic features/meanings from the content <ref type="bibr" coords="1,294.15,570.27,11.43,10.91" target="#b0">[1]</ref>.</p><p>Thanks to the recent development in Multimedia Analytics, Computer Vision (CV) and Artificial Intelligence (AI) techniques, different semantic notions, such as sentiments <ref type="bibr" coords="2,432.31,100.52,11.28,10.91" target="#b1">[2]</ref>, emotions <ref type="bibr" coords="2,492.15,100.52,11.28,10.91" target="#b2">[3]</ref>, and interestingness-level <ref type="bibr" coords="2,203.72,114.06,11.49,10.91" target="#b3">[4]</ref>, can be extracted from multimedia content. More recently, Deep Neural Networks (DNNs) have shown tremendous predictive capabilities in various multimedia content analysis tasks. Despite the proven performances, there are several tasks where a single Neural Network is not enough to accurately extract meaningful insights precisely. In order to increase the performance of individual models, researchers have been exploring the so called "fusion" techniques allowing multiple models to complement each others in such complex tasks <ref type="bibr" coords="2,114.49,195.36,11.41,10.91" target="#b4">[5]</ref>. The fusion techniques allow to combine multiple models to achieve higher accuracy compared to the individual models. Two popular methods to combine these models are the early fusion and late fusion techniques. In early fusion, the separate raw data is integrated into a unified representation before the learning process. On the other hand, in case of late fusion, fusion is performed at the decision level i.e, the output of different predictors is combined after the learning process to create a new and improved super predictor. The literature has reported the effectiveness of fusion technique in several applications, such as natural disasters analysis <ref type="bibr" coords="2,89.29,290.20,11.43,10.91" target="#b5">[6]</ref>, event recognition <ref type="bibr" coords="2,188.31,290.20,11.43,10.91" target="#b4">[5]</ref>, data analytics <ref type="bibr" coords="2,270.38,290.20,11.43,10.91" target="#b6">[7]</ref>.</p><p>This paper is based on one of the tasks in ImageCLEF 2022 <ref type="bibr" coords="2,383.18,303.75,11.58,10.91" target="#b7">[8]</ref>, which is a benchmark competition for image retrieval tasks. This year ImageCLEF proposes four different tasks. However, the work is based on Image Interestingness CLEFfusion 2022 task <ref type="bibr" coords="2,444.79,330.85,11.58,10.91" target="#b8">[9]</ref>. This is a regression task that aims at the prediction of image interestingness score. The task mainly focuses on the fusion of different inducers, whose scores are already provided, to jointly predict the interestingness of visual content. In this work, we propose both a naive fusion, where all inducers are assigned equal weights, and merit-based fusion techniques with optimized weights to combine the scores of the individual inducers for better prediction. For the merit-based fusion, we employ five different techniques to assign weights to the 29 inducers provided in the dataset by the organizers. These methods include evolutionary algorithms, namely Particle Swarm Optimization (PSO) and a Genetic algorithm (GA) based methods, Trust Region Constrained Optimization, Limited-memory Broyden-Fletcher-Goldfarb-Shann (LMBFGS) method, and Truncated Newton Algorithm (TNA) method.</p><p>The rest of the paper is organized as follows : Section 2 presents the overview of the related literature. Section 3.2 gives details about different fusion techniques that have been used in this research work. Section 4 provides the experimental results. Finally, Section 5 concludes the work and outlines the future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Media interestingness prediction, which involves an automatic analysis of multimedia content for the identification of relevant content of users' interest, got great attention from the community over the last few years <ref type="bibr" coords="2,251.24,606.27,16.42,10.91" target="#b9">[10]</ref>. It plays a vital role in several applications, such as image retrieval and recommendation and media summarization, etc. In the literature, the topic has been analyzed from two different perspectives including psychological and computational aspects of media interestingness <ref type="bibr" coords="2,233.56,646.91,16.12,10.91" target="#b9">[10]</ref>. The first part mainly focuses on psychological studies involving theoretical analysis and reports on human emotions, choices, and interests. For instance, Silvia et al. <ref type="bibr" coords="3,140.22,86.97,17.77,10.91" target="#b10">[11]</ref> linked interestingness level with emotions by providing a detailed analysis and overview of some unusual aesthetic emotions. The computational methods on the other hand involve multimedia analytics, CV, and ML techniques to analyze and extract semantic features from multimedia content for the prediction of interestingness level <ref type="bibr" coords="3,396.66,127.61,16.41,10.91" target="#b11">[12]</ref>. Extensive research exploring different aspects of the topic has been carried out in this direction. For instance, Liu et al. <ref type="bibr" coords="3,113.51,154.71,17.80,10.91" target="#b12">[13]</ref> analyzed the importance of feature extraction for the task by proposing a multi-view manifold learning framework. To this aim, the authors mapped multi-view data to a single common space by considering cross-view correlation to preserve the geometric structure and interestingness information. Wang et al. <ref type="bibr" coords="3,272.27,195.36,17.95,10.91" target="#b13">[14]</ref> discussed other two important aspects of media interestingness namely comparison information, and evaluation metric optimization. Despite sufficient improvement, the performance of most of the algorithms is not good as compared to other computer vision tasks.</p><p>As part of the efforts to improve the performances of media interestingness frameworks, a vast majority of the recent works rely on multiple models. To this aim, different fusion techniques have been incorporated to jointly employ multiple models for the task. For instance, Constantin et al. <ref type="bibr" coords="3,166.22,290.20,17.95,10.91" target="#b11">[12]</ref> proposed a deep fusion ensemble framework by exploring the potential of several deep networks including dense, attention, convolutional, and cross-space-fusion networks. Similarly, Almedia et al. <ref type="bibr" coords="3,245.78,317.30,17.89,10.91" target="#b14">[15]</ref> proposed a late fusion framework employing multiple ranking models trained on multimodal features for media interestingness score prediction.</p><p>In this work, we explore the potential of merit-based fusion by combining the predictions of several inducers using different weight optimization methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>Figure <ref type="figure" coords="3,118.89,416.58,4.97,10.91" target="#fig_0">1</ref> provides the block diagram of the methodology adopted in this work. There are two main components of the methodology, namely (i) prediction by individual inducers, and (ii) fusion of the score obtained with the individual inducers for joint prediction. Our contribution mainly lies in the fusion part, where we employed several weight selection/optimization techniques to assign weights to the inducers. The scores of the individual inducers are already provided by the task organizers. In the next subsections, we provide a detailed description of all the methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Inducer Scores and Pre-processing</head><p>The inducers' scores are provided by the task organizers. In total, the task organizers provided prediction scores of 29 inducers. For the majority of the inducers, the prediction scores were floating numbers between 0 and 1. However, the interestingness scores for some of the inducers were out of range. To combine the scores of the inducers properly, all the values should be in the same range. To this aim, before combing the scores in a late fusion, we normalized the inducers' scores to bring them to the same range.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Fusion Techniques</head><p>In this work, we mainly focused on late fusion techniques where we tried several weight optimization methods to obtain a combination of weights that provides highest interestingness score. To this aim, we picked several methods with proven performances in similar applications <ref type="bibr" coords="4,89.29,449.71,16.56,10.91" target="#b15">[16,</ref><ref type="bibr" coords="4,109.48,449.71,7.65,10.91" target="#b4">5]</ref>. As a baseline, we also considered a naive fusion method where equal weights are assigned to the inducers. Our late fusion method is represented by Equation 3.2.</p><formula xml:id="formula_0" coords="4,198.39,490.35,307.59,11.36">ùëÜ ùëê = ùëä 1 ùëÜ 1 + ùëä 2 ùëÜ 2 + ùëä 3 ùëÜ 3 + .... + ùëä ùëõ ùëÜ ùëõ<label>(1)</label></formula><p>In the equation, ùëÜ ùëê represents the combined interestingness score of different inducers, ùëÜ ùëõ is the score of the nth model and ùëä ùëõ is the corresponding weight used during the fusion. In our case, n=29. For the baseline, the weight ùëä for all the inducers is the same i.e., ùëä 1 = ùëä 2 = ùëä 3 .... = ùëä ùëõ . In case of merit based fusion, optimal weights are assigned to each individual inducer. In the next section, we provide the details of these optimization methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Genetic Algorithm</head><p>Our choice of Genetic Algorithm (GA) is based on our previous experience in similar applications <ref type="bibr" coords="4,89.29,627.45,16.56,10.91" target="#b15">[16,</ref><ref type="bibr" coords="4,109.56,627.45,12.59,10.91" target="#b16">17,</ref><ref type="bibr" coords="4,125.86,627.45,7.65,10.91" target="#b4">5]</ref>. GA, which is a meta-heuristic algorithm, is inspired by the natural evaluation process. In the natural evolution process, the fittest individuals of the current generation are firstly identified and then used for re-production in the next generation. A similar approach is adopted in GA-based optimization, where the algorithm searches for optimal value/set of values minimizing a given function also called fitness function. To this aim, GA requires a training procedure to determine optimal values. The process starts with a randomly selected generation of the population (i.e., a set of values). The fitness of every individual in the current population is evaluated using the fitness function after which individuals are selected for the next generation with a modified genome. The process is repeated until either the maximum number of generations is reached or a respectable fitness value is achieved.</p><p>In this work, since we are dealing with a regression problem, the fitness function is based on Mean Squared Error (MSE) as shown in equation 2. Moreover, each possible combination (i.e., set of weights assigned to the 29 inducers) is a potential solution. The goal is to find the set of weights with minimum MSE.</p><formula xml:id="formula_1" coords="5,237.47,231.33,268.52,26.30">ùëÄ ùëÜùê∏ = 1 ùëõ Œ£ ùëõ ùëñ=1 (ùë¶ ùëù -ùë¶ ùëé ) 2<label>(2)</label></formula><p>In the above equation, ùë¶ ùëù represents the predicted interestingness score while ùë¶ ùëé is the ground truth. For the implementation we used a python open source library, namely geneticalgorithm <ref type="foot" coords="5,501.11,274.25,3.71,7.97" target="#foot_0">1</ref> . As we have a total of 29 inducers so we kept the dimensions to 29. Moreover, we used 'real' for the variable type and the variable boundary fixed between 0 and 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Particle Swarm Optimzation</head><p>The second weight optimization/selection method employed in this work is based on PSO <ref type="bibr" coords="5,487.45,352.43,16.17,10.91" target="#b17">[18]</ref>. The optimization method is inspired by the flocking of birds. Unlike GA, PSO does not use mutation and crossover operations rather aims at an improvement to a candidate solution according to a pre-defined criterion, iteratively. There are three main steps involved in the process. These include an (i) evaluation of each candidate solution on the basis of fitness criteria, (ii) updates in personal best and global best values and finally (iii) updating the position and velocity of each particle.</p><p>In our case, each combination of the weights (i.e, 29 values to be assigned to the inducers) is a candidate solution. Moreover, the fitness function is based on MSE as shown in 2. For the implementation of the method, we used open source library namely pyswarm<ref type="foot" coords="5,463.14,472.62,3.71,7.97" target="#foot_1">2</ref> . As this algorithm support bounds like GA, we set the lower bound to 0 and the upper bound to be 1. Moreover, the maximum iterations hyperparameter is set to 10000 and the swarm size is kept at 300.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Nelder Mead Algorithm</head><p>Nelder Mead algorithm is a heuristic optimization technique and is appropriate for optimization problems where the gradient of the function is either unknown or cannot be reasonably computed. The algorithm can be used for both one dimensional and multi-dimensional optimization problems <ref type="bibr" coords="5,132.12,605.00,16.09,10.91" target="#b18">[19]</ref>. The algorithm starts with randomly generated simplex with number of vertices= ùëõ+1 points for an n-dimensional optimization problem. At every iteration, the algorithm moves the simplex one vertex at a time towards an optimal region in the search space with a goal to minimize/maximize a certain objective function. At the end, the vertex of the simplex that yields that most optimal values is returned. For our experiments, ùëõ = 29 and the objective function definition is the same as in 2. For the implementation of the method, we used a Python open source library, namely, SciPy<ref type="foot" coords="6,220.26,125.86,3.71,7.97" target="#foot_2">3</ref> . We set the value of absolute error in xopt between iterations that is acceptable for convergence to 1e-8 and the maximum iterations to 10000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4.">Trust Region Constrained Optimization Algorithm</head><p>Trust Region Constrained method belongs to the family of optimization methods that are based on trust regions. Trust regions-based methods solve optimization problems by defining a region around their current best solutions, where they can approximate the fitness function up to a certain extent. The methods then take a step forward within the region. In contrast to line-based solutions, the step size is determined beforehand of the improvement in the direction. At this stage, the model is considered to be a good representation of the original objective function if a significant decrease in the objective function is observed.</p><p>In this work, for the implementation of the method we used scipy library <ref type="foot" coords="6,419.97,283.58,3.71,7.97" target="#foot_3">4</ref> . The Trust Region Constrained algorithm requires initial weight values so for all the 29 inducers same value of 0.0345 is used. For the bounds, we used a lower bound of 0 and upper bound of 1. Moreover, we set the maximum iterations to 10000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.5.">Limited-memory Broyden-Fletcher-Goldfarb-Shanno Algorithm</head><p>The Broyden, Fletcher, Goldfarb, and Shanno, or BFGS Algorithm, is a local search optimization algorithm. It falls under the category of a Quasi-Newton optimization methods which deal with the optimization of second order derivative of the objective function. These type of algorithms are suitable for optimization problems where the second order derivatives can not be reasonably quantified. Unlike the first order methods which make use of the first order derivative to find the optimal values of the objective function, these algorithm rely on second order derivatives. For a multivariate function, the second derivatives of all the input variables are maintained in a matrix called Hessian. In order to find the optimal values of the objective function, the BFGS algorithm calculates the inverse of this matrix. This is done by approximating the inverse using gradient thereby eliminating the need for inverse calculation at each step of the algorithm. The size of the Hessian and its inverse is proportional to the number of input parameters to the objective function. For a function with many input parameters, the BFGS then becomes impractical due to very high memory demands. Therefore, a variant of BFGS called Limited BFGS is utilized in this work. This method does not require storing the entire approximation of the inverse matrix.</p><p>The definition of the objective function for our experiments is the same as given in 2. For implementation of the method, we used a Python open source library, namely, SciPy <ref type="foot" coords="6,501.01,590.34,3.71,7.97" target="#foot_4">5</ref> . Similar to Trust Region Constrained Optimization algorithm, the Limited-memory Broyden-Fletcher-Goldfarb-Shanno algorithm also requires initial weight values that are set at 0.0345 for all the 29 inducers. Moreover, the value of absolute error is set to 1e-8 and the maximum iterations to 10000. For the bounds, we set the lower and upper bounds to 0 and 1, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.6.">Truncated Newton Algorithm</head><p>The method is also called Hessian-free optimization algorithm and is more suitable for applications involving a large numbers of independent variables <ref type="bibr" coords="7,350.76,176.94,16.41,10.91" target="#b19">[20]</ref>. The method uses an iterative process to solve the Newton's equation, which involves finding the roots of a differentiable function, for updating the parameters of the cost function. The term "truncated" refers to the fact that the inner solver is run for a limited number of iterations, which means that the algorithm needs to produce good approximation in limited iterations. The definition of the objective function for our experiments is the same as given in 2. For implementation of the method, we used a Python open source library, namely, SciPy. The Truncated Newton algorithm also requires initial weight values, which are set at 0.0345 for all the 29 inducers. Moreover, we set the value of absolute error in xopt between iterations that are acceptable for convergence to 1e-8 and the maximum iterations to 10000. The lower and upper bounds are set at 0 and 1, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Dataset</head><p>The individual inducers' scores, which are provided by the task organizers, are extracted from the Interestingness10k dataset <ref type="bibr" coords="7,230.06,405.58,16.41,10.91" target="#b9">[10]</ref>. In total, prediction scores for 2435 images are provided from 29 inducers, each representing the visual interestingness-level for the images. The dataset is provided in two seperate sets namely (i) development set, and (ii) test set. The development set is composed of the scores from all of the inducers for 1877 images while the test set covers 558 images only. In the development set, each data sample for each inducer provides four values including a video ID, image ID, classification score (0 or 1), and predicted interestingness score by the inducer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experimental Results</head><p>Table <ref type="table" coords="7,114.65,536.60,4.10,10.91">4</ref>.2 provides the official results of the proposed methods in terms of mean average precision at the cutoff 10 (MAP@10). One of the main objectives of the experiments is to evaluate the potential of the different state-of-the-art optimization methods in this application.</p><p>As expected, overall lower results are obtained with the baseline method where all the inducers are treated equally by assigning them equal weights. Though there is no significant, difference in scores obtained between the least performing and the baseline, the merit-based fusion scheme seems more promising compared to simply averaging the individual scores. As far as the performances of the merit-based fusion methods are concerned, overall better results are obtained with PSO and TNC methods. One of the key advantages of TNC is its optimization capabilities in dealing with functions involving independent variables. This could be one of the main reasons for its better performance in the application as all the inducers are treated independently in the task. The highest score obtained in this work is 0.109 MAP@10, which indicates the complexity of the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions and Future Work</head><p>In this paper, we presented the experimental results of multiple fusion techniques for the media interestingness task presented in CLEF Fusion 2022. We used both a naive fusion scheme and merit-based fusion methods. Overll the results are much lower on the task compared to other computer vision tasks, which shows the complexity of the task. During the experiments, we observed better results for a merit-based fusion scheme where different weight optimization techniques are employed to assign weights to the individual inducers based on their performances. This verifies our assumption that individual performance should be considered in combining the prediction scores of the individual inducers.</p><p>In the future, we want to further explore different aspects of the application to further enhance the results. One potential direction could be an intelligent selection among the inducers instead of considering all of them.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,89.29,398.55,226.79,8.93"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Block diagram of the proposed methodology.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="8,88.99,90.49,338.31,123.44"><head>Table 1</head><label>1</label><figDesc>Experimental results in terms of mean average precision at the cutoff 10 MAP@10.</figDesc><table coords="8,208.18,118.53,178.91,95.40"><row><cell>Fusion Method</cell><cell>MAP@10</cell></row><row><cell>Equal Weights</cell><cell>0.081</cell></row><row><cell>Trust-Constr weighted Fusion</cell><cell>0.095</cell></row><row><cell>PSO weighted Fusion</cell><cell>0.109</cell></row><row><cell>GA weighted Fusion</cell><cell>0.093</cell></row><row><cell>LBFGSB weighted Fusion</cell><cell>0.095</cell></row><row><cell>Nelder Mead weighted Fusion</cell><cell>0.090</cell></row><row><cell>TNC weighted Fusion</cell><cell>0.109</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,108.93,660.07,153.89,8.97"><p>https://pypi.org/project/geneticalgorithm/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,108.93,671.03,156.14,8.97"><p>https://pyswarms.readthedocs.io/en/latest/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="6,108.93,649.10,62.20,8.97"><p>https://scipy.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="6,108.93,660.06,62.20,8.97"><p>https://scipy.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="6,108.93,671.02,62.20,8.97"><p>https://scipy.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,518.12,394.52,10.91;8,112.66,531.67,393.33,10.91;8,112.66,545.21,224.37,10.91" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="8,112.66,531.67,393.33,10.91;8,112.66,545.21,93.44,10.91">Predicting interestingness of visual content, in: Visual content indexing and retrieval with psycho-visual models</title>
		<author>
			<persName coords=""><forename type="first">C.-H</forename><surname>Demarty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sj√∂berg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">Q</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T.-T</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="233" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,558.76,393.33,10.91;8,112.66,572.31,355.71,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,478.51,558.76,27.48,10.91;8,112.66,572.31,244.92,10.91">Visual sentiment analysis from disaster images in social media</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">Z</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Al-Fuqaha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Conci</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,366.42,572.31,34.15,10.91">Sensors</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">3628</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,585.86,393.33,10.91;8,112.66,599.41,363.51,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,275.25,585.86,230.74,10.91;8,112.66,599.41,131.66,10.91">Exploring the contextual factors affecting multimodal emotion recognition in videos</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">K</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,252.68,599.41,191.57,10.91">IEEE Transactions on Affective Computing</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,612.96,394.53,10.91;8,112.66,626.51,393.33,10.91;8,112.66,640.06,200.61,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,283.15,626.51,222.84,10.91;8,112.66,640.06,56.91,10.91">An annotated video dataset for computing video memorability</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>Kiziltepe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Sweeney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Doctor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-H</forename><surname>Demarty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F</forename><surname>Smeaton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,178.23,640.06,57.08,10.91">Data in Brief</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page">107671</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,653.61,393.53,10.91;9,112.66,86.97,393.33,10.91;9,112.28,100.52,166.83,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,380.27,653.61,125.92,10.91;9,112.66,86.97,76.49,10.91">Ensemble of deep models for event recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Mekhalfi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Conci</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Melgani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">D</forename><surname>Natale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,197.60,86.97,308.38,10.91;9,112.28,100.52,98.12,10.91">ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,114.06,394.53,10.91;9,112.66,127.61,394.53,10.91;9,112.66,141.16,89.38,10.91" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="9,157.02,127.61,341.96,10.91">Deep learning approaches for flood classification and flood aftermath detection</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Said</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Pogorelov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Ostroukhova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Conci</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>MediaEval</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,154.71,394.53,10.91;9,112.28,168.26,394.37,10.91;9,112.41,181.81,65.99,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,156.42,154.71,346.40,10.91">Survey on deep multi-modal data analytics: Collaboration, rivalry, and fusion</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,112.28,168.26,394.37,10.91">ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,195.36,395.01,10.91;9,112.66,208.91,395.17,10.91;9,112.39,222.46,394.80,10.91;9,112.66,236.01,394.62,10.91;9,112.66,249.56,393.33,10.91;9,112.66,263.11,395.17,10.91;9,112.66,276.66,393.54,10.91;9,112.66,290.20,170.14,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,352.50,236.01,154.78,10.91;9,112.66,249.56,311.34,10.91">Overview of the ImageCLEF 2022: Multimedia Retrieval in Medical, Social Media and Nature Applications</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>M√ºller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Peteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>R√ºckert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Br√ºngel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Idrissi-Yaghir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sch√§fer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">D</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L.-D</forename><surname>≈ûtefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Deshayes-Chossart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,446.87,249.56,59.11,10.91;9,112.66,263.11,395.17,10.91;9,112.66,276.66,239.58,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction, Proceedings of the 13th International Conference of the CLEF Association (CLEF 2022)</title>
		<title level="s" coord="9,359.20,276.66,147.00,10.91;9,112.66,290.20,31.10,10.91">LNCS Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,303.75,393.33,10.91;9,112.66,317.30,394.52,10.91;9,112.66,330.85,394.53,10.91;9,112.66,344.40,22.69,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,356.66,303.75,149.33,10.91;9,112.66,317.30,390.45,10.91">Overview of imagecleffusion 2022 task -ensembling methods for media interestingness prediction and result diversification</title>
		<author>
			<persName coords=""><forename type="first">L.-D</forename><surname>≈ûtefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,126.96,330.85,109.80,10.91">CLEF2022 Working Notes</title>
		<title level="s" coord="9,243.94,330.85,171.64,10.91">CEUR Workshop Proceedings, CEUR-WS</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,357.95,393.33,10.91;9,112.66,371.50,393.33,10.91;9,112.48,385.05,222.55,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,478.57,357.95,27.42,10.91;9,112.66,371.50,326.74,10.91">Visual interestingness prediction: A benchmark framework and literature review</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L.-D</forename><surname>≈ûtefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">Q</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-H</forename><surname>Demarty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sj√∂berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,447.87,371.50,58.11,10.91;9,112.48,385.05,123.39,10.91">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="1526" to="1550" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,398.60,393.53,10.91;9,112.66,412.15,395.01,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,165.51,398.60,340.67,10.91;9,112.66,412.15,114.45,10.91">Looking past pleasure: anger, confusion, disgust, pride, surprise, and other unusual aesthetic emotions</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Silvia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,239.82,412.15,216.52,10.91">Psychology of Aesthetics, Creativity, and the Arts</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">48</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,425.70,393.33,10.91;9,112.39,439.25,394.80,10.91;9,112.66,452.79,70.43,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,297.23,425.70,208.76,10.91;9,112.39,439.25,143.35,10.91">Exploring deep fusion ensembling for automatic visual interestingness prediction</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L.-D</forename><surname>≈ûtefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,278.70,439.25,180.86,10.91">Human Perception of Visual Information</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="33" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,466.34,395.17,10.91;9,112.66,479.89,393.32,10.91;9,112.66,493.44,179.52,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,297.31,466.34,210.53,10.91;9,112.66,479.89,93.32,10.91">Multi-view manifold learning for media interestingness prediction</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>-M. Cheung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">A</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,229.04,479.89,276.94,10.91;9,112.66,493.44,92.00,10.91">Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval</title>
		<meeting>the 2017 ACM on International Conference on Multimedia Retrieval</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="308" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,506.99,394.53,10.91;9,112.66,520.54,393.33,10.91;9,112.66,534.09,394.53,10.91;9,112.66,547.64,45.01,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,256.86,506.99,245.45,10.91">Video interestingness prediction based on ranking model</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,127.19,520.54,378.80,10.91;9,112.66,534.09,365.33,10.91">Proceedings of the joint workshop of the 4th workshop on affective social multimedia computing and first multi-modal affective computing of large-scale multimedia data</title>
		<meeting>the joint workshop of the 4th workshop on affective social multimedia computing and first multi-modal affective computing of large-scale multimedia data</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="55" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,561.19,393.33,10.91;9,112.66,574.74,394.53,10.91;9,112.66,588.29,108.11,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,315.26,561.19,190.72,10.91;9,112.66,574.74,111.99,10.91">A rank aggregation framework for video interestingness prediction</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">P</forename><surname>Valem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">C</forename><surname>Pedronette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,247.30,574.74,255.41,10.91">International conference on image analysis and processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,601.84,393.33,10.91;9,112.66,615.39,393.32,10.91;9,112.66,628.93,107.17,10.91" xml:id="b15">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Ayub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Al-Fuqaha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.04462</idno>
		<title level="m" coord="9,421.96,601.84,84.02,10.91;9,112.66,615.39,321.38,10.91">Merit-based fusion of nlp techniques for instant feedback on water quality from twitter text</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,642.48,393.32,10.91;9,112.66,656.03,214.96,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,268.05,642.48,237.93,10.91;9,112.66,656.03,55.98,10.91">Intelligent fusion of deep features for improved waste classification</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Al-Fuqaha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,176.56,656.03,51.91,10.91">IEEE access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="96495" to="96504" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,669.58,395.17,10.91;10,112.66,86.97,367.36,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,232.99,669.58,128.62,10.91">Particle swarm optimization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,392.45,669.58,115.38,10.91;10,112.66,86.97,196.49,10.91">Proceedings of ICNN&apos;95-international conference on neural networks</title>
		<meeting>ICNN&apos;95-international conference on neural networks</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,100.52,318.10,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,200.27,100.52,101.80,10.91">Nelder-mead algorithm</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,310.61,100.52,57.40,10.91">Scholarpedia</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">2928</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,114.06,394.53,10.91;10,112.66,127.61,55.16,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="10,189.66,114.06,188.09,10.91">Deep learning via hessian-free optimization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,404.72,114.06,21.73,10.91">ICML</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="735" to="742" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
