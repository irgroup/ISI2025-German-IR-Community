<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,344.88,15.42;1,89.29,106.66,303.39,15.42">Ensembled Approach for Web Search Result Diversification Using Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,69.29,11.96"><forename type="first">Shreya</forename><surname>Sriram</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,171.23,134.97,106.15,11.96"><forename type="first">Madhuri</forename><surname>Mahalingam</surname></persName>
							<email>madhuri19057@cse.ssn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,290.02,134.97,102.24,11.96"><forename type="first">Sarah</forename><forename type="middle">Aymen</forename><surname>Naseer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,404.91,134.97,77.92,11.96"><forename type="first">Shajith</forename><surname>Hameed</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,148.92,91.37,11.96"><forename type="first">Rahul</forename><surname>Rajagopalan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,193.31,148.92,69.81,11.96"><forename type="first">Sai</forename><surname>Shashaank</surname></persName>
							<email>saishashaank2010084@ssn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,285.77,148.92,97.94,11.96"><forename type="first">Lekshmi</forename><surname>Kalinathan</surname></persName>
							<email>lekshmik@ssn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,162.87,127.97,11.96"><forename type="first">Prabavathy</forename><surname>Balasundaram</surname></persName>
							<email>prabavathyb@ssn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,344.88,15.42;1,89.29,106.66,303.39,15.42">Ensembled Approach for Web Search Result Diversification Using Neural Networks</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">945F4BF43590626E85CED4BAAE8ED328</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Result diversification</term>
					<term>Ensembling methods</term>
					<term>Grid Search</term>
					<term>Voting Regressor</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Result diversification provides a broader view of a topic, while maximizing the chances of retrieving relevant information. It avoids the bias in results, thus improving the user experience. This area finds a lot of applications in web searches and recommendation systems. The existing literature on this domain has achieved good accuracy on smaller datasets and using single models. An ensemble approach, using three neural network models, has been proposed to improve the existing predictions using a bigger dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Diversification of results is one of the most important trends in the areas of web searches, recommendation systems and structured databases. With the development of image resources in searches, retrieving diverse and relevant results for a query has become a challenging task. This is due to the requirement that the retrieved images should satisfy various semantic intents of the queries, based on the visual attributes and features of an image. Context information, such as captions, descriptions, and tags, provides opportunities for image retrieval systems to improve their result diversification. <ref type="bibr" coords="1,249.86,466.85,12.84,10.91" target="#b7">[8]</ref> The objective of result diversification is to provide user satisfaction, improve productivity, reduce bias or homogeneity in results and to be able to cater to alternate interpretations of a query. Diversification is relevant in image retrieval since it avoids retrieval of superficial results, it provides multifaceted results for a query. eg: If a user searches for pictures of cars, the system needs to retrieve images of different kinds of cars, taken at different locations and time of the day from various angles. Result diversification also guesses the intent of the query and obtains satisfactory results, for ambiguous and incomplete queries. <ref type="bibr" coords="1,354.62,561.70,12.84,10.91" target="#b8">[9]</ref> There are existing methods that use late fusion systems as shown in Table <ref type="table" coords="1,433.79,575.25,3.75,10.91" target="#tab_0">1</ref>. The approach  <ref type="bibr" coords="2,205.49,211.27,11.83,8.87" target="#b6">[7]</ref> Linear Fusion F1 score: 0.3987</p><p>taken in <ref type="bibr" coords="2,128.26,246.84,12.81,10.91" target="#b2">[3]</ref> uses Deep Neural Networks architectures as the primary ensembling learner with various network configurations that use dense and attention layers. Cross-Space-Fusion layer has been used here to manipulate the newly created spatial information. When compared with the current state of the art and traditional ensembling approaches, the proposed model showed significant improvements, by a margin of at least 38.58%. Search result diversification of text documents is necessary when a user issues an ambiguous query to the search engine. Such ambiguous queries require a diversified resultant list that includes documents that are relevant to as many different types of subtopics as possible. A group of fusion-based result diversification methods with novel methods of weight assignment for linear combination is proposed in <ref type="bibr" coords="2,261.91,368.78,11.58,10.91" target="#b6">[7]</ref>. This aims to improve performance that considers both relevance and diversity. The study <ref type="bibr" coords="2,279.17,382.33,13.00,10.91" target="#b5">[6]</ref> uses data fusion for result diversification and it investigates how to use differential evolution to learn weights for the linear combination method.</p><p>The latest developments in this field, using deep neural networks as the primary ensembling method has shown major improvements over the traditional ensembling methods by increasing the performance of the individual inducers <ref type="bibr" coords="2,277.99,450.08,11.23,10.91" target="#b2">[3,</ref><ref type="bibr" coords="2,291.77,450.08,7.42,10.91" target="#b3">4,</ref><ref type="bibr" coords="2,301.75,450.08,7.49,10.91" target="#b4">5]</ref>. The existing methods work more efficiently only under certain conditions therefore, it is of vital importance to come up with new computer vision and deep learning methods that can enable achieving diverse and appropriate search results for all kinds of data. In this context ImageCLEF <ref type="bibr" coords="2,343.82,490.73,11.58,10.91" target="#b0">[1]</ref>, a benchmarking activity on the cross-language annotation and retrieval of images in the Conference and Labs of the Evaluation Forum (CLEF) has proposed the ImageCLEFfusion task <ref type="bibr" coords="2,336.02,517.83,11.43,10.91" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Task and Dataset Description</head><p>Result diversification fusion task <ref type="bibr" coords="2,245.51,576.45,13.00,10.91" target="#b1">[2]</ref> aims to maximise the chances of retrieving relevant answers that correspond to the query. In the context of image retrieval, an inducer is generally responsible for retrieving a set of relevant images for the given query id. Output of the inducer consists of the relevant images, their similarity scores and ranks. However, a single inducer is disadvantageous for application in certain areas due to low precision and lack of performance. Hence, this task involves the use of ensembling to overcome this scenario. Ensembling is a technique which aggregates the predictions of several inducers.</p><p>The training data is fed into three or more models and their predictions are then combined to obtain a final prediction using a fusion algorithm (ensembling). The ensembled system is expected to yield a better performance compared to the highest performing individual inducer.</p><p>The data for this task is obtained from the Retrieving Diverse Social Images Task dataset [Ionescu2020]. The outputs of 56 inducers, representing a total of 123 queries (topics) are stored in separate text files. Each entry or row in these files is of the format as given below in the Table <ref type="table" coords="3,115.79,181.81,3.74,10.91" target="#tab_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodologies Used</head><p>Different networks namely, Multilayer Perceptron, Ridge Regressor using Grid Search and Keras Regressor using Sequential model were studied to learn the patterns of the outputs of the inducers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Multilayer Perceptron Regressor</head><p>Neural networks are mathematical structures that are formed with a neuron as the fundamental element. Artificial neurons are arranged in layers and coupled to build neural networks. Multi Layer Perceptron (MLP) network is the composition of neurons as shown in Figure <ref type="figure" coords="3,469.73,494.04,3.81,10.91" target="#fig_0">1</ref>. It is a feed forward neural network made up of successive layers that communicate and exchange information via synaptic connections represented by an adaptive weight. The structure of a multilayer network includes multiple layers of perceptrons. The input layer has number of perceptions same as the number of data attributes, an output layer with one perceptron in the case of regression, and all other layers are considered to be hidden. The information flows unidirectionally, from input layer to output layer, through the hidden layers. The hidden layers are the computation engine of the MLP. The weight adjustment training is done via backpropagation. In this method, an error is calculated when the network output is compared to the expected output. The error is then propagated back through the network, one layer at a time, and the weights are modified based on their contribution to the error. Backpropagation is a method of repeatedly adjusting the weights in order to minimize the difference between the actual and desired output. In the regression scenario, activation function will not be applied for the output of the dense layer. Hence, this output will serve as the predicted one. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Ridge Regressor using Grid Search method</head><p>The Ridge regression model is a linear regression model upon which Grid Search is applied to find the hyperparameters. Grid search is a parameter tuning method in which a model is built and evaluated for each set of algorithm parameters specified in a grid. The method calculates the performance of all combinations of the specified hyperparameters and their values and gives the best option. Hyperparameters are the values that are manually set before training. If these are set appropriately then the performance of the model can be improved. To minimize the overfitting with the ordinary Grid search, stratified cross-validation is applied where samples are divided into K-folds at random. An iterative approach is used to divide the training data into k parts. In each iteration, one division is kept for testing, and the remaining k-1 partitions are used to train the model. In the next iteration, the next partition is the test data and the remaining k-1 is the train data. The model performance is recorded and average of results is provided. The advantage of this method is that it gives less biased results compared to testtrain split. The GridSearchCV model from Scikit Learn<ref type="foot" coords="4,339.71,554.45,3.71,7.97" target="#foot_0">1</ref> is used to get the parameters. Grid Search is easy to implement and is reliable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Keras Regressor using Sequential Model</head><p>Regression is implemented using the KerasRegressor 2 class in Keras, which is applied over a Sequential model . A sequential model is a linear stack of layers, where each of the layers is a neural network layer with exactly one input vector of n-dimensions and an output vector of n-dimensions. These vectors of n-dimensions are also called tensors or n-dimension matrices. The sequential model consists of an input, multiple hidden and output dense layers as shown in Figure <ref type="figure" coords="5,121.08,127.61,3.81,10.91" target="#fig_1">2</ref>. A dense layer is a regular deeply connected neural network layer that on an input returns or outputs the activated sum of the dot product of the inputs with the kernels or weights and the bias.</p><formula xml:id="formula_0" coords="5,184.64,180.95,226.00,9.57">𝑜𝑢𝑡𝑝𝑢𝑡 = 𝑎𝑐𝑡𝑖𝑣𝑎𝑡𝑖𝑜𝑛(𝑑𝑜𝑡(𝑖𝑛𝑝𝑢𝑡, 𝑤𝑒𝑖𝑔ℎ𝑡) + 𝑏𝑖𝑎𝑠),</formula><p>The dense layer comprises of neurons or input nodes that are activated based on an activation function. An activation function decides if a neuron or node should be activated or not. The activation function is responsible for transforming the summed weighted input from the node into the activation of the node or output for that input at each layer. These functions are used to enhance the performance of deep learning models. The simplest activation function is referred to as the linear activation, where no transform is applied at all. However, nonlinear activation functions are preferred as they allow the nodes to learn more complex structures in the data. The widely used non-linear activation functions include ReLu, softmax and sigmoid. The bias used in the calculation of the output is a constant value or vector that is added to the weighted sum. It helps in shifting the result of the activation function towards the positive or negative side , in other words it's used to offset the result obtained. This addition of bias introduces flexibility and better generalization to the neural model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Voting Regressor</head><p>Given the similarity scores of the m inducers corresponding to n queries, it is essential to apprehend the evaluation of similarity scores by the inducers. In order to maximize the similarity scores, voting regressor has been adapted as shown in Figure <ref type="figure" coords="5,352.01,647.04,3.66,10.91" target="#fig_2">3</ref>. A Voting Regressor is an ensemble meta-estimator which fits several base regressors on the whole dataset. The regressors are ranked based on their MAE with the help of Rank Assigner. These ranks and the models are provided as input for the Voting Regressor <ref type="bibr" coords="6,362.23,600.75,18.60,10.91" target="#b9">[10]</ref>[11] which will consider the weight of the occurrences of predicted values before averaging. Further, the performance of the voting regressor can again be measured with MAE. The predictions of the voting regressor will be considered to be improved, if the MAE of it is lesser than the other predictors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Implementation</head><p>The given dataset was split into 90% for training and 10% for validation data. The similarity score column is extracted from the dataset and is normalized to ensure similar data distribution, to achieve faster convergence. This serves as our input and output. Three predictor models M 1 , M 2 and M 3 were built to study how similarity scores are assigned.</p><p>The model M 1 was implemented using sklearn.neural_network, which consists of an input layer of 5 neurons, 2 hidden layers of 6 &amp; 5 neurons each and an output layer of 1 neuron. The random state is set to 5 to avoid random split of data at each iteration. A constant learning rate of 0.01 is initialized to control the step size in updating the weights.</p><p>The model M 2 was created to solve the regression using the hyperparameters tuned by Grid Search. A search space with all possible hyperparameters is defined by Grid Search. Cross validation of the data is performed 3 times by splitting the data into 10 folds to obtain multiple iterations of training and testing on the data. The best model is chosen and the performance of the cross validated is evaluated by setting the scoring parameter of GridSearchCV as neg_mean_absolute_error.</p><p>The model M 3 was created using an input layer of 5 neurons, 2 dense layers of output dimensions 5 and 1, stacked over each other. The optimizer function is set as Stochastic Gradient Descent (SGD) with a learning rate of 0.0008.</p><p>The data is sampled into batches of size 5, such that every set of 5 inputs is used to predict the next input's similarity score, for every predictor. The above predictors are trained with 90% of the training set and validated with the remaining training set. The predicted values are compared with the actual values of the inputs and the mean absolute deviation is calculated as error. Ranks have been assigned for the models M 1 , M 2 and M 3 based on the error values.</p><p>The Voting Regressor is constructed with the ranks obtained and the 3 predictor models. The regressor is trained and tested on the entire training and validation data respectively. In the training phase, the output of the voting regressor for every batch is the prediction for the next input. This is compared with the actual value and error is calculated as the difference between these values. Further, it is tested on the test data provided and the original similarity score of the data is replaced with the improved score predicted by the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and Analysis</head><p>Validation dataset is used to test the models and voting regressor is used to predict the similarity scores. These predicted and the actual similarity score values were plotted for each one of them as shown in Figures <ref type="figure" coords="7,178.11,562.83,7.32,10.91" target="#fig_3">4,</ref><ref type="figure" coords="7,185.43,562.83,7.32,10.91" target="#fig_4">5,</ref><ref type="figure" coords="7,192.76,562.83,7.32,10.91" target="#fig_5">6,</ref><ref type="figure" coords="7,200.08,562.83,3.66,10.91" target="#fig_6">7</ref>. It is seen from figures 4 &amp; 5, that the model M 2 predicts better when compared to the model M 1 . Further, it is also seen from Figure <ref type="figure" coords="7,378.91,576.38,3.81,10.91" target="#fig_6">7</ref>, that the Voting Regressor predicted the similarity score better when compared to the model M 2 , as it utilized the weighted occurrences of predicted values before averaging. Table <ref type="table" coords="7,339.20,603.48,5.07,10.91" target="#tab_2">3</ref> shows the MAE and rank values for the base and voting regressor models.</p><p>The voting regressor model has been tested with the CLEF test data and metrics -F1 measure and cluster recall are used to compare and analyze the performance of the results thus obtained. Cluster recall is a metric that assesses how many different clusters from the cluster labels are   The voting regressor is used to predict the updated similarity score values for the testing data which contains 175,591 entries. 10 different variations of the voting regressor were built by varying the parameters, iteration size. Table <ref type="table" coords="8,285.66,658.86,5.01,10.91" target="#tab_3">4</ref> illustrates the F1 scores and CR scores evaluated  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In order to improve the predictions of the results of the inducers, the proposed ensemble model was implemented using three neural networks as base regressors. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,216.19,308.83,162.89,8.93;4,151.80,123.23,291.69,164.07"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Multi layer Perceptron model</figDesc><graphic coords="4,151.80,123.23,291.69,164.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,225.30,554.11,144.67,8.93;5,150.55,377.47,291.69,164.07"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Sequential Neural Model</figDesc><graphic coords="5,150.55,377.47,291.69,164.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,242.01,508.95,111.44,8.93;6,174.89,84.19,243.00,412.43"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Voting Regressor</figDesc><graphic coords="6,174.89,84.19,243.00,412.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,135.46,218.21,324.53,8.93;8,89.29,245.06,416.68,109.50"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Actual and Predicted Values of Similarity Score using MLP Regressor</figDesc><graphic coords="8,89.29,245.06,416.68,109.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="8,102.40,379.09,390.47,8.93"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Actual and Predicted Values of Similarity Score using Ridge Model using Grid Search</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="8,89.29,539.96,416.70,8.93;8,89.29,405.94,416.68,109.50"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Actual and Predicted Values of Similarity Score using Keras Regressor using Sequential model</figDesc><graphic coords="8,89.29,405.94,416.68,109.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="9,131.83,218.21,331.79,8.93;9,89.29,84.19,416.68,109.50"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Actual and Predicted Values of Similarity Score using Voting Regressor</figDesc><graphic coords="9,89.29,84.19,416.68,109.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,88.99,90.49,414.53,129.65"><head>Table 1</head><label>1</label><figDesc></figDesc><table coords="2,95.27,102.49,408.25,117.64"><row><cell></cell><cell>Existing Work</cell><cell></cell></row><row><cell>Existing Work</cell><cell>Proposed Methodology</cell><cell>Performance</cell></row><row><cell>Domain Independent System Fu-sion [3]</cell><cell>Cross Space Fusion Layers,Attention Layers are used with Dense Layers</cell><cell>F1 score: 0.2823</cell></row><row><cell>Differential Evolution-Based Fusion for Results Diversification of Web Search [6]</cell><cell>Differential evolution-based fusion (DE)</cell><cell>Normalised counted Cumulative Dis-Gain (NDCG): 0.5476</cell></row><row><cell>Fusion-Based Methods for Result</cell><cell></cell><cell></cell></row><row><cell>Diversification on the web</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,88.99,208.37,281.27,115.47"><head>Table 2</head><label>2</label><figDesc>Attributes of Inducer file</figDesc><table coords="3,225.02,237.76,145.25,86.07"><row><cell>Fields</cell><cell>Representation</cell></row><row><cell cols="2">query_id unique id of the query</cell></row><row><cell>inter</cell><cell>ignored value</cell></row><row><cell>photo_id</cell><cell>unique photo id</cell></row><row><cell>rank</cell><cell>photo rank</cell></row><row><cell>sim</cell><cell>similarity score</cell></row><row><cell>run_name</cell><cell>name of inducer</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,88.99,251.36,319.70,117.69"><head>Table 3</head><label>3</label><figDesc>Results of the base and voting regressor models</figDesc><table coords="9,179.38,282.98,229.31,86.08"><row><cell>Models</cell><cell>MAE</cell><cell>Rank</cell></row><row><cell>M 1 (Keras Regressor using Sequen-tial Model)</cell><cell>0.626</cell><cell>1</cell></row><row><cell>M 2 (MLP Regressor)</cell><cell>0.041</cell><cell>3</cell></row><row><cell>M 3 (Ridge Regressor using Grid Search)</cell><cell>0.032</cell><cell>2</cell></row><row><cell>Voting Regressor</cell><cell>0.030</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,88.99,391.31,306.66,212.87"><head>Table 4</head><label>4</label><figDesc>F1 score and Cluster Recall rates of 10 best runs</figDesc><table coords="9,89.29,420.71,271.85,183.47"><row><cell>Run</cell><cell>F1@20</cell><cell>CR@20</cell></row><row><cell>No</cell><cell>score</cell><cell>score</cell></row><row><cell>1</cell><cell>0.4316</cell><cell>0.3167</cell></row><row><cell>2</cell><cell>0.5095</cell><cell>0.4053</cell></row><row><cell>3</cell><cell>0.5398</cell><cell>0.4276</cell></row><row><cell>4</cell><cell>0.4929</cell><cell>0.3906</cell></row><row><cell>5</cell><cell>0.5563</cell><cell>0.4332</cell></row><row><cell>6</cell><cell>0.4963</cell><cell>0.3743</cell></row><row><cell>7</cell><cell>0.5533</cell><cell>0.4341</cell></row><row><cell>8</cell><cell>0.5604</cell><cell>0.4373</cell></row><row><cell>9</cell><cell>0.5547</cell><cell>0.4384</cell></row><row><cell>10</cell><cell>0.5568</cell><cell>0.4362</cell></row><row><cell>for 10 best file submissions.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,388.09,665.44,117.90,10.91"><head></head><label></label><figDesc>The model was trained on data from 56 different inducers, containing 167,139 training values and tested on data from 55 inducers, containing 175,591 testing values. The base regressors obtained MAE values of 0.626, 0.041 and 0.032 each. The ensemble method obtained an improved MAE score of 0.030. Among the ten best submissions, the best F1 score and CR score are 0.5604 and 0.4384 respectively.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,108.93,660.07,109.19,8.97"><p>https://scikit-learn.org/stable/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,108.93,671.03,57.90,8.97"><p>https://keras.io/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,112.66,186.24,394.53,10.91;10,112.28,199.79,394.91,10.91;10,112.28,213.34,393.71,10.91;10,112.66,226.89,104.36,10.91;10,213.72,232.04,1.32,5.98;10,217.02,226.89,290.16,10.91;10,112.48,240.44,393.49,10.91;10,112.66,253.99,393.33,10.91;10,112.66,267.54,393.33,10.91;10,112.66,281.08,393.33,10.91;10,112.33,294.63,393.86,10.91;10,112.66,308.18,41.65,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,142.63,253.99,363.36,10.91;10,112.66,267.54,108.85,10.91">Overview of the ImageCLEF 2022: Multimedia Retrieval in Medical, Social Media and Nature Applications</title>
		<author>
			<persName coords=""><forename type="first">Bogdan</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Renaud</forename><surname>Péteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Johannes</forename><surname>Rückert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Asma</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christoph</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Louise</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Raphael</forename><surname>Brüngel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ahmad</forename><surname>Idrissi-Yaghir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Serge</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Liviu-Daniel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Gabriel Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jérôme</forename><surname>Deshayes-Chossart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jon</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,240.63,267.54,265.36,10.91;10,112.66,281.08,393.33,10.91;10,112.33,294.63,26.77,10.91">Proceedings of the 13th International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="10,169.50,294.63,217.70,10.91">Springer Lecture Notes in Computer Science LNCS</title>
		<meeting>the 13th International Conference of the CLEF Association (CLEF<address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022-09-05">2022. September 5-8, 2022</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="10,112.66,321.73,66.87,10.91;10,176.23,326.88,1.32,5.98;10,179.53,321.73,328.13,10.91;10,112.66,335.28,395.16,10.91;10,112.66,348.83,393.33,10.91;10,112.66,362.38,289.33,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,112.66,335.28,395.16,10.91;10,112.66,348.83,181.92,10.91">Overview of the ImageCLEFfusion 2022 Task: Ensembling Methods for Media Interestingness Prediction and Result Diversification</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Liviu-Daniel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Gabriel Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bogdan</forename><surname>Ionescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,312.98,348.83,193.01,10.91;10,112.66,362.38,118.36,10.91">CLEF2022 Working Notes. CEUR Workshop Proceedings (CEUR-WS.org</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">September 5-8, 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,375.93,393.33,10.91;10,112.66,389.48,393.33,10.91;10,112.66,403.03,144.54,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,425.41,375.93,80.57,10.91;10,112.66,389.48,210.60,10.91">DeepFusion: Deep ensembles for domain independent system fusion</title>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liviu-Daniel</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bogdan</forename><surname>Ştefan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ionescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,331.72,389.48,174.27,10.91;10,112.66,403.03,39.76,10.91">International Conference on Multimedia Modeling</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,416.58,394.61,10.91;10,112.30,430.13,395.53,10.91;10,112.66,443.67,223.98,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,112.30,430.13,352.70,10.91">Visual interestingness prediction: A benchmark framework and literature review</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">D</forename><surname>S¸tefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">Q</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>Demarty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sj¨oberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,472.22,430.13,35.61,10.91;10,112.66,443.67,151.80,10.91">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,457.22,395.16,10.91;10,112.66,470.77,395.00,10.91;10,112.66,484.32,277.57,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,308.40,457.22,157.47,10.91">System fusion with deep ensembles</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">D</forename><surname>S¸tefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,488.54,457.22,19.29,10.91;10,112.66,470.77,349.69,10.91">Proceedings of the 2020 International Conference on Multimedia Retrieval (ICMR</title>
		<meeting>the 2020 International Conference on Multimedia Retrieval (ICMR</meeting>
		<imprint>
			<publisher>Association for Computing Machinery (ACM)</publisher>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="256" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,497.87,393.53,10.91;10,112.66,511.42,393.33,10.91;10,112.66,524.97,164.54,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,332.84,497.87,173.35,10.91;10,112.66,511.42,157.84,10.91">Differential evolution-based fusion for results diversification of web search</title>
		<author>
			<persName coords=""><forename type="first">Chunlin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chunlan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shengli</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,280.00,511.42,225.99,10.91;10,112.66,524.97,55.11,10.91">International Conference on Web-Age Information Management</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,538.52,395.17,10.91;10,112.66,552.07,138.38,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,201.24,538.52,271.17,10.91">Fusion-based methods for result diversification in web search</title>
		<author>
			<persName coords=""><forename type="first">Shengli</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,481.95,538.52,25.88,10.91;10,112.66,552.07,63.85,10.91">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="16" to="26" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,565.62,393.33,10.91;10,112.66,579.17,68.39,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,259.47,565.62,173.60,10.91">A survey of query result diversification</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,439.91,565.62,66.08,10.91">Knowl Inf Syst</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,592.72,393.33,10.91;10,112.66,606.27,113.02,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,302.48,592.72,123.25,10.91">Search result diversification</title>
		<author>
			<persName coords=""><forename type="first">Marina</forename><surname>Drosou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Evaggelia</forename><surname>Pitoura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,437.38,592.72,68.61,10.91;10,112.66,606.27,31.01,10.91">ACM SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="47" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,619.81,393.32,10.91;10,112.66,633.36,270.38,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,301.20,619.81,204.78,10.91;10,112.66,633.36,115.08,10.91">The impact of result diversification on search behavior and performance</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Maxwell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Moshfeghi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,235.38,633.36,61.33,10.91">Inf Retrieval J</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,646.91,393.60,10.91;10,112.66,660.46,296.51,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,257.95,646.91,129.35,10.91">Ensemble learning: A survey</title>
		<author>
			<persName coords=""><forename type="first">Omer</forename><surname>Sagi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lior</forename><surname>Rokach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,399.80,646.91,106.47,10.91;10,112.66,660.46,218.40,10.91">Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">e1249</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
