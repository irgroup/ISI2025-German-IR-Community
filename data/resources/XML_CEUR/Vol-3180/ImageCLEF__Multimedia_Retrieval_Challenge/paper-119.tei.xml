<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.69,84.74,415.01,15.42;1,89.29,106.66,321.24,15.42">Automated Classification of Lung Tuberculosis Using 3D Deep Convolutional Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,108.19,11.96"><forename type="first">Sushaanth</forename><surname>Srinivasan</surname></persName>
							<email>sushaanth19113@cse.ssn.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">SSN College of Engineering</orgName>
								<address>
									<addrLine>Rajiv Gandhi Salai</addrLine>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,210.13,134.97,90.93,11.96"><forename type="first">Sharvesh</forename><surname>Shankar</surname></persName>
							<email>sharvesh19101@cse.ssn.edu.</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">SSN College of Engineering</orgName>
								<address>
									<addrLine>Rajiv Gandhi Salai</addrLine>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,148.92,122.49,11.96"><forename type="first">Sabarivasan</forename><surname>Velayutham</surname></persName>
							<email>sabarivasan2010624@ssn.edu.in</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">SSN College of Engineering</orgName>
								<address>
									<addrLine>Rajiv Gandhi Salai</addrLine>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,380.07,148.92,100.77,11.96"><forename type="first">Lekshmi</forename><surname>Kalinathan</surname></persName>
							<email>lekshmik@ssn.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">SSN College of Engineering</orgName>
								<address>
									<addrLine>Rajiv Gandhi Salai</addrLine>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,162.87,130.39,11.96"><forename type="first">Prabavathy</forename><surname>Balasundaram</surname></persName>
							<email>prabavathyb@ssn.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">SSN College of Engineering</orgName>
								<address>
									<addrLine>Rajiv Gandhi Salai</addrLine>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.69,84.74,415.01,15.42;1,89.29,106.66,321.24,15.42">Automated Classification of Lung Tuberculosis Using 3D Deep Convolutional Neural Networks</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">FEB44D43DA3D1F58F72B137E0CBE0623</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Tuberculosis</term>
					<term>Deep Learning</term>
					<term>3D CNN Classification</term>
					<term>Cavern</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automated TB and disease classification is a dire need in these times, as traditional diagnostic procedures are inefficient. Existing literature is focused on TB identification and classification using 2D images. As 3D images contain extra depth information which helps in more accurate modelling of the disease cavern, an approach using the 3D-CNN model has been proposed to classify the type of caverns present in lung CT scans in order to ensure prompt treatment.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Tuberculosis (TB) is a bacterial infection caused by Mycobacterium Tuberculosis. It usually affects the lungs and can then spread to other parts of the body such as the brain and the spine. TB cavern has three classes which represent its property of having thick walls, foci around and the presence of calcification.</p><p>The traditional diagnostic procedures include skin tests, blood tests, imaging modalities, sputum testing and culture test. The results of a sputum smear requires several days, while the results of a culture needs several weeks. This reduces the diagnostic efficiency and frequently delays the isolation of infectious individuals. These tests have a low sensitivity as well. TB diagnosis, especially in smear-negative patients, can be extremely difficult.</p><p>If TB is not diagnosed properly, due to its highly transmittable nature, it spreads from one person to the next through the air. Hence, it is a dangerous disease, and if not treated rightly, can be fatal. According to the World Health Organization, a total of 1.6 million people died in the year of 2020 due to Tuberculosis.</p><p>Existing research presented in Table <ref type="table" coords="1,263.73,550.74,5.06,10.91" target="#tab_0">1</ref> has been applied on 2D images. However, 3D images provide better insights when compared to 2D images. The training process for 3D images would be time consuming when compared to the training process on 2D images. Hence, the inference can be made that a model using a 3D dataset is more reliable. Therefore it is crucial to come up with new deep learning solutions that can detect TB based on 3D images and provide higher accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Task and Dataset Description</head><p>The dataset used for this task is from ImageCLEF 2022 <ref type="bibr" coords="2,328.67,479.35,13.35,10.91" target="#b0">[1]</ref>. The goal of the Caverns Report task <ref type="bibr" coords="2,89.29,492.90,12.76,10.91" target="#b1">[2]</ref> is to predict 3 binary features of caverns namely, Has Thick Walls, Has Foci Around and Has Calcification.</p><p>A single 3D image is provided for each of the 60 patients. Each 3D image contains around 100 slices of 2D images of 512x512 pixels. All the CT images are stored in NIFTI file format with .nii.gz file extension (g-zipped .nii files). This file format stores raw voxel intensities in Hounsfield units (HU) as well the corresponding image metadata such as image dimensions, voxel size in physical units and slice thickness.</p><p>Two versions of automatically extracted masks of the lungs were provided for each CT image. This data is available along with the CT images of the patients. The first version of segmentation is able to provide masks in an accurate manner,but tends to miss features in severe TB cases where large abnormal regions of lungs are present. On the contrary, the second segmentation provides rough bounds, but includes lesion areas. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Techniques Used</head><p>The 3D-CNN architecture is frequently used for a stack of 2D images, particularly for medical images, as it can assess the positions of defects in the time domain. During the convolution step, the 3D-CNN generates a 3D activation map. This is required for time and volumetric context. To calculate the representation of elements at a low level, a three-dimensional filter is employed for the 3D convolution of the dataset.</p><p>Convolution and pooling layers connect only to local regions around each input in the CNN, which is a version of the classic neural network. CNNs are sparsely connected to hierarchical representation of the input, allowing them to process images from general forms to edge details. The 3D-CNN is a development of 2D-CNNs that captures discriminating features in both the spatial and temporal dimensions by dividing hierarchical 3D visual information into small cubes rather than 2D patches.</p><p>Figure <ref type="figure" coords="3,130.78,539.64,4.99,10.91" target="#fig_0">1</ref> illustrates the notion of a 3D convolution. The input 3D image is split into 2D slices. The process of 3D convolution begins with the 2D slices, with x ij denoting the j th receptive field on the i th slice. Local receptive fields are constructed on 2D slices to generate 2D features y ij , which are convolved along the temporal direction i to generate feature vector y j at the convolution layer. A 3D pooling layer follows the same steps as a 2D pooling layer. However, it takes the maximum or average values at each step. The CNN is ready for hierarchical learning from motifs to edges after repeated convolution and pooling operations until the picture information is adequately compressed.</p><p>The sequences of signals will be fed into the final hidden layer, where a fully connected neural network will learn the image's attributes and generate the output as data sequences. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Implementation</head><p>The model was trained on an Intel i7 core CPU, Samsung 1TB SSD and an Nvidia GeForce GTX 2060 Super GPU System. Google Colaboratory was also used which uses a 12GB Nvidia Tesla K80 GPU. The Deep Learning framework Tensorflow was used along with tools such as Anaconda, Jupyter Notebook Environment, CUDA, Numpy, Pandas and Sci-Kit Learn.</p><p>A TB classification system was built which has been implemented as multiple binary classifiers for each of the three classes; namely Has thick walls, Has foci around, and Has calcification. The procedure for the implementation of the system is given as follows:</p><p>• The labels were separated by class in order to implement multiple binary classifiers for the three classes. The separated labels were stored in a Numpy array. • The given dataset for the TB Task consists of 3D images. Each 3D image was split into a set of 2D image slices. Each slice was resized to 128x128 pixels using Spline Interpolated Zoom and Inter Cubic Interpolation. • During the learning process, the learning rate is automatically reduced if the loss remains the same for a predefined number of epochs. This callback monitors the validation loss and helps prevent stagnation. • If the model shows no improvement in the reduction of validation loss after a predefined number of epochs even after reduction of the learning rate, the training is automatically stopped. • The architecture of the model in as shown in Figure <ref type="figure" coords="5,350.17,444.35,3.74,10.91" target="#fig_1">2</ref>.</p><p>• K-fold cross validation was performed to estimate the prediction of the model on unseen data and is a preventive measure for overfitting. This ensures that the proportion of the feature of interest is the same across the original data, training and the test set, which gives a more accurate estimate of the performance of the model. • After training, the model was made to predict values for the test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Result and Analysis</head><p>The model was trained on a small scale dataset of five patients and then upscaled to sixty patient records. The model has attained an accuracy of 75% on training data and 60% on validation data. The area under the ROC curve for the validation data is 0.78 for the class Has Calcification, 0.74 for the class Has Foci Around, and 0.65 for the class Has Thick Walls.</p><p>For the classes Has Foci Around and Has Calcification, the most of the ROC curve is present towards the left of the line denoting the random classifier but it intersects the line. The validation accuracy is very less compared to the training accuracy and the validation loss is much greater shows that the model has correctly fitted the data. Thus, it can be inferred from this graph that the model performs well on this class as the positive and negative samples in the dataset for this class are balanced.</p><p>The following table describes the probability of the three classes predicted by the model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In summary, a Deep 3D Convolutional Neural Network model structure has been proposed to accurately predict the classification of the cavern present in CT Scans of Tuberculosis in the Lung region. In order to increase the predictions of the model, the parameters and the hyperparameters of the 3D-CNN model were tuned. The optimal model resulted in a training accuracy of 75%. The model was tested for the test data of 16 patients and achieved a mean AUC of 0.536.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,328.68,131.89,8.93;3,108.88,84.19,375.02,231.93"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: 3D-CNN Architecture</figDesc><graphic coords="3,108.88,84.19,375.02,231.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,89.29,663.66,172.46,8.93;4,183.01,84.18,226.77,566.91"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Proposed 3D-CNN Architecture</figDesc><graphic coords="4,183.01,84.18,226.77,566.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,89.29,225.26,191.75,8.93;6,89.94,84.19,192.76,128.51"><head>Figure 3 :Figure 4 :Figure 5 :</head><label>345</label><figDesc>Figure 3: (a) roc-thickwalls (validation data)</figDesc><graphic coords="6,89.94,84.19,192.76,128.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,88.99,90.49,411.71,278.98"><head>Table 1</head><label>1</label><figDesc>Existing work along with their methodology and performance</figDesc><table coords="2,94.57,118.27,406.12,251.19"><row><cell>Existing work</cell><cell>Methodology used</cell><cell>Performance</cell></row><row><cell>Automated TB classification using ensemble of deep architectures. Multimedia Tools and Applications [3]</cell><cell>Ensemble classifier using AlexNet, GoogleNet and ResNet to classify 2D CXR images</cell><cell>Accuracy -88.24% Area under Curve -0.93</cell></row><row><cell>Simple Neural Network based TB Classification. [4]</cell><cell>A simple shallow neural network is employed with three layers to classify 3D CT-images</cell><cell>Validation Accuracy-20% Testing Accuracy -22.1%</cell></row><row><cell>Tuberculosis (TB) detection system using deep neural networks. Neural Computing and Applications [5]</cell><cell>Model learns from the pre-trained (SVM) from the transferred knowledge weights of Inception V3 and classifies the data using support vector machine</cell><cell>Accuracy -95.05%</cell></row><row><cell>Application of a convolutional neural network using transfer learning for tuberculosis detection. [6]</cell><cell>ConvNet model that uses VGG16 to classify 2D CXR images</cell><cell>Accuracy -80% without applying augmentation, Accuracy -81.25% with application of augmentation</cell></row><row><cell>A deep learning approach for the classification of TB from NIH CXR dataset. [7]</cell><cell>A custom-built CNN architecture to classify 2D CXR images</cell><cell>Accuracy -92.5%</cell></row><row><cell>Analysis of Tuberculosis (TB) on</cell><cell>SURF Feature Extraction and</cell><cell></cell></row><row><cell>X-ray Image Using SURF Feature Extraction and the K-Nearest Neighbor</cell><cell>the K-Nearest Neighbor (KNN) Classification to classify</cell><cell>Average Accuracy -73%</cell></row><row><cell>(KNN) Classification Method.[8]</cell><cell>2D X-ray image</cell><cell></cell></row><row><cell>Diagnosing tuberculosis using deep convolutional neural network. [9]</cell><cell>Deep Convolutional Neural Network (CNN) to classify 2D CXR images</cell><cell>Validation Accuracy -87.1%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,107.28,288.54,398.71,67.82"><head></head><label></label><figDesc>• The training images were loaded into Numpy arrays in order to train the model. • The training data was normalized as it calibrates the different pixel intensities into a normal distribution which makes computation efficient and helps the model converge faster. • The normalized data was split into training and testing sets.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,88.99,155.92,344.41,228.24"><head>Table 2</head><label>2</label><figDesc>Probability of having Thick Walls, Foci Around and Calcification for first 15 patients</figDesc><table coords="7,174.30,183.56,246.68,200.60"><row><cell>Image</cell><cell>Thickwalls</cell><cell>Foci Around</cell><cell>Calcification</cell></row><row><cell>TST_00</cell><cell>0.9978415</cell><cell>0.8283372</cell><cell>0.9964127</cell></row><row><cell>TST_01</cell><cell>0.99999547</cell><cell>0.34543616</cell><cell>0.83471966</cell></row><row><cell>TST_02</cell><cell>0.999368</cell><cell>0.69200265</cell><cell>0.9884094</cell></row><row><cell>TST_03</cell><cell>0.9999981</cell><cell>0.8152172</cell><cell>0.9991033</cell></row><row><cell>TST_04</cell><cell>0.999992</cell><cell>0.38898218</cell><cell>0.9299915</cell></row><row><cell>TST_05</cell><cell>0.9999901</cell><cell>0.4413950</cell><cell>0.8158201</cell></row><row><cell>TST_06</cell><cell>0.9999924</cell><cell>0.73378474</cell><cell>0.9003653</cell></row><row><cell>TST_07</cell><cell>0.99952185</cell><cell>0.72178733</cell><cell>0.6093098</cell></row><row><cell>TST_08</cell><cell>0.9999995</cell><cell>0.30586368</cell><cell>0.9996055</cell></row><row><cell>TST_09</cell><cell>0.9991689</cell><cell>0.98074776</cell><cell>0.9726256</cell></row><row><cell>TST_10</cell><cell>0.99997044</cell><cell>0.9738817</cell><cell>0.96510625</cell></row><row><cell>TST_11</cell><cell>0.929831</cell><cell>0.5132923</cell><cell>0.99828976</cell></row><row><cell>TST_12</cell><cell>0.9966671</cell><cell>0.99855965</cell><cell>0.995698</cell></row><row><cell>TST_13</cell><cell>0.9999987</cell><cell>0.839497</cell><cell>0.915082</cell></row><row><cell>TST_14</cell><cell>0.99993134</cell><cell>0.93050194</cell><cell>0.79498357</cell></row><row><cell>TST_15</cell><cell>0.9987043</cell><cell>0.7850096</cell><cell>0.8628713</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank the <rs type="institution">CSE department of SSN College of Engineering</rs> for letting us utilize the GPU machine extensively to implement this task.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="7,107.59,642.48,400.08,10.91;7,102.51,656.03,405.16,10.91;7,102.51,669.58,404.68,10.91;8,102.51,86.97,404.75,10.91;8,102.51,100.52,403.48,10.91;8,102.51,114.06,336.66,10.91;8,439.18,112.31,6.81,7.97;8,449.03,114.06,56.95,10.91;8,102.51,127.61,404.67,10.91;8,102.51,141.16,131.87,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,348.96,86.97,158.31,10.91;8,102.51,100.52,308.81,10.91">Overview of the ImageCLEF 2022: Multimedia retrieval in medical, social media and nature applications</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Peteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rückert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Brüngel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Idrissi-Yaghir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">D</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L.-D</forename><surname>Ştefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Deshayes-Chossart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,433.16,100.52,72.83,10.91;8,102.51,114.06,336.66,10.91;8,439.18,112.31,6.81,7.97;8,449.03,114.06,56.95,10.91;8,102.51,127.61,212.44,10.91">Experimental IR Meets Multi-linguality, Multimodality, and Interaction, Proceedings of the 13 th International Conference of the CLEF Association (CLEF 2022)</title>
		<title level="s" coord="8,321.94,127.61,180.88,10.91">LNCS Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,107.59,168.26,398.40,10.91;8,102.51,181.81,403.48,10.91;8,102.51,195.36,312.13,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,335.92,168.26,170.07,10.91;8,102.51,181.81,193.10,10.91">Overview of ImageCLEF Tuberculosis 2022 -CT-based caverns detection and report</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<ptr target=".org&lt;http://ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="m" coord="8,316.34,181.81,109.22,10.91">CLEF2022 Working Notes</title>
		<title level="s" coord="8,432.52,181.81,73.47,10.91;8,102.51,195.36,99.32,10.91">CEUR Workshop Proceedings, CEUR-WS</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,107.59,222.46,398.40,10.91;8,102.51,236.01,389.25,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,254.05,222.46,251.93,10.91;8,102.51,236.01,55.96,10.91">Automated TB classification using ensemble of deep architectures</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Rahul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sofat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,180.13,236.01,189.75,10.91">Multimedia Tools and Applications Journal</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="31515" to="31532" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,107.59,263.11,398.40,10.91;8,102.51,276.66,85.37,10.91" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,349.49,263.11,156.49,10.91;8,102.51,276.66,59.96,10.91">Simple Neural Network based TB Classification</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">R</forename><surname>Anandan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Thai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,107.59,303.75,398.40,10.91;8,102.51,317.30,391.23,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,302.17,303.75,203.81,10.91;8,102.51,317.30,70.43,10.91">Tuberculosis (TB) detection system using deep neural networks</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Dinesh Jackson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">Rajesh</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Kanna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,195.20,317.30,195.06,10.91">Neural Computing and Applications Journal</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1533" to="1545" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,107.59,344.40,398.40,10.91;8,102.51,357.95,403.47,10.91;8,102.51,371.50,217.29,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,262.48,344.40,243.51,10.91;8,102.51,357.95,192.94,10.91">Application of a convolutional neural network using transfer learning for tuberculosis detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ahsan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Denton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,317.76,357.95,188.23,10.91;8,102.51,371.50,132.09,10.91">IEEE International Conference on Electro Information Technology (EIT)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="427" to="433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,107.59,398.60,398.40,10.91;8,102.51,412.15,395.62,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,348.26,398.60,157.73,10.91;8,102.51,412.15,186.37,10.91">A deep learning approach for the classification of TB from NIH CXR dataset</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">Z Y</forename><surname>Zaidi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">U</forename><surname>Akram</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jameel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">S</forename><surname>Alghamdi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,310.48,412.15,94.12,10.91">IET Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="787" to="796" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,107.59,439.25,398.40,10.91;8,102.19,452.79,404.45,10.91;8,102.51,466.34,403.47,10.91;8,102.19,479.89,106.27,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,390.36,439.25,115.62,10.91;8,102.19,452.79,404.45,10.91;8,102.51,466.34,92.61,10.91">Analysis of Tuberculosis (TB) on X-ray Image Using SURF Feature Extraction and the K-Nearest Neighbor (KNN) Classification Method</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">A</forename><surname>Rizal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">O</forename><surname>Purba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Siregar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Sinaga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Azizah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,217.43,466.34,288.56,10.91;8,102.19,479.89,32.89,10.91">Journal of Applied Information and Communication Technologies (JAICT)</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="9" to="12" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,107.59,506.99,399.60,10.91;8,102.51,520.54,405.16,10.91;8,102.26,534.09,36.52,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,214.29,506.99,287.98,10.91">Diagnosing tuberculosis using deep convolutional neural network</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Oloko-Oba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Viriri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,119.83,520.54,337.93,10.91">Proceedings of International Conference on Image and Signal Processing</title>
		<meeting>International Conference on Image and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="151" to="161" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
