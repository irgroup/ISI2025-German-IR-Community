<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,396.50,15.42;1,89.29,106.66,124.04,15.42">ImageCLEFcoral task: Coral reef image annotation and localisation</title>
				<funder>
					<orgName type="full">ESRC Impact Acceleration</orgName>
				</funder>
				<funder>
					<orgName type="full">University of Essex</orgName>
				</funder>
				<funder>
					<orgName type="full">Operation Wallacea</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.10,134.97,82.55,11.96"><forename type="first">Jon</forename><surname>Chamberlain</surname></persName>
						</author>
						<author>
							<persName coords="1,184.29,134.97,57.64,11.96"><forename type="first">Alba</forename><surname>García</surname></persName>
						</author>
						<author>
							<persName coords="1,244.92,134.97,77.86,11.96"><forename type="first">Seco</forename><surname>De Herrera</surname></persName>
						</author>
						<author>
							<persName coords="1,335.43,134.97,89.93,11.96"><forename type="first">Antonio</forename><surname>Campello</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Wellcome Trust</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,88.87,148.92,63.75,11.96"><forename type="first">Adrian</forename><surname>Clark</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Essex</orgName>
								<address>
									<addrLine>Wivenhoe Park</addrLine>
									<postCode>CO4 3SQ</postCode>
									<settlement>Colchester</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,396.50,15.42;1,89.29,106.66,124.04,15.42">ImageCLEFcoral task: Coral reef image annotation and localisation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AD9760F216F9AD8106CACFE094AA52C9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ImageCLEF</term>
					<term>image annotation</term>
					<term>image labelling</term>
					<term>classification</term>
					<term>segmentation</term>
					<term>coral reef image annotation</term>
					<term>3D photogrammetry</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents an overview of the ImageCLEFcoral 2022 task that was organised as part of the Conference and Labs of the Evaluation Forum -CLEF Labs 2022. The task addresses the problem of automatically segmenting and labelling a collection of underwater images that can be used in combination to create 3D models for the monitoring of coral reefs. The training data set contains images from four Worldwide geographical locations and the test data set contains images from only one of these locations. Therefore the participants could train on a subset of geographically similar images, which has been shown in previous editions of this task to be beneficial to performance. These images are grouped into image sets that can be used to create a 3D model of the environment using photogrammetry. The training dataset contained 1,374 images and 31,517 polygon objects. The test dataset comprises 200 images and 6,319 polygon objects. 6 teams registered to the ImageCLEFcoral 2022 task, of which 2 teams submitted 11 runs. Participants' entries showed that although automatic annotation of benthic substrates was possible, improving on the baselines set in previous years will be difficult.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Marine ecosystem monitoring is a key priority for evaluating ecosystem conditions <ref type="bibr" coords="1,454.75,461.28,11.28,10.91" target="#b0">[1]</ref>. Despite a wide range of monitoring programs for tropical coral reefs, there is still a crucial need to establish an effective monitoring process. This process can be made by collecting 3D visual data using autonomous underwater vehicles. The ImageCLEFcoral task organisers have developed a novel multi-camera system that allows large amounts of imagery to be captured by a SCUBA diver or autonomous underwater vehicle in a single dive which will provide useful information for both annotation and further study of the coral. By releasing this data through an ImageCLEF lab <ref type="bibr" coords="1,105.82,556.12,11.59,10.91" target="#b1">[2]</ref>, organised as part of the Conference and Labs of the Evaluation Forum -CLEF Labs 2022 1 , advances can be made in the automatic processing at scale.</p><p>Previous editions of ImageCLEFcoral in 2019 <ref type="bibr" coords="1,301.57,583.22,12.81,10.91" target="#b2">[3]</ref> and 2020 <ref type="bibr" coords="1,359.15,583.22,12.82,10.91" target="#b3">[4]</ref> have shown improvements in task performance and promising results on cross-learning between images from geographical regions. The 3rd edition <ref type="bibr" coords="2,200.41,86.97,12.95,10.91" target="#b4">[5]</ref> increased the complexity of the task and size of data available to participants through supplemental data, resulting in lower performance than previous years. As with this 4rd edition, in 2022, the training and test data form a complete set of images required to form 3D reconstructions of the marine environment. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Task and Participation</head><p>In 2022, the ImageCLEFcoral task followed the format of previous editions <ref type="bibr" coords="2,415.50,488.63,11.23,10.91" target="#b2">[3,</ref><ref type="bibr" coords="2,429.37,488.63,7.42,10.91" target="#b3">4,</ref><ref type="bibr" coords="2,439.43,488.63,7.49,10.91" target="#b4">5]</ref>. Participants were again asked to devise and implement algorithms for automatically annotating regions in a collection of images containing several types of benthic substrate, such as hard coral or sponge.</p><p>As in previous editions, 2022 comprised two sub-tasks: T1-"Coral reef image annotation and localisation" and T2-"Coral reef image pixel-wise parsing" subtasks. The "Coral reef image annotation and localisation" subtask uses bounding boxes, with sides parallel to the edges of the image, for the annotation of regions in a collection of images containing several types of benthic substrates. The "Coral reef image pixel-wise parsing" subtask uses a series of boundary image coordinates which form a single polygon around each identified region in the coral reef images; this has been dubbed pixel-wise parsing (these polygons should not have self-intersections). Participants were invited to make submissions for either or both tasks with a limit of 10 runs per subtask.</p><p>In this 4th edition of the task 4 teams registered. Table <ref type="table" coords="2,334.71,651.22,4.97,10.91">1</ref> presents the two teams that submitted runs. They submitted a total of 11 valid runs. Unfortunately, this year were no participants to the "Coral reef image pixel-wise parsing" subtask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1</head><p>Participating groups of the ImageCLEF 2022 Coral task. Teams with previous participation are marked with an asterisk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Team</head><p>Institution Runs T1 Runs T2</p><p>HHU <ref type="bibr" coords="3,120.96,173.81,11.83,8.87" target="#b5">[6]</ref> * Heinrich-Heine-Universität Düsseldorf, Germany 9 -UTK <ref type="bibr" coords="3,118.27,185.77,11.83,8.87" target="#b6">[7]</ref> University of Tennessee, Knoxville, UTK, USA 2 -</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Data Set</head><p>The images used in the data set were captured using an underwater multi-camera system developed at the Marine Technology Research Unit at the University of Essex (MTRU), UK.</p><p>A complete set of images required to form a 3D reconstruction of the environment was provided with the training and test data. Figure <ref type="figure" coords="3,297.45,297.73,4.97,10.91" target="#fig_0">1</ref> shows an example 3D reconstruction of one of the subsets of data (approx 4 × 6 m). Each image in the subset to create this model is represented by a blue rectangle, with the track of multi-camera array used for data collection clearly visible across the environment. The 3D models can be visualised online<ref type="foot" coords="3,373.11,336.62,3.71,7.97" target="#foot_0">2</ref> and the corresponding .obj files were available to the participants.</p><p>The training set contains images from 5 locations (see Table <ref type="table" coords="3,359.96,365.47,3.50,10.91" target="#tab_0">2</ref>). These images are grouped into image subsets that can be used to create a 3D model of the environment using photogrammetry and partially overlap. The test set contains images from a single location (K1, Kaledupa, Indonesia) so participants can choose which sets to train their systems with.</p><p>The ground truth annotations of the training and test sets were made by a combination of marine biology MSc students at the University of Essex and experienced marine researchers. All annotations were double checked by an experienced coral reef researcher. The annotations were performed using a web-based tool, designed to be simple to learn, quick to use and allows many people to work concurrently: full details are presented in the ImageCLEFcoral 2019 overview <ref type="bibr" coords="3,133.20,487.41,11.43,10.91" target="#b2">[3]</ref>.</p><p>The data set used for the 2022 task includes data from previous versions of the task; however, all data underwent a review to improve the gold standard:</p><p>• a thumbnail for each polygon was generated and placed within a subfolder per class; • the polygon thumbnail images for each class were reviewed at small sizing (approx. 50 per screen) to identify, remove and/or fix polygons that were very small, with an unusual shape, were a duplicate of another polygon, or had considerable overlap with another class; • the polygon thumbnail images for each class were reviewed at medium resolution (approx. 20 per screen) to identify and correct classification errors.</p><p>The images contain annotations of the following 13 types of substrates: Hard Coral -Branching; Hard Coral -Submassive; Hard Coral -Boulder; Hard Coral -Encrusting; Hard Coral The training dataset contained 1,374 images from 6 subsets from 4 locations (see Table <ref type="table" coords="4,479.25,352.74,3.50,10.91" target="#tab_0">2</ref>). All subsets were complete (containing all the images to build the 3D model), except K1-20180712-01 which was a partial collection. The test data (200 images) contained more images of the K1-20180712-01 dataset.</p><p>Participants were encouraged to use the publicly available NOAA NCEI data <ref type="foot" coords="4,425.38,405.18,3.71,7.97" target="#foot_2">4</ref> and/or CoralNet<ref type="foot" coords="4,501.78,405.18,3.71,7.97" target="#foot_3">5</ref> to train their approaches. The NOAA NCEI data typically contains 10 annotated pixels per image, with a considerably larger classification scheme than the classes used in ImageCLEFcoral. A NOAA Translation processor, used to capture the classification types within the data set and translate them via an expert-defined translation matrix into the ImageCLEFcoral classes, was provided. Furthermore, participants were encouraged to explore novel probabilistic computer vision techniques based around image overlap and transposition of data points.</p><p>Table <ref type="table" coords="4,126.06,501.78,4.97,10.91" target="#tab_1">3</ref> shows the distribution of polygons per class between the training and the test datasets. The training dataset had a higher proportion of algae, boulder coral, branching coral, submassive coral and sponge, compared to the test dataset which had much more soft coral. It was hoped the inclusion of additional large-scale public datasets from NOAA would allow the participants to address the lack of training examples for under-represented classes in the training data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Evaluation Methodology</head><p>Algorithmic performance was evaluated on the unseen test data using the popular intersection over union metric from the PASCAL VOC <ref type="foot" coords="5,275.52,372.11,3.71,7.97" target="#foot_4">6</ref> exercise. This computes the area of intersection of the output of an algorithm and the corresponding ground truth, normalising that by the area of their union to ensure its maximum value is bounded.</p><p>As in previous years we defined the following metric:</p><p>• MAP 0.5 IoU : the localised Mean Average Precision (MAP) for each submitted method using the performance measure of IoU &gt;=0.5 of the ground truth. • MAP 0.0 IoU : the localised Mean Average Precision (MAP) for each submitted method using the performance measure of IoU &gt;=0.0 of the ground truth. It indicates whether the classes are detected in the image without any localisation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>Table <ref type="table" coords="5,115.68,551.21,5.05,10.91">1</ref> presents the description of the teams who participated in this ImageCLEFcoral edition.</p><p>To get a better overview of the submitted runs, the results for each team are presented in Table <ref type="table" coords="5,500.34,564.76,3.66,10.91" target="#tab_2">4</ref>.</p><p>The training and testing datasets for the various editions of this coral annotation task have differed each year so direct comparisons have to be made with some caution. Nevertheless, for the "Coral reef image annotation and localisation" subtask, these results represent an improvement on the nearest comparable previous edition. Previous editions of this exercise have shown that the use of multiple locations in the training data impacts performance. There Both submissions pointed out that the dataset is significantly unbalanced, reflecting the real distribution of the different types of coral in the regions in which the imagery was obtained. In particular, substrate type c_soft_coral accounts almost 25% of all annotations, while the least populous annotations provide under 1.5% of them. Moreover, both groups also mentioned that colours are not consistent across the dataset, a fact which again illustrates the kinds of variation that a real-world system would have to cope with. Finally, some minor problems with some of the annotations were noted by both groups.</p><p>The UTK submission <ref type="bibr" coords="6,198.79,428.56,12.99,10.91" target="#b6">[7]</ref> used a Convolutional Neural Network (CNN) architecture based around the popular VVG16 model. There was significant pre-processing in preparing the data for their model, and also some post-processing to produce the particular labels required for this exercise.</p><p>The submission from the HHU group <ref type="bibr" coords="6,263.23,482.76,12.68,10.91" target="#b5">[6]</ref> also used a CNN-based approach, though in this case centred around Faster R-CNN and ResNet+FPN. The colour cast alluded to above, the consequence of red wavelengths being extinguished more quickly with water depth than shorter wavelengths, was explicitly addressed while preparing the imagery for presentation to their system. A certain amount of hyperparameter tuning was performed. A non-maximum suppression phase was used to reduce overlapping predictions: when two bounding boxes of different classes had a IoU &gt; 0.8, the one with the smaller confidence was discarded.</p><p>Submissions from this group use different depths of ResNet (-50, -101 and -150), and with or without colour balancing. In general, the deeper networks performed better, though the effects of colour cast removal were less clear.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>The submissions to this task show that improvements in the research community's use of deep networks continues to improve performance in their ability to identify types of coral. This is an especially difficult task because, being a biological structure, coral types have characteristic features but are not necessarily similar in appearance. Hence, the best MAP 0.5 IoU score of about 0.4 represents very good performance on this extraordinarily difficult problem.</p><p>As with the previous edition of the task, the training and test data formed a complete set of images required to form 3D reconstructions of the marine environment. We believe this style of data can be explored in the future for probabilistic computer vision techniques based around image overlap and transposition of data points. A goal for the future is to collaborate with research groups to expand the training data and improve algorithms for benthic species identification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,89.29,389.76,416.70,8.93;2,89.29,401.77,416.70,8.87;2,89.29,413.72,54.39,8.87;2,89.29,147.88,416.68,234.46"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: 3D reconstruction of a coral reef (approx. 4x6m). Each image in the subset to create this model is represented by a blue rectangle, with the track of multi-camera array clearly visible across the environment.</figDesc><graphic coords="2,89.29,147.88,416.68,234.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,88.09,90.49,418.66,259.62"><head>Table 2</head><label>2</label><figDesc>Detatails of the ImageCLEFcoral training set.</figDesc><table coords="4,95.45,122.10,404.63,163.28"><row><cell>Image subset</cell><cell>Location</cell><cell>Similarity to test set</cell><cell>Images</cell></row><row><cell>K1-20180712-01</cell><cell>K1, Kaledupa, Indonesia</cell><cell>Same location</cell><cell>173</cell></row><row><cell>PK-20180714-01</cell><cell>PK, Hoga Indonesia</cell><cell>Similar location (within 10</cell><cell>244</cell></row><row><cell></cell><cell></cell><cell>miles)</cell><cell></cell></row><row><cell>PK-20180729-02</cell><cell>PK, Hoga Indonesia</cell><cell>Similar location (within 10</cell><cell>270</cell></row><row><cell></cell><cell></cell><cell>miles)</cell><cell></cell></row><row><cell>20180406-spermonde-keke</cell><cell cols="2">Keke, Spermonde, Indonesia Geographically and</cell><cell>266</cell></row><row><cell></cell><cell></cell><cell>ecologically similar</cell><cell></cell></row><row><cell>20190417-seychelles-BL</cell><cell cols="2">Curieuse Island, Seychelles Geographically distinct but</cell><cell>120</cell></row><row><cell></cell><cell></cell><cell>ecologically similar</cell><cell></cell></row><row><cell>20170803-dominica-cabrits</cell><cell>Cabrits, Dominica</cell><cell>Geographically and</cell><cell>301</cell></row><row><cell></cell><cell></cell><cell>ecologically distinct</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Total images:</cell><cell>1,374</cell></row></table><note coords="4,88.09,312.10,418.66,10.91;4,89.29,325.64,211.14,10.91;4,300.43,323.89,3.71,7.97;4,304.64,325.64,201.55,10.91;4,89.29,339.19,203.63,10.91"><p><p><p><p><p>-Table</p>;</p>Hard Coral -Foliose; Hard Coral -Mushroom; Soft Coral; Soft Coral -Gorgonian; Sponge; Sponge -Barrel; Fire Coral -Millepora 3 ; and Algae -Macro or Leaves. See Table</p>5</p>for description and example images of each class.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,88.99,90.49,337.58,218.81"><head>Table 3</head><label>3</label><figDesc>Distribution of polygons per class for training and test datasets.</figDesc><table coords="5,168.70,122.05,257.87,187.24"><row><cell>Substrate</cell><cell>Training</cell><cell></cell><cell>Test</cell><cell></cell></row><row><cell>algae_macro_or_leaves</cell><cell>1,870</cell><cell>5.93%</cell><cell>106</cell><cell>1.68%</cell></row><row><cell>fire_coral_millepora</cell><cell>0</cell><cell>0.00%</cell><cell>1</cell><cell>0.02%</cell></row><row><cell>hard_coral_boulder</cell><cell cols="4">7,373 23.39% 1,209 19.13%</cell></row><row><cell>hard_coral_branching</cell><cell>3,132</cell><cell>9.94%</cell><cell>183</cell><cell>2.90%</cell></row><row><cell>hard_coral_encrusting</cell><cell>380</cell><cell>1.21%</cell><cell>14</cell><cell>0.22%</cell></row><row><cell>hard_coral_foliose</cell><cell>233</cell><cell>0.74%</cell><cell>119</cell><cell>1.88%</cell></row><row><cell>hard_coral_mushroom</cell><cell>335</cell><cell>1.06%</cell><cell>55</cell><cell>0.87%</cell></row><row><cell>hard_coral_submassive</cell><cell>2,637</cell><cell>8.37%</cell><cell>150</cell><cell>2.37%</cell></row><row><cell>hard_coral_table</cell><cell>920</cell><cell>2.92%</cell><cell>37</cell><cell>0.59%</cell></row><row><cell>soft_coral</cell><cell cols="4">7,769 24.65% 3,349 53.00%</cell></row><row><cell>soft_coral_gorgonian</cell><cell>171</cell><cell>0.54%</cell><cell>222</cell><cell>3.51%</cell></row><row><cell>sponge</cell><cell cols="2">6,091 19.33%</cell><cell cols="2">815 12.90%</cell></row><row><cell>sponge_barrel</cell><cell>606</cell><cell>1.92%</cell><cell>59</cell><cell>0.93%</cell></row><row><cell>Total</cell><cell>31,517</cell><cell></cell><cell>6,319</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.89,90.49,418.63,240.59"><head>Table 4</head><label>4</label><figDesc>Coral reef image annotation and localisation performance in terms of MAP 0.5 IoU and MAP 0.0 IoU. The best run per team is selected. Coral reef image pixel-wise parsing" this year: this is a more difficult task, albeit somewhat closer to the real-word problem.</figDesc><table coords="6,88.89,134.01,301.50,183.52"><row><cell cols="3">Run id Team MAP 0.5 IoU MAP 0.0 IoU</cell></row><row><cell>183919 HHU</cell><cell>0.396</cell><cell>0.752</cell></row><row><cell>183914 HHU</cell><cell>0.371</cell><cell>0.726</cell></row><row><cell>183920 HHU</cell><cell>0.366</cell><cell>0.686</cell></row><row><cell>183911 HHU</cell><cell>0.365</cell><cell>0.721</cell></row><row><cell>183922 HHU</cell><cell>0.336</cell><cell>0.697</cell></row><row><cell>183912 HHU</cell><cell>0.318</cell><cell>0.646</cell></row><row><cell>183916 HHU</cell><cell>0.305</cell><cell>0.654</cell></row><row><cell>183913 HHU</cell><cell>0.297</cell><cell>0.661</cell></row><row><cell>183918 HHU</cell><cell>0.291</cell><cell>0.661</cell></row><row><cell>185373 UTK</cell><cell>0.003</cell><cell>0.327</cell></row><row><cell>184144 UTK</cell><cell>0.001</cell><cell>0.30</cell></row><row><cell>was no participation in the "</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="3,108.93,671.04,78.40,8.97"><p>https://skfb.ly/oo6VZ</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="4,108.93,648.97,369.62,8.97"><p>After 2022 evaluation of the dataset, there were no examples of this class included in the training set.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="4,108.93,659.93,101.30,8.97"><p>https://www.ncei.noaa.gov/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="4,108.93,670.89,93.25,8.97"><p>https://coralnet.ucsd.edu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4" coords="5,108.93,671.00,144.76,8.97"><p>http://host.robots.ox.ac.uk/pascal/VOC/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The authors would like to thank the participants who have invested substantial amounts of time and effort in developing solutions to this task. The images used in this task were able to be gathered thanks to funding from the <rs type="funder">University of Essex</rs> and the <rs type="funder">ESRC Impact Acceleration</rs> Account, as well as logistical support from <rs type="funder">Operation Wallacea</rs>. We would also like to thank the <rs type="institution">MSc Tropical Marine Biology</rs> students who participated in the annotation of the images.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5</head><p>Classes of benthic substrate, including an updated description and examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class</head><p>Description Examples</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algae -Macro or Leaves</head><p>Leafy or bulbous structures that can also overgrow other benthic substrates. Fine (grass-like) turf algae is not included. Typically vibrant green.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sponge</head><p>Includes encrusting, leafy, tubular, boulder-like, vase and chimney morphologies that can appear in a variety of colours. Often have a "rough" looking surface from spicules and small holes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sponge -Barrel</head><p>Includes all large barrel-sponge shaped species such as Xestospongia muta, but also includes young, small barrel sponges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hard Coral -Foliose</head><p>Leaf-like or cabbage-like leaf structures</p><p>Hard Coral - </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hard Coral -Boulder</head><p>Boulder-like corals with polyps arranged evenly across the surface. Includes thin, hard encrusting type corals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hard Coral -Encrusting</head><p>Fleshy or boulder-like structures with polyps arranged in channels rather than individually. Includes brain corals, rose corals and bubble corals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Soft Coral</head><p>A wide range of morphologies from clumped, branching types (that can be confused with branching coral) to lobed structures. Can have a fleshy, soft appearance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Soft Coral -Gorgonian</head><p>Sea fans (thin vertical branching plates from a single stem) and sea whips (long, thin soft coral from a single stem).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fire Coral -Millepora</head><p>Fine branching structures similar to branching coral. Very few substrates were in the dataset and were hard to distinguish from Hard Coral -Branching so this category is not used.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="11,107.59,111.28,398.40,10.91;11,107.59,124.83,320.64,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,246.00,111.28,259.99,10.91;11,107.59,124.83,156.85,10.91">Indicator framework for monitoring ecosystem integrity of coral reefs in the western caribbean</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Carrillo-García</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kolb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,272.94,124.83,99.45,10.91">Ocean Science Journal</title>
		<imprint>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,107.59,138.38,399.59,10.91;11,107.59,151.93,400.08,10.91;11,107.59,165.48,399.60,10.91;11,107.41,179.03,398.57,10.91;11,107.59,192.57,400.24,10.91;11,107.59,206.12,398.40,10.91;11,107.59,219.67,399.60,10.91;11,107.59,233.22,89.12,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,292.03,179.03,213.95,10.91;11,107.59,192.57,247.74,10.91">Overview of the ImageCLEF 2022: Multimedia retrieval in medical, social media and nature applications</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Peteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rückert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Brüngel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Idrissi-Yaghir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">D</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L.-D</forename><surname>Ştefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Deshayes-Chossart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,377.90,192.57,129.92,10.91;11,107.59,206.12,398.40,10.91;11,107.59,219.67,161.81,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction, Proceedings of the 13th International Conference of the CLEF Association (CLEF 2022)</title>
		<title level="s" coord="11,276.45,219.67,183.53,10.91">LNCS Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,107.59,246.77,399.60,10.91;11,107.59,260.32,398.40,10.91;11,107.59,273.87,150.03,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,107.59,260.32,176.71,10.91">Overview of ImageCLEFcoral 2019 task</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">G</forename><surname>Clift</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="11,307.31,260.32,114.36,10.91">CLEF2019 Working Notes</title>
		<title level="s" coord="11,429.18,260.32,76.80,10.91;11,107.59,273.87,81.04,10.91">CEUR Workshop Proceedings, CEUR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,107.59,287.42,399.60,10.91;11,107.59,300.97,399.68,10.91;11,107.59,314.52,347.87,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,107.59,300.97,378.93,10.91">Overview of the ImageCLEFcoral 2020 task: Automated coral reef image annotation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">G</forename><surname>Clift</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="11,107.59,314.52,112.31,10.91">CLEF2020 Working Notes</title>
		<title level="s" coord="11,227.30,314.52,159.16,10.91">CEUR Workshop Proceedings, CEUR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,107.59,328.07,399.59,10.91;11,107.59,341.62,399.59,10.91;11,107.59,355.17,399.60,10.91;11,107.59,368.71,67.18,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,107.59,341.62,394.71,10.91">Overview of the ImageCLEFcoral 2021 task: Coral reef image annotation of a 3d environment</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Moustahfid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,123.63,355.17,115.64,10.91">CLEF2021 Working Notes</title>
		<title level="s" coord="11,247.52,355.17,180.80,10.91">CEUR Workshop Proceedings, CEUR-WS</title>
		<meeting><address><addrLine>Bucharest, Romania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,107.59,382.26,400.24,10.91;11,107.59,395.81,398.40,10.91;11,107.34,409.36,398.65,10.91;11,107.59,422.91,217.86,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,274.26,382.26,191.54,10.91">Monitoring coral reefs using faster R-CNN</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kerlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bogomasov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Conrad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,492.41,382.26,15.41,10.91;11,107.59,395.81,398.40,10.91;11,107.34,409.36,292.10,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction, Proceedings of the 13th International Conference of the CLEF Association (CLEF 2022)</title>
		<title level="s" coord="11,406.30,409.36,99.69,10.91;11,107.59,422.91,78.83,10.91">LNCS Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,107.59,436.46,398.40,10.91;11,107.59,450.01,399.60,10.91;11,107.59,463.56,398.40,10.91;11,107.59,477.11,399.59,10.91;11,107.59,490.66,47.34,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,224.92,436.46,281.06,10.91;11,107.59,450.01,197.61,10.91">A dual convolutional neural networks and regression model based coral reef annotation and localization</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">R</forename><surname>Gunti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rorissa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,329.88,450.01,177.31,10.91;11,107.59,463.56,398.40,10.91;11,107.59,477.11,129.24,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction, Proceedings of the 13th International Conference of the CLEF Association (CLEF 2022)</title>
		<title level="s" coord="11,243.36,477.11,177.40,10.91">LNCS Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
