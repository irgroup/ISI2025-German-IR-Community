<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,392.06,15.42;1,88.69,106.66,278.32,15.42">Plant Species Identification using Probability Tree Approach of Deep Learning Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,92.28,134.97,106.87,11.96"><forename type="first">Anantharaman</forename><surname>Karun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamilnadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,214.78,134.97,114.87,11.96"><forename type="first">Krishnakumar</forename><surname>Divyasri</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamilnadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,360.64,134.97,106.02,11.96"><forename type="first">Sella</forename><forename type="middle">Veluswami</forename><surname>Jansi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamilnadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,392.06,15.42;1,88.69,106.66,278.32,15.42">Plant Species Identification using Probability Tree Approach of Deep Learning Models</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">E142216EE206A6644DB0D503E611F5FB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Plant species</term>
					<term>Probabilistic approach</term>
					<term>ResNet50</term>
					<term>Image classification</term>
					<term>Image identification</term>
					<term>PlantCLEF 2022</term>
					<term>Single Level Classification</term>
					<term>Multi Level Classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the submissions made by our team SVJ- SSN-CSE to PlantCLEF 2022[5]. The challenge's goal was to identify plant species based on the test set made from only plant images in the field, given a training dataset consisting of 80k species and up to 100 images each. We submitted 2 runs , one run implemented a ResNet50 which was fine tuned by adding a flattened layer and a 2 dense hidden layers along with an output layer. The second run implemented a multi level classification model emulating taxonomic classification tree using probabilistic tree approach. We achieved a Mean Reciprocal Rank (MRR) of 0.00005 for the run 1 which was a single fine-tuned ResNet50 classification and comparably, we achieved an MRR of 0.000158 for the second run which is a multi level probabilistic tree approach using fine-tuned ResNet50 nodes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent times, the automation of tasks like identifying and associating the living world using visual cues has received considerable momentum. This assumes importance in ecological studies because, for accessing information pertinent to a species, or for recording such information in the first place, specimen identification is a prerequisite. But these are not straightforward tasks by any means, owing to the complicated nature of the form and appearance of biomass in general, which entails large levels of expertise and accuracy. This problem faced by taxonomic researchers, is touted to be one of the most critical hindrances to the Convention on Biological Diversity, according to the Rio Conference of 1992.</p><p>The most significant roadblock is the sheer number of the species under a category, with there being more than 10000 birds, about 30000 fishes, about 400000 flowering plants, and around 1.2 million invertebrates. Presently, a possible solution gaining increasing traction is that of content-based visual identification of specimen images. It requires to present the viewer with simplistic and comprehensive access to archived biological data, while gathering particulars and integrating the database in accelerated time-frames.</p><p>Recent activities show promising signs towards achieving this objective, as seen in the LifeCLEF 2017 <ref type="bibr" coords="2,150.56,86.97,13.96,10.91" target="#b6">[7]</ref> Plant Identification challenge <ref type="foot" coords="2,294.20,85.21,3.71,7.97" target="#foot_0">1</ref> , where datasets of 10,000 species were recorded with about 90% accuracy, by means of deep learning models. There exist a multitude of methods employed for this task, a few of which are based on multimedia data analysis and machine learning, as described by Gaston and O'Neill in 2004 <ref type="bibr" coords="2,317.65,127.61,11.28,10.91" target="#b3">[4]</ref>. They also postulated that the biologists could detect novel species if they were to circumvent the generation of voluminous training datasets, which preclude the efficient use of resources, and calculate the error rates, and set out with scaled-up automatic approaches to reduce them, then they could discover novel species effectively. To contribute in the direction towards attaining such an end, this paper presents the plant identification task that was organized within ImageCLEF 2022 for the system-oriented evaluation of visual-based plant identification.</p><p>The PlantCLEF2022 <ref type="bibr" coords="2,187.28,222.46,15.39,10.91" target="#b4">[5]</ref> challenge edition proposes to take a step in progressing automatic identification of plant species by tackling a multi-image (and metadata) classification problem with a very large number of classes The training dataset that has been made use of, could be distinguished into 2 main categories, in "trusted" and "web", i.e. with, and without species labels provided and checked by human experts, respectively, comprising a total of 4 million images between them. The "trusted" training dataset is based on a specific assortment of more than 2.9 million pictures across 80000 plant species. In contrast, the second data set is based on a collection of web images provided by the search engines, Google and Bing. The "trusted" dataset sized up to nearly 200 GB, and the "web" dataset measured around 100 GB of data, which is considerably large and necessitated remarkable amounts of computing power and time to be trained.</p><p>Through an initial literature survey, we came across ResNet50 -a pre trained transfer learning model, and Inception v3. These models were worked with, as they could be trained faster technically, and their subsequent failure will be discussed in this paper. Another method incorporated in the study was a probability tree approach in which the dataset was subdivided and trained separately, to result in a final score of 0.00015, and this behavior will also be elaborated on further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Dataset</head><p>Figure <ref type="figure" coords="2,222.24,609.62,3.82,10.91">1</ref>: Sample image from the trusted dataset This "trusted" dataset proved to be challenging to navigate through, owing to its significantly greater size, in comparison to those of other tasks, as well as the version from the previous year (it had 800,000 images, as opposed to the 2.8 million this year). 200 GB of training data consisted of images provided by the Global Biodiversity Information Facility (GBIF), and the Encyclopedia of Life (EOL). Sources have listed as museums, academic institutions, and other online platforms like iNaturalist and Pl@ntNet.</p><p>The dataset is unbalanced, with a minimum of only 101 images in one biological class(Ginkgoopsida), while the maximum number was found to be 2.1 million in another biological class(Magnoliopsida). The various classes, orders, families, genera, and species under each class, are depicted along with their count in Figure <ref type="figure" coords="3,346.46,168.26,3.81,10.91">1</ref>. The "web" dataset consists of 1.1 million images in total, and is also unbalanced in nature. Its largest class is Magnoliopsida, with 0.77 million images, and its smallest class is Ginkgoopsida, with only 25 images in it.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Related works</head><p>On a literature review of the previous year submissions to this shared task, a few well-performing models were observed. In the years from 2014 to 2021, the working notes from the organizers claimed that the external dataset did not actually improve the performance but rather, it was counterproductive owing to it being not properly labelled, of poor quality and introducing a lot of noise into the training dataset.</p><p>In the year 2019, a team named LIRMM from the university of Montepellier <ref type="bibr" coords="4,456.33,179.03,11.58,10.91" target="#b8">[9]</ref>, France modeled a deep convolutional neural network modeled on top of the Inception -v3 model, they trained the model as a classifier, using a cross entropy loss function and a softmax layer to get the output. The team who secured the third place in the same year, were from SSN College and VIT Chennai <ref type="bibr" coords="4,163.58,233.22,19.61,10.91" target="#b9">[10]</ref>. They had used probabilistic models, which say that the probability of encountering a species is proportional to its frequency in the training dataset. They combined it with traditional machine learning techniques like random forest, and XGBoost, and the authors identified 5 different feature groups and trained each one individually using a neural network, and combined them using artificial neural network techniques. A team from Turkey uses SesNet and DensNet pre trained models and uses Error Correcting Output Codes (ECOC) as an ensemble model achieving an accuracy of 87</p><p>Another team from Romania <ref type="bibr" coords="4,235.54,328.07,13.00,10.91" target="#b0">[1]</ref> also took a similar approach, where they used standard machine learning techniques like XGBoost, K-NN, and random forest, and combined them using ensembling techniques.</p><p>On referring to the submissions to the PlantCLEF2020 tasks, we found that a team from the USA <ref type="bibr" coords="4,112.17,382.26,16.27,10.91" target="#b11">[12]</ref>, who had secured the first rank, used a Partial Domain Adaptation (PDA) technique. They used a NASNetLarge pretrained model to extract the features, and then develop a novel Adversarial Consistent Learning (ACL) approach through a unified deep architecture. It combined 3 different loss functions -an adversarial loss, feature consistency loss and source domain classification loss. The adversarial loss aims to learn domain-invariant features while the feature consistent loss helps in preserving the fine-grained feature transition between the two domains.</p><p>Neuron AI who secured the second rank used a triple-loss network <ref type="bibr" coords="4,410.84,463.56,14.63,10.91" target="#b2">[3]</ref>. They used two inception v4, and a ResNet model, which were further fine-tuned in different parts of the dataset. They were then converted into embeddings. They used a cosine function as a distant metric and it was then transformed with Inverse Distance Weighting, into probabilities for ranking the classes. They used many augmentation techniques on the raw dataset, along with ensemble techniques between the triple-loss functions.</p><p>The Costa Rica Institute of Technology (ITCR) <ref type="bibr" coords="4,312.15,544.85,18.03,10.91" target="#b10">[11]</ref> team from Costa Rica and France used Few Shot Adversarial Domain Adaptation (FSADA) approach for a few of their runs. They also used ResNet50 without the final classifier part. <ref type="bibr" coords="4,301.75,571.95,12.92,10.91" target="#b7">[8]</ref> Another team from SSN College also used ResNet50 in a similar manner.</p><p>In the task for the year 2021, only 2 teams had participated. Of those, <ref type="bibr" coords="4,406.62,599.05,13.73,10.91" target="#b1">[2]</ref>one team developed their own model based on a two-streamed Herbarium-Field Triplet Loss Network (HTFL), and trained a complimentary One-Streamed Mixed network (OSM) which is similar to a triple network.</p><p>From the above, we understood that RestNet50 trains faster generally due to its missing net property. It is also used extensively for such classification tasks. Inception v3 could also be used as it shows a higher accuracy rate. So, these transfer learning, pre-trained models could be fine-tuned with the existing training datasets provided and an ensemble could be created between these two models. A probability tree approach could also be employed, where a set of 2000 species under each class are separately trained, and modeled using fine-tuned ResNet50. It is a general rule of thumb in machine learning to counter complex problems by inflating the number of layers in the neural network used. This brings about saturation in the accuracy, leading to the model being degraded. Residual Network model works to obviate this scenario. Such model relies on its fundamental strength in the concept of "skip connections". They are found at the core of the residual blocks, which essentially form the basis used by the deep residual nets to enhance the precision and accuracy of the models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">ResNet50 architecture</head><p>The work of the aforementioned skip connections is twofold: tackling the vanishing gradient problem, and associating an identity function with the model. The vanishing gradient is solved by means of channeling the gradient passage through an alternative short-cut, and subsequently back-propagating them to the earlier layers. The identity function helps the model to show similar levels of performance in the higher layers, as compared to the lower ones. In summation, the residual blocks are instrumental in easing the process of layers learning identity functions. Therefore, ResNet minimizes error occurrences and increases the efficiency of deep neural networks through increased number of neural layers. It starts off with a block of a stack of 3-layer bottleneck block</p><p>The convolution networks in this model have a 3x3 filter. It has 50 weighted layers and achieves a performance of 3.8 bn Floating point operations per second. A flatten layer and a couple dense layer was added on top of it followed by an output layer. The ResNet-50 has over</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experimental Analysis</head><p>The Run 1 is a Single-level Fine-tuned ResNet50 classification. The batch size of the ResNet50 was set to 32, and the Learning Rate was set to 1e-5, and a Sparse categorical cross-entropy was also employed, with an SDG optimizer. The model was set to run for 30 epochs, for which, and 2.4 million images of size 224 x 224 x 3 mm were fed into the model. The model was run on a GPU Tesla V100, and the first epoch took 24 hrs to executewith the runtime seeing a gradual reduction with each passing epoch. The partially trained model gave a Mean Reciprocal Rank (MRR) score of 0, as the datasets it was trained on were highly unbalanced, and no augmentation techniques had been employed either. The second approach is a probability tree built using Multi-level Fine-tuned ResNet50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Techniques used 4.3.1. ResNet50 and InceptionV3</head><p>Our initial approach to this problem was to employ transfer learning techniques with ResNet50 and Inception V3 models which were initialised with pre-trained ImageNet weights. The output layers of both models were flattened and 2 hidden layers (Dense) were added. An output layer consisting of 80000 neurons, representing each species was also appended to the above.</p><p>The pre-trained weights were left untouched, while the new layers were trained on the full trusted dataset, while the web dataset was used for validation. Ultimately, ResNet50 yielded a higher accuracy among the two, thus we picked the model for Run 1. A softmax layer was used to convert the output from the models to probabilities. The species with the top 30 probabilities, averaged across all images of an observation, were taken as the prediction for that observation.</p><p>The use sparse categorical could be pertained to the fact that each plant belongs to one definitive category. The task being a ranking task needed the use of cross entropy as the probability distribution needs to be concentrated, as close to the result as possible On retrospection and re-examination MRR seems like a preferable metric considering this is a ranking task.</p><p>The poor results yielded by this model due to extreme imbalance of the data brought us to the conclusion that a single level general classifier would not suffice for this problem. Thus, we moved onto a multi-level classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Probabilitistic Tree Approach</head><p>A multi-level classification model was used, emulating the taxonomic classification tree, made up of Fine-tuned ResNet50 models, trained on various parts of the dataset, relevant to the node they are in. The probability of a species (a leaf node in the taxonomic tree, is calculated at the product of probabilities of each node on the path from the root to the leaf).  <ref type="figure" coords="7,89.29,466.28,3.81,10.91" target="#fig_0">2</ref>. This taxonomic approach allows us to keep closely related species with similar attributes together, while distancing them from species of wildly different properties. Taking probabilities at each level, instead of deciding on a specific class, allows us to account for errors at each level, and the overall probability computed at the end will serve to mitigate these errors.</p><p>The objective was to identify the top 30 most probable species an observation may belong to. An observation consists of multiple images relating to a single plant species.</p><p>For each individual image, predictions across the whole tree was computed. Since the task was multi-image classification, we had to combine the predictions for multiple images within each observation. We did this by taking the average of all class probabilities for the images within the observation. Then among those, the top 30 relevant classes were picked and ranked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Result</head><p>The ranking metric used during the challenge was the MA-MRR, the MRR averaged by species. The MRR is a statistical metric for assessing any process that generates a list of potential answers to a sample of queries arranged by likelihood that the answers are correct. The multiplicative inverse of the rank of the first accurate response is the reciprocal rank of a query response. For the entire test set, the MRR is the average of the reciprocal ranks:</p><formula xml:id="formula_0" coords="8,243.38,124.87,106.82,34.74">ùëÄ ùëÖùëÖ = 1 |ùëÑ| |ùëÑ| ‚àëÔ∏Å ùëñ=1 1 ùëüùëéùëõùëò ùëñ</formula><p>where |Q| is the total number of query occurrences in the test set.</p><p>The following are the final MRR score achieved from the 3 runs using the probability tree approach and the ResNet50 model table here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>MA MRR Score </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Conclusion</head><p>In this paper we proposed and elaborated on a novel probabilistic approach to solve the plant classification and identification problem given by the organizers <ref type="bibr" coords="8,388.34,336.58,11.59,10.91" target="#b4">[5]</ref>. Our model employed multi level classification using fine tuned ResNet50. We also employed standard CNN models like ResNet50 and Inception v3 which with low parameters did not perform well and took a long time to train. The low score could be due to the unbalanced distribution of data. Further improvements to the model could include training the weights from scratch instead of just fine-tuning the model. Additionally data and image augmentation techniques could be employed to balance the data set, along with better pre-processing of data for more efficient training.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,105.60,475.14,154.60,10.91;3,369.16,483.04,169.17,10.91;3,100.20,496.29,458.36,159.63"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Web Dataset Distribution Figure 3: Trusted Dataset Distribution</figDesc><graphic coords="3,100.20,496.29,458.36,159.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,264.63,667.18,87.83,10.91"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Class Split</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,157.63,303.55,280.02,10.91;5,100.20,316.27,407.46,10.91;5,89.29,329.82,417.90,10.91;5,89.29,343.37,417.90,10.91;5,89.29,356.91,416.69,10.91;5,89.29,370.46,70.88,10.91;5,100.20,384.01,405.78,10.91;5,89.29,397.56,417.89,10.91;5,89.29,411.11,418.37,10.91;5,89.29,424.66,416.70,10.91;5,89.29,438.21,416.69,10.91;5,89.29,451.76,295.13,10.91;5,100.20,465.31,405.78,10.91;5,89.29,478.86,416.70,10.91;5,89.29,492.41,416.98,10.91;5,89.29,505.96,417.09,10.91;5,89.29,519.50,417.90,10.91;5,89.29,533.05,418.38,10.91;5,88.96,546.60,417.02,10.91;5,89.29,560.15,416.69,10.91;5,89.29,573.70,107.39,10.91;5,100.20,587.25,405.79,10.91;5,89.29,600.80,416.69,10.91;5,89.29,614.35,416.90,10.91;5,89.29,627.90,141.73,10.91;5,89.29,203.07,458.37,89.21"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Architecture of ResNet50 including the finetune layer ResNet50 is an innovative variant of the ResNet (Residual Network), which only had 50 layers. It was designed initially and documented in the 2015 computer vision research paper titled, "Deep Residual Learning For Image Recognition", authored by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun[6]. Such a pretrained, transfer learning model was employed to train the model.It is a general rule of thumb in machine learning to counter complex problems by inflating the number of layers in the neural network used. This brings about saturation in the accuracy, leading to the model being degraded. Residual Network model works to obviate this scenario. Such model relies on its fundamental strength in the concept of "skip connections". They are found at the core of the residual blocks, which essentially form the basis used by the deep residual nets to enhance the precision and accuracy of the models.The work of the aforementioned skip connections is twofold: tackling the vanishing gradient problem, and associating an identity function with the model. The vanishing gradient is solved by means of channeling the gradient passage through an alternative short-cut, and subsequently back-propagating them to the earlier layers. The identity function helps the model to show similar levels of performance in the higher layers, as compared to the lower ones. In summation, the residual blocks are instrumental in easing the process of layers learning identity functions. Therefore, ResNet minimizes error occurrences and increases the efficiency of deep neural networks through increased number of neural layers. It starts off with a block of a stack of 3-layer bottleneck blockThe convolution networks in this model have a 3x3 filter. It has 50 weighted layers and achieves a performance of 3.8 bn Floating point operations per second. A flatten layer and a couple dense layer was added on top of it followed by an output layer. The ResNet-50 has over 23 million trainable parameters.</figDesc><graphic coords="5,89.29,203.07,458.37,89.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,209.74,318.08,197.61,10.91;7,100.20,330.79,405.78,10.91;7,89.29,344.34,416.69,10.91;7,89.29,357.89,416.69,10.91;7,89.29,371.44,416.69,10.91;7,89.29,384.99,416.69,10.91;7,89.29,398.54,417.90,10.91;7,89.29,412.09,416.69,10.91;7,89.29,425.64,416.70,10.91;7,89.29,439.18,416.69,10.91;7,89.29,452.73,416.69,10.91;7,89.29,466.28,416.69,10.91;7,89.29,479.83,416.69,10.91;7,89.29,493.38,417.90,10.91;7,89.29,506.93,366.88,10.91;7,100.20,520.48,407.47,10.91;7,88.91,534.03,340.07,10.91;7,100.20,547.58,406.07,10.91;7,88.89,561.13,417.10,10.91;7,89.29,574.68,416.69,10.91;7,88.89,588.23,418.60,10.91;7,100.20,84.19,437.13,222.63"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Architecture of the probability tree The model consists of a 6-level depth tree starting with an abstract root node as the basis of classification, wherein all probabilities start at 1.25e-05. From the root, images are classified into the broadest level of classification, the biological 'class'. A maximum of 2000 images are taken in one level of classification. The given dataset has 8 different classes. The first three classes Cycadopsdia, Ginkgoopsida and Gnetopsida have about 2000 images under them, so they are retained as such, while the last 4 classes, Lycopodiopsida, Magnoliopsida, Pinopsida, and Polypodiopsida have more than 2000, images so they are further divided and classified into the order, family, and genus level. The class Liliopsida has about 5.9 million images, and it comprises the orders Asparagales and Poales, which have a huge number of images, and are separated into a distinct level of classification. These levels of classification are shown in Figure2. This taxonomic approach allows us to keep closely related species with similar attributes together, while distancing them from species of wildly different properties. Taking probabilities at each level, instead of deciding on a specific class, allows us to account for errors at each level, and the overall probability computed at the end will serve to mitigate these errors.The objective was to identify the top 30 most probable species an observation may belong to. An observation consists of multiple images relating to a single plant species.For each individual image, predictions across the whole tree was computed. Since the task was multi-image classification, we had to combine the predictions for multiple images within each observation. We did this by taking the average of all class probabilities for the images within the observation. Then among those, the top 30 relevant classes were picked and ranked.</figDesc><graphic coords="7,100.20,84.19,437.13,222.63" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,108.93,671.04,151.22,8.97"><p>https://www.imageclef.org/LifeCLEF2017</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,476.51,393.32,10.91;8,112.34,490.05,393.64,10.91;8,112.66,503.60,123.15,10.91" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="8,271.03,490.05,234.95,10.91;8,112.66,503.60,58.24,10.91">Plant identification with deep learning ensembles in expertlifeclef</title>
		<author>
			<persName coords=""><forename type="first">Sara</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Berrin</forename><surname>Yanikoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Erchan</forename><surname>Aptoula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ipek</forename><surname>Ganiyusufoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aras</forename><surname>Yƒ±ldƒ±z</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kerem</forename><surname>Yƒ±ldƒ±rƒ±r</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Barƒ±≈ü</forename><surname>Sevilmi≈ü</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>≈ûen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,517.15,393.53,10.91;8,112.66,530.70,370.38,10.91" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,297.72,517.15,208.47,10.91;8,112.66,530.70,326.68,10.91">Improved herbarium-field triplet network for cross-domain plant identification: Neuon submission to lifeclef 2021 plant</title>
		<author>
			<persName coords=""><forename type="first">Sophia</forename><surname>Chulif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Loong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chang</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,544.25,393.33,10.91;8,112.34,557.80,393.64,10.91;8,112.66,571.35,212.02,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,209.61,557.80,296.38,10.91;8,112.66,571.35,141.07,10.91">Plant identication on amazonian and guiana shield flora: Neuon submission to lifeclef 2019 plant</title>
		<author>
			<persName coords=""><forename type="first">Sophia</forename><surname>Chulif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jing</forename><surname>Kiat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Teck</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohammad</forename><forename type="middle">Abdullah</forename><surname>Wei Chan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Al</forename><surname>Monnaf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Loong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chang</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,273.75,572.36,20.40,9.72">CLEF</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,584.90,393.33,10.91;8,112.66,598.45,327.34,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,250.32,584.90,255.66,10.91;8,112.66,598.45,194.90,10.91">Iautomated species identification: why not? philosophical transactions of the royal society of london b</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">J</forename><surname>Gaston</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>O'neill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,314.72,598.45,81.47,10.91">Biological sciences</title>
		<imprint>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,612.00,393.33,10.91;8,112.66,625.55,393.32,10.91;8,112.66,639.10,121.60,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,315.95,612.00,190.04,10.91;8,112.66,625.55,145.89,10.91">Overview of PlantCLEF 2022: Image-based plant identification at global scale</title>
		<author>
			<persName coords=""><forename type="first">Herv√©</forename><surname>Go√´au</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,278.09,626.56,227.90,9.72;8,112.66,640.11,91.12,9.72">Working Notes of CLEF 2022 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,652.65,393.54,10.91;8,112.66,666.19,210.02,10.91" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="8,385.91,652.65,120.29,10.91;8,112.66,666.19,78.78,10.91">Deep residual learning for image recognition</title>
		<author>
			<persName coords=""><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno>CoRR, abs/1512.03385</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,86.97,395.17,10.91;9,112.66,100.52,395.17,10.91;9,112.66,114.06,393.33,10.91;9,112.66,127.61,22.69,10.91" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="9,178.39,114.06,309.62,10.91">Lifeclef 2017 lab overview: Multimedia species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Herv√©</forename><surname>Go√´au</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Herv√©</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Concetto</forename><surname>Spampinatoand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Willem-Pier</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean-Christophe</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Planque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>M√ºller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Simone</forename><surname>Palazzo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,141.16,393.53,10.91;9,112.66,154.71,393.33,10.91;9,112.66,168.26,394.51,10.91;9,112.66,181.81,395.01,10.91;9,112.66,195.36,90.78,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,328.40,141.16,177.79,10.91;9,112.66,154.71,83.78,10.91">Plant species identification using transfer learning -plantclef</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Nanda</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rakesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ram</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="9,183.32,169.28,318.89,9.72">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="9,379.10,182.82,128.56,9.72;9,112.66,195.36,21.79,10.91">CEUR Workshop Proceedings. CEUR</title>
		<editor>
			<persName><forename type="first">Linda</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Carsten</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Aur√©lie</forename><surname>N√©v√©ol</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-09-22">2020. September 22-25, 2020. 2696. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,208.91,393.33,10.91;9,112.48,222.46,395.18,10.91" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="9,176.00,222.46,268.02,10.91">Species recommendation using machine learning -geolifeclef</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">H</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">Praveen</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ram</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Mirunalini</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Aravindan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Jaisakthi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,236.01,393.33,10.91;9,112.66,249.56,207.81,10.91" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="9,263.32,236.01,242.67,10.91;9,112.66,249.56,51.83,10.91">Species recommendation using environment and biotic associations</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">E H M D T T</forename><surname>Si-Moussi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sara</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>proceedings of clef 2019. 09</note>
</biblStruct>

<biblStruct coords="9,112.66,263.11,395.01,10.91;9,112.66,276.66,395.01,10.91;9,112.66,290.20,62.80,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,112.66,276.66,370.33,10.91">Domain adaptation in the context of herbarium collections: A submission to plantclef</title>
		<author>
			<persName coords=""><forename type="first">Juan</forename><surname>Villacis-Llobet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Herv√©</forename><surname>Go√´au</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Erick</forename><surname>Mata-Montero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,124.54,291.22,20.40,9.72">CLEF</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,303.75,393.33,10.91;9,112.66,317.30,209.16,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,279.19,303.75,226.80,10.91;9,112.66,317.30,100.43,10.91">Adversarial consistent learning on partial domain adaptation of plantclef</title>
		<author>
			<persName coords=""><forename type="first">Youshan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brian</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,238.83,317.30,40.23,10.91">challenge</title>
		<imprint>
			<biblScope unit="volume">09</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
