<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,74.30,75.42,446.75,17.04;1,174.50,96.20,246.19,17.04">Assessing Wordplay-Pun classification from JOKER dataset with pretrained BERT humorous models</title>
				<funder ref="#_PYygFsc">
					<orgName type="full">Secretaría de Investigación y Posgrado of the Instituto Politécnico Nacional, Mexico</orgName>
				</funder>
				<funder ref="#_aQAKU8y">
					<orgName type="full">Mexican Government</orgName>
				</funder>
				<funder ref="#_Mum6HYm #_Rh6emsq">
					<orgName type="full">CONACYT, Mexico</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,72.02,129.10,70.18,10.80"><forename type="first">Victor</forename><surname>Manuel</surname></persName>
						</author>
						<author>
							<persName coords="1,145.22,129.10,74.98,10.80"><forename type="first">Palma</forename><surname>Preciado</surname></persName>
							<email>c.palma.p0@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Centro de Investigación en Computación (CIC)</orgName>
								<orgName type="institution">Instituto Politécnico Nacional (IPN)</orgName>
								<address>
									<addrLine>Av. Juan de Dios Batiz, s/n</addrLine>
									<postCode>07320</postCode>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,229.85,129.10,76.32,10.80"><forename type="first">Grigori</forename><surname>Sidorov</surname></persName>
							<email>sidorov@cic.ipn.mx</email>
							<affiliation key="aff0">
								<orgName type="department">Centro de Investigación en Computación (CIC)</orgName>
								<orgName type="institution">Instituto Politécnico Nacional (IPN)</orgName>
								<address>
									<addrLine>Av. Juan de Dios Batiz, s/n</addrLine>
									<postCode>07320</postCode>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,333.07,129.10,119.23,10.80"><forename type="first">Carolina</forename><forename type="middle">Palma</forename><surname>Preciado</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centro de Investigación en Computación (CIC)</orgName>
								<orgName type="institution">Instituto Politécnico Nacional (IPN)</orgName>
								<address>
									<addrLine>Av. Juan de Dios Batiz, s/n</addrLine>
									<postCode>07320</postCode>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">CLEF</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,74.30,75.42,446.75,17.04;1,174.50,96.20,246.19,17.04">Assessing Wordplay-Pun classification from JOKER dataset with pretrained BERT humorous models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1D96707B453CE719D173F48D579631CE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Humor identification</term>
					<term>Transformers</term>
					<term>Humourism</term>
					<term>Classifiers</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Humor is one of the most subjective matters of human behavior since it includes a wide range of variables: sentiments, wordplay, double meanings structurally or phonetic, all of this within the construction of written humor. It is important to assess the humor from a different point of view since this variability tends to provide insight into the true structure or the main core of the humoristic dilemma, as we know the range of humor is so diverse that it presents a high skilled problem even on the simplest tasks. Pre-trained base Bert and DistilBert models trained with a humorous one-liners dataset were used, these trained models were tested with a merged dataset from JOKER from data of tasks 1 and task 3, the collected data was trimmed from duplicated records and special characters to create a final dataset with 3,601 humorous sentences. Under this experiment we try to see if our models were able to detect a different humor from the initial type with which they were trained, it was noted that both methods are able to successfully classify another type of humor. On the one hand, it was expected that the pre-trained models would be able to classify at least a portion of the humor in the data set, the results obtained were much better than anticipated, obtaining 95.64% for BERT and 92.58% for DistilBERT, the models were really able to identify humor, an analysis of the worst and best cases were taken into account.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>As we know, humor has a high written complexity, in addition to its different formats and interpretations, which cause quite a big challenge in the field of NLP, as much as it is in the tasks of classification, interpretation, and translation. In previous work under the classification of written humor, the results were quite good for the set of One liners, which had 3 types of short jokes: the riddle type, the differences type, and a short sentence with a single delivery. These One liners, generally considered as humor, were used to train the BERT-like models and in turn, Emebbedigs such as ELMO and USE with simple networks, although these were surpassed by the BERT-like models.</p><p>Furthermore, we do not know if these models were really able to identify humor as a general concept or only the structure of humor contained in the data set, this leads to the question of whether the capacity of these models is extended to another type of data with humor, in the style of <ref type="bibr" coords="1,422.59,592.89,12.81,9.94" target="#b0">[1]</ref>[2] <ref type="bibr" coords="1,448.20,592.89,12.81,9.94" target="#b2">[3]</ref> that present a high level of typification as does the data set for the JOKER <ref type="bibr" coords="1,332.12,605.61,17.70,9.94" target="#b3">[4]</ref> tasks.</p><p>In this case, we are interested in knowing if the previously trained model has the ability to recognize the humor found in the data set provided in the JOKER <ref type="bibr" coords="1,316.21,630.93,17.76,9.94" target="#b3">[4]</ref> tasks and, therefore, check if this type of model is capable of recognizing another humor, in addition to the approach and vision of what was not classified as humor despite being so.</p><p>This work intends to use the data set of tasks 1 and 3 of JOKER <ref type="bibr" coords="1,355.20,668.88,17.65,9.94" target="#b3">[4]</ref> with a preprocessing step, joining them to have a larger data set, in order to have a better representation of humor in its different forms.</p><p>All this with the intention to check if our methods have a little more validity in terms of the humor type or in certain cases the same humor, therefore, said training could corroborate this type of classification in a certain way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Implementation</head><p>As one of the first steps in the development of the classification, we opted to perform a preprocessing step in which we remove the links, special characters, duplicates, and a very short superficial manual review was made to ensure a certain homogeneity of the conjunction of both sets of data, belonging to tasks 1 and 3. It was chosen a certain portion of the data with the tags [het, hom, pun], with both portions of test and train.</p><p>Of a total of 12,540 humorous texts that we initially had for classification, after trimming we were left with 3,639 texts before doing the manual review, to finally end up with a set of 3,601 registers. Subsequently, the models saved in their Tensorflow format were recovered to be used in the classification, using a wrapper called Ktrain <ref type="bibr" coords="2,263.80,258.88,13.64,9.94" target="#b4">[5]</ref> to easily load our BERT-like models, which in turn will help us determine if the model perceives the probability of any of the 2 events in the classification between humor and non-humor. With the aim of discovering, in the same way, some structure within the new data set that does allow us to enrich the knowledge that we have of our two models about the capabilities and limitations to see if these coincide with the weaknesses present in the original model.</p><p>Once the model was loaded and as part of our classification, the percentage of confidence of belonging to one of the 2 categories (humor-nohumor) was obtained, which were passed through BERThumor <ref type="bibr" coords="2,98.02,347.47,15.60,9.94" target="#b5">[6]</ref> and DistilBERT-humor <ref type="bibr" coords="2,217.03,347.47,15.42,9.94" target="#b5">[6]</ref> models, with which we classify the entire data set. As we know in general, the Tranformers scheme models and specifically the BERT-like ones tend to behave favorably with a sufficient amount of information, in most classification tasks, question-answering, ranking explainability, among others. On the other hand, the ELI5 library was used to obtain a weighted attention on the items to be classified, since it allows us to better visualize the structure we want to study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head><p>After performing the prediction process under the two pre-trained models proposed for the task of identifying humorous text (BERT and DistilBERT), it was found that the BERT model obtained better results since it identified 95.64% of the data set as humor, which means that of the 3,601 sentences in the data set obtained from JOKER, it correctly detected 3,444 records. For its part, DistilBERT although it did not achieve the same performance, obtained good results since 3,334 texts were correctly identified, thus reaching 92.59%. Table <ref type="table" coords="2,247.89,531.69,5.52,9.94" target="#tab_0">1</ref> shows the performance of the two models, and although both managed to distinguish the greatest amount of humorous text, there is a small difference of 110 incorrectly classified records between the two. For the performance of the models employed, which identify whether a text is humorous or not, a function that predicts the class to which they belong was applied and the confidence probability was also calculated for each record to assess how sure the model is that a text really belongs to the humor class. Even though the functions used to calculate the confidence yield values with six tenths, it was decided to make five ranges of 0.2 to present a more visual representation of the obtained data, these results are shown in Figure <ref type="figure" coords="2,193.92,732.12,4.14,9.94">1</ref>.</p><p>The confidence extracted from the predictions made by BERT reflects that for most of the texts the model classified them as humor with certainty greater than 0.8, although for 105 texts they were identified as humor with a score less than 0.2 which implies that the text is not a humorous one, these of cases were the minority. For the ranges between 0.2 to 0.8, lower records were found among the three, which indicates that the model predicts mostly with high confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1: BERT humorous probability classification</head><p>In the case of the DistilBERT model, the results obtained are similar to those found with BERT, since the largest amount of data had high confidence as 3,134 texts reached a value greater than 0.8. On the other hand, the other columns with ranges from 0.2 to 0.8 had a greater amount of data in comparison with BERT, but even so, these represent a smaller group; in comparison, both models present results alike (Figure <ref type="figure" coords="3,132.23,409.03,4.01,9.94">2</ref>). It is worth mentioning that the models recognize as humor texts reach a score above 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2: DistilBERT humorous probability classification</head><p>Once the analysis of the values obtained from the probabilities of each model was carried out, the humorous texts that obtained the best and worst scores were identified in order to visualize which types of writings the models manage to distinguish in a better way compared to the others. Table <ref type="table" coords="3,478.79,706.08,5.52,9.94" target="#tab_1">2</ref> presents the best five humorous texts detected by BERT, it is found that puns (PUN) are the ones that obtained the best probability. It can also be observed that the probability score obtained in confidence is high since it almost reaches 1. Likewise, the results of Table <ref type="table" coords="4,222.72,291.67,4.14,9.94" target="#tab_2">3</ref>, which shows the results of the DistilBERT model, are similar to those described above since they are also mostly puns and texts with the tag HOM, with the difference that DistilBERT has among its best scores text the identification tag HET. For both cases, the best scores are riddle texts which have a question-and-answer format. 0.9996402 HOM There was an eye doctor who wanted to re-locate but couldn't find a job because he didn't have enough contacts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0.9996402</head><p>HET What is the best store to be in during an earthquake? A stationery store.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0.9996401</head><p>On the other hand, for the case of the humorous texts with the worst probabilities presented in Table <ref type="table" coords="4,72.02,508.65,4.14,9.94">4</ref>, the BERT model detected mostly HET and very few HOM and wordplay (puns). As can be seen, the scores obtained were low since they tend to 0, this may be due to the structure of this type of example since in comparison with the best results no riddles are found in the worst rated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 4 Top BERT negative cases</head><p>Tag Humorous text Probability HET Opportunities take ''now'' for an answer 0.0000654 HET Podiatrist malpractice: Callous neglect 0.0001483 HOM Bill Gates took advantage of his Windows of opportunity 0.0001519 HET Exposure to the son may prevent burning 0.0002049 PUN Can honeybee abuse lead to a sting operation? 0.0002278</p><p>In the same way, this phenomenon occurs for the DistilBERT model since among the humorous text with the worst score there are two texts that also appear in results achieved by BERT, such as: Opportunities take ''now'' for an answer and Exposure to the son may prevent burning, this indicates that both models are perceiving the same text as not humorous, which points to a similar detection structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5 Top DistilBERT negative cases</head><p>Tag Humorous text Probability HET Exposure to the son may prevent burning 0.0007237 HET Opportunities take ''now'' for an answer 0.0007271 HET Exposure to the son prevents burning 0.0007380 HOM Could modern submarines be the wave of the future? 0.0007441 HET A budget helps us live below our yearnings 0.0007591</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">ELI5 prospection</head><p>The ELI5 library was used to obtain a certain resemblance to where our BERT-like models classify the humorous point of attention, given that it manages a joint probability, we can observe that in general the humorous sentences that fared better were those of the riddle type, which consists of a question and an answer as the humorous delivery is usually made.</p><p>Bert -humorous texts with the best scores: Why did the pig leave the party early? because everyone thought he was a boar! Why are ghosts bad liars? because you can see right through them! DistilBERT -humorous texts with the best scores: What's the best fruit for avoiding scurvy? Naval oranges, of course.</p><p>What does an angry pepper do? It gets jalapenos face.</p><p>As we can see above, humorous question-and-answer statements had a fairly good rating, since in general this type of text was successfully evaluated. On the other hand, the probability colorations that ELI5 marks make sense since they start with the WH-questions, which is one of the main ways of gathering information, and since in a riddle it is not interesting to reveal a small amount of information, it perfectly fulfills the scheme of attention to delivery after the question taking a darker coloration at the end of the sentence for both the question and answer.</p><p>Bert -humorous texts with the worst scores: Opportunities take ''now'' for an answer Podiatrist malpractice: Callous neglect DistilBERT -humorous texts with the worst scores: Exposure to the son may prevent burning Opportunities take ''now'' for an answer On the other hand, the sentences that did worse turned out to have a certain pattern, since if we try to look closely these sentences could very well allude to the title of a review or article, given their content between serious and humorous seemed to confuse the decision of the model, when it comes to classification. It seems that the model, given the coloration, focuses on nouns such as Opportunities, Malpractice and Exposure to classify the text as something that does not contain humor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>The pre-trained models used in this work that addresses the subject of humorous text identification, managed to detect the majority of the data set obtained from JOKER as humor with a good outcome for both models. It should be noted that it seems that the opposite or negative part (the data set previously used to train the models) strongly affects the result, that is, the non-humorous part of the data set.</p><p>The paradigm of the models based on Transformers tend to classify humorous texts well, in this case, BERT and DistilBERT manage to classify humorous texts with high probabilities. A tendency was also found for the models to identify with better scores the riddles that were found in the data set as puns, as opposed to the other types of examples. Therefore, it is obtained that the structure of the humorous text strongly influences its identification.</p><p>On the one hand, it is not surprising that it behaved favorably with the JOKER data set, since the humor contained in it in certain aspects becomes very similar to a certain extent to the humor with which these models were trained, it should be noted that Certain curiosities were found within the best and worst classified elements, certain patterns that have a lot to do with the counterpart of the humor with which it was trained, giving a view of some weaknesses and strengths of the models that will be explained later.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" coords="3,125.15,122.60,344.76,206.90"><head></head><label></label><figDesc></figDesc><graphic coords="3,125.15,122.60,344.76,206.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="3,132.25,444.22,344.65,207.77"><head></head><label></label><figDesc></figDesc><graphic coords="3,132.25,444.22,344.65,207.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,72.02,581.83,445.97,68.52"><head>Table 1</head><label>1</label><figDesc></figDesc><table coords="2,72.02,595.27,445.97,55.08"><row><cell>BERT-like models performance</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Models</cell><cell>Performance</cell><cell>Correctly detected</cell><cell>Incorrectly detected</cell></row><row><cell>BERT</cell><cell>95.64%</cell><cell>3,444</cell><cell>157</cell></row><row><cell>DistilBERT</cell><cell>92.58%</cell><cell>3,334</cell><cell>267</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,72.02,137.42,444.86,135.60"><head>Table 2 Top</head><label>2</label><figDesc></figDesc><table coords="4,76.70,150.86,440.18,122.16"><row><cell>BERT positive cases</cell><cell></cell><cell></cell></row><row><cell>Tag</cell><cell>Humorous text</cell><cell>Probability</cell></row><row><cell cols="2">PUN Why did the pig leave the party early? Because everyone thought he was a</cell><cell>0.9999985</cell></row><row><cell>boar!</cell><cell></cell><cell></cell></row><row><cell cols="2">PUN Why are ghosts bad liars? Because you can see right through them!</cell><cell>0.9999982</cell></row><row><cell cols="2">HOM Why don't people like to talk to garbage men? They mostly talk trash.</cell><cell>0.9999981</cell></row><row><cell cols="2">PUN Why don't sharks eat clowns? Because they taste funny.</cell><cell>0.9999980</cell></row><row><cell cols="2">PUN Why did the student eat his homework? Because the teacher told him it was</cell><cell>0.9999980</cell></row><row><cell>a piece of cake!</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,72.02,355.13,444.86,81.96"><head>Table 3 Top</head><label>3</label><figDesc></figDesc><table coords="4,78.62,368.57,438.26,68.52"><row><cell>DistilBERT positive cases</cell><cell></cell><cell></cell></row><row><cell>Tag</cell><cell>Humorous text</cell><cell>Probability</cell></row><row><cell cols="2">PUN What's the best fruit for avoiding scurvy? Naval oranges, of course.</cell><cell>0.9996407</cell></row><row><cell cols="2">PUN What does an angry pepper do? It gets jalapenos face.</cell><cell>0.9996404</cell></row><row><cell cols="2">PUN What do you call a duck that gets all A's? A wise quacker.</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5.">Acknowledgements</head><p>The work was done with partial support from the <rs type="funder">Mexican Government</rs> through the grant <rs type="grantNumber">A1-S-47854</rs> of <rs type="funder">CONACYT, Mexico</rs>, grants <rs type="grantNumber">20220852</rs> and <rs type="grantNumber">20220859</rs> of the <rs type="funder">Secretaría de Investigación y Posgrado of the Instituto Politécnico Nacional, Mexico</rs>. The authors thank the <rs type="institution">CONACYT</rs> for the computing resources brought to them through the <rs type="institution">Plataforma de Aprendizaje Profundo para Tecnologías del Lenguaje of the Laboratorio de Supercómputo of the INAOE, Mexico</rs> and acknowledge the support of Microsoft through the <rs type="grantName">Microsoft Latin America PhD Award</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_aQAKU8y">
					<idno type="grant-number">A1-S-47854</idno>
				</org>
				<org type="funding" xml:id="_Mum6HYm">
					<idno type="grant-number">20220852</idno>
				</org>
				<org type="funding" xml:id="_Rh6emsq">
					<idno type="grant-number">20220859</idno>
				</org>
				<org type="funding" xml:id="_PYygFsc">
					<orgName type="grant-name">Microsoft Latin America PhD Award</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,93.38,461.61,429.95,9.94;6,93.38,474.33,429.92,9.94;6,93.38,486.93,211.59,9.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,281.10,461.61,242.23,9.94;6,93.38,474.33,80.76,9.94">Making computers laugh: investigations in automatic humor recognition</title>
		<author>
			<persName coords=""><forename type="first">Mihalcea</forename><surname>Rada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Strapparava</forename><surname>Carlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,199.12,474.33,324.19,9.94;6,93.38,486.93,127.71,9.94">Conference on Human Language Technology and Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="531" to="538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,93.38,499.53,429.79,9.94;6,93.38,512.25,174.55,9.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,164.97,499.53,358.20,9.94;6,93.38,512.25,44.64,9.94">The Unuttered Punch Line: Pragmatic Incongruity and the Parsing of &apos;What&apos;s the Difference</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">E L</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,145.18,512.25,22.61,9.94">Jokes</title>
		<imprint>
			<date type="published" when="2009-12-03">3 December 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,93.38,524.85,430.16,9.94;6,93.38,537.57,430.15,9.94;6,93.38,550.17,276.16,9.94" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,252.08,524.85,248.00,9.94">The rJokes Dataset: a Large Scale Humor Collection</title>
		<author>
			<persName coords=""><forename type="first">Orion</forename><surname>Weller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Seppi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,93.38,537.57,331.78,9.94">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6136" to="6141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,93.38,562.77,430.02,9.94;6,93.38,575.38,429.84,10.05;6,93.38,588.09,429.92,9.94;6,93.38,600.81,429.74,9.94;6,93.38,613.41,370.53,9.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,128.04,588.09,318.90,9.94">CLEF Workshop JOKER: Automatic Wordplay and Humour Translation</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Puchalski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Regattin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">É</forename><surname>Mathurin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-G</forename><surname>Bosser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bokiniec</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L</forename><surname>Corre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Jeanjean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hannachi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ġ</forename><surname>Mallia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Saki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,466.15,600.81,56.98,9.94;6,93.38,613.41,95.68,9.94">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Hagen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Verberne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Seifert</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Nørvåg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Setty</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13186</biblScope>
			<biblScope unit="page" from="355" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,93.38,626.01,430.12,9.94;6,93.38,638.73,72.82,9.94" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="6,156.75,626.01,290.43,9.94">Ktrain: A Low-Code Library for Augmented Machine Learning</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">S</forename><surname>Maiya</surname></persName>
		</author>
		<idno>ArXiv, abs/2004.10703</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,93.38,651.25,430.10,10.05;6,93.38,664.08,429.93,9.94" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">M</forename><surname>Palma</surname></persName>
		</author>
		<title level="m" coord="6,163.29,651.25,181.21,10.04">Automatic Detection of Jokes in Texts</title>
		<meeting><address><addrLine>Ciudad de México, México</addrLine></address></meeting>
		<imprint>
			<publisher>Centro de Investigación en Computación (CIC)</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
		<respStmt>
			<orgName>Instituto Politécnico Nacional (IPN)</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
