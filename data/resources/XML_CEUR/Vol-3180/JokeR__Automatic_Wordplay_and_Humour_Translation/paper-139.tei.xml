<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,335.39,15.42">Humorous Wordplay Generation in French</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,113.06,70.18,11.96"><forename type="first">Loic</forename><surname>GlÃ©marec</surname></persName>
							<email>loic.glemarec1@etudiant.univ-brest.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">UniversitÃ© de Bretagne Occidentale</orgName>
								<address>
									<settlement>Brest</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,172.11,113.06,101.14,11.96"><forename type="first">Anne-Gwenn</forename><surname>Bosser</surname></persName>
							<email>bosser@enib.fr</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Lab-STIC CNRS UMR6285</orgName>
								<orgName type="institution">ENIB</orgName>
								<address>
									<settlement>Brest</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,285.90,113.06,67.15,11.96"><forename type="first">Julien</forename><surname>Boccou</surname></persName>
							<email>julien.boccou@etudiant.univ-brest.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">UniversitÃ© de Bretagne Occidentale</orgName>
								<address>
									<settlement>Brest</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,384.05,113.06,79.43,11.96"><forename type="first">Liana</forename><surname>Ermakova</surname></persName>
							<email>liana.ermakova@univ-brest.fr</email>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">UniversitÃ© de Bretagne Occidentale</orgName>
								<orgName type="institution" key="instit2">HCTI</orgName>
								<address>
									<settlement>Brest</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Maison des sciences de l&apos;homme en Bretagne</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,335.39,15.42">Humorous Wordplay Generation in French</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">C67D8DD7CE8C4D4E7B428E903CC783D1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Computational Humour</term>
					<term>Humour generation</term>
					<term>Wordplay</term>
					<term>Wellerism</term>
					<term>Word embedding</term>
					<term>Lexique 3</term>
					<term>Large pre-trained models</term>
					<term>Few-shot learning</term>
					<term>Computational creativity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent work have tackled the problem of generating puns in English, based on the corpus of English puns from SemEval 2017 Task 7. In this paper, we report on experiments on generating French puns based on the data released for the CLEF 2022 JOKER and inspired by methods for generating English puns with large pretrained models. 50% of generated wellerisms were funny.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Humour aims to provoke laughter and provide amusement. The appropriate use of humour can facilitate social interactions <ref type="bibr" coords="1,228.52,377.19,12.69,10.91" target="#b0">[1]</ref> as it can reduce awkward, uncomfortable, or uneasy feelings. Humour contributes to higher physical and psychological wellbeing and has shown to be effective to cope with distress <ref type="bibr" coords="1,225.47,404.29,11.51,10.91" target="#b1">[2]</ref>. Indeed, according to the benign-violation theory, 'humour only occurs when something seems wrong, unsettling, or threatening, but simultaneously seems okay, acceptable or safe' <ref type="bibr" coords="1,198.82,431.39,11.35,10.91" target="#b2">[3]</ref>. Wordplay is a common source of humor because of its subversive and catchy nature. Recent work by <ref type="bibr" coords="1,243.51,444.94,12.69,10.91" target="#b3">[4]</ref> have tackled the issue for generating humourous puns in English based on the data provided by <ref type="bibr" coords="1,260.90,458.49,11.38,10.91" target="#b4">[5]</ref>. The CLEF Joker Workshop <ref type="bibr" coords="1,400.38,458.49,11.32,10.91" target="#b5">[6,</ref><ref type="bibr" coords="1,414.42,458.49,8.93,10.91" target="#b6">7]</ref> provided a similar dataset for the French language, and allowed us to investigate how well this method could be transposed in French. In the work by <ref type="bibr" coords="1,274.94,485.58,11.58,10.91" target="#b3">[4]</ref>, the goal is to generate puns in English, relying on paronyms and a modification of the context of the sentence to create surprise, resolving the incongruity that will result in the humourous effect, by applying the pun at the end of sentences. Despite the generality of this principle, most of the published work that we could find on computational humor generation remains primarily for the English language. The work described in <ref type="bibr" coords="1,145.07,553.33,12.72,10.91" target="#b7">[8]</ref> makes use of constraints to provide structurally correct and successfully funny wordplay. Their approach, which rely less on statistical linguistic resources than the most recent literature, seems appropriate for languages other than English for which these might currently be less performing. It was also an inspiration for our work.</p><p>In this paper we show how to generate puns for the French language and that the method works for English as well. We describe a three-steps method: first, we select the word on which to apply wordplay; second, we select one of the most distant homophone semantically, and finally, we look for a novel context consistent with the homophone operated by prediction using a large language model. Using this method, we were able to generate grammatically but also structurally correct wordplay sentences (eg. following the expected pattern or template). Although we have not yet completed a full evaluation of the output, we curated a number of potentially humorous results some of which are provided in this paper.</p><p>The incongruity of the expected and given stimuli is also used in wellerisms which exploits the contradiction of figurative and literal meanings. Wellerisms are wordplays that make fun of established clichÃ©s and proverbs in a context where they are taken literally <ref type="bibr" coords="2,445.21,249.56,11.58,10.91" target="#b8">[9]</ref>. Thus, we also explore the effectiveness of large pre-trained models, such as GPT-3 <ref type="bibr" coords="2,422.05,263.11,16.42,10.91" target="#b9">[10]</ref>, for wellerism generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">5-step wordplay generation</head><p>Our goal is to generate wordplay based on homophones from a simple sentence without any sense of humor. Wordplay generation is built in 5 distinct steps. To do this, we must first locate the word on which to apply the wordplay: ğ‘¤ ğ‘ğ‘–ğ‘ğ‘˜ (PICK). Then, when we have selected a word, we search the list of all its homophones and select one: ğ‘¤ ğ‘ ğ‘¤ğ‘ğ‘ (SWAP). There is a subject detection step: ğ‘¤ ğ‘ ğ‘¢ğ‘ğ‘—ğ‘’ğ‘ğ‘¡ (SUBJECT). To accentuate the humorous effect we need to change the topic to correspond to ğ‘¤ ğ‘ ğ‘¤ğ‘ğ‘ so that the context is consistent: ğ‘¤ ğ‘¡ğ‘œğ‘ğ‘–ğ‘ (TOPIC). Finally, once all these generation elements have been brought together, it is possible to rebuild the sentence in the pun format (REBUILD).</p><p>PICK For the word selection, we started by listing all the adjectives and nouns of the sentence. For this we use the lexicon Lexique 3 for the French language <ref type="bibr" coords="2,359.26,492.32,16.30,10.91" target="#b10">[11,</ref><ref type="bibr" coords="2,378.16,492.32,12.23,10.91" target="#b11">12]</ref>. We proceeded iteratively and looked for homophones with the same part of speech (adjectives, nouns,...). To ensure grammatical correctness, we limited the selection to words that do not have two possible part of speech for the same spelling. When this is the case, the word is qualified as ambiguous and will therefore not be included in the list of possible targets for wordplay. We check the number of homophones that is information given by Lexique 3. If a noun or adjective does not have at least one homophone, it is also removed from the list. Finally, when several words are found to have homophones in the sentence, we select the word closest to the end. This choice is made in order to maximise the surprise and thus the potential comic effect, following the argument in the original paper by <ref type="bibr" coords="2,185.41,614.26,11.43,10.91" target="#b3">[4]</ref>. SWAP Before proceeding with the exchange, we first listed all the homophones by comparing their phonetic form which is provided as part of Lexique 3. We also added constraints to improve the selection with other key information:</p><p>â€¢ Flag 1 : The lemmatized form must not be the same as the initial word ğ‘¤ ğ‘ğ‘–ğ‘ğ‘˜ .</p><p>â€¢ Flag 2 : The homophone part of speech must be the same as that of the initial word ğ‘¤ ğ‘ğ‘–ğ‘ğ‘˜ .</p><p>This allows to keep the grammatical coherence. â€¢ Flag 3 : The frequency of occurrence of the homophone must be greater than 2, this information is also given using Lexique 3. Indeed, the two fields freqlemfilms and freqlemlivres respectively represent the frequency of the lemma according to a corpus of subtitles and the frequency of the lemma according to a corpus of books (both are given per million occurrences). This avoids replacing with a word too little known and therefore creates a feeling of incomprehension.</p><p>When these three conditions are met, but there are still several possible homophones, the ğ‘¤ ğ‘ ğ‘¤ğ‘ğ‘ will be the homophone that is the most semantically distant from ğ‘¤ ğ‘ğ‘–ğ‘ğ‘˜ . The choice of a semantically distant word permits the selection of the one that will have the most distant context possible. By doing this, the comic effect will be accentuated by an increased surprise.</p><p>To compare the semantic distance of words, we use the French version of fasttext <ref type="bibr" coords="3,459.14,270.47,17.79,10.91" target="#b12">[13]</ref> <ref type="foot" coords="3,476.93,268.72,3.71,7.97" target="#foot_0">1</ref> . This model allows mapping a word to a vector value. The comparison is done by measuring the distance between two word-vectors. The greater the distance, the more semantically distant the two words are. To calculate the distance, we compute the cosine value of the angle formed by the two vectors.</p><p>When these operation are successfully completed, we end up with one homophone (ğ‘¤ ğ‘ ğ‘¤ğ‘ğ‘ ) that will provide a grammatically correct substitution and will maximise the humourous potential. The next step is to provide a topic change in the sentence.</p><p>SUBJECT Before topic change in the sentence, we need to detect the subject (ğ‘¤ ğ‘ ğ‘¢ğ‘ğ‘—ğ‘’ğ‘ğ‘¡ ). It is is achieved through Jurassic<ref type="foot" coords="3,216.58,405.39,3.71,7.97" target="#foot_1">2</ref>  <ref type="bibr" coords="3,223.54,407.14,16.41,10.91" target="#b13">[14]</ref>, a Large Language Model. To do so, we provide the model with several examples (see in A) of sentences while highlighting their subject. This information will be use in next step and will permit a better generation precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TOPIC</head><p>The sentence topic change is also operated through Jurassic. As in the research we based our proposal on, the topic change is made by changing a word in the sentence. As in previous step, we provide the model with several examples (B), which were constructed using the dataset from the CLEF 2022 Joker Workshop <ref type="bibr" coords="3,310.21,503.16,12.99,10.91" target="#b5">[6]</ref> then we request the prediction of a new topic for the setup provided by the previous steps for some other example from the test dataset. Intending to guide the prediction toward what we are interested in, i.e. consistency between the new homophone and the topic, we give as information:</p><p>â€¢ The initial sentence â€¢ The ğ‘¤ ğ‘ğ‘–ğ‘ğ‘˜ word â€¢ The ğ‘¤ ğ‘ ğ‘¤ğ‘ğ‘ homophone â€¢ The ğ‘¤ ğ‘ ğ‘¢ğ‘ğ‘—ğ‘’ğ‘ğ‘¡ to change We asked for the generation of 15 predictions. This is followed by the removal of duplicates before selecting the subject (ğ‘¤ ğ‘¡ğ‘œğ‘ğ‘–ğ‘ ) most semantically close to ğ‘¤ ğ‘ ğ‘¤ğ‘ğ‘ . REBUILD Finally, it is now possible to reconstruct the pun. Again thanks to Jurassic and providing the following information (C):</p><p>â€¢ The initial sentence â€¢ The ğ‘¤ ğ‘ ğ‘¢ğ‘ğ‘—ğ‘’ğ‘ğ‘¡ word â€¢ The ğ‘¤ ğ‘¡ğ‘œğ‘ğ‘–ğ‘ word</p><p>The pun is therefore similar with respect to the initial sentence, but the subject ğ‘¤ ğ‘ ğ‘¢ğ‘ğ‘—ğ‘’ğ‘ğ‘¡ has been changed to ğ‘¤ ğ‘¡ğ‘œğ‘ğ‘–ğ‘ to ensure contextual consistency with the homophone ğ‘¤ ğ‘ ğ‘¤ğ‘ğ‘ of the word ğ‘¤ ğ‘ğ‘–ğ‘ğ‘˜ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Wellerism generation with large pre-trained models</head><p>Wellerisms are wordplay that make use of catchphrases, phrases or expressions recognized by their repeated utterance. Wellerisms are a common type of wordplay with recognizable conventional form which helps to prepare a joke. We generated the following types of wellerisms that were:</p><p>â€¢ Question-Answer. This type of wellerisms refers to bipartite jokes with the form of a question followed by an answer.</p><p>Example 2.1. Qu'est-ce que l'Ã©tudiant dit Ã  la calculatrice? Tu comptes beaucoup pour moi.</p><p>â€¢ Old soldiers never die wellerisms are transformations of the catchphrase, with the full version being Old soldiers never die, they simply fade away.</p><p>Example 2.2. Les vieux Ã©lectriciens ne meurent pas, ils 100 volts.</p><p>â€¢ Tom swifty are wellerisms with a phrase in which a quoted sentence is linked by a pun to the manner in which it is attributed. The standard form is for the quoted sentence to be first, followed by the description of the act of speaking of the conventional speaker Tom Example 2.3. "J'ai commencÃ© Ã  lire Voltaire", avoua Tom d'un ton candide.</p><p>To generate these types of wellerisms, we used prompt-tuning of large-pretrained models, namely GPT-3 <ref type="bibr" coords="4,157.66,531.73,16.41,10.91" target="#b9">[10]</ref>. Discrete prompt-tuning is a widely-used technique to condition frozen language models to perform specific downstream tasks <ref type="bibr" coords="4,337.49,545.28,16.28,10.91" target="#b14">[15]</ref>. We considered the generation of each type of these wellerisms as an individual task. The prompts were generated automatically based on the data in French constructed at the JOKER workshop <ref type="bibr" coords="4,168.25,585.93,11.23,10.91" target="#b5">[6,</ref><ref type="bibr" coords="4,182.21,585.93,7.49,10.91" target="#b6">7]</ref>. We applied regular expressions to extract Question-Answer, Old soldiers never die and Tom swifty wellerisms from the corpus. We generated a training prompt for each category by randomly selecting small training set from the corresponding subcorpus, i.e. we used three distinct training prompts in total. The same training prompt was applied for all generations. As all these wellerisms are bipartite, we split wordplay into to parts and we used the first part of each wordplay for the generation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Evaluation framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data description</head><p>Our data is twofold, containing human and machine translations of the SemEval-2017 corpus of English puns <ref type="bibr" coords="5,149.77,361.94,12.84,10.91" target="#b4">[5]</ref> into French <ref type="bibr" coords="5,219.20,361.94,11.43,10.91" target="#b6">[7]</ref>.</p><p>The 5-step wordplay generation aims to transform a non-humorous text into wordplay. Thus, the source corpus should without wordplay but with a potential to do it. With this consideration in mind, we used machine translations generated by the participants of JOKER Task 3: Pun translation from English into French <ref type="bibr" coords="5,255.99,416.13,11.58,10.91" target="#b6">[7]</ref>. We used only the machine translations that were annotated not to contain wordplay. The initial non-wordplay corpus consisted of 6 780 texts. As machine translations of the same source text might be quite similar, we dropped entries with duplicated identifiers of source puns in English and, thus, kept only one machine translation per English pun. Then, we filtered out texts for which we could not find homophones in Lexique-3.</p><p>The French wordplay subcorpus used for wellerism generation is a subset of human translations of the SemEval-2017 English puns <ref type="bibr" coords="5,261.49,497.43,12.68,10.91" target="#b4">[5]</ref> produced during at the JOKER translation contest <ref type="bibr" coords="5,492.63,497.43,11.28,10.91" target="#b6">[7]</ref>. We used a small subset for the training part of the prompt and 40-50 examples for generation. Although it is impossible to use a direct comparison of test data with generation for the evaluation due to multiple ways to play on words, the use of joke parts guarantee the possibility of wordplay. The details of the data statistics is given in Table <ref type="table" coords="5,346.91,551.62,3.66,10.91" target="#tab_1">2</ref>. Although, the corpus contains 272 Old soldiers never die wellerisms, we found only 50 distinct subject. Thus, we used 10 subjects for training and 40 subjects for test wellerism generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Annotation and evaluation metrics</head><p>A master student in translation, French native speaker, manually annotated the produced generation according to the following binary categories:</p><p>â€¢ wordplay presence; â€¢ non-sens;</p><p>â€¢ truncated text;</p><p>â€¢ syntax problem;</p><p>â€¢ lexical problem.</p><p>We applied the Likert scale <ref type="bibr" coords="6,212.22,290.16,17.94,10.91" target="#b15">[16]</ref> to evaluate joke hilariousness. We applied the scale from 0 to 5 referring to humorless and the funniest texts respectively. The annotator was also asked to provide free comment on jokes.</p><p>We report absolute values as well as the percentage of wordplay in generated texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>Table <ref type="table" coords="6,115.84,389.43,5.08,10.91" target="#tab_2">3</ref> shows the results of generation. The generation for the category Old soldiers never die was the most successful, with 65% wordplay produced. Notice that this category is the most homogeneous, as the beginning varies only in the subject. We observe a significant drop (twice lower wordplay rate) for the Tom swifty jokes which has a more heterogeneous form and the lowest results were demonstrated for the Question-Answer type as their form is the less strict. Figure <ref type="figure" coords="6,131.12,457.18,5.05,10.91">1</ref> presents the histogram of the hilariousness scores of generated wellerisms. Almost 50% of generated wellerisms were judged funny by the French native speaker annotator, i.e. they were attributed a hilariousness score &gt;= 1. The most successful jokes were Tom swifty while the vast majority of Question-Answering were judged non-humorous. Question-Answering was the most heterogeneous category.</p><p>The statistics on free category for generated wellerisms is given in Table <ref type="table" coords="6,428.31,524.93,3.77,10.91" target="#tab_3">4</ref>. As it is evident from the table, the Old soldiers never die wellerisms are considered to be euphemisms in 90% of cases.</p><p>Deadpans occur in Question-Answer jokes. Deadpan, also called dry or dry-wit humor, is a form of comedic delivery with the deliberate display of emotional neutrality contrasting with the ridiculousness or absurdity of the subject matter <ref type="bibr" coords="6,329.65,592.67,16.42,10.91" target="#b16">[17]</ref>. The delivery is meant to be blunt, ironic, or unintentional. We do not observe deadpans in Tom swifty nor Old soldiers never die wellerisms as they do not have interaction with interlocutor nor environment.</p><p>The results generated using the 5-stepts method are grammatically correct and structurally correspond to our expectations: the PICK phase keeps the part of speech of the word, and discards ambiguous words on this subject. This limits the number of grammatically false results, which could harm the humorous effect. The homophonic criteria being easy to use with a phonetic lexicon and providing obvious wordplay. These may limit the potential generation when compared to computing paronyms.</p><p>In D, you can find examples of puns we created. Each box contains an original sentence, as well as the built pun. These examples are also used for prompts for jurassic. Then, in E, you can find the test sentences that fulfill constraints. Sentences in F are all tagged as ambiguous, (The walrus said goodbye to its sea.)</p><p>â€¢ Seau / Sot (Bucket/Fool) Original sentence : L'ouvrier a fait tomber un seau.</p><p>(The worker dropped a bucket.) Generated : Un casse-tÃªte a fait tomber un sot.</p><p>(A puzzle knocked down a fool.)</p><p>The current implementation is a proof of concept, and the generativity of the solution could be improved in several ways.</p><p>The PICK phase provides coherence, but restricted to certain part of speech and forms of word for simplicity. We will later improve the range of homophones that can be used. We also plan to provide more variety during the SWAP phase, by expanding the puns to include paronyms instead of the restricted case of homophones. This led us to wonder about what criteria to use for deciding when and how paronyms are perceived and understood by humans. Whilst the answer to this question is likely to be context specific, skill specific (such as in ContrepÃ¨terie/spoonerism identification) and depend on the media used to communicate the pun (script, voice), we can already consider several criteria to take into account in identifying which words may be likened by humans in understanding puns, for instance: phonetic transcription closeness (Hamming distance), similar number of syllables, similar structure in terms of vowels and consonants, rhymes.</p><p>We plan to investigate whether and to which extent various types of punning criteria allow us to generate more varied and less obvious puns, which may render them more satisfying depending on the human audiences. Finally, the TOPIC step of our method was merely a first investigation of Large Language Models and can certainly be improved, especially in terms of contextual relevance between the homophone and the new topic. We plan to look for more effective prompts, to influence Jurassic's prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have presented the results of first investigations for generating humorous puns in French using large pre-trained language models. The first method is based on work previously done for the English language, with some adaptation to account for linguistic resources available for the French language. Our method proceeds in five steps which will transform a sentence: the PICK step quickly selects the target word for the pun, the SWAP step defines whether the word is replaceable by a homophone, the SUBJECT step retrieves the input sentence subject, the TOPIC step which, thanks to the Jurassic model, predicts a new, contextually coherent topic for the original sentence, and the REBUILD step build the final pun with Jurassic too. We have presented a few encouraging results. We plan to investigate this topic further: in particular we would like to work on extending puns to include a variety of structures and heuristics that humans use to recognize paronyms in punning, and try out different models. We also tried out the generation of wellerism using the GPT-3 Model, with prompt-tuning using puns sharing similar templates, with promising results. 50% of generated wellerisms were funny.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Online Resources</head><p>The sources for the generation of humorous puns in French are available via â€¢ GitLab : https://gitlab.com/loicgle/computational-humor-pun-generation,</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,89.29,291.22,295.64,8.93"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Histogram of the hilariousness scores of generated wellerisms</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="11,89.29,373.96,416.70,282.09"><head></head><label></label><figDesc></figDesc><graphic coords="11,89.29,373.96,416.70,282.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="13,89.29,110.27,416.70,331.04"><head></head><label></label><figDesc></figDesc><graphic coords="13,89.29,110.27,416.70,331.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="14,89.29,110.27,416.69,197.08"><head></head><label></label><figDesc></figDesc><graphic coords="14,89.29,110.27,416.69,197.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="14,89.29,356.79,416.69,127.72"><head></head><label></label><figDesc></figDesc><graphic coords="14,89.29,356.79,416.69,127.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="14,89.29,533.95,416.69,127.72"><head></head><label></label><figDesc></figDesc><graphic coords="14,89.29,533.95,416.69,127.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,88.99,90.49,411.02,81.83"><head>Table 1</head><label>1</label><figDesc>Statistics of data used for 5-step generation</figDesc><table coords="5,95.27,122.05,404.74,50.26"><row><cell>Step</cell><cell cols="3"># requests number # train instances # output</cell></row><row><cell>TOPIC</cell><cell>1</cell><cell>5</cell><cell>15</cell></row><row><cell>SUBJECT</cell><cell>1</cell><cell>6</cell><cell>1</cell></row><row><cell>REBUILD</cell><cell>1</cell><cell>5</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,88.99,194.57,411.02,81.83"><head>Table 2</head><label>2</label><figDesc>Statistics of data used for wellerism generation</figDesc><table coords="5,95.27,226.14,404.74,50.26"><row><cell>Wellerism category</cell><cell cols="3"># train instances # test instances # total in corpus</cell></row><row><cell>Question-Answer</cell><cell>20</cell><cell>50</cell><cell>392</cell></row><row><cell>Old soldiers never die</cell><cell>10</cell><cell>40</cell><cell>272</cell></row><row><cell>Tom swifty</cell><cell>20</cell><cell>50</cell><cell>503</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.99,90.49,411.02,105.74"><head>Table 3</head><label>3</label><figDesc>Results of generation</figDesc><table coords="6,95.27,122.02,404.74,74.20"><row><cell>Category</cell><cell cols="3">Wordplay Non-sens Truncated</cell><cell>Syntax</cell><cell>Lexical</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">problem problem</cell></row><row><cell>Question-Answer</cell><cell>8 (15%)</cell><cell>9</cell><cell>2</cell><cell>2</cell><cell>5</cell></row><row><cell>Tom swifty</cell><cell>15 (30%)</cell><cell>0</cell><cell>0</cell><cell>11</cell><cell>8</cell></row><row><cell>Old soldiers never die</cell><cell>26 (65%)</cell><cell>6</cell><cell>0</cell><cell>1</cell><cell>3</cell></row><row><cell>5-step</cell><cell>7(8%)</cell><cell>49</cell><cell>0</cell><cell>2</cell><cell>9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,88.99,90.49,416.99,390.98"><head>Table 4</head><label>4</label><figDesc>Free category statistics for generated wellerisms Le marin au milieu de rien, a jetÃ© son ancre. (The sailor in the middle of nothing, dropped his anchor.) Generated : Le poÃ¨te au milieu de rien, a jetÃ© son encre. (The poet in the middle of nothing, threw his ink.)</figDesc><table coords="8,89.29,121.99,416.69,249.80"><row><cell cols="3">Category Blunt Absurdism</cell><cell cols="2">Jokes Euphemism</cell><cell cols="2">Dark Deadpan</cell><cell cols="2">One Poetic</cell></row><row><cell></cell><cell></cell><cell></cell><cell>for Kids</cell><cell></cell><cell>humor</cell><cell></cell><cell>liner</cell><cell></cell></row><row><cell>QA</cell><cell>.</cell><cell>3</cell><cell>3</cell><cell>.</cell><cell>2</cell><cell>5</cell><cell>1</cell><cell>.</cell></row><row><cell>Tom</cell><cell>2</cell><cell>4</cell><cell>.</cell><cell>.</cell><cell>.</cell><cell>.</cell><cell>.</cell><cell>.</cell></row><row><cell>Old</cell><cell>2</cell><cell>.</cell><cell>.</cell><cell>36</cell><cell>.</cell><cell>.</cell><cell>2</cell><cell>3</cell></row><row><cell>5-step</cell><cell>.</cell><cell>1</cell><cell>.</cell><cell>.</cell><cell>.</cell><cell>.</cell><cell>.</cell><cell>.</cell></row><row><cell cols="9">even if they seem to be structurally encouraging, each one contains words that have known</cell></row><row><cell cols="4">homophones adequately placed in the sentences.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Here are selected results:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">â€¢ Comte / Compte (Count/Account)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">Original sentence : Nous avons beaucoup voyagÃ©, mais grace au comte.</cell><cell></cell><cell></cell></row><row><cell cols="4">(We have traveled a lot, but thanks to the count.)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Generated: La monnaie a beaucoup voyagÃ©, mais grace au compte.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">(The currency has traveled a lot, but thanks to the account.)</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">â€¢ Encre / Ancre (Anchor/Ink)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Original sentence :</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note coords="8,107.28,429.91,121.07,10.91;8,116.56,443.45,225.37,10.91;8,115.90,458.02,159.59,9.72;8,116.56,470.55,203.22,10.91"><p><p><p>â€¢ MÃ¨re / Mer (Mother/Sea)</p>Original sentence : Le fils a dit au revoir Ã  sa mÃ¨re.</p>(The son said goodbye to his mother.) Generated : Le morse a dit au revoir Ã  sa mer.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,108.93,660.08,66.31,8.97"><p>https://fasttext.cc/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,108.93,671.04,205.79,8.97"><p>https://studio.ai21.com/docs/jurassic1-language-models/</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C REBUILD Jurassic Prompt Appendix D Examples of before and after generation Appendix E French Test Sentences</head><p>Appendix F Ambiguous test sentences</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,112.66,610.54,393.33,10.91;9,112.66,624.09,155.85,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,174.53,610.54,211.03,10.91">Prudence and racial humor: Troubling epithets</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Rossing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,394.01,610.54,111.97,10.91;9,112.66,624.09,71.91,10.91">Critical Studies in Media Communication</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="299" to="313" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,637.64,393.61,10.91;9,112.66,651.19,103.98,10.91" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">A</forename><surname>Kuiper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">A</forename><surname>Martin</surname></persName>
		</author>
		<title level="m" coord="9,233.02,637.64,105.81,10.91">Humor and self-concept</title>
		<meeting><address><addrLine>Berlin/New York Berlin, New York</addrLine></address></meeting>
		<imprint>
			<publisher>Walter de Gruyter</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,86.97,393.53,10.91;10,112.66,100.52,393.32,10.91;10,112.33,114.06,78.48,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,359.50,86.97,146.69,10.91;10,112.66,100.52,274.39,10.91">Too close for comfort, or too far to care? finding humor in distant tragedies and close mishaps</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Mcgraw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Leonard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,395.90,100.52,97.10,10.91">Psychological science</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1215" to="1223" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,127.61,393.33,10.91;10,112.66,141.16,395.17,10.91;10,112.66,154.71,395.17,10.91;10,112.66,168.26,394.62,10.91;10,112.66,181.81,295.80,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,233.84,127.61,135.51,10.91">Pun Generation with Surprise</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1172</idno>
		<ptr target="https://aclanthology.org/N19-1172.doi:10.18653/v1/N19-1172" />
	</analytic>
	<monogr>
		<title level="m" coord="10,396.42,127.61,109.57,10.91;10,112.66,141.16,395.17,10.91;10,112.66,154.71,183.93,10.91">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1734" to="1744" />
		</imprint>
		<respStmt>
			<orgName>Association for Computational Linguistics</orgName>
		</respStmt>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="10,112.66,195.36,393.33,10.91;10,112.66,208.91,395.17,10.91;10,112.66,222.46,394.52,10.91;10,112.66,236.01,365.88,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,286.85,195.36,219.14,10.91;10,112.66,208.91,66.34,10.91">SemEval-2017 task 7: Detection and interpretation of English puns</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hempelmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S17-2005</idno>
		<ptr target="https://aclanthology.org/S17-2005.doi:10.18653/v1/S17-2005" />
	</analytic>
	<monogr>
		<title level="m" coord="10,202.19,208.91,305.64,10.91;10,112.66,222.46,85.40,10.91">Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</title>
		<meeting>the 11th International Workshop on Semantic Evaluation (SemEval-2017)<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="58" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,249.56,394.53,10.91;10,112.66,263.11,394.52,10.91;10,112.66,276.66,394.53,10.91;10,112.66,290.20,393.33,10.91;10,112.66,303.75,393.33,10.91;10,112.66,317.30,354.54,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,112.66,276.66,323.18,10.91">CLEF Workshop JOKER: Automatic Wordplay and Humour Translation</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Puchalski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Regattin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mathurin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>AraÃºjo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-G</forename><surname>Bosser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bokiniec</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L</forename><surname>Corre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Jeanjean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hannachi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mallia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Saki</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-99739-7_45</idno>
	</analytic>
	<monogr>
		<title level="m" coord="10,462.03,290.20,43.95,10.91;10,112.66,303.75,110.39,10.91">Advances in Information Retrieval</title>
		<title level="s" coord="10,231.69,303.75,163.12,10.91">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Hagen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Verberne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Seifert</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>NÃ¸rvÃ¥g</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Setty</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="355" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,330.85,394.53,10.91;10,112.48,344.40,393.50,10.91;10,112.14,357.95,395.05,10.91;10,112.66,371.50,393.33,10.91;10,112.66,385.05,212.10,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,308.42,344.40,197.56,10.91;10,112.14,357.95,206.78,10.91">Overview of JOKER@CLEF 2022: Automatic Wordplay and Humour Translation workshop</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Regattin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-G</forename><surname>Bosser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mathurin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L</forename><surname>Corre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>AraÃºjo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Boccou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Digue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Damoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Jeanjean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,329.61,357.95,177.58,10.91;10,112.66,371.50,393.33,10.91;10,112.66,385.05,125.83,10.91">Proceedings of the Thirteenth International Conference of the CLEF Association (CLEF</title>
		<meeting>the Thirteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
			<biblScope unit="page">13390</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="10,112.66,398.60,393.54,10.91;10,112.14,412.15,393.85,10.91;10,112.66,425.70,393.32,10.91;10,112.66,439.25,395.01,10.91;10,112.66,452.79,177.89,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,355.27,398.60,150.92,10.91;10,112.14,412.15,280.95,10.91">Let Everything Turn Well in Your Wife&quot;: Generation of Adult Humor Using Lexical Constraints</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Valitutti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Toivonen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Toivanen</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/P13-2044" />
	</analytic>
	<monogr>
		<title level="m" coord="10,420.45,412.15,85.54,10.91;10,112.66,425.70,315.13,10.91;10,152.29,439.25,191.74,10.91">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="243" to="248" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct coords="10,112.66,466.34,393.33,10.91;10,112.33,479.89,29.19,10.91" xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lundin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tom</forename><surname>Wellerness</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Swifties</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Orlando</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>SLEUTHSAYERS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,493.44,394.53,10.91;10,112.66,506.99,394.53,10.91;10,112.66,520.54,394.53,10.91;10,112.66,534.09,394.53,10.91;10,112.66,547.64,395.01,10.91;10,112.66,561.19,394.53,10.91;10,112.66,574.74,394.03,10.91;10,112.66,588.29,248.65,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,112.66,547.64,179.67,10.91">Language Models are Few-Shot Learners</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="s" coord="10,211.67,561.19,237.66,10.91">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Balcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
			<publisher>Curran Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,601.84,394.53,10.91;10,112.66,615.39,394.62,10.91;10,112.31,628.93,261.50,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,314.17,601.84,188.40,10.91">Lexique 2 : A new French lexical database</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>New</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Pallier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brysbaert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ferrand</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03195598</idno>
		<ptr target="https://doi.org/10.3758/BF03195598.doi:10.3758/BF03195598" />
	</analytic>
	<monogr>
		<title level="j" coord="10,112.66,615.39,254.14,10.91">Behavior Research Methods, Instruments, &amp; Computers</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="516" to="524" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,642.48,395.01,10.91;10,112.66,656.03,109.52,10.91" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Pallier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>New</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bourgin</surname></persName>
		</author>
		<ptr target="https://github.com/chrplr/openlexicon" />
		<title level="m" coord="10,245.01,642.48,54.08,10.91">Openlexicon</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">GitHub repository</note>
</biblStruct>

<biblStruct coords="10,112.66,669.58,393.33,10.91;11,112.66,86.97,395.01,10.91;11,112.66,100.52,137.64,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,331.70,669.58,174.29,10.91;11,112.66,86.97,52.01,10.91">Enriching word vectors with subword information</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00051</idno>
	</analytic>
	<monogr>
		<title level="j" coord="11,177.25,86.97,287.99,10.91">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,114.06,393.33,10.91;11,112.66,127.61,394.04,10.91;11,112.66,141.16,357.36,10.91" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Lieber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Sharir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Shoham</surname></persName>
		</author>
		<ptr target="https://uploads-ssl.webflow.com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_tech_paper.pdf" />
		<title level="m" coord="11,307.84,114.06,198.14,10.91;11,112.66,127.61,180.99,10.91">JURASSIC-1: TECHNICAL DETAILS AND EVALUATION</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>White Paper, AI21 Labs</note>
</biblStruct>

<biblStruct coords="11,112.66,154.71,393.33,10.91;11,112.33,168.26,393.65,10.91;11,112.66,181.81,393.33,10.91;11,112.66,195.36,397.48,10.91;11,112.36,211.35,169.07,7.90" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,273.58,154.71,232.41,10.91;11,112.33,168.26,28.98,10.91">The Power of Scale for Parameter-Efficient Prompt Tuning</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.243</idno>
		<ptr target="https://aclanthology.org/2021.emnlp-main.243.doi:10.18653/v1/2021.emnlp-main.243" />
	</analytic>
	<monogr>
		<title level="m" coord="11,163.32,168.26,342.66,10.91;11,112.66,181.81,287.77,10.91">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Online and</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Online and<address><addrLine>Punta Cana, Dominican Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3045" to="3059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,222.46,393.33,10.91;11,112.33,236.01,58.19,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,157.59,222.46,203.14,10.91">A technique for the measurement of attitudes</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Likert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,368.81,222.46,106.10,10.91">Archives of Psychology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="55" to="55" />
			<date type="published" when="1932">1932</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,249.56,394.53,10.91;11,112.66,263.11,22.69,10.91;11,88.53,313.15,108.87,18.49;11,89.29,349.36,258.52,12.85;12,89.29,85.67,241.17,12.85" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Rishel</surname></persName>
		</author>
		<title level="m" coord="11,169.93,249.56,199.88,10.91">Writing Humor: creativity and the comic mind</title>
		<imprint>
			<publisher>Wayne State University Press</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>Appendices Appendix A SUBJECT Jurassic Prompt Appendix B TOPIC Jurassic Prompt</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
