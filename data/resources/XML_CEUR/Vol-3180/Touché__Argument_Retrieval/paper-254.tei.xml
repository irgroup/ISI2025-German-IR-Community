<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,406.75,15.42;1,89.29,106.66,410.00,15.42;1,89.29,128.58,168.81,15.43;1,89.29,150.91,324.97,11.96">SEUPD@CLEF: Team 6musk on Argument Retrieval for Controversial Questions by Using Pairs Selection and Query Expansion Notebook for the Touché Lab on Argument Retrieval at CLEF 2022</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,176.82,99.54,11.96"><forename type="first">Lorenzo</forename><surname>Cappellotto</surname></persName>
							<email>lorenzo.cappellotto@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,201.47,176.82,67.82,11.96"><forename type="first">Matteo</forename><surname>Lando</surname></persName>
							<email>matteo.lando@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,281.94,176.82,60.27,11.96"><forename type="first">Daniel</forename><surname>Lupu</surname></persName>
							<email>daniel.lupu@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,354.85,176.82,76.76,11.96"><forename type="first">Marco</forename><surname>Mariotto</surname></persName>
							<email>marco.mariotto.1@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,190.76,83.52,11.96"><forename type="first">Riccardo</forename><surname>Rosalen</surname></persName>
							<email>riccardo.rosalen@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,203.81,190.76,60.31,11.96"><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
							<email>ferro@dei.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,406.75,15.42;1,89.29,106.66,410.00,15.42;1,89.29,128.58,168.81,15.43;1,89.29,150.91,324.97,11.96">SEUPD@CLEF: Team 6musk on Argument Retrieval for Controversial Questions by Using Pairs Selection and Query Expansion Notebook for the Touché Lab on Argument Retrieval at CLEF 2022</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">1DE4C4F117906DE5502F508C3432EA45</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Touchè 2022</term>
					<term>Argument Retrieval</term>
					<term>Search Engines</term>
					<term>Controversial Questions</term>
					<term>Pair of Sentences</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is a report based on the work done for Touché Task 1: Argument Retrieval for Controversial Questions at CLEF 2022 by team 6musk (whose members are all students of the University of Padua). This year's task focuses on the problem of retrieving a couple of sentences to support users who search for arguments to be used in conversations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This report aims at providing a brief explanation of the Information Retrieval system built for Touché lab 2022 <ref type="bibr" coords="1,162.94,405.09,11.40,10.91" target="#b0">[1]</ref>. We participated in Touché Task 1 1 : Argument Retrieval for Controversial Questions. This year's task focused on the retrieval of pairs of sentences, instead of whole documents, from the collection of arguments used for the previous iteration of the task. The corpus used for the development of the system is a pre-processed version of the args.me corpus <ref type="bibr" coords="1,89.29,459.28,13.00,10.91" target="#b1">[2]</ref> (version 2020-04-01) that was also used during the previous year's edition of the Touché task.</p><p>The level of complexity added to this year's version of Touché Task 1 required us to think on how to specialize a basic retrieval system for documents to support this new required functionality. After developing a basic system for last year's task, we focused on this year's challenges and on more elaborated ideas to solve them. In a first iteration we decided to divide the system in two distinct phases, the first one to retrieve the most relevant documents for a topic and the second one to select the two most argumentative sentences for each topic and each document retrieved. Once the full pipeline was in place, we tried to upgrade the second phase to select the two most argumentative sentences for each topic and each document retrieved. Our focus was not to produce a top performing specialized system, but to try to develop general ideas in order to approach sentences selection and query expansion.</p><p>The paper is organized as follows: Section 2 introduces related works; Section 3 describes our approach; Section 4 details the implementation process; Section 5 explains our experimental setup; Section 6 discusses our main findings; Section ?? carries out failure analysis; finally, Section 7 draws some conclusions and outlooks for future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work On Argument Search and Retrieval</head><p>Argumentation is a daily occurrence for taking individual and collaborative decisions. We follow the definition of an argument as proposed by <ref type="bibr" coords="2,297.48,267.54,85.08,10.91">[Walton et al. 2008</ref>] to be a conclusion (claim) supported by a set of premises (reason) and to be conveying a stance on a controversial topic <ref type="bibr" coords="2,89.29,294.63,124.97,10.91">[Freeley and Steinberg, 2009]</ref>. Sometimes the premise can be left implicit (enthymemes) and the mechanism to draw the conclusion from the premises is informal.</p><p>The Web is the most important and extensive source of information, and everyone will rely on Google at some point to fill their lack of knowledge. However, as much as search engines usually provide fast and correct answers for factual information, it is not so straightforward when there are multiple controversial opinions <ref type="bibr" coords="2,299.26,362.38,11.36,10.91" target="#b2">[3]</ref>. Also, fake news worsen their effectiveness, forcing users to check the credibility of sources <ref type="bibr" coords="2,310.70,375.93,13.00,10.91" target="#b3">[4]</ref> (e.g. the specific website he is visiting). As an example, determining the stance of Twitter users towards messages may constitute an indirect way to identify the truthfulness of discussed rumors <ref type="bibr" coords="2,362.08,403.03,11.43,10.91" target="#b4">[5]</ref>. The corpus we have is preprocessed from the argument search engine args.me<ref type="foot" coords="2,436.88,414.82,3.71,7.97" target="#foot_0">2</ref> , which clearly identifies sentences (both premises and conclusions) and the premise's stance towards conclusion, but crawling the Web to extract such data is a research field on its own. Automatically detecting argumentative content in natural language text, i.e. argument mining, can help to determine people's opinion on a given topic, why they hold it, and extract insight on public matters, such as politics <ref type="bibr" coords="2,196.09,484.32,11.27,10.91" target="#b5">[6]</ref>. More details about argument mining can be found in the survey by Lawrence and Reed <ref type="bibr" coords="2,178.92,497.87,11.43,10.91" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Touché 2021</head><p>Our starting point was the Overview of Touché 2021: Argument Retrieval paper <ref type="bibr" coords="2,459.32,540.18,11.59,10.91" target="#b7">[8]</ref>, which provided valuable insights on what is argumentation, how we can assess its quality and what retrieval approaches were successful past editions, being this the third one. We developed our system taking into account two winning techniques: query expansion through Wordnet synonyms/antonyms and DirichletLM as the best similarity function (among BM25, DPH, and TF-IDF). Furthermore, we used last year's qrels to identify the best combinations based on our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query Expansion</head><p>Query Expansion (QE) is a technique that automatically expands the initial query issued by the user, usually with a human controlled thesaurus. It helps to reduce ambiguity and to increase recall. We added synonyms to the original query in two different ways, namely with WordNet (vocabulary-based) and Word2vec (corpus-based). The interested reader can find more about QE in the comprehensive survey done by Azad and Deepak <ref type="bibr" coords="3,360.51,154.71,11.46,10.91" target="#b8">[9]</ref>, which provides an overview on core methodologies, use cases and state of the art approaches. Current techniques adopt transformer-based models which show more promising results than classical ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>On Stance Detection and Sentiment Analysis</head><p>This year we face an increased layer of complexity: we have to retrieve two sentences with the same stance, and identify if this last one is "pro" or "con" the given topic. The Webis Group<ref type="foot" coords="3,501.78,235.91,3.71,7.97" target="#foot_1">3</ref> already started tackling the task of predicting if two arguments share the same stance, though the Same Side Stance Classification Shared task <ref type="bibr" coords="3,309.18,264.77,16.41,10.91" target="#b9">[10]</ref>, which achieved promising results and showed that it's both feasible and there's room for improvement. Retrieving a relevant pair of sentences is closely related both to stance detection, for which a tutorial can be found in <ref type="bibr" coords="3,210.28,305.41,18.07,10.91" target="#b10">[11]</ref>  <ref type="foot" coords="3,228.34,303.66,3.71,7.97" target="#foot_2">4</ref> , and to sentiment analysis. For example, Alshari et al. <ref type="bibr" coords="3,488.07,305.41,17.91,10.91" target="#b11">[12]</ref> used a Word2vec model to expand SentiWordNet, a lexical dictionary for sentiment analysis to learn the polarity of words in the corpus, and evaluated their approach on the IMDB with two classifiers (Logistic Regression and SVM). To estimate the polarity of each non-opinion word in the vocabulary, they computed the score of a given word based on the polarity of the closest term present in SentiWordNet <ref type="bibr" coords="3,222.86,373.16,16.09,10.91" target="#b12">[13]</ref>, with encouraging performance in identifying "positive" and "negative" reviews . Also, current research on stance detection aims at finding the position of a person from a piece of text they produce, focusing on social media portals <ref type="bibr" coords="3,421.29,400.26,16.25,10.91" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>In this section we address how the system was developed starting from examples studied during the Search Engine course. Furthermore, we will highlight which parts we focused more on and, more in details, what we tried to improve the base system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Base system, our first steps into IR</head><p>As previously stated in the introduction, the system was built in a first iteration to obtain a fully functioning pipeline for retrieving pairs of sentences. In this sense, we spent the first part of the development phase building a basic functioning pipeline to retrieve documents as in last year's edition of Touché Task 1. After concluding the previous step, we turned to this year's challenges and focused on upgrading the base system to retrieve sentences and increasing the performance by trying both off-the-shelf components and custom ones. The three main components of the basic pipeline are the following:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">ToucheParser</head><p>Since the corpus was provided as a large .csv file, the first important step was to parse it keeping in mind the memory usage. ToucheParser is a class which specializes the abstract DocumentParser, an Iterable class used to run through the corpus and to index each document using the DocumentIndexer. In particular, by using a BufferedReader and the Jackson CsvMapper, each line of the corpus was transformed into a proper fielded instance of ParsedDocument which could then be easily used to index the document with Lucene<ref type="foot" coords="4,274.29,187.08,3.71,7.97" target="#foot_3">5</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">DirectoryIndexer</head><p>Once we parsed the lines from the corpus file correctly and created an Iterable class (ToucheParser) to obtain a ParsedDocument one by one, we proceeded to index all the documents by using the Lucene API. For indexing execution, our class expected to get 365408 documents, previously extracted from ToucheParser. As already mentioned, the initially implemented StandardAnalyzer belongs to the packet org.apache.lucene.analysis.Analyzer. It is a simple analyzer where we specified a StandardTokenizerFactory and a LowerCaseFilterFactory to make all texts lowercase. In addition, the BM25Similarity similarity function has been used as a starting point to match the documents with the topic. (In the next sections it will be shown how we were able to change the analyzer and the similarity function).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">BasicSearcher</head><p>After checking the integrity of the index using Luke (Lucene Index Toolbox) and verifying all the fields were containing the expected content, we created a basic searcher to retrieve documents. In particular, after opening an IndexSearcher and using ToucheTopicsReader to read each topic, the searcher constructs a query from the title of the topic only. The searcher matches it with the text and the conclusion of the documents in the index providing the best matching documents for each topic (at most 1000). For the initial searcher, StandardAnalyzer and BM25Similarity were used as Analyzer and similarity function to be coherent with what we used for indexing. As it will be shown in the results section, after this part we were able to run the system using last year's topics and relevance judgments to check the base performance for our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Different approaches for Sentence Selection</head><p>The second planned iteration of the development required upgrading the searcher(s) to select pairs of sentences in a meaningful way, instead of single documents. For this phase of the development, we decided to upgrade BasicSearcher to trivially retrieve the conclusion and the first premise of the initially selected documents, or, if no conclusion was present, add another premise to the output (e.g., choosing the first two premises of the document). This sparked the idea for two different approaches with a common idea at the core, doing sentence selection from the document initially matched with the last year's version of the system. In our view, this is beneficial since pairs of sentences from the same document have intuitively higher coherence than arbitrary pairs of sentences from the entire collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">SentencesSearcher</head><p>SentencesSearcher is the first of the two new solutions. The development of the class required the generalization of BasicSearcher into an abstract class AbstractSearcher to follow the DRY principle and avoid repetitions. AbstractSearcher was used to implement the shared portion of code and later became the superclass for all the rest of the searchers. Until this point, the sentences were not correctly indexed to provide fast matching between them and the topics, so it became necessary to index them. To separate the document retrieval from the sentences retrieval we chose to create a new index. As in the case of the searchers we made use of an abstract class called AbstractDirectoryIndexer that contained the shared code (DRY principle) for DirectoryIndexerDocument, the indexer for the documents, and DirectoryIndexerSentences, the index for the sentences. To sum up, the searcher works by retrieving for each topic the required number of documents using the index constructed by DirectoryIndexerDocument and then, for each document, providing the two sentences from that document that best match the topic title using the index constructed by DirectoryIndexerSentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">ConclusionSearcher</head><p>After developing SentencesSearcher, we decided to push more on the idea of coherence between sentences of the same document. ConclusionSearcher works in a similar way to SentencesSearcher. For each topic, it retrieves the required number of documents using the index constructed by DirectoryIndexerDocument and then, chooses the two sentences by selecting always the first conclusion of the document and the premise (of the same document) which better matches the text of the conclusion. To implement this second step, we constructed a query that finds only the relevant premises in the index created by DirectoryIndexerSentences and matches them with the text of the conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Increasing performance</head><p>Once the full system (Figure <ref type="figure" coords="5,223.24,533.43,4.25,10.91" target="#fig_0">1</ref>) for this year edition of Task 1 was completed and different sentence selection methods were explored, we decided to focus on improving the performance of the overall system. The way in which we decided to divide the system was beneficial in experimenting with ideas since we were able to evaluate them using last year relevance judgment. We've tried query expansions because it was listed among the winning approaches of last year and wanted to see its effectiveness against the new topics. Following are the details of the various off-the-shelf components tried and the custom query expansion techniques used to improve performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Trying out off-the-shelf components</head><p>To try different off-the-shelf components it was necessary to develop our own analyzer, a subclass of org.apache.lucene.analysis.Analyzer. The main components explored were:</p><p>• Stoplists. We experimented with 'glasgow.txt' and 'smart.txt' stoplists, respectively composed by 319 and 571 common words. • Stemming. We experimented with PorterStemFiler and KStemFilter, versions of the Porter stemmer and the Krovetz stemmer found in the Lucene library. • Character N-grams and Word N-grams (Shingles). Also in this case filters were implemented by Lucene, named respectively NGramTokenFilter (with 3 characters) and ShingleFilter (applied using 3 words).</p><p>The components were chosen using a heuristic approach. Starting from the baseline model we added one component at a time and selected at each iteration the best performing between the ones available. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Query expansion based on WordNet</head><p>WordNet is the most popular thesaurus <ref type="foot" coords="6,257.49,566.60,3.71,7.97" target="#foot_4">6</ref> . Different versions can be found online: for convenience reasons which we will explain in 4, we adopted a Prolog version of WordNet 3.1, which can be found at https://github.com/ekaf/wordnet-prolog. WordNet is a network where words are linked to other words which may be semantically related. The new searcher which is implemented in WordNetSearcher is an extension of ConclusionSearcher in the following sense: the query (topic title) is expanded using all synonyms from WordNet and searched among all documents (using Dirichlet similarity function); for each document among the top 1000 retrieved by the index searcher, the conclusion is again expanded using at most 2 synonyms for each term and searched among all sentences of this document to find the best possible matching premise (since the other selected sentence is necessarily the conclusion). The value 2 is a heuristic number and can be modified as we please: it is hard to define a precise value for the maximum number of synonyms without qrels.</p><p>To speed up the process of searching one can avoid expanding the full conclusion with all terms in WordNet, but instead provide a keep only filter: for instance one can decide to keep only synonyms appearing in the topic description, or in the topic narrative (or both) which likely may contain synonyms of words in the topic title. In the end we opted to fully expand the conclusion, even though the process of searching took almost an hour. See 7 for details on speeding things up or alternative designs.</p><p>One final note: we performed the search of the sentences as in ConclusionSearcher since we are confident that it is more likely that conclusion will be expanded further than the query title, as in general it is longer (in fact a mixed approach could be tried as well).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3.">Query expansion based on Word2vec</head><p>Word2vec <ref type="bibr" coords="7,137.17,312.43,18.07,10.91" target="#b14">[15]</ref> is a natural language technique to produce word embeddings, ideally from a large corpus of text. Each word is represented as a vector of numbers and the cosine similarity computes the semantic relationship between words. It's a set of neural network models with one hidden layer trained to predict the features of the surrounding window of a given word (Skipgram) or the target word from a context window (CBOW, continuous-bag-of-words). CBOW better captures syntactic relationships between words, meanwhile Skip-gram the semantic one. For example, given the term "day" CBOW may retrieve "days", whereas Skip-gram may also retrieve "night", which is semantically close but not syntactically. Skip-gram is less sensitive to high frequency words and is less likely to overfit because it looks at single words each iteration, whereas CBOW trains on a window of words, meaning that it sees frequent words more often. For the previous reasons, we opted for Skip-gram.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Implementation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Query expansion based on WordNet</head><p>The package org.apache.lucene.wordnet provided by Lucene allows for adding a synonym filter from a WordNet-like database in Prolog. It loads the database in a SynonymMap which is a fast hash map used to retrieve synonyms from any specified lowercase word. After creating this map, we can add a SynonymTokenFilter to our analyzer, passing the former to the constructor. We explicitly made an analyzer called WordNetQueryExpander which does other things among setting up a synonym filter. In this order, the first step consists in setting up a lower-case filter, then a stop filter, and finally the synonym filter. The constructor of the analyzer accepts a parameter set which enables us to keep only synonyms words contained in set: in this sense this has been used to speed up the process of searching, as said before. The second step applies this keep only filter if set is not null, and then applies the Krovetz Stemmer.</p><p>We tried two combinations of filters for this analyzer (the synonym filter is always applied clearly):</p><p>• a combination of lowercase filter, stop filter (Glasgow list), synonym filter, Krovetz stemmer (the default) • a combination of lowercase filter and synonym filter both were tried using BM-25 similarity and Dirichlet similarity (see 6 for a discussion of the final results).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Query expansion based on Word2vec</head><p>Word2Vec generates synonyms after training on the corpus, which we preprocessed to remove noise and improve performance (training and searching time). The training data for the word2vec model was built removing all duplicates, i.e. documents with the same "sourceId" sub-field, resulting in 58962 documents. We filtered from "args_processed_04_01.csv" the "sourceText" sub-field, replacing with a whitespace all words with three or more equal consecutive characters, words that contained numbers and the substring "xa0". All terms have been turned lowercase and only ones between 3 and 14 characters were kept.</p><p>The model was built using the deeplearning4j library with the following:</p><p>Word2Vec vec = new Word2Vec.Builder().stopWords(list).minWordFrequency(20) .layerSize(512).windowSize <ref type="bibr" coords="8,243.59,375.21,23.74,7.90" target="#b9">(10)</ref>.iterate(iter).tokenizerFactory(t).build();</p><p>• stopWords(list) is a stopword list based on 'smart.txt' plus approximately 50 of the more common terms from the context field. • minWordFrequency(20) forces the removal from the vocabulary of words with less than 20 repetitions. • tokenizerFactory(new StandardTokenizer()) is the default tokenizer of the deeplearning4j library. • windowSize is the number of words used to compute the numeric vector of a given word. Since we already preprocessed "SourceText" and removed many stop words we kept a relatively low value <ref type="bibr" coords="8,236.99,510.73,15.24,10.91" target="#b9">(10)</ref>. • layerSize is the number of features in the word vector. Default values are around 100, we used 512 to try to improve the quality, with no apparent downsides. Printing out synonyms for query terms we saw a closer semantic meaning with higher values of this parameter (512 vs 256).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word2Vec run description</head><p>In the first phase, query expansion was performed on the topic title, using two stoplists ('glasgow.txt' and 'smart.txt') but no stemming because, as can be seen from row 1 and rows 2 &amp; 3 (student-students) in table 1, we are kind of doing lemmatization. Also antonyms may be added (row 6)). During searching time, only synonyms with a similarity higher than a heuristically found value (0.53 in range 0-1) were added, and at most 5 per term of the original query. For the second phase, we've used the conclusion field from the retrieved document as input for another query to find the most similar premise in the document (as in ConclusionSearcher). The Krovetz stemmer has been applied and no stoplist. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Setup</head><p>This section contains more details on which hardware was used to run the experiments, alongside which tools and measures were used to evaluate the performance.</p><p>The hardware used to create the indices, search the topics and evaluating the performance is:</p><p>• OS: MacOS Big Sur • CPU: AMD Ryzen 7 3800X 3.9 Ghz • RAM: 16GB DDR4 3200MHZ • Storage: SSD M.2 PCIe NVMe 512GB</p><p>The development of the system was based on the experimental collections created for this year and last year editions of Touché Task 1. To evaluation tools used during the development are trec_eval <ref type="foot" coords="9,128.91,435.88,3.71,7.97" target="#foot_5">7</ref> to compute the measures and Luke, a GUI that lets you look inside the index Lucene creates, to check indices health and coherence. The evaluation measures used to check the system during the various phases of the development are:</p><p>• nDCG_cut_5 or Normalized Discounted Cumulated Gain at cut 5: main metric used for evaluating the systems in Touché Task 1. • MAP or Mean Average Precision: with a single number it gives an overall view of the system's performance, and offers a different perspective w.r.t nDCG_cut_5 since it's a binary relevance function. Plus, the more qrels available, the more accurate and we had the ground truth of previous two editions.</p><p>The git repository containing the source code of the system is available at the link seupd2122-6musk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Performance on This Year's Relevance Judgments</head><p>This year another class of judgments was given besides quality and relevance ones: in order to establish if a pair of sentences do not contradict each other, Touché organizers supplied us with coherence qrels. We want to understand whether our searching strategies are different or not: comparing performance scores between runs always requires statistical analysis; to do so, we will compare the distributions of NDCG values among the 5 runs we submitted to CLEF for each topic title. The runs we chose on last year performance are:</p><p>1. seupd2122-6musk-kstem-stop-shingle3 (uses 3.2.1 and off the shelf components described in 3.3.1) 2. seupd2122-6musk-stop-kstem-basic (described in 3.1.3) 3. seupd2122-6musk-stop-kstem-concsearch (described in 3.2.2) 4. seupd2122-6musk-stop-wordnet-kstem-dirichlet (described in 3.3.2) 5. seupd2122-6musk-word2vec-sentences-kstem (combines searcher from 3.2.1 and expansion technique described in 3.3.3)</p><p>We have the following results for NDCG on each type of judgment: This table only shows means computed by the trec_eval tool over all topics; to get a better idea over the whole data, boxplots are really useful: Informally we can say that runs 1, 3, 4, 5 perform all better than run 2, which intuitively makes sense, since the core of the searcher is very basic. Runs 3, 4, 5 are almost equal, in particular run 4 shows a lower interquartile range. To verify these statements we will apply both ANOVA one way and pairwise Student's t-tests.  Table <ref type="table" coords="11,127.92,401.22,5.17,10.91" target="#tab_3">3</ref> confirms that for each qrels file, the means of the NDCG distributions are not all equal among different runs, as boxplots anticipated (as p_values are less than 0.01 we reject the null hypothesis that all means are equal). To better understand pairwise differences, we show the p_values after computing pairwise t-tests:  So run 2 is in every case worse than all the other runs since the p_values are &lt; 0.01, as we suspected. We can't inference further differences between runs from the tables. Note that run 2 and run 3 use the same analyzer, whereas the difference relies only on the type of searcher. So we say for sure that searcher 3.2.2 makes a very substantial impact on the final result w.r.t. 3.1.3. We can also point out that even if run 1 and run 5 use very different first phases (and 3.2.1 as second phase of the system), they were not statistically different. Perhaps this suggests that another interesting test to execute would be to run the same first phase as in run 2 and run 3, but in combination with sentences searcher. This would have enabled us to see the difference in performance given by only 3.2.1 with respect to the other 2 sentence selection methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions and Future Work</head><p>Comparing our results on document retrieval with last year's overview paper <ref type="bibr" coords="12,442.04,253.99,12.98,10.91" target="#b7">[8]</ref> allowed us to ensure that the system we were developing had a satisfying enough performance, and we could proceed with sentence selection and retrieval. With the release of qrels, we will be able to discern which of the multiple approaches worked better and to fine-tune parameters (e.g., similarity functions, word2vec training parameters and WordNet max synonyms).</p><p>An evaluation measure for Touché 2022 Task 1 is the coherence between sentences; we may want to further improve it by means of character n-grams, word n-grams, and skip-grams that overcome data sparsity. Since sentences, especially conclusions, are often short phrases and should be meaningful claims, finding matching text between them may lead to an increase of syntactic similarity, and consequently in coherence. For this reason, we are interested to see how the just mentioned techniques could perform.</p><p>In the run file we have to print the stance w.r.t the query and, as can be seen from the args.me search engine's API <ref type="foot" coords="12,176.01,414.82,3.71,7.97" target="#foot_6">8</ref> , the one we have available in the premises field is towards conclusion. So, we don't have an immediate information if a retrieved argument is "pro" or "con" the original query, and we may try to address this issue through sentiment analysis. It's the application of natural language processing (NLP) to understand if the explicit or implicit opinion in a sentence is positive, negative or neutral. Through the use of Part of Speech (PoS) tagging, for example ApacheNLP <ref type="foot" coords="12,145.63,482.57,3.71,7.97" target="#foot_7">9</ref> , and human-validated sentiment lexicon we can define a polarity score for the premises and compare it with the stance towards conclusion to derive the final returned stance. Since "each sentence in the pair must ideally be the most representative/most important of its corresponding argument", sentiment analysis may also lead to an improvement in this regard.</p><p>As a further development we would like to retrieve sentences from different documents to encourage diversity, as suggested by Touché's organizers. To ensure coherence between sentences and query text, we may want to identify keywords, weight them and try synonym expansion with terms from the description or narrative field of the topic file.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,89.29,500.75,215.14,8.93;6,89.29,322.22,416.66,165.96"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Complete pipeline with the different parts</figDesc><graphic coords="6,89.29,322.22,416.66,165.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="10,89.29,650.56,149.82,8.93;10,297.64,649.13,159.42,8.93;10,89.29,512.32,208.35,125.67"><head>Figure 2 : 3 :Figure 4 :</head><label>234</label><figDesc>Figure 2: nDCG@5 for quality qrels Figure 3: nDCG@5 for relevance qrels</figDesc><graphic coords="10,89.29,512.32,208.35,125.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="11,89.29,544.33,417.09,9.08;11,99.71,463.60,187.51,68.32"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: p_values pairwise t-tests, quality qrels Figure 6: p_values pairwise t-tests, relevance qrels</figDesc><graphic coords="11,99.71,463.60,187.51,68.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="11,193.47,662.86,211.63,8.93;11,203.88,580.35,187.51,69.95"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: p_values pairwise t-tests, coherence qrels</figDesc><graphic coords="11,203.88,580.35,187.51,69.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="9,88.99,130.52,294.70,111.08"><head>Table 1</head><label>1</label><figDesc>Example of synonyms/antonyms generated with Word2vec</figDesc><table coords="9,211.58,158.61,172.11,82.99"><row><cell cols="3">Query Term Synonym Similarity</cell></row><row><cell>1 teachers</cell><cell>teacher</cell><cell>0.76</cell></row><row><cell>2 teachers</cell><cell>student</cell><cell>0.66</cell></row><row><cell>3 teachers</cell><cell>students</cell><cell>0.66</cell></row><row><cell>4 teachers</cell><cell cols="2">classroom 0.65</cell></row><row><cell>5 teachers</cell><cell>schools</cell><cell>0.61</cell></row><row><cell>6 legal</cell><cell>illegal</cell><cell>0.60</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="10,88.99,357.36,428.48,98.72"><head>Table 2</head><label>2</label><figDesc></figDesc><table coords="10,89.29,369.36,428.18,86.72"><row><cell>nDCG@5 for all judgments</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Run</cell><cell cols="3">nDCG@5 qual nDCG@5 rel nDCG@5 coh</cell></row><row><cell>seupd2122-6musk-kstem-stop-shingle3</cell><cell>0.7258</cell><cell>0.6378</cell><cell>0.3699</cell></row><row><cell>seupd2122-6musk-stop-kstem-basic</cell><cell>0.2876</cell><cell>0.1767</cell><cell>0.1962</cell></row><row><cell>seupd2122-6musk-stop-kstem-concsearch</cell><cell>0.7244</cell><cell>0.5881</cell><cell>0.3415</cell></row><row><cell>seupd2122-6musk-stop-wordnet-kstem-dirichlet</cell><cell>0.7299</cell><cell>0.6055</cell><cell>0.3622</cell></row><row><cell>seupd2122-6musk-word2vec-sentences-kstem</cell><cell>0.7183</cell><cell>0.5822</cell><cell>0.3374</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="11,88.99,361.01,96.30,20.87"><head>Table 3 F</head><label>3</label><figDesc></figDesc><table /><note coords="11,96.80,373.01,88.49,8.87"><p>statistic and p_values</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,108.93,670.98,118.98,8.97"><p>https://www.args.me/index.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="3,108.93,660.03,60.94,8.97"><p>https://webis.de/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="3,108.93,670.99,151.01,8.97"><p>https://dkucuk.github.io/stancedetection/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="4,108.93,671.04,94.91,8.97"><p>https://lucene.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4" coords="6,108.93,671.04,112.74,8.97"><p>https://wordnet.princeton.edu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5" coords="9,108.93,670.94,144.73,8.97"><p>https://github.com/usnistgov/trec_eval/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6" coords="12,108.93,659.95,121.89,8.97"><p>https://www.args.me/api-en.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_7" coords="12,108.93,670.91,101.05,8.97"><p>https://opennlp.apache.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="13,112.66,111.28,395.17,10.91;13,112.66,124.83,395.17,10.91;13,112.66,138.38,395.01,10.91;13,112.41,151.93,393.57,10.91;13,112.66,165.48,339.15,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,361.25,124.83,146.58,10.91;13,112.66,138.38,62.60,10.91">Overview of Touché 2022: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gurcke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,197.77,138.38,309.90,10.91;13,112.41,151.93,309.42,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction. 13th International Conference of the CLEF Association (CLEF 2022)</title>
		<title level="s" coord="13,429.80,151.93,76.18,10.91;13,112.66,165.48,78.83,10.91">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="13,112.66,179.03,393.53,10.91;13,112.28,192.57,393.71,10.91;13,112.66,206.12,393.73,10.91;13,112.34,219.67,286.03,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,415.08,179.03,91.11,10.91;13,112.28,192.57,167.13,10.91">Data Acquisition for Argument Search: The args.me corpus</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-30179-8_4</idno>
	</analytic>
	<monogr>
		<title level="m" coord="13,112.66,206.12,241.68,10.91">German Conference on Artificial Intelligence (KI 2019)</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Benzmüller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Stuckenschmidt</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="48" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,233.22,393.32,10.91;13,112.66,246.77,395.01,10.91;13,112.41,260.32,28.67,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,243.83,233.22,127.40,10.91">Argument retrieval from web</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Shahshahani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,394.79,233.22,111.19,10.91;13,112.66,246.77,301.62,10.91">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="75" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,273.87,393.61,10.91;13,112.66,287.42,393.33,10.91;13,112.28,300.97,122.06,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,308.28,273.87,197.99,10.91;13,112.66,287.42,220.64,10.91">Claimeval: Integrated and flexible framework for claim evaluation using credibility of sources</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Samadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Veloso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,363.39,287.42,142.60,10.91;13,112.28,300.97,92.47,10.91">Thirtieth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,314.52,394.53,10.91;13,112.66,328.07,394.53,10.91;13,112.66,341.62,393.32,10.91;13,112.66,355.17,394.62,10.91;13,112.66,368.71,293.47,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,112.66,328.07,389.57,10.91">SemEval-2019 task 7: RumourEval, determining rumour veracity and support for rumours</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gorrell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kochkina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Aker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zubiaga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bontcheva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Derczynski</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S19-2147</idno>
		<ptr target="https://aclanthology.org/S19-2147.doi:10.18653/v1/S19-2147" />
	</analytic>
	<monogr>
		<title level="m" coord="13,127.27,341.62,378.72,10.91;13,112.66,355.17,135.42,10.91">Proceedings of the 13th International Workshop on Semantic Evaluation, Association for Computational Linguistics</title>
		<meeting>the 13th International Workshop on Semantic Evaluation, Association for Computational Linguistics<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="845" to="854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,382.26,395.17,10.91;13,112.66,395.81,280.86,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,282.39,382.26,225.44,10.91;13,112.66,395.81,122.78,10.91">Detecting arguments and their positions in experimental communication data</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hüning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Mechtenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<idno>SSRN 4052402</idno>
	</analytic>
	<monogr>
		<title level="j" coord="13,243.63,395.81,41.24,10.91">Available</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,409.36,393.98,10.91;13,112.41,422.91,38.81,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,210.89,409.36,125.05,10.91">Argument mining: A survey</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Reed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,344.44,409.36,119.35,10.91">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="765" to="818" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,436.46,394.52,10.91;13,112.66,450.01,393.33,10.91;13,112.66,463.56,394.52,10.91;13,112.66,477.11,393.33,10.91;13,112.66,490.66,393.33,10.91;13,112.41,504.21,395.26,10.91;13,112.41,517.76,397.73,10.91;13,112.36,533.75,158.69,7.90" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,336.55,450.01,169.43,10.91;13,112.66,463.56,38.69,10.91">Overview of Touché 2021: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-85251-1_28</idno>
		<ptr target="https://link.springer.com/chapter/10.1007/978-3-030-85251-1_28.doi:10.1007/978-3-030-85251-1\_28" />
	</analytic>
	<monogr>
		<title level="m" coord="13,238.75,477.11,267.23,10.91;13,112.66,490.66,328.83,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction. 12th International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="13,150.93,505.22,143.04,9.72">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Candan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="volume">12880</biblScope>
			<biblScope unit="page" from="450" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,544.85,394.53,10.91;13,112.66,558.40,269.51,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,219.59,544.85,283.00,10.91">Query expansion techniques for information retrieval: a survey</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">K</forename><surname>Azad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Deepak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,112.66,558.40,175.43,10.91">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="1698" to="1735" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,571.95,393.32,10.91;13,112.66,585.50,132.61,10.91" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">El</forename><surname>Baff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Al-Khatib</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cimiano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<title level="m" coord="13,430.67,571.95,75.31,10.91;13,112.66,585.50,55.98,10.91">Same side stance classification</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct coords="13,112.66,599.05,393.33,10.91;13,112.66,612.60,354.73,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,195.06,599.05,132.93,10.91">A tutorial on stance detection</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Küçük</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Can</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,351.41,599.05,154.58,10.91;13,112.66,612.60,256.32,10.91">Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Fifteenth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1626" to="1628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,626.15,393.32,10.91;13,112.66,639.70,393.33,10.91;13,112.66,653.25,176.52,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,404.58,626.15,101.40,10.91;13,112.66,639.70,305.29,10.91">Senti2vec: An effective feature extraction technique for sentiment analysis based on word2vec</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Alshari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Azman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Doraisamy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Mustapha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Alksher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,426.60,639.70,79.39,10.91;13,112.66,653.25,92.58,10.91">Malaysian Journal of Computer Science</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="240" to="251" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,666.80,393.33,10.91;14,112.66,86.97,393.32,10.91;14,112.66,100.52,303.66,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,287.42,666.80,218.56,10.91;14,112.66,86.97,187.48,10.91">Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Baccianella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,323.62,86.97,182.36,10.91;14,112.66,100.52,273.52,10.91">Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC&apos;10)</title>
		<meeting>the Seventh International Conference on Language Resources and Evaluation (LREC&apos;10)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,114.06,394.53,10.91;14,112.66,127.61,253.39,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="14,226.90,114.06,275.86,10.91">Stance detection on social media: State of the art and trends</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Aldayel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Magdy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,112.66,127.61,175.43,10.91">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page">102597</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,141.16,393.33,10.91;14,112.66,154.71,397.48,10.91;14,112.66,170.70,26.14,7.90" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="14,304.78,141.16,201.20,10.91;14,112.66,154.71,64.26,10.91">Efficient estimation of word representations in vector space</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1301.3781</idno>
		<ptr target="https://arxiv.org/abs/1301.3781.doi:10.48550/ARXIV.1301.3781" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
