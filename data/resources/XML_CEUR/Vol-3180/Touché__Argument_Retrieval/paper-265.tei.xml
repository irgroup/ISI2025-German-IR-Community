<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,415.97,15.42;1,89.29,106.66,183.07,15.42;1,89.29,129.00,295.54,11.96">Similar but Different: Simple Re-ranking Approaches for Argument Retrieval Notebook of Team Hit-Girl for the TouchÃ© Lab on Argument</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.10,154.90,63.22,11.96"><forename type="first">Jerome</forename><surname>WÃ¼rf</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Leipzig University</orgName>
								<address>
									<addrLine>Augustusplatz 10</addrLine>
									<postCode>04109</postCode>
									<settlement>Leipzig</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,415.97,15.42;1,89.29,106.66,183.07,15.42;1,89.29,129.00,295.54,11.96">Similar but Different: Simple Re-ranking Approaches for Argument Retrieval Notebook of Team Hit-Girl for the TouchÃ© Lab on Argument</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">9E56523C0A5226F247828D7A4C949CB9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>information retrieval</term>
					<term>argument retrieval</term>
					<term>semantic search</term>
					<term>re-ranking</term>
					<term>TouchÃ© 2022</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work examines simple re-ranking approaches using the preprocessed args.me corpus to contribute to the TouchÃ© 2022 Argument Retrieval Task. The proposed retrieval system relies on an initial retrieval using a semantic search on a sentence level and takes advantage of simple heuristics. Our re-ranking approaches incorporate maximal marginal relevance, word mover's distance, and a novel approach based on a fuzzy matching on part of speech tags that we call structural distance. Further, we explore the applicability of a graph-based re-ranking approach. The results show that the proposed re-ranking approaches could beat our baseline. For relevance, our re-ranking using structural distance performs best, while for quality, the one using the word mover's distance achieves the highest score.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The waves of protests in response to the pandemic restrictions of last winter seem to highlight a problem in the current culture of discussion. Despite an increased exposure to facts on controversial topics through our daily lives, we fail to present the gained knowledge to enable debates and to support individuals' opinion formation. Regarding COVID- <ref type="bibr" coords="1,433.77,440.15,11.18,10.91" target="#b18">19</ref>, it has been shown that people exposed to misinformation, biased media, and conspiracy have lower trust in democratic institutions <ref type="bibr" coords="1,192.59,467.25,11.28,10.91" target="#b0">[1]</ref>. This situation makes it urgent for societies to confront misinformed individuals with reasonable arguments. Besides COVID-19, web resources, like blogs and news sites, address many other topics with a similar, potentially harmful impact. This development motivates our research on the automatic retrieval of reasonable arguments.</p><p>This work, describes the submission of team Hit-Girl 1 for Task 1 of TouchÃ© 2022 <ref type="bibr" coords="1,469.09,521.45,11.58,10.91" target="#b1">[2]</ref>. The task asks participants to create an argument retrieval system for a given corpus to support the opinion formation on controversial societal topics. In this year's version of the first task, the requirements for the final systems differ from the previous years, as participants are asked to retrieve argumentative sentence pairs instead of whole arguments for a given topic. The sentence pair is reasonable if the retrieved sentences are topic-relevant and qualitative. The quality of arguments is defined by <ref type="bibr" coords="1,246.30,602.74,11.75,10.91" target="#b0">(1)</ref> the argumentativeness of each sentence, <ref type="bibr" coords="1,445.61,602.74,11.75,10.91" target="#b1">(2)</ref> coherence between the sentences, and (3) together, the sentences of the pair should form a summary of their originating arguments <ref type="bibr" coords="2,215.67,100.52,11.43,10.91" target="#b1">[2]</ref>.</p><p>Our proposed system consists of three main components: indexing, initial retrieval, and re-ranking. The system's source code is publicly available <ref type="foot" coords="2,347.89,125.86,3.71,7.97" target="#foot_0">2</ref> . Before indexing, sentences of the provided preprocessed args.me corpus <ref type="bibr" coords="2,262.25,141.16,12.83,10.91" target="#b2">[3]</ref> are transformed into vector embeddings. Sentences and vector embeddings are stored into two indices, one holds only premises,/ and the other holds only conclusions. We conduct a nearest neighbor search in the embedding space at retrieval time. Initially, we rank according to the cosine similarity between the query embedding and the embeddings in the respective index. This approach should maximize the semantic similarity between sentences, resulting in topic-relevant sentences. In the following, we will refer to this as semantic search. Finally, we compare multiple re-ranking approaches that aim to balance relevance and diversification of query results by assessing differences between a query and the retrieved sentences. Having outlined our initial motivation and a rough system overview of how we approach the given task, we pose the following research question:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Do simple, argument quality agnostic re-ranking approaches improve argument quality compared to an initial semantic search?</head><p>To answer our research question, we conducted experiments with three different re-ranking approaches utilizing maximal marginal relevance (MMR), structural distance (SD), and word mover's distance (WMD). In comparison to the baseline, two re-ranking approaches could increase argument relevance. WMD results in a better quality score than the baseline, and all re-ranking approaches show better sentence coherence than the baseline. Further, we analyze the challenges of implementing a graph-based argument re-ranking approach. Section 2 will introduce the related work. Following the related work, we describe our system and re-ranking approaches in section 3. Section 4 presents the evaluation of our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>This section introduces the challenge of argument retrieval and describes existing re-ranking approaches. We pick up on the shortcomings of previous studies to justify the design of our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Challenges in argument retrieval</head><p>Search engines for argument retrieval for controversial topics aim to quickly and comprehensively provide users with supportive and opposing arguments. Argument search denotes a relatively new field of research. It unites challenges of natural language processing and information retrieval while opening up a broad range of research opportunities for computational argumentation <ref type="bibr" coords="2,159.02,604.19,11.55,10.91" target="#b3">[4]</ref>. In contrast to relevance orientated search engines, systems for argument retrieval additionally needs to focus on:</p><p>â€¢ incorporating the quality of the arguments to check for their validity</p><p>â€¢ providing an overview of arguments with different stances instead of a single best answer â€¢ assessing and reflecting the connections between arguments in the final ranking</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Existing methods in argument retrieval</head><p>ArgumenText <ref type="bibr" coords="3,153.11,151.06,12.81,10.91" target="#b4">[5]</ref> and args <ref type="bibr" coords="3,208.93,151.06,12.81,10.91" target="#b3">[4]</ref> are important pioneers offering diverse technical approaches to the outlined challenges of argument retrieval. ArgumentText <ref type="bibr" coords="3,365.85,164.61,12.91,10.91" target="#b4">[5]</ref> was one of the first systems ingesting heterogeneous Web documents, identifying arguments in topic-relevant documents and labeling the identified arguments with a "pro" or "con" stance. The identification of arguments relies on an attention-based neural network, and a stance recognition utilizes a BiLSTM model. Both models were trained on a dataset containing 49 topics with 600 sentences each, labeled as "pro", "con" or not an argument. The authors compare their system's performance to an expert-curated list of arguments within a specific online debate portal <ref type="foot" coords="3,420.47,244.15,3.71,7.97" target="#foot_1">3</ref> and reported that on three selected topics, the retrieved arguments matched 89% the ones of the expert-curated list. Further, they pointed out that 12% of the arguments identified by their approach were not contained in the expert-curated list. ArgumentText <ref type="bibr" coords="3,316.97,286.55,12.75,10.91" target="#b4">[5]</ref> differs from our system as we are using a preprocessed dataset that does already contain arguments that are split into their constituent sentences. Further, these sentences are also already labeled by a stance. Therefore, our system only relies on initial retrieval and re-ranking approaches.</p><p>Args <ref type="bibr" coords="3,122.63,340.75,12.75,10.91" target="#b3">[4]</ref> is a prototype argument retrieval system using a novel argument search framework and a newly crawled Web-based corpus <ref type="bibr" coords="3,266.67,354.29,11.36,10.91" target="#b2">[3]</ref>. The framework incorporates a common argument model. In this model, one argument consists of a claim/conclusion, zero or more premises, and an argument's context, which provides the full text in which a specific argument occurred. In general, the framework splits into an indexing process and a retrieval process. The indexing process contains the acquisition of documents, argument mining, an assessment, and indexing. For the initial acquisition, the authors crawl the args.me <ref type="bibr" coords="3,341.65,422.04,12.84,10.91" target="#b2">[3]</ref> corpus. The crawl focuses on five different debate portals and includes 34,784 debates containing 291,440 arguments that were finally parsed into 329,791 argument units. Argument mining and parsing into the common argument model rely on Apache UIMA <ref type="foot" coords="3,261.38,460.93,3.71,7.97" target="#foot_2">4</ref> . The final indexing is realized with Apache Lucene. In the retrieval process, the args prototype performs an initial retrieval for a given query, relying on an exact string match between query terms and terms in an indexed argument and conducts a ranking on relevant arguments using a BM25 model. To be more specific, a BM25F model was used to weigh the individual components of the common argument model. The authors performed a quantitative analysis using controversial topics from Wikipedia as queries. The scores were reported on the systems' coverage for logical combinations of query terms and phrase queries and the three components of the proposed common argument model: conclusions, arguments, and argument's context. Finally, the system achieved a good initial coverage ranging from 41.6%-84.6% for all query types on the conclusions and a coverage of 77.6% on phrase queries for whole arguments. The results indicate that a retrieval model with a higher weight on conclusions reaps arguments of higher relevance. Our system uses a preprocessed version of the args.me <ref type="bibr" coords="3,143.03,625.28,12.75,10.91" target="#b2">[3]</ref> corpus. To be specific, our system indexes sentences that were gained from the argument mining and the assessment step of the args search engine. Like args, our system's initial retrieval and re-ranking approaches will not rely on identifying argumentative structures within the indexed argument units. In contrast to args, we use two indices, one for conclusions and one for premises, instead of indexing whole arguments at once. Motivated by the findings of the args search engine that the conclusions should have higher weight, our system queries our conclusion index first and uses the retrieved conclusions to query the premises index. Furthermore, our system enforces a minimum amount of tokens in a retrieved conclusion compared to a query. This constraint is also motivated by the expectations of args' authors, "that the most relevant arguments need some space to lay out their reasoning" <ref type="bibr" coords="4,435.35,181.81,13.44,10.91" target="#b3">[4]</ref>.</p><p>Previous years of TouchÃ© showed substantial improvements in retrieval performance. In the first year, multiple submissions indicated that the DirichletLM <ref type="bibr" coords="4,372.26,208.91,12.95,10.91" target="#b5">[6]</ref> retrieval model is a strong baseline for the initial retrieval of argumentative text <ref type="bibr" coords="4,323.45,222.46,11.28,10.91" target="#b6">[7]</ref>. Additionally, query expansion mechanisms were deployed to increase recall. Submissions for the second round of TouchÃ© indicated that argument-aware re-ranking approaches using fine-tuned language models improved previous years' results. Moreover, approaches focused on parameter tuning of pipelines proposed in the previous year, using existing relevance judgments <ref type="bibr" coords="4,349.78,276.66,11.58,10.91" target="#b7">[8]</ref>. Up to now, only a minority of TouchÃ©'s submissions <ref type="bibr" coords="4,187.52,290.20,11.32,10.91" target="#b8">[9,</ref><ref type="bibr" coords="4,201.57,290.20,14.01,10.91" target="#b9">10]</ref> leveraged embeddings for an initial retrieval, which motivates us to gain a deeper understanding of this approach. Motivated by the promising results of query expansion of last year's submissions <ref type="bibr" coords="4,251.81,317.30,16.36,10.91" target="#b10">[11,</ref><ref type="bibr" coords="4,270.90,317.30,12.52,10.91" target="#b11">12,</ref><ref type="bibr" coords="4,286.15,317.30,12.27,10.91" target="#b12">13]</ref>, our system mimics a query expansion by first retrieving conclusions with an initial controversial topic and then using these conclusions to query an index holding the premises. Finally, our re-ranking distinguishes us from existing ones, as we do not rely on argument-specific domain features or machine learning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodological Approach</head><p>The architecture of our retrieval system (Figure <ref type="figure" coords="4,312.34,416.58,4.25,10.91">1</ref>) consists of indexing, retrieval, and a reranking module. The system relies on two Elasticsearch<ref type="foot" coords="4,349.70,428.37,3.71,7.97" target="#foot_3">5</ref> indices, one for conclusions and one for premises. Initially, our system uses the preprocessed args.me <ref type="bibr" coords="4,398.03,443.67,14.46,10.91" target="#b2">[3]</ref> corpus, which holds arguments divided into their constituent premise and conclusion sentences. The sentences are transformed into vector embeddings (Section 3.1). Premises and conclusions are indexed into the respective indices with their vector embeddings. While indexing, the standard tokenization pipeline of Elasticsearch is applied to save the number of tokens in a sentence as further metadata.</p><p>The retrieval module generates an initial ranking for premise and conclusion pairs. First, it queries the conclusion for a given controversial topic. Next, each conclusion serves as a query for the premise index. The initial retrieval scores are based on the cosine similarity between the vector embeddings of a query and the indexed sentences, thus mimicking the nearest neighbor search in the embedding space. Additionally, we introduce the hard constraint that a retrieved sentence must have at least 1.75 times the number of tokens of the query. The exact value was chosen by convention. In the following, we will refer to this constraint as token factor. The usage of a token factor is motivated by previous findings suggesting that qualitative argumentative sentences are longer than non argumentative ones <ref type="bibr" coords="4,420.80,633.36,13.19,10.91" target="#b3">[4]</ref>. By convention, we retrieve 100 conclusions and 50 premises per conclusion. A primary motivation behind this Figure <ref type="figure" coords="5,121.13,272.86,3.83,8.93">1</ref>: System architecture: Besides the preprocessing, our system splits into three parts: Indexing of sentences and embeddings, an initial retrieval on different controversial topics given a configuration, that determines the re-ranking strategy.</p><p>two-step retrieval is an expected increase in the premises recall, as we query the premise index multiple times using different conclusions.</p><p>Finally, the re-ranking module scores conclusions and premises separately using three different methods, which will be explained in section 3.2. In general, these methods should improve the ranking with respect to the argumentative quality of the retrieved sentences by calculating new ranking scores between the query and initially ranked sentences. Lastly, our system generates a text file in the "standard" TREC format. When writing the output file, we enforce on a topic level that there are no duplicates in the retrieved premises, and premises must match the stance of a conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preprocessing</head><p>The organizers of the shared task provide preprocessed args.me <ref type="bibr" coords="5,380.49,492.49,13.00,10.91" target="#b2">[3]</ref> corpus that contains the constituent sentences of each argument of the original args.me corpus. Further, it contains context meta-data for each argument and the stance for each sentence. Initially, we transform the provided preprocessed corpus into a structured parquet file. One row of this flat file corresponds to one sentence. One row holds information about the argument ID, sentence number <ref type="foot" coords="5,468.72,544.93,3.71,7.97" target="#foot_4">6</ref> , stance towards a topic, sentence text, and the sentence type, either conclusion or premise. The flat file contains 6,123,792 sentences that split into 338,595 conclusions and 5,785,197 premises. The original argument model of args.me <ref type="bibr" coords="5,276.33,587.34,12.99,10.91" target="#b2">[3]</ref> associates one conclusion with many premises, explaining the difference in the cardinality between conclusions and premises. Our approach breaks this association and combines the premises and conclusions of different arguments. We deduplicate the sentences using an exact string match. For the conclusions, we count 328,474 duplicates with 54,512 unique ones, which result, together with the non-duplicated ones, in a total of 64,633 conclusions to index. For the premises, we count 770,876 duplicates with 273,593 unique duplicates, which results in the non-duplicated ones in 5,626,509 premises to index. The high number of duplicates of conclusions arises from the parsing of debate platforms. Conclusions are often simply the headline of a post on a controversial topic, and a single post contains multiple arguments. The duplicated premises arise from direct citations between different posts. As a final preprocessing step, each sentence is encoded into a vector embedding via an out-of-the-box MiniLM <ref type="bibr" coords="6,223.40,181.81,17.80,10.91" target="#b13">[14]</ref> language model<ref type="foot" coords="6,313.48,180.06,3.71,7.97" target="#foot_5">7</ref> utilizing the sentence transformers library <ref type="bibr" coords="6,89.29,195.36,16.25,10.91" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Re-ranking approaches</head><p>To improve the argument quality of our initial retrieval, we examine three different re-ranking approaches using existing implementations. Our re-ranking approaches do not rely on argumentspecific sentence features. Due to the two-step retrieval approach of our system, re-ranking scores of conclusions and premises are calculated separately. First, we re-rank the conclusions, then each set of premises is retrieved for a conclusion. Each approach combines the respective re-ranking score with the initial ranking score using a weighted sum (Section 3.2.1). We expect that this general approach improves the argumentative quality of sentences by ensuring that the top results differ from the original query. Furthermore, we explore the challenges of a graph-based argument relevance for re-ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Maximal Marginal Relevance</head><p>The first sentence pairs of the results of our initial re-ranking were very similar, only differing in single words. Motivated by this observation we implement the maximal marginal relevance (MMR) <ref type="bibr" coords="6,123.83,429.91,16.41,10.91" target="#b15">[16]</ref>. The MMR linearly combines query relevance and the information novelty of a document within a ranking. The factor of information novelty ensures the assessed score of a document incorporates the dissimilarity towards the previously chosen ones. The tradeoff between query relevance and information novelty is controlled by a parameter ğœ†. For our experiments, we assess different ğœ† values. Our system calculates an MMR score for each sentence in the set of conclusions and each sentence in the individual sets of premises separately. The MMR for the conclusions calculates the query relevance between a specific conclusion and the given controversial topic and the information novelty of a specific conclusion within the set of already re-ranked ones. This approach is also conducted for every premise of the individual premise sets, where the respective conclusion serves as a query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Structural distance</head><p>As a second re-ranking approach, we propose a re-ranking based on the structural distance (SD) between query and retrieved sentences. The SD should impose a penalty on retrieved sentences that merely rephrase the search query by synonyms, thus boosting the scores of sentences that have a different structure than the query. We define the structure of a sentence as a list of part-of-speech tags<ref type="foot" coords="7,186.41,85.21,3.71,7.97" target="#foot_6">8</ref> generated by pre-trained pipeline<ref type="foot" coords="7,342.18,85.21,3.71,7.97" target="#foot_7">9</ref> using the spaCy NLP library <ref type="foot" coords="7,475.28,85.21,7.41,7.97" target="#foot_8">10</ref> . The calculations for SD (Equation <ref type="formula" coords="7,226.59,100.52,4.25,10.91">1</ref>) are closely related to the Jaro similarity. Using the part-ofspeech tags of a query ğ‘ and a retrieved sentence ğ‘ , we calculate the Jaro similarity ğ‘ ğ‘–ğ‘š(ğ‘, ğ‘ ) on a tag instead of a character level. The standard Jaro similarity uses the length of each string, the number of matching characters, and the number of transposed characters between both in a specific interval. We adapt this to the total number of part-of-speech tags of query |ğ‘| and sentence |ğ‘ |, the number of matching tags ğ‘š, and the number of transposed tags ğ‘¡ between query and a sentence. A matching or transposed tag within ğ‘ and ğ‘  counts towards ğ‘š or ğ‘¡ if it is within the window of âŒŠï¸ max(|ğ‘ğ‘ğ‘œğ‘ |,|ğ‘ ğ‘ğ‘œğ‘ |) 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>âŒ‹ï¸</head><p>-1. This approach allows for fuzzy matching based on the structure. For the calculation of the Jaro similarity, we use the popular text-distance package <ref type="foot" coords="7,125.76,225.46,7.41,7.97" target="#foot_9">11</ref> and pass at the method invocation of the Jaro similarity two lists of part-of-speech tags instead of two strings. Finally, we convert the gained similarity into a distance score by subtracting it from 1, obtaining SD.</p><formula xml:id="formula_0" coords="7,165.30,279.08,341.34,49.76">ğ‘†ğ·(ğ‘, ğ‘ ) = 1 -ğ‘ ğ‘–ğ‘š(ğ‘ ğ‘ğ‘œğ‘  , ğ‘  ğ‘ğ‘œğ‘  ) sim(ğ‘ ğ‘ğ‘œğ‘  , ğ‘  ğ‘ğ‘œğ‘  ) = {ï¸ƒ 0 if ğ‘š = 0 1 3 (ï¸ ğ‘š |ğ‘ğ‘ğ‘œğ‘ | + ğ‘š |ğ‘ ğ‘ğ‘œğ‘ | + ğ‘š-ğ‘¡ ğ‘š )ï¸ otherwise (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word mover's distance</head><p>In contrast to the other two previous re-ranking approaches that examine whole sentence strings, the word mover's distance, proposed by Kusner et al. <ref type="bibr" coords="7,364.49,380.42,15.49,10.91" target="#b16">[17]</ref>, considers the similarity of single words within two sentences to each other. For each word pair, the earth mover's distance of the corresponding words is calculated using their Word2Vec <ref type="bibr" coords="7,370.89,407.52,17.90,10.91" target="#b17">[18]</ref> embeddings. This process is formulated as a combinatorial problem to retrieve the word pairs leading to a minimal cumulative sum of distances of all constructed word pairs. Hence, it accounts for sentences with no words in common but similar meanings due to synonymy <ref type="bibr" coords="7,368.30,448.16,16.41,10.91" target="#b16">[17]</ref>. Our re-ranking leverages this behavior to rank sentences different from the query higher to provide a more diverse set of argumentative sentences. Our implementation uses the wmd-relax package <ref type="foot" coords="7,436.21,473.51,7.41,7.97" target="#foot_10">12</ref> as it provides an off-the-shelf spaCy hook that uses the same pretrained pipeline as in SD. Using this hook, allows for an easy integration into our re-ranking pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph based re-ranking</head><p>Wachsmuth et al. <ref type="bibr" coords="7,169.04,551.58,16.28,10.91" target="#b18">[19]</ref> have proposed a graph-based approach to measure relevance based on structural connections between argument units. Their hypothesis states that the content of arguments does not determine their relevance. The reasoning behind this hypothesis is the subjectivity of the content of an argument. Their proposed approach infers argument relevance from the number of arguments whose conclusions serve as a premise for other arguments.</p><p>Further, the approach incorporates the intrinsic relevance of those arguments in a recursive fashion. A recursive analysis of links between argument units allows for an objective assessment of argument relevance, as no human judgment is needed. The authors adopt vital components of the PageRank algorithm <ref type="bibr" coords="8,216.51,127.61,16.42,10.91" target="#b19">[20]</ref>. They use a framework of argument graphs, in which the arguments represent nodes. Arguments are split into premise and conclusion as argument units. Reusing a conclusion as a premise in another argument determines an edge between two argument nodes. An edge is constructed based on an interpretation function. The authors use an exact string match as an interpretation function.</p><p>Using our nested structure (multiple conclusions per topic and multiple premises per conclusion) provided by the initial retrieval step, we model one argument graph for each topic using the networkX <ref type="bibr" coords="8,178.30,222.46,17.86,10.91" target="#b20">[21]</ref> graph processing library. For edge interpretation, we reuse the vector embeddings of the initial retrieval and calculate the cosine similarity between each premise and all the other conclusions. If an interpretation threshold of .99 is surpassed, we would create an edge. Analyzing the threshold surpassing similarities over all topic-based argument graphs, we observe a high skew within the similarities (Figure <ref type="figure" coords="8,339.49,276.66,3.81,10.91" target="#fig_1">2</ref>, right). The skew can be attributed to the initial retrieval that is also based on the cosine similarity. Regarding the connectivity between arguments, the skewed distribution of cosine similarities leads to few highly connected argument nodes and a majority of nodes with only a single connection to another argument (Appendix 3a). In our system's setup, an application of a PageRank for arguments would not lead to any meaningful re-ranking scores.</p><p>Furthermore, we investigate the WMD for graph construction. Using the WMD instead of the cosine similarity should better assess the semantic differences between two argument units. We transform the WMD into a similarity to use it as an interpretation function. We call the transformed measurement word mover's similarity (WMS). WMS is gained by the following transformation ğ‘¤ğ‘šğ‘ (ğ‘  1 , ğ‘  2 ) = 1 1+ğ‘¤ğ‘šğ‘‘(ğ‘  1 ,ğ‘  2 ) . We assess an initial interpretation threshold of 0.2 that must be surpassed to draw an edge between two arguments. The similarity distribution over all topics differs tremendously from the distribution of cosine similarities (Figure <ref type="figure" coords="8,476.99,440.24,3.77,10.91" target="#fig_1">2</ref>, left). Nevertheless, similar to the argument graphs generated using cosine similarity, the node degree distribution is also skewed (Appendix 4b).</p><p>Next, we examined the total amount of edges for every topic for both interpretation functions (Appendix 3b and 4b). Due to the lower interpretation threshold of the WMS compared to the argument graph construction with the cosine similarity, the number of total edges in the argument graphs is higher. Increasing the threshold would lead to topics for which no WMS would surpass the threshold, thus not generating an argument graph. To alleviate the problem, an individual topic threshold must be tuned, questioning the general applicability of the re-ranking approach.</p><p>Finally, some edges could attribute the wrong arguments due to our initial deduplication of the provided corpus. The duplicated premises in the provided corpus originated from arguments citing each other within the crawled debate platforms. Our sentence level deduplication is based on exact string matches, and only the first occurrence of a sentence is kept, while the others are discarded. There, we could not enforce that a particular sentence is linked to the argument ID of the original argument, where it was written the first time. Due to the challenges outlined in this section, we did not further investigate a re-ranking based on argument graphs.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Final Scoring</head><p>Our system calculates the final re-ranking scores for conclusions and premises separately. For WMD and SD, we assess the final score ğ‘† of a premise or conclusion as a weighted sum between the initial cosine similarity ğ¼ and the respective re-ranking score ğ‘… (Equation <ref type="formula" coords="9,428.68,438.26,3.50,10.91" target="#formula_1">2</ref>). MMR does not need a weighted sum, as the MMR itself includes the initial re-ranking score information. Like ğœ† of the MMR, ğœ‡ controls the tradeoff between sentence relevance and difference to the query. A higher ğœ‡ emphasizes the initial ranking scores and penalizes the re-ranking score. ğ‘† denotes the final score between a query sentence ğ‘ and an indexed sentence ğ‘‘. We scale both ğ¼ and ğ‘… to the interval of [0, 1]. For each SD and WMD, we examined different parameters of ğœ‡, relying on our qualitative assessment of the generated rankings. For our final evaluations, we set ğœ‡ to the values of 0.9 for conclusions and 0.75 for premises. These parameter configurations were determined by a heuristic assessment of the relevance and quality of the generated rankings.</p><formula xml:id="formula_1" coords="9,209.63,573.75,297.01,11.95">ğ‘† (ğ‘,ğ‘‘) = ğœ‡ * ğ¼(ğ‘, ğ‘‘) + (1 -ğœ‡) * ğ‘…(ğ‘, ğ‘‘)<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Evaluation</head><p>We performed four runs on the TIRA platform <ref type="bibr" coords="9,296.88,632.38,17.85,10.91" target="#b21">[22]</ref> to ensure the reproducibility of our results. Runs are named after the planet Jupiter and the first three Galilean moons. The evaluation foots on the judgments that the task organizers provided. The reported scores adhere to the Resulting mean nDCG@5 for relevance, quality and coherence-based evaluation over 50 topics. Two of our re-ranking approaches could beat the baseline without any re-ranking on relevance. WMD achieves the highest quality score. All runs use a token factor of 1.75 for the initial retrieval. The the runs of SD and WMD use ğœ‡ = 0.9 for the re-ranking of conclusions and ğœ‡ = 0.75 for the re-ranking of premises. MMR uses a ğœ† = 0.75.</p><p>recommendation of calculating nDCG@5. Table <ref type="table" coords="10,307.14,256.58,5.11,10.91" target="#tab_0">1</ref> shows our relevance, quality, and sentence pair coherence results. To measure the effectiveness of our implemented re-ranking methods, we include a baseline (Jupiter) that relies on the initial retrieval based on the cosine similarities generated by Elasticsearch. Two re-ranking approaches, SD and WMD, could beat the baseline with a mean nDCG@5 of 0.588 and 0.583 for relevance. The run using SD ranks 12th for relevance among all submitted runs of the shared task. SD could not outperform the baseline regarding the quality. WMD showed the best quality measurement, ranking at 8th place among all participating runs. For relevance and quality, the MMR (Europa) experiment did worse in comparison to the baseline but slightly better than SD on quality. Unsurprisingly, none of our runs could achieve high scores regarding the coherence between two sentences, as our retrieval system does not optimize for this criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We examined whether re-ranking approaches that do not make inferences about argument quality can improve rankings generated by an initial semantic search. In our theory, the initial search maximizes topic relevance, and the argument agnostic re-rankings increase variety, potentially ranking more qualitative sentence pairs of premise and conclusion higher. We have implemented an argument retrieval system using word embeddings for the initial ranking and three argument quality agnostic re-ranking approaches to answer our research question. The re-ranking approaches foot on the maximal marginal relevance, the word mover's distance, and a novel distance measure based on a fuzzy matching on sentence tags, which we call structural distance. The results show that simple re-ranking approaches could outperform our baseline without re-ranking by a small margin. Our system introduces several parameters. The initial ranking uses a token factor, maximal marginal relevance imposes ğœ† and structural distance and word mover's distance use a weighting factor of ğœ‡. For the next iteration of TouchÃ©, when relevance and quality judgments on a sentence pair level are available, we will perform parameter fine-tuning to improve our outlined approaches in future research.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Argument Graphs: Edge Interpretation based on Cosine Similarity</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,89.29,293.21,416.69,8.93;9,89.29,305.22,416.69,8.87;9,88.93,317.18,417.05,8.87;9,89.29,329.13,416.70,8.87;9,89.29,341.09,416.70,8.87;9,89.29,353.04,136.20,8.87"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2:Comparison of the distribution of similarities between Word Mover's Similarity and Cosine Similarity.Word Mover's Similarity is gained by rescaling the Word Mover's Distance. Similarity values were gained by combining the similarities of the constructed argument graphs overall provided sample topics. Argument graph construction using word mover's similarity used an interpretation threshold of 0.2 to create an edge between two arguments, and the argument graph construction using cosine similarity used a threshold of .99.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="13,230.16,251.97,140.17,8.51;13,291.88,258.12,16.38,8.51;13,213.49,232.24,7.77,8.51;13,213.49,212.03,7.77,8.51;13,213.49,192.01,7.77,8.51;13,213.49,172.17,7.77,8.51;13,213.49,152.15,7.77,8.51;13,203.97,212.03,8.51,3.77;13,203.97,206.26,8.51,4.34;13,203.97,190.74,8.51,14.09;13,212.82,275.27,169.34,9.96"><head></head><label></label><figDesc>Node degree histogram over all topics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="13,166.46,444.58,6.36,9.46;13,203.50,444.58,6.36,9.46;13,240.54,444.58,6.36,9.46;13,277.58,444.58,6.36,9.46;13,314.62,444.58,6.36,9.46;13,350.07,444.58,9.54,9.46;13,247.26,451.41,33.69,9.46;13,155.96,439.18,3.18,9.46;13,149.60,423.36,9.54,9.46;13,146.42,407.55,12.72,9.46;13,146.42,391.73,12.72,9.46;13,146.42,375.92,12.72,9.46;13,146.42,360.10,12.72,9.46;13,146.42,344.29,12.72,9.46;13,146.42,328.47,12.72,9.46;13,146.42,312.66,12.72,9.46;13,135.84,383.16,9.46,4.19;13,135.84,366.38,9.46,15.19;13,187.88,474.19,219.22,9.96"><head></head><label></label><figDesc>Total count of edges between arguments per topic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="13,166.64,494.84,6.87,10.21;13,234.18,494.84,6.87,10.21;13,301.72,494.84,6.87,10.21;13,369.26,494.84,6.87,10.21;13,436.79,494.84,6.87,10.21;13,230.57,655.12,138.35,9.96;14,89.29,85.67,375.08,12.85;14,109.68,103.60,112.33,12.85;14,230.16,249.07,2.86,8.51;14,256.71,249.07,8.59,8.51;14,284.70,249.07,11.45,8.51;14,314.11,249.07,11.45,8.51;14,343.53,249.07,11.45,8.51;14,291.88,255.23,16.38,8.51;14,213.49,239.63,7.77,8.51;14,213.49,222.36,7.77,8.51;14,213.49,204.72,7.77,8.51;14,213.49,187.26,7.77,8.51;14,213.49,169.99,7.77,8.51;14,213.49,152.53,7.77,8.51;14,203.97,209.13,8.51,3.77;14,203.97,203.36,8.51,4.34;14,203.97,187.84,8.51,14.09;14,217.75,272.37,159.47,9.96"><head></head><label></label><figDesc>Node degree histogram of all topics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="14,179.58,425.95,5.72,8.51;14,212.91,425.95,5.72,8.51;14,246.25,425.95,5.72,8.51;14,279.59,425.95,5.72,8.51;14,312.92,425.95,5.72,8.51;14,344.83,425.95,8.59,8.51;14,252.30,432.10,30.32,8.51;14,170.13,421.09,2.86,8.51;14,158.68,398.19,14.31,8.51;14,158.68,375.28,14.31,8.51;14,158.68,352.37,14.31,8.51;14,158.68,329.47,14.31,8.51;14,158.68,306.56,14.31,8.51;14,149.16,370.68,8.51,3.77;14,149.16,355.58,8.51,13.67;14,187.88,453.29,219.22,9.96;14,175.24,474.90,7.63,11.35;14,250.28,474.90,7.63,11.35;14,325.32,474.90,7.63,11.35;14,400.36,474.90,7.63,11.35;14,475.40,474.90,7.63,11.35;14,253.97,652.22,138.35,9.96"><head></head><label></label><figDesc>Total count of edges between arguments per topic. Example graphs for five topics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="5,89.29,84.19,416.69,181.24"><head></head><label></label><figDesc></figDesc><graphic coords="5,89.29,84.19,416.69,181.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="10,88.99,89.90,337.76,82.44"><head>Table 1</head><label>1</label><figDesc></figDesc><table coords="10,168.53,89.90,258.22,62.22"><row><cell cols="4">Approach (TIRA tag) Relevance Quality Coherence</cell></row><row><cell>Baseline (Jupiter)</cell><cell>0.560</cell><cell>0.725</cell><cell>0.330</cell></row><row><cell>SD (Io)</cell><cell>0.588</cell><cell>0.719</cell><cell>0.365</cell></row><row><cell>MMR (Europa)</cell><cell>0.546</cell><cell>0.721</cell><cell>0.349</cell></row><row><cell>WMD (Ganymede)</cell><cell>0.583</cell><cell>0.776</cell><cell>0.377</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,108.93,671.02,178.46,8.97"><p>https://git.informatik.uni-leipzig.de/hit-girl/code</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="3,108.93,660.08,68.66,8.97"><p>https://ProCon.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="3,108.93,671.04,86.63,8.97"><p>https://uima.apache.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="4,108.93,671.03,143.00,8.97"><p>https://github.com/elastic/elasticsearch</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4" coords="5,108.66,660.06,397.33,8.97;5,89.29,671.02,78.59,8.97"><p>The sentence number presents the sentence's index in the array of premises of an argument within the preprocessed args.me</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5" coords="6,108.93,671.02,236.69,8.97"><p>https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6" coords="7,108.93,627.20,150.09,8.97"><p>https://universaldependencies.org/u/pos/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_7" coords="7,108.93,638.16,291.89,8.97"><p>https://github.com/explosion/spacy-models/releases/tag/en_core_web_md-3.3.0</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_8" coords="7,108.93,649.12,58.54,8.97"><p>https://spacy.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_9" coords="7,108.93,660.08,133.19,8.97"><p>https://github.com/life4/textdistance</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_10" coords="7,108.93,671.04,131.97,8.97"><p>https://github.com/src-d/wmd-relax</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="11,112.66,111.28,393.61,10.91;11,112.33,124.83,393.65,10.91;11,112.66,138.38,179.30,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,454.59,111.28,51.68,10.91;11,112.33,124.83,295.78,10.91">Conspiracy Theories and Their Societal Effects During the COVID-19 Pandemic</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Pummerer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>BÃ¶hm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lilleholt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Zettler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Sassenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,417.07,124.83,88.91,10.91;11,112.66,138.38,105.51,10.91">Social Psychological and Personality Science</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="49" to="59" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,151.93,395.17,10.91;11,112.66,165.48,395.17,10.91;11,112.66,179.03,395.01,10.91;11,112.41,192.57,393.57,10.91;11,112.66,206.12,339.15,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,361.25,165.48,146.58,10.91;11,112.66,179.03,62.60,10.91">Overview of TouchÃ© 2022: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>FrÃ¶be</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gurcke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,197.77,179.03,309.90,10.91;11,112.41,192.57,309.42,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction. 13th International Conference of the CLEF Association (CLEF 2022)</title>
		<title level="s" coord="11,429.80,192.57,76.18,10.91;11,112.66,206.12,78.83,10.91">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="11,112.66,219.67,393.53,10.91;11,112.28,233.22,249.12,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,414.77,219.67,91.42,10.91;11,112.28,233.22,123.67,10.91">Data Acquisition for Argument Search: The args</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,240.90,233.22,42.38,10.91">me Corpus</title>
		<imprint>
			<biblScope unit="page" from="48" to="59" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,246.77,394.53,10.91;11,112.30,260.32,394.98,10.91;11,112.66,273.87,393.33,10.91;11,112.66,287.42,232.08,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,264.52,260.32,221.57,10.91">Building an Argument Search Engine for the Web</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Al-Khatib</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Puschmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dorsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Morari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,112.66,273.87,393.33,10.91;11,112.66,287.42,46.58,10.91">Proceedings of the 4th Workshop on Argument Mining, Association for Computational Linguistics</title>
		<meeting>the 4th Workshop on Argument Mining, Association for Computational Linguistics<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="49" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,300.97,394.53,10.91;11,112.28,314.52,393.70,10.91;11,112.66,328.07,393.33,10.91;11,112.66,341.62,394.53,10.91;11,112.66,355.17,118.66,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,112.28,314.52,302.99,10.91">ArgumenText: Searching for Arguments in Heterogeneous Sources</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Daxenberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Stahlhut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Schiller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tauchmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Eger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,438.96,314.52,67.02,10.91;11,112.66,328.07,393.33,10.91;11,112.66,341.62,325.24,10.91">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations, Association for Computational Linguistics</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations, Association for Computational Linguistics<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="21" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,368.71,393.33,10.91;11,112.66,382.26,394.53,10.91;11,112.66,395.81,80.57,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,200.65,368.71,305.34,10.91;11,112.66,382.26,115.26,10.91">A Study of Smoothing Methods for Language Models Applied to Ad Hoc Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,250.68,382.26,80.94,10.91">ACM SIGIR Forum</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="268" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,409.36,394.53,10.91;11,112.28,422.91,394.90,10.91;11,112.66,436.46,395.01,10.91;11,112.41,450.01,393.58,10.91;11,112.66,463.56,335.38,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,219.18,422.91,217.68,10.91">TouchÃ©: First Shared Task on Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,355.45,436.46,152.22,10.91;11,112.41,450.01,242.24,10.91">Advances in Information Retrieval. 42nd European Conference on IR Research (ECIR 2020)</title>
		<title level="s" coord="11,436.84,451.02,69.15,9.72;11,112.66,464.57,74.59,9.72">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Castells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Jose</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>MagalhÃ£es</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Silva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12036</biblScope>
			<biblScope unit="page" from="517" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,477.11,394.52,10.91;11,112.66,490.66,393.33,10.91;11,112.66,504.21,394.52,10.91;11,112.66,517.76,393.33,10.91;11,112.66,531.30,393.33,10.91;11,112.41,544.85,394.78,10.91;11,112.66,558.40,55.16,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,336.55,490.66,169.43,10.91;11,112.66,504.21,38.69,10.91">Overview of TouchÃ© 2021: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>FrÃ¶be</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,238.75,517.76,267.23,10.91;11,112.66,531.30,328.83,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction. 12th International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="11,152.63,545.87,148.79,9.72">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Candan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>MÃ¼ller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="volume">12880</biblScope>
			<biblScope unit="page" from="450" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,571.95,393.33,10.91;11,112.66,585.50,394.53,10.91;11,112.66,599.05,65.30,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,285.35,571.95,220.63,10.91;11,112.66,585.50,211.44,10.91">Exploring Argument Retrieval for Controversial Questions Using Retrieve and Re-rank Pipelines</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Koniaev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schaefer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,346.97,585.50,130.06,10.91">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2285" to="2291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,612.60,393.32,10.91;11,112.66,626.15,395.01,10.91;11,112.66,639.70,48.96,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,278.17,612.60,227.82,10.91;11,112.66,626.15,198.39,10.91">Team Skeletor at TouchÃ© 2021: Argument Retrieval and Visualization for Controversial Questions</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">X</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,334.07,626.15,127.81,10.91">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2441" to="2454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,653.25,393.33,10.91;11,112.66,666.80,289.53,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,311.97,653.25,194.02,10.91;11,112.66,666.80,38.60,10.91">Learning to Rank Arguments with Feature Selection</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>FrÃ¶be</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,174.10,666.80,129.93,10.91">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2292" to="2301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,86.97,393.33,10.91;12,112.66,100.52,394.53,10.91;12,112.66,114.06,65.30,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,290.44,86.97,215.55,10.91;12,112.66,100.52,215.67,10.91">A Search Engine System for TouchÃ© Argument Retrieval Task to Answer Controversial Questions</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Raimondi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Alessio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Levorato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,350.80,100.52,126.98,10.91">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2423" to="2440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,127.61,393.33,10.91;12,112.66,141.16,288.87,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,304.04,127.61,201.95,10.91;12,112.66,141.16,38.01,10.91">Exploring Document Expansion for Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mailach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Eysoldt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kleine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,173.44,141.16,129.93,10.91">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2417" to="2422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,154.71,393.33,10.91;12,112.66,168.26,393.33,10.91;12,112.66,181.81,237.23,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,376.04,154.71,129.95,10.91;12,112.66,168.26,299.55,10.91">Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,420.35,168.26,85.63,10.91;12,112.66,181.81,143.15,10.91">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5776" to="5788" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,195.36,394.53,10.91;12,112.66,208.91,393.33,10.91;12,112.66,222.46,393.32,10.91;12,112.66,236.01,395.01,10.91;12,112.66,249.56,38.81,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,308.02,208.91,197.97,10.91;12,112.66,222.46,107.95,10.91">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Daxenberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,244.52,222.46,261.46,10.91;12,112.66,236.01,144.96,10.91">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="671" to="688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,263.11,393.33,10.91;12,112.66,276.66,393.33,10.91;12,112.66,290.20,131.24,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,226.94,263.11,279.05,10.91;12,112.66,276.66,172.49,10.91">The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,296.29,276.66,209.69,10.91;12,112.66,290.20,95.01,10.91">SIGIR Forum (ACM Special Interest Group on Information Retrieval</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,303.75,395.17,10.91;12,112.66,317.30,393.33,10.91;12,112.66,330.85,375.68,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,353.45,303.75,154.38,10.91;12,112.66,317.30,67.73,10.91">From Word Embeddings to Document Distances</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">I</forename><surname>Kolkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,203.86,317.30,302.13,10.91;12,112.66,330.85,155.37,10.91;12,322.66,330.85,35.59,10.91">Proceedings of the 32nd International Conference on International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="957" to="966" />
		</imprint>
	</monogr>
	<note>ICML&apos;15</note>
</biblStruct>

<biblStruct coords="12,112.66,344.40,393.33,10.91;12,112.30,357.95,232.12,10.91" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="12,296.39,344.40,209.60,10.91;12,112.30,357.95,54.83,10.91">Efficient Estimation of Word Representations in Vector Space</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,112.66,371.50,393.32,10.91;12,112.66,385.05,393.33,10.91;12,112.66,398.60,252.02,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="12,273.51,371.50,155.23,10.91">PageRank&quot; for Argument Relevance</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,452.02,371.50,53.96,10.91;12,112.66,385.05,393.33,10.91;12,112.66,398.60,46.74,10.91">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1117" to="1127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,412.15,393.33,10.91;12,112.66,425.70,304.41,10.91" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="12,311.38,412.15,194.60,10.91;12,112.66,425.70,72.01,10.91">The PageRank Citation Ranking: Bringing Order to the Web</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<idno>1999-66</idno>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>Stanford InfoLab</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="12,112.66,439.25,393.33,10.91;12,112.66,452.79,393.33,10.91;12,112.66,466.34,337.63,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="12,299.30,439.25,206.69,10.91;12,112.66,452.79,112.10,10.91">Exploring Network Structure, Dynamics, and Function using NetworkX</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A</forename><surname>Hagberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Schult</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Swart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,440.58,452.79,65.41,10.91;12,112.66,466.34,165.05,10.91">Proceedings of the 7th Python in Science Conference</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Vaught</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Millman</surname></persName>
		</editor>
		<meeting>the 7th Python in Science Conference<address><addrLine>Pasadena, CA USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="11" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,479.89,394.62,10.91;12,112.66,493.44,371.02,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="12,322.14,479.89,165.34,10.91">Tira Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,112.66,493.44,239.99,10.91">Information Retrieval Evaluation in a Changing World</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="123" to="160" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
