<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.69,106.66,379.65,15.42;1,89.29,132.57,324.97,5.42">Axiomatic Re-ranking and Query Reformulation Notebook for the Touché Lab on Argument Retrieval at CLEF 2022</title>
				<funder ref="#_ZKq6Und #_HwcFzkF">
					<orgName type="full">Deutsche Forschungsgemeinschaft (DFG)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.10,158.47,97.34,5.42"><forename type="first">Jan</forename><forename type="middle">Heinrich</forename><surname>Reimer</surname></persName>
							<email>jan.reimer@student.uni-halle.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Martin-Luther-Universität Halle-Wittenberg</orgName>
								<address>
									<postCode>06099</postCode>
									<settlement>Halle (Saale)</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,197.84,158.47,74.04,5.42"><forename type="first">Johannes</forename><surname>Huck</surname></persName>
							<email>johannes.huck@student.uni-halle.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Martin-Luther-Universität Halle-Wittenberg</orgName>
								<address>
									<postCode>06099</postCode>
									<settlement>Halle (Saale)</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,299.33,158.47,112.73,5.42"><forename type="first">Alexander</forename><surname>Bondarenko</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Martin-Luther-Universität Halle-Wittenberg</orgName>
								<address>
									<postCode>06099</postCode>
									<settlement>Halle (Saale)</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.69,106.66,379.65,15.42;1,89.29,132.57,324.97,5.42">Axiomatic Re-ranking and Query Reformulation Notebook for the Touché Lab on Argument Retrieval at CLEF 2022</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">2F1114A923C8D54C332B38DF18F288D4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Axiomatic Re-ranking</term>
					<term>Query Reformulation</term>
					<term>Comparative Questions</term>
					<term>Argument Quality</term>
					<term>Argument Stance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present the Team's Grimjack retrieval approaches for the Touché shared task on Argument Retrieval for Comparative Questions. In total, we submit five runs that pursue the two main objectives: favoring argumentative and high argument quality documents in the final ranking and balancing stance-based exposure by ensuring an even ratio of pro and con arguments at top ranks.</p><p>Our results indicate that BM25 outperforms query likelihood ranking for initial passage retrieval and that stance-based re-ranking can slightly improve a ranking effectiveness. For stance classification, prompting the T0 zero-shot language model is the best-performing approach when considering all available ground-truth labels.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Argument retrieval is a specific task that not only considers topical relevance of retrieved documents to given queries (usually of controversial, argumentative, or opinion nature) but also accounts for argument specific features like argument quality and stance <ref type="bibr" coords="1,419.15,438.81,11.42,4.94" target="#b0">[1,</ref><ref type="bibr" coords="1,433.29,438.81,7.62,4.94" target="#b1">2]</ref>. Furthermore, it has been shown that current search engines might return biased results <ref type="bibr" coords="1,426.61,452.36,12.99,4.94" target="#b2">[3]</ref> and argument retrieval systems return imbalanced pro / con arguments <ref type="bibr" coords="1,354.20,465.91,11.58,4.94" target="#b3">[4]</ref>. We especially emphasize the importance of retrieving diverse results for comparative questions (e.g., "Train or plane? Which is the better choice?") that provide different point of views to mitigate biasing users' decisions towards one or the other comparison option.</p><p>Our Team Grimjack participated in the Touché shared task on Argument Retrieval for Comparative Questions which goals are: <ref type="bibr" coords="1,255.24,533.66,11.81,4.94" target="#b0">(1)</ref> To retrieve relevant and high quality argumentative passages from a collection of 868 655 text passages to a set of 50 search topics and (2) to classify the stance of the retrieved passages towards the comparison objects in search topics <ref type="bibr" coords="1,456.10,560.76,11.28,4.94" target="#b4">[5]</ref>. As part of our participation in the task, we have developed a flexible retrieval pipeline in Python based on Pyserini <ref type="bibr" coords="2,142.90,90.23,12.87,4.94" target="#b5">[6]</ref> as an easily configurable command line application, which we release under a free open source license. 1 In the first step, our approach uses query (comparative questions from topics' titles) reformulation and expansion by important terms from topics' descriptions and narratives. Then the top-10 initially retrieved passages using query likelihood with Dirichlet smoothing <ref type="bibr" coords="2,138.20,144.43,12.68,4.94" target="#b6">[7]</ref> are axiomatically re-ranked based on the number and position of premises, claims (identified with TARGER <ref type="bibr" coords="2,200.83,157.97,10.93,4.94" target="#b7">[8]</ref>), and comparison objects, and argument quality predictions by the IBM Debater API <ref type="bibr" coords="2,168.42,171.52,12.86,4.94" target="#b8">[9]</ref> and T0++ <ref type="bibr" coords="2,229.55,171.52,16.27,4.94" target="#b9">[10]</ref>. Finally, the pro and con argumentative passages towards the compared objects are balanced in the final ranking by alternating documents of different stance (cf. Section 3 for more details on the approach and submitted runs). We also submitted our software using the TIRA platform <ref type="bibr" coords="2,258.38,212.17,17.81,4.94" target="#b10">[11]</ref> 2 that automatically evaluates submitted approaches and presents the results on a leaderboard.</p><p>Even though none of our runs (with query likelihood first-stage retrieval) outperform the official BM25 baseline in terms of relevance and rhetorical quality, we observe that stance-based re-ranking can slightly improve a ranking effectiveness while argument axiomatic re-ranking with KwikSort does not change retrieval effectiveness. Our runs using query expansion with the T0++ language model <ref type="bibr" coords="2,228.78,293.47,17.93,4.94" target="#b9">[10]</ref> should pose examples to discuss current doubts about the usefulness of large zero-shot language models in the field of search and information retrieval <ref type="bibr" coords="2,493.30,307.02,12.68,4.94" target="#b2">[3]</ref> as they are amongst the worst performing runs. For stance classification however, our T0-based approach using zero-shot prompts yields promising results, even though we are unable to directly compare it to other runs due to different test set coverage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Personal decision making often starts with formulating comparative questions like "Should I major in philosophy or psychology?" <ref type="bibr" coords="2,256.15,419.84,11.31,4.94" target="#b0">[1,</ref><ref type="bibr" coords="2,270.21,419.84,7.46,4.94" target="#b1">2,</ref><ref type="bibr" coords="2,280.40,419.84,7.55,4.94" target="#b4">5]</ref>. Short direct answers (potentially biased) <ref type="bibr" coords="2,476.49,419.84,17.87,4.94" target="#b11">[12]</ref> to such questions might be insufficient; instead, such questions require diverse opinions to provide a sufficient, balanced, and argumentative overview <ref type="bibr" coords="2,318.66,446.94,11.45,4.94" target="#b0">[1]</ref>. The Touché shared task on Argument Retrieval for Comparative Questions was proposed to evaluate retrieval approaches on a large corpus with respect to relevance and rhetorical quality of potential answers to comparative questions that also may represent different standpoints <ref type="bibr" coords="2,337.13,487.58,11.36,4.94" target="#b4">[5,</ref><ref type="bibr" coords="2,351.22,487.58,12.32,4.94" target="#b12">13]</ref>.</p><p>The most effective approaches at previous Touché editions <ref type="bibr" coords="2,371.56,501.13,11.48,4.94" target="#b0">[1,</ref><ref type="bibr" coords="2,386.13,501.13,9.03,4.94" target="#b1">2]</ref> successfully used query expansion with synonyms and antonyms <ref type="bibr" coords="2,271.81,514.68,16.10,4.94" target="#b13">[14]</ref>, identified premises and claims in retrieved documents <ref type="bibr" coords="2,119.58,528.23,16.54,4.94" target="#b14">[15,</ref><ref type="bibr" coords="2,138.84,528.23,12.40,4.94" target="#b15">16]</ref>, estimated argument quality <ref type="bibr" coords="2,285.63,528.23,16.39,4.94" target="#b13">[14]</ref>, and re-ranked initially retrieved documents based on argument quality and document "comparativeness", e.g., a ratio of comparative adjectives <ref type="bibr" coords="2,113.10,555.33,16.33,4.94" target="#b16">[17]</ref>. Inspired by the participant approaches from the previous Touché editions, we also include the components of argument mining and argument quality estimation in our retrieval pipeline, however, using different methods. We rely on a large language model T0 trained in multitask setting that showed to achieve state-of-the-art results for various Natural Language Processing tasks in zero-shot settings <ref type="bibr" coords="2,254.53,609.53,16.09,4.94" target="#b9">[10]</ref>. The largest pretrained T0 variant, T0++, was trained on 62 datasets with 12 task-specific prompts covering such tasks as question answering, sentiment analysis, summarization, etc. By using T0++, we aim for answering a question whether the abilities of large language models are sufficient for the new task of argument retrieval.</p><p>Our second idea of axiomatic re-ranking comes from axiomatic thinking in information retrieval, where axioms formally describe constraints that good retrieval model should fulfil, e.g., documents with more query term occurrences should be ranked higher Fang et al. <ref type="bibr" coords="3,487.30,414.49,16.29,4.94" target="#b17">[18]</ref>. It has already been shown that combining multiple axioms for re-ranking results of arbitrary retrieval models can improve final overall retrieval effectiveness <ref type="bibr" coords="3,374.17,441.59,16.16,4.94" target="#b18">[19]</ref>. Complementing existing retrieval axioms, Bondarenko et al. <ref type="bibr" coords="3,245.49,455.13,17.91,4.94" target="#b19">[20]</ref> introduced argumentativeness axioms based on claims and premises in documents identified with TARGER <ref type="bibr" coords="3,324.39,468.68,11.43,4.94" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approach</head><p>We design the architecture of our argumentative retrieval system as a multi-step pipeline that subsequently (re-)ranks, annotates, or modifies documents retrieved for each query with the query likelihood with Dirichlet smoothing (𝜇 = 1 000). As shown in Figure <ref type="figure" coords="3,435.16,554.41,3.81,4.94">1</ref>, our proposed pipeline consists of four main steps: (1) query expansion, reformulation, and combination, (2) first-stage retrieval, (3) argument quality estimation and stance detection, and (4) axiomatic re-ranking and stance-based re-ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Query Expansion, Reformulation, and Combination</head><p>The first step of our retrieval pipeline is original query (task's topic titles) reformulation and expansion that aims for increasing a recall. For that, we use two different strategies: (1) replacing the comparison objects with their synonyms (e.g., Ubuntu vs. Windows → Linux vs. Windows) and (2) generating additional, new queries exploiting the topics' description and narrative provided by the task organizers <ref type="bibr" coords="4,229.51,363.70,11.28,4.94" target="#b4">[5]</ref>. We then address the precision-recall trade-off by deploying re-ranking steps by moving more relevant documents at the top of the ranking (cf. Section 3.4).</p><p>Query Reformulation with Synonyms. To find synonyms of comparison objects mentioned in questions (search queries), we use two different strategies: (1) word embeddings and (2) a zero-shot generation with pre-trained large language models. For the first strategy, we use fastText word embeddings <ref type="bibr" coords="4,211.67,446.66,18.06,4.94" target="#b20">[21]</ref> from PyMagnitude<ref type="foot" coords="4,317.79,444.03,3.71,3.61" target="#foot_0">3</ref> to find the word with the highest cosine similarity to the given comparison objects in the embedding space. We manually examine synonyms from the fastText embeddings pre-trained on different corpora (e.g., Wikipedia and Twitter) and find that the Twitter-based embeddings provide more accurate synonyms.</p><p>Our second strategy is based on the T0++ zero-shot language model <ref type="bibr" coords="4,390.38,500.86,16.08,4.94" target="#b9">[10]</ref>. We prompt the model to generate an answer to the following question: What are synonyms of the word &lt;token&gt;?, where &lt;token&gt; is one of the two original comparison objects. We then process the output by splitting by commas and select the first term that is different from the original query term. With the synonyms returned by either strategy, we replace the comparison objects to formulate new question queries.</p><p>Query Reformulation with Topic Context. In the next step, we complement the expanded queries with two newly generated ones per topic taking into account the contextual information from the topic's descriptions and narratives that contain important details on the actual information. Using the Hugging Face Inference API <ref type="bibr" coords="4,403.65,638.01,16.41,4.94" target="#b21">[22]</ref>, we prompt T0++ with the following task: &lt;text&gt;. Extract a natural search query from this description., where &lt;text&gt; is either the topic's narrative or description. In Table <ref type="table" coords="5,436.63,103.78,3.81,4.94" target="#tab_1">1</ref>, we show the examples of generated queries. Albeit some of the generated queries (e.g., topic 53) are just reformulations of the original one, T0++ also generates potentially useful meaningful new queries (e.g., topic 12).</p><p>Query Combination and Expansion. Finally, we combine up to 5 question queries (reformulated with synonyms, generated, and the original one, depending on the submitted run; cf. Section 4) using a logical disjunction (Pyserini's OR operator). We choose the logical disjunction with the outlook on increasing the system's recall and decreasing the chance of empty result sets in the case that search terms are not present in the corpus.</p><p>In total we submitted 5 runs (retrieval results; cf. Section 4) to the task, in some of which we use only the original query, and the expanded queries in the others to test the influence of the query expansion and reformulation on the final ranking results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Passage Retrieval</head><p>To retrieve passages from the task's corpus, we first build an inverted index using the Pyserini framework <ref type="bibr" coords="5,141.46,331.30,11.49,4.94" target="#b5">[6]</ref>. In the index, we store index term positions, passage vectors, and raw passage contents. Index terms are stemmed using the Porter stemmer <ref type="bibr" coords="5,353.80,344.85,17.76,4.94" target="#b22">[23]</ref> and stop words are removed as per the default Pyserini stopword list <ref type="bibr" coords="5,251.54,358.40,11.27,4.94" target="#b5">[6]</ref>. We then retrieve passages for the previously combined query (cf. Section 3.1) using the query likelihood model with Dirichlet smoothing (𝜇 = 1 000). From this first-stage ranker, we retrieve 100 candidate passages for each query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Argument Tagging, Argument Quality and Stance Classification</head><p>After retrieving candidate passages, we tag the argumentative structure (premises and claims), estimate argument quality, and detect the stance (whether the passage is pro first comparison object, pro second, has neutral, or no stance.). This information is used in later steps of our retrieval pipeline for re-ranking (cf. Section 3.4). We tag each passage's argumentative structure with the TARGER argument tagger <ref type="bibr" coords="5,248.48,489.43,12.84,4.94" target="#b7">[8]</ref> using the targer-api Python package <ref type="foot" coords="5,435.78,486.79,3.71,3.61" target="#foot_1">4</ref> .</p><p>To estimate the passage's argument quality and detect the stance, we first split each passage into sentences using the NLTK library <ref type="bibr" coords="5,268.26,516.52,16.41,4.94" target="#b23">[24]</ref>. Then each sentence is treated as one potential argument; the quality score and stance for the whole passage is calculated by averaging the quality or stance scores for all sentences in the passage.</p><p>Argument Quality Estimation. We use two different methods for assessing the argument quality. Our first method is based on the IBM Debater API <ref type="bibr" coords="5,350.19,585.93,11.42,4.94" target="#b8">[9]</ref>. <ref type="foot" coords="5,365.42,583.30,3.71,3.61" target="#foot_2">5</ref> The API then determines how good the quality of each argument with regard to the topic is with a Bert-based <ref type="bibr" coords="5,440.54,599.48,17.76,4.94" target="#b24">[25]</ref> regression classifier model trained on the IBM-ArgQ-6.3kArgs dataset. The API returns a quality score ranging from 0 (low quality) to 1 (high quality). As a second method to obtain the argument quality we also use the T0++ model <ref type="bibr" coords="6,468.25,298.34,18.06,4.94" target="#b9">[10]</ref> and prompt it to generate a text to the following task: &lt;sentence&gt;. How would you rate the readability and consistency in this sentence? very good, good, bad, very bad, where &lt;sentence&gt; is one of the passage sentences. We then map the models textual outputs to numeric values using the mapping shown in Table <ref type="table" coords="6,316.59,352.54,8.31,4.94" target="#tab_1">1a</ref>.</p><p>Stance Detection. Stance detection for each sentence uses the same conceptual approaches but with different inputs and outputs. Since both the IBM Debater API <ref type="bibr" coords="6,403.98,394.85,17.89,4.94" target="#b25">[26]</ref> and T0++ <ref type="bibr" coords="6,469.88,394.85,17.88,4.94" target="#b9">[10]</ref> can predict only a single-target stance (i.e., for one of the two comparison objects), we combine the two single-target stance scores into a multi-target stance by taking the difference between the stance towards the first object and the stance towards the second object. We also experimented with different thresholds for the minimal difference between the single-target stances and found a threshold of 0.125 to work well by manually examining some classified examples.</p><p>For scoring the single-target argument stance for a sentence with the IBM Debater API, we again query the API with a sentence (argument) and a topic created using one of the comparison objects The classifier <ref type="bibr" coords="6,183.38,503.24,17.78,4.94" target="#b25">[26]</ref> then computes an argument's likelihood of being pro, con, or neutral with respect to the topic (i.e., the comparison object in our pipeline) by first classifying a sentiment and then detecting whether the topic's and argument's targets contradict each other. The API then returns a score from from -1 (against the comparison object) to +1 (in favor). By classifying different topics for each object (i.e., &lt;object&gt; is good and &lt;object&gt; is the best), we determine an averaged single-target stance for each comparison object.</p><p>When using the T0++ for the stance detection, we first experiment with directly prompting the model to output 'pro', 'con', or 'neutral' labels for the comparison objects. We formulate the task as two simple questions passed to the model, one to determine whether the sentence has a positive stance towards the comparison object and one to determine whether it has a negative stance: &lt;sentence&gt; Is this sentence pro &lt;object&gt;? yes or no and &lt;sentence&gt; Is this sentence against &lt;object&gt;? yes or no, where &lt;sentence&gt; is one sentence of the passage and &lt;object&gt; is one of the comparative objects. This results in two answers (yes</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2</head><p>Axioms used in our retrieval pipeline. An asterisk ( ⋆ ) indicates newly proposed axioms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name Description</head><p>ArgUC <ref type="bibr" coords="7,170.01,139.53,16.46,8.87" target="#b19">[20]</ref> Prefer more argumentative units. QTArg <ref type="bibr" coords="7,168.60,151.49,16.46,8.87" target="#b19">[20]</ref> Prefer more query terms in argumentative units. QTPArg <ref type="bibr" coords="7,174.07,163.45,16.46,8.87" target="#b19">[20]</ref> Prefer earlier query terms in argumentative units. CompArg ⋆ Prefer more comparative objects in argumentative units. CompPArg ⋆ Prefer earlier comparative objects in argumentative units. aSLDoc <ref type="bibr" coords="7,172.96,199.31,16.46,8.87" target="#b26">[27]</ref> Prefer passages with 12-20 words per sentence. ArgQ ⋆ Prefer higher argument quality.</p><p>or no) for the positive and negative stance respectively. We combine the two textual answers using the mapping shown in Table <ref type="table" coords="7,246.04,263.65,8.57,4.94" target="#tab_1">1b</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Axiomatic and Stance-based Re-rankers</head><p>Since recall of our retrieval system is increased by expanding and reformulating queries (cf. Section 3.1), we seek to improve precision by re-ranking the top-10 passages from the first-stage retrieval (cf. Section 3.2) using two different strategies that should rank more argumentative and of higher quality passages also ensuring a balanced overview of the two comparison objects.</p><p>(1) We re-rank based on argumentativeness axioms, and (2) we re-rank based on the passages' stances towards the comparison objects.</p><p>Argumentative Axiomatic Re-ranking. Ranking methods such as BM25 or query likelihood with Dirichlet smoothing do not capture the "argumentativeness" in text that is important for argument retrieval <ref type="bibr" coords="7,194.98,436.98,11.58,4.94" target="#b4">[5]</ref>. Some approaches for at the TREC Common Core and Decision tracks exploit task-specific, argumentativeness axioms to address the document argumentativeness <ref type="bibr" coords="7,129.12,464.08,16.55,4.94" target="#b19">[20,</ref><ref type="bibr" coords="7,148.86,464.08,12.42,4.94" target="#b26">27]</ref>. Axioms are constraints that define pairwise ranking preferences between documents or passages. Because of the promising development in the field of axiomatic information retrieval <ref type="bibr" coords="7,165.55,491.18,16.41,4.94" target="#b27">[28]</ref>, we re-rank the top-10 initially retrieved passages with the KwikSort algorithm <ref type="bibr" coords="7,137.03,504.73,16.42,4.94" target="#b18">[19]</ref>. For axiomatic re-ranking, we compute preferences for 7 argumentativeness axioms specified in Table <ref type="table" coords="7,202.58,518.28,3.68,4.94" target="#tab_2">2</ref>. The axioms cover general argumentativeness (ArgUC), argumentative relevance (QTArg, QTPArg), comparative relevance (CompArg, CompPArg), and rhetorical and argumentative quality (aSLDoc, ArgQ). We then combine the axioms in a majority voting scheme, i.e., we only keep preferences where at least 50 % of the 7 axioms agree, and fall back to the original ranking order if less than 50 % of all axioms agree. Using the ir_axioms framework <ref type="bibr" coords="7,141.07,586.02,16.25,4.94" target="#b27">[28]</ref>, <ref type="foot" coords="7,161.38,583.39,3.71,3.61" target="#foot_3">6</ref> we then re-rank with the combined axiom.</p><p>Stance-based Re-ranking. We also implement a stance-based re-ranker to produce rankings where the two conflicting stances (pro first comparison object and pro second comparison object) are nearly equally present. For balancing the stances, we experiment with two different re-ranking strategies: (1) alternating stance and (2) balanced top-𝑘 stance. For the alternating stance strategy, we split the result set into three lists: <ref type="bibr" coords="8,331.95,103.78,11.76,4.94" target="#b0">(1)</ref> with arguments in favor of the first comparison object, (2) in favor of the second comparison object, and (3) neutral arguments or arguments with no stance. We then alternately select passages from the first two lists. If one or both lists are empty, we fall back to the neutral list. The balanced top-𝑘 stance strategy is based on the original ranking. Here we count the number of passages in favor of the first comparison object and the second comparison object in the top-𝑘 initially retrieved passages. If the difference of these two values is greater than 1, we move the last passage from the majority within the top-𝑘 ranking behind the first minority passage after the top-𝑘 ranking. This way, passages of the underrepresented stance advance the ranking until the ranking is balanced in the top-𝑘 positions. In initial experiments, however, we find the alternating stance strategy to be more promising, because the balanced top-𝑘 stance strategy often lead to rankings containing mostly neutral passages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Submitted Runs</head><p>We submit five runs that use different components and strategies of our pipeline (cf. Section 3) to the Touché second task. Instead of uploading generated run files, we deploy our retrieval system as a working software on the TIRA platform <ref type="bibr" coords="8,323.09,338.54,16.25,4.94" target="#b10">[11]</ref>.</p><p>Query Likelihood Baseline (Run 1). For our first run, we simply retrieve top-100 passages ranked by query likelihood with Dirichlet smoothing <ref type="bibr" coords="8,320.14,380.85,12.68,4.94" target="#b6">[7]</ref> (𝜇 = 1000) for the original, unmodified queries (topic titles) and tag argument stance by comparing sentiments for each object using the IBM Debater API, treating a stance under a threshold of 0.125 as neutral.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Argument Axioms (Run 2).</head><p>To produce our second run, we re-rank the top-10 passages from the baseline result using KwikSort <ref type="bibr" coords="8,281.84,450.26,16.56,4.94" target="#b27">[28,</ref><ref type="bibr" coords="8,301.75,450.26,14.11,4.94" target="#b18">19]</ref> based on preferences from the argument axioms as described in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stance-based Re-ranking with Argumentative Axioms (Run 3).</head><p>Our third run also uses argument axiomatic re-ranking after the baseline retrieval. However to ensure that the stances towards both comparison objects are nearly equally represented in the result ranking, we apply stance-based re-ranking with the alternating stance strategy as described in Section 3.4.</p><p>All You Need is T0 (Run 4). Large language models have recently found application in many NLP tasks, web search, or retrieval. The trend of using large language models for solving almost any task has also been criticized. For instance, Shah and Bender <ref type="bibr" coords="8,400.68,589.07,12.84,4.94" target="#b2">[3]</ref> highlight conceptual flaws that question if such an extreme usage of not fully understood models is desirable when implementing search for answers to real-life questions (e.g., in search engines).</p><p>In our fourth submitted run, we want test a language model's T0++ zero-shot classification abilities. First, we reformulate and generate and combine queries; final queries are an expansion of the topic titles (cf. Section 3.1). We then retrieve 100 documents using query likelihood, and use T0++ again to estimate argument quality and stance (cf. Section 3.3).</p><p>Argumentative Stance-based Re-ranking with T0 (Run 5). In our last run, we combine most of the methods introduced in Section 3 to generate a ranking that is both as argumentative as possible and equally represents argument stances, but also uses T0++ for query reformulation and expansion. Here, we combine new queries generated by T0++ and reformulate queries by replacing synonyms returned by T0++. However, we also use synonyms from the fastText <ref type="bibr" coords="9,488.15,144.43,17.83,4.94" target="#b20">[21]</ref> embedding similarity method (cf. Section 3.1); final queries are an expansion of the topic titles. The top-10 results of the 100 passages retrieved using query likelihood for the expanded queries are then re-ranked based on the argumentativeness axioms and by alternating stance (cf. Section 3.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>We evaluate our approach by effectiveness to retrieve relevant and high-quality passages and to predict the correct stance towards the comparison objects, using manual judgments provided by Touché. The task organizers asked human volunteers to label each document pooled from all submitted runs at depth 5 with respect to relevance (0: not relevant, 1: relevant, 2: highly relevant), rhetorical quality (0: low quality or not argumentative, 1: average quality, 2: high quality), and stance (pro first object, pro second object, neutral, no stance).</p><p>The results for the relevance and quality effectiveness using nDCG@5 (Tables <ref type="table" coords="9,445.42,338.54,5.01,4.94">3</ref> and<ref type="table" coords="9,472.07,338.54,4.11,4.94" target="#tab_3">4</ref>) show that our baseline Run 1 using query likelihood with Dirichlet smoothing performs worse than the BM25 baseline (Puss in Boots <ref type="bibr" coords="9,240.04,365.64,11.15,4.94" target="#b4">[5]</ref>). Since our other runs re-rank retrieved results from the initial ranking, we compare our individual re-ranking strategies. Nonetheless, we acknowledge that all of our submitted runs are outperformed by the BM25 baseline and other dense rankers' results submitted to the shared task. The differences in nDCG@5 scores compared to our query likelihood baseline indicate that axiomatic re-ranking (Run 2) can increase consistency with argumentativeness axioms while retaining equal retrieval effectiveness. Unfortunately, query expansion with T0++ slightly decreases nDCG@5 on average by about 3 p.p. for relevance judgments and 2 p.p. for quality judgments. Stance-based re-ranking, however, can increase nDCG@5 by up to 5 p.p. for relevance judgments and by 4 p.p. for quality judgments. None of our re-ranking stages could sufficiently compensate for the worse retrieval performance of the initial query likelihood ranking.</p><p>For stance detection, we compare the T0-based stance classification approach with the best competing team's approach (Captain Levi, pre-trained RoBerta without fine-tuning) and the baseline (Puss in Boots) that predicts the majority class ('no stance'). In Table <ref type="table" coords="9,443.47,541.78,3.81,4.94">5</ref>, we report a macro-averaged F 1 -score per run and per team as well as the number of documents 𝑁 for which the predicted stance has a ground-truth label as provided by the task organizers. We observe that since only the top-5 passages were pooled for manual judgments only a limited number of predicted stance labels (e.g. 1208 for Run 4) can be used for evaluation, even though we predicted the stance up to depth 100 (i.e. 5000 predicted stance labels per run). In this setting our Run 4 (i.e. stance prediction using T0++; cf. Section 3.3) has the highest macro-averaged F 1 -score of all submitted runs to the task. However, due to the limited number of labels available for evaluation and because the number of available labels differs across teams and runs, we cannot directly compare different runs. For example, the 3 792 unjudged labels from Run 4 could be correctly</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 3</head><p>Relevance results of selected runs submitted to Task 2: Argument Retrieval for Comparative Questions. Reported are the mean nDCG@5 and the 95% confidence intervals for our runs, the best task's run result (team Captain Levi), and the official task baseline (Puss in Boots, in italics). Reported are the mean nDCG@5 and the 95% confidence intervals for our runs, the best task's run result (team Aldo Nadi), and the official task baseline (Puss in Boots, in italics). predicted (i.e., increasing F 1 ) or incorrectly predicted (i.e., decreasing F 1 ). As an alternative, comparable measure, in the rightmost columns of Table <ref type="table" coords="10,347.69,497.48,3.81,4.94">5</ref>, we report F 1 -scores of predicted stances of only the top-5 passages of each run. All 250 stance labels from the top-5 results of each submitted run have corresponding ground-truth labels due to the organizers' top-5 pooling for manual judgment. When considering only the top-5 passages, our stance classification approach using T0++ falls behind Team Captain Levi's best performing approaches. However, 250 samples might also be an insufficient sample size to compare classifier performance. It is also unclear how examining only top results affects the evaluation of classification performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Team</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Team</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In our approaches to retrieve relevant and high-quality argumentative passages that help answer comparative questions, we combine query reformulation and expansion techniques with axiomatic re-ranking exploiting argumentative structure and argument quality and stance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5</head><p>Stance detection results of selected runs submitted to Task 2: Argument Retrieval for Comparative Questions. Reported are a macro-averaged F 1 score and number of documents N where the predicted stance has a ground-truth label for our runs, the best task's run result (team Captain Levi), and the official task baseline that always predicts 'no stance' (Puss in Boots, in italics). F 1 score is computed for all predicted stance labels with corresponding ground-truth labels (All) or only for the top-5 passages per run (Top-5). Using the IBM Debater API and the T0++ language model, we showcase two state-of-the-art approaches for argument quality estimation. We extend previous query expansion approaches used in the Touché shared tasks by incorporating the contextual information provided in topics' descriptions and narratives. To attain nearly equal exposure across argument stances in the final ranking, we balance the pro and con arguments on top-10 ranks. While none of our runs outperform the BM25 baseline in terms of nDCG@5 on relevance and quality judgments, we find that axiomatic re-ranking and stance-based re-ranking can slightly increase the effectiveness of the first-stage query likelihood ranking. This poses an interesting direction for future work: applying our proposed re-ranking strategies to results of other retrieval models, e.g., BM25. Since our run featuring query expansion with generated texts by T0++ is the worst-performing in terms of relevance and rhetorical quality, we also question the usefulness of large language models in early retrieval stages. Our results represent additional motivation to investigate the effect of explainability on retrieval performance, as recently questioned in the community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Team</head><p>Our approach to stance classification heuristically maps single-target stance classification results to multi-target, and we were not able to find a satisfactory strategy to distinguish neutral stance from passages without stance. Arguably, fine-tuning a multi-class neural classifier like Bert on the stance dataset provided by Touché could possibly improve classification performance by directly predicting the multi-target stance. Our evaluation of F 1 stance prediction performance yields no clear winner as the participating teams predicted stance labels for different, potentially biased sub-sets of the document collection resulting in different test set coverage. We encourage future work to reproduce and evaluate stance prediction approaches of all participating teams on an independent test dataset.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,89.29,89.92,416.69,251.98"><head></head><label></label><figDesc>Architecture overview for the modular retrieval pipeline used to produce our runs. Dashed boxes indicate optional steps, that are not used in all runs.</figDesc><table coords="3,89.29,89.92,352.72,240.03"><row><cell>Passages</cell><cell>Indexing</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Retrieval</cell></row><row><cell>Topics</cell><cell>Query Expansion / Reformulation Query Expansion / Reformulation</cell><cell>Query Combination</cell></row><row><cell></cell><cell>Quality</cell><cell>Stance</cell></row><row><cell></cell><cell>Tagging</cell><cell>Tagging</cell></row><row><cell></cell><cell>Axiomatic Re-ranking</cell><cell>Stance-based Re-ranking</cell><cell>Ranking</cell></row><row><cell>Figure 1:</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.99,90.49,416.99,229.70"><head>Table 1</head><label>1</label><figDesc>Original queries (topic titles) provided by Touché and generated queries by T0++<ref type="bibr" coords="4,416.55,102.49,16.34,8.87" target="#b9">[10]</ref> by prompting the topic's description (D) or narrative (N).</figDesc><table coords="4,95.27,134.01,406.40,186.17"><row><cell cols="2">Topic Original query</cell><cell cols="2">Field Generated query</cell></row><row><cell>12</cell><cell>Train or plane? Which is the better choice?</cell><cell>D N</cell><cell>Travel What are the benefits of trains over planes for inter-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>continental travel?</cell></row><row><cell>53</cell><cell>Should I buy steel or ceramic knives?</cell><cell>D</cell><cell>Why should I choose ceramic knives over steel knives?</cell></row><row><cell></cell><cell></cell><cell>N</cell><cell>What are the pros and cons of ceramic knives?</cell></row><row><cell>88</cell><cell>Should I major in philosophy or psychology?</cell><cell>D</cell><cell>What is the difference between philosophy and psy-chology?</cell></row><row><cell></cell><cell></cell><cell>N</cell><cell>What are the benefits of a major in English or his-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>tory?</cell></row><row><cell>95</cell><cell>Which is more environmentally friendly, a</cell><cell>D N</cell><cell>What are the most environmentally friendly cars? What is more environmentally friendly, a diesel or a</cell></row><row><cell></cell><cell>hybrid or a diesel?</cell><cell></cell><cell>hybrid car?</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.98,90.49,417.60,177.89"><head>Table 2</head><label>2</label><figDesc>Argument quality label and argument stance label mapping from textual tokens returned T0++<ref type="bibr" coords="6,479.64,102.49,14.92,8.87" target="#b9">[10]</ref>.(a) Argument quality label mapping for the promptHow would you rate the readability and consistency in this sentence?. Argument stance label mapping for the prompts Is this sentence pro &lt;object&gt;? (Pro) and Is this sentence against &lt;object&gt;? (Con) given a single comparative object &lt;object&gt;.</figDesc><table coords="6,145.45,127.29,327.87,141.08"><row><cell>Text Label</cell><cell>Value</cell><cell cols="2">(b) Text Label</cell><cell>Value</cell></row><row><cell>very good</cell><cell>1.00</cell><cell>Pro</cell><cell>Con</cell><cell></cell></row><row><cell>good</cell><cell>0.75</cell><cell>yes / pro</cell><cell>yes / con</cell><cell>0</cell></row><row><cell>bad</cell><cell>0.25</cell><cell>yes / pro</cell><cell>no</cell><cell>+1</cell></row><row><cell>very bad</cell><cell>0.00</cell><cell>no</cell><cell>yes / con</cell><cell>-1</cell></row><row><cell>other</cell><cell>0.50</cell><cell>no</cell><cell>no</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>other</cell><cell>other</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="10,88.99,145.96,418.53,158.42"><head>Table 4</head><label>4</label><figDesc>Quality results of selected runs submitted to Task 2: Argument Retrieval for Comparative Questions.</figDesc><table coords="10,151.21,145.96,292.85,115.29"><row><cell></cell><cell>Run</cell><cell></cell><cell>nDCG@5</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Mean</cell><cell>Low</cell><cell>High</cell></row><row><cell>Captain Levi [29]</cell><cell>dense_initial_retr.</cell><cell>0.758</cell><cell>0.708</cell><cell>0.810</cell></row><row><cell>Puss in Boots [5]</cell><cell>BM25-Baseline</cell><cell>0.469</cell><cell>0.403</cell><cell>0.535</cell></row><row><cell>Grimjack</cell><cell>Run 3</cell><cell>0.422</cell><cell>0.349</cell><cell>0.500</cell></row><row><cell>Grimjack</cell><cell>Run 2</cell><cell>0.376</cell><cell>0.299</cell><cell>0.455</cell></row><row><cell>Grimjack</cell><cell>Run 1</cell><cell>0.376</cell><cell>0.301</cell><cell>0.459</cell></row><row><cell>Grimjack</cell><cell>Run 5</cell><cell>0.349</cell><cell>0.270</cell><cell>0.425</cell></row><row><cell>Grimjack</cell><cell>Run 4</cell><cell>0.345</cell><cell>0.273</cell><cell>0.425</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="4,108.93,673.69,143.20,4.06"><p>https://gitlab.com/Plasticity/magnitude</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="5,108.93,662.73,143.18,4.06"><p>https://github.com/webis-de/targer-api</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="5,108.93,673.69,180.99,4.06"><p>https://early-access-program.debater.res.ibm.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="7,108.93,673.70,145.43,4.06"><p>https://github.com/webis-de/ir_axioms/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was partially supported by the <rs type="funder">Deutsche Forschungsgemeinschaft (DFG)</rs> through the project "<rs type="grantNumber">ACQuA 2.0</rs>" (<rs type="projectName">Answering Comparative Questions with Arguments</rs>; project number <rs type="grantNumber">376430233</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_ZKq6Und">
					<idno type="grant-number">ACQuA 2.0</idno>
					<orgName type="project" subtype="full">Answering Comparative Questions with Arguments</orgName>
				</org>
				<org type="funding" xml:id="_HwcFzkF">
					<idno type="grant-number">376430233</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="12,112.66,200.27,394.52,4.94;12,112.66,213.82,393.33,4.94;12,112.66,227.36,393.33,4.94;12,112.66,240.91,394.53,4.94;12,112.66,252.21,395.00,9.72;12,112.66,268.01,218.47,4.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,336.55,213.82,169.43,4.94;12,112.66,227.36,38.77,4.94">Overview of Touché 2020: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/paper_261.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="12,435.95,227.36,70.03,4.94;12,112.66,240.91,286.65,4.94">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="12,287.49,252.21,151.17,9.72">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">September 22-25, 2020. 2696. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,281.56,394.52,4.94;12,112.66,295.11,393.33,4.94;12,112.66,308.66,393.33,4.94;12,112.14,322.21,395.05,4.94;12,112.66,333.51,394.52,9.72;12,112.66,349.31,378.89,4.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,336.55,295.11,169.43,4.94;12,112.66,308.66,38.31,4.94">Overview of Touché 2021: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2936/paper-205.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="12,422.71,308.66,83.28,4.94;12,112.14,322.21,340.26,4.94">Proceedings of the Working Notes of CLEF 2021 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="12,377.97,333.51,129.22,9.72;12,112.66,349.31,21.79,4.94">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<meeting>the Working Notes of CLEF 2021 -Conference and Labs of the Evaluation Forum<address><addrLine>Bucharest, Romania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">September 21st -to -24th, 2021. 2936. 2021</date>
			<biblScope unit="page" from="2258" to="2284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,362.86,393.33,4.94;12,112.66,376.41,393.33,4.94;12,112.41,389.95,375.88,4.94" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,219.44,362.86,72.16,4.94">Situating Search</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<idno type="DOI">10.1145/3498366.3505816</idno>
		<ptr target="https://doi.org/10.1145/3498366.3505816" />
	</analytic>
	<monogr>
		<title level="m" coord="12,401.48,362.86,104.51,4.94;12,112.66,376.41,258.80,4.94">CHIIR &apos;22: ACM SIGIR Conference on Human Information Interaction and Retrieval</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Elsweiler</surname></persName>
		</editor>
		<meeting><address><addrLine>Regensburg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2022">March 14 -18, 2022. 2022</date>
			<biblScope unit="page" from="221" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,403.50,393.33,4.94;12,112.66,417.05,393.33,4.94;12,111.79,430.60,395.40,4.94;12,112.30,444.15,395.36,4.94;12,112.66,457.70,204.07,4.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,353.75,403.50,152.23,4.94;12,112.66,417.05,38.73,4.94">Evaluating Fairness in Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">P</forename><surname>Cherumanal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Scholer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<idno type="DOI">10.1145/3459637.3482099</idno>
		<ptr target="https://doi.org/10.1145/3459637.3482099" />
	</analytic>
	<monogr>
		<title level="m" coord="12,479.10,417.05,26.89,4.94;12,111.79,430.60,390.00,4.94">CIKM &apos;21: The 30th ACM International Conference on Information and Knowledge Management</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Demartini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Culpepper</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Tong</surname></persName>
		</editor>
		<meeting><address><addrLine>Virtual Event, Queensland, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021">November 1 -5, 2021. 2021</date>
			<biblScope unit="page" from="3363" to="3367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,471.25,395.17,4.94;12,112.66,484.80,395.17,4.94;12,112.66,498.35,395.01,4.94;12,112.41,511.90,393.57,4.94;12,112.66,525.45,282.01,4.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,361.25,484.80,146.58,4.94;12,112.66,498.35,62.60,4.94">Overview of Touché 2022: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gurcke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,197.77,498.35,309.90,4.94;12,112.41,511.90,309.42,4.94">Experimental IR Meets Multilinguality, Multimodality, and Interaction. 13th International Conference of the CLEF Association (CLEF 2022)</title>
		<title level="s" coord="12,429.80,511.90,76.18,4.94;12,112.66,525.45,78.83,4.94">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,539.00,393.33,4.94;12,112.33,552.55,393.66,4.94;12,112.66,564.08,379.44,9.20" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="12,355.76,539.00,150.23,4.94;12,112.33,552.55,359.89,4.94">Pyserini: An Easy-to-Use Python Toolkit to Support Replicable IR Research with Sparse and Dense Representations</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="2102.10073" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,579.64,393.33,4.94;12,112.66,593.19,393.32,4.94;12,112.66,606.74,393.33,4.94;12,112.66,620.29,394.53,4.94;12,112.66,633.84,330.97,4.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,210.06,579.64,295.92,4.94;12,112.66,593.19,114.51,4.94">A Study of Smoothing Methods for Language Models Applied to Ad Hoc Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<idno type="DOI">10.1145/383952.384019</idno>
		<ptr target="https://doi.org/10.1145/383952.384019" />
	</analytic>
	<monogr>
		<title level="m" coord="12,480.49,593.19,25.49,4.94;12,112.66,606.74,393.33,4.94;12,112.66,620.29,183.68,4.94">SIGIR 2001: Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Harper</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Kraft</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Zobel</surname></persName>
		</editor>
		<meeting><address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">September 9-13, 2001. 2001</date>
			<biblScope unit="page" from="334" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,647.39,394.53,4.94;12,112.28,660.94,395.55,4.94;13,112.66,90.23,393.53,4.94;13,112.66,103.78,394.62,4.94;13,112.66,117.33,395.01,4.94;13,112.66,130.88,190.02,4.94" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,182.53,660.94,244.98,4.94">TARGER: Neural Argument Mining at Your Fingertips</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Chernodub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Oliynyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Heidenreich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p19-3031</idno>
		<ptr target="https://doi.org/10.18653/v1/p19-3031" />
	</analytic>
	<monogr>
		<title level="m" coord="13,235.08,90.23,271.11,4.94;13,112.66,103.78,164.48,4.94;13,112.66,117.33,105.99,4.94">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Costa-Jussà</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Alfonseca</surname></persName>
		</editor>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-08-02">July 28 -August 2, 2019. 2019</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="195" to="200" />
		</imprint>
	</monogr>
	<note>System Demonstrations</note>
</biblStruct>

<biblStruct coords="13,112.66,144.43,394.53,4.94;13,112.66,157.97,393.33,4.94;13,112.66,171.52,393.33,4.94;13,112.66,185.07,393.33,4.94;13,112.66,198.62,394.52,4.94;13,112.66,212.17,394.61,4.94;13,112.66,225.72,167.33,4.94" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,225.49,157.97,280.50,4.94;13,112.66,171.52,36.68,4.94">Automatic Argument Quality Assessment -New Datasets and Methods</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Toledo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gretz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cohen-Karlik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Venezian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lahav</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jacovi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Aharonov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Slonim</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1564</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-1564" />
	</analytic>
	<monogr>
		<title level="m" coord="13,343.47,171.52,162.51,4.94;13,112.66,185.07,393.33,4.94;13,112.66,198.62,300.31,4.94">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Inui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Ng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</editor>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">November 3-7, 2019. 2019</date>
			<biblScope unit="page" from="5624" to="5634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,239.27,394.53,4.94;13,112.33,252.82,394.86,4.94;13,112.66,266.37,394.53,4.94;13,112.66,279.92,394.53,4.94;13,112.33,293.47,393.94,4.94;13,112.66,307.02,395.01,4.94;13,112.66,318.55,278.59,9.20" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">H</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chaffin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Stiegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Raja</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Bari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Thakker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Szczechla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Chhablani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">V</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Manica</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">X</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bawden</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Neeraj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rozen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Santilli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Févry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Fries</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Teehan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Bers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="2110.08207" />
		<title level="m" coord="13,464.62,293.47,41.65,4.94;13,112.66,307.02,259.89,4.94">Multitask Prompted Training Enables Zero-Shot Task Generalization</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,334.11,394.61,4.94;13,112.66,347.66,393.32,4.94;13,112.66,358.96,394.52,9.72;13,112.66,374.76,307.01,4.94" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,319.39,334.11,168.40,4.94">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-22948-1_5</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-22948-1_5" />
	</analytic>
	<monogr>
		<title level="m" coord="13,224.46,347.66,281.52,4.94;13,112.66,361.21,137.71,4.94">Information Retrieval Evaluation in a Changing World -Lessons Learned from 20 Years of CLEF</title>
		<title level="s" coord="13,319.87,358.96,139.80,9.72">The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="123" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,388.31,393.57,4.94;13,112.33,401.86,285.35,4.94" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,264.05,388.31,158.77,4.94">The Dilemma of the Direct Answer</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1145/3451964.3451978</idno>
		<ptr target="https://doi.org/10.1145/3451964.3451978" />
	</analytic>
	<monogr>
		<title level="j" coord="13,433.66,388.31,59.12,4.94">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,415.41,393.33,4.94;13,112.66,428.96,394.53,4.94;13,112.30,442.51,393.68,4.94;13,112.14,456.06,395.05,4.94;13,112.28,469.61,305.76,4.94" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,467.07,415.41,38.91,4.94;13,112.66,428.96,236.13,4.94">Towards Understanding and Answering Comparative Questions</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dittmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Homann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Braslavski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3488560.3498534</idno>
		<ptr target="https://doi.org/10.1145/3488560.3498534" />
	</analytic>
	<monogr>
		<title level="m" coord="13,231.29,442.51,274.69,4.94;13,112.14,456.06,131.12,4.94">WSDM &apos;22: The Fifteenth ACM International Conference on Web Search and Data Mining</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Candan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Akoglu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><forename type="middle">L</forename><surname>Dong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</editor>
		<meeting><address><addrLine>Virtual Event / Tempe, AZ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2022">February 21 -25, 2022. 2022</date>
			<biblScope unit="page" from="66" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,483.16,393.33,4.94;13,112.66,496.70,393.33,4.94;13,112.66,510.25,394.52,4.94;13,112.66,521.55,395.00,9.72;13,112.66,537.35,218.47,4.94" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,261.22,483.16,244.77,4.94;13,112.66,496.70,100.52,4.94">An Open-Domain Web Search Engine for Answering Comparative Questions</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Abye</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sager</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">J</forename><surname>Triebel</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/paper_130.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="13,467.81,496.70,38.18,4.94;13,112.66,510.25,293.34,4.94">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="13,287.49,521.55,151.17,9.72">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">September 22-25, 2020. 2696. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,550.90,394.53,4.94;13,112.66,564.45,393.33,4.94;13,112.66,578.00,393.33,4.94;13,112.66,589.30,394.03,9.72;13,112.66,605.10,66.21,4.94" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="13,148.92,550.90,277.87,4.94">Development of a Search Engine to Answer Comparative Queries</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Huck</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/paper_178.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="13,291.12,564.45,214.87,4.94;13,112.66,578.00,128.24,4.94">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="13,124.43,589.30,153.99,9.72">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">September 22-25, 2020. 2696. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,618.65,393.33,4.94;13,112.66,632.20,393.32,4.94;13,112.14,645.75,395.05,4.94;13,112.66,657.05,394.52,9.72;13,112.66,672.84,378.89,4.94" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="13,237.24,618.65,70.28,4.94;13,337.72,618.65,168.27,4.94;13,112.66,632.20,42.13,4.94">Argument Retrieval for Comparative Questions</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Shirshakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Wattar</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2936/paper-219.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="13,423.74,632.20,82.24,4.94;13,112.14,645.75,340.26,4.94">Proceedings of the Working Notes of CLEF 2021 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="13,377.97,657.05,129.22,9.72;13,112.66,672.84,21.79,4.94">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<meeting>the Working Notes of CLEF 2021 -Conference and Labs of the Evaluation Forum<address><addrLine>Bucharest, Romania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-09-21">2021. September 21st -to -24th, 2021. 2936. 2021</date>
			<biblScope unit="page" from="2455" to="2462" />
		</imprint>
	</monogr>
	<note>Thor at Touché</note>
</biblStruct>

<biblStruct coords="14,112.66,90.23,393.33,4.94;14,112.66,103.78,393.32,4.94;14,112.14,117.33,395.05,4.94;14,112.66,128.63,394.52,9.72;14,112.66,144.43,378.89,4.94" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="14,238.95,90.23,267.04,4.94;14,112.66,103.78,41.19,4.94">Retrieving Comparative Arguments using Ensemble Methods and BERT</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Chekalina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2936/paper-211.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="14,423.73,103.78,82.26,4.94;14,112.14,117.33,340.26,4.94">Proceedings of the Working Notes of CLEF 2021 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="14,377.97,128.63,129.22,9.72;14,112.66,144.43,21.79,4.94">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<meeting>the Working Notes of CLEF 2021 -Conference and Labs of the Evaluation Forum<address><addrLine>Bucharest, Romania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">September 21st -to -24th, 2021. 2936. 2021</date>
			<biblScope unit="page" from="2354" to="2365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,157.97,394.62,4.94;14,112.66,171.52,393.33,4.94;14,112.66,185.07,393.33,4.94;14,112.66,198.62,394.62,4.94;14,112.66,212.17,179.39,4.94" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="14,240.77,157.97,240.26,4.94">A Formal Study of Information Retrieval Heuristics</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<idno type="DOI">10.1145/1008992.1009004</idno>
		<ptr target="https://doi.org/10.1145/1008992.1009004" />
	</analytic>
	<monogr>
		<title level="m" coord="14,358.12,171.52,147.87,4.94;14,112.66,185.07,393.33,4.94;14,112.66,198.62,98.14,4.94">SIGIR 2004: Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Allan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Bruza</surname></persName>
		</editor>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">July 25-29, 2004. 2004</date>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,225.72,395.17,4.94;14,112.66,239.27,394.53,4.94;14,112.66,252.82,393.33,4.94;14,112.66,266.37,394.53,4.94;14,112.28,279.92,315.91,4.94" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="14,295.93,225.72,127.19,4.94">Axiomatic Result Re-Ranking</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Völske</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Göring</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1145/2983323.2983704</idno>
		<ptr target="https://doi.org/10.1145/2983323.2983704" />
	</analytic>
	<monogr>
		<title level="m" coord="14,187.63,252.82,318.36,4.94;14,112.66,266.37,188.43,4.94">Proceedings of the 25th ACM International Conference on Information and Knowledge Management, CIKM 2016</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Mukhopadhyay</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Zhai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Bertino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mostafa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Si</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Sondhi</surname></persName>
		</editor>
		<meeting>the 25th ACM International Conference on Information and Knowledge Management, CIKM 2016<address><addrLine>Indianapolis, IN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">October 24-28, 2016. 2016</date>
			<biblScope unit="page" from="721" to="730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,293.47,393.33,4.94;14,112.66,307.02,395.17,4.94;14,112.66,320.56,393.53,4.94;14,112.41,331.87,393.57,9.72;14,112.33,347.66,383.87,4.94" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="14,440.42,293.47,65.57,4.94;14,112.66,307.02,112.80,4.94">Webis at TREC 2018: Common core track</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Völske</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<ptr target="https://trec.nist.gov/pubs/trec27/papers/Webis-CC.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="14,384.73,307.02,123.10,4.94;14,112.66,320.56,204.78,4.94">Proceedings of the Twenty-Seventh Text REtrieval Conference, TREC 2018</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>the Twenty-Seventh Text REtrieval Conference, TREC 2018<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<publisher>NIST Special Publication</publisher>
			<date type="published" when="2018">November 14-16, 2018. 2018</date>
			<biblScope unit="page" from="500" to="331" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,361.21,393.33,4.94;14,112.66,374.76,395.01,4.94;14,112.66,388.31,175.80,4.94" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="14,329.11,361.21,176.88,4.94;14,112.66,374.76,52.28,4.94">Enriching Word Vectors with Subword Information</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<ptr target="https://transacl.org/ojs/index.php/tacl/article/view/999" />
	</analytic>
	<monogr>
		<title level="j" coord="14,173.68,374.76,154.49,4.94">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,401.86,394.53,4.94;14,112.66,415.41,395.01,4.94;14,112.66,428.96,393.32,4.94;14,112.66,442.51,393.33,4.94;14,112.66,456.06,393.33,4.94;14,112.66,469.61,394.52,4.94;14,112.66,483.16,313.96,4.94" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="14,335.32,428.96,170.67,4.94;14,112.66,442.51,90.64,4.94">Transformers: State-of-the-Art Natural Language Processing</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.6</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.emnlp-demos.6" />
	</analytic>
	<monogr>
		<title level="m" coord="14,348.16,442.51,157.82,4.94;14,112.66,456.06,393.33,4.94;14,112.66,469.61,57.13,4.94">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, EMNLP 2020 -Demos</title>
		<editor>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Schlangen</surname></persName>
		</editor>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, EMNLP 2020 -Demos<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">November 16-20, 2020. 2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,496.70,394.62,4.94;14,112.31,510.25,121.41,4.94" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="14,171.28,496.70,150.41,4.94">An Algorithm for Suffix Stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
		<idno type="DOI">10.1108/eb046814</idno>
		<ptr target="https://doi.org/10.1108/eb046814" />
	</analytic>
	<monogr>
		<title level="j" coord="14,330.07,496.70,38.99,4.94">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,523.80,394.62,4.94;14,112.66,537.35,254.00,4.94" xml:id="b23">
	<monogr>
		<title level="m" type="main" coord="14,227.79,523.80,184.46,4.94">Natural Language Processing with Python</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<ptr target="http://www.oreilly.de/catalog/9780596516499/index.html" />
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>O&apos;Reilly</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,550.90,393.33,4.94;14,112.33,564.45,394.85,4.94;14,112.66,578.00,393.53,4.94;14,112.66,591.55,395.17,4.94;14,112.66,605.10,395.17,4.94;14,112.66,618.65,365.67,4.94" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="14,316.84,550.90,189.14,4.94;14,112.33,564.45,193.07,4.94">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1423</idno>
		<ptr target="https://doi.org/10.18653/v1/n19-1423" />
	</analytic>
	<monogr>
		<title level="m" coord="14,112.66,578.00,393.53,4.94;14,112.66,591.55,340.57,4.94">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Burstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Doran</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Solorio</surname></persName>
		</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">June 2-7, 2019. 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="14,112.66,632.20,393.33,4.94;14,112.66,645.75,393.33,4.94;14,112.41,659.29,394.77,4.94;14,112.66,672.84,393.53,4.94;15,112.66,90.23,395.00,4.94" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="14,399.52,632.20,106.47,4.94;14,112.66,645.75,116.70,4.94">Stance Classification of Context-Dependent Claims</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bar-Haim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Dinuzzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Slonim</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/e17-1024</idno>
		<ptr target="https://doi.org/10.18653/v1/e17-1024" />
	</analytic>
	<monogr>
		<title level="m" coord="14,425.07,645.75,80.92,4.94;14,112.41,659.29,394.77,4.94;14,112.66,672.84,48.84,4.94">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2017</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Lapata</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Koller</surname></persName>
		</editor>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2017<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">April 3-7, 2017. 2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="251" to="261" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="15,112.66,103.78,394.61,4.94;15,112.66,117.33,393.32,4.94;15,112.66,130.88,394.52,4.94;15,112.39,142.18,393.89,9.72;15,112.33,157.97,320.41,4.94" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="15,416.30,103.78,90.97,4.94;15,112.66,117.33,63.91,4.94">Webis at TREC 2019: Decision Track</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kasturia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Völske</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="https://trec.nist.gov/pubs/trec28/papers/Webis.D.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="15,333.87,117.33,172.12,4.94;15,112.66,130.88,147.61,4.94">Proceedings of the Twenty-Eighth Text REtrieval Conference, TREC 2019</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>the Twenty-Eighth Text REtrieval Conference, TREC 2019<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">November 13-15, 2019. 2019</date>
			<biblScope unit="volume">1250</biblScope>
		</imprint>
		<respStmt>
			<orgName>NIST Special Publication ; National Institute of Standards and Technology (NIST)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,171.52,393.33,4.94;15,112.66,185.07,393.33,4.94;15,112.66,198.62,397.91,4.94;15,112.66,210.15,48.22,9.20" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="15,419.16,171.52,86.83,4.94;15,112.66,185.07,139.42,4.94">Axiomatic Retrieval Experimentation with ir_axioms</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Reimer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Völske</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3477495.3531743</idno>
	</analytic>
	<monogr>
		<title level="m" coord="15,274.78,185.07,231.21,4.94;15,112.66,198.62,218.69,4.94">45th International ACM Conference on Research and Development in Information Retrieval (SIGIR 2022)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,225.72,394.53,4.94;15,112.66,239.27,393.33,4.94;15,112.66,252.82,393.33,4.94;15,112.66,266.37,314.69,4.94" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="15,112.66,239.27,393.33,4.94;15,112.66,252.82,34.62,4.94">LeviRANK: Limited Query Expansion with Voting Integration for Document Retrieval and Ranking</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rana</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Golchha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Juntunen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Coajă</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Elzamarany</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-C</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">P</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,406.13,252.82,99.86,4.94;15,112.66,266.37,284.57,4.94">Working Notes Papers of the CLEF 2022 Evaluation Labs, CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,279.92,394.61,4.94;15,112.33,293.47,394.86,4.94;15,112.28,307.02,394.91,4.94;15,112.66,320.56,160.06,4.94" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="15,440.00,279.92,67.27,4.94;15,112.33,293.47,279.10,4.94">SEUPD@CLEF: Team Kueri on Argument Retrieval for Comparative Questions</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Aba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Azra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gallo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Piacere</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Virginio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,252.92,307.02,254.27,4.94;15,112.66,320.56,129.93,4.94">Working Notes Papers of the CLEF 2022 Evaluation Labs, CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
