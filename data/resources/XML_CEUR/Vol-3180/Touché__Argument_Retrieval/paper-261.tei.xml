<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,322.51,15.42;1,89.29,106.66,184.82,15.42;1,89.29,129.00,324.97,11.96">Quality-Aware Argument Re-Ranking for Comparative Questions Notebook for the Touché Lab on Argument Retrieval at CLEF 2022</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,154.90,71.51,11.96"><forename type="first">Niclas</forename><surname>Arnhold</surname></persName>
							<email>niclas.arnhold@student.uni-halle.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Martin-Luther-Universität Halle-Wittenberg</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,172.28,154.90,72.05,11.96"><forename type="first">Philipp</forename><surname>Rösner</surname></persName>
							<email>philipp.roesner@student.uni-halle.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Martin-Luther-Universität Halle-Wittenberg</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,271.79,154.90,79.00,11.96"><forename type="first">Tobias</forename><surname>Xylander</surname></persName>
							<email>tobias.xylander@student.uni-halle.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Martin-Luther-Universität Halle-Wittenberg</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,322.51,15.42;1,89.29,106.66,184.82,15.42;1,89.29,129.00,324.97,11.96">Quality-Aware Argument Re-Ranking for Comparative Questions Notebook for the Touché Lab on Argument Retrieval at CLEF 2022</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">EC541061E2FCA9E09454646CBED1886A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Touché 2022</term>
					<term>Comparative queries</term>
					<term>Argument retrieval</term>
					<term>Argument quality</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe the team's Asuna participation in the Touché shared task on Argument Retrieval for Comparative Questions. We submit one run to the task. Apart from the BM25F retrieval algorithm we use concepts like tokenization, lemmatization, summarization, query expansion and machine learning approaches such as DistilBERT and SVM in our approach. At the core of our approach is re-ranking documents based on their argument quality.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The majority of comparative search engine question-like queries (e.g. "Should I major in Philosophy or Psychology?") require retrieved web documents to include relevant and highquality arguments for and against the to-be-compared options <ref type="bibr" coords="1,376.91,393.73,11.58,10.91" target="#b0">[1]</ref>. This requires a retrieval system to account not only for relevance but also for argument quality and stance <ref type="bibr" coords="1,456.61,407.28,11.43,10.91" target="#b1">[2]</ref>.</p><p>In this paper, we describe our team's participation in the Touché shared task on Argument Retrieval for Comparative Questions <ref type="bibr" coords="1,257.42,434.38,11.54,10.91" target="#b2">[3]</ref>. We propose an argument quality-aware re-ranking approach to address the aforementioned challenges in argument retrieval. Our approach consists of: (1) a preprocessing pipeline that builds the index, (2) a search pipeline that for each topic does an initial search followed by tokenization, lemmatization and query expansion, in order to construct expanded queries, and (3) a re-ranker which processes the final set of documents per topic.</p><p>Our proposed approach consists of two pipelines: a preprocessing pipeline and a search pipeline. The preprocessing pipeline extracts document-specific characteristics and builds the index. The search pipeline processes topics and uses a BM25F search approach which uses previously calculated document characteristics as BM25F fields. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preprocessing pipeline</head><p>Our team's approach builds an extended index for our search engine in order to use the extended attributes in our re-ranker and machine learning models.</p><p>For each document of the corpus we calculate an extractive summary and a spam score as well as premises and claims. These steps make it very easy for our search pipeline afterwards to retrieve these attributes from our index for arbitrary documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Premises &amp; Claims</head><p>In our re-ranking process we take into consideration the count of premises and claims per document, as proposed by the group "Rayla" of Alhamzeh et. al <ref type="bibr" coords="2,377.91,504.01,12.94,10.91" target="#b3">[4]</ref> of the CLEF 2021 Touché Lab second shared task.</p><p>For that we use, like the group "Rayla" the TARGER project, a neural argument mining program <ref type="bibr" coords="2,130.65,544.66,11.51,10.91" target="#b4">[5]</ref>. For each document we sent a request to the TARGER-API and add the resulting premises and claims as new fields.</p><p>We do not consider main claims and main premises, as our re-ranker only considers the respective count of premises and claims and their argument quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Summarization</head><p>Summaries can be used in BM25F as fields, so as part of our preprocess pipeline we calculate extractive summaries for each document and store them in the index.</p><p>Extractive summaries rank the words in a document by relevance in the document and create one (or more) document-representing sentences which only use words from the given document.</p><p>In contrast, abstractive summaries attempt to guess the meaning of the document and create a novel description of the document via machine learning approaches. As abstractive summaries can be quite expensive to calculate for the whole corpus, we focus on extractive summaries in our team's approach.</p><p>For extractive summaries we used the LexRank graph-based method supplied by the sumy Python library.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Spam scores</head><p>For calculating spam scores for documents we used the Webis corpus-waterloo-spam-cw12 data set. By merging this data set and the given corpus with Pandas <ref type="bibr" coords="3,365.42,245.09,14.03,10.91" target="#b5">[6]</ref>, we receive spam scores for most of the passages of the corpus.</p><p>Later, in the re-ranking process, we use these scores to re-rank documents partially based on their respective spam score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Building the index</head><p>Via the Pyserini <ref type="bibr" coords="3,156.52,335.46,13.22,10.91" target="#b6">[7]</ref> indexing mechanism we build an index which includes the original documents and all previously calculated document characteristics.</p><p>This enables us to query the index with BM25F and fields for extractive summaries, premises, claims and cleaned documents.</p><p>Under the hood of Pyserini the Lucene document generator and indexing process is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Search pipeline</head><p>At the beginning of the search pipeline we retrieve an initial ranking of 40 documents given the query. We then continue with tokenizing and lemmatizing the contents of those documents. With these processed contents we then perform Latent Dirichlet Allocation to extract the topics that belong to those documents.</p><p>Taking those topics and their related word lists as well as the initial query we then create a number of extended queries that will have some tokens replaced with synonyms after. These new queries we afterwards combine into a single new query again with the query builder.</p><p>After creating this new query it is used to perform another BM25F search. A pre-trained DistilBERT is then used to judge the Argument Quality of every document. Stance Detection of the documents through a DistilBERT model is the second to last step in the pipeline before a re-ranking is performed on the documents according to a number of factors including high argument quality, low spam likelihood (that was gained from the initial search) and so on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Initial search for related documents</head><p>After the user has entered their query we first retrieve the top 40 relevant documents via the pyserini Simplesearcher. As fields for the Simplesearcher we use the summary weights as well All the following steps aim to improve on the initially retrieved ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Tokenizing &amp; Lemmatizing</head><p>From the retrieved documents the contents are tokenized and the resulting number of tokens in each document's contents is saved. To achieve this we use 2 different tokenization functions: One function that first removes any punctuation then uses the gensim.utils library to tokenize the individual words followed by a function that uses the nltk.stem.WordNetLemmatizer aswell as the nltk.corpus.stopwords list to turn the tokens into their basic form and remove any common english stopwords. As a result a list of all word tokens of the document is returned. Our other tokenization function only removes punctuation and uses nltk.sent_tokenize to return a list of individual sentences of the given document (nltk and all nltk methods that were used in this project are described in <ref type="bibr" coords="4,250.46,534.65,11.09,10.91" target="#b7">[8]</ref>).</p><p>Also the number of sentences together with the amount of premises and claims in a retrieved document are added to a docs_list array.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Using LDA to build extended queries</head><p>At times the user might enter a word in their query that is not the most commonly used word of the overall topic they want a search result about to fulfil their information need. On such occasions it is possible to achieve an improvement of the query result by also taking into account the most common terms the entered query most likely belongs to.</p><p>In order to determine the most likely topic the query belongs to and all the words belonging to each topic existing in the 30 previously returned documents we use Latent Dirichlet Allocation <ref type="bibr" coords="5,493.00,101.53,12.99,9.72" target="#b8">[9]</ref> (short: LDA; as described by Blei et al <ref type="bibr" coords="5,253.50,114.06,10.93,10.91" target="#b8">[9]</ref>). As a basis for LDA we chose the dictionary of Gensim Corpus and input the tokens of the query. As the number of words belonging to a topic we decided to choose 5 and as the number of most likely topics LDA should consider we have chosen 3.</p><p>From this we gain a number of topics. Out of this list of topics we extract a list of words without scores belonging to the same topic as any word in the query to form the expanded queries. Finally we collect all the word tokens occurring in each of these extended queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Refining results with synonyms</head><p>The redundant words found in the previous step are then replaced by some of their synonyms found via src.search.synonyms. For each of those synonym replaced queries we search for the top 30 documents including their score. To keep the importance of a document occurring in different extended queries we add a third of the score from all of the same duplicate documents together. After all these scores are computed the documents are reranked by their new score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Argument Quality</head><p>To formulate justified answers for a comparative question it is substantial to find good arguments that support or oppose the objects of interest. For the CLEF 2021 Touché Lab second shared task the group "Rayla" of Alhamzeh et al. <ref type="bibr" coords="5,276.42,376.11,12.85,10.91" target="#b3">[4]</ref> used a network architecture, namely DistilBERT, proposed by Sanh et al. <ref type="bibr" coords="5,201.88,389.66,18.07,10.91" target="#b9">[10]</ref> to extract argumentative sentences on every document. They used the ratio of argumentative sentences to all sentences of the document as one of many features for reranking the results. In their work they experimented with different BERT-based architectures and found out that DistilBERT has a comparable effectiveness to other models for this task which is in accordance with the original work by Sanh et al. <ref type="bibr" coords="5,427.91,443.85,16.41,10.91" target="#b9">[10]</ref>. Team Rayla decided to use DistilBERT because of the better efficiency in terms of model size and running time. Overall they achieved good results for the Touché 2021 task.</p><p>Because of these insights we decided to use DistilBERT in our work too but instead of argument extraction the model is applied to predict argument quality of the premises and claims extracted by the TARGER-API <ref type="bibr" coords="5,180.00,511.60,11.28,10.91" target="#b4">[5]</ref>. For that task we use a pre-trained DistilBERT model with an additional linear layer and trained it on a regression task. We trained the model on the Webis-ArgQuality-20 data set proposed by Gienapp et al. <ref type="bibr" coords="5,247.20,538.70,17.83,10.91" target="#b10">[11]</ref> which was split into 80% train set, 10% validation set and 10% test set. Among other data the data set contains premises for 20 controversial topics and different quality scores for topic-premise-pairs. Furthermore the data set contains query formulations for the topics. As input the "long query" together with a corresponding "premise" was passed to the model. The model was fine-tuned to predict "combined quality" scores of the data set which were normalised to the interval [-1, 1] where a higher score means better quality of the argument. For implementation we used DistilBertForSequenceClassification and the Trainer API of Hugging Face (huggingface.co).</p><p>After the model was trained we use it in our pipeline to predict argument quality scores for re-ranking. Therefore a quality score for every premise and every claim extracted from a document by TARGER <ref type="bibr" coords="6,191.46,86.97,12.73,10.91" target="#b4">[5]</ref> is predicted by passing the query and premise or claim to the model. Then the scores for one document are summed up so that a document with a lot of arguments and good arguments has a higher score than a model with few arguments or arguments with minor score. If no claim and no premise are found in the document the score is set to -2.0. We suppose that this strategy extends the idea of team Rayla <ref type="bibr" coords="6,341.65,141.16,12.72,10.91" target="#b3">[4]</ref> because not only the frequency of the arguments in the documents is payed attention to but also the quality of these arguments.</p><p>For evaluation the model achieved the scores shown in table 1 which were compared to a baseline model which always predicts the mean score of the training set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Stance Detection</head><p>Besides the quality of the arguments per se one can be interested in the stance of them. Regarding comparative questions a text can support the first object or the second object, is neutral towards the objects or has no stance. In our opinion a text having no stance could be less relevant for answering a comparative question because it does not need to respond to the question. On the other side a text having a stance towards one of the objects or both objects has to be related to the objects and therefore to the question.</p><p>Because of that we decided to train a model for stance detection and use the predicted stance as a feature for reranking. Regarding to section 3.5 we decided to use DistilBERT <ref type="bibr" coords="6,442.72,415.79,17.76,10.91" target="#b9">[10]</ref> for stance detection. For training we used the Webis-Stance-Dataset from Bondarenko et al. <ref type="bibr" coords="6,461.88,429.33,12.99,10.91" target="#b1">[2]</ref> which contains 956 questions, answers and corresponding stances of the answers. There are 4 different stance labels: 0 No stance 1 Neutral 2 Pro first object 3 Pro second object We split the data stratified into 80% train set, 10% validation set and %10 test set. For training we used a approach similiar to the one Bondarenko et al. <ref type="bibr" coords="6,345.29,547.64,12.86,10.91" target="#b1">[2]</ref> achieved good results with. First we finetuned the pretrained masked language model by masking the objects in the answers. For masking we used the list of position of both object mentions in the answer provided by the dataset. As input the model received the question and masked answer. After finetuning the masked language model a linear layer was added to the end of the model and than the model was finetuned for stance detection using the same data and input. For implementation we used DistilBertForSequenceClassification and the Trainer API of Hugging Face (huggingface.co).</p><p>In our pipeline we used the trained model for predicting the stances using the query and the document passage content.</p><p>In our experiments the model achieved the results in table <ref type="table" coords="6,361.71,669.58,3.74,10.91" target="#tab_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Re-ranking</head><p>In their conclusion Team Rayla <ref type="bibr" coords="7,229.77,220.59,12.79,10.91" target="#b3">[4]</ref> mentioned that for future work they plan to use a machine learning model to learn the re-ranking of the retrieved documents based on extracted features.</p><p>In our work we want to try this approach. For that we use a Random Forest. As input the Random Forest receives the following features:</p><p>• BM25f-score • number of times the document was retrieved • number of tokens in document • number of sentences in document • number of premises in document • number of claims in document • waterloo spam-scores <ref type="bibr" coords="7,216.22,373.18,17.91,10.91" target="#b11">[12]</ref> • predicted argument quality • predicted stance</p><p>For training we used the 100 topics and relevance labels from Touché 2020 <ref type="bibr" coords="7,432.29,426.51,19.13,9.72" target="#b12">[13]</ref> and Touché 2021 <ref type="bibr" coords="7,106.86,440.06,17.57,9.72" target="#b13">[14]</ref>. The relevance labels are 0, 1 and 2 where 0 means not relevant and 3 means 2 highly relevant.</p><p>First the query was processed by our retrieval pipeline which outputs the retrieved documents and corresponding features for every document. Then the retrieved documents were merged with the annotations from the relevance labels data set to get annotated features which were used to train the Random Forest. Every passage was given the doc_id of the whole document for training. From a practical point of view giving every passage the same relevance is incorrect but for our approach it is essential to be able to merge the relevance scores with the retrieved passages to get annotated data.</p><p>The Random Forest predicts the relevance "class" of the document. The predicted relevance class is multiplied with the prediction probability to get scores with which the documents are re-ranked from highest to lowest score. We suppose that this approach helps to have truly relevant documents at high ranks because the documents with a high probability or confidence for label 2 are ranked to the first places.</p><p>The re-ranker was implemented by using the RandomForestClassifier provided by scikit-learn <ref type="bibr" coords="7,89.29,642.29,16.41,10.91" target="#b14">[15]</ref>. For our experiments we had 1747 samples which were split into 80% train set, 10% validation set and 10% test set. The Random Forest achieved the results in table <ref type="table" coords="7,446.19,655.84,3.74,10.91" target="#tab_2">3</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>In the following section we present and discuss our results for 3 different topics. In 4 you can see the content, the argument quality score, the stance classification and the final score for the second topic of the CLEF 2022 Touché Lab second shared task. In table 5 and table 6 you can see the results for topic 3 and topic 9, respectively. The document contents seem to represent, what the comparative question is about. Though, the argument quality score is quite different per document. It's interesting that most of the retrieved documents classify with a PRO FIRST stance. Judging the final scores, we can deduce that our retrieval mechanism can find many documents with similar scores, therefore it finds many documents answering the question. For topic 3, most of the retrieved documents classify as PRO SECOND stance. By the final score we can see that the first document is seen much more relevant than all other documents, which means that our retrieval mechanism has issues finding relevant documents for the question. Similar to topic 3, we can see for topic 9 that the first document has a much higher score than all other documents. The stances strongly tend to PRO SECOND and the argument quality scores are mixed.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,89.29,311.07,201.14,8.93"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Structure of the preprocessing pipeline</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,89.29,325.38,276.33,8.93"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Our search pipeline for answering comparative questions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,88.99,209.31,299.84,61.26"><head>Table 1</head><label>1</label><figDesc>Results for Argument Quality prediction; score: Mean-Squared-Error</figDesc><table coords="6,203.96,237.40,184.87,33.18"><row><cell>Set</cell><cell cols="2">Training Validation</cell><cell>Test</cell></row><row><cell>Baseline</cell><cell>0.2982</cell><cell>0.2857</cell><cell>0.2640</cell></row><row><cell>DistilBERT</cell><cell>0.0614</cell><cell>0.06463</cell><cell>0.1272</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,88.99,90.49,298.03,85.69"><head>Table 2</head><label>2</label><figDesc>Results for Stance Detection prediction</figDesc><table coords="7,205.76,118.58,181.26,57.60"><row><cell>Set</cell><cell cols="2">Training Validation</cell><cell>Test</cell></row><row><cell>Perplexity</cell><cell>4.04</cell><cell>4.21</cell><cell>4.16</cell></row><row><cell>Accuracy</cell><cell>0.4437</cell><cell>0.4583</cell><cell>0.2917</cell></row><row><cell>Micro-F 1</cell><cell>0.4437</cell><cell>0.4583</cell><cell>0.2917</cell></row><row><cell>Macro-F 1</cell><cell>0.3093</cell><cell>0.30369</cell><cell>0.1763</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,88.99,90.49,296.93,59.56"><head>Table 3</head><label>3</label><figDesc>Results for Random Forest relevance classification</figDesc><table coords="8,206.86,116.35,179.06,33.69"><row><cell>Set</cell><cell cols="2">Training Validation</cell><cell>Test</cell></row><row><cell>Micro-F 1</cell><cell>0.5877</cell><cell>0.5429</cell><cell>0.4857</cell></row><row><cell>Macro-F 1</cell><cell>0.4886</cell><cell>0.4334</cell><cell>0.3657</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,88.99,278.83,395.54,96.73"><head>Table 4</head><label>4</label><figDesc>Results for topic Nr. 2: Which is better, a laptop or a desktop?</figDesc><table coords="8,108.25,307.81,376.29,67.75"><row><cell>content</cell><cell>arg_qual</cell><cell>stance</cell><cell>final_score</cell></row><row><cell>Also should mention both laptop.. &amp; desktop</cell><cell>-3.05</cell><cell>PRO FIRST</cell><cell>1.34706</cell></row><row><cell>(The "desktop" category includes..</cell><cell>-0.56</cell><cell>PRO FIRST</cell><cell>1.33970</cell></row><row><cell>Another method, which is optimised for..</cell><cell>-6.11</cell><cell>PRO FIRST</cell><cell>1.26536</cell></row><row><cell>Which Is Best for School: Laptop or Desktop?..</cell><cell>-4.07</cell><cell>PRO FIRST</cell><cell>1.2526</cell></row><row><cell>Well, wonder no more. It really comes down..</cell><cell>-1.02</cell><cell>PRO FIRST</cell><cell>1.24925</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,88.99,490.89,408.08,96.73"><head>Table 5</head><label>5</label><figDesc>Results for topic Nr. 3: Which is better, Canon or Nikon?</figDesc><table coords="8,95.72,519.88,401.35,67.75"><row><cell>content</cell><cell>arg_qual</cell><cell>stance</cell><cell>final_score</cell></row><row><cell>If this sounds bad, it really isn't because..</cell><cell>-6.28</cell><cell>PRO SECOND</cell><cell>1.5444</cell></row><row><cell>Then, in the 1950s, Nikon became the 35mm..</cell><cell>-2.018151</cell><cell>PRO SECOND</cell><cell>0.6433</cell></row><row><cell>The great DSLR shootout noise reduction test..</cell><cell>-5.23</cell><cell>PRO SECOND</cell><cell>0.6279</cell></row><row><cell>Review Canon PowerShot G1 X Review Fujifilm..</cell><cell>-2.85</cell><cell>PRO SECOND</cell><cell>0.615</cell></row><row><cell>Nikon D3S vs Canon EOS 1D Mark IV: overview..</cell><cell>-4.18</cell><cell>PRO SECOND</cell><cell>0.6134</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Judging by the 4th result, even documents with seemingly no relation to the actual question are retrieved.</p><p>In general, we observe that quite a few spam-documents managed to get into the results. Overall though, the retrieved documents mostly relate to the question.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,112.66,310.45,394.53,10.91;9,112.66,324.00,394.53,10.91;9,112.14,337.55,393.85,10.91;9,112.33,351.10,395.33,10.91;9,112.66,364.65,37.91,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,198.10,324.00,148.76,10.91">Comparative web search questions</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Braslavski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Völske</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Aly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3336191.3371848</idno>
		<ptr target="https://dl.acm.org/doi/abs/10.1145/3336191.3371848" />
	</analytic>
	<monogr>
		<title level="m" coord="9,188.39,337.55,317.59,10.91;9,112.33,351.10,61.52,10.91">13th ACM International Conference on Web Search and Data Mining (WSDM 2020)</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Caverlee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><forename type="middle">B</forename><surname>Hu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Lalmas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="52" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,378.20,393.33,10.91;9,112.66,391.74,394.52,10.91;9,112.30,405.29,393.69,10.91;9,112.66,418.84,395.01,10.91;9,112.66,432.39,196.08,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,467.07,378.20,38.91,10.91;9,112.66,391.74,231.90,10.91">Towards understanding and answering comparative questions</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dittmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Homann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Braslavski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3488560.3498534</idno>
		<ptr target="https://dl.acm.org/doi/10.1145/3488560.3498534.doi:10.1145/3488560.3498534" />
	</analytic>
	<monogr>
		<title level="m" coord="9,252.63,405.29,253.36,10.91;9,112.66,418.84,93.34,10.91">ACM International Conference on Web Search and Data Mining (WSDM 2022)</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Candan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Akoglu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><forename type="middle">L</forename><surname>Dong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="66" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,445.94,395.17,10.91;9,112.66,459.49,393.33,10.91;9,112.66,473.04,393.61,10.91;9,112.33,486.59,393.65,10.91;9,112.66,500.14,386.90,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,349.01,459.49,156.98,10.91;9,112.66,473.04,35.10,10.91">Overview of touché 2022: Argument retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gurcke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,141.37,486.59,364.61,10.91;9,112.66,500.14,21.62,10.91">Advances in Information Retrieval. 44th European Conference on IR Research (ECIR 2022)</title>
		<title level="s" coord="9,141.33,500.14,155.05,10.91">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Hagen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Verberne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Seifert</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Nørvåg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Setty</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,513.69,395.16,10.91;9,112.66,527.24,369.98,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,384.34,513.69,123.49,10.91;9,112.66,527.24,223.74,10.91">Distilbert-based argumentation retrieval for answering comparative questions</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Alhamzeh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bouhaouel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Egyed-Zsigmond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mitrović</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,344.82,527.24,105.91,10.91">Working Notes of CLEF</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,540.79,394.53,10.91;9,112.28,554.33,393.70,10.91;9,112.66,567.88,395.17,10.91;9,112.66,581.43,395.01,10.91;9,112.66,594.98,318.76,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,180.89,554.33,236.09,10.91">TARGER: Neural argument mining at your fingertips</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chernodub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Oliynyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Heidenreich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-3031</idno>
		<ptr target="https://aclanthology.org/P19-3031.doi:10.18653/v1/P19-3031" />
	</analytic>
	<monogr>
		<title level="m" coord="9,439.76,554.33,66.22,10.91;9,112.66,567.88,395.17,10.91;9,112.66,581.43,235.60,10.91">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="195" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,608.53,393.53,10.91;9,112.14,622.08,395.04,10.91;9,112.66,635.63,239.31,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,187.27,608.53,230.51,10.91">Data Structures for Statistical Computing in Python</title>
		<author>
			<persName coords=""><forename type="first">Wes</forename><surname>Mckinney</surname></persName>
		</author>
		<idno type="DOI">10.25080/Majora-92bf1922-00a</idno>
	</analytic>
	<monogr>
		<title level="m" coord="9,240.63,622.08,235.98,10.91">Proceedings of the 9th Python in Science Conference</title>
		<editor>
			<persName><forename type="first">Jarrod</forename><surname>Stéfan Van Der Walt</surname></persName>
		</editor>
		<editor>
			<persName><surname>Millman</surname></persName>
		</editor>
		<meeting>the 9th Python in Science Conference</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="56" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,649.18,393.33,10.91;9,112.66,662.73,394.53,10.91;10,112.66,86.97,395.17,10.91;10,112.39,100.52,394.80,10.91;10,112.66,114.06,395.01,10.91;10,112.66,127.61,155.44,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,386.15,649.18,119.84,10.91;9,112.66,662.73,389.98,10.91">Pyserini: A python toolkit for reproducible information retrieval research with sparse and dense representations</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S.-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<idno type="DOI">10.1145/3404835.3463238</idno>
		<ptr target="https://doi.org/10.1145/3404835.3463238.doi:10.1145/3404835.3463238" />
	</analytic>
	<monogr>
		<title level="m" coord="10,128.24,86.97,379.60,10.91;10,112.39,100.52,209.11,10.91">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;21</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;21<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2356" to="2362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,141.16,394.53,10.91;10,112.66,154.71,22.69,10.91" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="10,231.22,141.16,182.25,10.91">Natural Language Processing with Python</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">L</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Klein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>O&apos;Reilly Media Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,168.26,393.99,10.91;10,112.66,181.81,43.89,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,261.58,168.26,112.80,10.91">Latent dirichlet allocation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,382.51,168.26,86.89,10.91">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,195.36,394.53,10.91;10,112.66,208.91,295.45,10.91" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01108</idno>
		<title level="m" coord="10,303.00,195.36,204.19,10.91;10,112.66,208.91,113.82,10.91">Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,222.46,393.33,10.91;10,112.66,236.01,393.33,10.91;10,112.66,249.56,144.26,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,315.65,222.46,190.33,10.91;10,112.66,236.01,28.28,10.91">Efficient pairwise annotation of argument quality</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,163.32,236.01,342.67,10.91;10,112.66,249.56,46.58,10.91">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5772" to="5781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,263.11,393.33,10.91;10,112.66,276.66,331.48,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,320.21,263.11,185.78,10.91;10,112.66,276.66,145.75,10.91">Efficient and effective spam filtering and re-ranking for large web datasets</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,266.58,276.66,93.63,10.91">Information retrieval</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="441" to="465" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,290.20,394.52,10.91;10,112.66,303.75,393.33,10.91;10,112.66,317.30,394.53,10.91;10,112.66,330.85,394.53,10.91;10,112.66,344.40,393.33,10.91;10,112.33,357.95,395.50,10.91;10,112.66,371.50,394.04,10.91;10,112.66,385.05,296.30,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,336.55,303.75,169.43,10.91;10,112.66,317.30,38.77,10.91">Overview of Touché 2020: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58219-7_26</idno>
		<ptr target="https://link.springer.com/chapter/10.1007/978-3-030-58219-7_26.doi:10.1007/978-3-030-58219-7\_26" />
	</analytic>
	<monogr>
		<title level="m" coord="10,339.32,330.85,167.87,10.91;10,112.66,344.40,393.33,10.91;10,112.33,357.95,27.86,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction. 11th International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="10,252.48,358.96,152.18,9.72">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lioma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="volume">12260</biblScope>
			<biblScope unit="page" from="384" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,398.60,394.52,10.91;10,112.66,412.15,393.33,10.91;10,112.66,425.70,394.52,10.91;10,112.66,439.25,393.33,10.91;10,112.66,452.79,393.33,10.91;10,112.41,466.34,395.26,10.91;10,112.41,479.89,397.73,10.91;10,112.36,495.88,158.69,7.90" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,336.55,412.15,169.43,10.91;10,112.66,425.70,38.69,10.91">Overview of Touché 2021: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-85251-1_28</idno>
		<ptr target="https://link.springer.com/chapter/10.1007/978-3-030-85251-1_28.doi:10.1007/978-3-030-85251-1\_28" />
	</analytic>
	<monogr>
		<title level="m" coord="10,238.75,439.25,267.23,10.91;10,112.66,452.79,328.83,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction. 12th International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="10,150.93,467.36,143.04,9.72">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Candan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="volume">12880</biblScope>
			<biblScope unit="page" from="450" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,506.99,394.53,10.91;10,112.66,520.54,394.53,10.91;10,112.66,534.09,393.32,10.91;10,112.66,547.64,176.63,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,228.10,534.09,182.14,10.91">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,419.22,534.09,86.76,10.91;10,112.66,547.64,82.55,10.91">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
