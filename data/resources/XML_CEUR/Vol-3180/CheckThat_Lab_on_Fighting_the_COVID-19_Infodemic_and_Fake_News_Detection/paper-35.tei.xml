<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,373.26,15.42;1,89.29,106.66,297.93,15.42">Zorros at CheckThat! 2022: Ensemble Model for Identifying Relevant Claims in Tweets</title>
				<funder ref="#_6Q5TJSj">
					<orgName type="full">Competitiveness Operational Programme Romania</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,57.26,11.96"><forename type="first">Nicu</forename><surname>Buliga</surname></persName>
							<email>nicu.buliga2000@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">&quot;Alexandru Ioan Cuza&quot; University of Iasi</orgName>
								<address>
									<settlement>Iasi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Bitdefender</orgName>
								<address>
									<settlement>Iasi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,164.49,134.97,86.47,11.96"><forename type="first">Madalina</forename><surname>Raschip</surname></persName>
							<email>madalina.raschip@uaic.ro</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">&quot;Alexandru Ioan Cuza&quot; University of Iasi</orgName>
								<address>
									<settlement>Iasi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,373.26,15.42;1,89.29,106.66,297.93,15.42">Zorros at CheckThat! 2022: Ensemble Model for Identifying Relevant Claims in Tweets</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">645AACE9048DD2A7C60945CD30D93489</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>check-worthiness</term>
					<term>COVID-19</term>
					<term>transformer models</term>
					<term>ensemble</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the system used by Zorros team in the CLEF2022 CheckThat! Lab for Task 1 on identifying relevant claims in tweets. Task 1 was divided into four subtasks, which try to detect if the tweets are worth fact-checking (1A), contain verifiable factual claims (1B), are harmful to society (1C) and are attention-worthy (1D). For each subtask, we proposed different models based on pre-trained transformer models that helped us achieve the first position for subtasks 1C and 1D, the second position for subtask 1A, and the fifth position for subtask 1B.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Social media platforms like Twitter play a major role in facilitating human communication and socialization by sharing different information, thus it is widely used by almost everyone who interacts with technology. Despite all the advantages, it has some dark sides, like fake news which spread faster than authentic ones and has increased considerably with this pandemic situation. A lot of false information spread online during the COVID-19 disease outbreak, from discrediting the threat of COVID-19 to conspiracy theories about vaccines. Misinformation on social media about COVID-19 is linked to vaccine hesitancy <ref type="bibr" coords="1,383.41,450.99,11.59,10.91" target="#b0">[1]</ref>. Therefore, the process of automatically identifying fake news is a very crucial and hard challenge for social media platforms, because even humans can not distinguish between fake and authentic news accurately. The CLEF2022 CheckThat! lab <ref type="bibr" coords="1,228.14,491.64,12.89,10.91" target="#b1">[2]</ref> is a good and relevant initiative for the current times since there is an urgent need for solutions to combat misinformation.</p><p>In this paper, we present an approach used for solving Tasks 1 (English) on Identifying Relevant Claims in Tweets <ref type="bibr" coords="1,211.95,532.29,12.97,10.91" target="#b2">[3]</ref> of CLEF 2022 CheckThat! Lab <ref type="bibr" coords="1,365.30,532.29,12.97,10.91" target="#b1">[2]</ref>  <ref type="bibr" coords="1,380.99,532.29,11.56,10.91" target="#b3">[4]</ref>. Task 1 was divided into four subtasks: 1A -Check-worthiness of tweets, 1B -Verifiable factual claims detection, 1C -Harmful tweet detection and 1D -Attention-worthy tweet detection. The approach used for each subtask is based on transformers. The key innovation of transformers is the introduction of a self-attention mechanism. The computation for each item is independent of all the others, which means that it can be easily parallelized. This parallelism enabled transformers to be trained on large general purpose corpora, leading to pre-trained transformer models like BERT <ref type="bibr" coords="2,89.29,86.97,13.00,10.91" target="#b4">[5]</ref> and T5. Those pre-trained models can be used to transfer knowledge to other NLP tasks, leading to significant improvements. Different pre-trained BERT <ref type="bibr" coords="2,379.32,100.52,12.86,10.91" target="#b4">[5]</ref> and RoBERTa <ref type="bibr" coords="2,458.63,100.52,12.85,10.91" target="#b5">[6]</ref> models are used in ensemble models to solve the subtasks 1A-1D.</p><p>The rest of the paper is organized as follows: section 2 -Related Work, section 3 -Problem Description, section 4 -Methodology, where the models used are described, section 5 -Evaluation and Results from the competition and section 6 -Conclusion and Future Work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Fake news detection has gained a lot of attention in the last years, especially during the worldwide COVID-19 pandemic, because of the misinformation spreading about COVID-19 on social media and there is a need of platforms to prevent it. Thus, many systems have been tested and used for detecting fake news, but they can not classify information accurately, because of their inability to fully understand the data. Some of the most recent deep learning models used for fake news detection tasks are described below. The paper <ref type="bibr" coords="2,202.66,294.63,12.77,10.91" target="#b6">[7]</ref> presents a hybrid Neural Network architecture that combines the capabilities of CNN and LSTM. Two different dimensionality reduction approaches, Principle Component Analysis and Chi-Square are used in order to reduce the dimensionality of the feature vectors before passing them to the classifier. To develop the idea, the authors acquired a dataset from the Fake News Challenges website which has four types of stances: agree, disagree, discuss, and unrelated. Their results show a 20% improvement in the F1-Score. Another model is described in <ref type="bibr" coords="2,158.96,375.93,11.59,10.91" target="#b7">[8]</ref>. The authors used a transformer model for fake news classification of a specific domain dataset, and included human justification and metadata for added performance. They have used multiple BERT models with shared weights between them to handle various inputs.</p><p>Related research areas are check-worthiness and credibility assessment of tweets. There are many approaches in literature for identifying check-worthiness in social media, starting from working with features like TF-IDF representations <ref type="bibr" coords="2,349.64,457.22,13.00,10.91" target="#b8">[9]</ref> until more recently used word embeddings from transformers. For example, the paper <ref type="bibr" coords="2,343.14,470.77,12.99,10.91" target="#b8">[9]</ref> analyzes different classifiers and uses different features like TF-IDF representations, part of speech tags, sentiment scores, and entity types to detect check-worthy factual claims in presidential debates.</p><p>CLEF has been organizing CheckThat! Labs since 2018. The best model <ref type="bibr" coords="2,438.21,511.42,18.07,10.91" target="#b9">[10]</ref> from 2018 for check-worthiness in political claims used a multilayer perceptron and many features like averaged word embeddings and bag-of-words representations. In the last two editions, with the emergence of the COVID-19 pandemic, the competition considered the task of check-worthiness of tweets about COVID-19. Also, transformer-based models have begun to be used often. In the last year, for the check-worthiness of tweets task the best approach <ref type="bibr" coords="2,381.60,579.17,17.75,10.91" target="#b10">[11]</ref> used several pre-trained transformer models, BERTweet <ref type="bibr" coords="2,230.96,592.72,17.91,10.91" target="#b11">[12]</ref> giving the best results on the development set.</p><p>Some recent works for credibility assessment are presented below. In <ref type="bibr" coords="2,404.63,606.27,16.09,10.91" target="#b12">[13]</ref>, a semi-supervised ranking model is described to automatically evaluate the credibility of a tweet. In <ref type="bibr" coords="2,453.05,619.81,16.23,10.91" target="#b13">[14]</ref>, a large multilingual dataset for fact checking is introduced along with several automated fact checking models based on transformers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problem Description</head><p>The Task 1 of the competition was separated into four subtasks, all of them related to the COVID-19 topic. The first three tasks are binary classification tasks, and the last one is a multiclass classification task. Every subtask had its own dataset, splitted into train, dev and test sets as shown in Table <ref type="table" coords="3,191.57,151.93,3.74,10.91" target="#tab_0">1</ref>. The label distributions are shown in Figure <ref type="figure" coords="3,301.80,292.19,5.17,10.91" target="#fig_0">1</ref> for subtasks 1A, 1B, 1C and in Figure <ref type="figure" coords="3,484.58,292.19,5.17,10.91" target="#fig_1">2</ref> for subtask 1D. We can clearly observe that for subtasks 1A, 1C and 1D the data are very unbalanced, so we have to use different techniques for balancing the data. The description of the subtasks is given below:</p><p>• Subtask 1A: Check-worthiness of tweets Given a tweet, the task is to predict whether it is worth fact-checking, so it has two labels: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yes and No. • Subtask 1B: Verifiable factual claims detection</head><p>For this subtask, we have to predict whether a tweet contains a verifiable factual claim.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Subtask 1C: Harmful tweet detection</head><p>We have to predict whether a tweet is harmful to society.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Subtask 1D: Attention-worthy tweet detection</head><p>This subtask has nine class labels and we have to predict whether a tweet should get the attention of policy makers and why. The labels are:</p><p>-No, not interesting -Yes, asks question -Yes, blame authorities -Yes, calls for action -Yes, harmful -Yes, contains advice -Yes, discusses action taken -Yes, discusses cure -Yes, other</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methodology</head><p>The proposed approach for solving the subtasks 1A-1D consists of four main steps: text preprocessing, tokenization for transformer based models, selection of the model architecture and the construction of the ensemble model. Each of them is described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Text Preprocessing</head><p>Given the small dataset for each task and the irrelevance of some tokens in the tweets for training our model, we performed the following modifications on raw tweets:</p><p>1. Lowercased the text of the tweet 2. Replaced all shorts, like don't to their normal form, do not 3. Removed all URLs, TAGs and non alphanumeric characters 4. Removed all stand-alone numbers</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Tokenization</head><p>To pass the tweets to the pre-trained models like BERT and RoBERTa, we need to convert every tweet into a list of tokens based on the vocabulary of the model and then find the tokens ids and the attention masks. For this step, we used the respective tokenizer of each model because it already knows the accepted structure of the model and can easily convert the tweets.</p><p>The sentences are grouped into batches, so the tweets in the same batch must have the same number of tokens. To satisfy this condition, we used the parameters of the tokenizer by specifying a maximum length based on tokens list length distribution (100 was the best length in experiments). Therefore, shorter tweets will be padded with the same predefined token and longer tweets will be truncated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Model Architecture</head><p>We have used only the encoder block of pre-trained BERT and RoBERTa models as the core of the final model, which can offer really good performance on NLP tasks. On top of that, we need a classification header for predicting, because until now we have only tweets embeddings. We need a binary classification model for subtasks 1A, 1B, 1C and a slightly different model for subtask 1D, because it has more than two labels. So, for the first three subtasks, we added an output neuron with the sigmoid as an activation function on top of the pre-trained model with a threshold at 0.5, giving us the probability of a tweet being in class YES. The loss function is Binary Cross Entropy and the optimizer is Adam with a weight decay of 0.01 and a learning rate of 2 • 10 -5 . The classification head has a dropout layer with a rate of 0.5. Dropout was applied to avoid over-fitting. The model architecture is given in Figure <ref type="figure" coords="5,406.00,515.91,3.74,10.91" target="#fig_2">3</ref>.</p><p>For the final subtask 1D, we have as a classification header nine neurons with softmax as an activation function and Cross Entropy as a loss function. The predicted output gives us a probability distribution over all classes. The optimizer respects the same parameters from the first model, and the dropout layer also has a rate of 0.5. The model architecture for subtask 1D is given in Figure <ref type="figure" coords="5,169.16,583.66,3.74,10.91" target="#fig_3">4</ref>.</p><p>We fine-tuned these models for every subtask on the train set consisting of a concatenation between the train set and the test set. For testing models performance we have used the dev set. For training, we chose 20 epochs with data grouped into batches of 16 tweets. To deal with the unbalanced datasets, we have used weights for classes in the loss functions, essentially assigning a higher weight to the loss of the minor classes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Fine-tuned BERT and RoBERTa Models</head><p>We fine-tuned the following ten models for every subtask:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1.">TweetEval based models</head><p>TweetEval <ref type="bibr" coords="6,139.13,500.30,18.04,10.91" target="#b14">[15]</ref> is a pre-trained RoBERTa-base model, further trained on ∼ 58𝑀 tweets, randomly collected. The result of this step is a Twitter-domain adapted version of RoBERTa.</p><p>We also used a selection of five TweetEval models, each fine tuned for a specific task: Irony Detection <ref type="bibr" coords="6,130.63,540.94,18.37,10.91" target="#b15">[16]</ref>, Offensive Language Identification <ref type="bibr" coords="6,307.51,540.94,16.97,10.91" target="#b16">[17]</ref>, Emotion Recognition <ref type="bibr" coords="6,423.90,540.94,18.67,10.91" target="#b17">[18]</ref>, Hate Speech Detection <ref type="bibr" coords="6,130.25,554.49,18.21,10.91" target="#b18">[19]</ref>, Sentiment Analysis <ref type="bibr" coords="6,239.96,554.49,18.08,10.91" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2.">BERTweet models</head><p>BERTweet <ref type="bibr" coords="6,139.32,603.82,18.06,10.91" target="#b11">[12]</ref> is the first public large-scale language model pre-trained for English Tweets. BERTweet is trained based on the RoBERTa pre-training procedure. The corpus used to pre-train BERTweet consists of 850𝑀 English Tweets (16𝐵 word tokens ∼ 80𝐺𝐵), containing 845𝑀 Tweets streamed from 01/2012 to 08/2019 and 5𝑀 Tweets related to the COVID-19 pandemic.</p><p>We used three versions of this model: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3.">COVID-Twitter-BERT v2</head><p>It is a BERT-large-uncased model, pre-trained on a corpus of messages from Twitter about COVID-19. This model is identical to COVID-Twitter-BERT v1 <ref type="bibr" coords="7,374.73,610.46,18.02,10.91" target="#b20">[21]</ref> but was trained on more data, resulting in higher downstream performance.</p><p>The first version of the model was trained on 160𝑀 tweets collected between January 12 and April 16, 2020, containing at least one of the keywords "wuhan", "ncov", "coronavirus", "covid", or "sars-cov-2". These tweets were filtered and preprocessed to reach a final sample of 22.5𝑀 tweets, containing 40.7𝑀 sentences and 633𝑀 tokens, which were used for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Ensemble Model</head><p>For subtasks 1A, 1B and 1C we used an ensemble model to predict the labels. The structure of the ensemble model is composed of ten BERT and RoBERTa pre-trained and fine-tuned models described above, with another classification header on top of them, with one neuron and sigmoid as activation function, predicting the probability of a tweet being in class YES. Essentially, we took the predictions from every fine-tuned model without the sigmoidal activation function and feed them to the classification header. Therefore every tweet will have a new feature vector of length 10, where an element is a raw prediction from one model.</p><p>The model structure can be seen in Figure <ref type="figure" coords="8,290.19,231.54,3.74,10.91" target="#fig_4">5</ref>.  This new model was trained for 50 epochs with a batch size of 8 and a learning rate of 2 • 10 -4 , checking its performance at every epoch and saving the model with the best performance.</p><p>For task 1D, we did not use an ensemble model but the model with the best performance out of all ten, which was COVID-Twitter-BERT v2 <ref type="bibr" coords="9,298.31,338.37,16.25,10.91" target="#b20">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Evaluation and Results</head><p>Task 1 is a classification task. Classification algorithms can be evaluated using several metrics including accuracy, precision, recall, and F1-score. For the subtasks 1A and 1C, the organizers used the F1 measure with respect to the positive class (minor class), for subtask 1B -accuracy and for 1D -weighted F1 score. We describe next the results obtained for every subtask on the last test set offered by the organizers and used for the contest. Tables 2-5 contain the results for all metrics; the column in bold from each table is the metric used by the organizers to establish the winners.</p><p>The results for subtask 1A can be found in Table <ref type="table" coords="9,309.71,491.84,3.66,10.91" target="#tab_1">2</ref>. Here we have tested ten transformer-based models and an ensemble model built from these. We can observe that the ensemble model has the best performance for every metric except accuracy, which is not that relevant when the data is very unbalanced. Therefore, this is the model we used for the contest.</p><p>For subtask 1B, we tested only five TweetEval derived models and an ensemble model made from these, because of the increased computation time. The results are given in Table <ref type="table" coords="9,477.66,559.59,3.80,10.91" target="#tab_2">3</ref>. The ensemble model yield the best results for this subtask, except for the macro recall, which is only 0.01 smaller than the maximum value of this metric. Therefore, we used the ensemble model for this subtask in the competition.</p><p>The results for subtask 1C are illustrated in Table <ref type="table" coords="9,319.28,613.78,3.68,10.91">4</ref>. The tested models are the same as those from subtask 1B. Here the ensemble has the best results for two out of five metrics, including the F1 score for positive class, which was used as evaluation for the contest.</p><p>For subtask 1D, we did not use an ensemble. We tested four models due to increased computation time. The results are given in Table <ref type="table" coords="9,283.47,667.98,3.81,10.91">5</ref>. Here the decision was simple, because COVID Twitter BERT v2 had the best results on three out of four metrics, including the one used for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and Future Work</head><p>In this paper, we present the results obtained in Task 1 of the CLEF 2022 CheckThat! lab. Different models based on pre-trained BERT encoders and fine-tuned BERT models offered really good results. For the first three subtasks we used ensemble models, while for subtask 1D a fine-tuned BERT model was enough. We obtained first place for subtasks 1C and 1D, second place for subtask 1A and fifth place for subtask 1B. The experimental results show the power of the existing pre-trained models, no longer being necessary to retrain a model from scratch, saving a lot of time on computation.</p><p>For future work, we will focus on learning more features from a sentence, making different combinations from BERT layers, like pooling the last four layers, or concatenating them to obtain a higher understanding of the semantic in a sentence.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,606.37,209.81,8.93;3,129.72,341.38,333.35,252.43"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Data distribution for subtasks 1A, 1B, 1C</figDesc><graphic coords="3,129.72,341.38,333.35,252.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,89.29,322.49,175.16,8.93;4,89.29,84.19,416.68,213.79"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Data distribution for subtask 1D</figDesc><graphic coords="4,89.29,84.19,416.68,213.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,89.29,392.80,224.38,8.93;6,129.72,84.19,333.36,296.04"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Model Architecture for Binary Classification</figDesc><graphic coords="6,129.72,84.19,333.36,296.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,89.29,439.52,242.21,8.93;7,108.88,84.19,375.02,342.76"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Model Architecture for Multi-class Classification</figDesc><graphic coords="7,108.88,84.19,375.02,342.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="8,89.29,645.26,151.05,8.93;8,181.42,254.25,229.95,378.45"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Ensemble Model Structure</figDesc><graphic coords="8,181.42,254.25,229.95,378.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,177.86,263.59,96.10"><head>Table 1</head><label>1</label><figDesc>Dataset Details</figDesc><table coords="3,242.69,203.73,109.89,70.24"><row><cell>Task</cell><cell>Data Train Dev Test</cell></row><row><cell>1A</cell><cell>2122 195 574</cell></row><row><cell>1B</cell><cell>3324 307 911</cell></row><row><cell>1C</cell><cell>3323 307 910</cell></row><row><cell>1D</cell><cell>3321 306 909</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,88.99,90.49,413.18,182.89"><head>Table 2</head><label>2</label><figDesc>Subtask 1A results</figDesc><table coords="9,95.27,116.30,406.90,157.07"><row><cell>Model</cell><cell>Positive Class F1 Score</cell><cell>Accuracy</cell><cell>Macro F1 Score</cell><cell>Macro Precision</cell><cell>Macro Recall</cell></row><row><cell>BERTweet Large</cell><cell>0.554</cell><cell>0.590</cell><cell>0.587</cell><cell>0.684</cell><cell>0.714</cell></row><row><cell>BERTweet COVID-19 Base Cased</cell><cell>0.579</cell><cell>0.698</cell><cell>0.671</cell><cell>0.678</cell><cell>0.729</cell></row><row><cell>BERTweet COVID-19 Base Uncased</cell><cell>0.568</cell><cell>0.724</cell><cell>0.683</cell><cell>0.676</cell><cell>0.714</cell></row><row><cell>TweetEval</cell><cell>0.601</cell><cell>0.698</cell><cell>0.679</cell><cell>0.696</cell><cell>0.754</cell></row><row><cell>TweetEval Irony</cell><cell>0.562</cell><cell>0.718</cell><cell>0.677</cell><cell>0.671</cell><cell>0.709</cell></row><row><cell>TweetEval Offensive</cell><cell>0.636</cell><cell>0.731</cell><cell>0.711</cell><cell>0.720</cell><cell>0.785</cell></row><row><cell>TweetEval Emotion</cell><cell>0.607</cell><cell>0.731</cell><cell>0.701</cell><cell>0.699</cell><cell>0.752</cell></row><row><cell>TweetEval Hate</cell><cell>0.598</cell><cell>0.684</cell><cell>0.669</cell><cell>0.696</cell><cell>0.753</cell></row><row><cell>TweetEval Sentiment</cell><cell>0.574</cell><cell>0.711</cell><cell>0.678</cell><cell>0.676</cell><cell>0.721</cell></row><row><cell>COVID Twitter BERT v2</cell><cell>0.609</cell><cell>0.785</cell><cell>0.730</cell><cell>0.724</cell><cell>0.738</cell></row><row><cell>Big Ensemble Model</cell><cell>0.667</cell><cell>0.771</cell><cell>0.746</cell><cell>0.740</cell><cell>0.804</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,88.99,90.49,387.30,377.55"><head>Table 3</head><label>3</label><figDesc>Subtask 1B results</figDesc><table coords="10,88.99,116.35,387.30,351.68"><row><cell>Model</cell><cell cols="3">Accuracy</cell><cell cols="2">Macro F1 Score</cell><cell>Macro Precision</cell><cell>Macro Recall</cell></row><row><cell cols="2">TweetEval Irony</cell><cell>0.709</cell><cell></cell><cell cols="2">0.683</cell><cell>0.703</cell><cell>0.679</cell></row><row><cell cols="2">TweetEval Offensive</cell><cell>0.703</cell><cell></cell><cell cols="2">0.674</cell><cell>0.697</cell><cell>0.661</cell></row><row><cell cols="2">TweetEval Emotion</cell><cell>0.689</cell><cell></cell><cell cols="2">0.658</cell><cell>0.681</cell><cell>0.656</cell></row><row><cell cols="2">TweetEval Hate</cell><cell>0.691</cell><cell></cell><cell cols="2">0.677</cell><cell>0.680</cell><cell>0.674</cell></row><row><cell cols="2">TweetEval Sentiment</cell><cell>0.703</cell><cell></cell><cell cols="2">0.683</cell><cell>0.693</cell><cell>0.680</cell></row><row><cell cols="2">Small Ensemble Model</cell><cell>0.709</cell><cell></cell><cell cols="2">0.683</cell><cell>0.703</cell><cell>0.679</cell></row><row><cell>Table 4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Subtask 1C results</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell cols="2">Positive Class F1 Score</cell><cell cols="3">Accuracy</cell><cell>Macro F1 Score</cell><cell>Macro Precision</cell><cell>Macro Recall</cell></row><row><cell>TweetEval Irony</cell><cell>0.347</cell><cell></cell><cell cols="2">0.625</cell><cell></cell><cell>0.542</cell><cell>0.569</cell><cell>0.625</cell></row><row><cell>TweetEval Offensive</cell><cell>0.396</cell><cell></cell><cell cols="2">0.711</cell><cell></cell><cell>0.602</cell><cell>0.597</cell><cell>0.662</cell></row><row><cell>TweetEval Emotion</cell><cell>0.392</cell><cell></cell><cell cols="2">0.753</cell><cell></cell><cell>0.618</cell><cell>0.608</cell><cell>0.650</cell></row><row><cell>TweetEval Hate</cell><cell>0.337</cell><cell></cell><cell cols="2">0.796</cell><cell></cell><cell>0.608</cell><cell>0.612</cell><cell>0.605</cell></row><row><cell>TweetEval Sentiment</cell><cell>0.370</cell><cell></cell><cell cols="2">0.729</cell><cell></cell><cell>0.598</cell><cell>0.592</cell><cell>0.636</cell></row><row><cell>Small Ensemble Model</cell><cell>0.397</cell><cell></cell><cell cols="2">0.685</cell><cell></cell><cell>0.592</cell><cell>0.599</cell><cell>0.671</cell></row><row><cell>Table 5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Subtask 1D results</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell></cell><cell cols="3">Weighted F1 Score</cell><cell cols="2">Accuracy</cell><cell>Weighted Precision</cell><cell>Weighted Recall</cell></row><row><cell cols="2">COVID Twitter BERT v2</cell><cell cols="2">0.725</cell><cell></cell><cell cols="2">0.721</cell><cell>0.735</cell><cell>0.721</cell></row><row><cell>BERTweet Large</cell><cell></cell><cell cols="2">0.716</cell><cell></cell><cell cols="2">0.713</cell><cell>0.724</cell><cell>0.713</cell></row><row><cell>TweetEval Base</cell><cell></cell><cell cols="2">0.706</cell><cell></cell><cell cols="2">0.713</cell><cell>0.702</cell><cell>0.713</cell></row><row><cell cols="2">BERTweet COVID-19 Base Uncased</cell><cell cols="2">0.724</cell><cell></cell><cell cols="2">0.717</cell><cell>0.737</cell><cell>0.717</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This paper is partially supported by the <rs type="funder">Competitiveness Operational Programme Romania</rs> under project number <rs type="grantNumber">SMIS 124759 -RaaS-IS</rs> (Research as a <rs type="institution">Service Iasi</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_6Q5TJSj">
					<idno type="grant-number">SMIS 124759 -RaaS-IS</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,112.66,231.32,393.33,10.91;11,112.66,244.87,393.33,10.91;11,112.66,258.42,95.49,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,476.40,231.32,29.59,10.91;11,112.66,244.87,343.37,10.91">Online misinformation is linked to early covid-19 vaccination hesitancy and refusal</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pierri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">L</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Deverna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K.-C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Flammini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Menczer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bryden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,464.28,244.87,41.71,10.91;11,112.66,258.42,31.84,10.91">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,271.96,394.53,10.91;11,112.33,285.51,394.85,10.91;11,112.66,299.06,218.91,10.91;11,383.86,299.06,122.12,10.91;11,112.66,312.61,394.53,10.91;11,112.66,326.16,395.17,10.91;11,112.66,339.71,193.11,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,272.14,299.06,59.43,10.91;11,383.86,299.06,122.12,10.91;11,112.66,312.61,154.75,10.91">The clef-2022 lab on fighting the covid-19 infodemic and fake news detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beltrán</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,272.10,326.16,151.66,10.91">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Hagen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Verberne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Seifert</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Nørvåg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Setty</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="416" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,353.26,394.52,10.91;11,112.14,366.81,393.85,10.91;11,112.66,380.36,393.33,10.91;11,112.66,393.91,394.52,10.91;11,112.66,407.46,47.34,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,451.89,366.81,54.10,10.91;11,112.66,380.36,333.06,10.91">Overview of the CLEF-2022 CheckThat! lab task 1 on identifying relevant claims in tweets</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beltrán</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,467.81,380.36,38.18,10.91;11,112.66,393.91,349.04,10.91">Working Notes of CLEF 2022-Conference and Labs of the Evaluation Forum, CLEF &apos;2022</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,421.01,394.53,10.91;11,112.33,434.55,394.85,10.91;11,112.66,448.10,393.33,10.91;11,112.66,461.65,394.52,10.91;11,112.66,475.20,393.33,10.91;11,112.28,488.75,394.91,10.91;11,112.66,502.30,89.12,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,432.00,448.10,73.99,10.91;11,112.66,461.65,390.20,10.91">Overview of the CLEF-2022 CheckThat! lab on fighting the COVID-19 infodemic and fake news detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beltrán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Köhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,126.92,475.20,379.07,10.91;11,112.28,488.75,390.55,10.91">Proceedings of the 13th International Conference of the CLEF Association: Information Access Evaluation meets Multilinguality, Multimodality, and Visualization, CLEF &apos;2022</title>
		<meeting>the 13th International Conference of the CLEF Association: Information Access Evaluation meets Multilinguality, Multimodality, and Visualization, CLEF &apos;2022<address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,515.85,395.17,10.91;11,112.66,529.40,319.37,10.91" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="11,313.24,515.85,194.58,10.91;11,112.66,529.40,136.87,10.91">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,112.66,542.95,394.53,10.91;11,112.30,556.50,393.68,10.91;11,112.66,570.05,107.17,10.91" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="11,173.53,556.50,256.77,10.91">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,112.66,583.60,393.33,10.91;11,112.66,597.15,395.01,10.91;11,112.66,610.69,179.18,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,424.70,583.60,81.28,10.91;11,112.66,597.15,228.34,10.91">Fake news stance detection using deep learning architecture (cnn-lstm)</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Umer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Imtiaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ullah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mehmood</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B.-W</forename><surname>On</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2020.3019735</idno>
	</analytic>
	<monogr>
		<title level="j" coord="11,348.58,597.15,52.96,10.91">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="156695" to="156706" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,624.24,393.33,10.91;11,112.66,637.79,394.62,10.91;11,112.66,651.34,371.81,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,352.87,624.24,153.11,10.91;11,112.66,637.79,124.26,10.91">A transformer-based architecture for fake news classification</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dwivedi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Patra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">Anand</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13278-021-00738-y</idno>
		<ptr target="https://doi.org/10.1007/s13278-021-00738-y.doi:10.1007/s13278-021-00738-y" />
	</analytic>
	<monogr>
		<title level="j" coord="11,248.82,637.79,170.68,10.91">Social Network Analysis and Mining</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,664.89,393.33,10.91;12,112.66,86.97,393.33,10.91;12,112.66,100.52,226.06,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,260.82,664.89,245.17,10.91;12,112.66,86.97,31.90,10.91">Detecting check-worthy factual claims in presidential debates</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tremayne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,168.64,86.97,337.35,10.91;12,112.66,100.52,127.10,10.91">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1835" to="1838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,114.06,393.33,10.91;12,112.66,127.61,394.53,10.91;12,112.66,141.16,22.69,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,261.81,114.06,244.18,10.91;12,112.66,127.61,182.48,10.91">A hybrid recognition system for check-worthy claims using heuristics and supervised learning</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Karakas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="12,320.25,127.61,133.69,10.91">CEUR workshop proceedings</title>
		<imprint>
			<biblScope unit="volume">2125</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,154.71,395.16,10.91;12,112.26,168.26,393.73,10.91;12,112.26,181.81,178.18,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,333.04,154.71,174.79,10.91;12,112.26,168.26,337.49,10.91">Nlpir@uned at checkthat! 2021: checkworthiness estimation and fake news detection using transformer models</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Martinez-Rico</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Martinez-Romo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Araujo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="12,478.71,168.26,27.27,10.91;12,112.26,181.81,101.09,10.91">CEUR workshop proceedings</title>
		<imprint>
			<date type="published" when="2021">2936. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,195.36,393.32,10.91;12,112.33,208.91,393.65,10.91;12,112.66,222.46,230.27,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,270.60,195.36,235.39,10.91;12,112.33,208.91,28.53,10.91">BERTweet: A pre-trained language model for English Tweets</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,162.88,208.91,343.10,10.91;12,112.66,222.46,157.27,10.91">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,236.01,393.33,10.91;12,112.66,249.56,395.01,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,315.66,236.01,190.33,10.91;12,112.66,249.56,88.36,10.91">Tweetcred: Real-time credibility assessment of content on twitter</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kumaraguru</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Meier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,223.03,249.56,198.80,10.91">International conference on social informatics</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="228" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,263.11,394.53,10.91;12,112.66,276.66,184.32,10.91" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Srikumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.09248</idno>
		<title level="m" coord="12,217.36,263.11,285.05,10.91">X-fact: A new benchmark dataset for multilingual fact checking</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,112.66,290.20,395.17,10.91;12,112.66,303.75,393.33,10.91;12,112.66,317.30,62.07,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,390.63,290.20,117.20,10.91;12,112.66,303.75,254.90,10.91">TweetEval:Unified Benchmark and Comparative Evaluation for Tweet Classification</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Espinosa-Anke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Neves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,389.93,303.75,116.06,10.91;12,112.66,317.30,30.55,10.91">Proceedings of Findings of EMNLP</title>
		<meeting>Findings of EMNLP</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,330.85,394.53,10.91;12,112.66,344.40,395.01,10.91;12,112.66,357.95,28.67,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,261.06,330.85,241.60,10.91">Semeval-2018 task 3: Irony detection in english tweets</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Van Hee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Lefever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Hoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,128.06,344.40,331.76,10.91">Proceedings of The 12th International Workshop on Semantic Evaluation</title>
		<meeting>The 12th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="39" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,371.50,393.33,10.91;12,112.66,385.05,394.62,10.91;12,112.66,398.60,394.87,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,443.92,371.50,62.07,10.91;12,112.66,385.05,374.11,10.91">Semeval-2019 task 6: Identifying and categorizing offensive language in social media (offenseval)</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,112.66,398.60,317.76,10.91">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="75" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,412.15,393.33,10.91;12,112.66,425.70,394.53,10.91;12,112.66,439.25,65.36,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="12,386.08,412.15,119.91,10.91;12,112.66,425.70,39.59,10.91">Semeval-2018 task 1: Affect in tweets</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bravo-Marquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Salameh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kiritchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,177.55,425.70,325.08,10.91">Proceedings of the 12th international workshop on semantic evaluation</title>
		<meeting>the 12th international workshop on semantic evaluation</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,452.79,394.53,10.91;12,112.66,466.34,393.33,10.91;12,112.66,479.89,394.53,10.91;12,112.28,493.44,395.39,10.91;12,112.66,506.99,366.94,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="12,112.66,466.34,393.33,10.91;12,112.66,479.89,42.86,10.91">SemEval-2019 task 5: Multilingual detection of hate speech against immigrants and women in Twitter</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nozza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Rangel Pardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanguinetti</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S19-2007</idno>
		<ptr target="https://www.aclweb.org/anthology/S19-2007.doi:10.18653/v1/S19-2007" />
	</analytic>
	<monogr>
		<title level="m" coord="12,178.63,479.89,328.55,10.91;12,112.28,493.44,183.55,10.91">Proceedings of the 13th International Workshop on Semantic Evaluation, Association for Computational Linguistics</title>
		<meeting>the 13th International Workshop on Semantic Evaluation, Association for Computational Linguistics<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="54" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,520.54,394.62,10.91;12,112.66,534.09,394.52,10.91;12,112.66,547.64,80.57,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="12,261.69,520.54,225.88,10.91">Semeval-2017 task 4: Sentiment analysis in twitter</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,112.66,534.09,320.35,10.91">Proceedings of the 11th international workshop on semantic evaluation</title>
		<meeting>the 11th international workshop on semantic evaluation</meeting>
		<imprint>
			<date type="published" when="2017">SemEval-2017. 2017</date>
			<biblScope unit="page" from="502" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,561.19,393.33,10.91;12,112.66,574.74,379.15,10.91" xml:id="b20">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Salathé</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">E</forename><surname>Kummervold</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.07503</idno>
		<title level="m" coord="12,289.76,561.19,216.22,10.91;12,112.66,574.74,197.41,10.91">Covid-twitter-bert: A natural language processing model to analyse covid-19 content on twitter</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
