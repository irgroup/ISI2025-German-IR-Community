<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,397.62,15.42;1,89.29,106.66,375.07,15.42;1,89.29,128.58,54.21,15.43">RUB-DFL at CheckThat! 2022: Transformer Models and Linguistic Features for Identifying Relevant Claims</title>
				<funder ref="#_RPRynBS">
					<orgName type="full">German Federal Ministry of Education and Research (BMBF)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,160.47,117.11,5.42"><forename type="first">Zehra</forename><forename type="middle">Melce</forename><surname>Hüsünbeyi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Digital Forensic Linguistics</orgName>
								<orgName type="institution">Ruhr-Universität-Bochum</orgName>
								<address>
									<addrLine>Universitätsstraße 150</addrLine>
									<postCode>44801</postCode>
									<settlement>Bochum</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,219.05,160.47,58.46,5.42"><forename type="first">Oliver</forename><surname>Deck</surname></persName>
							<email>oliver.deck@rub.de</email>
							<affiliation key="aff0">
								<orgName type="department">Digital Forensic Linguistics</orgName>
								<orgName type="institution">Ruhr-Universität-Bochum</orgName>
								<address>
									<addrLine>Universitätsstraße 150</addrLine>
									<postCode>44801</postCode>
									<settlement>Bochum</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,308.51,160.47,81.67,5.42"><forename type="first">Tatjana</forename><surname>Scheffler</surname></persName>
							<email>tatjana.scheffler@rub.de</email>
							<affiliation key="aff0">
								<orgName type="department">Digital Forensic Linguistics</orgName>
								<orgName type="institution">Ruhr-Universität-Bochum</orgName>
								<address>
									<addrLine>Universitätsstraße 150</addrLine>
									<postCode>44801</postCode>
									<settlement>Bochum</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,397.62,15.42;1,89.29,106.66,375.07,15.42;1,89.29,128.58,54.21,15.43">RUB-DFL at CheckThat! 2022: Transformer Models and Linguistic Features for Identifying Relevant Claims</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">65D1EC1A137B5413EE1E7284369ECC63</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>claim identification</term>
					<term>check-worthiness</term>
					<term>English</term>
					<term>Turkish</term>
					<term>linguistic features</term>
					<term>Twitter</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe our system for the CLEF 2022 CheckThat! Lab Task 1 Subtasks A,B,C on check-worthiness estimation, verifiable factual claims detection, and harmful tweet detection in both English and Turkish. We used transformer-based models as well as an ELMo-based attention network. We experimented with data pre-processing, data augmentation and adding linguistic features. The official evaluation ranked our system 1 st and 2 nd for the Turkish data while we achieved average results for the English data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The CheckThat! lab at CLEF <ref type="bibr" coords="1,223.79,371.88,11.48,4.94" target="#b0">[1,</ref><ref type="bibr" coords="1,238.74,371.88,9.03,4.94" target="#b1">2]</ref> aims at providing automated solutions that facilitate or support fake news detection and related subtasks. Automated systems can provide the basis for human fact checkers and may take over some of the more tedious tasks in dealing with an ever increasing number of online disinformation. This paper gives an overview of team RUB-DFL's system for Task 1: Identifying Relevant Claims in Tweets <ref type="bibr" coords="1,353.50,426.08,11.58,4.94" target="#b2">[3]</ref>. Fact checking should only be applied to claims (and not e.g. opinions or predictions about the future), so identifying claims and an assessment of their relevance can be used to prioritize which claims to check.</p><p>Our team participated in three of the four subtasks, namely check-worthiness estimation, claim detection, and harmful tweet detection, for both the English and Turkish data sets. We conducted experiments with transformer-based models, data augmentation and linguistic features, as well as ELMo embeddings and attention networks. Our system reached 1 st place for claim identification and check-worthiness estimation in Turkish and average results on English data. For harmful tweet detection, we placed 9 th on the English data and 2 nd on the Turkish data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Data and Pre-processing</head><p>The data for all three subtasks tackled by our team consisted of between 2891 and 4542 tweets. Tweets were provided with binary labels corresponding to either check-worthiness (subtask 1a), containing a claim (1b) or containing hateful speech (1c). Since there is considerable overlap between the datasets -e.g. every check-worthy claim in subtask 1a is automatically a positive example for a claim in subtask 1b -it is not particularly helpful to combine the datasets to gain a larger basis for training models. However, for subtask 1a, we could utilize last year's CheckThat! data, which we did in section 5.</p><p>Simple data pre-processing steps were taken into consideration for the experiments in section 4.2. These include: changing all text to lower case, removing all URLs, twitter mentions, punctuation that does is not part of an emoticon, and removing all remaining characters that are not letters, numbers, white space, or #.</p><p>We also considered two very simple approaches to data augmentation: Adding additional data from last year's challenge, as mentioned above, as well as adding linguistic inquiry and word counts (LIWC) <ref type="bibr" coords="2,179.91,566.09,16.09,4.94" target="#b15">[16]</ref>. For this step, we tokenized the tweet text and looked up each token in the LIWC dictionary; a word list categorized by psycholinguistic and cognitive dimensions, such as NegativeEmotion, Pronoun, or Health. For each token found in the LIWC dictionary, the corresponding LIWC category was simply appended to the tweet text. The hope was to push the classifier to pay greater attention to these psycholinguistic features, instead of relying simply on the given text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Transformer-based models</head><p>Transformer-based models like BERT <ref type="bibr" coords="3,260.19,135.51,18.01,4.94" target="#b16">[17]</ref> have significantly improved the performance on a wide range of NLP problems such as claim detection related tasks which are typically framed as text classification problems. The BERT architecture follows masked language model (MLM) and next sentence prediction (NSP) procedures. This structure allows the model to learn the relationship between masked words and bidirectionally incoming text, to predict whether a second sentence follows a first, and to examine sentence relationships in an advanced way. After the release of BERT, other transformer-based pretrained language models have employed similar approaches while refining aspects like model size, training speed and efficiency, multilingual embeddings and more.</p><p>After analysing recent studies on benchmark datasets <ref type="bibr" coords="3,346.29,257.45,18.07,4.94" target="#b17">[18]</ref> for text classification tasks, we decided to experiment with autoencoding pretrained language models (PLMs) which mostly outperform autoregressive PLMs (e.g., OpenGBT) and earlier contextualized language models (e.g., CNN and RNN based models). The following PLMs were chosen by considering criteria such as domain compatibility, latency and capacity constraints: BERTweet <ref type="bibr" coords="3,423.83,311.65,18.02,4.94" target="#b18">[19]</ref> because it fits the target domain of the task; XLM-R <ref type="bibr" coords="3,257.40,325.20,17.91,4.94" target="#b19">[20]</ref> to experiment with multilingual embedding spaces; ConvBERT <ref type="bibr" coords="3,139.71,338.75,17.96,4.94" target="#b20">[21]</ref> and ELECTRA <ref type="bibr" coords="3,225.74,338.75,17.96,4.94" target="#b21">[22]</ref> as more computationally efficient models. For the Turkish data, we also used the multilingual XLM-R model, but switched to the Turkish variants of the other models: BERTurk<ref type="foot" coords="3,191.87,363.21,3.71,3.61" target="#foot_0">1</ref> , ConvBERTurk<ref type="foot" coords="3,262.22,363.21,3.71,3.61" target="#foot_1">2</ref> and the Turkish ELECTRA<ref type="foot" coords="3,385.67,363.21,3.71,3.61" target="#foot_2">3</ref> model.</p><p>Despite the significance of hyperparameter tuning, the growing parameter space and lack of memory limit the tuning process to the chosen hyperparameters. We tuned hyperparameters along with controlled experiments and used a fixed seed value used to ensure consistency. For all experiments, weighted-average F1 scores are presented, considering the size of each class and their contribution to the f-score. We used the rich and publicly available AI repository Huggingface<ref type="foot" coords="3,146.19,444.51,3.71,3.61" target="#foot_3">4</ref> for the PLMs. <ref type="table" coords="3,212.96,475.90,3.74,4.94" target="#tab_0">1</ref>, all four models lead to comparable results, although ConvBERT was slightly ahead for subtask 1a (check-worthiness of tweets) with an f-score of 0.839, while BERTweet achieved the highest f-score on subtasks 1b (verifiable factual claims detection) at 0.814 and 1c (harmful tweet detection) at 0.895. However, all f-scores, with the exception of XLM-R in subtask 1a, were within 0.03 points of each other. Such close results, combined with different systems winning different, though related, tasks on very similar data prohibit identifying a clearly superior approach. Further experimentation is needed to explore relevant factors for the success of a particular model. Turkish For the Turkish data, BERTurk provided the highest f-score for subtask 1a at 0.813, the multilingual model XLM-R achieved the highest f-score on subtask 1b at 0.768 and ConvBERTurk took the lead in task 1c at 0.781 f-score, see Table <ref type="table" coords="4,318.00,638.13,3.81,4.94" target="#tab_1">2</ref>. Again, the close field -only XLM-R in subtask 1c deviated by more than 0.03 f-score from any of the other systems -provided little insight into which system would perform best in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>English As seen in Table</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Transformer-based models with pre-processed data</head><p>To investigate the merits of data pre-processing described in section 3, we ran the same systems again on the simpler, cleaner data. With fewer confusing factors such as Twitter mentions and punctuation, the transformer-based models presumably encountered fewer situations they had not seen in training. As can be seen in Table <ref type="table" coords="5,284.17,151.45,4.97,4.94" target="#tab_2">3</ref> and Table <ref type="table" coords="5,336.43,151.45,4.97,4.94" target="#tab_3">4</ref> we therefore achieved slightly higher f-scores.</p><p>English ConvBERT increased in subtask 1a from 0.839 to 0.843, overtaking BERTweet (previously 0.814) with 0.817 in subtask 1b and achieving even numbers with BERTweet (previously 0.895) in subtask 1c where both increased to 0.906 f-score with the pre-processed data. XLM-R and BERTweet were not strongly affected by the pre-processing (BERTweet performance shows a slight decrease for subtask 1a and XLM-R for subtask 1b). ELECTRA, however, exhibited lower scores for all subtasks, leading to the assumption that it managed to pick up on signals that were removed by pre-processing.</p><p>Turkish Simple pre-processing lead to small increases in all three subtasks for the Turkish data as well: In subtask 1a, the top system BERTurk increased from 0.813 to 0.822 f-score, for subtask 1b, BERTurk overtook XLM-R (which decreased from 0.768 to 0.740) with an f-score of 0.788. In subtask 1c, ConvBERTurk increase from 0.781 to 0.781. All increases are fairly small and some systems even decreased in performance. However, since the best models for each task showed improvements, it seems that pre-processing also helps with the agglutinative structure of the Turkish language. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Transformer-based models with data augmentation</head><p>In a first simple step, we focused on augmenting the data of subtask 1a (check-worthiness estimation) with additional data from last year's CheckThat! challenge; subtasks 1b and 1c were different from last year. We first collected the tweets from the 2021 challenge, removed all duplicates and negative examples (to balance the dataset more towards the positive, i.e. check-worthy class). This left us with an additional 875 English and 237 Turkish tweets, which we added to the training data.</p><p>As can be seen in Table <ref type="table" coords="6,207.61,470.03,3.76,4.94" target="#tab_4">5</ref>, results varied based on the language of the data. For English, we saw f-score increases from 0.839 to 0.854 (without pre-processing) and 0.843 to 0.853 for the ConvBERT system, indicating that the additional data contained textual markers that could be picked up by the transformer model. For Turkish, on the other hand, the performance of the winning system BERTweet decreased from 0.813 to 0.805 without pre-processing. For the pre-processed data, while BERTweet achieved 0.822 f-score on the non-augmented data, its performance dropped to 0.797 when trained on the augmented data, reaching second place behind ConvBERTurk with 0.805 f-score. It therefore seems that the Turkish systems may have picked up specific markers of the 2022 data before that better solved the development set, but may not have been actual markers of check-worthiness, leading to a reduced performance when trained on additional data from 2021. Further discussion of the challenges of the Turkish dataset can be found in the Error Analysis section below.</p><p>Our second approach to data augmentation was adding LIWC categories to tweets. This was only possible for the English data, since we had no access to the Turkish version of LIWC. Table <ref type="table" coords="6,116.27,659.72,5.17,4.94" target="#tab_5">6</ref> shows the best performing systems for each subtask on this augmented data. As can be seen, there was no increase in performance when compared to training on either the raw or pre-processed data. Highest f-scores were 0.821 as opposed to 0.843 for subtask 1a, 0.771 as opposed to 0.817 for subtask 1b, and 0.895 as opposed to 0.906 for subtask 1c.</p><p>One explanation is that transformer-based models are trained on natural text and artificially appended LIWC categories are not something the model has seen in training. Such features may be more helpful when integrated in an ensemble model where one part picks up on the LIWC features and can then be combined with the transformers' output. Due to time constraints, we must leave this experiment for future work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Transformer-based models with additional linguistic features</head><p>For this approach, we first calculated nine basic linguistic features as a baseline: word count, character count, punctuation count, emoji count, contains emoji, contains non-Twitter URL, number of LIWC categories, text complexity, and sentiment. For Turkish, only the first six features were calculated. The features were concatenated with our transformer-based models to see if adding simple linguistic markers would lead to improvements.</p><p>For the English data, we also calculated 239 additional linguistic features with the help of the lingfeat library<ref type="foot" coords="8,199.84,189.46,3.71,3.61" target="#foot_4">5</ref> which was originally used for readability assessment <ref type="bibr" coords="8,450.87,192.09,16.41,4.94" target="#b22">[23]</ref>. Due to time constraints, we were not able to implement our own feature set specifically adapted for claim detection and relied on this out-of-the-box solution for English. The 239 features include semantic (e.g. Wikipedia knowledge), discourse (e.g. entity density), syntactic (e.g. part-ofspeech), lexico-semantic (e.g. type token ratio), as well as shallow traditional features (e.g. average number of tokens). An overview of all features can be found in <ref type="bibr" coords="8,409.42,259.84,52.44,4.94">[23, p. 10672</ref>].</p><p>The transformer-based models capture different levels of semantic and syntactic knowledge by use of multi-head attention layers. By concatenating the last four layers of our best performing transformer-based model for each task, we aimed to obtain better representations. These 3072dimensional document embeddings were processed through a fully connected layer with 1024 hidden units and the ReLU activation function. A dropout regularization with a rate of 0.2 was then performed. The resulting hidden layer was incorporated with the 9-dimensional and 239-dimensional external linguistic features separately for the English datasets and the 6dimensional numerical features for the Turkish datasets. The concatenated vectors were passed to a fully connected layer with 128 hidden units and the ReLU activation function. Another dropout regularization with a rate of 0.1 was applied to the hidden layer and predictions were generated with a sigmoid activation function.</p><p>The results for both the baseline features and the whole range of linguistic features provided by the lingfeat library can be found in Table <ref type="table" coords="8,298.79,435.98,3.66,4.94" target="#tab_6">7</ref>. Like before, only the best performing models are shown here. As can be seen, the performance was lower than our pure transformer-based models trained on pre-processed data in Tables <ref type="table" coords="8,295.21,463.08,4.97,4.94" target="#tab_2">3</ref> and<ref type="table" coords="8,321.05,463.08,3.66,4.94" target="#tab_3">4</ref>. What is more, the 239 linguistic features for English lead to lower performance than the 9 simple features. Other experiments with a logistic regression classifier on the linguistic features alone provided very low numbers that barely beat a random baseline. From this we can gather that simply adding a large list of linguistic features which are not necessarily adapted to the task at hand is not helpful. Instead, the low performance of the linguistic features lead to a deterioration of the ensemble when compared to the transformer models alone. However, with more fine-tuning and by identifying linguistic features that are domain-specific, different fusion techniques could be explored in the future. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">ELMo embeddings, attention network and linguistic features</head><p>In a final round of experiments, we moved away from the transformer architecture and evaluated the basic and advanced linguistic features in an ensemble of ELMo embeddings [see 24] in an attention network. Pre-trained ELMo embeddings were processed along with the encoder, a bidirectional RNN based model. We used a GRU rather than an LSTM model to decrease parameters and prevent overfitting given the small size of our corpus. The models were trained with a 500-dimensional bidirectional GRU token encoder. Then, an attention layer producing a sequence vector with indicative tokens received the hidden states of the encoder layer. After dropout regularization with a rate of 0.2, the attention layer's output vectors were merged with either the 9-dimensional or 239-dimensional external linguistic features separately. These concatenated vectors were then fed to a fully connected layer with a ReLU activation function.</p><p>We also added dropout regularization with a rate of 0.1 to the hidden layer. Predictions were created using the sigmoid activation function.</p><p>The results are shown in Table <ref type="table" coords="9,240.98,474.18,3.77,4.94" target="#tab_7">8</ref>. As with the transformer models in section 4.2, the ELMo embedding ensemble performed worse when compared to the transformer models trained on pre-processed text. For the runs with 9 linguistic features, the subtask 1a f-score was 0.803 which would take 3rd place in direct comparison with the transformer models. In subtask 1b, all transformer models beat the 0.7612 f-score of the ELMo ensemble, but in subtask 1c, the 0.881 f-score would place it in 3rd place behind the 0.906 of BERTweet and ConvBERT. When compared to combining transformer models with linguistic features, the attention network with ELMo embeddings performed much better, which may be based on the transformers picking up more relevant linguistic features in their training process inherently, while the architecture used in this chapter lends itself more easily to adding additional signals.</p><p>Again, the 239-dimensional linguistic features lead to lower performance. Since the features are not task-specific for any of the three subtasks, they may simply provide too much noisy data leading to lower performance in the systems. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Official results on the test set</head><p>We submitted the best models in terms of f-score measure for subtasks 1a, 1b, and 1c in both English and Turkish: For subtask 1a English ConvBert with additional data, for Turkish BERTurk with data pre-processing. For subtask 1b English we chose ELECTRA, for Turkish BERTurk with data pre-processing. For subtask 1c English BERTweet with data pre-processing, and for Turkish ConvBert with data pre-processing were chosen.</p><p>Our systems reached average scores on the English data, placing 6 th out of 13 teams in subtask 1a with an F1 score for the positive class of 0.525 (winning system: 0.698). In subtask 1b, we placed 6 th out of 9 systems with an F1 accuracy score of 0.709 (winning system: 0.761) and for subtask 1c we placed 9 th out of 11 teams with an F1 for the positive class of 0.273 (winning system: 0.397).</p><p>On the Turkish data, we placed 1 st in subtask 1a (F1 positive class: 0.212) and 1b (F1 accuracy: 0.801) and 2 nd in subtask 1c (F1 positive class: 0.353, winning system: 0.366). While the scores for task 1c were low across both languages, as well as in the Arabic, Bulgarian and Dutch data sets, the extremely low numbers for task 1a (check-worthiness) in Turkish are an outlier. Here, we were the only team that managed to surpass 0.2 F1 score. It seems that all systems overfit on the training and development data and were not capable of identifying actual check-worthiness markers that would translate to performing well on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Error Analysis</head><p>Due to the overall low evaluation scores on the test set of the check-worthiness subtask in Turkish, we analyzed some of the incorrectly predicted results of our best model. Out of a total of 67 misclassified tweets, there were 5 false negative and 62 false positive instances.</p><p>We checked the false negatives for clues to improve recall. In one example tweet, a wellknown Turkish person is mentioned with a mention tag. The tweet also contains the use of the quotation sign and the last sentence ends with a question mark. It can be interpreted as containing a claim, with the author exhibiting a skeptical distance from that claim. There were also examples in which an exclamation mark was placed in two parentheses, signifying sarcastic use, and suffixes were used to compare two opposite situations. We also found cases where the masses were tried to be mobilized around a claim with the words of the address.</p><p>In the false positive samples, on the other hand, there was a large number of tweets which are difficult to classify. In our manual re-evaluation, we found sentences that could be reclassified as checkworthy claims. It can be seen that quotations which specify the source are frequently used to strengthen statements that can be very dangerous, as in the following example:</p><p>(1) Prof. Serhat Fındık: Hindistan Covid i aşılamayı bırakıp, İvermectin'e geçerek yendi. Afrika da aynı şekilde. İvermectin çok ucuz bir ilaçtır. Küresel ilaç şirketleri ucuz ilaçları sevmezler. 'Prof. Serhat Fındık: India defeated Covid by stopping the vaccine and switching to Ivermectin, likewise in Africa. Ivermectin is a very inexpensive drug. Global pharmaceutical companies do not like cheap drugs. '</p><p>The tweet in ( <ref type="formula" coords="11,160.76,236.08,3.78,4.94">1</ref>) is judged "non-checkworthy", even though in our view it does contain several checkworthy claims (mixed with opinions). The high rate of such gray area cases in the Turkish test data could partially explain the extremely low scores across all systems submitted for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Work</head><p>We have described our system for the CLEF 2022 CheckThat! Lab Task 1. We tackled subtasks 1a, 1b and 1c on check-worthiness, claim detection, and harmful tweet detection, in both English and Turkish. We experimented with four different transformer-based architectures as well as an ELMo-based attention network ensemble. We also tried different methods of pre-processing, data augmentation and included a number of linguistic features. We placed 6 th , 6 th and 9 th for the English data and 1 st , 1 st , and 2 nd for Turkish for the three subtasks. During this trial-anderror process, we realized that transformer based models already capture more comprehensive linguistic features than those we included in the system.</p><p>In the future, we plan to investigate more adapted and task-specific linguistic features, especially since transformer models rely on large amounts of training text which are not available for the majority of the world's languages. Additionally, we will examine what features are most relevant for our problem for designing a more interpretable model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,88.99,90.49,402.29,247.71"><head>Table 1</head><label>1</label><figDesc>Transformer-based models without data pre-processing (English).</figDesc><table coords="4,103.99,122.01,387.30,216.18"><row><cell>English</cell><cell></cell><cell cols="3">accuracy precision recall f-score</cell></row><row><cell></cell><cell>BERTweet</cell><cell>0.824</cell><cell>0.823 0.824</cell><cell>0.823</cell></row><row><cell>Check-worthiness of tweets (EN)</cell><cell>XLM-R</cell><cell>0.807</cell><cell>0.788 0.807</cell><cell>0.790</cell></row><row><cell></cell><cell>ConvBERT</cell><cell>0.838</cell><cell>0.841 0.838</cell><cell>0.839</cell></row><row><cell></cell><cell>ELECTRA</cell><cell>0.826</cell><cell>0.815 0.826</cell><cell>0.818</cell></row><row><cell></cell><cell>BERTweet</cell><cell>0.816</cell><cell>0.814 0.816</cell><cell>0.814</cell></row><row><cell>Verifiable factual claims detection (EN)</cell><cell>XLM-R</cell><cell>0.809</cell><cell>0.807 0.809</cell><cell>0.806</cell></row><row><cell></cell><cell>ConvBERT</cell><cell>0.810</cell><cell>0.810 0.810</cell><cell>0.804</cell></row><row><cell></cell><cell>ELECTRA</cell><cell>0.828</cell><cell>0.826 0.828</cell><cell>0.826</cell></row><row><cell></cell><cell>BERTweet</cell><cell>0.907</cell><cell>0.889 0.907</cell><cell>0.895</cell></row><row><cell>Harmful tweet detection (EN)</cell><cell>XLM-R</cell><cell>0.910</cell><cell>0.828 0.910</cell><cell>0.867</cell></row><row><cell></cell><cell>ConvBERT</cell><cell>0.903</cell><cell>0.885 0.903</cell><cell>0.892</cell></row><row><cell></cell><cell>ELECTRA</cell><cell>0.910</cell><cell>0.828 0.910</cell><cell>0.867</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.99,360.45,408.47,247.71"><head>Table 2 Transformer</head><label>2</label><figDesc></figDesc><table coords="4,97.81,391.98,399.65,216.18"><row><cell>Turkish</cell><cell></cell><cell cols="3">accuracy precision recall f-score</cell></row><row><cell></cell><cell>BERTurk</cell><cell>0.820</cell><cell>0.808 0.820</cell><cell>0.813</cell></row><row><cell>Check-worthiness of tweets (TR)</cell><cell>XLM-R</cell><cell>0.833</cell><cell>0.803 0.833</cell><cell>0.805</cell></row><row><cell></cell><cell>ConvBERTurk</cell><cell>0.830</cell><cell>0.800 0.830</cell><cell>0.806</cell></row><row><cell></cell><cell>ELECTRA</cell><cell>0.827</cell><cell>0.795 0.827</cell><cell>0.801</cell></row><row><cell></cell><cell>BERTurk</cell><cell>0.782</cell><cell>0.777 0.782</cell><cell>0.772</cell></row><row><cell>Verifiable factual claims detection (TR)</cell><cell>XLM-R</cell><cell>0.777</cell><cell>0.771 0.777</cell><cell>0.768</cell></row><row><cell></cell><cell>ConvBERTurk</cell><cell>0.762</cell><cell>0.755 0.762</cell><cell>0.756</cell></row><row><cell></cell><cell>ELECTRA</cell><cell>0.770</cell><cell>0.764 0.770</cell><cell>0.764</cell></row><row><cell></cell><cell>BERTurk</cell><cell>0.781</cell><cell>0.773 0.782</cell><cell>0.776</cell></row><row><cell>Harmful tweet detection (TR)</cell><cell>XLM-R</cell><cell>0.736</cell><cell>0.675 0.736</cell><cell>0.630</cell></row><row><cell></cell><cell>ConvBERTurk</cell><cell>0.788</cell><cell>0.777 0.788</cell><cell>0.781</cell></row><row><cell></cell><cell>ELECTRA</cell><cell>0.760</cell><cell>0.743 0.761</cell><cell>0.748</cell></row></table><note coords="4,139.17,372.46,218.64,8.87"><p>-based models without data pre-processing (Turkish).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,88.99,410.85,402.29,247.71"><head>Table 3</head><label>3</label><figDesc>Transformer-based models with data pre-processing (English).</figDesc><table coords="5,103.99,442.38,387.30,216.18"><row><cell>English</cell><cell></cell><cell cols="3">accuracy precision recall f-score</cell></row><row><cell></cell><cell>BERTweet</cell><cell>0.819</cell><cell>0.821 0.819</cell><cell>0.820</cell></row><row><cell>Check-worthiness of tweets (EN)</cell><cell>XLM-R</cell><cell>0.820</cell><cell>0.784 0.820</cell><cell>0.793</cell></row><row><cell></cell><cell>ConvBERT</cell><cell>0.845</cell><cell>0.841 0.845</cell><cell>0.843</cell></row><row><cell></cell><cell>ELECTRA</cell><cell>0.775</cell><cell>0.601 0.775</cell><cell>0.677</cell></row><row><cell></cell><cell>BERTweet</cell><cell>0.819</cell><cell>0.817 0.819</cell><cell>0.816</cell></row><row><cell>Verifiable factual claims detection (EN)</cell><cell>XLM-R</cell><cell>0.799</cell><cell>0.797 0.799</cell><cell>0.795</cell></row><row><cell></cell><cell>ConvBERT</cell><cell>0.820</cell><cell>0.818 0.820</cell><cell>0.817</cell></row><row><cell></cell><cell>ELECTRA</cell><cell>0.787</cell><cell>0.784 0.787</cell><cell>0.784</cell></row><row><cell></cell><cell>BERTweet</cell><cell>0.914</cell><cell>0.902 0.914</cell><cell>0.906</cell></row><row><cell>Harmful tweet detection (EN)</cell><cell>XLM-R</cell><cell>0.910</cell><cell>0.828 0,910</cell><cell>0,867</cell></row><row><cell></cell><cell>ConvBERT</cell><cell>0.909</cell><cell>0.903 0.909</cell><cell>0.906</cell></row><row><cell></cell><cell>ELECTRA</cell><cell>0.910</cell><cell>0.828 0.910</cell><cell>0.867</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,88.99,90.49,408.47,247.71"><head>Table 4</head><label>4</label><figDesc>Transformer-based models with data pre-processing (Turkish).</figDesc><table coords="6,338.52,122.10,158.94,8.87"><row><cell>accuracy precision recall f-score</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,88.99,90.49,409.71,316.79"><head>Table 5</head><label>5</label><figDesc>Transformer-based models, data augmentation with additional positive samples and pre-processing.</figDesc><table coords="7,326.78,122.10,158.94,8.87"><row><cell>accuracy precision recall f-score</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,88.99,557.83,402.29,92.78"><head>Table 6</head><label>6</label><figDesc>Best-performing transformer-based models, data augmentation with LIWC categories.</figDesc><table coords="7,332.34,589.45,158.94,8.87"><row><cell>accuracy precision recall f-score</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,88.99,90.49,417.01,161.15"><head>Table 7</head><label>7</label><figDesc>Best-performing transformer-based models merged with additional linguistic features.</figDesc><table coords="9,379.66,120.92,126.34,7.05"><row><cell>accuracy precision recall f-score</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="10,88.99,90.49,417.00,134.53"><head>Table 8</head><label>8</label><figDesc>ELMo embeddings and attention network model merged with additional linguistics features</figDesc><table coords="10,360.04,121.63,145.95,8.14"><row><cell>accuracy precision recall f-score</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,108.93,640.83,198.12,4.06"><p>https://huggingface.co/dbmdz/bert-base-turkish-cased</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,108.93,651.79,217.29,4.06"><p>https://huggingface.co/dbmdz/convbert-base-turkish-cased</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,108.93,662.75,262.23,4.06"><p>https://huggingface.co/dbmdz/electra-base-turkish-cased-discriminator</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="3,108.93,673.71,84.73,4.06"><p>https://huggingface.co/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="8,108.93,673.71,138.63,4.06"><p>https://github.com/brucewlee/lingfeat</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was partially funded by the <rs type="funder">German Federal Ministry of Education and Research (BMBF)</rs> in the project "<rs type="projectName">NoFake: AI assisted system for the crowdsourcing based detection of disinformation spread via digital platforms</rs>" (<rs type="grantNumber">16KIS1518K</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_RPRynBS">
					<idno type="grant-number">16KIS1518K</idno>
					<orgName type="project" subtype="full">NoFake: AI assisted system for the crowdsourcing based detection of disinformation spread via digital platforms</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,112.66,628.75,394.53,4.94;11,112.33,642.30,394.85,4.94;11,112.66,655.84,393.33,4.94;11,112.66,669.39,394.53,4.94;12,112.66,90.23,393.53,4.94;12,112.66,103.78,225.55,4.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,284.29,655.84,221.70,4.94;11,112.66,669.39,198.07,4.94">The CLEF-2022 CheckThat! Lab on fighting the covid-19 infodemic and fake news detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beltrán</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,313.54,90.23,148.39,4.94">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Hagen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Verberne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Seifert</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Nørvåg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Setty</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="416" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,117.33,394.53,4.94;12,112.33,130.88,394.85,4.94;12,112.66,144.43,393.33,4.94;12,112.66,157.97,394.52,4.94;12,112.66,171.52,394.53,4.94;12,112.66,185.07,393.33,4.94;12,112.66,198.62,393.33,4.94;12,112.66,212.17,366.90,4.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,432.00,144.43,73.99,4.94;12,112.66,157.97,390.20,4.94">Overview of the CLEF-2022 CheckThat! lab on fighting the COVID-19 infodemic and fake news detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beltrán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Köhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,397.65,185.07,108.34,4.94;12,112.66,198.62,393.33,4.94;12,112.66,212.17,270.79,4.94">Proceedings of the 13th International Conference of the CLEF Association: Information Access Evaluation meets Multilinguality, Multimodality, and Visualization, CLEF &apos;2022</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Degli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Esposti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Sebastiani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Pasi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><surname>Nicola</surname></persName>
		</editor>
		<meeting>the 13th International Conference of the CLEF Association: Information Access Evaluation meets Multilinguality, Multimodality, and Visualization, CLEF &apos;2022<address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,225.72,394.52,4.94;12,112.14,239.27,394.25,4.94;12,112.66,252.82,394.62,4.94;12,112.66,266.37,393.59,4.94;12,112.66,279.92,382.34,4.94" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,462.25,239.27,44.14,4.94;12,112.66,252.82,371.38,4.94">Overview of the CLEF-2022 CheckThat! lab task 1 on identifying relevant claims in tweets</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beltrán</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,402.71,266.37,103.53,4.94;12,112.66,279.92,286.23,4.94">Working Notes of CLEF 2022-Conference and Labs of the Evaluation Forum, CLEF &apos;2022</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Guglielmo Andd Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><surname>Potthast</surname></persName>
		</editor>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,293.47,394.52,4.94;12,112.66,307.02,395.01,4.94;12,112.66,319.74,97.35,7.90" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,208.54,293.47,298.64,4.94;12,112.66,307.02,81.44,4.94">A Survey of Fake News: Fundamental Theories, Detection Methods, and Opportunities</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zafarani</surname></persName>
		</author>
		<idno type="DOI">10.1145/3395046</idno>
		<idno type="arXiv">arXiv:1812.00315</idno>
	</analytic>
	<monogr>
		<title level="j" coord="12,205.56,307.02,118.20,4.94">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="1" to="40" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,334.11,395.01,4.94;12,112.66,346.84,97.35,7.90" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Augenstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.10274</idno>
		<idno>arXiv:2108.10274</idno>
		<title level="m" coord="12,182.32,334.11,161.38,4.94">Towards Explainable Fact Checking</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct coords="12,112.66,361.21,393.33,4.94;12,112.66,374.76,393.92,4.94;12,112.66,387.49,43.94,7.90" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,273.75,361.21,168.07,4.94">A Survey on Automated Fact-Checking</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00454</idno>
	</analytic>
	<monogr>
		<title level="j" coord="12,449.90,361.21,56.08,4.94;12,112.66,374.76,214.55,4.94">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="178" to="206" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,401.86,393.72,4.94;12,112.66,415.41,393.33,4.94;12,112.33,428.96,394.86,4.94;12,112.66,442.51,23.23,4.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,463.51,401.86,42.87,4.94;12,112.66,415.41,393.33,4.94;12,112.33,428.96,123.01,4.94">Overview of the CLEF-2021 CheckThat! Lab Task 2 on Detecting Previously Fact-Checked Claims in Tweets and Political Debates</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="12,258.22,428.96,127.35,4.94">CEUR Workshop Proceedings</title>
		<imprint>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2021">2021</date>
			<pubPlace>Bucharest, Romania</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,456.06,394.52,4.94;12,112.66,469.61,393.61,4.94;12,112.41,483.16,393.58,4.94;12,112.66,496.70,201.79,4.94" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,290.22,469.61,216.04,4.94;12,112.41,483.16,294.81,4.94">Overview of the CLEF-2021 CheckThat! Lab Task 1 on Check-Worthiness Estimation in Tweets and Political Debates</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beltrán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,430.52,483.16,75.47,4.94;12,112.66,496.70,51.81,4.94">CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Bucharest, Romania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,510.25,394.53,4.94;12,112.28,523.80,395.55,4.94;12,112.66,537.35,395.01,4.94;12,112.66,550.90,161.38,4.94" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,361.80,523.80,146.03,4.94;12,112.66,537.35,123.31,4.94">ClaimBuster: The first-ever endto-end fact-checking system</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Caraballo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gawsane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sable</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tremayne</surname></persName>
		</author>
		<idno type="DOI">10.14778/3137765.3137815</idno>
	</analytic>
	<monogr>
		<title level="m" coord="12,244.67,537.35,168.94,4.94">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1945" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,564.45,394.53,4.94;12,112.66,578.00,394.53,4.94;12,112.66,591.55,393.33,4.94;12,112.33,605.10,393.86,4.94;12,112.66,618.65,393.92,4.94;12,112.66,631.38,14.27,7.90" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,172.39,578.00,256.77,4.94">ClaimsKG: A Knowledge Graph of Fact-Checked Claims</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tchechmedjiev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Fafalios</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Boland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gasquet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zloch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zapilko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dietze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Todorov</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-30796-7_20</idno>
	</analytic>
	<monogr>
		<title level="m" coord="12,143.54,605.10,146.85,4.94">The Semantic Web -ISWC 2019</title>
		<title level="s" coord="12,298.55,605.10,160.55,4.94">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Ghidini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><surname>Hartig</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maleshkova</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Svátek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Cruz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hogan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Lefrançois</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Gandon</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="309" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,645.75,393.33,4.94;12,112.66,659.29,394.62,4.94;12,112.66,672.84,394.53,4.94;13,112.66,90.23,23.23,4.94" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,430.88,645.75,75.11,4.94;12,112.66,659.29,355.74,4.94">Overview of the CLEF-2019 CheckThat! Lab: Automatic Identification and Verification of Claims</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barron-Cedeno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,475.88,659.29,31.39,4.94;12,112.66,672.84,106.97,4.94">Task 2: Evidence and Factuality</title>
		<title level="s" coord="12,244.38,672.84,133.00,4.94">CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,103.78,395.17,4.94;13,112.33,117.33,394.85,4.94;13,112.66,130.88,296.89,4.94" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,352.12,103.78,155.71,4.94;13,112.33,117.33,270.48,4.94">Overview of the CLEF-2019 Check-That! Lab: Automatic Identification and Verification of Claims</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Karadzhov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mohtarami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,390.21,117.33,112.09,4.94;13,127.29,130.88,129.93,4.94">CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
	<note>Task 1: Check-Worthiness</note>
</biblStruct>

<biblStruct coords="13,112.66,144.43,394.53,4.94;13,112.66,157.97,393.32,4.94;13,112.66,171.52,394.53,4.94;13,112.66,185.07,84.67,4.94" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,222.56,157.97,283.42,4.94;13,112.66,171.52,179.75,4.94">Overview of CheckThat! 2020 English: Automatic Identification and Verification of Claims in Social Media</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barron-Cedeno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,315.21,171.52,127.03,4.94">CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,198.62,394.62,4.94;13,112.66,212.17,393.33,4.94;13,112.14,225.72,250.44,4.94" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,335.13,198.62,172.15,4.94;13,112.66,212.17,345.18,4.94">NLP\&amp;IR@UNED at CheckThat! 2021: Check-worthiness estimation and fake news detection using transformer models</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Martinez-Rico</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Martinez-Romo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Araujo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,479.79,212.17,26.20,4.94;13,112.14,225.72,100.46,4.94">CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Bucharest, Romania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,239.27,393.33,4.94;13,112.66,252.82,395.01,4.94" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="13,288.91,239.27,217.08,4.94;13,112.66,252.82,91.81,4.94">Aschern at CheckThat! 2021: Lambda-Calculus of Fact-Checked Claims</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chernyavskiy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ilvovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,227.76,252.82,129.93,4.94">CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Bucharest, Romania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,266.37,393.33,4.94;13,112.66,279.92,181.04,4.94" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="13,315.89,266.37,190.10,4.94;13,112.66,279.92,18.15,4.94">Linguistic inquiry and word count: LIWC 2015</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">J</forename><surname>Booth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Pennebaker Conglomerates</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,293.47,395.17,4.94;13,112.66,307.02,395.01,4.94;13,112.66,319.74,97.35,7.90" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="13,349.15,293.47,158.69,4.94;13,112.66,307.02,243.72,4.94">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805[cs</idno>
		<idno>arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,334.11,394.52,4.94;13,112.66,347.66,393.58,4.94;13,112.33,361.21,53.12,4.94" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="13,439.11,334.11,68.08,4.94;13,112.66,347.66,219.72,4.94">Deep learningbased text classification: a comprehensive review</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Minaee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Nikzad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chenaghlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,340.97,347.66,152.21,4.94">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="1" to="40" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,374.76,393.53,4.94;13,112.66,388.31,393.33,4.94;13,112.66,401.86,394.53,4.94;13,112.66,415.41,300.89,4.94" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="13,297.14,374.76,209.05,4.94;13,112.66,388.31,64.55,4.94">BERTweet: A pre-trained language model for English Tweets</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Tuan</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.2</idno>
	</analytic>
	<monogr>
		<title level="m" coord="13,200.44,388.31,305.55,4.94;13,112.66,401.86,390.37,4.94">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,428.96,394.53,4.94;13,112.66,442.51,393.33,4.94;13,112.66,456.06,393.33,4.94;13,112.66,469.61,397.48,4.94;13,112.36,482.34,157.20,7.90" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="13,273.11,442.51,232.87,4.94;13,112.66,456.06,31.29,4.94">Unsupervised Cross-lingual Representation Learning at Scale</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.747</idno>
	</analytic>
	<monogr>
		<title level="m" coord="13,165.95,456.06,340.04,4.94;13,112.66,469.61,232.95,4.94">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8440" to="8451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,496.70,393.32,4.94;13,112.66,510.25,394.53,4.94;13,112.39,523.80,259.65,4.94" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="13,350.88,496.70,155.10,4.94;13,112.66,510.25,145.50,4.94">ConvBERT: Improving BERT with Span-based Dynamic Convolution</title>
		<author>
			<persName coords=""><forename type="first">Z.-H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="13,279.59,510.25,222.85,4.94">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="12837" to="12848" />
			<date type="published" when="2020">2020</date>
			<publisher>Curran Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,537.35,393.33,4.94;13,112.66,550.08,304.71,7.90" xml:id="b21">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10555</idno>
		<title level="m" coord="13,323.19,537.35,182.80,4.94;13,112.66,550.90,174.50,4.94">ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,564.45,393.33,4.94;13,112.66,578.00,393.33,4.94;13,112.66,591.55,394.53,4.94;13,112.66,605.10,394.51,4.94;13,112.66,617.83,115.65,7.90" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="13,231.63,564.45,274.36,4.94;13,112.66,578.00,143.69,4.94">Pushing on Text Readability Assessment: A Transformer Meets Handcrafted Linguistic Features</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.834</idno>
	</analytic>
	<monogr>
		<title level="m" coord="13,281.22,578.00,224.77,4.94;13,112.66,591.55,394.53,4.94;13,112.66,605.10,49.12,4.94">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Online and</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Online and<address><addrLine>Punta Cana, Dominican Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="10669" to="10686" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,632.20,393.32,4.94;13,112.66,645.75,393.33,4.94;13,112.28,659.29,393.71,4.94;13,112.33,672.84,394.05,4.94;14,112.66,90.23,319.57,4.94" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="13,482.48,632.20,23.51,4.94;13,112.66,645.75,162.01,4.94">Deep Contextualized Word Representations</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1202</idno>
	</analytic>
	<monogr>
		<title level="m" coord="13,296.40,645.75,209.59,4.94;13,112.28,659.29,393.71,4.94;13,112.33,672.84,57.15,4.94">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
