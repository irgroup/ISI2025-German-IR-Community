<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,372.89,15.42;1,89.29,106.66,334.68,15.42">iCompass at CheckThat! 2022: Combining Deep Language Models for Fake News Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,64.45,11.96"><forename type="first">Bilel</forename><surname>Taboubi</surname></persName>
							<email>bileltaboubi20@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">iCompass</orgName>
								<address>
									<addrLine>Emeraude Palace, Rue du Lac Windermère, Les Berges du Lac</addrLine>
									<postCode>1053</postCode>
									<settlement>Tunis</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,166.39,134.97,73.55,11.96"><forename type="first">Mohamed</forename><surname>Aziz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">iCompass</orgName>
								<address>
									<addrLine>Emeraude Palace, Rue du Lac Windermère, Les Berges du Lac</addrLine>
									<postCode>1053</postCode>
									<settlement>Tunis</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,242.92,134.97,52.56,11.96"><forename type="first">Ben</forename><surname>Nessir</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">iCompass</orgName>
								<address>
									<addrLine>Emeraude Palace, Rue du Lac Windermère, Les Berges du Lac</addrLine>
									<postCode>1053</postCode>
									<settlement>Tunis</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,326.47,134.97,73.55,11.96"><forename type="first">Hatem</forename><surname>Haddad</surname></persName>
							<email>haddad.hatem@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">iCompass</orgName>
								<address>
									<addrLine>Emeraude Palace, Rue du Lac Windermère, Les Berges du Lac</addrLine>
									<postCode>1053</postCode>
									<settlement>Tunis</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,372.89,15.42;1,89.29,106.66,334.68,15.42">iCompass at CheckThat! 2022: Combining Deep Language Models for Fake News Detection</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">25BCA44EB87CE1F47C2A13BCFBCF067D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Categorical Classification</term>
					<term>fake news detection</term>
					<term>BERT</term>
					<term>RoBERTa</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Users of social media tend to explore different platforms to obtain news and find information about different events and activities. Furthermore they read, share, publish news with no prior knowledge of the certainty of being real or fake. This necessitates the development of an automated system for fake news detection. In this paper we report a system and its output as part of CLEF2022 -CheckThat! Lab Fighting the COVID-19 Infodemic and Fake News Detection. Task 3 was carried out using two BERT base uncased and data preprocessing with stop-words removal, lemmatization. We achieve an F1 score of 0.339 on news classification on English dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Social media platforms have grown to unimaginable heights with a vast amount of information exponentially increasing. This information flow increase allows social media platforms to be a host for plenty of unwanted, untruthful and misleading information that can be made and shared by anyone. As a result a category of people took advantage of it and started disseminating false information about people or entities, making negative impacts to individuals, business and society. The amount of information being shared is uncontrollable and cannot be totally covered by manually fact checking sites, as a result an automated system to detect whether an information is real or fake is in need. In this paper, we have tackled Task 3: Fake News Detection CLEF2022-CheckThat! <ref type="bibr" coords="1,239.03,477.02,11.44,10.91" target="#b0">[1]</ref>. The task required multi-class classification of articles to determine the article claim is true, false, partially false or other (lack of evidence). This task is offered as a mono-lingual task in English and as cross-lingual task for English and German (English training data, German test data) <ref type="bibr" coords="1,274.96,517.66,11.51,10.91" target="#b1">[2]</ref>. The paper discusses the results obtained on the English dataset with pre-trained transformers models and pre-processing techniques applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Tasks Definition</head><p>Task 3 is a multi-class classification problem. Given the text and the title of a news article, determine whether the main claim made in the article is true, partially true, false, or other. This task is offered as a mono-lingual task in English and as cross-lingual task for English and German.</p><p>CheckThat!2022 lab organizers <ref type="bibr" coords="2,240.68,165.48,12.84,10.91" target="#b2">[3]</ref> defined the labels for the categories as follows:</p><p>• False -The claim made in an article is untrue.</p><p>• Partially False -The given claim have weak evidence of the claim and cannot be considered as 100% true or false, • True -The claim is totally true.</p><p>• Other -Articles that cannot be proven as false, true or partially true.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Literature Review</head><p>Internet and social media platforms became a main part in our daily life, our main source for information as well as for misinformation. With the huge increase of false information social media needs to curb the spreading of misinformation through their platform. As a result, fake news detection got wide attention in the NLP research community. In <ref type="bibr" coords="2,404.68,344.40,11.49,10.91" target="#b3">[4]</ref>, authors conducted an exploratory study of COVID-19 misinformation on Twitter. They created two dataset, the first one contains 1500 tweets relating to 1274 false and 226 partially false claims collected from fact-checked claims related to COVID-19 by professional fact-checking organisations with different languages. The non-English tweets got translated into English language with the use of google translator API. The second dataset contains a corpus of 163,096 English tweets with purpose of understanding the misinformation around COVID-19. This study showed that false claims propagate faster than any other fake news category and even verified Twitter accounts of celebrities and organizations are taking part in misinformation spread. In <ref type="bibr" coords="2,408.31,452.79,12.68,10.91" target="#b4">[5]</ref> Das et al. proposed an Ensemble model for COVID-19 fake news detection for the Constraint COVID19 shared task <ref type="bibr" coords="2,110.16,479.89,11.37,10.91" target="#b5">[6]</ref>. They combined pre-trained models with a heuristic algorithm based on the username handle and link-domain in tweets. In <ref type="bibr" coords="2,251.97,493.44,11.28,10.91" target="#b6">[7]</ref>, authors created a multilingual dataset 'The FakeCovid' collected from 92 different fact-checking websites with 5182 articles circulated in 105 countries where 40.8% of articles are written in the English language, the dataset was manually annotated in in three languages English, Hindi and German due to limited knowledge about other different languages. They applied BERT based without finetuning and with preprocessing techniques on the data such as abbreviations and contractions of words, spelling correction to achieve F1-score of 0.76 on English dataset. In <ref type="bibr" coords="2,269.51,574.74,11.59,10.91" target="#b7">[8]</ref>, authors presented a semi-automatic framework 'AMUSED' to collect data from different networking sites such as Twitter, YouTube, and Reddit in different languages with the following steps, identify domain and data sources, scrap the web and detect language, extract social media links and crawl data from them, label the crawled data, human verification and finally merge the social media crawled data with the details from the news articles. They made a use case of COVID-19 misinformation with the framework to collect 8,077 fact-checked news articles from 105 countries in 40 languages. In <ref type="bibr" coords="2,452.60,656.03,11.58,10.91" target="#b8">[9]</ref>, authors presented overview of the CLEF-2021 CheckThat! Lab on Task 3 fake news detection where they described Task 3A, which is about determining whether a claim is true, partially true, false, or other, and Task 3B, which is about classifying an article to a topical domain (health, crime, climate, election, and education). Thus they described the provided data for each task and their collection and annotation steps, the participants team and their solution. There were 27 teams for Task 3A, The best performing system for Task 3A was obtained by NoFake team and achieved a macro F1-score of 0.84 and was ahead of the rest by a rather large margin, they applied BERT base and trained it with additional data from different fact-checking websites. For Task 3B there were 20 teams and the best system was made by NITK_NLP <ref type="bibr" coords="3,441.97,181.81,17.97,10.91" target="#b9">[10]</ref> achieving 0.88 marco F1 score with an ensemble of three transformers models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Data Preparation</head><p>The provided dataset contains about 1264 articles in English (title and text) with the respective label (true, partially true, false, or other) divided into a training set with 900 rows and a development set with 394 rows. Table <ref type="table" coords="3,260.35,281.08,5.08,10.91" target="#tab_0">1</ref> presents a sample of the dataset for task 3 and table 2 introduces the distribution of the dataset according to their respective classes. For the data pre-processing we applied various techniques, such as applying lowercase, lemmatization, English stopwords removal such as "are", "the", "is" and etc, punctuation removal using NLTK <ref type="bibr" coords="3,144.84,638.86,17.76,10.91" target="#b10">[11]</ref> library. The dataset contained null values for texts and titles. In order to make it more manageable null values for titles were replaced by their texts and null values for texts were replaced with their titles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Approach</head><p>This paper introduced two concatenated parallel BERT models for classifying whether the news are real or fake. The process of predicting the news different categories true, false, partially false or other is done by using the following architecture:</p><p>-Title input layer, Text input layer.</p><p>-BERT model for text input followed by a gated recurrent unit with 128 untis and 0.3 probability for dropout and a dropout layer with 0.1 probability.</p><p>-BERT model for title input following by global max pooling layer and dropout layer with 0.1 probability.</p><p>-Concatenation layer to concatenate the output of the BERT models.</p><p>-Dense layer with softmax activation function and four units. As presented in figure <ref type="figure" coords="4,205.62,576.49,5.17,10.91" target="#fig_0">1</ref> the model takes as input each of text and title after getting preprocessed. The inputs layers passes the data to BERT models one for the text input and the other for title input. Before predicting the classes, the output of each BERT model get concatenated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Pre-trained Models</head><p>In order to achieve the best results different pre-trained models were used, combined and fine-tuned with different hyperparameters for the multi-class classification task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BERT base Uncased</head><p>BERT <ref type="bibr" coords="5,118.01,174.56,18.06,10.91" target="#b11">[12]</ref> is a trained Transformer Encoder stack that uses bidirectional self-attention. The BERT's model architecture is composed by multiple encoder layers (also called Transformer Blocks) twelve in the Base version. Thus, it has larger feedforward networks (768 hidden units) and 12 attention heads. The model is trained on unlabeled data over different pre-training tasks. For finetuning, the BERT model is initialized with the pre-trained parameters and can be used directly. The model initial parameters change by training it by labeled data from the downstream tasks such as Masked LM, Next Sentence Prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RoBERTa</head><p>The self-supervised transformer model RoBERTa <ref type="bibr" coords="5,314.88,305.58,18.07,10.91" target="#b12">[13]</ref> was trained on a enormous corpus of English data containing five English-language corpora of varying sizes and domains, totaling over 160GB of uncompressed text. Self-supervised means it was pre-trained on raw texts with no human annotation, and then utilized an automated way to generate inputs and labels from those texts. RoBERTa model achieves state-of-the-art results on GLUE (The General Language Understanding Evaluation), RACE (The ReAding Comprehension from Examinations) and SQuAD (The Stanford Question Answering Dataset).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Results &amp; Discussion</head><p>Pre-trained models BERT base uncased and RoBERTa were trained and finetuned with the following architecture: the model is a multi-input, a concatenation between 2 sub-model just before the classification layer where the first is taking text input followed by embedding layer which will contain a BERT model , Gated recurrent network layer with 128 units and 0.3 dropout rate, global max pooling and a dropout layer. The second sub-model consisted of an input layer, Embedding layer which will contain a second BERT model, Global max pooling layer and a dropout layer. The average training time of a model is around 8 minutes. Best results achieved by each pre-trained model is presented in the table <ref type="table" coords="5,321.74,540.34,5.16,10.91" target="#tab_1">3</ref> where they got trained on the train set, tested with dev set. RoBERTa was pre-trained on a bigger vocabulary than BERT base uncased but it got outperformed and that is due to the limited resources available to train the models, the batch size and sequence length was limited where we was unable to exceed 10 batch size and 128 sequence length while training RoBERTa model with the proposed architecture.</p><p>The submitted model was BERT base uncased, trained with a 10 epochs, 2e-5 learning rate for Adam optimizer, a sequence length of 128, 22 batch size and categorical cross entropy loss function. The model achieved F1_score 0.513 on the dev set.</p><p>Our model for task 3 achieved interesting results on English test set and we were placed first in task 3 ranking leaderboard with 0.339 macro F1 measure among 25 participants as shown in table <ref type="table" coords="6,113.59,208.91,3.74,10.91" target="#tab_2">4</ref>. The low macro F1 score can be explained with the categories 'other' and 'partially false', since these classes presented low precision and recall scores as shown in the table 5. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>In this paper, we analysed pre-trained models BERT base uncased and RoBERTa. In order to obtain the best macro F1 for fake news classification on the English dataset different preprocessing techniques were used such as stopwards removal, lemmatization, etc. with the purpose of reducing irrelevant words from the text and title for training. Our model attained 0.339 macro F1 measure which is unsatisfactory and that is due to the data low distribution specially for the categories 'other' and 'partially false'. In future, we will explore augmentation and resembling strategies to create a large balanced dataset for training and validating our proposed model and try to overcome our limitations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,89.29,262.30,163.18,8.93;4,184.25,278.20,226.78,283.48"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: News classes prediction steps</figDesc><graphic coords="4,184.25,278.20,226.78,283.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,323.64,399.25,259.77"><head>Table 1</head><label>1</label><figDesc>Samples of Task 3 dataset</figDesc><table coords="3,88.99,351.68,399.25,231.73"><row><cell cols="2">public_id text</cell><cell></cell><cell>title</cell><cell>rating</cell></row><row><cell></cell><cell></cell><cell></cell><cell>The Texas State</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Senate -Senator Paul Bettencourt:</cell><cell>true</cell></row><row><cell></cell><cell></cell><cell></cell><cell>District 7</cell></row><row><cell></cell><cell cols="2">A 2,500-strong border and coastguard corps could</cell><cell></cell></row><row><cell>2d06d27c</cell><cell cols="2">see armed personnel sent to Greece. The island of Lesbos has been deluged with migrants The</cell><cell>EU army to protect borders</cell><cell>false</cell></row><row><cell></cell><cell>European Union's ...</cell><cell></cell><cell></cell></row><row><cell>Table 2</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Data distribution of task 3</cell><cell></cell><cell></cell></row><row><cell></cell><cell>rating</cell><cell>occurence</cell><cell></cell></row><row><cell></cell><cell>True</cell><cell>211</cell><cell></cell></row><row><cell></cell><cell>False</cell><cell>578</cell><cell></cell></row><row><cell></cell><cell cols="2">Partially False 358</cell><cell></cell></row><row><cell></cell><cell>Other</cell><cell>117</cell><cell></cell></row></table><note coords="3,107.04,382.12,36.74,8.87;3,161.23,370.06,199.89,8.87;3,161.23,382.02,192.88,8.87;3,161.23,393.97,182.40,8.87"><p>1145ea7c U.S. military officials worked to ensure President Trump wouldn't see the warship that bears the name of the late senator, a frequent target ...</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,88.99,580.45,332.61,71.00"><head>Table 3</head><label>3</label><figDesc>Task 1A Pre-trained models results on test set.</figDesc><table coords="5,173.67,618.27,247.94,33.17"><row><cell>Type</cell><cell>F1</cell><cell cols="3">Accuracy Precision Recall</cell></row><row><cell cols="2">BERT base uncased 0.513</cell><cell>0.511</cell><cell>0.555</cell><cell>0.511</cell></row><row><cell>RoBERTa</cell><cell>0.227</cell><cell>0.237</cell><cell>0.220</cell><cell>0.237</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.99,235.47,277.84,85.18"><head>Table 4</head><label>4</label><figDesc>Top 3 on Task 3 English leaderboard</figDesc><table coords="6,228.45,275.51,138.38,45.13"><row><cell>Team</cell><cell cols="2">Accuracy F1-Score</cell></row><row><cell>iCompass</cell><cell>0.547</cell><cell>0.339</cell></row><row><cell>nlpiruned</cell><cell>0.541</cell><cell>0.332</cell></row><row><cell>awakened</cell><cell>0.531</cell><cell>0.323</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,88.99,394.01,301.64,97.13"><head>Table 5</head><label>5</label><figDesc>Classification report on the test set</figDesc><table coords="6,204.65,434.05,185.98,57.09"><row><cell>iCompass</cell><cell cols="3">precision recall F1-Score</cell></row><row><cell>false</cell><cell>0.636</cell><cell>0.832</cell><cell>0.721</cell></row><row><cell>other</cell><cell>0.105</cell><cell>0.065</cell><cell>0.079</cell></row><row><cell>partially false</cell><cell>0.145</cell><cell>0.214</cell><cell>0.173</cell></row><row><cell>true</cell><cell>0.602</cell><cell>0.281</cell><cell>0.383</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,112.66,111.28,393.33,10.91;7,112.66,124.83,393.58,10.91;7,112.66,138.38,382.34,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,431.30,111.28,74.69,10.91;7,112.66,124.83,259.59,10.91">Overview of the CLEF-2022 CheckThat! lab task 3 on fake news detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Köhler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,397.40,124.83,108.85,10.91;7,112.66,138.38,286.23,10.91">Working Notes of CLEF 2022-Conference and Labs of the Evaluation Forum, CLEF &apos;2022</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,151.93,394.53,10.91;7,112.33,165.48,394.85,10.91;7,112.66,179.03,393.32,10.91;7,112.66,192.57,394.53,10.91;7,112.66,206.12,395.17,10.91;7,112.66,219.67,193.11,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,272.14,179.03,233.84,10.91;7,112.66,192.57,154.75,10.91">The clef-2022 checkthat! lab on fighting the covid-19 infodemic and fake news detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beltrán</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,272.10,206.12,151.66,10.91">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Hagen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Verberne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Seifert</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Nørvåg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Setty</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="416" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,233.22,394.53,10.91;7,112.33,246.77,394.85,10.91;7,112.66,260.32,393.33,10.91;7,112.66,273.87,394.52,10.91;7,112.66,287.42,393.33,10.91;7,112.28,300.97,394.91,10.91;7,112.66,314.52,89.12,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,432.00,260.32,73.99,10.91;7,112.66,273.87,390.20,10.91">Overview of the CLEF-2022 CheckThat! lab on fighting the COVID-19 infodemic and fake news detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beltrán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Köhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,126.92,287.42,379.07,10.91;7,112.28,300.97,390.55,10.91">Proceedings of the 13th International Conference of the CLEF Association: Information Access Evaluation meets Multilinguality, Multimodality, and Visualization, CLEF &apos;2022</title>
		<meeting>the 13th International Conference of the CLEF Association: Information Access Evaluation meets Multilinguality, Multimodality, and Visualization, CLEF &apos;2022<address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,328.07,395.17,10.91;7,112.66,341.62,394.62,10.91;7,112.66,355.17,397.48,10.91;7,112.66,371.16,186.37,7.90" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,324.52,328.07,183.31,10.91;7,112.66,341.62,103.58,10.91">An exploratory study of covid-19 misinformation on twitter</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dirkson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Majchrzak</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.osnem.2020.100104</idno>
		<ptr target="https://doi.org/10.1016/j.osnem.2020.100104" />
	</analytic>
	<monogr>
		<title level="j" coord="7,231.08,341.62,164.73,10.91">Online Social Networks and Media</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">100104</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,382.26,393.33,10.91;7,112.66,395.81,397.48,10.91;7,112.66,411.80,32.07,7.90" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="7,245.27,382.26,260.71,10.91;7,112.66,395.81,63.61,10.91">A heuristic-driven ensemble framework for covid-19 fake news detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Basak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dutta</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2101.03545</idno>
		<ptr target="https://arxiv.org/abs/2101.03545.doi:10.48550/ARXIV.2101.03545" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,422.91,394.53,10.91;7,112.33,436.46,393.65,10.91;7,112.66,450.01,393.32,10.91;7,112.66,463.56,397.48,10.91;7,112.36,479.55,146.82,7.90" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,182.43,436.46,222.61,10.91">Fighting an infodemic: COVID-19 fake news dataset</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Patwa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Pykl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Guptha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ekbal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Chakraborty</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-73696-5_3</idno>
		<ptr target="https://doi.org/10.1007%2F978-3-030-73696-5_3.doi:10.1007/978-3-030-73696-5_3" />
	</analytic>
	<monogr>
		<title level="m" coord="7,426.05,436.46,79.94,10.91;7,112.66,450.01,287.41,10.91">Combating Online Hostile Posts in Regional Languages during Emergency Situation</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,490.66,393.33,10.91;7,112.66,504.21,397.48,10.91;7,112.36,520.20,14.27,7.90" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,216.16,490.66,289.83,10.91;7,112.66,504.21,58.27,10.91">FakeCovid-A Multilingual Cross-domain Fact Check News Dataset for COVID-19</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nandini</surname></persName>
		</author>
		<idno type="DOI">10.36190/2020.14</idno>
		<ptr target="https://doi.org/10.36190/2020.14.doi:10.36190/2020.14" />
	</analytic>
	<monogr>
		<title level="j" coord="7,178.93,504.21,30.63,10.91">ICWSM</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,531.30,395.00,10.91;7,112.66,544.85,338.78,10.91" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="7,168.04,531.30,309.60,10.91">Amused: An annotation framework of multi-modal social media data</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2010.00502</idno>
		<ptr target="https://arxiv.org/abs/2010.00502.doi:10.48550/ARXIV.2010.00502" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,558.40,393.33,10.91;7,112.66,571.95,349.75,10.91" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M S</forename><surname>Gautam Kishore</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Mand</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2936/paper-30.pdf" />
		<title level="m" coord="7,292.82,558.40,213.17,10.91;7,112.66,571.95,102.82,10.91">Overview of the clef-2021 checkthat! lab: Task 3 on fake news detection</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,585.50,393.64,10.91;7,112.66,599.05,394.84,10.91" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K M</forename><surname>Hariharan</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2936/paper-49.pdf" />
		<title level="m" coord="7,196.34,585.50,309.96,10.91;7,112.66,599.05,151.23,10.91">RamakrishnaIyer LekshmiAmmal, Overview of the clef-2021 checkthat! lab: Task 3 on fake news detection</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,612.60,393.33,10.91;7,112.66,626.15,253.14,10.91" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="7,228.64,612.60,277.34,10.91;7,112.66,626.15,122.59,10.91">Natural language processing with Python: analyzing text with the natural language toolkit</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>O&apos;Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,639.70,393.33,10.91;7,112.66,653.25,395.01,10.91;7,112.66,666.80,167.31,10.91" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="7,352.90,639.70,153.09,10.91;7,112.66,653.25,186.90,10.91">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1810.04805</idno>
		<ptr target="https://arxiv.org/abs/1810.04805.doi:10.48550/ARXIV.1810.04805" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,86.97,394.53,10.91;8,112.30,100.52,394.97,10.91;8,112.31,114.06,288.85,10.91" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="8,170.33,100.52,252.97,10.91">Roberta: A robustly optimized bert pretraining approach</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1907.11692</idno>
		<ptr target="https://arxiv.org/abs/1907.11692.doi:10.48550/ARXIV.1907.11692" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
