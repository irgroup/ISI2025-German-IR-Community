<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,85.05,315.45,15.39;1,89.29,106.97,366.22,15.39">NUS-IDS at CheckThat!2022: Identifying Check-worthiness of Tweets using CheckthaT5</title>
				<funder ref="#_du9YzC5">
					<orgName type="full">NUS</orgName>
				</funder>
				<funder>
					<orgName type="full">CTIC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,136.29,60.29,10.68"><forename type="first">Mingzhe</forename><surname>Du</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Data Science</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,167.94,136.29,108.23,10.68"><forename type="first">Sujatha</forename><surname>Das Gollapalli</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Data Science</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Centre for Trusted Internet and Community</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,312.47,136.29,67.27,10.68"><forename type="first">See-Kiong</forename><surname>Ng</surname></persName>
							<email>seekiong@nus.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Data Science</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Centre for Trusted Internet and Community</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,85.05,315.45,15.39;1,89.29,106.97,366.22,15.39">NUS-IDS at CheckThat!2022: Identifying Check-worthiness of Tweets using CheckthaT5</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">BD6E083D094AF6F99EB6C9B0D0CEB224</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Fact-checking</term>
					<term>Multilingual</term>
					<term>Transformers</term>
					<term>Social media</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our system CheckthaT5, which was designed in the context of the Checkthat! 2022 competition at CLEF. CheckthaT5 explores the feasibility of adapting sequence-to-sequence models for detecting check-worthy social media content in a multilingual environment (Arabic, Bulgarian, Dutch, English, Spanish and Turkish) provided in the competition. We feed all languages into CheckThaT5 uniformly, thus enabling knowledge transfer from high-resource languages to low-resource languages. Empirically, CheckthaT5 outperforms strong baselines in all low-resource languages. In addition, we incorporate tasks based on non-textual features that complement tweets and other related Checkthat! 2022 tasks into CheckthaT5 through multitask learning further improving the average classification performance by 3 per cent. With our CheckThaT5 model, we rank first in 4 out of 6 languages at Checkthat! 2022 Task 1A.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the rise of social media, everyone can disseminate information on the Internet, while the Internet was inherently deficient in regulatory mechanisms for information authenticity <ref type="bibr" coords="1,492.23,429.35,11.58,9.74" target="#b1">[1]</ref>. Fact-checking systems were developed, and the task of verifying whether the information has check-worthiness is the outset of fact-checking system pipelines <ref type="bibr" coords="1,378.75,456.45,11.43,9.74" target="#b2">[2]</ref>.</p><p>Until recently, most fact-checking systems were designed in the context of Wikipedia <ref type="bibr" coords="1,481.78,470.00,11.34,9.74">[3,</ref><ref type="bibr" coords="1,495.85,470.00,7.55,9.74" target="#b4">4]</ref>, academic papers <ref type="bibr" coords="1,165.76,483.55,11.45,9.74" target="#b5">[5]</ref>, and other relatively formal domains <ref type="bibr" coords="1,346.91,483.55,11.37,9.74" target="#b6">[6,</ref><ref type="bibr" coords="1,361.02,483.55,7.48,9.74" target="#b7">7,</ref><ref type="bibr" coords="1,371.24,483.55,7.58,9.74" target="#b8">8]</ref>, in which the canonical and logical writing style may help models identify factual inconsistencies <ref type="bibr" coords="1,393.81,497.10,11.28,9.74" target="#b8">[8]</ref>. Yet the real challenge of fact-checking comes from social media. Social media enables speedy dissemination of massive content, while at the same time lacks regulatory and quality control due to which the problem of fact-checking is significantly increased <ref type="bibr" coords="1,282.68,537.75,11.58,9.74" target="#b9">[9]</ref>. Thus models that are designed to sift highly influential and check-worthy content through the information flood are highly desirable.</p><p>Current state-of-the-art fact-checking models do not adequately address low-resource languages. Previous works train a dedicated model for each language <ref type="bibr" coords="1,398.93,578.39,16.41,9.74" target="#b10">[10]</ref>. However, the per-formance of these models usually is not comparable to English models, due to the limited corpus resources and labeled data <ref type="bibr" coords="2,239.10,101.64,16.09,9.74" target="#b10">[10]</ref>. To address this shortcoming, we seek to enhance model understanding of language-independent knowledge through multitask learning, thereby improving the model performance on low-resource languages with assistance from high-resource languages.</p><p>To this end, we propose CheckthaT5, a powerful sequence-to-sequence model based on mT5 <ref type="bibr" coords="2,111.84,169.38,16.10,9.74" target="#b11">[11]</ref>. CheckthaT5 can uniformly handle classification tasks as well as regression tasks in a multitask learning manner. In the Checkthat! 2022 task 1A, Our model achieved the best results on Arabic, Bulgarian, Dutch and Spanish datasets, ranked second among Turkish and eighth among English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Task Background and Data Analysis</head><p>Checkthat! 2022 competition aims to fight the COVID-19 infodemic and detects fake news <ref type="bibr" coords="2,487.41,268.66,19.77,9.74" target="#b12">[12,</ref><ref type="bibr" coords="2,89.04,282.21,12.27,9.74" target="#b13">13]</ref>. <ref type="foot" coords="2,105.40,279.53,4.06,7.79" target="#foot_0">1</ref> The dataset consists of 16,000 manually annotated tweets for fine-grained disinformation analysis, which covers Arabic, Bulgarian, Dutch, English, Spanish and Turkish. Based on this dataset, the competition organisers construct multiple downstream tasks of fact-checking. In this paper, we focus on the task "check-worthiness of tweets", which predicts whether the given tweet is worth for fact-checking <ref type="bibr" coords="2,232.43,336.40,16.09,9.74" target="#b14">[14]</ref>. In this section, we describe our qualitative investigations, through which we obtain insights used to design our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multilingual tasks</head><p>The Checkthat! 2022 dataset includes six languages. Compared with English, the other five languages are relatively low-resource languages. Previous works typically train a dedicated model for each language, which involves fine-tuning pre-trained language models on specific datasets <ref type="bibr" coords="2,214.92,404.15,16.56,9.74" target="#b15">[15,</ref><ref type="bibr" coords="2,234.26,404.15,12.59,9.74" target="#b16">16,</ref><ref type="bibr" coords="2,249.64,404.15,12.42,9.74" target="#b17">17]</ref>. Following this approach, fact-checking models have made rapid progress in languages such as English where large-scale language models and corpora are available. However, large-scale models or corpora to train them are infeasible in low-resource languages. These languages may have available monolingual models and corresponding corpora, but their size and quantity are much less than those of mainstream languages such as English. It is challenging to train accurate classifiers using the above approach. Instead, a large, labeled dataset may be required which again comprises a roadblock for lowresource languages. Therefore, we posit that if we extract language-independent knowledge representations from multilingual language models and transfer them to low-resource language tasks, we can effectively improve the performance of these tasks. Accordingly, we adopt the multitask learning paradigm in our model.</p><p>Class Imbalance in Training Data. The competition organisers provided training, development and development-test sets for each language. Table <ref type="table" coords="2,354.16,566.74,5.02,9.74" target="#tab_0">1</ref> provides the label distribution of Checkthat! 2022 Task 1A datasets. As can be seen in this table, the competition datasets have significant class imbalance. Previous research has indicated that address class imbalance is crucial while designing classification models especially when the training datasets are significantly small as in low-resource settings <ref type="bibr" coords="2,241.27,620.94,16.42,9.74" target="#b18">[18]</ref>. We therefore adopt class weighted loss and two data sampling methods to alleviate this problem. Link Processing. Though a large number of tweets in the provided datasets have URL information, we noticed that these links are not informative and instead seem to have been generated randomly. We therefore substitute all URLs with a placeholder "[LINK]" in the preprocessing step. Experimentally, we found that the results with link replacement not only promotes the model performance but also shortens the input sequence length and thereby improves the training efficiency. Table <ref type="table" coords="3,259.07,545.16,4.97,9.74" target="#tab_1">2</ref> reveals the performance difference on the development set between models training with links and without links.</p><p>Tweet Meta-features. Apart from the content of tweets, tweets also contain a number of meta-features, such as the author profile, the count of tweet likes and whether the tweet topic is hot, etc. Hence, we consider the effectiveness of these features in improving check-worthiness prediction. To exploit these features, we constructed new datasets by including these tweet meta-features. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Baselines</head><p>The CLEF Checkthat! 2022 competition organizers provided three baselines, namely: Majority, Random and ùëÅ-gram. We selected the ùëÅ-gram baseline among them to compare with our model since it is difficult to derive task-related insights from the other two models. Furthermore, based on best performing models from the previous year's competition <ref type="bibr" coords="4,371.39,277.13,16.09,9.74" target="#b10">[10]</ref>, such as Schlicht et al. <ref type="bibr" coords="4,488.22,277.13,17.76,9.74" target="#b19">[19]</ref> who employed a multilingual transformer model, we selected a strong multilingual transformer model RoBerta <ref type="bibr" coords="4,157.90,304.22,17.91,9.74" target="#b20">[20]</ref> as a baseline. We report our best results and baseline results in Table <ref type="table" coords="4,487.38,304.22,3.74,9.74" target="#tab_2">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">N-gram</head><p>The ùëÅ-gram baseline uses the TF-IDF vector representation of uni-grams into a support vector classification (SVC) <ref type="bibr" coords="4,175.88,367.50,17.76,9.74" target="#b21">[21]</ref> model to predict binary labels. This method is fast and straightforward, but cannot handle unknown words in the training data and also ignores the relationship between words. In Checkthat! 2021, Martinez-Rico <ref type="bibr" coords="4,289.65,394.60,18.07,9.74" target="#b22">[22]</ref> and Touahri <ref type="bibr" coords="4,372.03,394.60,18.07,9.74" target="#b23">[23]</ref> used more sophisticated word vector techniques such as word2vec <ref type="bibr" coords="4,277.22,408.15,17.91,9.74" target="#b24">[24]</ref> and GloVe <ref type="bibr" coords="4,346.04,408.15,16.25,9.74" target="#b25">[25]</ref>, which obtained more semantic information through training on a large corpus. However, these methods are inherently deficient in contextual understanding since they do not incorporate sentence-level information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Multilingual Models</head><p>In addition to the ùëÅ-gram baseline described in the previous section, we set up another baseline using the multilingual transformer model XLM-RoBERTa <ref type="bibr" coords="4,359.31,498.52,16.42,9.74" target="#b26">[26]</ref>. It is pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages and provides a strong baseline for comparing against our proposed CheckthaT5 model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data Preprocessing</head><p>To mitigate model bias and over-fitting due to the class imbalance issue mentioned in Section 2, we use class weighted loss and two data sampling methods, scilicet upsampling and downsampling <ref type="bibr" coords="4,113.82,632.31,16.09,9.74" target="#b18">[18]</ref>, to enhance model generalisation. For class weighted loss, weighing the loss computed for samples differently based on the corresponding class proportion. For downsampling, we randomly remove the preponderance class samples until the number of classes is balanced. For upsampling, we repeatedly sample the disadvantaged class samples until the proportions of all classes are close. After experiments, we found that upsampling works best.</p><p>After the link processing step, mentioned in Section 2, data samples are divided into queries and labels in the preprocessing stage. Depending on the language and task type, we insert a prompt string to the head of queries. The specific generation method of the prompt string will be introduced in Section 4.2.<ref type="foot" coords="5,215.42,153.16,4.06,7.79" target="#foot_1">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Multitask Training</head><p>Based on the exploratory data analysis, we found that whether a tweet is check-worthy is also affected by factors other than the content of the tweet. For example, the number of followers, the number of retweets, and whether the related topic is popular among others. To utilise these tweet meta-features, we construct a set of auxiliary tasks.</p><p>We created a new dataset using tweets and corresponding like counts to set up an auxiliary regression task that predicts "tweet likes" counts. Similarly, we also found that other sub-tasks in Checkthat! 2022 Task 1, such as "Verifiable factual claims detection", "Attention-worthy tweet detection", can assist CheckthaT5 to improve the performance of the main task "Checkworthiness detection".</p><p>In addition, "translation" tasks are created as follows: We used the different language datasets from CheckThat! 2022 Task 1A and employed the Google translation library Rosetta <ref type="bibr" coords="5,475.94,341.05,18.07,9.74" target="#b27">[27]</ref> to get their corresponding English translations. Using each of these non-English datasets, we added five "OL to EN" translation tasks to our multitask learning setup where OL refers to a non-English language from the set AR (Arabic), BG (Bulgarian), NL (Dutch), ES (Spanish), TR (Turkish). A language prompt string is assigned for each language separately <ref type="bibr" coords="5,453.34,395.25,16.31,9.74" target="#b28">[28]</ref>. In this way by adding English translation tasks for all available languages and training them jointly, we hope to learn cross-language representation and boost performance for low-resource languages using the better resourced ones such as English.</p><p>As described above, both classification and regression tasks can uniformly added into our multitask learning set up. We list the different tasks and their prompts used in CheckThaT5 in Table <ref type="table" coords="5,115.56,476.55,3.70,9.74" target="#tab_3">4</ref>. In Section 5.2, the effectiveness of each of these tasks for improving check-worthiness is studied experimentally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">CheckthaT5 Model</head><p>The processed datasets are afterwards fed into a point-wise model, which we call CheckthaT5. This model is based on mT5, a multilingual sequence-to-sequence transformer pretrained on the mC4 corpus, covering 101 languages <ref type="bibr" coords="5,274.99,566.92,16.42,9.74" target="#b11">[11]</ref>. All tasks can be cast as sequence-to-sequence tasks in mT5. We follow this style to convert all mentioned tasks by using the following input sequence:</p><formula xml:id="formula_0" coords="5,206.66,607.57,181.95,9.74">&lt; ùëÉùëüùëúùëöùëùùë° ‚Äñ ùëÑùë¢ùëíùëüùë¶ ‚à∂ ùëûùë¢ùëíùëüùë¶ ‚Äñ ùêøùëéùëèùëíùëô ‚à∂ ùëôùëéùëèùëíùëô &gt;</formula><p>This core idea of CheckthaT5 is to train distinct tasks jointly, enabling the model to learn language-independent knowledge. We purpose to handle classification tasks and regression tasks uniformly through the model decoder layers. For binary classification tasks, the model is fine-tuned to produce the tokens "yes" or "no" by the particular task definition. For regression tasks, the model output should be a string of numbers. However, the original output space of language models spans the entire vocabulary. To ensure the model output only comprises of classification labels (e.g., "yes" or "no"), we ignore all logits except label words for classification tasks. Similarly, to produce numerical output predictions in regression tasks, we only consider output tokens that are digits, i.e. 0 to 9 thus ensuring that the final output is a legal number (e.g., "224" or "619"). We fine-tune the mT5-XL model<ref type="foot" coords="6,241.38,353.77,4.06,7.79" target="#foot_2">3</ref> with a batch size of 128 for 2,000 steps. The learning rate is constant at 0.001. After fine-tuning, we pick the best checkpoint based on the development set scores. Further details of configurations are available in our code repository.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Leaderboard Results</head><p>The official metric of Checkthat! 2022 check-worthiness was F1 score (positive class) for all languages. Table 5 lists our results. Arabic, Bulgarian, Dutch and Spanish performed the best with 0.628, 0.617, 0.642 and 0.571, respectively. It was followed by Turkish (0.173) as the second and English(0.519) as the eighth. <ref type="foot" coords="6,233.80,501.10,4.06,7.79" target="#foot_3">4</ref> We note in the last row of Table <ref type="table" coords="6,387.30,503.78,3.74,9.74" target="#tab_4">5</ref>, that though we rank the second, our F1 score is low.</p><p>Considering that our model achieved an F1 score of 0.498 on the dev-test split (Table <ref type="table" coords="6,479.55,530.88,3.58,9.74" target="#tab_2">3</ref>), we conjecture that the test data distribution is slightly different from that in the data shared as part of the competition and used to train and fine-tune models (train/dev/dev-test splits). Indeed, as indicated on the leaderboard all the participating systems attain low test performance on the Turkish language with the system that ranked first obtaining an F1 score of 0.212 compared to our 0.173. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Ablation Study</head><p>We consider the following tasks in the ablation study: check-worthiness of tweets(CW), verifiable factual claims detection(FC), harmful tweet detection(HD), attention-worthy tweet detection(AD), English translation(ET), tweet favorite count(TF) and tweet retweet count(TR). Table <ref type="table" coords="7,126.01,437.33,4.97,9.74">6</ref> shows the result of the ablation study using F1 scores on the dev-test splits provided as part of the competition. Compared to single-task learning models (first row), multitask learning results in improved performance for all six languages. In particular, comparing rows 1 and</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we introduced CheckthaT5, a novel pipeline for verifying multilingual fact checkworthiness. It can capture check-worthy content from the information torrent of social media. Empirically, CheckthaT5 effectively acquires language-independent knowledge through the multitask learning paradigm, which supports our system on the top of most language tracks in CLEF Checkthat! 2022 Task 1A.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,90.67,293.50,257.09"><head>Table 1</head><label>1</label><figDesc>The label distribution of Checkthat! 2022 Task 1A datasets</figDesc><table coords="3,212.78,118.87,169.71,228.88"><row><cell cols="2">language split</cell><cell>yes</cell><cell>no</cell><cell>total</cell></row><row><cell></cell><cell>train</cell><cell cols="3">962 1,551 2,513</cell></row><row><cell>Arabic</cell><cell>dev</cell><cell>100</cell><cell>135</cell><cell>235</cell></row><row><cell></cell><cell>test</cell><cell>266</cell><cell>425</cell><cell>691</cell></row><row><cell></cell><cell>train</cell><cell cols="3">378 1,493 1,871</cell></row><row><cell>Bulgarian</cell><cell>dev</cell><cell>36</cell><cell>142</cell><cell>178</cell></row><row><cell></cell><cell>test</cell><cell>106</cell><cell>413</cell><cell>519</cell></row><row><cell></cell><cell>train</cell><cell>377</cell><cell>546</cell><cell>923</cell></row><row><cell>Dutch</cell><cell>dev</cell><cell>28</cell><cell>44</cell><cell>72</cell></row><row><cell></cell><cell>test</cell><cell>102</cell><cell>150</cell><cell>252</cell></row><row><cell></cell><cell>train</cell><cell cols="3">447 1,675 2,122</cell></row><row><cell>English</cell><cell>dev</cell><cell>44</cell><cell>151</cell><cell>195</cell></row><row><cell></cell><cell>test</cell><cell>129</cell><cell>447</cell><cell>576</cell></row><row><cell></cell><cell cols="4">train 1,903 3,087 4,990</cell></row><row><cell>Spanish</cell><cell>dev</cell><cell cols="3">305 2,195 2,500</cell></row><row><cell></cell><cell>test</cell><cell cols="3">305 2,195 2,500</cell></row><row><cell></cell><cell>train</cell><cell cols="3">423 1,994 2,417</cell></row><row><cell>Turkish</cell><cell>dev</cell><cell>45</cell><cell>177</cell><cell>222</cell></row><row><cell></cell><cell>test</cell><cell>114</cell><cell>546</cell><cell>660</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,88.99,370.11,416.99,79.59"><head>Table 2 Model</head><label>2</label><figDesc></figDesc><table coords="3,141.83,428.83,307.64,20.86"><row><cell>with links</cell><cell>0.582</cell><cell>0.680</cell><cell>0.706</cell><cell>0.643</cell><cell>0.576</cell><cell>0.462</cell></row><row><cell cols="2">without links 0.599</cell><cell>0.711</cell><cell>0.700</cell><cell>0.682</cell><cell>0.635</cell><cell>0.498</cell></row></table><note coords="3,117.24,382.06,388.74,8.91;3,89.29,394.02,94.13,8.91;3,142.61,411.40,310.83,8.91"><p>performance difference (positive class F1) on the development split between models training with links and without links Link settings Arabic Bulgarian Dutch English Spanish Turkish</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,88.99,90.67,378.64,93.78"><head>Table 3</head><label>3</label><figDesc>Positive class F1 score comparison of our model and baseline models on the test split</figDesc><table coords="4,127.64,122.24,340.00,62.21"><row><cell>Language</cell><cell cols="6">Arabic Bulgarian Dutch English Spanish Turkish</cell></row><row><cell>Random</cell><cell>0.342</cell><cell>0.261</cell><cell>0.421</cell><cell>0.242</cell><cell>0.139</cell><cell>0.268</cell></row><row><cell>N-gram</cell><cell>0.378</cell><cell>0.377</cell><cell>0.531</cell><cell>0.515</cell><cell>0.489</cell><cell>0.148</cell></row><row><cell cols="2">XLM-RoBerta-Large 0.561</cell><cell>0.674</cell><cell>0.670</cell><cell>0.689</cell><cell>0.639</cell><cell>0.477</cell></row><row><cell>CheckthaT5(ours)</cell><cell>0.610</cell><cell>0.711</cell><cell>0.721</cell><cell>0.682</cell><cell>0.642</cell><cell>0.498</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,88.98,90.67,362.03,129.67"><head>Table 4</head><label>4</label><figDesc>Auxiliary tasks and their corresponding prompts</figDesc><table coords="6,144.26,122.26,306.76,98.07"><row><cell>Task</cell><cell>Type</cell><cell>Prompt</cell></row><row><cell>Check-worthiness of tweets (CW)</cell><cell cols="2">Classification checkworthy</cell></row><row><cell cols="3">Verifiable factual claims detection (FC) Classification claim</cell></row><row><cell>Harmful tweet detection (HD)</cell><cell cols="2">Classification harmful</cell></row><row><cell cols="3">Attention-worthy tweet detection (AD) Classification attentionworthy</cell></row><row><cell>English translation (ET)</cell><cell cols="2">Classification backtranslate</cell></row><row><cell>Tweet favorite count (TF)</cell><cell>Regression</cell><cell>favorite</cell></row><row><cell>Tweet retweet count (TR)</cell><cell>Regression</cell><cell>retweet</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,88.99,90.67,389.01,257.73"><head>Table 5</head><label>5</label><figDesc>CheckthaT5 results from Checkthat! 2022 Task 1A public leaderboard</figDesc><table coords="7,88.99,122.24,389.01,226.15"><row><cell></cell><cell cols="3">language F1</cell><cell>Rank</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Arabic</cell><cell></cell><cell cols="2">0.628 1-st</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">Bulgarian 0.617 1-st</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Dutch</cell><cell></cell><cell cols="2">0.642 1-st</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">English</cell><cell cols="2">0.519 8-th</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Spanish</cell><cell cols="2">0.571 1-st</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Turkish</cell><cell cols="2">0.173 2-nd</cell><cell></cell><cell></cell></row><row><cell>Table 6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">Multitask learning ablation study using F1 scores on the development-test splits</cell></row><row><cell>Language</cell><cell cols="7">Arabic Bulgarian Dutch English Spanish Turkish</cell></row><row><cell>CW</cell><cell>0.582</cell><cell>0.680</cell><cell></cell><cell>0.706</cell><cell>0.643</cell><cell>0.576</cell><cell>0.462</cell></row><row><cell>CW + ET</cell><cell>0.607</cell><cell>0.675</cell><cell></cell><cell>0.701</cell><cell>0.663</cell><cell>0.637</cell><cell>0.489</cell></row><row><cell>CW + ET + TF</cell><cell>0.601</cell><cell>0.700</cell><cell></cell><cell>0.712</cell><cell>0.659</cell><cell>0.642</cell><cell>0.477</cell></row><row><cell>CW + ET + AD</cell><cell>0.600</cell><cell>0.709</cell><cell></cell><cell>0.710</cell><cell>0.665</cell><cell>0.618</cell><cell>0.491</cell></row><row><cell>CW + ET + FC + AD</cell><cell>0.596</cell><cell>0.698</cell><cell></cell><cell>0.704</cell><cell>0.656</cell><cell>0.605</cell><cell>0.494</cell></row><row><cell cols="2">CW + ET + FC + AD + TF 0.600</cell><cell>0.711</cell><cell></cell><cell cols="2">0.721 0.682</cell><cell>0.635</cell><cell>0.498</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,92.46,671.93,178.74,8.01"><p>https://sites.google.com/view/clef2022-checkthat</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,92.46,671.94,344.18,8.01"><p>Pre-processed data can be downloaded from https://huggingface.co/datasets/Elfsong/clef_data</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="6,92.46,660.91,178.11,8.01"><p>Model link https://huggingface.co/google/mt5-xl</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="6,92.46,671.87,236.07,8.01"><p>The public leaderboard can be found in http://shorturl.at/nuCOS</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_4" coords="7,97.19,477.97,408.79,9.74;7,89.29,491.52,416.69,9.74;7,89.29,505.07,416.69,9.74;7,89.29,518.62,217.11,9.74"><p>in the table, the English translation tasks 4.2 enable the model to obtain a significant score improvement in Arabic, English, Spanish and English. In addition, we found that appending the task of predicting the number of Twitter likes further improved the F1 score demonstrating the effectiveness of the multitask learning paradigm.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research is supported by <rs type="funder">CTIC</rs>, <rs type="funder">NUS</rs> grant number: <rs type="grantNumber">A-0003503-05-00</rs>. Additionally, we would like to thank <rs type="institution">Google</rs> for computational resources in the form of Google Cloud credits and <rs type="institution">Google TPU Research Cloud</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_du9YzC5">
					<idno type="grant-number">A-0003503-05-00</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,102.92,547.09,87.93,10.69;7,88.91,568.35,417.27,9.74;7,89.29,581.90,416.69,9.74;7,89.29,595.45,416.69,9.74;7,89.29,609.00,418.53,9.74;7,89.29,622.55,416.69,9.74;7,89.29,636.09,153.11,9.74;8,89.29,284.40,71.57,12.83" xml:id="b0">
	<monogr>
		<title level="m" coord="7,113.44,547.09,77.41,10.69;7,88.91,568.35,417.27,9.74;7,89.29,581.90,89.13,9.74">Error Analysis Although our model achieves good performance on low-resource languages and best on four out of six languages</title>
		<imprint/>
	</monogr>
	<note>namely Arabic, Bulgarian, Dutch and Spanish, it performs mediocre on the English dataset. We speculate that one possible reason for the lower performance on English is that we feed all language datasets into a single model, which makes the model more languageagnostic, but also loses certain language-specific information. We will explore an opportune trade-off point in further research. References</note>
</biblStruct>

<biblStruct coords="8,112.66,310.95,394.53,9.74;8,112.66,324.50,393.32,9.74;8,112.66,338.05,126.33,9.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,112.66,324.50,283.84,9.74">Misinformation of covid-19 on the internet: infodemiology study</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Y</forename><surname>Cuan-Baltazar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Mu√±oz-Perez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Robledo-Vega</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>P√©rez-Zepeda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Soto-Vega</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,404.81,324.50,101.17,9.74;8,112.66,338.05,53.64,9.74">JMIR public health and surveillance</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">18444</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,351.60,393.31,9.74;8,112.66,365.15,393.32,9.74;8,112.66,378.70,394.82,9.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,305.06,351.60,200.91,9.74;8,112.66,365.15,194.70,9.74">Toward automated fact-checking: Detecting check-worthy factual claims by claimbuster</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tremayne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,331.13,365.15,174.85,9.74;8,112.66,378.70,297.77,9.74">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1803" to="1812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,392.25,393.53,9.74;8,112.66,405.79,317.13,9.74" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05355</idno>
		<title level="m" coord="8,367.93,392.25,138.26,9.74;8,112.66,405.79,135.31,9.74">Fever: a large-scale dataset for fact extraction and verification</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,419.34,394.52,9.74;8,112.28,432.89,393.70,9.74;8,112.66,446.44,233.34,9.74" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Aly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Cocarascu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.05707</idno>
		<title level="m" coord="8,160.83,432.89,345.16,9.74;8,112.66,446.44,50.99,9.74">Feverous: Fact extraction and verification over unstructured and structured information</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,459.99,393.53,9.74;8,112.66,473.54,330.04,9.74" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.14974</idno>
		<title level="m" coord="8,474.46,459.99,31.72,9.74;8,112.66,473.54,147.93,9.74">Fact or fiction: Verifying scientific claims</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,487.09,393.33,9.74;8,112.66,500.64,395.16,9.74;8,112.66,514.19,394.61,9.74;8,112.66,527.74,146.92,9.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,259.84,487.09,246.15,9.74;8,112.66,500.64,59.33,9.74">Improving evidence retrieval for automated explainable fact-checking</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Samarinas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,200.98,500.64,306.84,9.74;8,112.66,514.19,394.61,9.74;8,112.66,527.74,68.85,9.74">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="84" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,541.29,393.32,9.74;8,112.66,554.84,208.48,9.74" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ostrowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Augenstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.06401</idno>
		<title level="m" coord="8,349.29,541.29,156.69,9.74;8,112.66,554.84,26.37,9.74">Multi-hop fact checking of political claims</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,568.38,393.32,9.74;8,112.66,581.93,300.69,9.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,277.20,568.38,163.78,9.74">A survey on automated fact-checking</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,449.33,568.38,56.66,9.74;8,112.66,581.93,216.75,9.74">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="178" to="206" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,595.48,393.33,9.74;8,112.66,609.03,393.97,9.74;8,112.41,622.58,32.84,9.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,314.26,595.48,191.72,9.74;8,112.66,609.03,219.31,9.74">Systematic literature review on the spread of health-related misinformation on social media</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mckee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Torbica</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Stuckler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,341.07,609.03,117.17,9.74">Social science &amp; medicine</title>
		<imprint>
			<biblScope unit="volume">240</biblScope>
			<biblScope unit="page">112552</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,636.13,394.54,9.74;8,112.66,649.68,393.32,9.74;9,112.66,88.09,394.53,9.74;9,112.66,101.64,22.69,9.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,274.46,649.68,231.51,9.74;9,112.66,88.09,266.50,9.74">Overview of the clef-2021 checkthat! lab task 1 on check-worthiness estimation in tweets and political debates</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Martino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,402.81,88.09,99.84,9.74">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,115.19,395.16,9.74;9,112.66,128.74,393.33,9.74;9,112.66,142.29,107.17,9.74" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11934</idno>
		<title level="m" coord="9,488.99,115.19,18.83,9.74;9,112.66,128.74,318.78,9.74">Raffel, mt5: A massively multilingual pre-trained text-to-text transformer</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,155.84,394.52,9.74;9,112.33,169.38,394.86,9.74;9,112.66,182.93,393.32,9.74;9,112.66,196.48,394.52,9.74;9,112.66,210.03,394.52,9.74;9,112.66,223.58,393.32,9.74;9,112.66,237.13,393.32,9.74;9,112.66,250.68,366.90,9.74" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,431.99,182.93,73.99,9.74;9,112.66,196.48,390.20,9.74">Overview of the CLEF-2022 CheckThat! lab on fighting the COVID-19 infodemic and fake news detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barr√≥n-Cede√±o</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Stru√ü</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>M√≠guez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beltr√°n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>K√∂hler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,397.65,223.58,108.32,9.74;9,112.66,237.13,393.32,9.74;9,112.66,250.68,270.79,9.74">Proceedings of the 13th International Conference of the CLEF Association: Information Access Evaluation meets Multilinguality, Multimodality, and Visualization, CLEF &apos;2022</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Barr√≥n-Cede√±o</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Degli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Esposti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Sebastiani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Pasi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><surname>Nicola</surname></persName>
		</editor>
		<meeting>the 13th International Conference of the CLEF Association: Information Access Evaluation meets Multilinguality, Multimodality, and Visualization, CLEF &apos;2022<address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,264.23,394.52,9.74;9,112.33,277.78,394.86,9.74;9,112.66,291.33,393.32,9.74;9,112.66,304.88,394.52,9.74;9,112.66,318.43,393.53,9.74;9,112.66,331.98,225.54,9.74" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,284.01,291.33,221.97,9.74;9,112.66,304.88,197.93,9.74">The CLEF-2022 CheckThat! Lab on fighting the covid-19 infodemic and fake news detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barr√≥n-Cede√±o</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Stru√ü</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>M√≠guez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beltr√°n</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,313.53,318.43,148.40,9.74">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Hagen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Verberne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Seifert</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>N√∏rv√•g</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Setty</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="416" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,345.52,394.52,9.74;9,112.14,359.07,394.25,9.74;9,112.66,372.62,394.61,9.74;9,112.66,386.17,393.59,9.74;9,112.66,399.72,382.34,9.74" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,462.24,359.07,44.15,9.74;9,112.66,372.62,371.46,9.74">Overview of the CLEF-2022 CheckThat! lab task 1 on identifying relevant claims in tweets</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barr√≥n-Cede√±o</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>M√≠guez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beltr√°n</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,402.72,386.17,103.52,9.74;9,112.66,399.72,286.23,9.74">Working Notes of CLEF 2022-Conference and Labs of the Evaluation Forum, CLEF &apos;2022</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Guglielmo Andd Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><surname>Potthast</surname></persName>
		</editor>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,413.27,393.59,9.74;9,112.66,426.82,146.44,9.74" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="9,206.54,413.27,266.67,9.74">Universal language model fine-tuning for text classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.06146</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,440.37,395.17,9.74;9,112.66,453.92,282.15,9.74" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.05987</idno>
		<title level="m" coord="9,269.49,440.37,238.34,9.74;9,112.66,453.92,100.28,9.74">To tune or not to tune? adapting pretrained representations to diverse tasks</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,467.47,394.52,9.74;9,112.66,481.02,394.61,9.74;9,112.66,494.57,394.61,9.74;9,112.66,508.11,178.59,9.74" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,213.52,481.02,270.29,9.74">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,112.66,494.57,394.61,9.74;9,112.66,508.11,100.66,9.74">Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations</title>
		<meeting>the 2020 conference on empirical methods in natural language processing: system demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,521.66,394.61,9.74;9,112.66,535.21,298.25,9.74" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="9,358.76,521.66,148.50,9.74;9,112.66,535.21,107.12,9.74">Data imbalance in classification: Experimental evaluation</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Thabtah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hammoud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kamalov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gonsalves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,228.16,535.21,93.74,9.74">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">513</biblScope>
			<biblScope unit="page" from="429" to="441" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,548.76,395.17,9.74;9,112.66,562.31,393.32,9.74;9,112.33,575.86,29.19,9.74" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">B</forename><surname>Schlicht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F M</forename><surname>De Paula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.09232</idno>
		<title level="m" coord="9,290.24,548.76,217.59,9.74;9,112.66,562.31,243.09,9.74">Upv at checkthat! 2021: Mitigating cultural differences for identifying multilingual check-worthy claims</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,589.41,394.53,9.74;9,112.30,602.96,393.69,9.74;9,112.66,616.51,107.17,9.74" xml:id="b20">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="9,173.37,602.96,257.07,9.74">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,630.06,393.32,9.74;9,112.66,643.61,96.31,9.74" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="9,190.94,630.06,247.94,9.74">Support vector machines for classification and regression</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Gunn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,447.04,630.06,58.94,9.74;9,112.66,643.61,27.59,9.74">ISIS technical report</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="5" to="16" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,657.16,393.70,9.74;9,112.66,670.70,393.33,9.74;10,112.66,88.09,83.75,9.74" xml:id="b22">
	<monogr>
		<title level="m" type="main" coord="9,338.23,657.16,168.13,9.74;9,112.66,670.70,393.33,9.74;10,112.66,88.09,47.16,9.74">Nlp&amp;ir@ uned at checkthat! 2020: A preliminary approach for check-worthiness and claim retrieval tasks using neural networks and graphs</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Martinez-Rico</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Martinez-Romo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,101.64,393.32,9.74;10,112.66,115.19,373.43,9.74" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="10,219.64,101.64,286.34,9.74;10,112.66,115.19,242.77,9.74">Evolutionteam at checkthat! 2020: integration of linguistic and sentimental features in a fake news detection approach</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Touahri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mazroui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,364.21,115.19,73.85,9.74">Cappellato et al</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,128.74,393.32,9.74;10,112.39,142.29,230.07,9.74" xml:id="b24">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<title level="m" coord="10,298.67,128.74,207.31,9.74;10,112.39,142.29,52.97,9.74">Efficient estimation of word representations in vector space</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,155.84,394.61,9.74;10,112.66,169.38,393.32,9.74;10,112.33,182.93,136.87,9.74" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="10,290.37,155.84,197.87,9.74">Glove: Global vectors for word representation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,112.66,169.38,393.32,9.74;10,112.33,182.93,37.99,9.74">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,196.48,394.53,9.74;10,112.66,210.03,393.32,9.74;10,112.66,223.58,201.68,9.74" xml:id="b26">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Guzm√°n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.02116</idno>
		<title level="m" coord="10,271.56,210.03,234.42,9.74;10,112.66,223.58,19.96,9.74">Unsupervised cross-lingual representation learning at scale</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,237.13,394.53,9.74;10,112.66,250.68,22.69,9.74" xml:id="b27">
	<monogr>
		<title level="m" type="main" coord="10,169.23,237.13,333.53,9.74">Rosetta: A high performance translation tool powered by Google Translate</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mingzhe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,264.23,393.33,9.74;10,112.66,277.78,209.60,9.74" xml:id="b28">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08691</idno>
		<title level="m" coord="10,275.36,264.23,230.62,9.74;10,112.66,277.78,27.32,9.74">The power of scale for parameter-efficient prompt tuning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
