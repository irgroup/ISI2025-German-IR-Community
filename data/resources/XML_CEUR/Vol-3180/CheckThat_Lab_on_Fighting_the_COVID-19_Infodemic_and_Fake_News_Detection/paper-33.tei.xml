<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,416.61,15.42;1,89.29,106.66,164.94,15.42">CIC at CheckThat! 2022: Multi-class and Cross-lingual Fake News Detection</title>
				<funder ref="#_UckSHnT #_fNJApTu #_zUVsHMn">
					<orgName type="full">CONACYT, Mexico</orgName>
				</funder>
				<funder ref="#_6eTmWW3">
					<orgName type="full">Secretaría de Figure 5</orgName>
				</funder>
				<funder ref="#_GGzqcPz">
					<orgName type="full">Mexican Government</orgName>
				</funder>
				<funder ref="#_q22Fr6J">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,81.37,11.96"><forename type="first">Muhammad</forename><surname>Arif</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centro de Investigación en Computación (CIC)</orgName>
								<orgName type="institution">Instituto Politécnico Nacional (IPN)</orgName>
								<address>
									<addrLine>Av. Juan de Dios Batiz, s/n</addrLine>
									<postCode>07320</postCode>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,183.30,134.97,81.69,11.96"><forename type="first">Atnafu</forename><surname>Lambebo</surname></persName>
							<email>atnafu.lambebo@wsu.edu.</email>
							<affiliation key="aff0">
								<orgName type="department">Centro de Investigación en Computación (CIC)</orgName>
								<orgName type="institution">Instituto Politécnico Nacional (IPN)</orgName>
								<address>
									<addrLine>Av. Juan de Dios Batiz, s/n</addrLine>
									<postCode>07320</postCode>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,308.23,134.97,55.44,11.96"><forename type="first">Iqra</forename><surname>Ameer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centro de Investigación en Computación (CIC)</orgName>
								<orgName type="institution">Instituto Politécnico Nacional (IPN)</orgName>
								<address>
									<addrLine>Av. Juan de Dios Batiz, s/n</addrLine>
									<postCode>07320</postCode>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,376.31,134.97,85.73,11.96"><forename type="first">Olga</forename><surname>Kolesnikova</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centro de Investigación en Computación (CIC)</orgName>
								<orgName type="institution">Instituto Politécnico Nacional (IPN)</orgName>
								<address>
									<addrLine>Av. Juan de Dios Batiz, s/n</addrLine>
									<postCode>07320</postCode>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,88.87,148.92,94.84,11.96"><forename type="first">Alexander</forename><surname>Gelbukh</surname></persName>
							<email>gelbukh@cic.ipn.mx</email>
							<affiliation key="aff0">
								<orgName type="department">Centro de Investigación en Computación (CIC)</orgName>
								<orgName type="institution">Instituto Politécnico Nacional (IPN)</orgName>
								<address>
									<addrLine>Av. Juan de Dios Batiz, s/n</addrLine>
									<postCode>07320</postCode>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,196.36,148.92,75.90,11.96"><forename type="first">Grigori</forename><surname>Sidorov</surname></persName>
							<email>sidorov@cic.ipn.mx</email>
							<affiliation key="aff0">
								<orgName type="department">Centro de Investigación en Computación (CIC)</orgName>
								<orgName type="institution">Instituto Politécnico Nacional (IPN)</orgName>
								<address>
									<addrLine>Av. Juan de Dios Batiz, s/n</addrLine>
									<postCode>07320</postCode>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,303.26,148.92,60.13,11.96"><forename type="first">Abdul</forename><surname>Gafar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centro de Investigación en Computación (CIC)</orgName>
								<orgName type="institution">Instituto Politécnico Nacional (IPN)</orgName>
								<address>
									<addrLine>Av. Juan de Dios Batiz, s/n</addrLine>
									<postCode>07320</postCode>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,366.38,148.92,72.97,11.96"><forename type="first">Manuel</forename><surname>Meque</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centro de Investigación en Computación (CIC)</orgName>
								<orgName type="institution">Instituto Politécnico Nacional (IPN)</orgName>
								<address>
									<addrLine>Av. Juan de Dios Batiz, s/n</addrLine>
									<postCode>07320</postCode>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,416.61,15.42;1,89.29,106.66,164.94,15.42">CIC at CheckThat! 2022: Multi-class and Cross-lingual Fake News Detection</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">7F6AD75A4593B8ED1990A298209B31C0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Fake news detection</term>
					<term>Cross-lingual classification</term>
					<term>Multi-class detection</term>
					<term>Fake news detection for low resource languages</term>
					<term>Transfer learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Nowadays, social media is one widely used platform to access information. Fake news on social media and various other media is widely spreading. It is a matter of serious concern due to its ability to cause a lot of social and national damage with destructive impacts. Therefore, detecting misleading news is critical to detect automatically. Fake news detection software has been used in a variety of fields, such as social media, health, political news, etc. This paper presents the Instituto Politécnico Nacional (Mexico) at CheckThat! 2022. In this paper, we discuss using different algorithms for the multiclass and cross-lingual fake news detection task. We achieved a macro F1-score of 28.60% for a mono-lingual task in English (task 3a) using RoBERTa pre-trained model and 17.21% for a cross-lingual task for English and German (task 3b) using Bi-LSTM deep learning algorithm.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Fake news refers to falsified news or propaganda that is disseminated through traditional media platforms such as print and television, as well as non-traditional media platforms such as social media <ref type="bibr" coords="1,118.52,453.50,11.28,10.91" target="#b0">[1]</ref>. The primary objective of disseminating such information is to deceive readers, harm a company's reputation, or profit from sensationalism. It is widely regarded as one of the most serious threats to democracy, free speech, and social order <ref type="bibr" coords="1,362.30,480.60,11.59,10.91" target="#b1">[2]</ref>. Fake news is rapidly being disseminated through social media platforms such as Twitter and Facebook, according to <ref type="bibr" coords="1,492.30,494.15,11.53,10.91" target="#b2">[3]</ref>. These platforms provide a venue for the general public to express their thoughts and opinions in an unfiltered and uncensored manner. Compared to conventional method views from media publishers' platforms, some news pieces hosted or shared on social media sites receive more views. According to researchers who researched the speed with which fake news spreads on Twitter, tweets containing misleading information reach individuals six times faster than factual tweets <ref type="bibr" coords="2,121.50,86.97,11.54,10.91" target="#b1">[2]</ref>. The negative consequences of false news appear to be unavoidable, ranging from making people believe Hillary Clinton had an alien baby to affecting the 2016 US presidential elections <ref type="bibr" coords="2,131.47,114.06,11.43,10.91" target="#b2">[3]</ref>. A few facts about fake news in the United States are as follows:</p><p>• 62% of Americans get their news from social media <ref type="bibr" coords="2,346.92,138.41,12.84,10.91" target="#b3">[4]</ref> • Fake news had a higher Facebook share than legitimate news <ref type="bibr" coords="2,391.89,153.03,12.84,10.91" target="#b4">[5]</ref> Another interesting, however, a sad example is a false statement claiming that "alcohol is a cure for COVID-19" caused multiple deaths and hospitalizations in Iran, according to <ref type="bibr" coords="2,468.10,191.09,11.39,10.91" target="#b5">[6]</ref>. This shows how helpless we are against fake news in some critical situations and how severe the consequences can be if we ignore them. The first step in dealing with fake news is recognizing and distinguishing it from real news.</p><p>Detecting fake information on social media poses numerous new and challenging research problems. Although fake news itself isn't a new problem-nations or groups have been using the news media to execute propaganda or affect operations for centuries-the rise of web-generated news on social media makes fake news a more powerful force that challenges traditional journalistic norms. There are numerous traits of this hassle that make it uniquely challenging for automatic detection <ref type="bibr" coords="2,195.11,313.03,11.35,10.91" target="#b6">[7]</ref>. In this paper, we propose a methodology to trained the model that detects whether an article is authentic or fake based on its words, phrases, sources, and titles. It will apply supervised machine learning algorithms on an annotated (labeled) dataset and for automatic fake news detection.</p><p>We used three models: Passive Aggressive Classifier (PAC), a machine learning algorithm; Bi-LSTM, a deep learning algorithm; and RoBERTa a pre-trained language model from the BERT family for fine-tuning. Then, according to confusion matrix results, feature selection methods are applied to experiment and choose the best-fit features to obtain the highest precision. We propose to create the model using different classification algorithms. The product model will test the unseen data, the results will be plotted, and accordingly, the product will be a model that detects and classifies fake articles and can be used and integrated with any system for future use. <ref type="bibr" coords="2,135.51,462.07,12.17,10.91" target="#b7">[8]</ref>.</p><p>This paper discusses multi-class and cross-lingual fake news detection methods for the shared task at CheckThat!2022. The paper is organized as follows: section 2 describes the past work related to this study, section 3 gives an overview of the dataset statistics, section 4 explains the methodology adopted in this study including used algorithms, section 5 emphasizes on the experimental results and description. Finally, section 6 concludes the paper and sheds some light on possible future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Faking a piece of news has been part of all eras of technology in the form of yellow journalism. However, since the advent of social media, the impact of the harm has grown many folds. It has hence been one of the most challenging problems for researchers to solve for the last decade as it is very difficult to distinguish fake text from real text <ref type="bibr" coords="2,360.28,642.48,11.48,10.91" target="#b8">[9,</ref><ref type="bibr" coords="2,375.08,642.48,12.59,10.91" target="#b9">10,</ref><ref type="bibr" coords="2,391.00,642.48,12.42,10.91" target="#b10">11]</ref>. Fake news detection approaches, by and large, fall into two classes relying upon whether they use (1) news content or (2) social settings <ref type="bibr" coords="2,180.08,669.58,11.31,10.91" target="#b6">[7]</ref>. Theoretical fake news studies have examined the classification of fake news in the form of misinformation, disinformation, hysteria, falsehood, propaganda, clickbait, and conspiracy theories. The last decade has evidenced considerable advances in research on fake news that has had a real-life impact.</p><p>With the emergence of larger datasets, the research on fake news detection got into force when numerous studies arose in 2017. Among the first, Wang <ref type="bibr" coords="3,357.44,141.16,17.76,10.91" target="#b11">[12]</ref> introduced LIAR -a relatively large dataset of 12, 000 truth-checked and multi-class labeled short news statements from the political area. To this novel data, he applied various algorithms and deep learning architectures such as Support Vector Machines(SVM), Logistic Regression, Bi-LSTM, and Convolutional Neural Network (CNN).</p><p>The domain of automated fake news detection and fake news classification across languages was not studied in depth in previous research. Though <ref type="bibr" coords="3,342.14,222.46,18.06,10.91" target="#b12">[13]</ref> trained their models with news texts from one language to classify them in another, their approach relied on prior machine translation as a pre-processing step. The lack of cross-language classification studies in fake news detection was due to the absence of appropriate data. Yet, recently <ref type="bibr" coords="3,430.52,263.11,18.37,10.91" target="#b13">[14]</ref> presented a multilingual dataset that offers a possibility to study transfer learning in fake news classification. Utilizing the embedding of XLM-R without fine-tuning the model, the authors reported accuracy of 82% for transfer classification from Italian to French. As their overall results show room for improvement, this study aims to extend the proposed model further to gain valuable insights from transfer learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Dataset</head><p>In the experimentation phase, we used the dataset for task 3 from shared task organizers <ref type="bibr" coords="3,472.76,389.48,16.31,10.91" target="#b14">[15,</ref><ref type="bibr" coords="3,491.36,389.48,12.23,10.91" target="#b15">16]</ref>. The dataset contains train, validation, and test sets for English and test data for the German language. The training data includes about 1, 300 articles in English with the respective labels such as true, partially false, false, or other <ref type="bibr" coords="3,277.52,430.13,16.25,10.91" target="#b16">[17]</ref>. The features are as follows:</p><p>• ID is a unique identifier to identify each instance uniquely.</p><p>• Text is the content of the news.</p><p>• Title is the headlines of the news.</p><p>• Label is the class assigned to the instance as true, partially false, false, or other.</p><p>The "partially false" label is associated with articles that contain partially true and partially false information but cannot be considered 100% true. While the "other" label is assigned to articles that cannot be categorized as true, false, or partially false due to the lack of evidence about their claims.</p><p>Figure <ref type="figure" coords="3,130.96,580.04,5.02,10.91" target="#fig_0">1</ref> shows training and validation dataset statistics and the imbalance between the four classes in both the training and validation dataset. The training dataset is slightly imbalanced 46% of the texts labeled as false, 28% were labelled as partially false, 17% were labelled as true, and 9% were labelled as other. This shows that approximately half of the training dataset was labelled as false, and approximately one-third was labelled as partially false. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methodology</head><p>For fake news detection, we used three models: Passive Aggressive Classifier (PAC), a machine learning algorithm; Bi-LSTM, a deep learning algorithm; and RoBERTa <ref type="bibr" coords="4,424.09,310.97,18.07,10.91" target="#b17">[18]</ref> a pre-trained language model from the BERT family for fine-tuning. For task 3a, we used the English training dataset that contains four labels to train the model with three different algorithms. We used the English test dataset to test the models' performance. For task 3b, we used the English dataset to train the models and then tested them on the German test dataset to evaluate cross-lingual performance. F1-score was used to measure the models' efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data pre-processing</head><p>Data pre-processing is one of the important steps in natural language processing (NLP) tasks. We performed the following data pre-processing in order to prepare the data for training. We performed several pre-processing steps, including removing unwanted characters, stop word removal, as well as converting labels to integers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Algorithms</head><p>In this section, we discuss algorithms used in this paper: passive aggressive classifier, a machine learning algorithm, Bi-LSTM, a deep learning algorithm, and RoBERTa, a pre-trained language model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Passive Aggressive Classifier</head><p>Passive aggressive classification (PAC) is an online learning classifier that is used in cases where there is a need to keep a 24 × 7 check on the data like news, social media, etc. <ref type="bibr" coords="4,450.74,608.80,16.41,10.91" target="#b18">[19]</ref>. PAC is a noteworthy classifier among the online learning algorithms. The classification function is updated if there is a misclassification in newly seen data or if a predetermined margin is not exceeded by its classification score <ref type="bibr" coords="4,244.32,649.44,16.15,10.91" target="#b19">[20]</ref>. The input to PAC is a matrix of TF-IDF features. Thus, a model is formed while trained on the training data and then applied to the test set to evaluate its performance. We used the following parameters in training fake news detection using PAC, tfidf_vectorizer to transform text into vector, max_df=0.7, C=0.5, max_iter=50, random_state=5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Bi-LSTM</head><p>Deep learning models are widely used for linguistic modeling. Typical deep learning models such as Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) can detect complex patterns in textual data. Long Short-Term Memory (LSTM) is a tree-structured recurrent neural network used to analyze variable-length sequential data <ref type="bibr" coords="5,420.76,190.16,16.36,10.91" target="#b20">[21]</ref>. Bi-directional LSTM(Bi-LSTM) allows looking at a particular sequence both from front to back as well as from back to front. Long short-term memory (LSTM) is a structure that learns how much of the previous network state to apply when input data is received. By using the hidden state, information can flow in both directions. At each time step, the outputs of the two LSTMs are merged. This BiLSTM model helps remove the barriers of traditional RNNs. The BiLSTM provides excellent accuracy and makes the context much easier to understand.able 1 shows the parameters used for the Bi-LSTM model for our experiment. After pre-processing the text we used tokenizer function from Keras to tokenize the input and added padding to tokinized input. We converted tokenized input after padding to tensors using convert to tensor. To build BiLSTM model we used the keras library package. Our BiLSTM model contains embedding layer which is composed of vocab size of 34,172, embed units of 100, input length of 5,840, dropout layers, a fully connected layer with 256 neurons, binary cross entropy as loss function, adam as optimizer and relu activation. The model is trained using batch size of 32, 50 number of iteration and 0.0001 learning rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">RoBERTa</head><p>RoBERTa is a transformer model pre-trained on a large corpus of English data in a self-supervised fashion. RoBERTa is an optimized BERT model re-trained with improved training methodology, more data, and hardware resources proposed by <ref type="bibr" coords="5,314.36,656.03,16.42,10.91" target="#b17">[18]</ref>. RoBERTa without the next sentence prediction concept is similar to BERT and employs dynamic masking, which results in changing the masked token during the training epochs. RoBERTa is trained with dynamic masking , full-sentences without NSP (Next-Sentence Prediction) loss, large mini-batches and a larger byte-level BPE (Byte-Pair Encoding). Furthermore, RoBERTa is pre-trained on more data, longer sequences and with bigger batch sizes. Table <ref type="table" coords="6,293.94,127.61,5.16,10.91" target="#tab_1">2</ref> shows parameters used to train the RoBERTa model. The RoBERTa base model used for this paper was fine-tuned on a given fake news dataset. We used a "roberta-base" model from the Hugging Face library, which is already pre-trained. For both tasks we added batch normalization layer to speed up training, to make learning easier and a fully-connected output layer with a SoftMax function so that a probabilistic output of all labels for fake news detection would be produced. For both tasks we fine tuned the model using 20 number of iteration. For Task 3a, the model is fine-tuned and tested in English dataset while for Task 3b we used English dataset for fine tuning and tested the model with German test data without explicitly training in German dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Result and Discussion</head><p>Table <ref type="table" coords="6,117.48,485.79,5.17,10.91">3</ref> presents the Accuracy, Precision, Recall, and F1-scores obtained by applying the deep learning and transfer learning methods on the dataset provided by the organizers of the CheckThat! 2022 fake news detection shared task at CLEF 2022. In this table, "Task" refers to the monolingual task in English (Task 3a) and the cross-lingual task for English and German (Task 3b). The"Model" refers to deep learning and transfer learning-based models applied in this study.</p><p>As shown in Table <ref type="table" coords="6,185.09,567.09,5.05,10.91">3</ref> for Task 3a (multi-class fake news classification), fine-tuning RoBERTa model on the English dataset gives better results than using Bi-LSTM and PAC. This shows that languages with fewer resources can benefit from using pre-trained models. For Task 3b, cross-lingual fake news classification Bi-LSTM gives better results than RoBERTa and passive classifier by only testing the model on the German test dataset. This shows that monolingual pre-trained language models have lower performance on new languages if a large amount of dataset does not efficiently fine-tune them. Figure <ref type="figure" coords="6,316.51,648.38,5.14,10.91">2</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 3</head><p>Results for Task 3a and Task 3b using three different models observed that the validation loss is greater than the training loss after 20 epochs, and train accuracy is very high, but the validation accuracy is low and constant as we increase the number of epochs. This shows that the model is not predicting well on the validation data. It may indicate that the model is underfitting and depends on the size of the datasets. The latter is typical for deep learning algorithms. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Work</head><p>This paper discussed some classification models for detecting multi-class and cross-lingual fake news. RoBERTa pre-trained model performed well for the monolingual task compared  to other Bi-LSTM and PAC algorithms we applied in our experiments. We also observed that for cross-lingual fake news detection, Bi-LSTM performed well compared to RoBERTa. In the future, we will explore how increasing the amount of data will influence the performance of pre-trained models. We also suggest multilingual pre-trained models may improve cross-lingual fake news classification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,89.29,235.51,254.51,8.93;4,297.64,84.19,208.35,125.96"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Label distribution of training and validation dataset</figDesc><graphic coords="4,297.64,84.19,208.35,125.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,89.29,494.50,235.17,8.93;7,164.39,301.23,266.50,180.70"><head>Figure 2 :Figure 4</head><label>24</label><figDesc>Figure 2: BiLSTM train loss vs validation loss for Task 3b</figDesc><graphic coords="7,164.39,301.23,266.50,180.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,89.29,277.45,277.08,8.93;8,170.24,84.19,254.80,180.70"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: BiLSTM train accuracy vs validation accuracy for Task 3b</figDesc><graphic coords="8,170.24,84.19,254.80,180.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,89.29,497.57,229.21,8.93;8,172.19,304.30,250.90,180.70"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: RoBERTa train and validation loss for Task 3b</figDesc><graphic coords="8,172.19,304.30,250.90,180.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,88.99,313.30,284.64,169.67"><head>Table 1</head><label>1</label><figDesc>LSTM parameters used in model training</figDesc><table coords="5,219.15,341.34,154.49,141.63"><row><cell cols="2">Parameters used in Bi-LSTM</cell></row><row><cell>Parameters</cell><cell>Values</cell></row><row><cell>hidden_units</cell><cell>128</cell></row><row><cell>embed_units</cell><cell>100</cell></row><row><cell>Dropout</cell><cell>0.2</cell></row><row><cell>learning_rate</cell><cell>0.0001</cell></row><row><cell>optimizer</cell><cell>adam</cell></row><row><cell>batch_size</cell><cell>32</cell></row><row><cell>loss</cell><cell>binary cross entropy</cell></row><row><cell>num_itr</cell><cell>50</cell></row><row><cell>activation</cell><cell>sigmoid</cell></row><row><cell cols="2">Total params 3,717,745</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,88.99,167.72,273.20,145.76"><head>Table 2</head><label>2</label><figDesc>RoBERTa parameters used in model training</figDesc><table coords="6,230.59,195.76,131.60,117.72"><row><cell cols="2">Parameters used in RoBERTa</cell></row><row><cell>Parameters</cell><cell>Values</cell></row><row><cell>hidden_units</cell><cell>128</cell></row><row><cell>Dropout</cell><cell>0.1</cell></row><row><cell>learning_rate</cell><cell>0.0001</cell></row><row><cell>optimizer</cell><cell>adam</cell></row><row><cell>batch_size</cell><cell>32</cell></row><row><cell>num_itr</cell><cell>20</cell></row><row><cell>activation</cell><cell>softmax</cell></row><row><cell cols="2">Total params 125,798,148</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,89.29,648.38,416.70,24.46"><head></head><label></label><figDesc>and 3 shows the training loss, validation loss, as well as train and validation accuracy of the Bi-LSTM algorithm for task 3b. It can be</figDesc><table coords="7,158.74,86.37,277.79,81.44"><row><cell>Task</cell><cell>Model</cell><cell cols="4">Accuracy Precision Recall F1-score</cell></row><row><cell></cell><cell>PAC</cell><cell>0.51</cell><cell>0.29</cell><cell>0.25</cell><cell>0.2</cell></row><row><cell cols="3">Task 3a Bi-LSTM 0.52</cell><cell>0.13</cell><cell>0.25</cell><cell>0.17</cell></row><row><cell></cell><cell cols="2">RoBERTa 0.47</cell><cell>0.36</cell><cell>0.34</cell><cell>0.29</cell></row><row><cell></cell><cell>PAC</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="3">Task 3b Bi-LSTM 0.61</cell><cell>0.37</cell><cell>0.39</cell><cell>0.35</cell></row><row><cell></cell><cell cols="2">RoBERTa 0.28</cell><cell>0.13</cell><cell>0.26</cell><cell>0.17</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The work was done with partial support from the <rs type="funder">Mexican Government</rs> through the grant <rs type="grantNumber">A1S-47854</rs> of <rs type="funder">CONACYT, Mexico</rs>, grants <rs type="grantNumber">20220852</rs>, <rs type="grantNumber">20220859</rs>, and <rs type="grantNumber">20221627</rs> of the <rs type="funder">Secretaría de Figure 5</rs>: <rs type="projectName">RoBERTa</rs> train and validation accuracy for <rs type="projectName">Task 3b Investigación y Posgrado</rs> of the <rs type="institution">Instituto Politécnico Nacional, Mexico</rs>. The authors thank the <rs type="institution">CONACYT</rs> for the computing resources brought to them through the <rs type="institution">Plataforma de Aprendizaje Profundo para Tecnologías del Lenguaje of the Laboratorio de Supercómputo of the INAOE, Mexico</rs> and acknowledge the support of Microsoft through the <rs type="grantName">Microsoft Latin America PhD Award</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_GGzqcPz">
					<idno type="grant-number">A1S-47854</idno>
				</org>
				<org type="funding" xml:id="_UckSHnT">
					<idno type="grant-number">20220852</idno>
				</org>
				<org type="funding" xml:id="_fNJApTu">
					<idno type="grant-number">20220859</idno>
				</org>
				<org type="funding" xml:id="_zUVsHMn">
					<idno type="grant-number">20221627</idno>
				</org>
				<org type="funded-project" xml:id="_6eTmWW3">
					<orgName type="project" subtype="full">RoBERTa</orgName>
				</org>
				<org type="funded-project" xml:id="_q22Fr6J">
					<orgName type="grant-name">Microsoft Latin America PhD Award</orgName>
					<orgName type="project" subtype="full">Task 3b Investigación y Posgrado</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,112.66,427.88,394.53,10.91;9,112.66,441.43,169.28,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,298.87,427.88,203.54,10.91">Fake news detection: a deep learning approach</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Thota</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tilak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ahluwalia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Lohia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,112.66,441.43,116.68,10.91">SMU Data Science Review</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,454.98,394.53,10.91;9,112.66,468.52,110.31,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,161.01,454.98,342.04,10.91">Fake news spreads faster than true news on twitter-thanks to people, not bots</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Langin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,112.66,468.52,78.39,10.91">Science magazine</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,482.07,393.33,10.91;9,112.66,495.62,179.52,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,232.29,482.07,218.03,10.91">Social media and fake news in the 2016 election</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Allcott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gentzkow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,460.42,482.07,45.57,10.91;9,112.66,495.62,100.66,10.91">Journal of economic perspectives</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="211" to="236" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,509.17,123.56,10.91;9,264.44,509.17,242.75,10.91;9,112.66,522.72,394.04,10.91;9,112.33,536.27,29.19,10.91" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="9,264.44,509.17,210.63,10.91">News use across social media platforms</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gottfried</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Shearer</surname></persName>
		</author>
		<ptr target="http://www.journalism.org/2016/05/26/news-use-across-social-media-platforms-2016/" />
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,549.82,393.32,10.91;9,112.66,563.37,178.79,10.91" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="9,236.98,549.82,269.00,10.91;9,112.66,563.37,41.97,10.91">How teens in the balkans are duping trump supporters with fake news</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Silverman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Alexander</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-11-14">14 november, 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,576.92,393.33,10.91;9,112.66,590.47,88.00,10.91" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="9,214.40,576.92,291.58,10.91;9,112.66,590.47,58.44,10.91">Hundreds die of poisoning in iran as fake news suggests methanol cure for virus</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gambrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,604.02,393.33,10.91;9,112.66,617.57,337.29,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,303.46,604.02,202.53,10.91;9,112.66,617.57,83.30,10.91">Fake news detection on social media: A data mining perspective</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sliva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,204.32,617.57,171.84,10.91">ACM SIGKDD explorations newsletter</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="22" to="36" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,631.11,393.32,10.91;9,112.66,644.66,394.53,10.91;9,112.66,658.21,140.95,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,309.63,631.11,196.35,10.91;9,112.66,644.66,48.08,10.91">Fake news detection using machine learning approaches</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Khanam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Alwasel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sirafi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rashid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,184.09,644.66,257.17,10.91">IOP Conference Series: Materials Science and Engineering</title>
		<imprint>
			<publisher>IOP Publishing</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1099</biblScope>
			<biblScope unit="page">12040</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,86.97,394.53,10.91;10,112.66,100.52,382.91,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,275.04,86.97,227.82,10.91">Deception detection for news: three types of fakes</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">L</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">K</forename><surname>Conroy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,112.66,100.52,319.27,10.91">Proceedings of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="1" to="4" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,114.06,389.02,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,154.69,114.06,172.45,10.91">A functional analysis of disinformation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fallis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,335.63,114.06,134.13,10.91">IConference 2014 Proceedings</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,127.61,394.53,10.91;10,112.66,141.16,159.84,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,262.97,127.61,240.14,10.91">Defining &quot;fake news&quot; a typology of scholarly definitions</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">C</forename><surname>Tandoc</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">W</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,112.66,141.16,80.98,10.91">Digital journalism</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="137" to="153" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,154.71,394.52,10.91;10,112.66,168.26,173.79,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,177.28,154.71,92.61,10.91">liar, liar pants on fire</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.00648</idno>
	</analytic>
	<monogr>
		<title level="m" coord="10,280.09,154.71,222.69,10.91">A new benchmark dataset for fake news detection</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,181.81,393.32,10.91;10,112.66,195.36,137.08,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,246.65,181.81,156.10,10.91">Cross-language fake news detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K W</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,410.98,181.81,95.00,10.91;10,112.66,195.36,58.22,10.91">Data and Information Management</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="100" to="109" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,208.91,393.61,10.91;10,112.66,222.46,351.94,10.91" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.04088</idno>
		<title level="m" coord="10,245.44,208.91,260.83,10.91;10,112.66,222.46,169.66,10.91">Mm-covid: A multilingual and multimodal data repository for combating covid-19 disinformation</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,236.01,393.33,10.91;10,112.66,249.56,211.28,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,263.99,236.01,241.99,10.91;10,112.66,249.56,65.16,10.91">Overview of the clef-2021 checkthat! lab task 3 on fake news detection</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,186.11,249.56,105.90,10.91">Working Notes of CLEF</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,263.11,393.33,10.91;10,112.66,276.66,393.33,10.91;10,112.66,290.20,387.87,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,220.22,263.11,285.77,10.91;10,112.66,276.66,49.79,10.91">FakeCovid -a multilingual cross-domain fact check news dataset for covid-19</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nandini</surname></persName>
		</author>
		<ptr target="http://workshop-proceedings.icwsm.org/pdf/2020_14.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="10,183.76,276.66,322.22,10.91;10,112.66,290.20,73.20,10.91">Workshop Proceedings of the 14th International AAAI Conference on Web and Social Media</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,303.75,393.33,10.91;10,112.66,317.30,283.01,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,292.17,303.75,213.82,10.91;10,112.66,317.30,42.26,10.91">An exploratory study of covid-19 misinformation on twitter</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dirkson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Majchrzak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,162.86,317.30,154.86,10.91">Online Social Networks and Media</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">100104</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,330.85,394.53,10.91;10,112.30,344.40,393.68,10.91;10,112.66,357.95,107.17,10.91" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="10,173.53,344.40,256.77,10.91">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,371.50,393.53,10.91;10,112.66,385.05,394.52,10.91;10,112.66,398.60,123.33,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,225.84,371.50,280.35,10.91;10,112.66,385.05,124.63,10.91">Fake news detection using passive-aggressive classifier and other machine learning algorithms</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Nagashri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sangeetha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,260.19,385.05,241.82,10.91">Advances in Computing and Network Communications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="221" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,412.15,393.33,10.91;10,112.33,425.70,68.33,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="10,220.66,412.15,179.50,10.91">Online passive-aggressive active learning</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,408.38,412.15,79.89,10.91">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="141" to="183" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,439.25,393.33,10.91;10,112.66,452.79,276.10,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="10,253.26,439.25,252.72,10.91;10,112.66,452.79,66.09,10.91">Fake news detection using bi-directional lstm-recurrent neural network</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bahad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kamal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,187.66,452.79,122.24,10.91">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="page" from="74" to="82" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
