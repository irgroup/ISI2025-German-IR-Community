<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,85.05,359.08,15.39;1,89.29,106.97,346.01,15.39;1,89.29,128.89,165.72,15.39">Fraunhofer SIT at CheckThat! 2022: Ensemble Similarity Estimation for Finding Previously Fact-Checked Claims</title>
				<funder>
					<orgName type="full">German Federal Ministry of Education and Research (BMBF)</orgName>
				</funder>
				<funder ref="#_BGP6c98">
					<orgName type="full">Hessian Ministry of Higher Education, Research, Science and the Arts</orgName>
				</funder>
				<funder ref="#_7ut4ga3">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,158.21,115.10,10.68"><forename type="first">Raphael</forename><forename type="middle">Antonius</forename><surname>Frick</surname></persName>
							<email>raphael.frick@sit.fraunhofer.de</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Fraunhofer Institute for Secure Information Technology SIT</orgName>
								<orgName type="institution" key="instit2">ATHENE -National Research Center for Applied</orgName>
								<address>
									<addrLine>Cybersecurity Rheinstrasse 75</addrLine>
									<postCode>64295</postCode>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,217.06,158.21,52.30,10.68"><forename type="first">Inna</forename><surname>Vogel</surname></persName>
							<email>inna.vogel@sit.fraunhofer.de</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Fraunhofer Institute for Secure Information Technology SIT</orgName>
								<orgName type="institution" key="instit2">ATHENE -National Research Center for Applied</orgName>
								<address>
									<addrLine>Cybersecurity Rheinstrasse 75</addrLine>
									<postCode>64295</postCode>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,85.05,359.08,15.39;1,89.29,106.97,346.01,15.39;1,89.29,128.89,165.72,15.39">Fraunhofer SIT at CheckThat! 2022: Ensemble Similarity Estimation for Finding Previously Fact-Checked Claims</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">843246735EB10B5DE5500EEE3428920D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Similarity Estimation</term>
					<term>Sentence Transformer</term>
					<term>Ensemble Classification</term>
					<term>Twitter</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>During the corona pandemic misinformation has been increasingly spread on social media. Since the automatic verification of social media postings has shown to be challenging, there exists the need of systems, that can identify whether a claim in a post has already been previously analyzed by independent fact-checkers. In this paper, a system based on ensemble classification is proposed. It takes advantage of state-of-the-art sentence transformers for estimating the semantic similarity between a given tweet and individual parts of a fact-check. Furthermore, it incorporates several preprocessing steps as well as back-translation as a data augmentation technique. The proposed model ranked sixth best in the competition.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>During the corona pandemic, a lot of misinformation was distributed over social media and instant messengers. They were used to sharing conspiracy theories about the existence of the virus, the origin of the outbreak as well as to promoting alternative medication in favor of the vaccine. Thus, there exists the need to detect, whether a social media posting contains false information or claims.</p><p>Since automatic verification of social media content still cannot be done with high accuracy <ref type="bibr" coords="1,136.65,516.60,11.05,9.63" target="#b0">[1]</ref>, they aren't reliable enough to be used in practice e.g., by journalists. They are required to conduct fact-checking prior to publishing any article. Journalists sometimes leverage from information collected from social media due to them being the only source available. Major media houses, such as the AFP, Reuters and DPA, either have an in-house department or rely on third-party NGOs, such as Snopes, checking statements manually. Some of these fact-checks are made publicly available and can help with estimating the truthfulness of a claim.</p><p>The subtask 2A of this year's CLEF2022-CheckThat! Challenge <ref type="bibr" coords="2,404.08,87.63,11.39,9.63" target="#b1">[2,</ref><ref type="bibr" coords="2,419.07,87.63,8.42,9.63" target="#b2">3]</ref> revolved around detecting, whether a statement made in a tweet was previously fact-checked. In this paper, a new approach to identifying whether the content of a tweet has already been subject to fact-checking is presented. It combines multiple state-of-the-art sentence transformers for estimating the semantic similarity between tweets and fact-checks. The similarity score is then used to rank the fact-checks based on the likelihood, that they cover the statements and claims made in a given tweet.</p><p>The paper remainder is structured as follows: at first, an introduction to related work presented in the previous iteration of this competition is given in Section 2. Then, in Section 3 the task and the associated datasets are presented. In Section 4 an overview of the proposed approach is given along with explanations on the applied data augmentation and preprocessing. Section 5 showcases and discusses the experimental results achieved on the test set. The paper then concludes in Section 6 with an outlook for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The identification of previously fact-checked claims was part of the previous iteration of the CheckThat! Challenge <ref type="bibr" coords="2,218.61,322.48,11.50,9.63" target="#b3">[4,</ref><ref type="bibr" coords="2,233.75,322.48,7.66,9.63" target="#b4">5]</ref>. The best performing system utilized a combination of sentence-BERT and TF-IDF as features <ref type="bibr" coords="2,282.50,336.03,10.86,9.63" target="#b5">[6]</ref>. Furthermore, the author took advantage of LambdaMART for re-ranking the outputs. The second best submission <ref type="bibr" coords="2,441.72,349.58,11.63,9.63" target="#b6">[7]</ref> fine-tuned a RoBERTa model to be used to solve the ranking as a regression problem, while the system that ranked third <ref type="bibr" coords="2,212.39,376.68,10.93,9.63" target="#b7">[8]</ref>, also utilized a sentence-BERT, but used a neural network for re-ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Task &amp; Dataset Description</head><p>The objective of this year's CheckThat! Lab task 2 <ref type="bibr" coords="2,327.27,448.94,11.40,9.63" target="#b2">[3]</ref> was to identify whether a claim had already been subject to a previously conducted fact-check. The task itself was divided into several subtasks, with the objective of task 2A being to predict, which previously fact-checked claim is represented by a given tweet. Although the task was available in English and in Arabic, the authors only participated in the English variant of the task.</p><p>Along with the challenge a dataset containing 14, 231 fact checks collected from Snopes and a multiset of tweets had been released. The tweets were split into a train split, a validation split, a validation-test split and a test split. Statistics on the number of tweets featured in each split is showcased in Table <ref type="table" coords="2,301.73,557.34,4.29,9.63" target="#tab_0">2</ref>. Each fact-check consisted of three main parts: a title, a subtitle and the claim as visualized in Table <ref type="table" coords="2,393.21,570.89,4.33,9.63">1</ref>. Further information contained the date of publishing as well as the author. While each tweet only referenced exactly one fact-check, one fact-check may refer to one or more tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methodology</head><p>In this section, the proposed ranking pipeline is presented. The proposed concept is visualized in Figure <ref type="figure" coords="2,186.20,670.25,4.24,9.63">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1</head><p>Example of the structure of a fact-check conducted by Snopes in the dataset</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Title</head><p>Did Vandals Attack 12 Churches in France in One Week? Subtitle A Breitbart report re-emerged on social media in the aftermath of the April 2019 fire at Notre Dame Cathedral in Paris.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Claim</head><p>In early 2019, vandals targeted 12 churches in France over seven days. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data Augmentation</head><p>Back-translation was used to augment training input data so that the models learn to generalize better to unseen data and to generate additional positive samples; samples which are semantically identical to a previously conducted fact-check. Back-translation allows creating new data samples from a reference sample by translating the content of the reference sample into a target language and then back into the language of the reference. The newly crafted samples feature a similar semantic to reference sample, but will differ a lot syntactically. For this lab, back-translation using German, Spanish and Chinese was considered. Translating sentences into Chinese may result in more translation errors than e.g., a translation into German. This however, may allow simulating the introduction of typos and grammar errors that are often found in social media posts. Google Translate hereby served as the translation service and the resulting samples were then used to Original A number of fraudulent text messages informing individuals they have been selected for a military draft have circulated throughout the country this week. German A number of fraudulent text messages that have been selected throughout the country for a military design have been selected throughout the country. Spanish Several fraudulent text messages that report people who have been selected for a military draft have circulated throughout the country this week. Chinese Many fraudulent SMS notifications that they have been selected as a military draft individuals have been scattered throughout the country this week.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 4</head><p>Result of the preprocessing applied on a sample tweet Original This is the content we need #coronavirus content Https://t.co/gwjzukb16u Preprocessed This is the content we need coronavirus content emoji face with tears of joy emoji emoji face with tears of joy emoji emoji United States emoji enrich the training dataset. Example results are showcased in Table <ref type="table" coords="4,417.36,319.53,4.24,9.63" target="#tab_1">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Preprocessing</head><p>The tweets in the dataset need to undergo several preprocessing steps, before can be used in the ranking system. Preprocessing is mainly done with the help of the Python package pysentimiento <ref type="bibr" coords="4,189.92,396.43,14.00,9.63" target="#b8">[9]</ref>. Firstly, emojis are converted into descriptive tokens. Secondly, user mentions (e.g., @reuters) and URLs are turned into generic tokens. The generic URL tokens are then removed as part of the preprocessing step, as they do not contain any useful semantic information. The result on a sample is displayed in Table <ref type="table" coords="4,464.47,437.08,4.24,9.63">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ensemble Classifier</head><p>The ensemble classifier consists of weak classifiers, which outputs were merged to a unified similarity score using a meta-classifier. The base for the weak classifiers consisted of fine-tuned all-MiniLM-L6-v2 and all-MPNet-Base-v2 sentence transformers <ref type="bibr" coords="4,452.80,513.98,16.02,9.63" target="#b9">[10]</ref>. While experiments had also considered the utilization of other sentence-transformer models, all-MiniLM-L6-v2 and all-MPNet-Base-v2 scored best on the validation set. For each part of the fact-check (title, subtitle, claim) a classifier was trained for 10 epochs on the augmented train set. Hereby, the adam-optimizer was used in conjunction with an inital learning rate of 0.00002. The training set consisted of a randomly selected subset of the released train split. For each positive sample, a tweet and its corresponding fact-check, a negative pair using the same tweet and a fact-check not covering the claim has been crafted. This resulted in a balanced dataset and by utilizing the back-translated samples during pair generation, more negative samples could be considered during training. The training procedure took advantage of model checkpoints. By this only the best performing models on the validation set were kept, resulting in a total of 2 × 3 = 6 weak classifiers. Since sentence transformers output vector-embeddings representing the input queries, the cosine-similarity metric was chosen to get similarity scores of sample pairs. These scores were then fed into the meta-classifier. For the meta-classification, an SVM was trained on the development split of the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>Table <ref type="table" coords="5,118.50,601.92,5.38,9.63" target="#tab_2">5</ref> displays the scores achieved by different configurations of the system on the test set.</p><p>The reciprocal rank scores achieved by each individual sentence transformer range between 0.2614 to 0.7614. The best results were achieved by the fine-tuned All-MiniLM-L6-v2 model, that was trained on the train set consisting of claims. The models that were fine-tuned on subtitles performed the worst not only on the validation set, but also on the test set. Thus, they were omitted from the final model. Two types of ensemble classification techniques were experimented on during evaluation. One averages the similarity scores that are output by each weak classifier, while the other takes advantage of the proposed SVM meta-classifier. In the evaluative results it showed, that averaging the similarity scores did not enhance the performance. In fact, the performance worsened in comparison to the fine-tuned All-MiniLM-L6-v2 model. The proposed meta-classifier however was able to get the best scores when including data preprocessing and augmentation. Omitting data preprocessing and data augmentation yielded less good results, even though there were only minor differences. Unfortunately, due to an error during submission, the similarity score averaging model was submitted to the competition's leaderboard instead of the one using the trained meta-classifier. It ranked sixth in the competition (Table <ref type="table" coords="6,278.12,398.15,4.24,9.63" target="#tab_3">6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, a new approach to detecting whether statements in tweets were previously fact-checked. It consisted of multiple fine-tuned sentence transformers served as weak classifiers in an ensemble classification scheme. Instead of only taking the claims of the fact-check into consideration during ranking, the semantic similarity between a given tweet and the title or the subtitle of the published fact-check was analyzed as well. An SVM was then used to as a meta-classifier. Further, it took advantage of data augmentation, in particular back-translation, and data preprocessing. Experimental results have shown, that while the system was indeed able to identify which statements were subject to a previously conducted fact-checking, the system still needs some improvements in order to be used in practice. Interestingly, the ranking did not benefit from the utilization of the estimated semantic similarity between tweets and subtitles of the fact-checks during classification. Future work could revolve around including a re-ranker as well as taking advantage of a cross-encoder.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,184.26,397.06,270.74"><head>Table 2</head><label>2</label><figDesc>Number of tweets per split of the CheckThat! 2022 Task 2A English dataset</figDesc><table coords="3,89.29,212.33,396.76,242.67"><row><cell></cell><cell></cell><cell></cell><cell>#Tweets</cell></row><row><cell></cell><cell></cell><cell>Train Split</cell><cell>999</cell></row><row><cell></cell><cell></cell><cell>Validation Split</cell><cell>200</cell></row><row><cell></cell><cell></cell><cell>Validation-Test Split</cell><cell>202</cell></row><row><cell></cell><cell></cell><cell>Test Split</cell><cell>209</cell></row><row><cell cols="3">Figure 1: Visualization of the ranking pipeline</cell><cell></cell></row><row><cell>Tweet</cell><cell>Back-Translation (training only)</cell><cell>Data Preprocessing</cell><cell>All-MiniLM-L6-v2</cell></row><row><cell></cell><cell></cell><cell></cell><cell>SVM</cell><cell>Score</cell></row><row><cell></cell><cell>Title</cell><cell></cell><cell>All-MPNet-Base-v2</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Ensemble Classifier</cell></row><row><cell>Fact-</cell><cell>Sub-</cell><cell></cell><cell></cell></row><row><cell>Check</cell><cell>title</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Claim</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.99,90.67,311.73,20.86"><head>Table 3</head><label>3</label><figDesc>Example of the structure of a fact-check conducted by Snopes in the dataset</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,88.43,90.67,447.26,386.99"><head>Table 5</head><label>5</label><figDesc>Scored Reciprocal Rank, Precision and MAP of the individual models on the test set.</figDesc><table coords="5,88.43,114.58,447.26,363.08"><row><cell cols="3">* indicates the submitted model</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="7">All-MiniLM-All-MPNet-All-MiniLM-All-MPNet-All-MiniLM-All-MPNet-</cell></row><row><cell></cell><cell></cell><cell>L6-v2</cell><cell>Base-v2</cell><cell>L6-v2</cell><cell>Base-v2</cell><cell></cell><cell>L6-v2</cell><cell>Base-v2</cell></row><row><cell></cell><cell></cell><cell>(Claims)</cell><cell>(Claims)</cell><cell>(Title)</cell><cell>(Title)</cell><cell cols="2">(Subtitle)</cell><cell>(Subtitle)</cell></row><row><cell cols="2">Reciprocal Rank</cell><cell>0.7614</cell><cell>0.7105</cell><cell>0.7380</cell><cell>0.7028</cell><cell></cell><cell>0.2614</cell><cell>0.2995</cell></row><row><cell></cell><cell>@1</cell><cell>0.7143</cell><cell>0.6476</cell><cell>0.6714</cell><cell>0.6381</cell><cell></cell><cell>0.1905</cell><cell>0.2476</cell></row><row><cell></cell><cell>@3</cell><cell>0.2635</cell><cell>0.2492</cell><cell>0.2635</cell><cell>0.2460</cell><cell></cell><cell>0.0968</cell><cell>0.1000</cell></row><row><cell>Prec. @N</cell><cell>@5</cell><cell>0.1629</cell><cell>0.1571</cell><cell>0.1619</cell><cell>0.1533</cell><cell></cell><cell>0.0667</cell><cell>0.0686</cell></row><row><cell></cell><cell>@10</cell><cell>0.0833</cell><cell>0.0833</cell><cell>0.0829</cell><cell>0.0819</cell><cell></cell><cell>0.0395</cell><cell>0.0410</cell></row><row><cell></cell><cell>@20</cell><cell>0.0436</cell><cell>0.0426</cell><cell>0.0426</cell><cell>0.0417</cell><cell></cell><cell>0.0231</cell><cell>0.0245</cell></row><row><cell></cell><cell>@1</cell><cell>0.7143</cell><cell>0.6476</cell><cell>0.6714</cell><cell>0.6381</cell><cell></cell><cell>0.1905</cell><cell>0.2476</cell></row><row><cell></cell><cell>@3</cell><cell>0.7484</cell><cell>0.6921</cell><cell>0.7286</cell><cell>0.6857</cell><cell></cell><cell>0.2349</cell><cell>0.2722</cell></row><row><cell>Map @N</cell><cell>@5</cell><cell>0.7534</cell><cell>0.7009</cell><cell>0.7326</cell><cell>0.6921</cell><cell></cell><cell>0.2452</cell><cell>0.2817</cell></row><row><cell></cell><cell>@10</cell><cell>0.7565</cell><cell>0.7069</cell><cell>0.7352</cell><cell>0.7000</cell><cell></cell><cell>0.2535</cell><cell>0.2907</cell></row><row><cell></cell><cell>@20</cell><cell>0.7595</cell><cell>0.7082</cell><cell>0.7368</cell><cell>0.7009</cell><cell></cell><cell>0.2581</cell><cell>0.2960</cell></row><row><cell></cell><cell></cell><cell cols="2">Similarity</cell><cell>Meta</cell><cell>Meta</cell><cell></cell><cell></cell><cell>Meta</cell></row><row><cell></cell><cell></cell><cell>Score</cell><cell></cell><cell>Classifier</cell><cell>Classifier</cell><cell></cell><cell cols="2">Classifier</cell></row><row><cell></cell><cell></cell><cell cols="2">Averaging</cell><cell></cell><cell cols="4">No Preprocessing No Augmentation</cell></row><row><cell></cell><cell></cell><cell cols="3">(Claim + Title + Subtitle)* (Claim + Title)</cell><cell cols="2">(Claim + Title)</cell><cell cols="2">(Claim + Title)</cell></row><row><cell cols="2">Reciprocal Rank</cell><cell>0.6236</cell><cell></cell><cell>0.8014</cell><cell>0.7980</cell><cell></cell><cell></cell><cell>0.7979</cell></row><row><cell></cell><cell>@1</cell><cell>0.5571</cell><cell></cell><cell>0.0.7524</cell><cell>0.7476</cell><cell></cell><cell></cell><cell>0.7614</cell></row><row><cell></cell><cell>@3</cell><cell>0.2206</cell><cell></cell><cell>0.2746</cell><cell>0.2778</cell><cell></cell><cell></cell><cell>0.2678</cell></row><row><cell>Prec. @N</cell><cell>@5</cell><cell>0.1410</cell><cell></cell><cell>0.1705</cell><cell>0.1705</cell><cell></cell><cell></cell><cell>0.1614</cell></row><row><cell></cell><cell>@10</cell><cell>0.0752</cell><cell></cell><cell>0.0881</cell><cell>0.0876</cell><cell></cell><cell></cell><cell>0.0861</cell></row><row><cell></cell><cell>@20</cell><cell>0.0407</cell><cell></cell><cell>0.0450</cell><cell>0.0450</cell><cell></cell><cell></cell><cell>0.0442</cell></row><row><cell></cell><cell>@1</cell><cell>0.5571</cell><cell></cell><cell>0.7524</cell><cell>0.7476</cell><cell></cell><cell></cell><cell>0.7614</cell></row><row><cell></cell><cell>@3</cell><cell>0.6008</cell><cell></cell><cell>0.7873</cell><cell>0.7873</cell><cell></cell><cell></cell><cell>0.7868</cell></row><row><cell>Map @N</cell><cell>@5</cell><cell>0.6103</cell><cell></cell><cell>0.7942</cell><cell>0.7916</cell><cell></cell><cell></cell><cell>0.7911</cell></row><row><cell></cell><cell>@10</cell><cell>0.6167</cell><cell></cell><cell>0.7983</cell><cell>0.7945</cell><cell></cell><cell></cell><cell>0.7940</cell></row><row><cell></cell><cell>@20</cell><cell>0.6207</cell><cell></cell><cell>0.7999</cell><cell>0.7963</cell><cell></cell><cell></cell><cell>0.7976</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,88.99,90.67,455.01,133.54"><head>Table 6</head><label>6</label><figDesc>Leaderboard of the task for the evaluation on the test set</figDesc><table coords="6,95.67,116.47,448.34,107.74"><row><cell>User/team</cell><cell cols="5">MAP All MAP 1 MAP 3 MAP 5 MAP 10</cell><cell>RR</cell><cell cols="3">Prec. 3 Prec. 5 Prec. 10</cell></row><row><cell>mshlis [11]</cell><cell>0.957</cell><cell>0.943</cell><cell>0.955</cell><cell>0.956</cell><cell>0.956</cell><cell>0.957</cell><cell>0.322</cell><cell>0.194</cell><cell>0.098</cell></row><row><cell>Viktor [12]</cell><cell>0.922</cell><cell>0.904</cell><cell>0.919</cell><cell>0.922</cell><cell>0.922</cell><cell>0.922</cell><cell>0.313</cell><cell>0.19</cell><cell>0.095</cell></row><row><cell>watheq9</cell><cell>0.923</cell><cell>0.9</cell><cell>0.921</cell><cell>0.921</cell><cell>0.921</cell><cell>0.923</cell><cell>0.316</cell><cell>0.189</cell><cell>0.095</cell></row><row><cell>Team_SimBa [13]</cell><cell>0.907</cell><cell>0.876</cell><cell>0.905</cell><cell>0.907</cell><cell>0.907</cell><cell>0.907</cell><cell>0.314</cell><cell>0.19</cell><cell>0.095</cell></row><row><cell>motlogelwan</cell><cell>0.878</cell><cell>0.833</cell><cell>0.87</cell><cell>0.873</cell><cell>0.876</cell><cell>0.878</cell><cell>0.306</cell><cell>0.187</cell><cell>0.095</cell></row><row><cell>Fraunhofer SIT</cell><cell>0.624</cell><cell>0.557</cell><cell>0.601</cell><cell>0.61</cell><cell>0.617</cell><cell>0.624</cell><cell>0.221</cell><cell>0.141</cell><cell>0.075</cell></row><row><cell>Team_Vax_Misinfo</cell><cell>0.096</cell><cell>0.005</cell><cell>0.011</cell><cell>0.02</cell><cell>0.054</cell><cell>0.096</cell><cell>0.006</cell><cell>0.011</cell><cell>0.033</cell></row><row><cell>random-baseline</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported by the <rs type="funder">German Federal Ministry of Education and Research (BMBF)</rs> and the and the <rs type="funder">Hessian Ministry of Higher Education, Research, Science and the Arts</rs> within their joint support of "<rs type="projectName">ATHENE -Disinformation on Corona</rs>" and "<rs type="projectName">Lernlabor Cybersicherheit</rs>".</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_BGP6c98">
					<orgName type="project" subtype="full">ATHENE -Disinformation on Corona</orgName>
				</org>
				<org type="funded-project" xml:id="_7ut4ga3">
					<orgName type="project" subtype="full">Lernlabor Cybersicherheit</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,111.71,211.35,394.27,9.63;7,111.71,224.90,394.27,9.63;7,111.71,238.44,395.78,9.63;7,111.71,251.99,217.63,10.20" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,295.12,211.35,210.86,9.63;7,111.71,224.90,139.91,9.63">Overview of the CLEF-2021 CheckThat! lab task 3 on fake news detection</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2936/paper-30.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="7,278.23,224.90,227.75,9.63;7,111.71,238.44,213.07,9.63">Working Notes of CLEF 2021-Conference and Labs of the Evaluation Forum, CLEF &apos;2021</title>
		<meeting><address><addrLine>Bucharest, Romania (online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.71,265.54,395.79,9.63;7,111.71,279.09,395.79,9.63;7,111.71,292.64,394.27,9.63;7,111.71,306.19,394.28,9.63;7,111.71,319.74,394.63,9.63;7,111.31,333.29,396.19,9.63;7,111.71,346.84,252.72,9.63" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,446.50,292.64,59.48,9.63;7,111.71,306.19,394.28,9.63;7,111.71,319.74,68.89,9.63">Overview of the CLEF-2022 CheckThat! lab on fighting the COVID-19 infodemic and fake news detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beltrán</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,207.08,319.74,299.26,9.63;7,111.31,333.29,396.19,9.63;7,111.71,346.84,146.14,9.63">Proceedings of the 13th International Conference of the CLEF Association: Information Access Evaluation meets Multilinguality, Multimodality, and Visualization, CLEF &apos;2022</title>
		<meeting>the 13th International Conference of the CLEF Association: Information Access Evaluation meets Multilinguality, Multimodality, and Visualization, CLEF &apos;2022<address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.71,360.39,395.79,9.63;7,111.71,373.94,395.36,9.63;7,111.71,387.49,394.27,9.63;7,111.71,401.04,255.42,9.63" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,111.71,373.94,395.36,9.63;7,111.71,387.49,70.02,9.63">Overview of the CLEF-2022 CheckThat! lab task 2 on detecting previously factchecked claims</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,211.95,387.49,294.03,9.63;7,111.71,401.04,148.83,9.63">Working Notes of CLEF 2022-Conference and Labs of the Evaluation Forum, CLEF &apos;2022</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.71,414.58,395.79,9.63;7,111.71,428.13,395.79,9.63;7,111.31,441.68,395.07,9.63;7,111.71,455.23,395.36,9.63;7,111.71,468.78,394.27,9.63;7,111.71,482.33,395.79,9.63;7,111.71,495.88,395.78,9.63;7,111.71,509.43,318.17,10.20" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,462.71,441.68,43.67,9.63;7,111.71,455.23,395.36,9.63;7,111.71,468.78,138.21,9.63">Overview of the CLEF-2021 CheckThat! lab on detecting check-worthy claims, previously factchecked claims, and fake news</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-85251-1_19</idno>
		<ptr target="https://link.springer.com/chapter/10.1007/978-3-030-85251-1_19" />
	</analytic>
	<monogr>
		<title level="m" coord="7,276.38,468.78,229.60,9.63;7,111.71,482.33,395.79,9.63;7,111.71,495.88,219.39,9.63">Proceedings of the 12th International Conference of the CLEF Association: Information Access Evaluation Meets Multiliguality, Multimodality, and Visualization, CLEF &apos;2021</title>
		<meeting>the 12th International Conference of the CLEF Association: Information Access Evaluation Meets Multiliguality, Multimodality, and Visualization, CLEF &apos;2021<address><addrLine>Bucharest, Romania (online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.71,522.98,395.78,9.63;7,111.71,536.53,395.37,9.63;7,111.32,550.08,395.76,9.63;7,111.71,563.63,394.27,9.63;7,111.71,577.17,395.18,9.63;7,111.71,591.18,187.94,9.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,330.59,536.53,176.49,9.63;7,111.32,550.08,395.76,9.63;7,111.71,563.63,67.91,9.63">Overview of the CLEF-2021 Check-That! lab task 2 on detecting previously fact-checked claims in tweets and political debates</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2936/paper-29.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="7,219.28,563.63,286.70,9.63;7,111.71,577.17,176.59,9.63">Working Notes of CLEF 2021-Conference and Labs of the Evaluation Forum, CLEF &apos;2021</title>
		<meeting><address><addrLine>Bucharest, Romania (online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.71,604.27,394.49,9.63;7,111.71,617.82,216.42,9.63" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chernyavskiy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ilvovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<title level="m" coord="7,316.92,604.27,189.28,9.63;7,111.71,617.82,182.05,9.63">Aschern at checkthat! 2021: normalcr lambda-calculus of fact-checked claims</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.71,631.37,394.27,9.63;7,111.71,644.92,395.78,9.63" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,176.73,631.37,329.26,9.63;7,111.71,644.92,308.57,9.63">Nlytics at checkthat! 2021: Multi-class fake news detection of news articles and domain identification with roberta -a baseline model</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pritzkau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,447.22,644.92,25.60,9.63">CLEF</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.71,87.63,395.79,9.63;8,111.71,101.18,355.20,9.63" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="8,111.71,101.18,227.25,9.63">Dips at checkthat! 2021: verified claim retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mihaylova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Borisova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chemishanov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Hadzhitsanev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hardalov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<editor>Faggioli et al.</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.71,114.73,394.28,9.63;8,111.71,128.28,247.11,9.84" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,288.74,114.73,217.25,9.63;8,111.71,128.28,129.99,9.63">pysentimiento: A python toolkit for sentiment analysis and socialnlp tasks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Giudici</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Luque</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,283.18,129.98,18.39,8.14">r X i v</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1 0 6</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.71,141.83,395.36,9.63;8,111.71,155.38,394.27,9.63;8,111.71,168.93,395.56,10.20;8,111.36,182.93,119.97,9.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,236.65,141.83,270.41,9.63;8,111.71,155.38,39.59,9.63">Sentence-bert: Sentence embeddings using siamese bertnetworks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1908.10084" />
	</analytic>
	<monogr>
		<title level="m" coord="8,177.86,155.38,328.12,9.63;8,111.71,168.93,304.44,9.63">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.71,196.03,394.49,9.63;8,111.71,209.57,395.36,9.63;8,111.71,223.12,394.27,9.63;8,111.71,236.67,274.20,9.63" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,256.77,196.03,249.43,9.63;8,111.71,209.57,166.28,9.63">RIET Lab at CheckThat! 2022: improving decoder based re-ranking for claim matching</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">D</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Michael Shliselberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,238.28,223.12,267.70,9.63;8,111.71,236.67,167.61,9.63">Working Notes of CLEF 2022 -Conference and Labs of the Evaluation Forum, CLEF &apos;2022</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Guglielmo Andd Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><surname>Potthast</surname></persName>
		</editor>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.71,250.22,394.27,9.63;8,111.71,263.77,395.80,9.63;8,111.31,277.32,394.68,9.63;8,111.71,290.87,312.89,9.63" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,171.12,250.22,334.86,9.63;8,111.71,263.77,196.67,9.63">AI Rational at CheckThat! 2022: reranking previously fact-checked claims on semantic and lexical similarity</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kostov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,274.54,277.32,231.44,9.63;8,111.71,290.87,206.29,9.63">Working Notes of CLEF 2022 -Conference and Labs of the Evaluation Forum, CLEF &apos;2022</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Guglielmo Andd Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><surname>Potthast</surname></persName>
		</editor>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.71,304.42,394.27,9.63;8,111.71,317.97,395.36,9.63;8,111.71,331.52,394.28,9.63;8,110.86,345.07,396.64,9.63;8,111.71,358.62,162.68,9.63" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,305.68,304.42,200.30,9.63;8,111.71,317.97,395.36,9.63;8,111.71,331.52,60.49,9.63">SimBa at CheckThat! 2022: lexical and semantic similarity based detection of verified claims in an unsupervised and supervised way</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hövelmeyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Boland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dietze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,145.65,345.07,361.85,9.63;8,111.71,358.62,56.09,9.63">Working Notes of CLEF 2022 -Conference and Labs of the Evaluation Forum, CLEF &apos;2022</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Guglielmo Andd Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><surname>Potthast</surname></persName>
		</editor>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
