<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,85.05,350.75,15.39;1,89.29,106.97,387.93,15.39;1,89.29,128.89,146.98,15.39">BUM at CheckThat! 2022: A Composite Deep Learning Approach to Fake News Detection using Evidence Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,158.21,85.04,10.68"><forename type="first">David</forename><forename type="middle">La</forename><surname>Barbera</surname></persName>
							<email>labarbera.david@spes.uniud.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Udine</orgName>
								<address>
									<addrLine>Via Delle Scienze 206</addrLine>
									<postCode>33100</postCode>
									<settlement>Udine</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,193.43,158.21,67.07,10.68"><forename type="first">Kevin</forename><surname>Roitero</surname></persName>
							<email>kevin.roitero@uniud.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Udine</orgName>
								<address>
									<addrLine>Via Delle Scienze 206</addrLine>
									<postCode>33100</postCode>
									<settlement>Udine</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,279.60,158.21,73.66,10.68"><forename type="first">Joel</forename><surname>Mackenzie</surname></persName>
							<email>joel.mackenzie@uq.edu.au</email>
							<affiliation key="aff1">
								<orgName type="institution">The University of Queensland</orgName>
								<address>
									<postCode>QLD 4072</postCode>
									<settlement>St Lucia</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,372.35,158.21,74.67,10.68"><forename type="first">Damiano</forename><surname>Spina</surname></persName>
							<email>damiano.spina@rmit.edu.au</email>
							<affiliation key="aff2">
								<orgName type="institution">RMIT University</orgName>
								<address>
									<addrLine>124 La Trobe St</addrLine>
									<postCode>3000</postCode>
									<settlement>Melbourne</settlement>
									<region>VIC</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,172.16,96.26,10.68"><forename type="first">Gianluca</forename><surname>Demartini</surname></persName>
							<email>demartini@acm.org</email>
							<affiliation key="aff1">
								<orgName type="institution">The University of Queensland</orgName>
								<address>
									<postCode>QLD 4072</postCode>
									<settlement>St Lucia</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,216.57,172.16,78.83,10.68"><forename type="first">Stefano</forename><surname>Mizzaro</surname></persName>
							<email>mizzaro@uniud.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Udine</orgName>
								<address>
									<addrLine>Via Delle Scienze 206</addrLine>
									<postCode>33100</postCode>
									<settlement>Udine</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,85.05,350.75,15.39;1,89.29,106.97,387.93,15.39;1,89.29,128.89,146.98,15.39">BUM at CheckThat! 2022: A Composite Deep Learning Approach to Fake News Detection using Evidence Retrieval</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">D585377DF82E5121424F775164132B27</idno>
					<note type="submission">Accessed: 21 June 2022].</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>fake news</term>
					<term>fact-checking</term>
					<term>deep learning</term>
					<term>information retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We detail a deep learning approach based on the transformer architecture for performing fake news detection. The proposed approach is composed of a deep learning network which receives as input the claim to be verified, a series of predictions made by other models, and supporting evidence in the form of ranked passages. We validate our approach participating as the Brisbane-Udine-Melbourne (BUM) Team in the CLEF2022-CheckThat! Lab (Task 3: Fake News Detection), where we achieve an F1-score of 0.275, ranking 10 th out of 25 participants.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The increasing popularity of the internet, particularly social networks, has been accompanied by the spread of fake news. Due to the huge amount of data that people produce and share every day, specialized human fact-checkers struggle to keep up with manually annotating and validating such data. Therefore, researchers and practitioners are investing significant resources to develop automated approaches to support fact-checkers by identifying fake news in a fast and reliable way.</p><p>To address this important issue, the CLEF-2022 CheckThat! Lab <ref type="bibr" coords="1,385.16,502.08,11.40,9.74" target="#b0">[1]</ref>, as done in the previous edition <ref type="bibr" coords="1,123.87,515.63,11.59,9.74" target="#b1">[2]</ref>, has a task to develop systems that, given an article described by its text and title, are able to determine whether the main claim made in the article is true, partially true, false, or other (e.g., claims in dispute). To support this task (Task 3, English), the CheckThat! Lab released a database made up to 1,300 unique statements and their labels.</p><p>In this paper we present our approach to the aforementioned task as follows. In Section 2, we briefly describe the purpose of the challenge. In Section 3, we detail supplemental data that we have employed to expand the available dataset. Then, in Section 4, we describe our approach to the task: we build a deep learning pipeline relying on (i) a BERT model trained on external additional data; (ii) a T5 transformer to perform entailment for each statement with the top evidence found with information retrieval models; and (iii) we use those additional data combined together to form a novel dataset to predict the final score. Finally, Section 5 concludes the report.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Task 3: Fake News Detection</head><p>The goal of Task 3: English fake news detection is to label the truthfulness of English news articles based on four truthfulness levels defined as follows:</p><p>False: The main claim made in an article is untrue;</p><p>Partially False: The main claim of an article is a mixture of true and false information. The article contains partially true and partially false information but cannot be considered 100% true;</p><p>True: This rating indicates that the primary elements of the main claim are demonstrably true;</p><p>Other: An article that cannot be categorized as true, false, or partially false due to a lack of evidence about its claims. This category includes articles in dispute and unproven articles.</p><p>The available training dataset contains 1,264 different articles with the respective title, body text, and truthfulness labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Expanding the Dataset</head><p>In this Section we describe the additional data that we use to train our models, and the retrieval techniques used to find adequate evidence for the original training set described above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Additional Data</head><p>To train part of our models we rely on additional data suggested by Shahi et al. <ref type="bibr" coords="2,432.41,570.88,11.52,9.74" target="#b2">[3]</ref>; we manually annotate the data to map the ground truth scale to the same scale used in this challenge. We adapt the following datasets, keeping only the columns related to the title, text, and ground truth of the claim:</p><p>‚Ä¢ We use the Fake News Detection Challenge KDD 2020 dataset <ref type="foot" coords="2,392.11,631.37,4.06,7.79" target="#foot_0">1</ref>  ‚Ä¢ From the public Kaggle repository FakeNewsNet <ref type="bibr" coords="3,336.00,205.21,11.37,9.74" target="#b3">[4,</ref><ref type="bibr" coords="3,350.08,205.21,7.48,9.74" target="#b4">5,</ref><ref type="bibr" coords="3,360.28,205.21,3.79,9.74" target="#b5">6</ref>], <ref type="foot" coords="3,371.64,202.53,4.06,7.79" target="#foot_3">3</ref> we use the BuzzFeed dataset, which consists of 91 false statements and 91 true statements.</p><p>‚Ä¢ We use 120 statements from the PolitiFact dataset, originally set by Wang <ref type="bibr" coords="3,444.95,241.04,11.42,9.74" target="#b6">[7]</ref>, which we have used in prior work <ref type="bibr" coords="3,225.04,254.59,11.29,9.74" target="#b7">[8,</ref><ref type="bibr" coords="3,239.06,254.59,7.45,9.74" target="#b8">9,</ref><ref type="bibr" coords="3,249.23,254.59,12.27,9.74" target="#b9">10]</ref>. We adapt the ground truth by setting the pants on fire statements to false, the barely true, half true, and mostly true statements to partially false, and leaving the others unchanged. From that same work by Roitero et al. <ref type="bibr" coords="3,450.36,281.68,11.46,9.74" target="#b7">[8]</ref>, Soprano et al. <ref type="bibr" coords="3,140.30,295.23,11.40,9.74" target="#b8">[9]</ref>, La Barbera et al. <ref type="bibr" coords="3,232.27,295.23,16.22,9.74" target="#b9">[10]</ref>, we use 60 statements from the ABC dataset, mapping the ground truth from negative to false, in between to partially false, and positive to true.</p><p>‚Ä¢ We use the FEVER dataset <ref type="bibr" coords="3,233.54,331.06,16.17,9.74" target="#b10">[11]</ref>, consisting of 145,449 unique statements, by mapping the ground truth from supports to true, refutes to false, and setting the remaining statements as other.</p><p>‚Ä¢ Finally, we also use the data from Jiang et al. <ref type="bibr" coords="3,325.46,380.43,16.29,9.74" target="#b11">[12]</ref>, consisting of 18,171 statements, in which we map the supported ground truth to true, and set the others to false.</p><p>Combining these individual collections results in a novel dataset made up of 213,715 additional statements with the same ground truth scale as the one made available for the challenge and described in Section 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Evidence Retrieval</head><p>To further enrich the data available for the classification task, we employed Wikipedia as a source of evidence. In particular, we used the WikiExtractor<ref type="foot" coords="3,379.07,504.19,4.06,7.79" target="#foot_4">4</ref> tool to extract documents from Wikimedia's XML dump of the English segment of Wikipedia. <ref type="foot" coords="3,403.94,517.74,4.06,7.79" target="#foot_5">5</ref> After extracting the raw documents, we also created a passage-level representation of the data. Since we had both document-level and passage-level representations, we created two separate indexes with the Lucene-based Anserini system <ref type="bibr" coords="3,246.38,561.07,16.41,9.74" target="#b12">[13]</ref>. In total, the document index consisted of 6.5 million documents, and the passage index contained 49.2 million passages; both indexes were built from around 15 GiB of raw Wikipedia text data. We used the title of each article as a query, and retrieved the top-ùëò documents/passages using a simple bag-of-words BM25 model <ref type="bibr" coords="3,486.67,601.72,16.41,9.74" target="#b13">[14]</ref>, returning the full text of those top-ùëò items for further processing. Table <ref type="table" coords="4,407.24,451.48,5.02,9.74" target="#tab_1">1</ref> shows two examples of passage-level evidence retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Proposed Approach</head><p>The rationale behind our approach is to use information retrieval techniques to provide evidence for each claim, and to use some models to perform preliminary operations on the data. This allows us to enrich the available dataset with further information which we hypothesize will increase the performance of the final classification. To this end, we build an informative textual string representation that can be fed to a transformer-based (i.e., BERT) model, consisting of:</p><p>‚Ä¢ The title of the claim;</p><p>‚Ä¢ The text of the claim;</p><p>‚Ä¢ The prediction and the confidence of a BERT model trained on the external datasets;</p><p>‚Ä¢ A T5 transformer used to perform entailment with the top ranking passage that was retrieved to find a justification for each claim using the Wikipedia index; and ‚Ä¢ The top-10 passages retrieved according to the retrieval strategy detailed above.</p><p>The idea is to use the "textification" approach, which has been successfully applied to tasks related to the medical domain, in particular to automatic encoding of diagnostic texts <ref type="bibr" coords="5,457.68,380.84,16.31,9.74" target="#b14">[15,</ref><ref type="bibr" coords="5,476.19,380.84,12.50,9.74" target="#b15">16,</ref><ref type="bibr" coords="5,490.88,380.84,12.23,9.74" target="#b16">17]</ref>, as well as in human mobility forecasting <ref type="bibr" coords="5,272.44,394.39,16.25,9.74" target="#b17">[18]</ref>. All of the aforementioned information is combined for each statement to build up the final classification for the task. In the following subsection, we will describe each component of our composite model. We rely on PyTorch and Hugging Face to implement, fine-tune, and deploy our models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">BERT Classification Relying on External Data</head><p>The first component we use is a BERT model <ref type="bibr" coords="5,293.51,498.31,18.00,9.74" target="#b18">[19]</ref> to predict truthfulness of given statements. We use the additional data detailed in Section 3.1 to fine-tune a b e r t -b a s e -u n c a s e d model <ref type="foot" coords="5,485.95,509.18,4.06,7.79" target="#foot_6">6</ref> for three epochs on a classification task, thus using Cross-Entropy as loss function.</p><p>For all the models that we have used for our fake news detection pipeline, we rely on 10% of the statements from the original training set as a test set to validate the model performances. After the fine-tuning phase, our model achieves an accuracy of 0.779 and a macro-F1 score of 0.645.</p><p>At this point, we use this model to perform predictions on the original training set for the challenge. For each claim we than use the model prediction and its confidence to ensemble a string with the following format: " c l a s s P R</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E D I C T E D C L A S S w i t h c o n f i d e n c e M O D E L P R E D I C T I O N</head><formula xml:id="formula_0" coords="5,89.29,633.80,55.65,9.74">C O N F I D E N C E " .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">T5 Transformer Entailment</head><p>The second component that we use to enrich the available information for each claim is a pre-trained T5 transformer which is used to perform entailment. In particular, we rely on the t 5 -b a s e<ref type="foot" coords="6,123.18,133.08,4.06,7.79" target="#foot_7">7</ref> model which has been already fine-tuned for the entailment task on multiple datasets (see <ref type="bibr" coords="6,109.43,149.31,70.22,9.74">Raffel et al. [20,</ref><ref type="bibr" coords="6,182.62,149.31,44.27,9.74">Appendix]</ref>). After different attempts we decided to perform entailment by relying on the Recognizing Textual Entailment (RTE) task prefix and modality (we refer to the original paper <ref type="bibr" coords="6,172.98,176.40,18.05,9.74" target="#b19">[20]</ref> for an in depth explanation of each available modality, an example of the one used in this paper can be found in Appendix C.5 of that work), which we found to perform best. We choose to not rely on other T5 modalities other than RTE, since RTE was the most effective. We leave an in-depth study of the different T5 entailment modalities for fact-checking purposes to future work. Thus, to check if the claim is a logical consequence of the best evidence provided, we use the textual representation of the highly ranked passage from the retrieved evidence described in Section 3.2 and perform entailment for each claim in the test set. Finally, we store the model prediction results as evidence for the final classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">BERT Classification Aggregation</head><p>We now describe the model that we develop to perform the final classification. Relying on the information available for each statement, along with the additional information that we have computed using both BERT and T5, we build a string for each claim containing its title, the claim, the T5 entailment prediction, and the BERT string described in Section 4.1. Moreover, to provide the model with the top-10 most relevant retrieved passages for each claim and overcome the maximum length for a given input for BERT (i.e. 512 tokens), we use the information listed above for each statement as a prefix. We then concatenate part of the evidence (i.e. part of the top-10 passages, from rank one to rank ten) until the size of 512 tokens is reached. We repeat this process until we have paired the result string with all of the evidence passages. This process is detailed in Figure <ref type="figure" coords="6,219.55,442.52,3.81,9.74" target="#fig_0">1</ref>. We use the model to compute its predictions for each string. Thus, we aggregate those predictions over the same statement (identified not only by an ID, but also from the prefix) using a majority vote (i.e., the mode function) to obtain the final prediction from our pipeline.</p><p>We decided on applying the aforementioned model as our submission to the challenge after trying several alternatives to padding and splitting on instances of 512 tokens. In fact, we did experiment with models implementing more efficient attention such as the Longformer <ref type="bibr" coords="6,469.74,523.82,17.76,9.74" target="#b20">[21]</ref> and Reformer <ref type="bibr" coords="6,134.08,537.36,17.97,9.74" target="#b21">[22]</ref> models, but they performed worse than the padded BERT model and exhibited unstable losses during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">System Performance</head><p>The performance of our composite model is summarized in Table <ref type="table" coords="6,380.30,600.64,3.71,9.74">2</ref>, where the first row shows the overall results of the system, and the subsequent rows show the results computed per ground truth label. The metric used to rank the systems for the challenge, the F1-score, was 0.275 for our model, leading us to rank 10 th overall for the task of fake news detection in the CLEF-2022</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2</head><p>Overall and per-label metric scores of the proposed system under the test set for the challenge. Submissions were ranked using the F1-score. CheckThat! Lab. Investigating the model performance by taking into account the measures for each label, we can see that we have much greater scores for the false label with respect to all of the other labels. This result is probably due to bias from the large amount of false statements in the training dataset. Thus, given more equally distributed training data, we believe that our system performance could improve significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Accuracy Precision</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper, we present our approach for the task of fake news detection for the CLEF-2022 CheckThat! Lab. We proposed a deep learning pipeline strongly relying on retrieval techniques to augment the training data, and textify the data for use within a BERT model. Our best run achieved the 10 th place on the English fake news classification dataset. We believe that our solution is suitable for further improvements that could enhance the quality of the overall predictions. First of all, we aim to improve data quality, since we found that some claims were noisy. Also, we aim to include more statements from other datasets in the additional meta-dataset that we have built. We also aim to improve the quality of our evidence retrieval, by using models beyond bag-of-words, and by using other sources of information beyond Wikipedia. Further investigation on the fine-tuning of the T5 Transformer and alternative modalities or combinations thereof may further improve performance. Finally we also aim to test further alternatives with respect to those described and tested in Section 4.2.1, such as different textification and combination of models and methodologies such as those explored by Xue et al. <ref type="bibr" coords="7,189.01,530.54,17.91,9.74" target="#b17">[18]</ref> and Radford et al. <ref type="bibr" coords="7,290.85,530.54,16.25,9.74" target="#b22">[23]</ref>.</p><p>In the future we will continue to improve this approach, as we believe that our system can contribute to the fight against misinformation by leveraging the complementary roles of evidence retrieval and the power of large language models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,89.29,90.67,360.21,8.91"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Schema of the approach used to train the model with the combined evidence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,116.56,634.05,389.66,23.29"><head></head><label></label><figDesc>which is made by 4,987 unique true or false statements; ‚Ä¢ We use part of the public Fakenews Classification Datasets 2 on Kaggle, such as the Emergent Phase2 2018, consisting of 90 statements, where we map the statements with ground truth set as Unverified to other; the Fake dataset, consisting of 23,481 false statements; the</figDesc><table coords="3,116.27,128.74,390.91,63.94"><row><cell>True dataset, consisting of 21,417 true statements; and the Snopes dataset, consisting of</cell></row><row><cell>4,745 statements for which we map the original mostly true, mostly false, misattributed,</cell></row><row><cell>miscaptioned, and mixture labels to partially false, the scam and legend labels as false, and</cell></row><row><cell>leave the remaining labels unchanged. All other data was unused, since it was not clear</cell></row><row><cell>how to properly adapt it for this challenge.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.99,90.67,416.98,333.10"><head>Table 1</head><label>1</label><figDesc>Two examples of passage-based evidence retrieval. The top example shows successful retrieval, and the bottom example shows a failure. Social media accounts, including Donald Trump Jr's Twitter account, circulated the false claim that 183 people had been arrested for arson during the Australian fire crisis. In 2021, the Australian Press Council determined the news report that 183 arsonists had been arrested "was not misleading". These 183 people were subject to legal action, but only 24 for "deliberately-lit bushfires". An opinion piece for "The Conversation" website stated "In the first week of 2020, hashtag #ArsonEmergency became the focal point of a new online narrative surrounding the bushfire crisis. The message: the cause is arson, not climate change. Police and bushfire services (and some journalists) have contradicted this claim [...] We have observed both troll and bot accounts spouting disinformation regarding the bushfires on Twitter". The article also argued that a disinformation was underway to downplay the role of climate change in causing the fires. The vice.com website wrote "Research conducted by the Queensland University of Technology showed that Twitter accounts with the characteristics of bots or trolls were spreading disinformation about the responsibility of arsonists and Greens". "The Guardian" accused News Corp of furthering arson disinformation.</figDesc><table /><note coords="4,99.71,134.20,353.19,8.91;4,99.71,146.15,56.93,8.91;4,99.71,163.60,42.38,8.90;4,99.71,349.60,275.76,8.91;4,99.71,361.55,56.93,8.91;4,99.71,379.00,42.38,8.90;4,99.71,390.95,396.03,8.91;4,99.71,402.90,396.10,8.91;4,99.71,414.86,118.64,8.91"><p>Title: Australian Authorities: Arsonists to Blame for Bushfires -NOT Climate Change Rating: False Passage 1 Title: Energy secretary warns of ¬£500m 'electric shock' after Brexit Rating: False Passage 1 A regenerative shock absorber is a type of shock absorber that converts parasitic intermittent linear motion and vibration into useful energy, such as electricity. Conventional shock absorbers simply dissipate this energy as heat.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,171.72,134.22,251.84,79.65"><head>Recall F1-score</head><label></label><figDesc></figDesc><table coords="7,171.72,151.65,241.01,62.21"><row><cell>overall</cell><cell>.472</cell><cell>.301</cell><cell>.299</cell><cell>.275</cell></row><row><cell>false</cell><cell>-</cell><cell>.624</cell><cell>.781</cell><cell>.694</cell></row><row><cell>other</cell><cell>-</cell><cell>.060</cell><cell>.065</cell><cell>.062</cell></row><row><cell>partially false</cell><cell>-</cell><cell>.104</cell><cell>.214</cell><cell>.140</cell></row><row><cell>true</cell><cell>-</cell><cell>.414</cell><cell>.138</cell><cell>.207</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,92.46,671.96,242.12,8.01"><p>https://www.kaggle.com/c/fakenewskdd2020/overview [Accessed:</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="21" xml:id="foot_1" coords="2,348.14,671.96,40.60,8.01"><p>June 2022].</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2" coords="3,92.46,628.12,351.52,8.01"><p>https://www.kaggle.com/datasets/liberoliber/onion-notonion-datasets [Accessed: 21 June 2022].</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3" coords="3,92.46,639.07,298.27,8.01"><p>https://www.kaggle.com/datasets/mdepak/fakenewsnet [Accessed: 21 June 2022].</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4" coords="3,92.46,650.03,241.92,8.01"><p>https://github.com/attardi/wikiextractor [Accessed: 21 June 2022].</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5" coords="3,92.46,660.99,415.04,8.01;3,92.46,671.95,79.73,8.01"><p>Dump from April 2, 2022. https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2 [Accessed: 21 June 2022].</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6" coords="5,92.46,671.92,260.60,8.01"><p>see https://huggingface.co/bert-base-uncased [Accessed: 21 June 2022].</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7" coords="6,92.46,671.94,219.99,8.01"><p>see https://huggingface.co/t5-base [Accessed: 21 June 2022].</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,112.66,629.81,393.32,9.74;7,112.66,643.36,393.59,9.74;7,112.66,656.91,382.34,9.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,452.20,629.81,53.78,9.74;7,112.66,643.36,265.83,9.74">Overview of the CLEF-2022 CheckThat! lab task 3 on fake news detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>K√∂hler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Stru√ü</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sch√ºtz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,401.70,643.36,104.54,9.74;7,112.66,656.91,286.23,9.74">Working Notes of CLEF 2022-Conference and Labs of the Evaluation Forum, CLEF &apos;2022</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,88.09,393.32,9.74;8,112.66,101.64,393.32,9.74;8,112.66,115.19,394.03,9.74;8,112.30,128.74,102.37,9.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,270.91,88.09,235.06,9.74;8,112.66,101.64,107.65,9.74">Overview of the CLEF-2021 CheckThat! Lab Task 3 on Fake News Detection</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Stru√ü</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2936/paper-30.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="8,244.10,101.64,261.88,9.74;8,112.66,115.19,127.07,9.74">Working Notes of CLEF 2021-Conference and Labs of the Evaluation Forum, CLEF 2021</title>
		<meeting><address><addrLine>Bucharest, Romania (online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,142.29,393.70,9.74;8,112.66,155.84,358.15,9.74" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="8,410.51,142.29,95.85,9.74;8,112.66,155.84,199.98,9.74">CT-FAN-22 corpus: A Multilingual dataset for Fake News Detection</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Stru√ü</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>K√∂hler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.6508748</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,169.38,393.31,9.74;8,112.66,182.93,340.28,9.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,303.16,169.38,202.82,9.74;8,112.66,182.93,83.30,9.74">Fake news detection on social media: A data mining perspective</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sliva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,204.32,182.93,174.83,9.74">ACM SIGKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="22" to="36" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,196.48,393.33,9.74;8,112.66,210.03,107.17,9.74" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.07709</idno>
		<title level="m" coord="8,219.29,196.48,216.31,9.74">Exploiting tri-relationship for fake news detection</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,223.58,393.32,9.74;8,112.66,237.13,393.32,9.74;8,112.66,250.68,207.15,9.74" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mahudeswaran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.01286</idno>
		<title level="m" coord="8,340.93,223.58,165.05,9.74;8,112.66,237.13,393.32,9.74;8,112.66,250.68,24.53,9.74">Fakenewsnet: A data repository with news content, social context and dynamic information for studying fake news on social media</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,264.23,394.61,9.74;8,112.66,277.78,393.32,9.74;8,112.33,291.33,394.85,9.74;8,112.66,304.88,199.53,9.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,171.92,264.23,316.33,9.74">liar, liar pants on fire&quot;: A new benchmark dataset for fake news detection</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-2067</idno>
	</analytic>
	<monogr>
		<title level="m" coord="8,112.66,277.78,393.32,9.74">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="422" to="426" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct coords="8,112.66,318.43,393.61,9.74;8,112.66,331.98,394.60,9.74;8,112.66,345.52,395.17,9.74;8,112.66,359.07,394.52,9.74;8,112.66,372.62,207.93,9.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,404.88,318.43,101.39,9.74;8,112.66,331.98,374.37,9.74">Can the crowd identify misinformation objectively? The effects of judgment scale and assessor&apos;s background</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Roitero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Soprano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mizzaro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Demartini</surname></persName>
		</author>
		<idno type="DOI">10.1145/3397271.3401112</idno>
	</analytic>
	<monogr>
		<title level="m" coord="8,112.66,345.52,395.17,9.74;8,112.66,359.07,128.13,9.74">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="439" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,386.17,394.52,9.74;8,112.33,399.72,393.65,9.74;8,112.66,413.27,395.74,9.74;8,112.42,426.82,108.90,9.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,112.33,399.72,393.65,9.74;8,112.66,413.27,100.97,9.74">The many dimensions of truthfulness: Crowdsourcing misinformation assessments on a multidimensional scale</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Soprano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Roitero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>La</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barbera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ceolin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mizzaro</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Demartini</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2021.102710</idno>
		<idno>doi:10. 1 0 1 6 / j</idno>
	</analytic>
	<monogr>
		<title level="j" coord="8,221.60,413.27,175.79,9.74">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page">102710</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>. i p m . 2 0 2 1 . 1 0 2 7 1 0</note>
</biblStruct>

<biblStruct coords="8,112.66,440.37,394.61,9.74;8,112.33,453.92,395.34,9.74;8,112.66,467.47,352.81,9.74" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="8,379.39,440.37,127.88,9.74;8,112.33,453.92,213.03,9.74">Crowdsourcing Truthfulness: The Impact of Judgment Scale and Assessor Bias</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barbera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Roitero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mizzaro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Demartini</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-45442-5_26</idno>
		<ptr target="https://doi.org/https://doi.org/10.1007/978-3-030-45442-5_26" />
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="207" to="214" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,481.02,393.53,9.74;8,112.66,494.57,393.32,9.74;8,112.28,508.11,393.70,9.74;8,112.33,521.66,394.07,9.74;8,112.66,535.21,287.52,9.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,364.22,481.02,141.97,9.74;8,112.66,494.57,143.90,9.74">FEVER: a large-scale dataset for fact extraction and VERification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1074</idno>
	</analytic>
	<monogr>
		<title level="m" coord="8,282.43,494.57,223.55,9.74;8,112.28,508.11,393.70,9.74;8,112.33,521.66,57.13,9.74">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="809" to="819" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="8,112.66,548.76,395.16,9.74;8,112.66,562.31,393.32,9.74;8,112.66,575.86,395.01,9.74;8,112.66,589.41,395.74,9.74;8,141.70,602.96,60.96,9.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,385.70,548.76,122.12,9.74;8,112.66,562.31,174.12,9.74">HoVer: A dataset for manyhop fact extraction and claim verification</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bordia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Dognin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.309</idno>
		<ptr target="https://aclanthology.org/2020.findings-emnlp.309.doi:10.18653/v1/2020.gs-emnlp.309" />
	</analytic>
	<monogr>
		<title level="m" coord="8,307.66,562.31,198.32,9.74;8,112.66,575.86,311.33,9.74">Findings of the Association for Computational Linguistics: EMNLP 2020, Association for Computational Linguistics</title>
		<meeting><address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3441" to="3460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,616.51,393.32,9.74;8,112.66,630.06,212.84,9.74" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,220.35,616.51,244.03,9.74">Anserini: Reproducible ranking baselines using Lucene</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,473.21,616.51,32.77,9.74;8,112.66,630.06,144.12,9.74">Journal of Data and Information Quality</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,643.61,394.53,9.74;8,112.66,657.16,297.02,9.74" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,245.71,643.61,256.44,9.74">The probabilistic relevance framework: BM25 and beyond</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,112.66,657.16,218.16,9.74">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,670.70,393.32,9.74;9,112.66,88.09,393.32,9.74;9,112.66,101.64,313.18,9.74" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,337.70,670.70,168.27,9.74;9,112.66,88.09,246.50,9.74">Automatic assignment of ICD-10 codes to diagnostic texts using transformers based techniques</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">H</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Roitero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Travasci</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">Della</forename><surname>Mea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,406.00,88.09,99.98,9.74;9,112.66,101.64,198.94,9.74">IEEE 9th International Conference on Healthcare Informatics (ICHI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="page" from="188" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,115.19,393.53,9.74;9,112.66,128.74,294.14,9.74" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,354.41,115.19,151.78,9.74;9,112.66,128.74,121.19,9.74">DiLBERT: Cheap embeddings for disease related medical NLP</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Roitero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Portelli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">H</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">Della</forename><surname>Mea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,243.13,128.74,54.37,9.74">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="159714" to="159723" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,142.29,393.33,9.74;9,112.66,155.84,394.53,9.74;9,112.66,169.38,229.33,9.74" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,298.72,142.29,207.27,9.74;9,112.66,155.84,389.57,9.74">Underlying cause of death identification from death certificates using reverse coding to text and a nlp based deep learning approach</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Della Mea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">H</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Roitero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,112.66,169.38,151.37,9.74">Informatics in Medicine Unlocked</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">100456</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,182.93,393.33,9.74;9,112.66,196.48,395.16,9.74;9,112.66,210.03,394.90,9.74" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,291.82,182.93,214.17,9.74;9,112.66,196.48,123.18,9.74">Translating human mobility forecasting through natural language generation</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">D</forename><surname>Salim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
		<idno type="DOI">10.1145/3488560.3498387</idno>
	</analytic>
	<monogr>
		<title level="m" coord="9,259.39,196.48,248.44,9.74;9,112.66,210.03,164.02,9.74">Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Fifteenth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1224" to="1233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,223.58,393.32,9.74;9,112.66,237.13,393.32,9.74;9,112.66,250.68,393.32,9.74;9,112.66,264.23,393.32,9.74;9,112.66,277.78,375.60,9.74" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="9,323.14,223.58,182.83,9.74;9,112.66,237.13,186.81,9.74">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m" coord="9,328.03,237.13,177.95,9.74;9,112.66,250.68,393.32,9.74;9,112.66,264.23,99.96,9.74">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="9,112.66,291.33,394.52,9.74;9,112.66,304.88,393.32,9.74;9,112.66,318.43,192.41,9.74" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="9,112.66,304.88,341.66,9.74">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,462.63,304.88,43.35,9.74;9,112.66,318.43,123.70,9.74">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,331.98,393.59,9.74;9,112.66,345.52,146.44,9.74" xml:id="b20">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05150</idno>
		<title level="m" coord="9,268.37,331.98,204.11,9.74">Longformer: The long-document transformer</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,359.07,393.33,9.74;9,112.66,372.62,393.33,9.74;9,112.66,386.17,60.90,9.74" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="9,264.16,359.07,159.02,9.74">Reformer: The efficient transformer</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kitaev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Levskaya</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rkgNKkHtvB" />
	</analytic>
	<monogr>
		<title level="m" coord="9,447.00,359.07,58.98,9.74;9,112.66,372.62,181.93,9.74">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,399.72,394.53,9.74;9,112.66,413.27,395.16,9.74;9,112.66,426.82,394.90,9.74" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="9,230.89,413.27,276.93,9.74;9,112.66,426.82,39.14,9.74">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,174.95,426.82,204.16,9.74">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8748" to="8763" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
