<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,417.18,15.42;1,89.29,106.66,352.18,15.42">iCompass at CheckThat! 2022: ARBERT and AraBERT for Arabic Checkworthy Tweet Identification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,64.45,11.96"><forename type="first">Bilel</forename><surname>Taboubi</surname></persName>
							<email>bileltaboubi20@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">iCompass</orgName>
								<address>
									<addrLine>Emeraude Palace, Rue du Lac Windermère, Les Berges du Lac</addrLine>
									<postCode>1053</postCode>
									<settlement>Tunis</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,166.39,134.97,73.55,11.96"><forename type="first">Mohamed</forename><surname>Aziz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">iCompass</orgName>
								<address>
									<addrLine>Emeraude Palace, Rue du Lac Windermère, Les Berges du Lac</addrLine>
									<postCode>1053</postCode>
									<settlement>Tunis</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,242.92,134.97,52.56,11.96"><forename type="first">Ben</forename><surname>Nessir</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">iCompass</orgName>
								<address>
									<addrLine>Emeraude Palace, Rue du Lac Windermère, Les Berges du Lac</addrLine>
									<postCode>1053</postCode>
									<settlement>Tunis</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,326.47,134.97,73.55,11.96"><forename type="first">Hatem</forename><surname>Haddad</surname></persName>
							<email>haddad.hatem@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">iCompass</orgName>
								<address>
									<addrLine>Emeraude Palace, Rue du Lac Windermère, Les Berges du Lac</addrLine>
									<postCode>1053</postCode>
									<settlement>Tunis</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,417.18,15.42;1,89.29,106.66,352.18,15.42">iCompass at CheckThat! 2022: ARBERT and AraBERT for Arabic Checkworthy Tweet Identification</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">8B367224A336DF74E5463B07672021CF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>GRU</term>
					<term>ARBERT</term>
					<term>ARABERT</term>
					<term>Arabic</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper provides a detailed overview of systems and its achieved results, which were produced as part of CLEF2022 -Check-That! Lab Fighting the COVID-19 Infodemic and Fake News Detection. The task was carried out using transformers pre-trained models Arabic BERT, ARBERT, MARBERT, AraBERT, Arabic ALBERT and BERT base arabic. The models were fine-tuned for the down-stream task in hand, binary classification of Arabic tweets. According to the results, AraBERT attained the highest 0.462 F1 score on the test set of subtask 1A and ARBERT attained the best F1 score 0.557 on the test set of subtask 1C.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The spread of fake news misinformation is increasing and almost turning to be unlimited due to the increase of social media users and platforms allowing anyone these days can create and join and share articles and information in social medias platforms pretending to be a news agency or a popular person and this is causing serious problems to society, partly due to the fact that more and more people only read headlines or highlights of news assuming that everything is reliable instead of carefully analysing whether it can contain distorted or false information. Harmful Speech is particularly widespread in online communication due to users' anonymity and the lack of harmful speech detection tools on social media platforms. Consequently, Harmful speech detection has determined a growing interest in using Machine/Deep Learning techniques to address this issue <ref type="bibr" coords="1,168.33,489.65,11.31,10.91" target="#b0">[1]</ref>. The increase of social media users conducted to a uncontrollable amount of information shared daily, making it impossible to be covered by manual fact checking sites where organizations and researchers began to move for a creation of automated systems with an aim to solve the mess caused by these misinformation. This paper focus on Subtask 1A and 1C in Arabic from CheckThat, a lab contest with various tasks for competitors <ref type="bibr" coords="1,444.90,543.84,11.47,10.91" target="#b1">[2]</ref>. This year, the lab offered the following three main tasks: Detecting Check-Worthy Claims (Task 1), Fact Checking Claims (Task 2), and Fake News Detection (Task 3). Task 1 was divided into four subtasks and the rest of the tasks each contain two subtasks. Both Subtask 1A and 1C where</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The winner team from the recent years contest CheckThat! Lab 2020 <ref type="bibr" coords="2,393.27,186.24,12.69,10.91" target="#b2">[3]</ref> and 2021 <ref type="bibr" coords="2,450.20,186.24,12.70,10.91" target="#b3">[4]</ref> proposed a solution using two models BERT and RoBERTa then adding a mean-pooling, a dropout layers and finally a classification layer.</p><p>They also used data augmentation, in particular, they generated synthetic training data using lexical substitution to create additional synthetic examples for the positive class and used machine translation to translate Arabic data to English and then to Arabic again.</p><p>The paper <ref type="bibr" coords="2,146.68,267.54,12.69,10.91" target="#b4">[5]</ref> evaluates Deep learning approches using supervised algorithms for text classification based on Convolutional Neural Networks (CNN), Long Short Term Memory (LSTM), and Bidirectional Encoder Representations from Transformers (BERT) for Fake news detection.The dataset was preprocessed as following, Removal of HTML tags, Convert Accented Characters to ASCII, Expand contractions, Removal of Special Characters, Noise Removal, Normalization, Stemming, and Stop-words Removal. All Transformers based models outperformed basic models with a difference of 3-4% in accuarcy . The best accuracy was reached using language model pretraining on BERT 98.41%.</p><p>Experiments were done by IEEEAcces <ref type="bibr" coords="2,272.11,375.93,12.84,10.91" target="#b5">[6]</ref> using the open source Fake News Corpus dataset available on Github, the dataset has been used for determining a veracity of news articles. Text Preprocessing techniques were applied on news article to transforms the text to UTF-8, remove stop words and punctuation, lemmatize the sentences to get them back to their root form and transform the text to lowercase. Many deep learning architectures were applied such as LSTM, GRU, CNN with different word embedding techniques Word2Vec, FastText and GloVe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Data Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Subtask 1A: Check-worthiness of tweets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Dataset Statistics</head><p>The dataset for CLEF Subtask 1A contains 3439 tweets written in Arabic dialect, the data set had originally 4 parts, train, dev, dev test, and test but we reassembled it into train, development and test sets as shown in Table , labelled with binary labels, 1 for worthy claims with a percentage of 61.4 and 0 for unworthy for the rest 38.6% of the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Subtask 1C: Harmful tweet detection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Dataset Statistics</head><p>The provided training dataset of the CLEF Subtask 1C harmful tweet detection is about 5k tweets, labelled with the 2 categories Normal and Harmful. 81% of the tweets are Normal and  The dataset is highly unbalanced so we downsampled the Normal tweets, we tried multiple combinations and percentages but down sampling it to 65%, as in making it roughly 1.5 times the size of the harmful tweets gave the best results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Data preparation</head><p>We experimented with various preprocessing techniques, such as removing emojis, normalizing hashtags, removing Latin characters, removing URLs, data normalization, deleting tashkeel and the letter madda from texts, as well as duplicates etc. The best results were given on the raw unpreprocessed data for each of subtasks 1A and 1C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Pre-trained Models</head><p>Different pre-trained models were used in order to achieve the best results when fine-tuning it in a multi-task fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">AraBERT</head><p>AraBERT (V2) <ref type="bibr" coords="3,153.40,574.43,11.27,10.91" target="#b6">[7]</ref>, is a BERT based model for Modern Standard Arabic Language understanding, trained on 70M sentences from several public Arabic datasets and news websites. It was finetuned on 3 tasks: Sequence Classification, Named Entity Recognition and Question Answering. It was reported to achieve state-of-the-art performances even on Arabic dialects after fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Bert base Arabic</head><p>The Arabic BERT model <ref type="bibr" coords="4,196.23,107.54,12.69,10.91" target="#b7">[8]</ref> was trained on 8.2 billion words using the Arabic version of OSCAR, Recent dump of Arabic Wikipedia and other Arabic resources which sum up to 95GB of text which was filtered using Common Crawl. The final version of corpus contains some non-Arabic words inlines. The corpus and the vocabulary set are not restricted to MSA, they contain some dialectical (spoken) Arabic too, which boosted models performance in terms of data from social media platforms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">ARBERT</head><p>ARBERT <ref type="bibr" coords="4,131.06,225.01,12.85,10.91" target="#b8">[9]</ref> is also a Bert based model trained on 61GB of Modern Standard Arabic text (6.5B tokens) gathered from books, news articles, crawled data and Wikipedia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">MARBERT</head><p>MARBERT <ref type="bibr" coords="4,141.08,288.28,12.93,10.91" target="#b8">[9]</ref> is a large-scale pretrained language model using the BERT base's architecture. MARBERT is trained on on 128 GB of tweets from various Arabic dialects containing at least 3 Arabic words. With very light preprocessing the tweets were almost kept at their initial state to retain a faithful representation of the naturally occurring text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Subtask 1A: Check-worthiness of tweets</head><p>Pre-trained models AraBERT and BERT base Arabic were trained and finetuned with the following architecture:  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Subtask 1C: Harmful tweet detection</head><p>Different language models were used in this work. However, ARBERT achieved the best results. This was the case because it was pre-trained on modern standard arabic text from tweets with little no normalization therefore works better for our case. In addition, the data imbalance further illustrated in figure <ref type="figure" coords="6,213.15,389.87,5.13,10.91" target="#fig_0">1</ref> decreased the model performance causing it to easily overfit on the training dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>In this paper, we demonstrated the performance of gated recurrent unit for each fo the subtasks Harmful tweet detection and Check-worthiness of tweets by fine-tuning the pre-trained models ARBERT and AraBERT. Despite the small sized annotated data, the model achieved satisfactory results.</p><p>With respect to the models, further work should explore meta-learning, Focal loss, semi-supervised learning.</p><p>As for the data, further work should focus on the exploring other augmentation and resampleing strategies as well as collectiong more harmful tweets for Subtask1C, and feature extracting features like account types, as number of likes, number of shares from tweet links provided within the data for more distinguishability between the worthy and unworthy claims.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,89.29,580.43,193.13,8.93;6,198.42,426.13,198.43,141.74"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Subtask 1c harmful speech statistics.</figDesc><graphic coords="6,198.42,426.13,198.43,141.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,90.49,305.08,118.22"><head>Table 1</head><label>1</label><figDesc>Task 1A dataset statistics.</figDesc><table coords="3,89.04,128.31,305.03,80.40"><row><cell>Type</cell><cell cols="2">Train Dev Test Total</cell></row><row><cell>Worthy claims</cell><cell>962</cell><cell>100 266 1328</cell></row><row><cell cols="3">Unworthy claims 1551 135 425 2111</cell></row><row><cell>19% are Harmful as shown in</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,221.73,197.80,220.63,10.91"><head>Table 2 .</head><label>2</label><figDesc>Again this data set was also reassembled.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,88.99,226.80,298.28,71.00"><head>Table 2</head><label>2</label><figDesc>Task 1C dataset statistics..</figDesc><table coords="3,208.01,264.63,179.26,33.18"><row><cell>Type</cell><cell cols="4">Train Dev. Dev. Test Total</cell></row><row><cell>Harmful</cell><cell>678</cell><cell>60</cell><cell>189</cell><cell>927</cell></row><row><cell>Normal</cell><cell>2946</cell><cell>276</cell><cell>805</cell><cell>4027</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,89.29,444.59,416.69,121.50"><head></head><label></label><figDesc>Sigmoid activation function and one unitBest results achieved by each pre-trained model is presented in the table3where they got trained on the train set,validated on development set and tested with test set.</figDesc><table coords="4,107.28,444.59,317.49,85.43"><row><cell>• Input layer</cell></row><row><cell>• Bert model</cell></row><row><cell>• A gated recurrent unit with 128 untis and 0.3 probability for dropout.</cell></row><row><cell>• Dense layer with 50 units and Relu activation function</cell></row><row><cell>• A dropout layer with 0.1 probability.</cell></row><row><cell>• Dense layer with a</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,88.99,584.18,329.06,71.00"><head>Table 3</head><label>3</label><figDesc>Task 1A Pre-trained models results on dev set.</figDesc><table coords="4,177.23,622.01,240.82,33.18"><row><cell>Type</cell><cell>F1</cell><cell cols="3">Accuracy Precision Recall</cell></row><row><cell>AraBERT</cell><cell>0.590</cell><cell>0.536</cell><cell>0.453</cell><cell>0.844</cell></row><row><cell cols="2">BERT base Arabic 0.576</cell><cell>0.672</cell><cell>0.601</cell><cell>0.554</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>The submitted model was AraBERT, trained with a 10 epochs, 2e-5 learning rate for Adam optimizer, a sequence length of 150, 32 batch size and binary cross entropy loss function.The model achieved F1_score 0.590 on the dev set,and 0.462 on the submission test set to get rank 3 in Subtask 1A Arabic leaderboard as shown in the table 4.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Subtask 1C: Harmful tweet detection</head><p>All the models were finetuned with :</p><p>• A gated recurrent unit with 256 untis and 0.5 dropout.</p><p>• A gated recurrent unit with 128 untis and 0.4 dropout.</p><p>• A gated recurrent unit with 64 untis and 0.3 dropout.</p><p>• 1-dimensional convolution neural network with 64 units and a kernel size of 3.</p><p>• A 0.3 dropout layer.</p><p>• A layer to concatenate Global Average Pooling 1D and Global Maximum Pooling 1D of the previous output. • A 0.05 dropout layer.</p><p>• A final dense layer with a Sigmoid activation function and one unit.</p><p>All of the models results are presented in table <ref type="table" coords="5,310.10,462.49,3.74,10.91">5</ref>. The best results were achived with ARBERT, The submitted model was trained with a total of 16 epochs. The first 4 epochs were only used to warm up the GRU layers, we froze ARBERT and trained them with a learning rate of 1e-4 and then and for the rest 12 epochs we unfroze ARBERT and used a learning rate of 1e-5. For both parts we used Adam optimizer, a batch size of 64 and a binary cross entropy loss function. The model achieved an F1 score of 0.557 on the test set and got rank 1, the subtask participants are shown in the table 6. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="7,107.59,267.54,398.40,10.91;7,107.59,281.08,398.40,10.91;7,107.59,294.63,399.60,10.91;7,107.59,308.18,391.31,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,233.12,267.54,272.86,10.91;7,107.59,281.08,46.35,10.91">A survey on hate speech detection using natural language processing</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-1101</idno>
		<ptr target="https://aclanthology.org/W17-1101.doi:10.18653/v1/W17-1101" />
	</analytic>
	<monogr>
		<title level="m" coord="7,181.76,281.08,324.23,10.91;7,107.59,294.63,320.92,10.91">Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media, Association for Computational Linguistics</title>
		<meeting>the Fifth International Workshop on Natural Language Processing for Social Media, Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.59,321.73,399.60,10.91;7,107.06,335.28,399.32,10.91;7,107.59,348.83,399.68,10.91;7,107.59,362.38,398.66,10.91;7,107.59,375.93,382.34,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,461.99,335.28,44.40,10.91;7,107.59,348.83,375.35,10.91">Overview of the CLEF-2022 CheckThat! lab task 1 on identifying relevant claims in tweets</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beltrán</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,401.41,362.38,104.84,10.91;7,107.59,375.93,286.23,10.91">Working Notes of CLEF 2022-Conference and Labs of the Evaluation Forum, CLEF &apos;2022</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Guglielmo Andd Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><surname>Potthast</surname></persName>
		</editor>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.59,389.48,398.39,10.91;7,107.59,403.03,399.10,10.91;7,107.59,416.58,220.49,10.91" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Novak</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2009.02431</idno>
		<ptr target="https://arxiv.org/abs/2009.02431.doi:10.48550/ARXIV.2009.02431" />
		<title level="m" coord="7,269.89,389.48,236.09,10.91;7,107.59,403.03,247.36,10.91">Accenture at checkthat! 2020: If you say so: Post-hoc fact-checking of claims using transformer-based models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.59,430.13,400.24,10.91;7,107.59,443.67,400.08,10.91;7,107.59,457.22,338.78,10.91" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="7,260.49,430.13,247.33,10.91;7,107.59,443.67,368.91,10.91">Accenture at checkthat! 2021: Interesting claim identification and ranking with contextually sensitive lexical training data augmentation</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tran</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2107.05684</idno>
		<ptr target="https://arxiv.org/abs/2107.05684.doi:10.48550/ARXIV.2107.05684" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.59,470.77,398.61,10.91;7,107.59,484.32,398.40,10.91;7,107.59,497.87,399.68,10.91;7,107.59,511.42,398.99,10.91;7,107.29,527.41,14.27,7.90" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,323.97,470.77,182.23,10.91;7,107.59,484.32,125.32,10.91">Evaluating deep learning approaches for covid19 fake news detection</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Wani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Khandve</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Wagh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Joshi</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-73696-5_15</idno>
		<ptr target="https://doi.org/10.1007q%2F978-3-030-73696-5_15.doi:10.1007/978-3-030-73696-5_15" />
	</analytic>
	<monogr>
		<title level="m" coord="7,256.09,484.32,249.89,10.91;7,107.59,497.87,126.51,10.91">Combating Online Hostile Posts in Regional Languages during Emergency Situation</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="153" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.59,538.52,399.68,10.91;7,107.20,552.07,399.43,10.91;7,107.34,565.62,200.43,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,323.10,538.52,184.17,10.91;7,107.20,552.07,295.01,10.91">Context-aware misinformation detection: A benchmark of deep learning architectures using word embeddings</title>
		<author>
			<persName coords=""><forename type="first">V.-I</forename><surname>Ilie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-O</forename><surname>Truică</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">S</forename><surname>Apostol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Paschke</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2021.3132502</idno>
	</analytic>
	<monogr>
		<title level="j" coord="7,410.74,552.07,67.15,10.91">IEEE Access PP</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.59,579.17,400.24,10.91;7,107.59,592.72,402.55,10.91;7,107.59,608.71,32.07,7.90" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="7,238.12,579.17,269.70,10.91;7,107.59,592.72,51.70,10.91">Arabert: Transformer-based model for arabic language understanding</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Antoun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Baly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hajj</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2003.00104</idno>
		<ptr target="https://arxiv.org/abs/2003.00104.doi:10.48550/ARXIV.2003.00104" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.59,619.81,398.60,10.91;7,107.59,633.36,398.40,10.91;7,107.59,646.91,398.40,10.91;8,107.26,86.97,402.88,10.91;8,107.29,102.96,163.13,7.90" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,273.28,619.81,232.91,10.91;7,107.59,633.36,197.08,10.91">KUISAIL at SemEval-2020 task 12: BERT-CNN for offensive speech identification in social media</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Safaya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Abdullatif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Yuret</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.semeval-1.271</idno>
		<ptr target="https://aclanthology.org/2020.semeval-1.271.doi:10.18653/v1/2020.semeval-1.271" />
	</analytic>
	<monogr>
		<title level="m" coord="7,327.26,633.36,178.72,10.91;7,107.59,646.91,348.27,10.91">Proceedings of the Fourteenth Workshop on Semantic Evaluation, International Committee for Computational Linguistics</title>
		<meeting>the Fourteenth Workshop on Semantic Evaluation, International Committee for Computational Linguistics<address><addrLine>Barcelona (online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2054" to="2059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,107.59,114.06,400.24,10.91;8,107.59,127.61,399.58,10.91;8,107.29,143.61,97.35,7.90" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Abdul-Mageed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Elmadany</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M B</forename><surname>Nagoudi</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2101.01785</idno>
		<ptr target="https://arxiv.org/abs/2101.01785.doi:10.48550/ARXIV.2101.01785" />
		<title level="m" coord="8,354.81,114.06,153.01,10.91;8,107.59,127.61,128.33,10.91">Arbert &amp; marbert: Deep bidirectional transformers for arabic</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
