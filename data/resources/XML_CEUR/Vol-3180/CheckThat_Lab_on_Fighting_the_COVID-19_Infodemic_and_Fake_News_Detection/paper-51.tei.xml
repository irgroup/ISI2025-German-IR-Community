<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,382.56,15.42;1,89.29,106.66,416.69,15.42">NITK-IT NLP at CheckThat! 2022: Window based approach for Fake News Detection using transformers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,217.15,11.96"><forename type="first">Hariharan</forename><forename type="middle">Ramakrishnaiyer</forename><surname>Lekshmiammal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">National Institute of Technology Karnataka</orgName>
								<address>
									<settlement>Surathkal</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,322.08,134.97,124.81,11.96"><forename type="first">Anand</forename><surname>Kumar Madasamy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">National Institute of Technology Karnataka</orgName>
								<address>
									<settlement>Surathkal</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,382.56,15.42;1,89.29,106.66,416.69,15.42">NITK-IT NLP at CheckThat! 2022: Window based approach for Fake News Detection using transformers</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">7B659F9D6329D4541A059E889E22C470</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Fake news</term>
					<term>DeBERTa</term>
					<term>Disinformation</term>
					<term>RoBERTa</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Misinformation is a severe threat to society which mainly spreads through online social media. The amount of misinformation generated and propagated is much more than authentic news. In this paper, we have proposed a model for the shared task on Fake News Classification by CLEF2022 CheckThat! Lab 1 , which had mono-lingual Multi-class Fake News Detection in English and cross-lingual task for English and German. We employed a transformer-based model with overlapping window strides, which helped us to achieve 7 ùë°‚Ñé and 2 ùëõùëë positions out of 25 and 8 participants on the final leaderboard of the two tasks respectively. We got an F1 score of 0.2980 and 0.2245 against the top score of 0.3391 and 0.2898 for the two tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Social media can be considered the leading media through which the latest news is propagated. Even though this can be seen as the advancement of technology, it poses a severe threat to society by giving false or fake information to the users who are dependent on them. As per the literature, it's evident that the number of fake news propagates faster than authentic news <ref type="bibr" coords="1,492.47,418.96,11.39,10.91" target="#b0">[1]</ref>. During the COVID-19 pandemic, we have seen a lot of disinformation connected to the virus's cure and vaccines, which all portray the importance of combating fake news on social media.</p><p>CLEF-2022 CheckThat! <ref type="bibr" coords="1,206.48,459.61,11.36,10.91" target="#b1">[2,</ref><ref type="bibr" coords="1,220.58,459.61,8.96,10.91" target="#b2">3]</ref> Lab had organized a shared task named Fake News Classification 1  <ref type="bibr" coords="1,114.42,473.16,11.58,10.91" target="#b3">[4]</ref>. They had two subtasks for Fake News Detection of News Articles: a Mono-lingual task in English and a Cross-lingual task for English and German (English training data and German test data). Both tasks were to classify the articles into fake, partially fake, other, and true labels. They had provided datasets for both the tasks, from 2010 to 2022, covering several topics like elections, COVID-19, etc.</p><p>In this paper, we have used transformers-based models, which are pre-trained on a vast amount of data and are capable of understanding words based on their context. We have used the various transformer-based models like DeBERTa, RoBERTa <ref type="bibr" coords="1,363.76,568.00,23.19,10.91">[5, 6?</ref> ] and used a novel window striding approach to handle the long documents which were given in the training data. This trained model was then used to get predictions for the test data. This paper is presented as follows, section 2 about the related works, section 3 describes the dataset, section 4 explains the methodology and system description, and section 5 reports on the experiments and results. This is followed by the conclusion and some outlook on future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The ease of social media data availability had made Fake news analysis and detection gain attention. The primary reason is that they need to reduce the spread of unauthentic news propagating through their platform. Many traditional systems are based on machine learning methods to classify fake and authentic information. Still, their performance is not so accurate because of the inability to understand the context of the data. With the advent of different deep learning methods, they have become an integral part of most designs. We have analyzed recent works incorporating deep learning models and other methods explained below.</p><p>Shahi et al. <ref type="bibr" coords="2,153.30,281.08,13.00,10.91" target="#b6">[7]</ref> have done an experimental study of COVID-19 misinformation on Twitter. They have analyzed the propagation, authors, and content of misinformation to gain early insights and categorized tweets into false, partially false, true, and other. They have also found that fake claims disseminate faster than partially false claims. In our previous work <ref type="bibr" coords="2,454.73,321.73,12.68,10.91" target="#b7">[8]</ref> we have used an ensemble of different transformer-based models which try to account for both long and normal-sized text. Shahi et al. <ref type="bibr" coords="2,227.80,348.83,13.00,10.91" target="#b8">[9]</ref> have proposed a benchmark classification dataset for fake news, which had multilingual cross-domain fact-checked news articles for COVID-19, collected from 92 fact-checking websites. Shahi <ref type="bibr" coords="2,259.70,375.93,17.86,10.91" target="#b9">[10]</ref> proposed an annotation framework of multi-modal social media data. They have presented a semi-automated framework for collecting multi-modal annotated data from social media combining machines and humans in the data compilation process. They have also implemented this framework for gathering COVID-19 misinformation. Mehta et al. <ref type="bibr" coords="2,145.27,430.13,17.97,10.91" target="#b10">[11]</ref> have proposed a transformer model for fake news classification of a specific domain dataset, including human justification and metadata for added performance. They have used multiple BERT models with shared weights between them to handle various inputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Dataset Description</head><p>There were two tasks given on the competition website<ref type="foot" coords="2,352.29,514.10,3.71,7.97" target="#foot_0">2</ref> under Fake News Detection by CLEF2022-CheckThat! Lab, namely Multi-class Fake News Detection of news articles (English) and Cross-Lingual Task (German). We were provided with training and validation data in English (only) language, whose classwise details are given in Table <ref type="table" coords="2,387.65,556.50,3.72,10.91" target="#tab_0">1</ref>. We have been given test data in English and German, where German was for the cross-lingual task, Table <ref type="table" coords="2,444.33,570.05,4.97,10.91" target="#tab_0">1</ref> provides the details of the test data.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methodology</head><p>In this shared task, we had Multi-class fake news detection of new articles in English and German, where German is a Cross-Lingual Task; both have to be classified into different labels as given in Figure <ref type="figure" coords="3,171.50,449.91,3.75,10.91" target="#fig_0">1</ref>. The proposed model had steps such as Text Preprocessing, Tokenization, and Model building, whose design is as shown in figure <ref type="figure" coords="3,336.37,463.46,3.78,10.91">2</ref>; a detailed description of each step is explained in the upcoming subsections. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Text Preprocessing and Tokenization</head><p>As the dataset was retrieved from many social media sites, preprocessing was essential before proceeding with model building. Here, we used the clean-text<ref type="foot" coords="4,373.40,324.52,3.71,7.97" target="#foot_1">3</ref> library from python, which helped remove contents like URLs, ASCII conversions, etc. We had 1264 articles in the training data, which were mostly long articles or news. We had to convert these articles to token sequences and pass them on to the models to process them. We have used tokenization methods <ref type="foot" coords="4,89.11,378.72,3.71,7.97" target="#foot_2">4</ref> corresponding to the particular pre-trained model being used. These tokenizers will tokenize according to the structure underlying the respective model. RoBERTa <ref type="bibr" coords="4,402.74,394.02,11.47,10.91" target="#b5">[6]</ref>, BERT <ref type="bibr" coords="4,449.03,394.02,16.29,10.91" target="#b11">[12]</ref>, BigBird <ref type="bibr" coords="4,89.29,407.57,16.25,10.91" target="#b12">[13]</ref>, DeBERTa [? ] are the different models which we have used to build our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Model Architecture</head><p>The transformer-based pre-trained models <ref type="foot" coords="4,273.30,455.54,3.71,7.97" target="#foot_3">5</ref> were used for building our system. The models have been individually trained for data using the pre-trained weights, which give the probabilities for the different labels. We have finetuned the pre-trained models, which had their vocabulary and embeddings with the training data for predictions. The same model configuration is used for test data prediction. The hyperparameters were as per the standard values used for the particular pre-trained model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Data Analysis and Modeling</head><p>We have explored different transformer-based models for building the system. As the articles were long, as shown in Figure <ref type="figure" coords="4,233.55,588.32,3.81,10.91">3</ref>, we concentrated on bringing the best out of the models, even though most models have a maximum token size of 512. The data analysis shows that the average number of tokens falls within 1000, though few articles had more than 7000. As mentioned previously, we have used models BERT, RoBERTa, and DeBERTa, which all are capable of having a maximum token of 512. Along with them, we have tried the BigBird model, which was designed for long text.</p><p>We have used a window-based striding approach to handle the long articles. The main idea was to leverage the use of pre-trained models for the overall document without losing much information. We have divided the whole document into batches of 500 tokens, with each set of 500 tokens having the same label as the original one. We attempted different overlapping strides over the text, trained the model, and validated it, which gave good results compared to the usual approach. We tried different stride values so that the model could learn better without losing the entire context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments and Results</head><p>We have fine-tuned the pre-trained models for the training data using AdamW <ref type="bibr" coords="5,431.16,267.54,17.75,10.91" target="#b13">[14]</ref> and learning rate 3e-5. We used the cross-entropy loss as the loss function. The experiments were performed on Kaggle, Tesla V100 16GB GPU. The learning rate was the same for all models and trained for five epochs, with callbacks on validation loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Results of Different Models</head><p>This subsection will discuss the individual model results for English on the validation data. As far as the cross-lingual task is concerned, we used the best model, which gave good results on English data. The different model results are shown in Table <ref type="table" coords="5,379.74,385.01,3.81,10.91" target="#tab_1">2</ref>. Here we can observe that DeBERTa is the best model among all the others, giving an overall F1 score of 0.9893. DeBERTa model with a stride of 0.9 means we are overlapping 90% of the tokens of different batches and combining the result as the final label for an article during training. As the DeBERTa model with stride 0.9 gave the best results, we employed the same value for different models, whose results are also included in Table <ref type="table" coords="5,237.75,452.75,3.74,10.91" target="#tab_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Result of Model on Test Data</head><p>Here we will discuss our results on test data. We have submitted the system for testing, which gave the best result on validation data to the shared task, whose results are as shown in Table <ref type="table" coords="5,500.35,655.15,3.66,10.91" target="#tab_2">3</ref>.</p><p>We got an F1 score of 0.2980, which was placed at 7 th position on the leaderboard with the best score of 0.3391. In the case of cross-lingual task with German data, we got an F1 score of 0.2245, which was placed at 2 nd position on the leaderboard with the best score of 0.2898. The final leaderboard for the two subtasks are published here 6 . We further analyzed the test data to improve the results after the publication of the final leaderboard, but we were not able to improve due to time constraints. The distribution of test data shows that it had more 'true' labels, which could be a problem for our model performance degradation because the distribution was different for training and validation data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Work</head><p>Nowadays, people consider social media as the primary source of news. Hence, verified and accurate information must be propagated through social media, which is not always the case. In this paper, we have concentrated on building a model that can classify long news articles from social media comprising politics, entertainment, COVID-19, etc., as fake or not. We have used a novel window-based method to fine-tune the transformer-based models like DeBERTa, RoBERTa, etc., which helped to have a model that can handle long text documents. In the future, we would like to extend our work further to improve the results so that the model can perform even on different distributions of datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,281.55,221.04,8.93;3,160.24,84.19,272.30,184.80"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Distibution of Training and Validation Data</figDesc><graphic coords="3,160.24,84.19,272.30,184.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,89.29,617.29,99.45,8.93;3,89.29,499.72,416.69,93.05"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Model Design</figDesc><graphic coords="3,89.29,499.72,416.69,93.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,314.70,258.23,59.44"><head>Table 1 Test</head><label>1</label><figDesc></figDesc><table coords="3,108.11,326.71,239.11,47.44"><row><cell>Data</cell><cell></cell></row><row><cell cols="2">Language # of articles</cell></row><row><cell>English</cell><cell>612</cell></row><row><cell>German</cell><cell>586</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,88.99,479.31,325.65,107.26"><head>Table 2 Different</head><label>2</label><figDesc></figDesc><table coords="5,128.58,491.32,286.06,95.26"><row><cell cols="2">Model Results on Validation Data</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell cols="4">Stride Precision Recall F1-Score</cell></row><row><cell></cell><cell>0.5</cell><cell>0.9823</cell><cell>0.9886</cell><cell>0.9854</cell></row><row><cell>DeBERTa</cell><cell>0.7</cell><cell>0.9858</cell><cell>0.9856</cell><cell>0.9855</cell></row><row><cell></cell><cell>0.9</cell><cell>0.9862</cell><cell>0.9928</cell><cell>0.9893</cell></row><row><cell>RoBERTa</cell><cell></cell><cell>0.9728</cell><cell>0.9833</cell><cell>0.9778</cell></row><row><cell>XLM-RoBERTa</cell><cell>0.9</cell><cell>0.9332</cell><cell>0.9454</cell><cell>0.9390</cell></row><row><cell>BigBird</cell><cell></cell><cell>0.9666</cell><cell>0.9699</cell><cell>0.9681</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.99,197.27,321.23,59.63"><head>Table 3</head><label>3</label><figDesc></figDesc><table coords="6,89.29,209.27,320.93,47.63"><row><cell>Results on Test Data</cell><cell></cell><cell></cell></row><row><cell cols="3">Language Precision Recall</cell><cell>F1-Score</cell></row><row><cell>English</cell><cell>0.3804</cell><cell cols="2">0.3140 0.2980 (7 ùë°‚Ñé position)</cell></row><row><cell>German</cell><cell>0.3342</cell><cell cols="2">0.2785 0.2245 (2 ùëõùëë position)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,108.93,670.89,180.93,8.97"><p>https://codalab.lisn.upsaclay.fr/competitions/4633</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="4,108.93,649.10,127.66,8.97"><p>https://pypi.org/project/clean-text/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="4,108.93,660.05,196.53,8.97"><p>https://huggingface.co/docs/tokenizers/python/latest/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="4,108.93,671.01,107.31,8.97"><p>http://huggingface.co/models</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,112.66,471.84,393.98,10.91;6,112.41,485.39,394.76,10.91;6,112.66,501.38,91.42,7.90" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,239.95,471.84,178.02,10.91">The spread of true and false news online</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename></persName>
		</author>
		<idno type="DOI">10.1126/science.aap9559</idno>
		<ptr target="https://science.sciencemag.org/content/359/6380/1146.doi:10.1126/science.aap9559" />
	</analytic>
	<monogr>
		<title level="j" coord="6,426.23,471.84,33.12,10.91">Science</title>
		<imprint>
			<biblScope unit="volume">359</biblScope>
			<biblScope unit="page" from="1146" to="1151" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.66,512.49,394.53,10.91;6,112.33,526.04,394.85,10.91;6,112.66,539.59,393.33,10.91;6,112.66,553.14,394.52,10.91;6,112.66,566.68,393.33,10.91;6,112.28,580.23,394.91,10.91;6,112.66,593.78,89.12,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,432.00,539.59,73.99,10.91;6,112.66,553.14,390.20,10.91">Overview of the CLEF-2022 CheckThat! lab on fighting the COVID-19 infodemic and fake news detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barr√≥n-Cede√±o</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Stru√ü</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>M√≠guez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beltr√°n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>K√∂hler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,126.92,566.68,379.07,10.91;6,112.28,580.23,390.55,10.91">Proceedings of the 13th International Conference of the CLEF Association: Information Access Evaluation meets Multilinguality, Multimodality, and Visualization, CLEF &apos;2022</title>
		<meeting>the 13th International Conference of the CLEF Association: Information Access Evaluation meets Multilinguality, Multimodality, and Visualization, CLEF &apos;2022<address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.66,607.33,394.53,10.91;6,112.33,620.88,394.85,10.91;6,112.66,634.43,393.32,10.91;6,112.66,647.98,394.53,10.91;6,105.65,669.47,2.78,5.98;6,108.93,671.04,224.31,8.97;7,112.66,86.97,395.17,10.91;7,112.66,100.52,193.11,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,272.14,634.43,233.84,10.91;6,112.66,647.98,154.75,10.91">The clef-2022 checkthat! lab on fighting the covid-19 infodemic and fake news detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barr√≥n-Cede√±o</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Stru√ü</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>M√≠guez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beltr√°n</surname></persName>
		</author>
		<ptr target="https://codalab.lisn.upsaclay.fr/competitions/4633#participateK" />
	</analytic>
	<monogr>
		<title level="m" coord="7,272.10,86.97,151.66,10.91">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>N√∏rv√•g</surname></persName>
		</editor>
		<editor>
			<persName><surname>Setty</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="416" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,114.06,393.33,10.91;7,112.66,127.61,393.59,10.91;7,112.66,141.16,382.34,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,452.21,114.06,53.78,10.91;7,112.66,127.61,266.01,10.91">Overview of the CLEF-2022 CheckThat! lab task 3 on fake news detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>K√∂hler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Stru√ü</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sch√ºtz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,401.42,127.61,104.83,10.91;7,112.66,141.16,286.23,10.91">Working Notes of CLEF 2022-Conference and Labs of the Evaluation Forum, CLEF &apos;2022</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,154.71,394.53,10.91;7,112.66,168.26,394.53,10.91;7,112.66,181.81,393.33,10.91;7,112.66,195.36,253.34,10.91" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<title level="m" coord="7,309.90,181.81,196.09,10.91;7,112.66,195.36,123.30,10.91">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,208.91,394.53,10.91;7,112.30,222.46,394.97,10.91;7,112.66,236.01,256.43,10.91" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<ptr target="https://github.com/pytorch/fairseq.arXiv:1907.11692" />
		<title level="m" coord="7,172.90,222.46,276.19,10.91">RoBERTa: A robustly optimized BERT pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,249.56,393.33,10.91;7,112.66,263.11,283.01,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,292.17,249.56,213.82,10.91;7,112.66,263.11,42.26,10.91">An exploratory study of covid-19 misinformation on twitter</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dirkson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Majchrzak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,162.86,263.11,154.86,10.91">Online Social Networks and Media</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">100104</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,276.66,393.53,10.91;7,112.66,290.20,223.53,10.91" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">R</forename><surname>Lekshmiammal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Madasamy</surname></persName>
		</author>
		<title level="m" coord="7,283.29,276.66,222.91,10.91;7,112.66,290.20,149.24,10.91">Nitk_nlp at checkthat! 2021: Ensemble transformer model for fake news classification</title>
		<imprint>
			<publisher>CLEF</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,303.75,393.33,10.91;7,112.66,317.30,393.33,10.91;7,112.66,330.85,387.87,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,220.22,303.75,285.77,10.91;7,112.66,317.30,49.79,10.91">FakeCovid -a multilingual cross-domain fact check news dataset for covid-19</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nandini</surname></persName>
		</author>
		<ptr target="http://workshop-proceedings.icwsm.org/pdf/2020_14.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="7,183.76,317.30,322.22,10.91;7,112.66,330.85,73.20,10.91">Workshop Proceedings of the 14th International AAAI Conference on Web and Social Media</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,344.40,393.59,10.91;7,112.66,357.95,146.44,10.91" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.00502</idno>
		<title level="m" coord="7,168.48,344.40,305.06,10.91">Amused: An annotation framework of multi-modal social media data</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,112.66,371.50,393.32,10.91;7,112.66,385.05,395.01,10.91;7,112.66,398.60,174.74,10.91" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="7,354.08,371.50,151.90,10.91;7,112.66,385.05,119.12,10.91">A transformer-based architecture for fake news classification</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dwivedi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Patra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">‚Ä¢</forename><forename type="middle">M</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13278-021-00738-y</idno>
		<ptr target="https://doi.org/10.1007/s13278-021-00738-y.doi:10.1007/s13278-021-00738-y" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">39</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,412.15,395.17,10.91;7,112.66,425.70,344.59,10.91" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="7,289.64,412.15,218.19,10.91;7,112.66,425.70,165.11,10.91">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><forename type="middle">C</forename><surname>Kenton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kristina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:arXiv:1810.04805v2</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,439.25,394.53,10.91;7,112.28,452.79,393.70,10.91;7,112.66,466.34,232.48,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,265.85,452.79,189.59,10.91">Big bird: Transformers for longer sequences</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Guruganesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">A</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ainslie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ontanon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ravula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,463.76,452.79,42.22,10.91;7,112.66,466.34,187.69,10.91">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,479.89,395.01,10.91;7,112.66,495.88,97.35,7.90" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05101</idno>
		<title level="m" coord="7,262.02,479.89,203.76,10.91">Decoupled weight decay regularization</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
