<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,357.17,15.42;1,89.29,106.66,73.92,15.43">Early detection of depression using BERT and DeBERTa</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,113.56,11.96"><forename type="first">Sreegeethi</forename><surname>Devaguptam</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">National Institute of Technology Surathkal</orgName>
								<address>
									<region>Karnataka</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,214.77,134.97,87.47,11.96"><forename type="first">Thanmai</forename><surname>Kogatam</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">National Institute of Technology Surathkal</orgName>
								<address>
									<region>Karnataka</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,314.05,134.97,69.63,11.96"><forename type="first">Nishka</forename><surname>Kotian</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">National Institute of Technology Surathkal</orgName>
								<address>
									<region>Karnataka</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,411.14,134.97,69.09,11.96"><forename type="first">Anand</forename><surname>Kumar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">National Institute of Technology Surathkal</orgName>
								<address>
									<region>Karnataka</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,357.17,15.42;1,89.29,106.66,73.92,15.43">Early detection of depression using BERT and DeBERTa</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">0282933CED7D86A4E011494073B62968</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Natural Language Processing</term>
					<term>BERT</term>
					<term>DeBERTa</term>
					<term>transfer learning</term>
					<term>text augmentation</term>
					<term>social media</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In today's world, social media usage has become one of the most fundamental human activities. On the report of Oberlo, at present, 3.2 billion people are on social media, which comprises 42% of the World's population. People usually post about their daily life style, special occasions, views about on-going issues and their networks on the social media platforms. People also share things on social media which otherwise would not have shared with other people. Social media helps us to stay connected, keep informed, mobilise on social issues. Due to the surge of suicide attempts, social media can act as a life saver in detecting and tracing users who are on the verge of depression and self-harm. Natural language processing methods with the help of deep learning are aiding in solving language/text related real world problems like sentiment analysis, translation of text into different languages, depression detection. Many transformer based models like BERT (Bidirectional Encoders Representations from Transformers) are put to use to solve NLP problems, which voluntarily learns to attend to different features differently (Weighing). In this paper, a supervised machine learning algorithm with transfer learning approach is used to detect self-harm tendency in the social media users at the earliest.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Major depressive disorder, often known as clinical depression, is a mood condition that affects how you feel and creates a permanent feeling of melancholy and loss of interest. Depression has an impact on how a person feels, thinks, and acts, and can result in a number of emotional and physical issues. According to the World Health Organization's 2020 report, about 264 million people worldwide suffer from depression. It is critical to have it checked; otherwise, there is a risk of depression worsening over time, leading to self-harm or suicide. Major depressive episodes are most common in adolescents aged 12 to 17 years, followed by young adults aged 18 to 25 years, and are rare in people over the age of 50 according to the Substance Abuse and Mental Health Services Association, 2018. Various help lines and mental health awareness initiatives have been established to minimise the suicide rate and to assist persons suffering from depression. Because of modern gadgets, social media networks, and lifestyle, people's behaviours have changed. Millennials prefer to text rather than converse on the phone or face to face. According to a poll of 500 millennials conducted by OpenMarket, "75% of millennials would rather lose the capacity to converse than text". With the growth of social media, there are now a plethora of websites and channels where individuals freely discuss their depression difficulties and battles. People can share their tales regarding despair, attempted suicide, and other self-harm occurrences in support groups. People prefer to text/write about sadness on social media rather than seek professional treatment, and some even prefer to chat to Bots. We now have some textual data that may be rescued for early diagnosis of depression/self-harming inclinations thanks to social media outlets. Textual data has certain hidden patterns and styles that can be used to identify an author or even gender. Depressed people can be identified using some tools of Natural Language processing. Depressed persons can perhaps be diagnosed using natural language processing techniques before their condition worsens or they self-harm, thanks to improved natural language processing methodologies and tools.</p><p>The goal of Early Depression Detection (EDD) is to track a user's messages over time in chronological sequence and determine whether or not the user is depressed early enough to intervene and provide assistance. There haven't been any diversified solutions to the specific challenge to check from other datasets due to the lack of distinct public datasets relating early diagnosis of depression in internet users based on their writings and also feed on their social media accounts. For EDD, researchers have employed Natural Language methods combined with ensemble classifiers, but only a few have attempted to address the problem using cuttingedge deep learning models. Although a machine learning model cannot replace a professional therapist or psychiatrist, not everyone has access to one, and with the proliferation of social media and textual data, a smart model can assist internet users. In this paper, deep learning models are trained for early detection of depression based on texts taken from reddit in chronological order. This paper follows the approach of fine tuning BERT and DeBERTa models along with data augmentation to get a balanced dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Self-harm detection has got the limelight in deep learning domain as it directly affects the lives of the people. This has attracted many scholars and researchers to work on this problem. There is a huge contribution made in detection of self-harm <ref type="bibr" coords="2,329.05,457.22,11.35,10.91" target="#b7">[8,</ref><ref type="bibr" coords="2,343.13,457.22,7.56,10.91" target="#b8">9]</ref>. Many of the papers have been on different ML (Machine Learning) algorithms in addition with transfer learning models <ref type="bibr" coords="2,474.80,470.77,11.36,10.91" target="#b5">[6,</ref><ref type="bibr" coords="2,488.88,470.77,7.57,10.91" target="#b6">7]</ref>.</p><p>Yueh-Ming Tai et al. <ref type="bibr" coords="2,197.14,484.32,13.10,10.91" target="#b0">[1]</ref> has collected the medical data and eight other factors of Taiwan Soldiers and people admitted in hospitals due to mental disorders like age, depression status, family and community history with depression related problems . They have used Artificial Neural Networks (ANN) algorithm called Radial Basis Function (RBF) models to detect self-harm history and suicide attempt history. Taru Jain et al. <ref type="bibr" coords="2,319.79,538.52,12.89,10.91" target="#b1">[2]</ref> has taken tweets from Twitter as their dataset and trained Adversarial Machine Learning algorithm. The paper also talks about the detection of character and word level detection of the self-harm risk. In Adversarial training, they have used augmentation with GANs like SentiGAN.</p><p>A. Benton et al. <ref type="bibr" coords="2,176.56,592.72,13.10,10.91" target="#b2">[3]</ref> proposes a model which considers the demographic attributes along with mental attributes of a person under study. It has deployed Multi-task Learning (MTL) Framework and logistic regression to detect the onset of different neurological problems in a person. Pratool Bharti et al. <ref type="bibr" coords="2,213.56,633.36,12.65,10.91" target="#b3">[4]</ref> uses watch dog model which has three important phases in the detection of self harm risk of a person likely being an accelerometer is given to every studied user to wear it on wrist, developing an to predict whether a person is active/lazy and deploying a machine learning algorithms like random forest classification which can detect the self harm risk in a person.</p><p>Parallel efforts have been made to develop strong strategies to improve the robustness of AI systems. Prior research has included word recognition models <ref type="bibr" coords="3,393.40,127.61,16.58,10.91" target="#b12">[13]</ref>, <ref type="bibr" coords="3,417.57,127.61,16.58,10.91" target="#b13">[14]</ref>, and denoising auto-encoders <ref type="bibr" coords="3,155.37,141.16,17.97,10.91" target="#b14">[15]</ref> to combat character level attacks. Adversarial training has been proven to be effective for word level perturbations <ref type="bibr" coords="3,276.04,154.71,16.58,10.91" target="#b15">[16]</ref>, and we employ it in our study as well. Other protection strategies include reinforcement learning <ref type="bibr" coords="3,319.78,168.26,17.55,10.91" target="#b16">[17]</ref> and detecting adversarial noise before it has an impact on model predictions <ref type="bibr" coords="3,259.81,181.81,16.25,10.91" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>Two transformer based models were trained to detect early traces of depression. From figure <ref type="figure" coords="3,499.79,240.44,3.70,10.91" target="#fig_0">1</ref>, it can be seen that the dataset provided is quite imbalanced. It contains a much higher number of writings of users who did not have depression compared to those who did. We applied text augmentation to increase the size of data in the positive class and performed downsampling on the negative class. Figure <ref type="figure" coords="3,219.39,294.63,5.11,10.91" target="#fig_2">3</ref> represents the flowchart of our method (a sample paraphrased sentence is used). A description of the techniques used is given below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data Preprocessing</head><p>The first stage is data preprocessing. The writings were cleaned by applying several techniques. Conversion of text to lowercase, removal of urls and html tags, removal of special characters and numbers, stopword removal and substitution of emoticons with their corresponding textual descriptions were included as a part of our preprocessing stage. As most of the writings were within 100 words as seen in Figure <ref type="figure" coords="3,248.28,412.11,3.79,10.91" target="#fig_1">2</ref>, longer posts were split into parts to make sure that the length was below 100.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Data Augmentation</head><p>Data augmentation techniques are used to artificially generate additional data using the available data. It is very widely used in several of the computer vision tasks and can also be used in NLP. Text augmentation is quite challenging as it requires understanding of the context in the sentences. In our method, word level augmentation was applied using the Synonym augmentor from the nlpaug library. The source database used was wordnet and the maximum number of words that would be augmented was set to 20. It simply replaces words with suitable synonyms. This is possibly one of the preferable method in terms of computation cost. Word embedding based augmentation techniques using Glove or even Bert may give better results. Augmentation was done only for the train set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Classification</head><p>Two transformer based models were trained -namely BERT and DeBERTa. These contain stacked transformer blocks each of which contains a self attention head followed by a fully connected feed forward network. After performing the intial steps, the dataset is divided as 80% data for training the data and 20% for validating the data The input textual data is first converted into the required input data format using a tokenizer. Splitting the tokens is handled by the tokenizer i.e., the sequence is split into tokens available in the tokenizer vocabulary. These tokens can be words or subwords. Additionally, it performs truncation and padding to make sure that the maximum length is 100 and adds special tokens. It returns the input ids and the attention mask in tensor format. Once the input data is prepared, it can be used to train the models. Transfer learning technique is used wherein the BERT model which was originally pretrained on bookcorpus and wikipedia data on two tasks i.e language modelling and next sentence prediction is fine tuned on our self harm detection dataset to perform sequence classification. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">BERT</head><p>BERT and other Transformer encoder architectures have proven to be quite effective in a range of NLP tasks. They create natural language vector-space representations that can be used in deep learning models. Attention mechanism is used to learn contextual relations between the words. The context of a word is understood from both the left and right parts surrounding it. These models are pre-trained on a huge corpus of text before being fine-tuned for specific tasks. We have used BERT-base cased model for training the model, which has trained weights of the original BERT model. As we are dealing with the binary classification problem i.e., self-harm or not self-harm, we use binary cross-entropy loss function. For optimization, we have used Adam optimizer (learning_rate=2e-5, epsilon=1e-08) which limits the prediction loss and does regularization by weight decay (not utilizing moments).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">DeBERTa</head><p>DeBERTa improves on the BERT and ROBERTa models. It uses a disentangled attention mechanism where each word is represented in terms of two vectors, one to encode information about the word's position and other about its content. The attention weights are calculated from disentangled matrices on the basis of content and relative arrangement. This is created from the idea that the relative positioning of the words could provide useful information. The dependency between a pair of words could be higher when they occur adjacent to each other. Second, deBERTa uses an enhanced mask decoder which takes into consideration the absolute word positions. Although the relative positional and content are considered by the attention mechanism, it does not take into account the absolute positions which could be pivotal in certain cases. Further, it uses the virtual adversial training regularization technique to improve the performance. It is incorporated right before the softmax layer. This helps to prevent over-fitting and improve generalization. We used SparseCategoricalCrossentropy as the loss function, Adam as the optimizer (learning_rate=2e-05, epsilon=1e-06) and accuracy as the metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>Table <ref type="table" coords="6,115.34,111.28,4.98,10.91" target="#tab_0">1</ref> contains the performance evaluation results that were obtained. For run 0, BERT model without text augmentation is used, run 1 uses DeBERTa model without text augmentation, run 2 uses BERT model with text augmentation and run 3 uses DeBERTa model with text augmentation. The system fires an alert when the last user post is classified as positive. Comparing the results from these runs it can be found that the highest Recall value was obtained using deBERTa when augmentation was not used while the highest F1 was obtained using deBERTa with augmentation technique. ERDE values were found to be greater in run 2. These values though are not very ideal and there is scope for improvement. There was a considerable time lapse of 01:52:57 while processing the writings which is not optimal. The low number of writings processed (6) may have not been able to give a good idea about the overall model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions and Future work</head><p>In this experiment a unique text augmentation method was applied to create additional samples of posts with signs of depression in order to create a balanced dataset. This was done after random downsampling on the negative class. As seen from the results, majority of the performance metrics did not show a great change between the models trained with and without augmentation. The two different transformer models used showed only minor differences in terms of performance. Due to limitations on computing resources the models were trained only for one epoch and also substantial amount of data was removed during the downsampling process applied for the negative class. We have only explored one of the many text augmentation methods. The augmentation process can be refined by creating a pipeline of several different augmentors as well as by the use of more advanced techniques that can take into account the context in the sentences. These aspects can be considered to improve the experiment in the future. Ultimately, the development of an efficient tool that can accurately identify signs of depression from posts can be very beneficial and could be integrated to social media platforms. Further to improve upon the work, an explainable AI model can be developed so that the predicted result can be interpreted and can give an idea about why a post is classified into that particular class.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,602.66,212.29,8.93;3,198.43,448.37,198.42,141.73"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Pie chart of number of users in each class</figDesc><graphic coords="3,198.43,448.37,198.42,141.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,89.29,266.84,149.14,8.93;4,170.08,84.19,255.12,170.08"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Histogram of post lengths</figDesc><graphic coords="4,170.08,84.19,255.12,170.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,89.29,251.42,203.31,8.93;5,89.29,84.19,416.68,154.66"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Flowchart for classification using BERT</figDesc><graphic coords="5,89.29,84.19,416.68,154.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,88.99,258.17,400.66,86.90"><head>Table 1</head><label>1</label><figDesc>Decision based evaluation result</figDesc><table coords="6,105.63,258.17,384.02,57.09"><row><cell>Run</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell cols="4">ERDE5 ERDE50 latencyTP speed latency-weightedF1</cell></row><row><cell>0</cell><cell cols="3">0.138 0.796 0.235</cell><cell>0.047</cell><cell>0.039</cell><cell>2.0</cell><cell>0.996</cell><cell>0.234</cell></row><row><cell>1</cell><cell cols="3">0.135 0.806 0.231</cell><cell>0.047</cell><cell>0.039</cell><cell>2.0</cell><cell>0.996</cell><cell>0.230</cell></row><row><cell>2</cell><cell cols="3">0.132 0.786 0.225</cell><cell>0.050</cell><cell>0.040</cell><cell>2.0</cell><cell>0.996</cell><cell>0.225</cell></row><row><cell>3</cell><cell cols="3">0.149 0.724 0.248</cell><cell>0.049</cell><cell>0.039</cell><cell>2.0</cell><cell>0.996</cell><cell>0.247</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,107.59,111.28,400.25,10.91;7,107.59,124.83,400.24,10.91;7,107.59,138.38,209.50,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,259.13,111.28,248.70,10.91;7,107.59,124.83,157.93,10.91">Artificial Neural Network Analysis on Suicide and Self-Harm History of Taiwanese Soldiers</title>
		<author>
			<persName coords=""><forename type="first">Yueh-Ming</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hung-Wen</forename><surname>Chiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,272.38,124.83,235.45,10.91;7,107.59,138.38,143.99,10.91">Second International Conference on Innovative Computing, Information and Control</title>
		<imprint>
			<publisher>ICICIC</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.59,151.93,398.40,10.91;7,107.59,165.48,291.73,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,158.78,151.93,293.97,10.91">Adversarial Machine Learning for Self Harm Disclosure Analysis</title>
		<author>
			<persName coords=""><forename type="first">Taru</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,484.09,151.93,21.90,10.91;7,107.59,165.48,286.48,10.91">IEEE Sixth International Conference on Multimedia Big Data (BigMM)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.59,179.03,400.24,10.91;7,107.59,192.57,398.40,10.91;7,107.59,206.12,400.08,10.91;7,107.34,219.67,83.73,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,317.30,179.03,190.53,10.91;7,107.59,192.57,157.61,10.91">Multitask learning for mental health conditions with limited social media data</title>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Benton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,272.22,192.57,233.77,10.91;7,107.59,206.12,265.13,10.91">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<title level="s" coord="7,429.90,206.12,55.07,10.91">Long Papers</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017-04">Apr. 2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="152" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.59,233.22,398.40,10.91;7,107.59,246.77,398.39,10.91;7,107.59,260.32,157.49,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,476.71,233.22,29.28,10.91;7,107.59,246.77,322.91,10.91">Watch dog : Detecting Self-Harming Activities from Wrist Worn Accelerometers</title>
		<author>
			<persName coords=""><forename type="first">Pratool</forename><surname>Bharti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anurag</forename><surname>Panwar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ganesh</forename><surname>Gopalakrishna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sriram</forename><surname>Chellappan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,437.96,246.77,68.02,10.91;7,107.59,260.32,153.04,10.91">IEEE Journal of Biomedical and Health Informatics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.59,273.87,398.40,10.91;7,107.59,287.42,337.56,10.91" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="7,358.03,273.87,147.96,10.91;7,107.59,287.42,277.53,10.91">Predicting Sign of Depression via Using Frozen Pre-trained Models and Random Forest Classifier</title>
		<author>
			<persName coords=""><forename type="first">Hassan</forename><surname>Alhuzali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tianlin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
		<imprint/>
		<respStmt>
			<orgName>CLEF eRisk</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.59,300.97,398.40,10.91;7,107.59,314.52,370.25,10.91" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="7,176.33,300.97,329.66,10.91;7,107.59,314.52,338.33,10.91">Bioinfo@ uavr at erisk 2020: on the use of psycholinguistics features and machine learning for the classification and quantification of mental diseases</title>
		<author>
			<persName coords=""><forename type="first">Lu´ıs</forename><surname>Oliveira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.59,328.07,398.68,10.91;7,107.59,341.62,374.48,10.91" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Martínez-Castaño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amal</forename><surname>Htait</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Leif</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yashar</forename><surname>Moshfeghi</surname></persName>
		</author>
		<title level="m" coord="7,461.22,328.07,45.04,10.91;7,107.59,341.62,342.56,10.91">Early risk detection of self-harm and depression severity using bert-based transformers</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.59,355.17,399.68,10.91;7,107.06,368.71,398.92,10.91;7,107.59,382.26,399.99,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,107.06,368.71,328.05,10.91">What Twitter profile and posted images reveal about depression and anxiety</title>
		<author>
			<persName coords=""><forename type="first">Chandra</forename><surname>Sharath</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Guntuku</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Johannes</forename><forename type="middle">C</forename><surname>Preotiuc-Pietro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lyle</forename><forename type="middle">H</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,441.85,368.71,64.13,10.91;7,107.59,382.26,262.03,10.91">Proceedings of the international AAAI conference on web and social media</title>
		<meeting>the international AAAI conference on web and social media</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="236" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,107.59,395.81,398.40,10.91;7,107.59,409.36,400.24,10.91;7,107.59,422.91,398.40,10.91;7,107.59,436.46,398.39,10.91;7,107.59,450.01,128.91,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,205.37,409.36,302.45,10.91;7,107.59,422.91,22.65,10.91">Detecting depression in social media using fine-grained emotions</title>
		<author>
			<persName coords=""><forename type="first">Mario</forename><surname>Ezra Aragón</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Pastor López-Monroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luis</forename><surname>Carlos González-Gurrola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manuel</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,134.77,422.91,371.21,10.91;7,107.59,436.46,275.50,10.91">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1481" to="1486" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="7,112.66,463.56,393.33,10.91;7,107.59,477.11,303.80,10.91" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="7,347.61,463.56,158.38,10.91;7,107.59,477.11,219.25,10.91">Early Risk Detection of Pathological Gambling, Self-Harm and Depression Using BERT</title>
		<author>
			<persName coords=""><forename type="first">Ana-Maria</forename><surname>Bucur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Cosma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liviu</forename><forename type="middle">P</forename><surname>Dinu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>CLEF eRisk</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,490.66,395.17,10.91;7,107.59,504.21,398.39,10.91;7,107.59,517.76,117.11,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,141.58,504.21,364.40,10.91;7,107.59,517.76,33.76,10.91">NLP-UNED at eRisk 2021: self-harm early risk detection with TF-IDF and linguistic features</title>
		<author>
			<persName coords=""><forename type="first">Elena</forename><surname>Campillo-Ageitos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hermenegildo</forename><surname>Fabregat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lourdes</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Juan</forename><surname>Martinez-Romo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,148.30,517.76,50.98,10.91">CLEF eRisk</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,531.30,393.33,10.91;7,107.59,544.85,398.69,10.91;7,107.59,558.40,240.23,10.91" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="7,171.71,544.85,334.56,10.91;7,107.59,558.40,156.40,10.91">uOttawa at eRisk 2021: Automatic Filling of the Beck&apos;s Depression Inventory Questionnaire using Deep Learning</title>
		<author>
			<persName coords=""><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ruba</forename><surname>Skaik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prasadith</forename><surname>Buddhitha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dimo</forename><surname>Angelov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maxwell</forename><forename type="middle">Thomas</forename><surname>Fredenburgh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>CLEF eRisk</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,571.95,393.33,10.91;7,107.18,585.50,184.19,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,311.73,571.95,194.25,10.91;7,107.18,585.50,129.16,10.91">Lipton : Combating adversarial misspellings with robust word recognition</title>
		<author>
			<persName coords=""><forename type="first">Danish</forename><surname>Pruthi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zachary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,243.53,585.50,16.81,10.91">ACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,599.05,395.17,10.91;7,107.59,612.60,398.40,10.91;7,107.20,626.15,367.04,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,433.83,599.05,74.01,10.91;7,107.59,612.60,247.93,10.91">Robsut wrod reocginiton via semi-character recurrent neural network</title>
		<author>
			<persName coords=""><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,364.08,612.60,141.91,10.91;7,107.20,626.15,190.95,10.91">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017-09">February 4-9 2017. 2017</date>
			<biblScope unit="page" from="3281" to="3287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,639.70,393.33,10.91;7,107.59,653.25,85.40,10.91" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="7,370.14,639.70,135.84,10.91;7,107.59,653.25,55.98,10.91">Towards robust toxic content classification</title>
		<author>
			<persName coords=""><forename type="first">Keita</forename><surname>Kurita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anna</forename><surname>Belova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonios</forename><surname>Anastasopoulos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,666.80,393.32,10.91;8,107.59,86.97,398.40,10.91;8,107.59,100.52,348.30,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,373.42,666.80,132.56,10.91;8,107.59,86.97,324.62,10.91">Is bert really robustƒ a strong baseline for natural language attack on text classification and entailment</title>
		<author>
			<persName coords=""><forename type="first">Di</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhijing</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joey</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,439.56,86.97,66.43,10.91;8,107.59,100.52,205.99,10.91">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020-04">04 2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8018" to="8025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,114.06,395.17,10.91;8,107.59,127.61,398.40,10.91;8,107.59,141.16,398.40,10.91;8,107.59,154.71,400.08,10.91;8,107.59,168.26,95.04,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="8,424.42,114.06,83.41,10.91;8,107.59,127.61,333.47,10.91">LexicalAT: Lexicalbased adversarial reinforcement training for robust sentiment classification</title>
		<author>
			<persName coords=""><forename type="first">Jingjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hanqi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qi</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yun</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,451.71,127.61,54.28,10.91;8,107.59,141.16,398.40,10.91;8,107.59,154.71,378.55,10.91">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Nat-ural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Nat-ural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019-11">Nov. 2019</date>
			<biblScope unit="page" from="5518" to="5527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,181.81,395.17,10.91;8,107.59,195.36,370.44,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="8,365.36,181.81,142.47,10.91;8,107.59,195.36,265.03,10.91">Learning to discriminate perturbations for blocking adversarial attacks in text classification</title>
		<author>
			<persName coords=""><forename type="first">Yichao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jyun-Yu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,379.34,195.36,67.63,10.91">EMNLP/IJCNLP</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,208.91,393.33,10.91;8,107.59,222.46,211.29,10.91" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="8,371.61,208.91,134.37,10.91;8,107.59,222.46,155.89,10.91">DeBERTa: Decoding-enhanced BERT with Disentangled Attention</title>
		<author>
			<persName coords=""><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,236.01,395.01,10.91;8,107.59,249.56,398.40,10.91;8,107.59,263.11,335.06,10.91" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<title level="m" coord="8,291.95,249.56,214.03,10.91;8,107.59,263.11,228.48,10.91">Attention Is All You Need, 31st Conference on Neural Information Processing Systems (NIPS 2017)</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,276.66,393.33,10.91;8,107.59,290.20,342.10,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="8,407.72,276.66,98.26,10.91;8,107.59,290.20,273.84,10.91">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,389.04,290.20,35.23,10.91">NAACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,303.75,393.61,10.91;8,107.59,317.30,399.60,10.91;8,107.59,330.85,399.60,10.91;8,107.59,344.40,270.34,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="8,426.33,303.75,79.94,10.91;8,107.59,317.30,196.47,10.91">Overview of eRisk 2022: Early Risk Prediction on the Internet</title>
		<author>
			<persName coords=""><forename type="first">Javier</forename><surname>Parapar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patricia</forename><surname>Martín-Rodilla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,328.48,317.30,178.70,10.91;8,107.59,330.85,399.60,10.91;8,107.59,344.40,45.05,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction. 13th International Conference of the CLEF Association, CLEF 2022</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
