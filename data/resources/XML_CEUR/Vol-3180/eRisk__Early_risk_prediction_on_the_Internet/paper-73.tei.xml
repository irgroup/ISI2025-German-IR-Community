<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,383.35,15.42;1,89.29,106.66,87.64,15.43">Sunday Rockers at eRisk 2022: Early Detection of Depression</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,109.93,11.96"><forename type="first">Raluca-Andreea</forename><surname>GÃ®nga</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Computer Science</orgName>
								<orgName type="institution">University of Bucharest</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,211.86,134.97,124.51,11.96"><forename type="first">Andrei-Alexandru</forename><surname>Manea</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Computer Science</orgName>
								<orgName type="institution">University of Bucharest</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,367.37,134.97,102.46,11.96"><forename type="first">Bogdan-Mihai</forename><surname>Dobre</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Computer Science</orgName>
								<orgName type="institution">University of Bucharest</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,383.35,15.42;1,89.29,106.66,87.64,15.43">Sunday Rockers at eRisk 2022: Early Detection of Depression</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">7937A22240BAE36520A7AA30E56ABA9A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CLEF eRisk</term>
					<term>Sunday Rocker2</term>
					<term>BERT</term>
					<term>Depression</term>
					<term>MixUP</term>
					<term>Voting Classifier</term>
					<term>Support Vector Machines</term>
					<term>XGBoost</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe the participation of Sunday Rockers team at eRisk 2022 on "Early Detection of Depression" task. The main goal of this task is to sequentially process pieces of evidence and detect as quickly as possible early traces of depression. Our approaches for this task varied from using TF-IDF and linguistic statistical features extracted from Reddit writings to using MixUP technique, a new approach for sentence classification to augment the data through interpolation. We obtained our best results with a Voting Classifier with hard voting applied on Text features and with an SVM applied on both textual features and numerical features as well.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The last three decades have brought a huge development of information and communication technology. The advent and proliferation of the Internet have made it possible to create complex global networks of communication and collaboration. These new technologies have transformed the way we learn, communicate and work -they have fundamentally transformed the way we live. This evolution has brought with it various opportunities and benefits from an economic and social point of view, but also the emergence of new challenges.</p><p>One of these challenges is that even though the Internet was not designed with children in mind, many of the users of this environment are children and young people with specific needs and vulnerabilities that need to be recognized. Given the opportunities that the Internet offers in accessing knowledge, the benefits that it can have in developing the skills needed for the 21st century, but also the wide range of risks and dangers to which children may be exposed, it is necessary that decisions taken for the younger generation are based on real needs and current data.</p><p>Generally speaking, social networks gather individuals who have common goals. They were developed rapidly in the last 20 years, becoming the main way to create and maintain virtual relationships. Social networks may be classified by user experience: sharing photos (Pinterest), movies (YouTube, Netflix), thoughts (Facebook, Twitter, Reddit), and others for career management (LinkedIn).</p><p>Although we have access to a lot of information that can be interesting and useful, social networks might also be used to detect certain mental illnesses. A fairly common mental health condition is depression.</p><p>A study by the World Health Organization Evans-Lacko et al. <ref type="bibr" coords="2,389.12,141.16,12.84,10.91" target="#b0">[1]</ref> found that depression affects about 121 million people worldwide. It is estimated that annually, 3-15% of the general population has a depressive episode, of which 0.4 -5% are severe depressive episodes. In Europe, 58 out of 1,000 adults have a major depressive disorder (33.4 million people). All these worrying numbers have made depression one of the most studied mental disorders at the moment.</p><p>Early detection of depression can help mitigate these threats, but most studies on early detection are based on patient diagnoses based on questionnaires or reported experiences Halfin <ref type="bibr" coords="2,89.29,236.01,12.84,10.91" target="#b1">[2]</ref> that are financially expensive and time-consuming, and a major part of some countries with a public health system do not have the necessary support for these diagnoses. Fortunately, social media can come to our aid with a solution to this problem, as many studies have been able to easily extract the data and content of social media posts to analyze and predict the mental well-being of a user (Choudhury et al. <ref type="bibr" coords="2,262.04,290.20,11.44,10.91" target="#b2">[3]</ref>, Moreno et al. <ref type="bibr" coords="2,342.08,290.20,11.44,10.91" target="#b3">[4]</ref>, Sadeque et al. <ref type="bibr" coords="2,424.12,290.20,11.44,10.91" target="#b4">[5]</ref>, Schwartz et al. <ref type="bibr" coords="2,89.29,303.75,11.09,10.91" target="#b5">[6]</ref>).</p><p>In this paper, we present the 5 models for "Early Detection of Depression" task that we sent to the eRisk 2022 edition <ref type="bibr" coords="2,205.47,330.85,11.58,10.91" target="#b6">[7]</ref>. The main goal of this task is to sequentially process pieces of evidence and detect as quickly as possible early traces of depression. Our approaches for this task varied from using TF-IDF and linguistic statistical features extracted from Reddit writings to using MixUP technique, a new approach for sentence classification to augment the data through interpolation.</p><p>The rest of the paper is organized as follows. In section 2, the related work is introduced. In section 3 the eRisk 2022 task is described, along with the origin of the datasets and the problem to be solved. Then, section 4 describes the experiments and methods approached, along with the results obtained in the 5 runs. The paper ends with some conclusions about the best approach and other methods that could be tried in the future for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>There has been significant research in the area of early detection of depression in the scientific community. It was demonstrated that early detection and treatment of depression can alleviate some of the emotional symptoms of depression and lower the costs of care Halfin <ref type="bibr" coords="2,454.36,538.52,11.43,10.91" target="#b1">[2]</ref>.</p><p>The idea that certain patterns in text might be an indication of depression was enforced by many studies. Stirman and Pennebaker Stirman and Pennebaker <ref type="bibr" coords="2,407.15,565.62,12.84,10.91" target="#b7">[8]</ref> discovered a clear predisposition on the side of depressed poets to use self centered words such as "I, me, my". Zinken et al. <ref type="bibr" coords="2,147.39,592.72,12.84,10.91" target="#b8">[9]</ref> showed that depressed individual who were unable to successfully participate in guided self help tend to use less complex syntax and fewer causation words than those who were able to successfully complete the program. That brings us to the conclusion that linguistic markers may not only be useful for detection of depression but also for assessing the severity of the disease.</p><p>Shen et all Shen et al. <ref type="bibr" coords="2,198.01,660.46,17.91,10.91" target="#b9">[10]</ref> proposed an approach to detect depression in the case of Twitter users and, more recently, Jooshi and Kanoongo Joshi and Kanoongo <ref type="bibr" coords="3,395.81,86.97,17.91,10.91" target="#b10">[11]</ref> researched methods for depression detection on Twitter, Facebook and Live Journal.</p><p>There was some research that focused on detecting certain mental illnesses in the case of Reddit users. The study of Shen and Rudzics Shen and Rudzicz <ref type="bibr" coords="3,363.89,127.61,17.91,10.91" target="#b11">[12]</ref> dealt with detecting anxiety at Reddit users and obtained an accuracy of 0.98 and a precision of 0.99 using Neural Networks with lexicon based features and N-grams.</p><p>There has been some research on depression detection and related domains on Reddit. De Choudhury et al. <ref type="bibr" coords="3,185.28,181.81,17.91,10.91" target="#b12">[13]</ref> found some linguistic markers that are associated with users who engage in suicidal ideation such as heightened self-attentional focus and poor linguistic coherence.</p><p>Tadesse et al. <ref type="bibr" coords="3,158.66,222.46,17.91,10.91" target="#b13">[14]</ref> achieved 0.91 accuracy and 0.93 F1 score for the dataset of Reddit users posts from CLEF eRISK 2018 (Conference and Labs of Evaluation Forum for Early Risk Prediction) using a Multilayer Perceptron and LIWC, LDA and bigrams as features. The challenge consisted of sequentially processing the posts of reddit users and flagging potentially depressed users as soon as possible.</p><p>In this paper we will approach a similar task: Early Detection of Depression from CLEF eRisk 2022 workshop, containing eRisk 2017 and 2018 datasets as training datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Task Description</head><p>The Early Detection of Depression task is part of the CLEF eRisk 2022 workshop <ref type="foot" coords="3,454.76,360.62,3.71,7.97" target="#foot_0">1</ref> . This task consists of performing the early detection of the risk of depression by analyzing a series of comments and content published by certain users on the Reddit platform <ref type="foot" coords="3,429.24,387.72,3.71,7.97" target="#foot_1">2</ref> . In this regard, a system receives user-generated content as input and must return a prediction about the likelihood that the user will be prone to depression.</p><p>This challenge consists of sequentially processing evidence and detecting any signs of depression as soon as possible. This task refers to the evaluation of Text Mining solutions and thus focuses on texts written on the Reddit network. Texts must be processed in the order in which they were created.</p><p>The dataset for this task contains the datasets from previous editions of eRisk from 2017 and 2018. The data collection for this task is described in detail in Losada and Crestani <ref type="bibr" coords="3,464.71,497.87,16.29,10.91" target="#b14">[15]</ref>. The dataset consists in a collection of writings (either in the form of posts or comments) from a set of users extracted from Reddit platform. There are two categories of users: depressive (at risk) and non-depressive (control group) and, for each such user, his collection of writings. The task was organized in two different stages:</p><p>â¢ Training phase, in which participants had access to training data (those of 2017 and 2018) with the entire writing history and associated labels (positive or negative) â¢ Test phase, in which participants had to iteratively extract the writings of a number of 2001 users and send the predictions to the eRisk server</p><p>The evaluation was not only based on the correctness of the system result (i.e. whether or not the user was diagnosed with depression), but also on the delay with which this decision was issued and other metrics described in Parapar et al. <ref type="bibr" coords="4,338.72,114.06,16.25,10.91" target="#b15">[16]</ref>.</p><p>The following table 1 contains a general overview of the training set, where "Avg. time span" is the average number of days between the first and the last submission and a submission stands for any post or comment. It can be seen the high imbalance between the positive subjects and the negative subjects, so the first problem of this task was the classes imbalance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We requested the maximum of 5 submissions, presented in the following subsections. Three of the 5 submitted models (Voting Text, XGB Metadata and SVM Combined) were based on 3 variations of the dataset:</p><p>1. Dataset based only on text (i.e. on writings written by different users) -called "Voting</p><p>Text", because we used Voting Ensemble only on the textual features 2. Dataset based on numeric features (detailed in the next subsection) -called "XGB Metadata", since we used an XGBoost only on the numerical features 3. Dataset based on both text and numeric features (ie a combination of the two) -called "SVM Combined", since we used an SVM on this dataset variation (combination of both textual features and numerical features extracted from text as well)</p><p>The other two models were BERTs: one based on Mental-Bert, and the other one based on an augmentation technique for text classification, MixUp.</p><p>In order to see the generalization of our models and have some preliminary results regarding the efficiency of the algorithms developed, we proceeded into a train-test split of the dataset (80% reserved for training, 20% for validation). Both training and validation datasets were saved for further experimenting and ensuring all of the experiments have the same source of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Text Preprocessing</head><p>The datasets formed were based on chunks of 100 writings in order to have a smaller dataset and capture even the writings of some users that are positive (depressed), having writings that don't necessary belong to "depression" category.</p><p>The preprocessing steps consisted in:</p><p>â¢ removing the links from the writings â¢ fixing the contractions (i.e. "I'll" turns into "I will") â¢ removing the "[removed]" comments/posts from Reddit â¢ replacing emoticons and emojis with plain text using FlashText <ref type="foot" coords="5,398.13,216.65,3.71,7.97" target="#foot_2">3</ref> and Emot<ref type="foot" coords="5,447.84,216.65,3.71,7.97" target="#foot_3">4</ref> modules â¢ adding to the existing user writing the emotional affect using NRCLex library <ref type="foot" coords="5,461.81,231.55,3.71,7.97" target="#foot_4">5</ref>â¢ removing the numbers from the posts â¢ ignoring the mentions (using "@" sign) and keeping the words through hashtag â¢ removing the words with less than 3 characters â¢ removing the additional whitespaces</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Features</head><p>We implemented and combined two types of features: 1) TF-IDF-based, and 2) textual-based features (called metadata).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">TF-IDF features</head><p>A TF-IDF vectorizer was trained on the texts. This vectorizer was then used to obtain TF-IDF features with a maximum of 5000 features. These features were passed then on to the classifier. We experimented with different n-grams: unigrams, bigrams and trigrams, but we obtained better performance using only unigrams. We have also tried different variations of TF-IDF analyzers: word and character-based, obtaining better scores on word analyzer. Thus, we continued with unigrams &amp; word analyzers as TF-IDF arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Textual-based features (Metadata)</head><p>For this kind of features, we used different types of text-based features. All of them were normalized by the text length.</p><p>â¢ Language-style features (here we included the total number of words, nouns, adjectives, verbs, adverbs, negations in users' writings, number of question marks, exclamation marks, capitalized words and other punctuation marks.</p><p>Another interesting features belonging to this category are Formality scores, Trager coefficients, readiness to action &amp; aggressiveness coefficients, activity index.</p><p>Formality score Heylighen et al. <ref type="bibr" coords="6,260.69,86.97,17.91,10.91" target="#b16">[17]</ref> measures the degree of formality of a text and the quality of a text in terms of the abundance of a vocabulary. F-measure score is given by the following formula:</p><formula xml:id="formula_0" coords="6,150.24,137.51,355.75,51.46">ð _ðððð ð¢ðð = (ððð¢ðð¹ ððð + ðððð¹ ððð + ððððð¹ ððð + ððð¡ð¹ ððð) 2 - (ððððð¹ ððð + ð£ðððð¹ ððð + ððð£ð¹ ððð + ððð¡ðð¹ ððð) + 100 2<label>(1)</label></formula><p>Trager coefficient, as pronominalisation, measures the stability/instability, dynamism of the text. It is given by the number of verbs divided by the number of nouns.</p><p>Readiness to Action indicates the certainty of some sort of action and the degree of socialization (or expressing ideas to an audience).</p><p>Aggressiveness coefficient is given by the excessive use of verbs or verbs forms in comparison with the rest of words.</p><p>Activity index is given by the number of verbs / (number of verb + adjective + adverbs).</p><p>â¢ User behaviour. Here we included time posting level as a user-related feature, since users with sleep disorders tend to post late at night. That is why because lack of sleep and insomnia occur in 60%-80% of depressed patients Luca et al. <ref type="bibr" coords="6,384.55,331.13,16.25,10.91" target="#b17">[18]</ref>.</p><p>â¢ Self-preoccupation. There are some studies suggesting that people who are using more first-person pronouns on average are more depressed than people who use the third person (Nerbonne <ref type="bibr" coords="6,197.32,382.69,16.21,10.91" target="#b18">[19]</ref>, Edwards and Holtzman <ref type="bibr" coords="6,323.47,382.69,15.63,10.91" target="#b19">[20]</ref>). In this regard, we decided to include another feature that is counting the occurrence of first-number pronouns. Another feature we included was the count of over-generalization, since depressed users tend to overgeneralize and include intense quantifiers, like all, everybody, nobody, everyone, etc.. For example, instead of criticizing, judging a specific category of people, a person may write "All men/women are bad".</p><p>â¢ Reminiscence. Mowery et al. <ref type="bibr" coords="6,244.35,474.89,17.91,10.91" target="#b20">[21]</ref> showed that depressive users tend to make reference to past more frequently than control users. We defined a feature to capture the reference to past called temporal_past, where we counted the number of past tense verbs related to time that were used by the users in their writings.</p><p>â¢ Drugs, feelings (symptoms) and relevant depression lexicon. There is also evidence linking depression to non-suicidal self-harm Greaves <ref type="bibr" coords="6,356.97,553.55,16.27,10.91" target="#b21">[22]</ref>, so tracking this information would prove beneficial for our task. In this regard, we decided to build some dictionaries related to depression-domain: antidepressants, psychoactive drugs, unpleasant feelings and NSSI-words Greaves <ref type="bibr" coords="6,229.38,594.19,16.25,10.91" target="#b21">[22]</ref>.</p><p>-The unpleasant feelings, antidepressant drugs, psychoactive drugs were obtained from Choudhury et al. <ref type="bibr" coords="6,242.76,625.77,17.91,10.91" target="#b22">[23]</ref> and Wikipedia. -The trigrams and 5-grams related to suicide and negative feelings were taken from Colombo et al. <ref type="bibr" coords="6,207.86,654.23,16.25,10.91" target="#b23">[24]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2</head><p>Characteristics and Features extracted from the texts written by users -NSSI-words. We used a word dictionary of terms related to non-suicidal self injury (NSSI words) from Greaves <ref type="bibr" coords="7,267.27,395.21,16.29,10.91" target="#b21">[22]</ref>. This dictionary is divided in several categories: 1) Methods of NSSI; 2) NSSI terms; 3) Instruments used; 4) Reasons for NSSI. We decided to build a feature where we tracked the number of NSSI-related words.</p><p>Table <ref type="table" coords="7,127.03,447.82,5.07,10.91">2</ref> is showing the list of features described above. The correlation between the features is shown in the figure <ref type="figure" coords="7,359.23,461.37,3.66,10.91" target="#fig_0">1</ref>. As we can see, formality metric is in an inverse correlation with the label, so we can assume that the users who are prone to depression write in a more informal way. Readiness to action seems to have a positive and moderate correlation with label, expressing the fact that the users tend to socialize and write long texts on Reddit platform. These features were useful to the prediction in combination with the textual features as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Threshold BERT</head><p>We used a BERT model pretrained Ji et al. <ref type="bibr" coords="7,276.04,578.84,17.91,10.91" target="#b26">[27]</ref> on mental health datasets, including eRisk 2018 and achieved a similar performance with the first BERT. It was modified with a sequence of 2 layers of fully connected neurons, having GELU Hendrycks and Gimpel <ref type="bibr" coords="7,427.59,605.94,17.91,10.91" target="#b27">[28]</ref> as activation function and a dropout of 20%.</p><p>We decided to train only the last 5 layers of the BERT pretrained encoder layers, the BERT pooler and the final classifier. The optimizer was AdamW Loshchilov and Hutter <ref type="bibr" coords="7,446.17,646.58,16.22,10.91" target="#b28">[29]</ref>, with the default parameters, including learning rate of 10 -3 . It also included a scheduler for reducing it So, the second attempt was to train the model with a regression loss, the mean squared error. Also, the learning rate from the optimizer was changed to 2 Ã 10 -5 and ð = 10 -8 .</p><p>The output of this model, can be considered a class probability. In order to provide a classification result, we may choose a threshold ð for a proper class separation. The decision function will be:</p><formula xml:id="formula_1" coords="8,251.55,541.26,90.68,29.86">ð ð (ð¥) = {ï¸ 0 ð¥ â¤ ð 1 ð¥ &gt; ð</formula><p>where we consider ð¥, the output probability of the model. So, having a fixed value of ð, we can collect all the probabilities, ð¥ ð for each chunk from the validation set, and obtain the result ð¦ ^ð = ð ð (ð¥ ð ). Then, we can compute the F1 score for both class 0 and 1. F1 for a class ð represents the harmonic mean of the precision and recall computed solely on the class c. For ð = 0.5, the validation F1 score for class 1 was 19.23%. So we decided to plot the histogram of the probabilities (ð¥ ð ), displayed in figure <ref type="figure" coords="8,449.00,648.68,3.66,10.91" target="#fig_1">2</ref>. In order to find the best separation, we took 100 equidistant values of ð â [0, 1], and chose the one which maximizes the F1 score on positive class. The evolution can be seen in figure <ref type="figure" coords="9,442.42,371.65,5.17,10.91" target="#fig_2">3</ref> and the best parameter found ð = 0.556, obtaining f1_score_0 = 95%, f1_score_1 = 60%. By choosing this value, the model will also ignore the negative cases from the interval [0.5, 0.55], resulting in more confusions, but a better class separation according to the model understanding of the text.</p><p>Another attempts has been made by freezing all BERT layers, but they didn't outcome the first separation result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Voting Text</head><p>In the second run, we decided to use a Voting Classifier on the textual features. Voting Classifier is that type of Machine Learning estimator that is training various base models or estimators and is predicting on the basis of aggregating the findings of each base estimator.</p><p>For this Voting Classifier, we decided to use as estimators: Logistic Regression, Light Gradient Boosting Machines and Support Vector Machines with linear kernel, since we've come to the conclusion that these algorithms provided very good results on the datasets on their own (without using a Voting system).</p><p>To overcome the imbalance present between the classes (depressed -control groups), we added a class weight to each algorithm in order to balance the datasets and provide better results.</p><p>In our case, the Voting Classifier consisted in aggregating the predicted class on basis of hard voting (voting is calculated on the predicted output class). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">XGB Metadata</head><p>In the third run, we used a XGBoost model on the metadata features presented above. It was at first trained on the metadata features extracted from the whole training data. Then, for each new set of user posts received, the complete text for each user from their posts so far was created and the metadata extracted from these texts was used for prediction. Multiple models were evaluated on the metadata extracted from the train data and XGBoost had the best performance, hence it seemed to be the most promising for this approach. The model used the default parameters from the XGBoost Python library, with the exception of scale_pos_weight which had the value 10 in order to control the balance for positive and negative weights. This parameter is important when working with unbalanced datasets like the one in this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">SVM Combined</head><p>In the fourth run, we used a Linear Support Vector Machines Classifier on the textual features + metadata features (numerical features with Standard Scaler transformer applied on them).</p><p>We have also tried other variations of Support Vector Machines algorithm, with different kernels (polynomial, RBF, sigmoid), but linear kernel worked best in our case. This algorithm provided as well the best results on the combined features (texts + numerical). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">MixUp BERT</head><p>The fifth model used was BERT using MixUp technique.</p><p>The MixUp approach, proposed by Zhang et al. <ref type="bibr" coords="11,316.64,273.40,17.91,10.91" target="#b29">[30]</ref> in 2017, is a more innovative one and less explored, especially in image classification field, that brought the best results for image classification tasks.</p><p>Usually, we input a data point ð into a neural network with parameters, obtaining a predicted class/label along with the true label. We also have a loss function that compares what is the output with the true label and then trying to make that loss smaller. Briefly, we want to adjust our parameters such as the next time, the output of ð, to be a little closer to the reality. We are calling this technique Empirical Risk Minimization (ERM), because our data point ð comes from some data distribution ð like the space of all natural images, but what we actually have is a dataset of a finite amount of data that we can sample ð and ð¦ from, so instead of minimizing our true risk, we minimize the empirical risk. What is the problem of ERM? The problem is that we can get overly confident about our data points and nothing else and thus, it will hurt the generalization.</p><p>The paper of Zhang et al. <ref type="bibr" coords="11,211.97,449.54,17.91,10.91" target="#b29">[30]</ref> proposes to train these classifiers on all the data points that are between some two random samples. In mixup technique, it is starting by taking two samples from the dataset and mixing them together, resulting in a data point that's in between the other two samples. This mixing is done in a linear fashion and what is really important is that it is applied both on the feature vectors and the target labels. Coefficient ð is sampled randomly, however, it's always going to be in [0, 1] interval.</p><p>Unlike image which consists of pixels, sentence is composed of a sequence of words. Therefore, a sentence representation is often built to aggregate information from a sequence of words. The first step of text classification is to use the word embedding to convert each word into a vector representation. In our approach, instead of using the traditional encoding methods, we use transformer-based pre-trained language models to learn the representations for text data. The BERT model we've used was fine-tuned with the mixup data augmentation method. Formally, mixup-transformer constructs virtual hidden representations dynamically during the training process as seen in figure <ref type="figure" coords="11,200.50,625.67,3.74,10.91" target="#fig_3">4</ref>.</p><p>In this approach, we used Bert Tokenizer with bert-base-uncased to tokenize the original texts, writings and BERT-base-uncased as BERT model. We trained the model for 5 epochs, with a learning rate of 2 * 10 -5 , using as training dataset the mix-up augmentation of the original training dataset with ð = 0.5. At the end, we added as callback Early Stopping with a patience of 2.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="8,89.29,358.86,217.58,8.93;8,89.29,84.19,416.70,250.16"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Correlation between the features and label</figDesc><graphic coords="8,89.29,84.19,416.70,250.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,89.29,298.02,416.69,9.43;9,89.29,310.03,417.79,8.87;9,89.29,321.71,416.69,9.14;9,89.29,333.67,276.65,9.14;9,89.29,84.19,416.69,194.45"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Histogram of the probabilities (ð¥ ð ) obtained from the best BERT model on the validation set. The most of the negative probabilities have a distribution similar to exponential density function, and most of them lies in the interval of [0.5, 0.55], whereas the outputs from the negative class are are double-normal distributed in the region of [0.5, 0.55] and [0.7, 0.75]</figDesc><graphic coords="9,89.29,84.19,416.69,194.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="10,89.29,333.92,416.69,9.15;10,89.29,346.14,416.69,8.87;10,89.29,358.10,392.52,8.87;10,89.29,84.19,416.69,230.57"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: F1 score evolution on both 0 and 1 class evolution, according to the threshold ð. The significant interval is around [0.5, 0.75] where both scores have are ascending and then descending. The red vertical line representing the best option, which is also the local maxima point for both of the functions.</figDesc><graphic coords="10,89.29,84.19,416.69,230.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="11,89.29,177.55,416.70,9.65;11,89.29,189.50,416.69,9.65;11,89.29,201.73,206.96,8.87;11,129.72,84.19,333.36,86.15"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The overall framework of mixup-transformer, ð¥ ð , ð¥ ð are two separate sentences, fed to the same Transformer ð . ð (ð¥ ð ) is the representation of the input ð¥ ð generated by ð , ð¥ ^and ð¦ ^are the interpolated representation and label, respectively.</figDesc><graphic coords="11,129.72,84.19,333.36,86.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,88.99,197.27,441.73,129.65"><head>Table 1</head><label>1</label><figDesc>General observation of the training dataset</figDesc><table coords="4,95.27,228.89,435.45,98.03"><row><cell>Year</cell><cell>Label</cell><cell cols="4">Num. subjects Num. submissions Avg. num. of. submissions/user Avg. time span</cell></row><row><cell cols="2">2017 negative</cell><cell>752</cell><cell>481837</cell><cell>641</cell><cell>625</cell></row><row><cell cols="2">2017 positive</cell><cell>135</cell><cell>49557</cell><cell>367</cell><cell>587</cell></row><row><cell cols="2">2018 negative</cell><cell>741</cell><cell>504523</cell><cell>681</cell><cell>703</cell></row><row><cell cols="2">2018 positive</cell><cell>79</cell><cell>40665</cell><cell>515</cell><cell>787</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,108.93,660.03,82.03,8.97"><p>https://erisk.irlab.org/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,108.93,670.99,67.61,8.97"><p>https://reddit.com.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,108.93,649.10,115.69,8.97"><p>https://flashtext.readthedocs.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,108.93,660.06,134.92,8.97"><p>https://github.com/NeelShah18/emot</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,108.93,671.01,155.69,8.97"><p>https://github.com/metalcorebear/NRCLex</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We would like to thank our supervisor, <rs type="person">Ana-Sabina Uban</rs>, for the guidance throughout the development of this project.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8.">Results</head><p>The validation results we obtained on our validation data for each model are presented in table <ref type="table" coords="12,89.29,163.37,3.74,10.91">3</ref>. The evaluation results we received from the organizers for the 5 runs are in table <ref type="table" coords="12,456.29,372.64,3.66,10.91">4</ref>. The runs are indexed from 0 to 4. The order in which we used the models for the runs is the following: Threshold BERT, Voting text, XGB Metadata, SVM Combined and MixUpBERT. In terms of F1 score, we can see that the second model, Voting text, achieves the best result of 0.489 while the 2 BERT models have similar performance. The best F1 score achieved by any team was 0.712. In both 2017 and 2018, for the same task, the best F1 score was 0.64.</p><p>Comparing to the other teams on the decision-based metrics, presented in table 4, we had high recall and low precision on the deep models, whereas the others were more balanced. The latency_weighted_f1 of the second model was the 5 ð¡â best in the ranking.</p><p>On the other evaluation metrics, presented in table 5, the 4 ð¡â model reached state-of-the-art performance on 1 writing for P@10 and NDCG@10. The last column tuple is full of zeros,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5</head><p>Results from ranking-based evaluation 1 writings 100 writings 500 writings 1000 writings Team Run P@10 NDCG@10 NDCG@100 P@10 NDCG@10 NDCG@100 P@10 NDCG@10 NDCG@100 P@10 NDCG@10 NDCG@100 Sunday-Rocker2 0 because we submitted only 682 runs. This was due to the inference for the 2 BERT models which was computational expensive. All 682 runs took 4 days and 4 hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper, we presented the contributions of the Sunday Rockers team in the eRisk 2022 "Early Detection of Depression" shared task. We have used a variety of models and techniques, including Transformers, Voting Ensemble &amp; other Machine Learning models using multiple linguistic features. We described 5 solutions: 2 for chunk classification using deep models and 3 for cumulative texts using lighter models. Different from most previous methods, we handcrafted the statistical features and combined them with TF-IDFs.</p><p>Our maximum latency weighted, obtained with the second submission (Voting Text), is ranked on the 5 ð¡â place.</p><p>For future work, we aim to address the issue of severely imbalanced training data and small amount of positive samples by augmentation of texts inserting common sentences or even extracting them from various Depression subreddits from Reddit.</p><p>Moreover, there is a need to optimize the inference of high volume data, especially for deep models. This may be done by deploying the model inference on a special cloud with a high speed transfer. By overcoming this, we would also make use of previous hidden layers of BERT in order to monitor the evolution of the individual mindset.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="13,112.66,656.03,394.53,10.91;13,112.14,669.58,395.05,10.91;14,112.66,86.97,393.33,10.91;14,112.39,100.52,393.60,10.91;14,112.66,114.06,393.33,10.91;14,112.66,127.61,279.75,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="14,434.13,86.97,71.86,10.91;14,112.39,100.52,393.60,10.91;14,112.66,114.06,322.87,10.91">Socio-economic variations in the mental health treatment gap for people with anxiety, mood, and substance use disorders: Results from the who world mental health (wmh) surveys</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Evans-Lacko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Aguilar-Gaxiola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Al-Hamzawi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Benjet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bruffaerts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Florescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>De Girolamo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Gureje</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Haro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Karam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovess</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Levinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Thornicroft</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0033291717003336</idno>
	</analytic>
	<monogr>
		<title level="j" coord="14,444.08,114.06,61.90,10.91;14,112.66,127.61,41.00,10.91">Psychological Medicine</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,141.16,393.33,10.91;14,112.66,154.71,217.91,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="14,161.12,141.16,266.34,10.91">Depression: the benefits of early and appropriate treatment</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Halfin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,440.97,141.16,65.02,10.91;14,112.66,154.71,108.09,10.91">The American journal of managed care</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="92" to="97" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>Suppl</note>
</biblStruct>

<biblStruct coords="14,112.66,168.26,394.53,10.91;14,112.66,181.81,77.55,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="14,339.14,168.26,163.24,10.91">Predicting depression via social media</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Counts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,127.29,181.81,31.25,10.91">ICWSM</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,195.36,394.53,10.91;14,112.66,208.91,393.33,10.91;14,112.66,222.46,174.06,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="14,112.66,208.91,393.33,10.91;14,112.66,222.46,14.26,10.91">Feeling bad on facebook: depression disclosures by college students on a social networking site</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jelenchick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">G</forename><surname>Egan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">D</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">N</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Gannon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">L</forename><surname>Becker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,134.41,222.46,107.52,10.91">Depression and Anxiety</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,236.01,393.61,10.91;14,112.66,249.56,395.00,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="14,449.67,236.01,56.60,10.91;14,112.66,249.56,254.68,10.91">Why do they leave: Modeling participation in online depression forums</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sadeque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Solorio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Shrestha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Rey-Villamizar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,390.65,249.56,85.96,10.91">SocialNLP@EMNLP</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,263.11,394.53,10.91;14,112.66,276.66,395.17,10.91;14,112.66,290.20,393.33,10.91;14,112.66,303.75,311.17,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="14,472.03,276.66,35.81,10.91;14,112.66,290.20,283.31,10.91">Predicting individual well-being through the language of social media</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kapelner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dziurzynski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Stillwell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kosinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Seligman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,405.35,290.20,100.64,10.91;14,112.66,303.75,232.31,10.91">Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="516" to="527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,317.30,394.53,10.91;14,112.66,330.85,394.52,10.91;14,112.66,344.40,98.08,10.91" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>BarrÃ³n-CedeÃ±o</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Esposti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<title level="m" coord="14,265.93,330.85,241.26,10.91;14,112.66,344.40,64.43,10.91">Experimental ir meets multilinguality, multimodality, and interaction</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,357.95,394.53,10.91;14,112.66,371.50,193.28,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="14,257.24,357.95,245.63,10.91">Word use in the poetry of suicidal and nonsuicidal poets</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">W</forename><surname>Stirman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,112.66,371.50,109.34,10.91">Psychosomatic medicine</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="517" to="522" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,385.05,393.33,10.91;14,112.66,398.60,393.61,10.91;14,112.66,412.15,126.48,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="14,353.14,385.05,152.85,10.91;14,112.66,398.60,338.46,10.91">Analysis of syntax and word use to predict successful participation in guided self-help for anxiety and depression</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zinken</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Zinken</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Skinner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,459.52,398.60,46.74,10.91;14,112.66,412.15,37.47,10.91">Psychiatry research</title>
		<imprint>
			<biblScope unit="volume">179</biblScope>
			<biblScope unit="page" from="181" to="186" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,425.70,393.33,10.91;14,112.39,439.25,394.80,10.91;14,112.66,452.79,65.30,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="14,412.06,425.70,93.93,10.91;14,112.39,439.25,314.98,10.91">Depression detection via harvesting social media: A multimodal dictionary learning solution</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,454.29,439.25,22.72,10.91">IJCAI</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3838" to="3844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,466.34,393.33,10.91;14,112.66,479.89,319.51,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="14,228.16,466.34,277.82,10.91;14,112.66,479.89,147.39,10.91">Depression detection using emotional artificial intelligence and machine learning: a closer review</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kanoongo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,268.53,479.89,131.72,10.91">Materials Today: Proceedings</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,493.44,393.33,10.91;14,112.14,506.99,393.84,10.91;14,112.66,520.54,154.77,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="14,215.59,493.44,148.49,10.91">Detecting anxiety through reddit</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rudzicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,388.01,493.44,117.97,10.91;14,112.14,506.99,393.84,10.91;14,112.66,520.54,77.50,10.91">Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology-From Linguistic Signal to Clinical Reality</title>
		<meeting>the Fourth Workshop on Computational Linguistics and Clinical Psychology-From Linguistic Signal to Clinical Reality</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="58" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,534.09,393.33,10.91;14,112.66,547.64,393.33,10.91;14,112.66,561.19,369.94,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="14,426.17,534.09,79.82,10.91;14,112.66,547.64,283.45,10.91">Discovering shifts to suicidal ideation from mental health content in social media</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">De</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kiciman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Coppersmith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,421.32,547.64,84.67,10.91;14,112.66,561.19,271.78,10.91">Proceedings of the 2016 CHI conference on human factors in computing systems</title>
		<meeting>the 2016 CHI conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2098" to="2110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,574.74,393.33,10.91;14,112.66,588.29,216.96,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="14,277.41,574.74,228.58,10.91;14,112.66,588.29,54.55,10.91">Detection of depression-related posts in reddit social media forum</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Tadesse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,176.10,588.29,54.37,10.91">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="44883" to="44893" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,601.84,394.52,10.91;14,112.66,615.39,66.36,10.91" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="14,236.95,601.84,266.01,10.91">A test collection for research on depression and language use</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">A</forename><surname>Crestani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>CLEF</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,628.93,393.60,10.91;14,112.66,642.48,394.52,10.91;14,112.66,656.03,394.53,10.91;14,112.30,669.58,395.53,10.91;15,112.66,86.97,394.51,10.91;15,112.66,102.96,123.08,7.90" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="14,368.45,628.93,137.81,10.91;14,112.66,642.48,131.83,10.91">Overview of erisk 2021: Early risk prediction on the internet</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>MartÃ­n-Rodilla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-85251-1_22</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-85251-1_22.doi:10.1007/978-3-030-85251-1_22" />
	</analytic>
	<monogr>
		<title level="m" coord="14,267.14,642.48,240.05,10.91;14,112.66,656.03,394.53,10.91;14,112.30,669.58,60.29,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 12th International Conference of the CLEF Association, CLEF 2021, Virtual Event</title>
		<meeting><address><addrLine>Berlin, Heidel-berg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2021">September 21-24, 2021. 2021</date>
			<biblScope unit="page" from="324" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,114.06,393.32,10.91;15,112.66,127.61,137.63,10.91" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="15,276.40,114.06,229.58,10.91;15,112.66,127.61,106.30,10.91">Formality of language: definition, measurement and behavioral determinants</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Heylighen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dewaele</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Apostel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,141.16,394.53,10.91;15,112.66,154.71,393.32,10.91;15,112.28,168.26,121.69,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="15,245.31,141.16,261.87,10.91;15,112.66,154.71,278.22,10.91">Sleep disorders and depression: brief review of the literature, case report, and nonpharmacologic interventions for depression</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Luca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Luca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Calandra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,399.27,154.71,106.71,10.91;15,112.28,168.26,27.23,10.91">Clinical Interventions in Aging</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1033" to="1039" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,181.81,393.33,10.91;15,112.66,195.36,122.40,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="15,174.26,181.81,259.50,10.91">The secret life of pronouns. what our words say about us</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nerbonne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,443.06,181.81,62.92,10.91;15,112.66,195.36,38.47,10.91">Lit. Linguistic Comput</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="139" to="142" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,208.91,393.33,10.91;15,112.66,222.46,359.59,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="15,239.28,208.91,266.71,10.91;15,112.66,222.46,125.97,10.91">A meta-analysis of correlations between depression and first person singular pronoun use</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">S</forename><surname>Holtzman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,246.86,222.46,151.59,10.91">Journal of Research in Personality</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="63" to="68" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,236.01,393.33,10.91;15,112.66,249.56,394.53,10.91;15,112.66,263.11,22.69,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="15,348.67,236.01,157.32,10.91;15,112.66,249.56,275.33,10.91">Towards automatically classifying depressive symptoms from twitter data for population health</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">L</forename><surname>Mowery</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Conway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,411.68,249.56,89.14,10.91">PEOPLES@COLING</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,276.66,393.33,10.91;15,112.66,290.20,132.68,10.91" xml:id="b21">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Greaves</surname></persName>
		</author>
		<title level="m" coord="15,187.42,276.66,318.56,10.91;15,112.66,290.20,102.03,10.91">A corpus linguistic analysis of public reddit and tumblr blog posts on non-suicidal self-injury</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,303.75,394.53,10.91;15,112.66,317.30,77.55,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="15,339.14,303.75,163.24,10.91">Predicting depression via social media</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Counts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,127.29,317.30,31.25,10.91">ICWSM</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,330.85,395.17,10.91;15,112.66,344.40,376.87,10.91" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="15,331.97,330.85,175.86,10.91;15,112.66,344.40,155.64,10.91">Analysing the connectivity and communication of suicidal users on twitter</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Burnap</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hodorog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Scourfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,276.24,344.40,123.89,10.91">Computer Communications</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="291" to="300" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,357.95,394.53,10.91;15,112.28,371.50,361.31,10.91" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="15,173.48,357.95,329.75,10.91">Psycholinguistic text analysis for evaluation of person&apos;s emotional state</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vasyliuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,112.28,371.50,302.47,10.91">Abstracts of the 2nd International scientific and practical conference</title>
		<meeting><address><addrLine>Lviv</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,385.05,393.33,10.91;15,112.66,398.60,204.66,10.91" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="15,357.57,385.05,148.42,10.91;15,112.66,398.60,45.62,10.91">Text-based detection of the risk of depression</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>HavigerovÃ¡</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Haviger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kuera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>HoffmannovÃ¡</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,166.77,398.60,105.76,10.91">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,412.15,393.33,10.91;15,112.66,425.70,394.62,10.91;15,112.66,439.25,244.15,10.91" xml:id="b26">
	<monogr>
		<title level="m" type="main" coord="15,368.05,412.15,137.93,10.91;15,112.66,425.70,227.62,10.91">Mentalbert: Publicly available pretrained language models for mental healthcare</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="2110.15621" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,452.79,393.33,10.91;15,112.66,466.34,395.01,10.91;15,112.66,482.34,97.35,7.90" xml:id="b27">
	<monogr>
		<title level="m" type="main" coord="15,225.45,452.79,280.54,10.91;15,112.66,466.34,78.07,10.91">Bridging nonlinearities and stochastic regularizers with gaussian error linear units</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="1606.08415" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,493.44,395.01,10.91;15,112.66,509.43,97.35,7.90" xml:id="b28">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05101</idno>
		<title level="m" coord="15,262.02,493.44,203.76,10.91">Decoupled weight decay regularization</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,520.54,394.53,10.91;15,112.28,534.09,128.06,10.91" xml:id="b29">
	<monogr>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>CissÃ©</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno>ArXiv abs/1710.09412</idno>
		<title level="m" coord="15,315.62,520.54,186.91,10.91">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
