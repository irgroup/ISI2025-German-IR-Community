<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,417.06,15.42;1,89.29,106.66,145.95,15.42">UNSL at eRisk 2022: Decision policies with history for early classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.10,134.97,94.52,11.96"><forename type="first">Juan</forename><forename type="middle">Mart√≠n</forename><surname>Loyola</surname></persName>
							<email>jmloyola@unsl.edu.ar</email>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Nacional de San Luis (UNSL)</orgName>
								<address>
									<addrLine>Ej√©rcito de Los Andes 950</addrLine>
									<postCode>5700</postCode>
									<settlement>San Luis</settlement>
									<region>C.P</region>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Instituto de Matem√°tica Aplicada San Luis (IMASL)</orgName>
								<orgName type="institution">CONICET-UNSL</orgName>
								<address>
									<addrLine>Av. Italia 1556</addrLine>
									<postCode>5700</postCode>
									<settlement>San Luis</settlement>
									<region>C.P</region>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,201.55,134.97,94.45,11.96"><forename type="first">Horacio</forename><surname>Thompson</surname></persName>
							<email>hjthompson@unsl.edu.ar</email>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Nacional de San Luis (UNSL)</orgName>
								<address>
									<addrLine>Ej√©rcito de Los Andes 950</addrLine>
									<postCode>5700</postCode>
									<settlement>San Luis</settlement>
									<region>C.P</region>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Consejo Nacional de Investigaciones Cient√≠ficas y T√©cnicas (CONICET)</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,313.92,134.97,76.19,11.96"><forename type="first">Sergio</forename><surname>Burdisso</surname></persName>
							<email>sburdisso@unsl.edu.ar</email>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Nacional de San Luis (UNSL)</orgName>
								<address>
									<addrLine>Ej√©rcito de Los Andes 950</addrLine>
									<postCode>5700</postCode>
									<settlement>San Luis</settlement>
									<region>C.P</region>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Idiap Research Institute</orgName>
								<address>
									<addrLine>Rue Marconi 19</addrLine>
									<postCode>1920</postCode>
									<settlement>Martigny</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,148.92,88.49,11.96"><forename type="first">Marcelo</forename><surname>Errecalde</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Nacional de San Luis (UNSL)</orgName>
								<address>
									<addrLine>Ej√©rcito de Los Andes 950</addrLine>
									<postCode>5700</postCode>
									<settlement>San Luis</settlement>
									<region>C.P</region>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,417.06,15.42;1,89.29,106.66,145.95,15.42">UNSL at eRisk 2022: Decision policies with history for early classification</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">2F1A6DBAD798DA98A84D9E9CAD9AB6F6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Early Risk Detection</term>
					<term>Early Classification</term>
					<term>Learned Early Alert Policy</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For the 2022 edition of the CLEF eRisk Laboratory, our research group at Universidad Nacional de San Luis (UNSL) added new approaches and improvements concerning our last participation. We proposed two decision policies for EarlyModel that take into account historic information available to the models, and incorporated two score normalization steps into the SS3 model. We also significantly reduced the runtime to process the inputs. Despite not having achieved the best performances, our team obtained the best results for the ERDE50 in tasks T1 and T2. Besides, considering the ùêπ latency , we were the third-best team for both tasks. Finally, a couple of our models got some of the best performance for the ranking-based metrics for task T1.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The 2022 edition of the early risk prediction on the Internet laboratory (eRisk) <ref type="bibr" coords="1,451.80,432.33,12.99,10.91" target="#b0">[1]</ref> presents two tasks for early risk detection: early detection of signs of pathological gambling and early detection of depression. Both had been introduced in previous editions <ref type="bibr" coords="1,425.84,459.43,11.48,10.91" target="#b1">[2,</ref><ref type="bibr" coords="1,441.11,459.43,7.52,10.91" target="#b2">3,</ref><ref type="bibr" coords="1,452.42,459.43,7.65,10.91" target="#b3">4]</ref>, thus the participants have a corpus to use for training or validation. The performance was assessed with the same metrics as last edition. That is, the standard classification measures (precision, recall, and ùêπ 1 score), measures that penalize delay in the response (ERDE <ref type="bibr" coords="1,397.25,500.08,12.99,10.91" target="#b4">[5]</ref> and ùêπ latency <ref type="bibr" coords="1,467.34,500.08,11.26,10.91" target="#b5">[6]</ref>), and ranking-based evaluation metrics were used. The ùêπ 1 and ùêπ latency scores were computed with respect to the positive class only.</p><p>The remaining sections describe the models and datasets used, and discuss the results obtained. Section 2 gives a brief description of the methods and points out the main differences from our last participation. Sections 3 and 4 describe the datasets, the models' parameters, and their results for Task 1 and Task 2, respectively. Finally, Section 5 closes with the conclusions of the work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Method</head><p>Our participation in this edition followed similar steps as the last edition <ref type="bibr" coords="2,432.69,159.14,11.58,10.91" target="#b6">[7]</ref>. The corpus generation and data pre-processing steps did not change. The same kinds of models were used, but we improved upon them and proposed new decision policies. Also, to compare our performance with the models from last year, we trained and validated our models using the generated corpus and tested them using the provided corpus. Finally, we reduced the time each run took to process the writings.</p><p>In what follows, the enhancements with respect to our previous participation are presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Early risk detection models</head><p>The models proposed for early risk detection were based on the early classification framework presented by Loyola et al. <ref type="bibr" coords="2,206.50,303.71,11.46,10.91" target="#b7">[8]</ref>. This framework divides the task into two separated but related problems: classifying with partial information and deciding the moment of classification. The task of classification with partial information (CPI) consists in obtaining an effective model that predicts the class of a document only using the available information. On the other hand, the task of deciding the moment of classification (DMC) involves determining the point at which we can stop reading the input with some certainties that the prediction made will be correct. We used the same kind of models as last year: EarlyModel <ref type="bibr" coords="2,363.35,385.01,11.49,10.91" target="#b6">[7]</ref>, EARLIEST <ref type="bibr" coords="2,431.44,385.01,11.49,10.91" target="#b8">[9]</ref>, and SS3 <ref type="bibr" coords="2,487.27,385.01,16.31,10.91" target="#b9">[10]</ref>. The main difference was in the DMC component. We proposed two new decision policies for EarlyModel and two different normalization steps for the SS3 scores. The new decision policies consider the model's past scores and other information from the documents context. The motivation behind the normalization of the SS3 scores was to restrict the scores to the interval [0, 1] and avoid an infinite increasing score <ref type="foot" coords="2,320.63,451.00,3.71,7.97" target="#foot_0">1</ref> .</p><p>Next, we briefly describe each early risk detection model and the proposed improvements.</p><p>EarlyModel. This model tackles both tasks of early classification separately. Thus, it is composed of two parts: a classifier with partial information and a decision policy in charge of raising an alarm. While the input is being processed, the partial classifier categorizes it, returning the class probability. The class probability and other information from the context are fed to the decision policy that decides if we should stop processing the input and raise an alarm or continue reading. The EarlyModels were built following our last edition workflow. The best &lt;representation, classifier with partial information&gt; pairs were selected and integrated with a decision policy. This year three policies were evaluated:</p><p>‚Ä¢ SimpleStopCriterion. Decision policy used last year. To decide if an alarm for a user had to be emitted, three attributes were consider: the predicted class, the current delay, and the predicted positive class probability. If the user is predicted as positive, the probability of belonging to the positive class exceeds a certain threshold (ùõø), and more than ùëõ posts are processed, then an alarm is raised. Different combinations of ùõø and ùëõ were tested, selecting the best ones according to the ùêπ latency measure obtained in the validation stage. ‚Ä¢ HistoricStopCriterion. To avoid hasty alarms, SimpleStopCriterion was extended by considering some of the model's previous positive class probabilities. This policy defines that if the current probability exceeds the threshold and the last ùëö predictions also do so, the system must issue a user at-risk alarm and end the analysis; otherwise, it is necessary to continue evaluating the user. ‚Ä¢ LearnedDecisionTreeStopCriterion. Decision policy based on a learned decision tree.</p><p>This was only used in the depression task since the laboratory organizers provided two datasets, one of which we could use to train the model without leakage of information. In order to train this model, we labelled the point ùëù in which the system could emit an alarm. Fifty positive users of the depression training corpus for eRisk 2018<ref type="foot" coords="3,408.74,291.16,3.71,7.97" target="#foot_1">2</ref> were labelled for this task. Half of them were used for training and the other half for validation. For each user, multiple samples were generated, one for each of the posts. A sample in time ùë° contained all the publications in time ùëñ such that ùëñ ‚â§ ùë°. To label each sample, we compared the time ùë° of the sample with the decision point ùëù. If ùë° &lt; ùëù, a negative label was assigned to the sample. For the following ten samples, ùëù ‚â§ ùë° &lt; ùëù + 10, the positive label was assigned.</p><p>The features calculated for each sample were: current positive class probability given by the CPI, an average of the last ten positive class probabilities given by the CPI, an average of the last five positive class probabilities given by the CPI, median of the last ten positive class probabilities given by the CPI, current delay, the current label assigned by the CPI, an average of the last ten labels assigned by the CPI, number of words in the top 0.01 percentile of information gain for the depression training corpus for eRisk 2018, and the number of words in the top 0.015 percentile of chi-squared for the depression training corpus for eRisk 2018. Then, a decision tree model was trained using group k-fold to ensure all the samples for a user were in the same group. Grid search was used to find the best parameters. Finally, the best model was evaluated in the testing corpus built.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EARLIEST.</head><p>It is an end-to-end deep learning model that tackles both early classification tasks at the same time. The model is composed of three parts: a base RNN that summarizes the partial input, a controller that decides if we should continue or not processing the input, and a discriminator that classifies the partial input once the controller halts the processing. Reinforcement learning is used in order to train the model. This year, a couple of bugs in the implementation were fixed and the model was forced to make decisions after seen five posts at least.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SS3.</head><p>It is a two-part early classification model where SS3 <ref type="bibr" coords="4,344.64,86.97,17.76,10.91" target="#b9">[10]</ref> is used as a classifier with partial information, and a user-global early alert policy is proposed to halt the processing. The policy used to raise an alarm for a particular user takes into account its score value, globally, with respect to the current score of all the other users. This year the users' scores were normalized using two approaches:</p><p>‚Ä¢ N1. First, to limit the score to the interval [0, 1], the softmax function was applied to the confidence values (cv) that the model gave to the positive and negative classes. Given the additive nature of the confidence values and the behaviour of the softmax function when the values increase <ref type="foot" coords="4,232.47,197.45,3.71,7.97" target="#foot_2">3</ref> , the confidence values were divided by the current delay of the document. For the users that do not have more posts, the delay is equal to the total number of posts sent. Finally, the score for a user was calculated as:</p><p>ùë†ùëúùëì ùë°ùëöùëéùë•( ùëêùë£ positive delay , ùëêùë£ negative delay )</p><p>‚Ä¢ N2. Second, the proportion of the positive confidence value given the sum of both positive and negative confidence values was used. Thus, the score for a user was computed as:</p><formula xml:id="formula_0" coords="4,267.47,300.19,87.11,26.33">ùëêùë£ positive ùëêùë£ positive + ùëêùë£ negative</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Training workflow</head><p>Following other teams decision from previous editions of the laboratory, we augmented the provided corpus with posts from Reddit. Though, this time, we didn't used the provided corpus for the initial training and validation of the models. The generated Reddit corpus was used to select the models and its hyper-parameters. Once we selected the best models, we evaluated them in the provided corpus. Note that these datasets were used for testing in previous editions of the laboratory, thus we were able to compare the performance. Finally, before we started processing the writings, we retrained the models with the obtained hyper-parameters using all the datasets available.</p><p>In order to speed the training process and to simulate the laboratory pipeline, a mock server was developed <ref type="foot" coords="4,157.11,482.68,3.71,7.97" target="#foot_3">4</ref> . This server replicate the GET/POST behaviour of the eRisk laboratory. That is, a team can ask for new writings using the same GET request structure as the one used during the laboratory. Similarly, the same POST request structure can be used to send the team response for each run. Besides these, the mock server can:</p><p>‚Ä¢ Manage teams: create, list, and get information of a team. ‚Ä¢ Show a separation plot for a given team and time.</p><p>‚Ä¢ Plot the user score evolution for a given team and run.</p><p>‚Ä¢ Plot the elapsed times of teams.</p><p>‚Ä¢ Show the table with the results of all finished experiments. ‚Ä¢ Plot the server elapsed times to answer the requests. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Speed up runs</head><p>One of the concerns about our participation last year was the time it took our models to process the writings. Input/output operations to communicate with the laboratory server caused part of this delay. Each model had to wait for the previous one to finish sending its responses to start processing the input. Therefore, this year we processed each writing concurrently which allowed us to reduce the total processing time. That is, some models could be already processing the input while others could still be sending data and/or be waiting for server responses. We used the asyncio <ref type="foot" coords="5,164.80,350.40,3.71,7.97" target="#foot_4">5</ref> Python package to implement this behaviour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Task T1: Early Detection of Signs of Pathological Gambling</head><p>In this section, the details of our participation addressing the eRisk's early detection of pathological gambling task are given. Namely, the details of the datasets and the five models submitted to this challenge are introduced. Finally, the results obtained after the evaluation stage are shown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Datasets</head><p>For Task T1, the eRisk's organizers provided a corpus to train, validate or test the participating models. The corpus was made available as a set of XML files, one for each user. In our case, we used the provided corpus to compare our results with last edition models, thus we initially did not train or validate our models using this. In order to train and validate our models a complementary corpus was built using data from Reddit following the same steps as last year <ref type="bibr" coords="5,492.63,555.35,11.28,10.91" target="#b6">[7]</ref>. This corpus was split into a training and a validation set, each containing half of the users. Finally, once the best hyper-parameters were found using the generated datasets, all the datasets (including the one provided by the organizers) were used to retrain the models before deploying them.</p><p>Table <ref type="table" coords="5,127.16,623.10,5.10,10.91" target="#tab_0">1</ref> shows the details of each complementary corpus along with the validation and test datasets provided for this task. In this table, "T1_test" refers to the test set used to evalu-ate all participating models, "T1_valid" to the validation set provided by the organizers, and "T1_redd_train" and "T1_redd_valid" to the training and validation sets built using Reddit.</p><p>Note that the corpus used to evaluate the participating models this year was more unbalanced than last year, thus, probably making this year task more difficult to address. Note that in the provided corpus 6.9% of the users are positives, whereas in the corpus used to evaluate participating models, only 3.8%. On the other hand, T1_redd_train and T1_redd_valid had a much lower number of total posts and posts per user than the datasets used by the organizers. Finally, in T1_test, there were empty posts (without words), which could be due to users who edited their posts after posting, deleting their content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Models</head><p>This section describes the details of the models used by our team to tackle this task. Namely, from the results obtained after the model selection and the hyper-parameter optimization stage, the following five models were selected for participating: UNSL#0. An EarlyModel with a bag of words (BoW) representation and a logistic regression classifier. Words unigrams were used for the BoW representation with term frequency times inverse document-frequency (commonly known as tf-idf ) as the weighting scheme. For the logistic regression, a balanced weighting for the classes was used, that is, each input was weighted inversely proportional to its class frequencies in the input data. Finally, for the decision-making policy, a SimpleStopCriterion with threshold ùõø = 0.7 and minimum number of posts ùëõ = 10 was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UNSL#1.</head><p>An EarlyModel with a BoW representation and a support vector machine (SVM) classifier. For the BoW representation, character 4-grams were used with tf-idf as the weighting scheme. The support vector machine was parameterized with a radial basis function kernel with gamma="scale" and regularization parameter ùê∂ = 2 weighted inversely proportional to its class frequencies in the input data. Finally, for the decisionmaking policy, a SimpleStopCriterion with threshold ùõø = 0.7 and minimum number of posts ùëõ = 10 was used. UNSL#2. An EarlyModel based on BERT with an extended vocabulary. For the finetuning process, the following parameters were used: architecture=BERT-based-uncased <ref type="foot" coords="6,500.59,531.69,3.71,7.97" target="#foot_5">6</ref> , optimizer=Adam, learning_rate=3e-5, batch_size=8, and n_epochs=3. Also, 25 new words were added to the BERT's vocabulary <ref type="bibr" coords="6,291.92,560.54,18.06,10.91" target="#b10">[11]</ref> by applying the following process: an SS3 model was trained on all available data (Reddit and eRisk2021's datasets), then words were ordered according to their confidence values on the positive class, and finally, the top-25 most important words were extracted. Finally, the decision policy HistoricStopCriterion was applied with a threshold ùõø = 0.7, a minimum number of posts ùëõ = 10, and considering the last ùëö = 10 previous predictions. UNSL#3. An SS3 model 7 with a policy value of ùõæ = 2.5 and the normalization N1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UNSL#4.</head><p>An EARLIEST model with a doc2vec representation. Each post was represented as a 300-dimensional vector. To learn this representation the Reddit training corpus, T1_redd_train, was used. The base recurrent neural network chosen was a one-layer LSTM with an input feature dimension of 300 and 256 hidden units. The discriminator of the EARLIEST model reduced the hidden state of the LSTM to two dimensions representing the probabilities of both, the positive and negative classes. Finally, the value of lambda used to train was ùúÜ = 1e-4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Results</head><p>Table <ref type="table" coords="7,115.50,247.80,5.01,10.91" target="#tab_1">2</ref> shows the results obtained for the decision-based performance metrics. As can be seen, our team achieved the best performance in terms of the ERDE 50 measure. Besides, considering all teams, we obtained the third-best team performance for the ERDE 5 , ùêπ 1 , and ùêπ latency measures. Despite not having obtained the best results, our team achieved competitive performance in most metrics, exceeding the average level among all teams for this edition.</p><p>Analyzing the performance of our team, the EarlyModels (UNSL#0, #1, and #2) reached the best score in the ERDE 50 measure, but only UNSL#1 could stand out, achieving the best ùêπ 1 and ùêπ latency scores. However, in ERDE 5 , these models showed a lower performance. The SS3 model (UNSL#3) proved to be competitive, achieving acceptable performance in all metrics and, in particular, obtaining the best results for ERDE 5 . Finally, the EARLIEST model (UNSL#4), did not perform well on this task.</p><p>On the other hand, Table <ref type="table" coords="7,213.06,396.84,5.02,10.91" target="#tab_2">3</ref> shows the results obtained for the performance metrics based on rankings. Our team achieved the best performance in most metrics with respect to the different rankings used for the evaluation. In particular, the EarlyModels (UNSL#0 and UNSL#1) were able to stand out from other models presented by our team. The only exceptions was NDCG@100 with 1 and 500 posts, where the results were very close to the best of the competition: for 1 post, the best was 0.76 by UNED-NLP#2 and our best model obtained 0.70; and for 500 posts, the best result was 0.95 by UNED-NLP#4 and our best model got 0.93.</p><p>It is also interesting to note that most of the NDCG@100 values improved as more writings were processed. In early classification problems, this is usually common since the models' accuracy improves as the size of the input increases. However, an excessive delay in classification can become a problem, as it could put people's lives at risk. An early decision could be made considering less data, but still, accuracy remains key to the final performance of the models. This behavior is not present for the ranking measures that only consider the top 10 scores (P@10 and NDCG@10) because their reduced sample size makes them more unstable. One sample could bias the final measure, unlike when 100 samples are used. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Task T2: Early Detection of Depression</head><p>In this section, the details of our participation addressing the eRisk's early detection of depression task are given. Namely, the details of the datasets and the five models submitted to this challenge are introduced. Finally, the results obtained after the evaluation stage are shown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>For Task T2, the eRisk's organizers provided datasets to train and validate the participating models. Each corpus was made available as a set of XML files, one for each user. Part of the supplied training corpus was used to train the decision policy LearnedDecisionTreeStopCriterion.</p><p>The provided validation corpus was used to compare our results with the models from eRisk 2018 <ref type="foot" coords="9,112.19,261.59,3.71,7.97" target="#foot_6">8</ref> . In order to train and validate our models a complementary corpus was built using data from Reddit following the same steps as last year <ref type="bibr" coords="9,308.78,276.90,11.37,10.91" target="#b6">[7]</ref>. This corpus was split into a training and a validation set, each containing half of the users. Next, the best hyper-parameters were found using the generated datasets and, finally, all the datasets (including the ones provided by the organizers) were used to retrain the models before deploying them. Table <ref type="table" coords="9,127.16,331.10,5.10,10.91" target="#tab_3">4</ref> shows the details of each complementary corpus along with the validation and test datasets provided for this task. In this table, "T2_test" refers to the test set used to evaluate all participating models, "T2_train" and "T2_valid" to the training and validation sets provided by the organizers, and "T2_redd_train" and "T2_redd_valid" to the training and validation sets built using Reddit.</p><p>As with Task T1, the corpus used to evaluate the participating models was more unbalanced than in previous years. Note that in the provided training and validation sets 15.21% and 9.63% of the users were positive, respectively, whereas in the test set only 7%. On the other hand, the number of total posts and posts per user in T2_redd_train and T2_redd_valid was notably smaller than in T2_test (used for evaluation). Finally, in the same way as with T1_test, in T2_test there were empty posts with no words in them, i.e. empty posts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Models</head><p>This section describes the details of the models used by our team to address this task. Namely, from the results obtained after model selection and hyper-parameter optimization, the following five models were selected for participating: UNSL#0. An EarlyModel with latent semantic analysis representation and a logistic regression classifier. Fifty factors were used to depict each user, transforming the input and projecting it into the space generated by the single value decomposition algorithm trained in T2_redd_train. For the logistic regression, a balanced weighting for the classes was used, that is, each input was weighted inversely proportional to its class frequencies in the input data. Finally, for the decision-making policy, a LearnedDecisionTreeStopCriterion was used. The first levels of the obtained decision tree are shown in Figure <ref type="figure" coords="9,447.82,649.54,5.01,10.91" target="#fig_0">1</ref> and the full decision tree is shown in Figure <ref type="figure" coords="10,264.57,305.69,3.81,10.91" target="#fig_1">2</ref>. The best hyper-parameters found after grid search were: class_weight="balanced", criterion="entropy", max_depth=4, min_samples_leaf=1, and splitter="best". UNSL#1. An EarlyModel with a BoW representation and an SVM classifier. For the BoW representation, character 3-grams were used with tf-idf as the weighting scheme. The support vector machine was parameterized with a radial basis function kernel with gamma="scale" and regularization parameter ùê∂ = 8. Finally, for the decision-making policy, a SimpleStopCriterion with threshold ùõø = 0.7 and minimum number of posts ùëõ = 10 was used. UNSL#2. An SS3 model with a policy value of ùõæ = 2.5 and the normalization N1. UNSL#3. An SS3 model with a policy value of ùõæ = 2 and the normalization N2. UNSL#4. An EARLIEST model with the same hyper-parameters and structure as the one used in UNSL#4 for Task T1. In this case, to learn the doc2vec representation, T2_redd_train was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results</head><p>The Table <ref type="table" coords="10,135.71,601.84,5.07,10.91" target="#tab_4">5</ref> shows the results obtained for the decision-based performance metrics. As can be seen, our team achieved the best performance in terms of the ERDE 50 measure together with SCIR2. Besides, considering all teams, we obtained the second-best team performance for the ERDE 5 measure and we were the third-best team for the ùêπ latency .</p><p>If we compare our models performance, we can see that UNSL#2 (SS3) outperform the rest in almost every metric. Looking at the performance of both SS3 models (UNSL#2 and UNSL#3), Ranking-based evaluation results for Task T2. Results are reported according to the three classification metrics obtained after processing 1, 100, 500, and 1000 posts, respectively. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="10,89.29,257.45,417.69,8.96;10,89.29,269.41,151.89,8.96;10,184.05,84.19,227.19,166.67"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: First levels of the decision tree classifier learned for task T2 in the context of the LearnedDeci-sionTreeStopCriterion decision policy.</figDesc><graphic coords="10,184.05,84.19,227.19,166.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="14,89.29,654.67,417.69,8.96;14,89.29,666.63,80.91,8.96;14,188.64,84.21,218.00,563.87"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Decision tree classifier learned for task T2 in the context of the LearnedDecisionTreeStopCriterion decision policy.</figDesc><graphic coords="14,188.64,84.21,218.00,563.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,88.99,90.49,418.09,135.40"><head>Table 1</head><label>1</label><figDesc>Details of the corpora used for Task T1: the different training and validation sets, as well as the test set used by the eRisk organizers to evaluate the participating models. The number of users (total, positives, and negatives) and the number of posts of each corpus are reported. The median, minimum, and maximum number of posts per user and words per post in each corpus are detailed.</figDesc><table coords="5,98.03,154.51,399.23,71.37"><row><cell>Corpus</cell><cell cols="2">#users Total Pos Neg</cell><cell>#posts</cell><cell cols="4">#posts per user Med Min Max Med Min Max #words per post</cell></row><row><cell>T1_test</cell><cell>2,079</cell><cell cols="2">81 1,998 1,177,590</cell><cell>297</cell><cell>3 2,001</cell><cell>11</cell><cell>0 6,728</cell></row><row><cell>T1_valid</cell><cell cols="3">2,348 164 2,184 1,130,799</cell><cell>244</cell><cell>10 2,001</cell><cell>11</cell><cell>1 8,241</cell></row><row><cell cols="3">T1_redd_train 1,746 286 1,460</cell><cell>158,924</cell><cell>51</cell><cell>31 1,188</cell><cell>20</cell><cell>1 7,479</cell></row><row><cell cols="3">T1_redd_valid 1,746 286 1,460</cell><cell>161,204</cell><cell>53</cell><cell>31 1,337</cell><cell>20</cell><cell>1 3,234</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,88.99,90.49,418.09,181.82"><head>Table 2</head><label>2</label><figDesc>Decision-based evaluation results for Task T1. The best teams taking into account the ERDE 5 , ERDE 50 , and ùêπ latency are shown (values in bold), as well as the median and mean values of the results report for CLEF eRisk 2022.</figDesc><table coords="8,114.15,139.99,366.49,132.31"><row><cell>Model</cell><cell>P</cell><cell>R</cell><cell>ùêπ 1</cell><cell cols="4">ERDE 5 ERDE 50 latency TP speed ùêπ latency</cell></row><row><cell>UNSL#0</cell><cell cols="3">0.401 0.951 0.564</cell><cell>0.041</cell><cell>0.008</cell><cell>11.0</cell><cell>0.961</cell><cell>0.542</cell></row><row><cell>UNSL#1</cell><cell cols="3">0.461 0.938 0.618</cell><cell>0.041</cell><cell>0.008</cell><cell>11.0</cell><cell>0.961</cell><cell>0.594</cell></row><row><cell>UNSL#2</cell><cell cols="3">0.398 0.914 0.554</cell><cell>0.041</cell><cell>0.008</cell><cell>12.0</cell><cell>0.957</cell><cell>0.531</cell></row><row><cell>UNSL#3</cell><cell cols="3">0.365 0.864 0.513</cell><cell>0.017</cell><cell>0.009</cell><cell>3.0</cell><cell>0.992</cell><cell>0.509</cell></row><row><cell>UNSL#4</cell><cell cols="3">0.052 0.988 0.100</cell><cell>0.051</cell><cell>0.030</cell><cell>5.0</cell><cell>0.984</cell><cell>0.098</cell></row><row><cell cols="4">UNED-NLP#4 0.809 0.938 0.869</cell><cell>0.020</cell><cell>0.008</cell><cell>3.0</cell><cell>0.992</cell><cell>0.862</cell></row><row><cell>SINAI#1</cell><cell cols="3">0.575 0.802 0.670</cell><cell>0.015</cell><cell>0.009</cell><cell>1.0</cell><cell>1.000</cell><cell>0.670</cell></row><row><cell>BLUE#0</cell><cell cols="3">0.260 0.975 0.410</cell><cell>0.015</cell><cell>0.009</cell><cell>1.0</cell><cell>1.000</cell><cell>0.410</cell></row><row><cell>Mean</cell><cell cols="3">0.223 0.846 0.279</cell><cell>0.034</cell><cell>0.021</cell><cell>4.8</cell><cell>0.985</cell><cell>0.297</cell></row><row><cell>Median</cell><cell cols="3">0.116 0.963 0.205</cell><cell>0.037</cell><cell>0.015</cell><cell>2.8</cell><cell>0.993</cell><cell>0.211</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,88.99,292.17,416.99,196.37"><head>Table 3</head><label>3</label><figDesc>Ranking-based evaluation results for Task T1. Results are reported according to the three classification metrics obtained after processing 1, 100, 500, and 1000 posts, respectively.</figDesc><table coords="8,131.19,332.22,332.90,156.32"><row><cell>Ranking</cell><cell>Metric</cell><cell cols="5">UNSL#0 UNSL#1 UNSL#2 UNSL#3 UNSL#4</cell></row><row><cell></cell><cell>P@10</cell><cell>1.00</cell><cell>1.00</cell><cell>0.90</cell><cell>1.00</cell><cell>0.10</cell></row><row><cell>1 post</cell><cell>NDCG@10</cell><cell>1.00</cell><cell>1.00</cell><cell>0.90</cell><cell>1.00</cell><cell>0.07</cell></row><row><cell></cell><cell>NDCG@100</cell><cell>0.68</cell><cell>0.70</cell><cell>0.66</cell><cell>0.69</cell><cell>0.32</cell></row><row><cell></cell><cell>P@10</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>0.60</cell><cell>0.10</cell></row><row><cell>100 posts</cell><cell>NDCG@10</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>0.58</cell><cell>0.07</cell></row><row><cell></cell><cell>NDCG@100</cell><cell>0.90</cell><cell>0.90</cell><cell>0.77</cell><cell>0.72</cell><cell>0.32</cell></row><row><cell></cell><cell>P@10</cell><cell>1.00</cell><cell>1.00</cell><cell>0.90</cell><cell>0.80</cell><cell>0.20</cell></row><row><cell>500 posts</cell><cell>NDCG@10</cell><cell>1.00</cell><cell>1.00</cell><cell>0.92</cell><cell>0.81</cell><cell>0.13</cell></row><row><cell></cell><cell>NDCG@100</cell><cell>0.93</cell><cell>0.92</cell><cell>0.78</cell><cell>0.77</cell><cell>0.33</cell></row><row><cell></cell><cell>P@10</cell><cell>1.00</cell><cell>1.00</cell><cell>0.90</cell><cell>0.80</cell><cell>0.30</cell></row><row><cell>1000 posts</cell><cell>NDCG@10</cell><cell>1.00</cell><cell>1.00</cell><cell>0.90</cell><cell>0.81</cell><cell>0.22</cell></row><row><cell></cell><cell>NDCG@100</cell><cell>0.95</cell><cell>0.93</cell><cell>0.77</cell><cell>0.78</cell><cell>0.37</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,88.99,90.49,418.09,148.77"><head>Table 4</head><label>4</label><figDesc>Details of the corpora used for Task T2: the different training and validation sets, as well as the test set used by the eRisk organizers to evaluate the participating models. The number of users (total, positives, and negatives) and the number of posts of each corpus are reported. The median, minimum, and maximum number of posts per user and words per post in each corpus are detailed.</figDesc><table coords="9,98.14,154.54,399.02,84.72"><row><cell>Corpus</cell><cell cols="3">#users Total Pos Neg</cell><cell>#posts</cell><cell cols="3">#posts per user Med Min Max Med Min Max #words per post</cell></row><row><cell>T2_test</cell><cell>1,400</cell><cell cols="4">98 1,302 898,326 457.0</cell><cell>6 2,000</cell><cell>12</cell><cell>0 8,009</cell></row><row><cell>T2_train</cell><cell cols="2">887 135</cell><cell cols="3">752 531,394 321.0</cell><cell>10 2,000</cell><cell>13</cell><cell>1 7,450</cell></row><row><cell>T2_valid</cell><cell>820</cell><cell>79</cell><cell cols="3">741 545,188 411.5</cell><cell>10 2,000</cell><cell>13</cell><cell>1 7,280</cell></row><row><cell cols="3">T2_redd_train 1,056 499</cell><cell cols="2">557 142,059</cell><cell>66.0</cell><cell>31 2,282</cell><cell>21</cell><cell>1 6,792</cell></row><row><cell cols="3">T2_redd_valid 1,057 500</cell><cell cols="2">557 130,534</cell><cell>61.0</cell><cell>31 2,220</cell><cell>20</cell><cell>1 6,629</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="11,88.99,90.49,418.09,181.82"><head>Table 5</head><label>5</label><figDesc>Decision-based evaluation results for Task T2. The best teams taking into account the ERDE 5 , ERDE 50 , and ùêπ latency are shown (values in bold), as well as the median and mean values of the results report for CLEF eRisk 2022.</figDesc><table coords="11,100.13,139.99,394.52,132.31"><row><cell>Model</cell><cell>P</cell><cell>R</cell><cell>ùêπ 1</cell><cell cols="4">ERDE 5 ERDE 50 latency TP speed ùêπ latency</cell></row><row><cell>UNSL#0</cell><cell cols="3">0.161 0.918 0.274</cell><cell>0.079</cell><cell>0.042</cell><cell>14.5</cell><cell>0.947</cell><cell>0.260</cell></row><row><cell>UNSL#1</cell><cell cols="3">0.310 0.786 0.445</cell><cell>0.078</cell><cell>0.037</cell><cell>12.0</cell><cell>0.957</cell><cell>0.426</cell></row><row><cell>UNSL#2</cell><cell cols="3">0.400 0.755 0.523</cell><cell>0.045</cell><cell>0.026</cell><cell>3.0</cell><cell>0.992</cell><cell>0.519</cell></row><row><cell>UNSL#3</cell><cell cols="3">0.144 0.929 0.249</cell><cell>0.055</cell><cell>0.035</cell><cell>3.0</cell><cell>0.992</cell><cell>0.247</cell></row><row><cell>UNSL#4</cell><cell cols="3">0.080 0.918 0.146</cell><cell>0.099</cell><cell>0.074</cell><cell>5.0</cell><cell>0.984</cell><cell>0.144</cell></row><row><cell cols="4">NLPGroup-IISERB#0 0.682 0.745 0.712</cell><cell>0.055</cell><cell>0.032</cell><cell>9.0</cell><cell>0.969</cell><cell>0.690</cell></row><row><cell>LauSAn#4</cell><cell cols="3">0.201 0.724 0.315</cell><cell>0.039</cell><cell>0.033</cell><cell>1.0</cell><cell>1.000</cell><cell>0.315</cell></row><row><cell>SCIR2#3</cell><cell cols="3">0.316 0.847 0.460</cell><cell>0.079</cell><cell>0.026</cell><cell>44.0</cell><cell>0.834</cell><cell>0.383</cell></row><row><cell>Mean</cell><cell cols="3">0.200 0.730 0.278</cell><cell>0.068</cell><cell>0.048</cell><cell>22.8</cell><cell>0.922</cell><cell>0.288</cell></row><row><cell>Median</cell><cell cols="3">0.149 0.847 0.249</cell><cell>0.070</cell><cell>0.041</cell><cell>6.0</cell><cell>0.981</cell><cell>0.256</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="11,88.99,292.17,32.19,8.93"><head>Table 6</head><label>6</label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,108.93,638.11,397.29,8.97;2,89.29,649.06,416.70,8.97;2,89.29,660.02,416.69,8.97;2,89.29,670.98,44.90,8.97"><p>Note that the score of each user is additive. That is, as new posts arrive, the user's score could potentially increase more and more, never reaching a limit. Since SS3 has a global decision policy, the score of all users is considered to make a decision. Even users that have already finished processing the input impact the decision of active users.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,108.93,660.01,397.05,8.97;3,89.29,670.97,30.55,8.97"><p>Note that this corpus was not used for training, validation or testing of the system, thus any leakage was avoided.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,108.93,627.20,397.05,8.97;4,89.29,638.16,416.93,8.97;4,89.29,649.12,59.58,8.97"><p>When the values given to the function increase beyond one, the function assigns most of the probability to the largest input. On the other hand, when the parameters tend to zero, the softmax function returns equal probability to all the inputs.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,108.93,660.08,397.49,8.97;4,89.29,671.04,49.13,8.97"><p>The source code and instructions to run the mock server are available at: https://github.com/jmloyola/erisk_ mock_server.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,108.93,671.01,169.98,8.97"><p>https://docs.python.org/3/library/asyncio.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="6,108.93,671.02,152.16,8.97"><p>https://huggingface.co/bert-base-uncased</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6" coords="9,108.93,671.04,287.42,8.97"><p>The last year the task of early detection of depression was evaluated was 2018.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ranking</head><p>Metric UNSL#0 UNSL#1 UNSL#2 UNSL#3 UNSL#4 we can see that the choice of normalization step and the value of ùõæ play a critical role. However, considering the EarlyModels, UNSL#0 and UNSL#1 achieved measures barely over the median of all teams. Finally, the EARLIEST model (UNSL#4), did not perform well on this task either. On the other hand, Table <ref type="table" coords="11,217.27,553.54,5.17,10.91">6</ref> shows the results obtained for the performance metrics based on rankings. Here, our team did not accomplish a performance as good as with task T1. The EarlyModel UNSL#1 was the only one to reach the best performance among all teams when reading one post for P@10 and NDCG@10. UNSL#2 came close to this model, surpassing it in some metrics when reading more than 500 posts. The rest were not able to achieve good enough results.</p><p>In this task, we observe the same behavior with NDCG@100 as with task T1. When the number of posts processed increased, the ranking measure improved. EARLIEST was the only model that didn't show this behavior, which could be related to the model underfitting the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper we briefly presented the models proposed for early risk detection by our team from Universidad Nacional de San Luis for tasks T1 and T2 of the eRisk 2022 laboratory. The differences with our previous participation are described in detail and the final results are presented. Furthermore, we show a summary of the datasets used, both the provided and the generated ones.</p><p>Even though we improved last year's models, the performance obtained was not as good as the last edition. Nonetheless, our team got the best score for ERDE 50 for T1 and T2. Also, we were the third-best team with respect to the ùêπ latency metric for both tasks. Finally, considering the ranking-based metrics, our results for T1 were one of the best among all the teams.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="12,112.66,278.30,393.61,10.91;12,112.66,291.85,393.33,10.91;12,112.66,305.40,394.53,10.91;12,112.66,318.95,22.69,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,353.57,278.30,152.70,10.91;12,112.66,291.85,112.14,10.91">Overview of eRisk 2022: Early risk prediction on the internet</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mart√≠n-Rodilla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,247.41,291.85,258.58,10.91;12,112.66,305.40,295.24,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction. 13th International Conference of the CLEF Association</title>
		<meeting><address><addrLine>CLEF</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,332.50,393.33,10.91;12,112.66,346.05,393.32,10.91;12,112.66,359.59,319.84,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,274.40,332.50,24.12,10.91;12,327.34,332.50,178.64,10.91;12,112.66,346.05,154.10,10.91">CLEF lab on early risk prediction on the internet: experimental foundations</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,289.99,346.05,215.99,10.91;12,112.66,359.59,188.80,10.91">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="346" to="360" />
		</imprint>
	</monogr>
	<note>eRisk</note>
</biblStruct>

<biblStruct coords="12,112.66,373.14,393.33,10.91;12,112.66,386.69,393.53,10.91;12,112.66,400.24,221.51,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,286.13,373.14,219.85,10.91;12,112.66,386.69,34.35,10.91">Overview of eRisk: early risk prediction on the internet</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,177.78,386.69,328.41,10.91;12,112.66,400.24,90.47,10.91">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="343" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,413.79,393.61,10.91;12,112.66,427.34,393.33,10.91;12,112.66,440.89,269.16,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,353.57,413.79,152.70,10.91;12,112.66,427.34,110.69,10.91">Overview of eRisk 2021: Early risk prediction on the internet</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mart√≠n-Rodilla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,245.65,427.34,260.33,10.91;12,112.66,440.89,138.12,10.91">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="324" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,454.44,394.61,10.91;12,112.66,467.99,394.52,10.91;12,112.66,481.54,45.01,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,223.60,454.44,264.55,10.91">A test collection for research on depression and language use</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,112.66,467.99,291.91,10.91">Proc. of Conference and Labs of the Evaluation Forum (CLEF 2016)</title>
		<meeting>of Conference and Labs of the Evaluation Forum (CLEF 2016)<address><addrLine>Evora, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="28" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,495.09,393.33,10.91;12,112.66,508.64,393.33,10.91;12,112.66,522.18,141.84,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,253.35,495.09,252.63,10.91;12,112.66,508.64,24.04,10.91">Measuring the latency of depression detection in social media</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sadeque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,159.70,508.64,346.29,10.91;12,112.66,522.18,53.57,10.91">Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Eleventh ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="495" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,535.73,394.62,10.91;12,112.28,549.28,393.71,10.91;12,112.66,562.83,371.19,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,415.49,535.73,65.49,10.91;12,112.28,549.28,290.55,10.91">A comparison of three early alert policies for early risk detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Loyola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Burdisso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cagnina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Errecalde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,425.96,549.28,80.03,10.91;12,112.66,562.83,252.47,10.91">Working Notes of CLEF 2021-Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Bucarest, Romania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note>UNSL at eRisk</note>
</biblStruct>

<biblStruct coords="12,112.66,576.38,393.61,10.91;12,112.66,589.93,394.53,10.91;12,112.66,603.48,45.01,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,389.80,576.38,116.47,10.91;12,112.66,589.93,116.72,10.91">Learning when to classify for early text classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Loyola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Errecalde</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">J</forename><surname>Escalante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Gomez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,251.94,589.93,182.52,10.91">Argentine Congress of Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="24" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,617.03,393.53,10.91;12,112.66,630.58,393.32,10.91;12,112.66,644.13,266.97,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,341.05,617.03,165.14,10.91;12,112.66,630.58,81.81,10.91">Adaptive-halting policy network for early classification</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hartvigsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Rundensteiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,217.14,630.58,288.84,10.91;12,112.66,644.13,178.70,10.91">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,657.68,393.32,10.91;13,112.66,86.97,393.98,10.91;13,112.41,100.52,327.06,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,339.90,657.68,166.08,10.91;13,112.66,86.97,216.86,10.91">ùúè -SS3: A text classifier with dynamic n-grams for early risk detection over text streams</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">G</forename><surname>Burdisso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Errecalde</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y G√≥mez</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.patrec.2020.07.001</idno>
		<ptr target="https://doi.org/10.1016/j.patrec.2020.07.001" />
	</analytic>
	<monogr>
		<title level="j" coord="13,338.00,86.97,121.52,10.91">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,114.06,393.33,10.91;13,112.26,127.61,393.73,10.91;13,112.28,141.16,347.37,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,336.74,114.06,169.25,10.91;13,112.26,127.61,305.33,10.91">exBERT: Extending pre-trained models with domain-specific vocabulary under constrained training resources</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Comiter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-F</forename><surname>Kuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,440.35,127.61,65.63,10.91;13,112.28,141.16,249.38,10.91">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1433" to="1439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,154.71,395.17,10.91;13,112.66,168.26,393.33,10.91;13,112.66,181.81,107.17,10.91" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="13,354.11,154.71,153.72,10.91;13,112.66,168.26,321.53,10.91">PySS3: A python package implementing a novel text classifier with visualization tools for explainable ai</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">G</forename><surname>Burdisso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Errecalde</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y G√≥mez</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.09322</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
