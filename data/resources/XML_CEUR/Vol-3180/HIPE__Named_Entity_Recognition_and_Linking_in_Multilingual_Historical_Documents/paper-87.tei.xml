<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,88.22,398.98,8.01;1,89.29,110.14,235.21,8.01">hmBERT: Historical Multilingual Language Models for Named Entity Recognition</title>
				<funder ref="#_j2kTPrs">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,78.65,11.96"><forename type="first">Stefan</forename><surname>Schweter</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Digital Library/ Munich Digitization Center</orgName>
								<orgName type="institution">Bayerische Staatsbibliothek München</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,180.59,134.97,54.03,11.96"><forename type="first">Luisa</forename><surname>März</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Digital Philology</orgName>
								<orgName type="department" key="dep2">Research Group Data Mining and Machine Learning</orgName>
								<orgName type="institution">University of Vienna</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Natural Language Processing Expert Center</orgName>
								<orgName type="department" key="dep2">Data:Lab</orgName>
								<orgName type="institution">Volkswagen AG</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,252.54,134.97,87.27,11.96"><forename type="first">Katharina</forename><surname>Schmid</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Digital Library/ Munich Digitization Center</orgName>
								<orgName type="institution">Bayerische Staatsbibliothek München</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,370.81,134.97,55.53,11.96"><forename type="first">Erion</forename><surname>Çano</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Digital Philology</orgName>
								<orgName type="department" key="dep2">Research Group Data Mining and Machine Learning</orgName>
								<orgName type="institution">University of Vienna</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,88.22,398.98,8.01;1,89.29,110.14,235.21,8.01">hmBERT: Historical Multilingual Language Models for Named Entity Recognition</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">1A8ACCCEEEE934A8C8A21C0E9B512005</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Named Entity Recognition</term>
					<term>historical NER</term>
					<term>Transformer-based language models</term>
					<term>Historical texts</term>
					<term>Flair</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Compared to standard Named Entity Recognition (NER), identifying persons, locations, and organizations in historical texts constitutes a big challenge. To obtain machine-readable corpora, the historical text is usually scanned and Optical Character Recognition (OCR) needs to be performed. As a result, the historical corpora contain errors. Also, entities like location or organization can change over time, which poses another challenge. Overall, historical texts come with several peculiarities that differ greatly from modern texts and large labeled corpora for training a neural tagger are hardly available for this domain. In this work, we tackle NER for historical German, English, French, Swedish, and Finnish by training large historical language models. We circumvent the need for large amounts of labeled data by using unlabeled data for pretraining a language model. We propose hmBert, a historical multilingual BERT-based language model, and release the model in several versions of different sizes. Furthermore, we evaluate the capability of hmBert by solving downstream NER as part of this year's HIPE-2022 shared task and provide detailed analysis and insights. For the Multilingual Classical Commentary coarse-grained NER challenge, our tagger HISTeria outperforms the other teams' models for two out of three languages.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Standard Named Entity Recognition (NER) for high resource domains has already been successfully addressed with performances above 90% F1-score <ref type="bibr" coords="1,329.51,484.79,11.23,10.91" target="#b0">[1,</ref><ref type="bibr" coords="1,343.37,484.79,7.49,10.91" target="#b1">2]</ref>. In contrast, NER taggers often fail to achieve satisfying results in the historical domain. Since historical datasets usually stem from Optical Character Recognition (OCR) and also include domain shifts, they contain characteristic errors not found in modern text. Low-resource fonts like Fraktur pose additional challenges for clean OCR. Another problem is that large amounts of labeled data are required when training neural models and only little labeled data exists for historical NER <ref type="bibr" coords="1,396.29,552.53,11.58,10.91" target="#b2">[3]</ref>. Because of all these challenges, systems designed for contemporary datasets cannot be applied to the historical domain without adaptations or further training. However, in the last few years, a number of works have shown that it is possible to adapt systems by using different approaches <ref type="bibr" coords="1,464.98,593.18,11.43,10.91" target="#b3">[4]</ref>.</p><p>In this work, we develop a new BERT-based language model <ref type="bibr" coords="2,376.74,86.97,12.99,10.91" target="#b4">[5]</ref> for the historical context: hmBert. We tackle NER for historical German, English, French, Swedish, and Finnish. We use self-supervised learning to pretrain our language model on unlabeled data before we fine-tune the NER tagger on labeled data. This allows to reduce the need for large amounts of labeled training data. To mitigate the impact of OCR noise in the pretraining corpora, we use a filtering step that allows to control the OCR confidence of the texts.</p><p>Another design step in training language models is the choice of the underlying vocabulary. Beltagy et al. <ref type="bibr" coords="2,173.78,181.81,12.84,10.91" target="#b5">[6]</ref> showed that using a domain-specific vocabulary leads to performance improvements compared to using a general domain vocabulary. Thus, we use a sub-corpus of our pretraining corpus to create an in-domain vocabulary for the hmBert training. Finally, we arrive with a powerful hmBert model that establishes state-of-the-art results for three out of four languages on the NewsEye NER dataset <ref type="bibr" coords="2,303.37,236.01,11.49,10.91" target="#b6">[7]</ref>. As large language models require a lot of computational resources for pretraining and during inference time, we also provide smaller models.</p><p>Addressing the HIPE-2022 NERC-Coarse task, we also study a single-model vs. one-model approach. Our comparison shows that fine-tuning hmBert models for each language individually (single-model approach) improves performance compared to models that were fine-tuned on data from all languages (one-model approach). At the same time, however, fine-tuning individual models is much more computationally expensive. The one-model approach is more efficient, achieving similar performance while requiring less computation.</p><p>In addition, our final model HISTeria is trained by using multi-stage fine-tuning. We first fine-tune the multilingual model and evaluate it over the development data of all the different available languages. The resulting hyperparameter configuration is used for another finetuning step for each monolingual model. Finally, our detailed study of hmBert also includes experiments with a knowledge-based approach, training an ELECTRA-based language model <ref type="bibr" coords="2,492.15,412.15,11.28,10.91" target="#b7">[8]</ref>, and addressing a tokenization issue. These additional experiments did not enhance performance but represent a suitable starting point for further research.</p><p>Our contributions are i) the comprehensive description of the development of hmBert, ii) the release of hmBert models of different sizes, iii) the release of the hmBert pretraining code, and iv) extensive experiments using hmBert including detailed insights for the community.</p><p>This paper is structured as follows: the next section (2) describes hmBert and its development in details. We include an explanation of the used datasets, as well as processing, hyperparameter settings, and pretraining steps. We close the section with a downstream task evaluation. Section 3 provides insights into the HIPE-2022 Multilingual Commentary Challenge<ref type="foot" coords="2,426.90,532.34,3.71,7.97" target="#foot_0">1</ref>  <ref type="bibr" coords="2,433.83,534.09,11.42,10.91" target="#b8">[9]</ref>. We describe our approach for the shared task submission in detail and provide an analysis of our results. We conclude the paper with Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">hmBert: Historical Multilingual BERT Model</head><p>In this section, we present hmBert which supports German, English, French, Finnish, and Swedish. We train two different models with different vocabulary sizes: 32,000 and 64,000. We first describe the corpora used for training hmBert, as well as preprocessing and filtering steps to create the pretraining corpus. In addition, we explain the pretraining process and end the section by evaluating the model on a downstream NER task. Figure <ref type="figure" coords="3,417.79,331.03,5.17,10.91" target="#fig_0">1</ref> shows the overall pretraining procedure for hmBert and its application on downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Corpora</head><p>For German, French, Swedish and Finnish we use the Europeana newspapers<ref type="foot" coords="3,444.04,392.55,3.71,7.97" target="#foot_1">2</ref> provided by the European Library. For English we use a dataset published by the British Library <ref type="bibr" coords="3,465.11,407.86,16.28,10.91" target="#b9">[10]</ref>. The dataset contains OCR-processed text from digitized books and has also been used by Hosseini et al. <ref type="bibr" coords="3,113.33,434.96,17.91,10.91" target="#b10">[11]</ref> to train historical language models for English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Filtering</head><p>OCR full-text for the Europeana newspapers also includes an OCR confidence value. This measure indicates the average OCR confidence for each word of a newspaper <ref type="foot" coords="3,440.97,496.08,3.71,7.97" target="#foot_2">3</ref> . For German and French we perform a number of characters per year analysis using different (minimum required) OCR confidence thresholds. For German, we test three different thresholds and report the resulting dataset size (see Table <ref type="table" coords="3,249.18,538.48,10.17,10.91" target="#tab_13">15</ref> in the appendix). We use an OCR confidence threshold of 0.60 to get a final dataset of approx. 28 GB. For French, we test five different OCR confidence values (see Table <ref type="table" coords="3,165.71,565.58,10.00,10.91" target="#tab_14">16</ref> in the appendix) and choose 0.70 so that the resulting dataset size of 27 GB is comparable to the size of the German dataset. For Finnish and Swedish, we use an OCR confidence threshold of 0.60. However, training data for Swedish and Finnish is very limited. In total, only 1.2 GB for Finnish, and 1.1 GB for Swedish are available, thus these corpora are not filtered any further using other OCR confidence thresholds. For English, language filtering using   langdetect <ref type="foot" coords="4,146.01,437.29,3.71,7.97" target="#foot_3">4</ref> for each book in the corpus is performed. Additionally, we use books published between 1800 and 1900 exclusively. The resulting English corpus has a total size of 24 GB.</p><p>To get a deeper insight into the filtered corpora, we analyze the distribution of characters over time for each language. Figure <ref type="figure" coords="4,247.21,479.69,4.98,10.91" target="#fig_1">2</ref> shows the distribution for German. The period from 1865 to 1914 is well-covered in the dataset, while the years from 1683 to 1849 and the 20 th century are underrepresented. For French, the 20 th century is highly covered, but there is only little data available for the 19 th century (see Figure <ref type="figure" coords="4,290.99,520.34,3.51,10.91" target="#fig_2">3</ref>), which contrasts with the German corpus. The English corpus contains texts from the 19 th century only and shows good coverage starting from 1850. However, there is only little coverage from 1800 to 1849 (see Figure <ref type="figure" coords="4,444.74,547.44,3.61,10.91" target="#fig_3">4</ref>). Since both Finnish and Swedish corpora include newspapers from 1900 to 1910 only, we do not analyze the number of characters per year for these datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2.">Multilingual Vocabulary Generation</head><p>To create a BERT-compatible wordpiece-based vocabulary <ref type="bibr" coords="4,348.62,623.86,16.20,10.91" target="#b11">[12]</ref>, we use 10GB of each language and train the vocabulary using the Hugging Face Tokenizers library <ref type="foot" coords="4,387.02,635.66,3.71,7.97" target="#foot_4">5</ref> . We build a cased vocabu- lary with no lower casing or accent stripping being performed. For Finnish and Swedish we need to upsample<ref type="foot" coords="5,167.76,386.40,3.71,7.97" target="#foot_5">6</ref> the corpus because both corpora have a size of 1 GB only. We create a 32k and 64k vocabulary. Inspired by Rust et al. <ref type="bibr" coords="5,377.23,401.70,16.29,10.91" target="#b12">[13]</ref>, we report the subword fertility rate (SFR) and the portion of unknown (UNK) tokens per language on various historical NER datasets (see Table <ref type="table" coords="5,197.22,428.80,3.57,10.91" target="#tab_0">1</ref>). The SFR is defined as the average number of subwords a tokenizer produces per word <ref type="bibr" coords="5,177.26,442.35,16.41,10.91" target="#b12">[13]</ref>. It indicates how aggressively a tokenizer splits, i.e. whether it oversegments or not. As over-segmentation can negatively impact downstream performance, an SFR close to 1 (indicating that the tokenizer vocabulary contains every word in the input text) is optimal. UNK tokens are challenging because such tokens are not seen during pretraining and the model cannot provide useful information for them during the fine-tuning phase <ref type="bibr" coords="5,458.85,496.55,16.13,10.91" target="#b13">[14]</ref>. Table <ref type="table" coords="5,89.29,510.10,4.97,10.91">2</ref> and Table <ref type="table" coords="5,141.38,510.10,4.97,10.91" target="#tab_1">3</ref> show the SFR and portion of UNKs in the 32k/64k corpus. French and English have the lowest SFRs, whereas Finnish has the highest rate in both wordpiece-based vocabularies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Final Pretraining Corpus</head><p>For common multilingual models such as multilingual BERT [mBERT; 5], XLM-RoBERTa <ref type="bibr" coords="5,488.08,573.34,17.90,10.91" target="#b15">[16]</ref> or mT5 <ref type="bibr" coords="5,124.16,586.89,17.82,10.91" target="#b16">[17]</ref> different corpus sampling strategies have been developed to up-/downsample low-/high-resource languages <ref type="bibr" coords="5,204.25,600.43,16.25,10.91" target="#b17">[18]</ref>. Since our multilingual language model includes five languages only (mBERT covers 104 languages <ref type="foot" coords="5,244.33,612.23,3.71,7.97" target="#foot_6">7</ref> ), we use a similar size for all languages. After upsampling the Swedish and Finnish corpora to 27GB each, we arrive at a total dataset size of 130 GB. Table 4 shows an overview of the sizes per language included in our final pretraining corpus. For the hmBert model with a vocabulary size of 32k, we use the official BERT implementation <ref type="foot" coords="6,462.29,392.11,3.71,7.97" target="#foot_7">8</ref> to create pretraining data. Detailed description of all parameters used for the creation of pretraining data can be found in Section A.2 of the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Models</head><p>We pretrain an hmBert model with a vocabulary size of 32k, further denoted as ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 , and another hmBert model with a vocabulary size of 64k, further denoted as ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 .</p><p>Inspired by Hou et al. <ref type="bibr" coords="6,193.69,497.79,16.29,10.91" target="#b18">[19]</ref>, we also pretrain and release smaller hmBert models, with the number of layers ranging from 2 to 8 and hidden sizes ranging from 128 to 512. Pretraining of the different models is described in detail in Section A.3 of the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Downstream Task Evaluation</head><p>We evaluate the ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 models on the NewsEye NER dataset <ref type="bibr" coords="6,397.77,574.61,11.57,10.91" target="#b6">[7]</ref>, because this dataset includes most of the languages that hmBert covers (except English), and compare them with the current state-of-the-art reported by Hamdi et al. <ref type="bibr" coords="6,329.04,601.71,16.29,10.91" target="#b19">[20]</ref>. We use the Flair <ref type="bibr" coords="6,434.66,601.71,18.07,10.91" target="#b20">[21]</ref> library and perform a hyperparameter search (see Table <ref type="table" coords="6,293.65,615.26,10.35,10.91" target="#tab_6">18</ref> in appendix) using the common fine-tuning paradigm. Fine-tuning adds a single linear layer to a Transformer and fine-tunes the entire architecture on the NER downstream task. To bridge the difference between subword modeling and token-level predictions, subword pooling is applied to create token-level presentations which are then passed to the final linear layer. A common subword pooling strategy is to use the first subtoken to represent the entire token and we also use this strategy in our experiments.</p><p>To train our architecture, we use AdamW <ref type="bibr" coords="7,274.90,281.01,17.83,10.91" target="#b21">[22]</ref> optimizer, a very small learning rate and a fixed number of epochs as a hard-stopping criterion. We evaluate the model performance after each training epoch on the development set and use the best model (strict micro F1-score) for final evaluation. We adopt a one-cycle <ref type="bibr" coords="7,245.54,321.66,18.07,10.91" target="#b22">[23]</ref> training strategy, in which the learning rate linearly decreases until it reaches 0 by the end of the training. Tables <ref type="table" coords="7,357.27,335.21,4.97,10.91" target="#tab_3">5</ref><ref type="table" coords="7,364.95,335.21,3.61,10.91" target="#tab_4">6</ref><ref type="table" coords="7,364.95,335.21,3.61,10.91" target="#tab_5">7</ref><ref type="table" coords="7,371.27,335.21,4.97,10.91" target="#tab_6">8</ref>show the performance of our ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 models compared to the current state-of-the-art. For German, even the ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 base model could not reach the performance reported by Hamdi et al. <ref type="bibr" coords="7,144.33,375.86,16.21,10.91" target="#b19">[20]</ref>, that was based on the models developed by Boros et al. <ref type="bibr" coords="7,407.71,375.86,16.21,10.91" target="#b23">[24]</ref>. The performance difference is 1.64 percentage points. This could be due to the fact that the German NewsEye dataset is very large and the hyperparameter search needed to be extended. Furthermore, Hamdi et al. <ref type="bibr" coords="7,147.57,416.50,17.91,10.91" target="#b19">[20]</ref> proposed a new architecture for handling OCR errors by adding two extra transformer layers, whereas we only performed a standard fine-tuning approach. For French our ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 medium sized model is very close to the result reported by Hamdi et al. <ref type="bibr" coords="7,465.68,443.60,16.21,10.91" target="#b19">[20]</ref>. The ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 base model outperforms the current best result by +2.7 percentage points. The same performance gain can be observed for Finnish and Swedish: The ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 base model outperforms the current SOTA by 2.41 percentage points for Finnish, and 2.1 percentage points for the Swedish NewsEye dataset. Figure <ref type="figure" coords="7,275.01,497.80,5.11,10.91" target="#fig_4">5</ref> shows an overall performance comparison for the pretrained ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 smaller models on the NewsEye dataset. On average, the performance difference between the 8-layer ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 medium and the 12-layer ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 base model is 2.7 percentage points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">HIPE-2022: Multilingual Classical Commentary Challenge</head><p>We participated in the Multilingual Classical Commentary Challenge (MCC) that was newly introduced in the 2022 edition of HIPE <ref type="bibr" coords="7,268.44,610.62,18.07,10.91" target="#b24">[25]</ref> with our tagger being denoted as HISTeria. The challenge requires participants to work with historical classical commentaries in at least two different languages and to develop solutions for Named Entity Recognition, Classification, and/or Linking. HISTeria aims to detect and classify named entities according to coarse-grained types (NERC-Coarse task) and is described in more detail in this section. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data</head><p>A classical commentary is a scholarly publication that aims to facilitate the reading and understanding of classical works of literature by providing additional information such as translations or bibliographic references. Apart from the challenges that are common to historical texts, commentaries have other characteristics that may complicate Named Entity Recognition and Classification: they frequently cite the original literary text, making them inherently multilingual, and they often use abbreviations to convey information more concisely. For the Multilingual Classical Commentary Challenge, HIPE <ref type="foot" coords="8,330.74,631.33,3.71,7.97" target="#foot_8">9</ref> has chosen a single dataset that was  created in the context of the Ajax MultiCommentary project <ref type="foot" coords="9,368.07,441.67,7.41,7.97" target="#foot_9">10</ref> (ajmc dataset). The dataset contains excerpts from commentaries published in the 19 th century in English, French, and German. The French texts date from 1886, the German ones from 1853 and 1894, and the English ones from 1881 and 1896. This emphasis on the second half of the 19 th century fits well with the temporal distribution of our pretraining data for English and German. Apart from standard entity types like person or location, the dataset also includes domain-specific annotations like the scope and work entity type for bibliographic references. Additional dataset statistics can be found in Table <ref type="table" coords="9,156.55,538.27,5.07,10.91" target="#tab_7">9</ref> and in the HIPE 2022 Overview paper <ref type="bibr" coords="9,335.24,538.27,11.43,10.91" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Single-Models vs. One-Model Approach</head><p>In preliminary experiments models that are independently fine-tuned for each language (singlemodel approach) and a model that uses training data from all languages (one-model approach) are compared. We perform hyperparameter searches for the two approaches. The relevant hyperparameters for fine-tuning models are shown in the appendix (Table <ref type="table" coords="9,413.00,628.64,7.74,10.91" target="#tab_7">19</ref>). We use the Flair library for all experiments. For the one-model approach, a breakdown analysis for each language is performed after determining the best hyperparameter configuration. This is compared to the three independently fine-tuned models for each language. For German, the one-model approach is +0.47 percentage points better than the single-model approach. For English, the one-model approach performs slightly worse (-0.13 percentage points) and for French, the single-model approach outperforms the one-model by 0.6 percentage points. However, the single-model approach requires fine-tuning of 120 models, whereas the one-model approach only needs 40 models to be fine-tuned for hyperparameter search. To save resources, we decided to use the one-model approach for further experiments. The performance comparison on the ajmc dataset is shown in Table <ref type="table" coords="10,169.99,319.37,8.36,10.91" target="#tab_8">10</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Multi-Stage Fine-Tuning</head><p>Wang et al. <ref type="bibr" coords="10,141.27,369.10,17.91,10.91" target="#b25">[26]</ref> proposed a knowledge-based system for multilingual NER using a multi-stage fine-tuning approach for the MultiCoNER SemEval 2022 task <ref type="foot" coords="10,362.97,380.89,7.41,7.97" target="#foot_10">11</ref> . The first stage of multi-stage fine-tuning refers to training a multilingual model on data from different languages. In the second stage, this fine-tuned multilingual model is used as a starting point for training a monolingual model. We adapt this approach for our final system: in the first stage, we fine-tune one multilingual model over the training data of all three languages (German, English, and French) and optimize over all development data (one-model approach) using a hyperparameter search. We select the best hyperparameter configuration as a combination of batch size, the number of epochs, and the learning rate, which results in five models (because of five different random seeds). The hyperparameter search grid for the different stages is shown in Section B.1 in the appendix. From these five models, we choose the one with the highest F1-score on the development set for second stage fine-tunings. In the second stage, we use the best model from the first stage and fine-tune single models for each language with a hyperparameter search on the development set. For each language, we select the best hyperparameter configuration and choose the best performing model with the highest F1-score on the development set. In preliminary experiments, this multi-stage fine-tuning approach boosts performance by 1.23 percentage points on average compared to results in the first stage.</p><p>For our final submission, ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 achieves the best results during the first-stage of fine-tuning with a batch size of 4, 10 fine-tuning epochs and a learning rate of 5𝑒 -05. This results in an average F1-score of 86.89 on the (combined) development sets for ajmc. The best hyperparameter configuration for ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 can be achieved when using a batch size of 8, 10 epochs of fine-tuning and a learning rate of 3𝑒-05. This results in an overall F1-score of 86.69 percentage points. Thus, ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 is slightly worse than ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 (-0.2 percentage points). Table <ref type="table" coords="11,155.63,284.89,10.35,10.91" target="#tab_9">11</ref> shows the performance for our final submissions using ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 and ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 for all languages in the ajmc dataset. We report strict and fuzzy F1-scores using the official HIPE-scorer <ref type="foot" coords="11,193.17,310.24,7.41,7.97" target="#foot_11">12</ref> . We exclude document-level scores for better readability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">HISTeria Results</head><p>Table <ref type="table" coords="11,115.59,361.72,10.06,10.91" target="#tab_10">12</ref> shows an overview of HISTeria compared to the runs of other teams in the HIPE-2022 shared task <ref type="foot" coords="11,139.84,373.51,7.41,7.97" target="#foot_12">13</ref> .</p><p>To gain a better understanding of our models, we use the attribute-aided evaluation proposed by Fu et al. <ref type="bibr" coords="11,141.37,402.37,16.27,10.91" target="#b26">[27]</ref>. In order to highlight the strengths and weaknesses of different models, they analyze how model performance varies with regard to certain attributes. In the case of NER, properties that may influence performance are i) how consistently a given surface form of a token or an entity is labelled across a dataset (tCon and eCon), ii) how often a given token or entity appears in the dataset (tFre and eFre), iii) the number of tokens that make up an entity (eLen) or sentence (sLen) as well as iv) the relative number of out-of-vocabulary words and entities per sentence (oDen and eDen). Using the implementation by Fu et al. <ref type="bibr" coords="11,469.01,483.66,16.29,10.91" target="#b26">[27]</ref>, we distribute the values into buckets and compute the strict F1-score for each bucket. Table <ref type="table" coords="11,495.64,497.21,10.35,10.91" target="#tab_11">13</ref> shows Spearman's rank correlation coefficient as a measure of how well the attribute correlates with the F1-score, and the standard deviation of the F1-score to indicate how strongly the attribute influences performance. We omit results that are not statistically significant.</p><p>For the two German models, none of the attributes seem to correlate with performance in a statistically significant way. For the English and French models, performance correlates directly and positively with the consistency of the token labels. The standard deviation of 10% (French) and 8-9% (English) of the F1-score indicates that this attribute has a marked impact on performance. For French ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 , entity length influences performance to the same degree. In this case, performance gets worse the more tokens an entity has. The impact of entity length on English ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 and ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 is less strong but still notable (standard deviation of 6% and 1% respectively). In addition to entity length, the amount of words that did not feature in the training set also correlates negatively with the performance of English ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Challenges</head><p>We also experimented with the knowledge-based system for multilingual NER that was proposed by Wang et al. <ref type="bibr" coords="12,155.66,648.01,16.24,10.91" target="#b25">[26]</ref>. We used their implementation to enrich the original ajmc datasets with a knowledge base and implemented their context approach in the Flair library. More precisely, we used the FLERT approach <ref type="bibr" coords="13,220.37,86.97,17.83,10.91" target="#b27">[28]</ref> and utilized the knowledge-base enriched context as the left context for each training example. A left context size of 128 performs best in the experiments. However, the final result was slightly worse than using no context at all. This may be due to the fact that a contemporary, general-purpose knowledge base (Wikipedia) was used. A domainspecific knowledge base may yield better results. As the preliminary results were slightly worse than our main baseline, we did not conduct further experiments with this knowledge-based system.</p><p>We calculated the portion of UNKs in the German ajmc dataset and found that the portion rate of 16.3 % is unreasonably high. We discovered that the German ajmc dataset contains long-s characters, unlike the Europeana Newspaper corpora which were used to train a vocabulary. As a consequence, the hmBert tokenizer is not able to handle tokens that include long-s characters, resulting in UNKs. For our final system, we manually replaced all long-s characters with a normal s character to circumvent the UNK problem. In upcoming versions of our hmBert models, we will add this replacement step in the tokenizer configuration directly. Furthermore, we also trained an ELECTRA model <ref type="bibr" coords="13,256.54,276.66,12.99,10.91" target="#b7">[8]</ref> for 1M steps on the same pretraining corpus as the ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 model. We found that the downstream performance on NewsEye datasets was 1 to 3 percentage points worse than ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 and -0.28 percentage points worse on the ajmc dataset. We have therefore decided not to release the model yet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Community Contributions</head><p>To foster research on language and NER models for the historical domain, we publicly release our pretrained and fine-tuned models on the Hugging Face Model Hub<ref type="foot" coords="13,416.95,378.82,7.41,7.97" target="#foot_13">14</ref> under the dbmdz namespace <ref type="foot" coords="13,139.01,392.37,7.41,7.97" target="#foot_14">15</ref> . We also publicly release all code that was used for fine-tuning models <ref type="foot" coords="13,467.91,392.37,7.41,7.97" target="#foot_15">16</ref> . Table <ref type="table" coords="13,89.04,407.68,10.23,10.91" target="#tab_12">14</ref> shows an overview of released models for our HIPE-2022 submission, including the model identifier on the Hugging Face Model Hub. All models are released under a permissive MIT license. Additionally, we added dataset support for all HIPE-2022 NER datasets into Flair library <ref type="foot" coords="13,119.39,446.57,7.41,7.97" target="#foot_16">17</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>We presented hmBert, a new multilingual BERT-based language model for historical data. hmBert is composed of German, French, English, Finnish, and Swedish unsupervised corpora of historical OCR-processed texts. The corpora have been filtered for OCR confidence as well as sampled so that each language contributes a similar amount of data to the model. The underlying vocabulary is also derived from each of the languages used for hmBert. In our temporal analysis of the pretraining corpora, we have found that data from the 18 th and 19 th century is unevenly distributed across the different languages. For future models, we are looking for additional datasets to balance this representation. We evaluated two hmBert models of different sizes with downstream Named Entity Recognition. For the NewsEye dataset hmBert established a new state-of-the-art for three out of four languages: French, Finnish, and Swedish.</p><p>For the 2022 HIPE Multilingual Classical Commentary Challenge, our HISTeria system could outperform the other systems for two out of three languages. Using multi-stage fine-tuning together with the multilingual BERT-based model led the model to its optimal performance. Detailed analysis showed the benefits of all of hmBerts design choices, as well as interesting findings for future research. Our contributions include all of the trained hmBert models and our source code, which are made publicly available. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. hmBERT: Historical Multilingual BERT Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Corpora Filtering</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Final Pretraining Corpus</head><p>For creation of the pretraining data, we use the same parameters as BERTurk <ref type="bibr" coords="18,436.99,424.42,16.45,10.91" target="#b28">[29]</ref>: maximum sequence length = 512, maximum predictions per sequence = 75, masked language probability rate = 0.15, duplication factor = 5. Due to hardware limitations, we split the pretraining corpus into chunks of 1GB and create pretraining data for each chunk individually. For the hmBert model with a vocabulary size of 64k we use the official implementation <ref type="foot" coords="18,434.72,476.86,7.41,7.97" target="#foot_17">18</ref> with the same parameters as for the 32k model, but we increase the maximum predictions per sequence to 76.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Models</head><p>We use the official BERT implementation <ref type="foot" coords="18,279.98,540.13,7.41,7.97" target="#foot_18">19</ref> for pretraining ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 . ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 is trained with the recently proposed "token dropping" approach by Hou et al. <ref type="bibr" coords="18,436.50,555.44,16.29,10.91" target="#b29">[30]</ref>. Using this approach, unimportant tokens starting from an intermediate layer in the model are dropped to make the model focus on important tokens more efficiently, which makes model pretraining faster compared to the original BERT implementation. For both pretraining approaches, we use a maximum sequence length of 512 for the full training time. For the pretraining of ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 a batch size of 128 is used for 3M training steps. Pretraining was done on a v3-32 TPU pod within 67 hours. The pretraining of ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 was done on a single v4-8 TPU with a batch size of 512 for 1M steps within 114 hours. Figure <ref type="figure" coords="19,303.69,100.52,4.97,10.91" target="#fig_5">6</ref> shows the pretraining loss for ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 and ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 . The final ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 has 110.62M, whereas ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 has 135.19M parameters due to the increased vocabulary size.</p><p>For better comparability, we measure the number of total subtokens seen during pretraining<ref type="foot" coords="19,498.07,139.41,7.41,7.97" target="#foot_19">20</ref> and the number of total subtokens of the pretraining corpus for our two hmBert models. More precisely, ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 has seen 196B subtokens during pretraining, whereas the pretraining corpus has a total size of 42B subtokens. This results in 4.7 pretraining epochs over the corpus. Our ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 model has seen 262B subtokens during pretraining. Because of the larger vocabulary size, the number of subtokens for the corpus is 39B. This results in 6.7 pretraining epochs over the corpus. For the smaller models, we use the same pretraining data and hyperparameter as for the base ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 model and pretrain them on a v3-32 TPU pod. Table <ref type="table" coords="19,408.74,450.77,10.06,10.91" target="#tab_15">17</ref> shows an overview of pretrained models, including their model size, number of parameters and pretraining time. Figure <ref type="figure" coords="19,120.36,477.87,5.07,10.91">7</ref> shows an overview of pretraining loss for all smaller ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 models. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,257.97,416.70,9.65;3,89.29,271.49,416.88,7.21;3,89.29,283.93,25.45,4.79;3,89.29,84.19,416.66,166.57"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1:Overall pretraining of our ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 model and fine-tuning procedure for NER downstream tasks. CLS is a special symbol added in front of every input example, and SEP is a special separator token.</figDesc><graphic coords="3,89.29,84.19,416.66,166.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,89.29,171.97,418.22,4.82;4,89.29,84.19,416.66,73.39"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Number of characters per year distribution for filtered German Europeana corpus (1683-1949).</figDesc><graphic coords="4,89.29,84.19,416.66,73.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,89.29,284.79,418.23,4.82;4,89.29,197.01,416.66,73.39"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Number of characters per year distribution for filtered French Europeana corpus (1814-1944).</figDesc><graphic coords="4,89.29,197.01,416.66,73.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,89.29,391.63,416.94,4.82;4,88.99,403.59,48.55,4.79;4,89.29,309.82,416.67,73.24"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Number of characters per year distribution for filtered English corpus from British Library (1800-1899).</figDesc><graphic coords="4,89.29,309.82,416.67,73.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="9,89.29,290.58,416.69,9.65;9,89.29,304.58,127.34,4.79;9,155.91,84.19,283.47,200.03"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Overview of performance of ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 smaller models on NewsEye NER datasets. F1-score on the test set is reported here.</figDesc><graphic coords="9,155.91,84.19,283.47,200.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="19,89.29,407.36,310.91,9.65;19,184.25,245.17,226.77,149.84"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Overview of pretraining loss for ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 and ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 .</figDesc><graphic coords="19,184.25,245.17,226.77,149.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,88.99,92.50,416.99,253.25"><head>Table 1</head><label>1</label><figDesc>NER datasets that are used for calculating subword fertility rate and portion of UNKs. For English, the development dataset was used due to a missing training split.</figDesc><table coords="5,88.99,135.83,416.99,209.92"><row><cell>Language</cell><cell cols="2">NER Corpora</cell></row><row><cell>German</cell><cell cols="2">CLEF-HIPE-2020 [15], NewsEye [7]</cell></row><row><cell>French</cell><cell cols="2">CLEF-HIPE-2020 [15], NewsEye [7]</cell></row><row><cell>English</cell><cell cols="2">CLEF-HIPE-2020 [15]</cell></row><row><cell>Finnish</cell><cell cols="2">NewsEye [7]</cell></row><row><cell>Swedish</cell><cell cols="2">NewsEye [7]</cell></row><row><cell>Table 2</cell><cell></cell><cell></cell></row><row><cell cols="3">Subword fertility rate and portion of UNKs calculated on NER datasets using a 32k wordpiece-based</cell></row><row><cell>vocabulary.</cell><cell></cell><cell></cell></row><row><cell cols="3">Language Subword Fertility UNK Portion</cell></row><row><cell>German</cell><cell>1.43</cell><cell>0.0004</cell></row><row><cell>French</cell><cell>1.25</cell><cell>0.0001</cell></row><row><cell>English</cell><cell>1.25</cell><cell>0.0</cell></row><row><cell>Finnish</cell><cell>1.69</cell><cell>0.0007</cell></row><row><cell>Swedish</cell><cell>1.43</cell><cell>0.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,88.99,92.50,416.99,113.38"><head>Table 3</head><label>3</label><figDesc>Subword fertility rate and portion of UNKs calculated on NER datasets using a 64k wordpiece-based vocabulary.</figDesc><table coords="6,205.50,135.35,184.28,70.52"><row><cell cols="3">Language Subword Fertility UNK Portion</cell></row><row><cell>German</cell><cell>1.31</cell><cell>0.0004</cell></row><row><cell>French</cell><cell>1.16</cell><cell>0.0001</cell></row><row><cell>English</cell><cell>1.17</cell><cell>0.0</cell></row><row><cell>Finnish</cell><cell>1.54</cell><cell>0.0007</cell></row><row><cell>Swedish</cell><cell>1.32</cell><cell>0.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.99,232.45,259.90,118.85"><head>Table 4</head><label>4</label><figDesc>Size per language of final pretraining corpus for hmBert.</figDesc><table coords="6,246.38,263.83,102.51,87.48"><row><cell cols="2">Language Dataset Size</cell></row><row><cell>German</cell><cell>28GB</cell></row><row><cell>French</cell><cell>27GB</cell></row><row><cell>English</cell><cell>24GB</cell></row><row><cell>Finnish</cell><cell>27GB</cell></row><row><cell cols="2">Swedish 27GB</cell></row><row><cell>Total</cell><cell>130GB</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,88.99,92.50,340.88,118.88"><head>Table 5</head><label>5</label><figDesc>Performance overview of ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 models on German NewsEye NER dataset.</figDesc><table coords="7,165.40,123.88,264.47,87.51"><row><cell>Model Name</cell><cell cols="2">Development F1-Score Test F1-Score</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Tiny</cell><cell>30.16</cell><cell>24.35</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Mini</cell><cell>35.74</cell><cell>31.54</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Small</cell><cell>40.27</cell><cell>39.04</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Medium</cell><cell>43.45</cell><cell>43,41</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Base</cell><cell>46.17</cell><cell>46.66</cell></row><row><cell>Hamdi et al. [20]</cell><cell>-</cell><cell>48.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,88.99,92.50,340.88,118.85"><head>Table 6</head><label>6</label><figDesc>Performance overview of ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 models on French NewsEye NER dataset.</figDesc><table coords="8,165.40,123.88,264.47,87.48"><row><cell>Model Name</cell><cell cols="2">Development F1-Score Test F1-Score</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Tiny</cell><cell>60.04</cell><cell>50.79</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Mini</cell><cell>70.55</cell><cell>62.28</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Small</cell><cell>75.72</cell><cell>69.02</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Medium</cell><cell>78.99</cell><cell>72.51</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Base</cell><cell>81.58</cell><cell>75.10</cell></row><row><cell>Hamdi et al. [20]</cell><cell>-</cell><cell>72.7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,88.99,237.93,340.88,118.85"><head>Table 7</head><label>7</label><figDesc>Performance overview of ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 models on Finnish NewsEye NER dataset.</figDesc><table coords="8,165.40,269.30,264.47,87.48"><row><cell>Model Name</cell><cell cols="2">Development F1-Score Test F1-Score</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Tiny</cell><cell>30.37</cell><cell>34.76</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Mini</cell><cell>56.60</cell><cell>62.68</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Small</cell><cell>64.31</cell><cell>73.20</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Medium</cell><cell>69.95</cell><cell>76.34</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Base</cell><cell>76.05</cell><cell>80.11</cell></row><row><cell>Hamdi et al. [20]</cell><cell>-</cell><cell>77.7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,88.99,383.35,340.88,118.85"><head>Table 8</head><label>8</label><figDesc>Performance overview of ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 models on Swedish NewsEye NER dataset.</figDesc><table coords="8,165.40,414.73,264.47,87.48"><row><cell>Model Name</cell><cell cols="2">Development F1-Score Test F1-Score</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Tiny</cell><cell>43.65</cell><cell>38.91</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Mini</cell><cell>64.05</cell><cell>65.58</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Small</cell><cell>73.47</cell><cell>76.29</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Medium</cell><cell>78.07</cell><cell>82.47</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Base</cell><cell>81.13</cell><cell>83.60</cell></row><row><cell>Hamdi et al. [20]</cell><cell>-</cell><cell>81.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="9,88.99,337.92,328.45,76.49"><head>Table 9</head><label>9</label><figDesc>Dataset statistics about ajmc dataset.</figDesc><table coords="9,177.84,368.28,239.60,46.13"><row><cell cols="3">Language Training Sentences Development Sentences</cell></row><row><cell>German</cell><cell>1,024</cell><cell>192</cell></row><row><cell>English</cell><cell>1,154</cell><cell>252</cell></row><row><cell>French</cell><cell>894</cell><cell>202</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="10,88.99,92.50,416.99,89.50"><head>Table 10</head><label>10</label><figDesc>Performance comparison for NERC-coarse between single-model and one-model approach on ajmc development dataset. Numbers express F1-score calculated by using the strict evaluation regime.</figDesc><table coords="10,215.11,135.83,165.06,46.17"><row><cell cols="3">Language Single-Model One-Model</cell></row><row><cell>German</cell><cell>86.21</cell><cell>86.68</cell></row><row><cell>English</cell><cell>84.98</cell><cell>84.85</cell></row><row><cell>French</cell><cell>85.69</cell><cell>85.09</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="11,88.99,92.50,418.65,139.10"><head>Table 11</head><label>11</label><figDesc>Final results on ajmc development dataset for all languages using best models after multi-stage finetuning. Results are reported with official HIPE scorer.</figDesc><table coords="11,99.13,135.83,397.02,95.77"><row><cell>Submission ID</cell><cell cols="3">Hyperparameter Configuration Strict F1-Score Fuzzy F1-Score</cell></row><row><cell>German (ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 ) -1</cell><cell>bs8-e05-lr3e-05</cell><cell>91.5</cell><cell>94.2</cell></row><row><cell>German (ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 ) -2</cell><cell>bs8-e10-lr3e-05</cell><cell>92.0</cell><cell>93.9</cell></row><row><cell>English (ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 ) -1</cell><cell>bs4-e10-lr3e-05</cell><cell>89.1</cell><cell>92.9</cell></row><row><cell>English (ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 ) -2</cell><cell>bs8-e10-lr3e-05</cell><cell>88.0</cell><cell>93.8</cell></row><row><cell>French (ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 ) -1</cell><cell>bs4-e10-lr3e-05</cell><cell>86.8</cell><cell>93.1</cell></row><row><cell>French (ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 ) -2</cell><cell>bs4-e10-lr5e-05</cell><cell>85.9</cell><cell>93.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="12,88.99,92.50,416.99,243.88"><head>Table 12</head><label>12</label><figDesc>Final results on ajmc test dataset for all languages compared to other participants in the HIPE-2022 shared task. HISTeria denotes our system. Rank is ordered by strict F1-score.</figDesc><table coords="12,125.74,135.83,343.80,200.55"><row><cell cols="3">Rank Language Submission ID</cell><cell cols="2">Strict F1-Score Fuzzy F1-Score</cell></row><row><cell>1</cell><cell>German</cell><cell>L3i (team 2) -2</cell><cell>93.4</cell><cell>95.2</cell></row><row><cell>2</cell><cell>German</cell><cell>HISTeria (ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 ) -1</cell><cell>91.3</cell><cell>93.7</cell></row><row><cell>3</cell><cell>German</cell><cell>HISTeria (ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 ) -2</cell><cell>91.2</cell><cell>94.5</cell></row><row><cell>4</cell><cell>German</cell><cell>L3i (team 2) -1</cell><cell>90.8</cell><cell>93.4</cell></row><row><cell>5</cell><cell>German</cell><cell>Neural baseline</cell><cell>81.8</cell><cell>87.3</cell></row><row><cell>1</cell><cell>English</cell><cell>HISTeria (ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 ) -2</cell><cell>85.4</cell><cell>91.0</cell></row><row><cell>2</cell><cell>English</cell><cell>L3i (team 2) -1</cell><cell>85.0</cell><cell>89.4</cell></row><row><cell>3</cell><cell>English</cell><cell>L3i (team 2) -2</cell><cell>84.1</cell><cell>88.4</cell></row><row><cell>4</cell><cell>English</cell><cell>HISTeria (ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 ) -1</cell><cell>81.9</cell><cell>89.9</cell></row><row><cell>5</cell><cell>English</cell><cell>Neural baseline</cell><cell>73.6</cell><cell>82.8</cell></row><row><cell>1</cell><cell>French</cell><cell>HISTeria (ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 ) -2</cell><cell>84.2</cell><cell>88.0</cell></row><row><cell>2</cell><cell>French</cell><cell>HISTeria (ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 ) -1</cell><cell>83.3</cell><cell>88.8</cell></row><row><cell>3</cell><cell>French</cell><cell>L3i (team 2) -2</cell><cell>82.6</cell><cell>87.2</cell></row><row><cell>4</cell><cell>French</cell><cell>L3i (team 2) -1</cell><cell>79.8</cell><cell>86.0</cell></row><row><cell>5</cell><cell>French</cell><cell>Neural baseline</cell><cell>74.1</cell><cell>82.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="12,88.99,362.95,417.00,168.49"><head>Table 13</head><label>13</label><figDesc>Spearman's rank correlation coefficient and standard deviation of models' F1-score depending on different attribute values. We omit results that are not statistically significant.</figDesc><table coords="12,155.70,406.29,283.87,125.16"><row><cell>Model</cell><cell cols="3">Attribute Spearman Standard Deviation</cell></row><row><cell cols="2">English ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 tCon</cell><cell>1.0</cell><cell>0.09</cell></row><row><cell></cell><cell>eLen</cell><cell>-1.0</cell><cell>0.06</cell></row><row><cell></cell><cell>oDen</cell><cell>-1.0</cell><cell>0.09</cell></row><row><cell cols="2">English ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 tCon</cell><cell>1.0</cell><cell>0.08</cell></row><row><cell></cell><cell>eLen</cell><cell>-1.0</cell><cell>0.01</cell></row><row><cell cols="2">French ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 tCon</cell><cell>1.0</cell><cell>0.10</cell></row><row><cell></cell><cell>eLen</cell><cell>-1.0</cell><cell>0.10</cell></row><row><cell cols="2">French ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 tCon</cell><cell>1.0</cell><cell>0.10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="14,88.99,92.50,416.99,203.33"><head>Table 14</head><label>14</label><figDesc>Community contributions for our HIPE-2022 submission: Pretrained language models and fine-tuned NER models are publicly available on the Hugging Face Model Hub.</figDesc><table coords="14,108.40,135.04,378.48,160.79"><row><cell>Model Description</cell><cell>Model Name</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Tiny Model</cell><cell>dbmdz/bert-tiny-historic-multilingual-cased</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Mini Model</cell><cell>dbmdz/bert-mini-historic-multilingual-cased</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Small Model</cell><cell>dbmdz/bert-small-historic-multilingual-cased</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Medium Model</cell><cell>dbmdz/bert-medium-historic-multilingual-cased</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Base Model</cell><cell>dbmdz/bert-base-historic-multilingual-cased</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 Base Model</cell><cell>dbmdz/bert-base-historic-multilingual-64k-td-cased</cell></row><row><cell>NER First Stage (ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 )</cell><cell>dbmdz/flair-hipe-2022-ajmc-all</cell></row><row><cell>NER First Stage (ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 )</cell><cell>dbmdz/flair-hipe-2022-ajmc-all-64k</cell></row><row><cell cols="2">NER Second Stage -German (ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 ) dbmdz/flair-hipe-2022-ajmc-de</cell></row><row><cell>NER Second Stage -English (ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 )</cell><cell>dbmdz/flair-hipe-2022-ajmc-en</cell></row><row><cell>NER Second Stage -French (ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 )</cell><cell>dbmdz/flair-hipe-2022-ajmc-fr</cell></row><row><cell cols="2">NER Second Stage -German (ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 ) dbmdz/flair-hipe-2022-ajmc-de-64k</cell></row><row><cell>NER Second Stage -English (ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 )</cell><cell>dbmdz/flair-hipe-2022-ajmc-en-64k</cell></row><row><cell>NER Second Stage -French (ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 )</cell><cell>dbmdz/flair-hipe-2022-ajmc-fr-64k</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" coords="18,88.81,149.95,415.16,77.51"><head>Table 15</head><label>15</label><figDesc>Word level OCR confidence thresholds for German. Bold OCR confidence is used for the final corpus.</figDesc><table coords="18,231.65,181.32,131.98,46.13"><row><cell cols="2">OCR Confidence Dataset Size</cell></row><row><cell>0.60</cell><cell>28GB</cell></row><row><cell>0.65</cell><cell>18GB</cell></row><row><cell>0.70</cell><cell>13GB</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14" coords="18,88.81,265.99,409.87,101.42"><head>Table 16</head><label>16</label><figDesc>Word level OCR confidence thresholds for French. Bold OCR confidence is used for the final corpus.</figDesc><table coords="18,231.65,297.36,131.98,70.05"><row><cell cols="2">OCR Confidence Dataset Size</cell></row><row><cell>0.60</cell><cell>31GB</cell></row><row><cell>0.65</cell><cell>27GB</cell></row><row><cell>0.70</cell><cell>27GB</cell></row><row><cell>0.75</cell><cell>23GB</cell></row><row><cell>0.80</cell><cell>11GB</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15" coords="19,88.99,508.89,416.99,121.67"><head>Table 17</head><label>17</label><figDesc>Overview of smaller ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 models with their corresponding model size, number of parameters and pretraining time.</figDesc><table coords="19,107.50,552.22,380.28,78.34"><row><cell>Model Name</cell><cell cols="4">Number of Layers Hidden Size Parameters Pretraining Time</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Tiny</cell><cell>2</cell><cell>128</cell><cell>4.58M</cell><cell>4.3s / 1k steps</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Mini</cell><cell>4</cell><cell>256</cell><cell>11.55M</cell><cell>10.5s / 1k steps</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Small</cell><cell>4</cell><cell>512</cell><cell>29.52M</cell><cell>20.7s / 1k steps</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Medium</cell><cell>8</cell><cell>512</cell><cell>42.13M</cell><cell>35.0s / 1k steps</cell></row><row><cell>ℎ𝑚𝐵𝐸𝑅𝑇 32𝑘 Base</cell><cell>12</cell><cell>768</cell><cell>110.62M</cell><cell>80.0s / 1k steps</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,108.93,671.03,140.44,8.97"><p>https://hipe-eval.github.io/HIPE-2022/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,108.93,660.04,143.67,8.97"><p>http://www.europeana-newspapers.eu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,108.93,671.00,307.09,8.97"><p>https://www.clarin.eu/sites/default/files/Nuno_Freire_Europeana_CLARINPLUS.pdf</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,108.93,660.08,152.61,8.97"><p>https://github.com/Mimino666/langdetect</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,108.93,671.04,156.26,8.97"><p>https://github.com/huggingface/tokenizers</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="5,108.93,649.12,397.23,8.97;5,89.29,660.08,35.04,8.97"><p>For upsampling we simply concatenate the original corpus 𝑁 -times to match the desired 10 GB size per language.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="5,108.93,671.04,254.49,8.97"><p>https://github.com/google-research/bert/blob/master/multilingual.md</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="6,108.93,671.02,234.27,8.97"><p>https://github.com/google-research/bert#pre-training-with-bert</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="8,108.93,671.00,336.95,8.97"><p>https://github.com/hipe-eval/HIPE-2022-data/blob/main/documentation/README-ajmc.md</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9" coords="9,108.93,671.02,198.86,8.97"><p>https://mromanello.github.io/ajax-multi-commentary/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10" coords="10,108.93,671.02,103.42,8.97"><p>https://multiconer.github.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_11" coords="11,108.93,660.07,152.74,8.97"><p>https://github.com/hipe-eval/HIPE-scorer</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_12" coords="11,108.93,671.03,168.25,8.97"><p>https://github.com/hipe-eval/HIPE-2022-eval/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_13" coords="13,108.93,638.16,84.73,8.97"><p>https://huggingface.co/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_14" coords="13,108.93,649.12,109.11,8.97"><p>https://huggingface.co/dbmdz</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_15" coords="13,108.93,660.08,130.21,8.97"><p>https://github.com/dbmdz/clef-hipe</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_16" coords="13,108.93,671.04,295.16,8.97"><p>Added in Flair version 0.11: https://github.com/flairNLP/flair/releases/tag/v0.11</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_17" coords="18,108.93,649.11,389.88,8.97;18,89.29,660.07,115.42,8.97"><p>https://github.com/tensorflow/models/blob/27fb855b027ead16d2616dcb59c67409a2176b7f/official/legacy/ bert/README.md#pre-training</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_18" coords="18,108.93,671.03,146.79,8.97"><p>https://github.com/google-research/bert</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20" xml:id="foot_19" coords="19,108.93,660.08,397.05,8.97;19,89.29,671.04,74.90,8.97"><p>Total number of subtokens during pretraining can be calculated as multiplication of training steps, batch size and sequence length</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We would like to thank <rs type="institution">Google's TPU Research Cloud (TRC)</rs> <rs type="programName">program</rs> for giving us access to TPUs that were used for training our hmBert models. We would also like to thank <rs type="person">Hugging Face</rs> for providing the ability to host and perform inferencing of our models on the Hugging Face Model Hub.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_j2kTPrs">
					<orgName type="program" subtype="full">program</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Downstream Task Evaluation</head><p>As a batch size of 16 and learning rates of 1𝑒 -05 and 2𝑒 -05 do not perform well, we exclude them when performing hyperparameter search with ℎ𝑚𝐵𝐸𝑅𝑇 64𝑘 .</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="14,112.66,560.75,393.33,10.91;14,112.66,574.30,393.33,10.91;14,112.66,587.85,394.53,10.91;14,112.30,601.40,394.89,10.91;14,112.66,614.95,273.56,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="14,288.78,560.75,217.20,10.91;14,112.66,574.30,84.37,10.91">Pooled Contextualized Embeddings for Named Entity Recognition</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1078</idno>
	</analytic>
	<monogr>
		<title level="m" coord="14,227.79,574.30,278.19,10.91;14,112.66,587.85,389.93,10.91">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="724" to="728" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="14,112.66,628.50,393.33,10.91;14,112.66,642.04,393.33,10.91;14,112.66,655.59,393.33,10.91;15,112.48,86.97,393.71,10.91;15,112.66,100.52,145.69,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="14,391.19,628.50,114.80,10.91;14,112.66,642.04,183.27,10.91">Automated Concatenation of Embeddings for Structured Prediction</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,321.69,642.04,184.30,10.91;14,112.66,655.59,393.33,10.91;15,112.48,86.97,316.98,10.91">the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,114.06,393.33,10.91;15,112.66,127.61,394.52,10.91;15,112.66,141.16,255.62,10.91" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="15,330.98,114.06,175.00,10.91;15,112.66,127.61,85.78,10.91">Diachronic Evaluation of NER Systems on Old Newspapers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Colavizza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Rochat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kaplan</surname></persName>
		</author>
		<ptr target="http://infoscience.epfl.ch/record/221391" />
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="97" to="107" />
			<pubPlace>Bochum, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Bochumer Linguistische Arbeitsberichte</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,154.71,393.33,10.91;15,112.66,168.26,393.33,10.91;15,112.33,181.81,251.68,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="15,420.50,154.71,85.48,10.91;15,112.66,168.26,270.96,10.91">A Survey of Named Entity Recognition and Classification in Historical Documents</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Linhares Pontes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Douvet</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2109.11406" />
	</analytic>
	<monogr>
		<title level="j" coord="15,392.82,168.26,113.16,10.91">ACM Computing Surveys</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="15,112.66,195.36,393.33,10.91;15,112.33,208.91,393.65,10.91;15,112.66,222.46,393.32,10.91;15,112.66,236.01,393.33,10.91;15,112.66,249.56,394.88,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="15,321.08,195.36,184.91,10.91;15,112.33,208.91,192.59,10.91">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m" coord="15,330.38,208.91,175.60,10.91;15,112.66,222.46,393.32,10.91;15,112.66,236.01,99.97,10.91">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="15,112.66,263.11,394.61,10.91;15,112.66,276.66,393.33,10.91;15,112.66,290.20,395.17,10.91;15,112.66,303.75,394.53,10.91;15,112.66,317.30,163.56,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="15,234.41,263.11,253.35,10.91">SciBERT: A Pretrained Language Model for Scientific Text</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1371</idno>
	</analytic>
	<monogr>
		<title level="m" coord="15,112.66,276.66,393.33,10.91;15,112.66,290.20,395.17,10.91;15,112.66,303.75,229.97,10.91">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3615" to="3620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,330.85,394.53,10.91;15,112.66,344.40,393.33,10.91;15,112.66,357.95,292.45,10.91" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="15,112.66,344.40,393.33,10.91;15,112.66,357.95,109.63,10.91">Multilingual Dataset for Named Entity Recognition, Entity Linking and Stance Detection in Historical Newspapers</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">L</forename><surname>Pontes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Boros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">T H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hackl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.4573313</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,371.50,393.33,10.91;15,112.66,385.05,393.33,10.91;15,112.66,398.60,337.83,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="15,331.30,371.50,174.69,10.91;15,112.66,385.05,192.43,10.91">ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=r1xMH1BtvB" />
	</analytic>
	<monogr>
		<title level="m" coord="15,332.29,385.05,173.70,10.91;15,112.66,398.60,69.13,10.91">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,412.15,395.17,10.91;15,112.66,425.70,394.61,10.91;15,112.28,439.25,394.91,10.91;15,112.28,452.79,394.91,10.91;15,112.66,466.34,393.33,10.91;15,112.66,479.89,394.53,10.91;15,112.66,493.44,22.69,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="15,424.19,412.15,83.64,10.91;15,112.66,425.70,373.61,10.91">Overview of HIPE-2022: Named Entity Recognition and Linking in Multilingual Historical Documents</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Najem-Meyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,339.03,452.79,168.16,10.91;15,112.66,466.34,393.33,10.91;15,112.66,479.89,125.83,10.91">Proceedings of the Thirteenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="15,269.88,479.89,184.66,10.91">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Degli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Esposti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Sebastiani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Pasi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Thirteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="15,112.66,506.99,394.51,10.91;15,112.66,522.98,26.14,7.90" xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">L</forename><surname>Labs</surname></persName>
		</author>
		<idno type="DOI">10.21250/DB14</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Digitised books. c.. ocr derived text)</note>
</biblStruct>

<biblStruct coords="15,112.66,534.09,393.53,10.91;15,112.66,547.64,395.01,10.91" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Beelen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Colavizza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">Coll</forename><surname>Ardanuy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.11321</idno>
		<idno>arXiv:2105.11321</idno>
		<title level="m" coord="15,374.08,534.09,132.10,10.91;15,112.66,547.64,121.46,10.91">Neural Language Models for Nineteenth-Century English</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,561.19,394.53,10.91;15,112.66,574.74,394.53,10.91;15,112.66,588.29,394.53,10.91;15,112.66,601.84,394.61,10.91;15,112.66,615.39,395.01,10.91;15,112.66,628.93,264.57,10.91" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="15,306.89,601.84,200.38,10.91;15,112.66,615.39,261.96,10.91">Google&apos;s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Klingner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kazawa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Kurian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Riesa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rudnick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="1609.08144" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,642.48,393.33,10.91;15,112.66,656.03,393.33,10.91;15,112.66,669.58,393.33,10.91;16,112.66,86.97,394.52,10.91;16,112.28,100.52,394.89,10.91;16,112.36,116.51,121.59,7.90" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="15,346.68,642.48,159.31,10.91;15,112.66,656.03,293.96,10.91">How Good is Your Tokenizer? On the Monolingual Performance of Multilingual Language Models</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rust</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Vulić</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.243</idno>
	</analytic>
	<monogr>
		<title level="m" coord="15,437.75,656.03,68.23,10.91;15,112.66,669.58,393.33,10.91;16,112.66,86.97,281.02,10.91">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3118" to="3135" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="16,112.66,127.61,393.33,10.91;16,112.66,141.16,393.33,10.91;16,112.66,154.71,394.53,10.91;16,112.66,168.26,394.51,10.91;16,112.66,184.25,115.65,7.90" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="16,310.28,127.61,195.71,10.91;16,112.66,141.16,147.21,10.91">UNKs Everywhere: Adapting Multilingual Language Models to New Scripts</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Vulić</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.800</idno>
	</analytic>
	<monogr>
		<title level="m" coord="16,282.82,141.16,223.17,10.91;16,112.66,154.71,394.53,10.91;16,112.66,168.26,49.12,10.91">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Online and</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Online and<address><addrLine>Punta Cana, Dominican Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="10186" to="10203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,195.36,393.33,10.91;16,112.66,208.91,393.32,10.91;16,112.66,222.46,331.58,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="16,356.51,195.36,149.48,10.91;16,112.66,208.91,247.11,10.91">Extended Overview of CLEF HIPE 2020: Named Entity Processing on Historical Newspapers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Flückiger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.4117566</idno>
	</analytic>
	<monogr>
		<title level="s" coord="16,436.55,209.92,69.44,9.72;16,112.66,223.47,48.39,9.72">CEUR Workshop Proceedings</title>
		<imprint>
			<biblScope unit="volume">2696</biblScope>
			<biblScope unit="page">38</biblScope>
			<date type="published" when="2020">2696. 2020</date>
			<publisher>CEUR-WS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,236.01,394.53,10.91;16,112.66,249.56,393.33,10.91;16,112.66,263.11,393.33,10.91;16,112.66,276.66,397.48,10.91;16,112.36,292.65,157.20,7.90" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="16,273.11,249.56,232.87,10.91;16,112.66,263.11,31.29,10.91">Unsupervised Cross-lingual Representation Learning at Scale</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.747</idno>
	</analytic>
	<monogr>
		<title level="m" coord="16,165.95,263.11,340.04,10.91;16,112.66,276.66,233.00,10.91">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8440" to="8451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,303.75,394.61,10.91;16,112.28,317.30,393.70,10.91;16,112.66,330.85,393.33,10.91;16,112.66,344.40,394.52,10.91;16,112.66,357.95,316.00,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="16,484.95,303.75,22.32,10.91;16,112.28,317.30,284.93,10.91">mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.41</idno>
	</analytic>
	<monogr>
		<title level="m" coord="16,421.58,317.30,84.40,10.91;16,112.66,330.85,393.33,10.91;16,112.66,344.40,390.24,10.91">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="483" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,371.50,394.53,10.91;16,112.66,385.05,393.32,10.91;16,112.66,398.60,394.62,10.91;16,112.31,412.15,387.34,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="16,230.93,371.50,193.89,10.91">Cross-lingual Language Model Pretraining</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2019/file/c04c19c2c2474dbf5f7ac4372c5b9af1-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="s" coord="16,420.63,385.05,85.36,10.91;16,112.66,398.60,144.34,10.91">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alché-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
			<publisher>Curran Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,425.70,393.53,10.91;16,112.66,439.25,395.01,10.91" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">Yuanzhe</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.13240</idno>
		<idno>arXiv:2203.13240</idno>
		<title level="m" coord="16,418.25,425.70,87.94,10.91;16,112.66,439.25,115.59,10.91">Token Dropping for Efficient BERT Pretraining</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,452.79,393.71,10.91;16,112.66,466.34,393.33,10.91;16,112.66,479.89,393.33,10.91;16,112.66,493.44,273.68,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="16,498.63,452.79,7.73,10.91;16,112.66,466.34,393.33,10.91;16,112.66,479.89,97.37,10.91">A Multilingual Dataset for Named Entity Recognition, Entity Linking and Stance Detection in Historical Newspapers</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Boroş</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">L</forename><surname>Pontes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">T H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hackl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,233.64,479.89,272.35,10.91;16,112.66,493.44,244.04,10.91">Proceedings of the 44rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 44rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,506.99,393.33,10.91;16,112.66,520.54,393.33,10.91;16,112.28,534.09,394.91,10.91;16,112.66,547.64,70.43,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="16,407.80,506.99,98.18,10.91;16,112.66,520.54,149.13,10.91">FLAIR: An easy-to-use framework for state-of-the-art NLP</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Schweter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,283.85,520.54,222.14,10.91;16,112.28,534.09,390.09,10.91">NAACL 2019, 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="54" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,561.19,393.33,10.91;16,112.66,574.74,393.33,10.91;16,112.66,588.29,58.17,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="16,233.10,561.19,180.82,10.91">Decoupled weight decay regularization</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Bkg6RiCqY7" />
	</analytic>
	<monogr>
		<title level="m" coord="16,446.71,561.19,59.28,10.91;16,112.66,574.74,182.30,10.91">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,601.84,393.33,10.91;16,112.66,615.39,395.01,10.91;16,112.66,631.38,97.35,7.90" xml:id="b22">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">N</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.09820</idno>
		<idno>arXiv:1803.09820</idno>
		<title level="m" coord="16,166.78,601.84,339.21,10.91;16,112.66,615.39,209.16,10.91">A disciplined approach to neural network hyper-parameters: Part 1 -learning rate, batch size, momentum, and weight decay</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,642.48,394.53,10.91;16,112.28,656.03,393.71,10.91;16,112.66,669.58,394.53,10.91;17,112.28,86.97,360.95,10.91" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="16,166.23,656.03,339.75,10.91;16,112.66,669.58,46.92,10.91">Alleviating Digitization Errors in Named Entity Recognition for Historical Documents</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Boros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Linhares Pontes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Cabrera-Diego</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Sidere</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.conll-1.35" />
	</analytic>
	<monogr>
		<title level="m" coord="16,181.63,669.58,320.95,10.91">Proc. of the 24th Conference on Computational Natural Language Learning</title>
		<meeting>of the 24th Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="431" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,100.52,393.32,10.91;17,112.33,114.06,394.94,10.91;17,112.66,127.61,96.20,10.91;17,208.86,125.86,4.03,7.97;17,216.11,127.61,289.87,10.91;17,112.66,141.16,394.03,10.91;17,112.66,154.71,173.99,10.91" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="17,353.42,100.52,152.57,10.91;17,112.33,114.06,373.07,10.91">Introducing the HIPE 2022 Shared Task:Named Entity Recognition and Linking in Multilingual Historical Documents</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-99739-7_44</idno>
		<ptr target="https://link.springer.com/chapter/10.1007/978-3-030-99739-7_44" />
	</analytic>
	<monogr>
		<title level="m" coord="17,112.66,127.61,96.20,10.91;17,208.86,125.86,4.03,7.97;17,216.11,127.61,220.42,10.91">Proceedings of the 44 d European Conference on IR Research (ECIR 2022)</title>
		<title level="s" coord="17,443.62,127.61,62.37,10.91;17,112.66,141.16,90.30,10.91">Lecture Notes in Computer Science</title>
		<meeting>the 44 d European Conference on IR Research (ECIR 2022)<address><addrLine>Stavanger, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,168.26,394.53,10.91;17,112.14,181.81,393.85,10.91;17,112.66,195.36,395.01,10.91;17,112.66,211.35,97.35,7.90" xml:id="b25">
	<monogr>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="2203.00545" />
		<title level="m" coord="17,193.54,181.81,312.44,10.91;17,112.66,195.36,191.67,10.91">DAMO-NLP at SemEval-2022 Task 11: A Knowledge-based System for Multilingual Named Entity Recognition</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,222.46,395.17,10.91;17,112.66,236.01,393.33,10.91;17,112.66,249.56,394.53,10.91;17,112.66,263.11,228.84,10.91" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="17,217.91,222.46,289.92,10.91;17,112.66,236.01,16.17,10.91">Interpretable Multi-dataset Evaluation for Named Entity Recognition</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.489</idno>
	</analytic>
	<monogr>
		<title level="m" coord="17,151.42,236.01,354.57,10.91;17,112.66,249.56,283.96,10.91">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6058" to="6069" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,276.66,394.53,10.91;17,112.66,290.20,122.77,10.91" xml:id="b27">
	<monogr>
		<title level="m" type="main" coord="17,214.89,276.66,287.56,10.91">FLERT: Document-Level Features for Named Entity Recognition</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Schweter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Akbik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.06993</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,303.75,395.00,10.91" xml:id="b28">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Schweter</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.3770924</idno>
		<title level="m" coord="17,167.97,303.75,158.09,10.91">BERTurk -BERT models for Turkish</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,317.30,393.33,10.91;17,112.66,330.85,395.17,10.91;17,112.66,344.40,394.53,10.91;17,112.66,357.95,379.80,10.91" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="17,380.99,317.30,125.00,10.91;17,112.66,330.85,74.82,10.91">Token Dropping for Efficient BERT Pretraining</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2022.acl-long.262" />
	</analytic>
	<monogr>
		<title level="m" coord="17,209.54,330.85,298.29,10.91;17,112.66,344.40,94.56,10.91">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3774" to="3784" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
