<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,88.22,377.60,8.01;1,89.29,110.14,397.31,8.01;1,89.29,132.05,89.00,8.01">Extended Overview of HIPE-2022: Named Entity Recognition and Linking in Multilingual Historical Documents</title>
				<funder>
					<orgName type="full">SoNAR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,160.47,76.29,5.42"><forename type="first">Maud</forename><surname>Ehrmann</surname></persName>
							<email>maud.ehrmann@epfl.ch</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Digital Humanities Laboratory</orgName>
								<orgName type="institution">Ecole Polytechnique F√©d√©rale de Lausanne (EPFL)</orgName>
								<address>
									<settlement>Lausanne</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,178.22,160.47,89.60,5.42"><forename type="first">Matteo</forename><surname>Romanello</surname></persName>
							<email>matteo.romanello@unil.ch</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Lausanne</orgName>
								<address>
									<settlement>Lausanne</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.47,160.47,93.50,5.42"><forename type="first">Sven</forename><surname>Najem-Meyer</surname></persName>
							<email>sven.najem-meyer@epfl.ch</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Digital Humanities Laboratory</orgName>
								<orgName type="institution">Ecole Polytechnique F√©d√©rale de Lausanne (EPFL)</orgName>
								<address>
									<settlement>Lausanne</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,386.62,160.47,77.64,5.42"><forename type="first">Antoine</forename><surname>Doucet</surname></persName>
							<email>antoine.doucet@univ-lr.fr</email>
							<affiliation key="aff2">
								<orgName type="institution">University of La Rochelle</orgName>
								<address>
									<settlement>La Rochelle</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,174.41,83.52,5.42"><forename type="first">Simon</forename><surname>Clematide</surname></persName>
							<email>simon.clematide@uzh.ch</email>
							<affiliation key="aff3">
								<orgName type="department">Department of Computational Linguistics</orgName>
								<orgName type="institution">University of Zurich</orgName>
								<address>
									<settlement>Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,88.22,377.60,8.01;1,89.29,110.14,397.31,8.01;1,89.29,132.05,89.00,8.01">Extended Overview of HIPE-2022: Named Entity Recognition and Linking in Multilingual Historical Documents</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">E9C142C17169DF0A443B570C13F67D16</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Named entity recognition and classification</term>
					<term>Entity linking</term>
					<term>Historical texts</term>
					<term>Information extraction</term>
					<term>Digitised newspapers</term>
					<term>Classical commentaries</term>
					<term>Digital humanities</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents an overview of the second edition of HIPE (Identifying Historical People, Places and other Entities), a shared task on named entity recognition and linking in multilingual historical documents. Following the success of the first CLEF-HIPE-2020 evaluation lab, HIPE-2022 confronts systems with the challenges of dealing with more languages, learning domain-specific entities, and adapting to diverse annotation tag sets. This shared task is part of the ongoing efforts of the natural language processing and digital humanities communities to adapt and develop appropriate technologies to efficiently retrieve and explore information from historical texts. On such material, however, named entity processing techniques face the challenges of domain heterogeneity, input noisiness, dynamics of language, and lack of resources. In this context, the main objective of HIPE-2022, run as an evaluation lab of the CLEF 2022 conference, is to gain new insights into the transferability of named entity processing approaches across languages, time periods, document types, and annotation tag sets. Tasks, corpora, and results of participating teams are presented. Compared to the condensed overview [1], this paper contains more refined statistics on the datasets, a break down of the results per type of entity, and a discussion of the 'challenges' proposed in the shared task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="24" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="25" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="26" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Through decades of massive digitisation, an unprecedented amount of historical documents became available in digital format, along with their machine-readable texts. While this represents a major step forward in terms of preservation and accessibility, it also bears the potential for new ways to engage with historical documents' contents. The application of machine reading to historical documents is potentially transformative and the next fundamental challenge is to adapt and develop appropriate technologies to efficiently search, retrieve and explore information from this 'big data of the past' <ref type="bibr" coords="2,221.28,117.33,11.28,4.94" target="#b1">[2]</ref>. Semantic indexing of historical documents is in great demand among humanities scholars, and the interdisciplinary efforts of the digital humanities (DH), natural language processing (NLP), computer vision and cultural heritage communities are progressively pushing forward the processing of facsimiles, as well as the extraction, linking and representation of the complex information enclosed in transcriptions of digitised collections <ref type="bibr" coords="2,492.63,171.52,11.28,4.94" target="#b2">[3]</ref>. In this regard, information extraction techniques, and particularly named entity (NE) processing, can be considered among the first and most crucial processing steps.</p><p>Yet, the recognition, classification and disambiguation of NEs in historical texts is not straightforward, and performances are not on par with what is usually observed on contemporary well-edited English news material <ref type="bibr" coords="2,246.80,239.27,11.59,4.94" target="#b3">[4]</ref>. In particular, NE processing on historical documents faces the challenges of domain heterogeneity, input noisiness, dynamics of language, and lack of resources <ref type="bibr" coords="2,145.51,266.37,11.39,4.94" target="#b4">[5]</ref>. Although some of these issues have already been tackled in isolation in other contexts (with e.g., user-generated text), what makes the task particularly difficult is their simultaneous combination and their magnitude: texts are severely noisy, and domains and time periods are far apart. Motivation and Objectives. As the first evaluation campaign of its kind on multilingual historical newspaper material, the CLEF-HIPE-2020 edition<ref type="foot" coords="2,359.90,331.48,3.71,3.61" target="#foot_0">1</ref>  <ref type="bibr" coords="2,366.85,334.11,11.47,4.94" target="#b5">[6,</ref><ref type="bibr" coords="2,381.06,334.11,9.03,4.94" target="#b6">7]</ref> proposed the tasks of NE recognition and classification (NERC) and entity linking (EL) in ca. 200 years of historical newspapers written in English, French and German. HIPE-2020 brought together 13 teams who submitted a total of 75 runs for 5 different task bundles. The main conclusion of this edition was that neural-based approaches can achieve good performances on historical NERC when provided with enough training data, but that progress is still needed to further improve performances, adequately handle OCR noise and small-data settings, and better address entity linking. HIPE-2022 attempts to drive further progress on these points, and also confront systems with new challenges. An additional point is that in the meantime several European cultural heritage projects have prepared additional NE-annotated text material, thus opening a unique window of opportunity to organize a second edition of the HIPE evaluation lab in 2022.</p><p>HIPE-2022 <ref type="foot" coords="2,146.42,480.52,3.71,3.61" target="#foot_1">2</ref> shared task focuses on named entity processing in historical documents covering the period from the 18th to the 20th century and featuring several languages. Compared to the first edition, HIPE-2022 introduces several novelties:</p><p>‚Ä¢ the addition of a new type of document alongside historical newspapers, namely classical commentaries <ref type="foot" coords="2,179.34,543.68,3.71,3.61" target="#foot_2">3</ref> ;</p><p>‚Ä¢ the consideration of a broader language spectrum, with 5 languages for historical newspapers (3 for the previous edition), and 3 for classical commentaries;</p><p>‚Ä¢ the confrontation with heterogeneous annotation tag sets and guidelines.</p><p>Overall, HIPE-2022 confronts participants with the challenges of dealing with more languages, learning domain-specific entities, and adapting to diverse annotation schemas. The objectives of the evaluation lab are to contribute new insights on how best to ensure the transferability of NE processing approaches across languages, time periods, document and annotation types, and to answer the question whether one architecture or model can be optimised to perform well across settings and annotation targets in a cultural heritage context. In particular, the following research questions are addressed:</p><p>1. How well can general prior knowledge transfer to historical texts? 2. Are in-domain language representations (i.e. language models learned on the historical document collections) beneficial, and under which conditions?</p><p>3. How can systems adapt and integrate training material with different annotations?</p><p>4. How can systems, with limited additional in-domain training material, (re)target models to produce a certain type of annotation?</p><p>Recent work on NERC showed encouraging progress on several of these topics: Beryozkin et al. <ref type="bibr" coords="3,102.23,320.98,12.81,4.94" target="#b7">[8]</ref> proposed a method to deal with related, but heterogeneous tag sets. Several researchers successfully applied meta-learning strategies to NERC to improve transfer learning: Li et al. <ref type="bibr" coords="3,103.67,348.08,13.00,4.94" target="#b8">[9]</ref> improved results for extreme low-resource few-shot settings where only a handful of annotated examples for each entity class are used for training; Wu et al. <ref type="bibr" coords="3,440.09,361.63,18.06,4.94" target="#b9">[10]</ref> presented techniques to improve cross-lingual transfer; and Li et al. <ref type="bibr" coords="3,347.99,375.18,17.97,4.94" target="#b10">[11]</ref> tackled the problem of domain shifts and heterogeneous label sets using meta-learning, proposing a highly data-efficient domain adaptation approach.</p><p>The remainder of this paper is organized as follows. Sections 2 and 3 present the tasks and the material used for the evaluation. Section 4 details the evaluation framework, with evaluation metrics and the organisation of system submissions around tracks and challenges. Section 5 introduces the participating systems, while Section 6 presents and discusses their results. Finally, Section 7 summarizes the benefits of the task and concludes. <ref type="foot" coords="3,393.08,467.39,3.71,3.61" target="#foot_3">4</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Task Description</head><p>HIPE-2022 focuses on the same tasks as CLEF-HIPE-2020, namely:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task 1: Named Entity Recognition and Classification (NERC)</head><p>‚Ä¢ Subtask NERC-Coarse: this task includes the recognition and classification of high-level entity types (person, organisation, location, product and domain-specific entities, e.g. mythological characters or literary works in classical commentaries).</p><p>‚Ä¢ Subtask NERC-Fine: includes the recognition and classification of entity mentions according to fine-grained types, plus the detection and classification of nested entities of depth 1. This subtask is proposed for English, French and German only. Task 2: Named Entity Linking (EL) This task corresponds to the linking of named entity mentions to a unique item ID in Wikidata, our knowledge base of choice, or to a NIL value if the mention does not have a corresponding item in the knowledge base (KB). We will allow submissions of both end-to-end systems (NERC and EL) and of systems performing exclusively EL on gold entity mentions provided by the organizers (EL-only).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Data</head><p>HIPE-2022 data consists of six NE-annotated datasets composed of historical newspapers and classic commentaries covering ca. 200 years. Datasets originate from the previous HIPE-2020 campaign, from HIPE organisers' previous research project, and from several European cultural heritage projects which agreed to postpone the publication of 10% to 20% of their annotated material to support HIPE-2022. Original datasets feature several languages and were annotated with different entity tag sets and according to different annotation guidelines. See Table <ref type="table" coords="4,485.32,442.79,5.11,4.94" target="#tab_0">1</ref> for an overview.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Original Datasets</head><p>Historical newspapers. The historical newspaper data is composed of several datasets in English, Finnish, French, German and Swedish which originate from various projects and national libraries in Europe:</p><p>‚Ä¢ HIPE-2020 data corresponds to the datasets of the first HIPE-2020 campaign. They are composed of articles from Swiss, Luxembourgish and American newspapers in French, German and English (19C-20C) that were assembled during the impresso project<ref type="foot" coords="4,480.10,583.13,3.71,3.61" target="#foot_4">5</ref>  <ref type="bibr" coords="4,487.15,585.76,16.41,4.94" target="#b12">[13]</ref>.</p><p>Together, the train, dev and test hipe2020 datasets contain 17,553 linked entity mentions, classified according to a fine-grained tag set, where nested entities, mention components and metonymic senses are also annotated <ref type="bibr" coords="4,304.10,626.41,16.25,4.94" target="#b13">[14]</ref>.</p><p>‚Ä¢ NewsEye data corresponds to a set of NE-annotated datasets composed of newspaper articles in French, German, Finnish and Swedish (19C-20C) <ref type="bibr" coords="5,384.11,103.78,16.33,4.94" target="#b14">[15]</ref>. Built in the context of the NewsEye project<ref type="foot" coords="5,207.78,114.69,3.71,3.61" target="#foot_5">6</ref> , the newseye train, dev and test sets contain 36,790 linked entity mentions, classified according to a coarse-grained tag set and annotated on the basis of guidelines similar to the ones used for hipe2020. Roughly 20% of the data was retained from the original dataset publication and is published for the first time for HIPE-2022, where it is used as test data (thus the previously published test set became a second dev set in HIPE-2022 data distribution).</p><p>‚Ä¢ ‚Ä¢ Living with Machines data corresponds to an NE-annotated dataset composed of newspaper articles from the British Library newspapers in English (18C-19C) and assembled in the context of the Living with Machine project <ref type="foot" coords="5,321.01,391.66,3.71,3.61" target="#foot_7">8</ref> . The topres19th dataset contains 4,601 linked entity mentions, exclusively of geographical types annotated following their own annotation guidelines <ref type="bibr" coords="5,216.51,421.40,16.29,4.94" target="#b15">[16]</ref>. Part of this data has been retained from the original dataset publication and is used and released for the first time for HIPE-2022.</p><p>Historical commentaries. The classical commentaries data originates from the Ajax Multi-Commentary project and is composed of OCRed 19C commentaries published in French, German and English <ref type="bibr" coords="5,142.17,487.55,16.09,4.94" target="#b16">[17]</ref>, annotated with both universal NEs (person, location, organisation) and domainspecific NEs (bibliographic references to primary and secondary literature). In the field of classical studies, commentaries constitute one of the most important and enduring forms of scholarship, together with critical editions and translations. They are information-rich texts, characterised by a high density of NEs.</p><p>These six datasets compose the HIPE-2022 corpus. They underwent several preparation steps, with conversion to the tab-separated HIPE format, correction of data inconsistencies, metadata consolidation, re-annotation of parts of the datasets, deletion of extremely rare entities (esp. for topres19th), and rearrangement or composition of train and dev splits <ref type="foot" coords="5,408.22,601.81,3.71,3.61" target="#foot_8">9</ref> . The datasets in the corpus are quite heterogeneous in terms of annotation guidelines. Two datasets -hipe2020 and letemps -follow the same guidelines <ref type="bibr" coords="7,385.47,192.09,16.56,4.94" target="#b13">[14,</ref><ref type="bibr" coords="7,405.44,192.09,12.42,4.94" target="#b17">18]</ref>, and newseye was annotated using a slightly modified version of these guidelines. In the sonar dataset, persons, locations and organisations were annotated, whereas in topres19th only toponyms were considered. Compared to the other datasets, ajmc stands out for having being annotated according to domain-specific guidelines <ref type="bibr" coords="7,263.15,246.29,16.09,4.94" target="#b18">[19]</ref>, which focus on bibliographic references to primary and secondary literature. This heterogeneity of guidelines leads to a wide variety of entity types and sub-types for the NERC task (see Table <ref type="table" coords="7,278.26,273.39,4.97,4.94" target="#tab_2">2</ref> and<ref type="table" coords="7,304.10,273.39,3.50,4.94" target="#tab_5">5</ref>). Among these types, only persons, locations and organisations are found in all datasets (except for topres19th), thus constituting a set of "universal" entity types. Certain entity types are under-represented in some datasets (e.g. objects, locations and dates in ajmc) and, as such, constitute good candidates for the application of data augmentation strategies. Moreover, while nested entities are annotated in all datasets except topres19th and sonar, only hipe2020 and newseye have a sizable number of such entities.</p><p>Detailed information about entity mentions that are affected by OCR mistakes is provided in ajmc and hipe2020 (only for the test set for the latter). As OCR noise constitutes one of the main challenges of historical NE processing <ref type="bibr" coords="7,290.94,395.33,11.58,4.94" target="#b4">[5]</ref>, this information can be extremely useful to explain differences in performance between datasets or between languages in the same dataset. For instance, looking at the percentage of noisy mentions for the different languages in ajmc, we find that it is three times higher in French documents than in the other two languages.</p><p>HIPE-2022 datasets show significant differences in terms of lexical overlap between train, dev and test sets. Following the observations of Augenstein et al. <ref type="bibr" coords="7,382.28,463.08,17.96,4.94" target="#b19">[20]</ref> and Taill√© et al. <ref type="bibr" coords="7,473.81,463.08,17.96,4.94" target="#b20">[21]</ref> on the impact of lexical overlap on NERC performance, we computed the percentage of mention overlap between data folds for each dataset, based on the number of identical entity mentions (in terms of surface form) between train+dev and test sets (see Table <ref type="table" coords="7,408.60,503.72,3.65,4.94" target="#tab_6">6</ref>). Evaluation results obtained on training and test sets with low mention overlap, for example, can be taken as an indicator of the ability of the models to generalise well to unseen mentions. We find that ajmc, letemps and topres19th have a mention overlap which is almost twice that of hipe2020, sonar and newseye.</p><p>Finally, regarding entity linking, it is interesting to observe that the percentage of NIL entities (i.e. entities not linked to Wikidata) varies substantially across datasets. The Wikidata coverage is drastically lower for newseye than for the other newspaper datasets (44.36%). Conversely, only 1.45% of the entities found in ajmc cannot be linked to Wikidata. This fact is not at all surprising considering that commentaries mention mostly mythological figures, scholars of the past and literary works, while newspapers mention many relatively obscure or unknown individuals, for whom no Wikidata entry exists.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">HIPE-2022 Releases</head><p>HIPE-2022 data is released as a single package consisting of the neatly structured and homogeneously formatted original datasets. The data is released in IOB format with hierarchical information, similarly to CoNLL-U<ref type="foot" coords="10,249.51,452.14,7.41,3.61" target="#foot_9">10</ref> , and consists of UTF-8 encoded, tab-separated values (TSV) files containing the necessary information for all tasks (NERC-Coarse, NERC-Fine, and EL). There is one TSV file per dataset, language and split. Original datasets provide different document metadata with different granularity. This information is kept in the files in the form of metadata blocks that encode as much information as necessary to ensure that each document is self-contained with respect to HIPE-2022 settings. Metadata blocks use namespacing to distinguish between mandatory shared task metadata and dataset-specific metadata. HIPE-2022 data releases are published on the HIPE-eval GitHub organisation repository<ref type="foot" coords="10,498.26,546.98,7.41,3.61" target="#foot_10">11</ref> and on Zenodo <ref type="foot" coords="10,158.20,560.53,7.41,3.61" target="#foot_11">12</ref> . Various licences (of type CC-BY and CC-BY-NC-SA) apply to the original datasets -we refer the reader to the online documentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Evaluation Framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Task Bundles, Tracks and Challenges</head><p>To accommodate the different dimensions that characterise the HIPE-2022 shared task (languages, document types, entity tag sets, tasks) and to foster research on transferability, the evaluation lab is organised around tracks and challenges. Challenges guide participation towards the development of approaches that work across settings, e.g. with documents in at least two different languages or annotated according to two different tag sets or guidelines, and provide a well-defined and multi-perspective evaluation frame.</p><p>To manage the total combinations of datasets, languages, document types and tasks, we defined the following elements (see also Figure <ref type="figure" coords="11,265.29,236.02,3.63,4.94" target="#fig_0">1</ref>):</p><p>‚Ä¢ Task bundle: a task bundle is a predefined set of tasks as in HIPE-2020 (see bundle table in Fig. <ref type="figure" coords="11,171.08,272.09,3.52,4.94" target="#fig_0">1</ref>). Task bundles offer participating teams great flexibility in choosing which tasks to compete for, while maintaining a manageable evaluation frame. Concretely, teams were allowed to submit several 'submission bundles', i.e. a triple composed of dataset/language/taskbundle, with up to 2 runs each.</p><p>‚Ä¢ Track: a track corresponds to a triple composed of dataset/language/task and forms the basic unit for which results are reported.</p><p>‚Ä¢ Challenge: a challenge corresponds to a predefined set of tracks. A challenge can be seen as a kind of tournament composed of tracks.</p><p>HIPE-2022 specifically evaluates 3 challenges:</p><p>1. Multilingual Newspaper Challenge (MNC): This challenge aims at fostering the development of multilingual NE processing approaches on historical newspapers. The requirements for participation in this challenge are that submission bundles consist only of newspaper datasets and include at least two languages for the same task (so teams had to submit a minimum of two submission bundles for this challenge).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Multilingual Classical Commentary Challenge (MCC):</head><p>This challenge aims at adapting NE solutions to domain-specific entities in a specific digital humanities text type of classic commentaries. The requirements are that submission bundles consist only of the ajmc dataset and include at least three languages for the same task.</p><p>3. Global Adaptation Challenge (GAC): Finally, the global adaptation challenge aims at assessing how efficiently systems can be retargeted to any language, document type and guidelines. Bundles submitted for this challenge could be the same as those submitted for MNC and MCC challenges. The requirements are that they consist of datasets of both types (commentaries and newspaper) and include at least two languages for the same task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation Measures</head><p>As in HIPE-2020, NERC and EL tasks are evaluated in terms of Precision, Recall and F-measure (F1-score) <ref type="bibr" coords="12,135.00,572.14,16.15,4.94" target="#b21">[22]</ref>. Evaluation is carried out at entity level according to two computation schemes: micro average, based on true positives, false positives, and false negative figures computed over all documents, and macro average, based on averages of micro figures per document. Our definition of macro differs from the usual one: averaging is done at document level and not at entity type level. This allows to account for variance in document length and entity distribution within documents and avoids distortions that would occur due to the unevenly distributed entity classes.</p><p>Both NERC and EL benefit from strict and fuzzy evaluation regimes, depending on how strictly entity type and boundaries correctness are judged. For NERC (Coarse and Fine), the strict regime corresponds to exact type and boundary matching, and the fuzzy to exact type and overlapping boundaries. It is to be noted that in the strict regime, predicting wrong boundaries leads to a 'double' punishment of one false negative (entity present in the gold standard but not predicted by the system) and one false positive (entity predicted by the system but not present in the gold standard). Although it penalizes harshly, we keep this metric to be consistent with CoNLL and refer to the fuzzy regime when boundaries are of less importance. The definition of strict and fuzzy regimes differs for entity linking. In terms of boundaries, EL is always evaluated according to overlapping boundaries in both regimes (what is of interest is the capacity to provide the correct link rather than the correct boundaries). EL strict regime considers only the system's top link prediction (NIL or Wikidata QID), while the fuzzy regime expands system predictions with a set of historically related entity QIDs. For example, "Germany" QID is complemented with the QID of the more specific "Confederation of the Rhine" entity and both are considered as valid answers. The resource allowing for such historical normalization was compiled by the task organizers for the entities of the test data sets (for hipe2020 and ajmc datasets), and are released as part of the HIPE-scorer. For this regime, participants were invited to submit more than one link, and F-measure is additionally computed with cut-offs @3 and @5 (meaning, counting a true positive if the ground truth QID can be found within the first 3 or 5 candidates).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">System Evaluation, Scorer and Evaluation Toolkit</head><p>Teams were asked to submit system responses based on submission bundles and to specify at least one challenge to which their submitted bundles belong. Micro and macro scores were computed and published for each track, but only micro figures are reported here.</p><p>The evaluation of challenges, which corresponds to an aggregation of tracks, was defined as follows: given a specific challenge and the tracks submitted by a team for this challenge, the submitted systems are rewarded points according to their F1-based rank for each track (considering only the best of the submitted runs for a given track). The points obtained are summed over all submitted tracks, and systems/teams are ranked according to their total points. Further details on system submission and evaluation can be found in the HIPE Participation Guidelines <ref type="bibr" coords="13,139.52,505.78,16.25,4.94" target="#b22">[23]</ref>.</p><p>The evaluation is performed using the HIPE-scorer <ref type="foot" coords="13,338.07,516.70,7.41,3.61" target="#foot_12">13</ref> . Developed during the first edition of HIPE, the scorer has been improved with minor bug fixes and additional parameterisation (input format, evaluation regimes, HIPE editions). Participants could use the HIPE-scorer when developing their systems. After the evaluation phase, a complete evaluation toolkit was also released, including the data used for evaluation (v2.1), the system runs submitted by participating teams, and all the evaluation recipes and resources (e.g. historical mappings) needed to replicate the present evaluation 14 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">System Descriptions</head><p>In this second HIPE edition, 5 teams submitted a total of 103 system runs. Submitted runs do not cover all of the 35 possible tracks (dataset/language/task combinations), nevertheless we received submission for all datasets, with most of them focusing on NERC-Coarse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Baselines</head><p>As a neural baseline (Neur-bsl) for NERC-Coarse and NERC-fine, we fine-tuned separately for each HIPE-2022 dataset XLM-R ùêµùê¥ùëÜùê∏ , a multilingual transformer-based language representation model pre-trained on 2.5TB of filtered CommonCrawl texts <ref type="bibr" coords="14,354.06,218.47,16.19,4.94" target="#b23">[24]</ref>. The models are implemented using HuggingFace<ref type="foot" coords="14,174.68,229.38,7.41,3.61" target="#foot_13">15</ref>  <ref type="bibr" coords="14,185.30,232.01,16.20,4.94" target="#b24">[25]</ref>. Since transformers rely primarily on subword-based tokenisers, we chose to label only the first subwords. This allows to map the model outputs to the original text more easily. Tokenised texts are split into input segments of length 512. For each HIPE-2022 dataset, fine-tuning is performed on the train set (except for sonar and hipe2020-en which has only dev sets) for 10 epochs using the default hyperparameters (Adam ùúñ = 10e-8, Learning rate ùõº = 5e-5). The code of this baseline (configuration files, scripts) is published in a dedicated repository on the HIPE-eval Github organisation <ref type="foot" coords="14,305.02,310.68,7.41,3.61" target="#foot_14">16</ref> , and results are published in the evaluation toolkit.</p><p>For entity linking in EL-only setting, we provide the NIL baseline (Nil-bsl), where each entity link is replaced with the NIL value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Participating Systems</head><p>The following system descriptions are compiled from information provided by the participants. More details on the implementation and results can be found in the system papers of the participants <ref type="bibr" coords="14,145.01,430.78,16.25,4.94" target="#b25">[26]</ref>.</p><p>Team L3i, affiliated with La Rochelle University and with the University of Toulouse, France, successfully tackled an impressive amount of multilingual newspaper datasets with strong runs for NERC-coarse, NERC-fine and EL. For the classical commentary datasets (ajmc) the team had excellent results for NERC <ref type="foot" coords="14,229.40,482.35,7.41,3.61" target="#foot_15">17</ref> . For NERC, L3i -the winning team in HIPE's 2020 edition -builds on their transformer-based approach <ref type="bibr" coords="14,301.60,498.53,16.42,4.94" target="#b26">[27]</ref>. Using transformer-based adapters <ref type="bibr" coords="14,486.67,498.53,16.41,4.94" target="#b27">[28]</ref>, parameter-efficient fine-tuning in a hierarchical multitask setup (NERC-coarse and NERC-fine) has been shown to work well with historical noisy texts <ref type="bibr" coords="14,346.43,525.63,16.41,4.94" target="#b26">[27]</ref>. The innovation for this year's submission lies in the addition of context information in the form of external knowledge from two sources (inspired by <ref type="bibr" coords="14,199.48,552.73,15.58,4.94" target="#b28">[29]</ref>). First, French and German Wikipedia documents based on dense vector representations computed by a multilingual Sentence-BERT model <ref type="bibr" coords="14,430.48,566.27,16.42,4.94" target="#b29">[30]</ref>, including a k-Nearest-Neighbor search functionality provided by ElasticSearch framework. Second, English Wikidata knowledge graph (KG) embeddings that are combined with the first paragraph of English Wikipedia pages (Wikidata5m) <ref type="bibr" coords="14,259.84,606.92,16.09,4.94" target="#b30">[31]</ref>. For the knowledge graph embeddings, two methods are tested on the HIPE-2022 data: 1) the one-stage KG Embedding Retrieval Module that retrieves top-ùëò KG "documents" (in this context, a document is an ElasticSearch retrieval unit that consists of an entity identifier, an entity description and an entity embedding) via vector similarity on the dense entity embedding vector space; 2) the two-stage KG Embedding Retrieval Module that retrieves the single top similar document first and then in a second retrieval step gets the ùëò most similar documents based on that first entity. All context enrichment techniques work by simply concatenating the original input segment with the retrieved context segments and processing the contextualized segments through their "normal" hierarchical NER architecture. Since the L3i team's internal evaluation on HIPE-2022 data (using a multilingual BERT base pre-trained model) indicated that the two-stage KG retrieval was the best context generator overall, it was used for one of the two officially submitted runs. The other "baseline" run did not use any context enrichment techniques. Both runs additionally used stacked monolingual BERT embeddings for English, French and German, for the latter two languages in the form of Europeana models that were built from digitized historical newspaper text material. Even with improved historical monolingual BERT embeddings, the context-enriched run was consistently better in terms of F1-score in NERC-Coarse and -Fine settings.</p><p>Team histeria, affiliated with the Bayerische Staatsbibliothek M√ºnchen, Germany, the Digital Philology department of the University of Vienna, Austria and the NLP Expert Center, Volkswagen AG Munich, Germany, focused on the ajmc dataset for their NERC-coarse submission (best results for French and English, second best for German), but also provides experimental results for all languages of the newseye datasets <ref type="foot" coords="15,264.57,345.03,7.41,3.61" target="#foot_16">18</ref> . Their NER tagging experiments tackle two important questions: a) How to build an optimal multilingual pre-trained BERT language representation model for historical OCRized documents? They propose and release hmBERT <ref type="foot" coords="15,388.47,385.68,7.41,3.61" target="#foot_17">19</ref> , which includes English, Finnish, French, German and Swedish in various model and vocabulary sizes, and specifically apply methods to deal with OCR noise and imbalanced corpus sizes per language. In the end, roughly 27GB of text per language is used in pre-training.</p><p>b) How to fine-tune a multilingual pre-trained model given comparable NER annotations in multiple languages? They compare a single-model approach (training models separately for each language) with a one-model approach (training only one model that covers all languages). The results indicate that, most of the time, the single-model approach works slightly better, but the difference may not be large enough to justify the considerably greater effort to train and apply the models in practice.</p><p>histeria submitted two runs for each ajmc datasets, using careful hyperparameter grid search on the dev sets in the process. Both runs build on the one-model approach in a first multilingual fine-tuning step. Similar to <ref type="bibr" coords="15,271.82,550.90,16.38,4.94" target="#b28">[29]</ref>, they build monolingual models by further finetuning on language-specific training data <ref type="foot" coords="15,277.59,561.82,7.41,3.61" target="#foot_18">20</ref> . Run 1 of their submission is based on hmBERT with vocabulary size 32k, while run 2 has a vocabulary size of 64k. Somewhat unexpectedly, the larger vocabulary does not improve the results in general on the development set. For the test set, though, the larger vocabulary model is substantially better overall. Similar to the team L3i, histeria also experimented with context enrichment techniques suggested by <ref type="bibr" coords="16,487.19,103.78,16.38,4.94" target="#b28">[29]</ref>. However, for the specific domain of classical commentaries, general-purpose knowledge bases such as Wikipedia could not improve the results. Interestingly, L3i also observed much less improvement with Wikipedia context enrichment on ajmc in comparison to the hipe2020 newspaper datasets. In summary, histeria outperformed the strong neural baseline by about 10 F1-score percentage points in strict boundary setting, thereby demonstrating the importance of carefully constructed domain-specific pre-trained language representation models.</p><p>Team Aauzh, affiliated with University of Zurich, Switzerland and University of Milan, Italy, focused on the multilingual newspaper challenge in NERC-coarse setting and experimented with 21 different monolingual and multilingual, as well as contemporary and historical transformerbased language representation models available on the HuggingFace platform. For fine-tuning, they used the standard token classification head of the transformer library for NER tagging with default hyperparameters and trained each dataset for 3 epochs. In a preprocessing step, token-level NER IOB labels were mapped onto all subtokens. At inference time, a simple but effective summing pooling strategy for NER for aggregating subtoken-level to token-level labels was used <ref type="bibr" coords="16,134.69,307.02,16.42,4.94" target="#b31">[32]</ref>. Run 2 of Aauzh are the predictions of the best single model. Run 1 is the result of a hard-label ensembling from different pre-trained models: in case of ties between O and B/I labels, the entity labels were preferred. The performance of the submitted runs varies strongly in comparison with the neural baseline: for German and English it generally beats the baseline clearly for hipe2020 and sonar datasets, but suffers on French hipe2020 and German/Finnish newseye datasets. This again indicates that in transfer learning approaches to historical NER, the selection of pre-trained models has a considerable impact. The team also performed some post-submission experiments to investigate the effect of design choices: Applying soft-label ensembling using averaged token-level probabilities turned out to improve results on the French newseye datasets by 1.5 percentage point in micro average and 2.4 points in macro average (F1-score). For all languages of the newseye, they also tested a one-model approach with multilingual training. The best multilingual dbmdz Europeana BERT model had a better performance on average (58%) than the best monolingual models (56%). However, several other multilingual pre-trained language models had substantially worse performance, resulting in 57% ensemble F1-score (5 models), which was much lower than 67% achieved by the monolingual ensemble.</p><p>Team Sbb, affiliated with the Berlin State Library, Germany, participated exclusively in the EL-only subtask, but covered all datasets in English, German and French. Their system builds on models and methods developed in the HIPE-2020 edition <ref type="bibr" coords="16,343.70,550.90,16.24,4.94" target="#b32">[33]</ref>. Their approach uses Wikipedia sentences with an explicit link to a Wikipedia page as textual representations of its connected Wikidata entity. The system makes use of the metadata of the HIPE-2022 documents to exclude entities that were not existing at the time of its publication. Going via Wikipedia reduces the amount of accessible Wikidata IDs, however, for all datasets but ajmc the coverage is still 90%. Given the specialised domain of ajmc, a coverage of about 55% is to be accepted. The entity linking is done in the following steps: a) A candidate lookup retrieves a given number of candidates (25 for submission run 1, 50 for submission run 2) using a nearest neighbour index based on word embeddings of Wikipedia page titles. An absolute cut-off value is used to limit the retrieval (0.05 for submission 1 and 0.13 for submission 2). b) A probabilistic candidate sentence matching is performed by pairwise comparing the sentence with the mention to link and a knowledge base text snippet. To this end, a BERT model was fine-tuned on the task of whether or not two sentences mention the same entity. c) The final ranking of candidates includes the candidate sentence matching information as well as lookup features from step (a) and more word embedding information from the context. A random forest model calculates the overall probability of a match between the entity mention and an entity linking candidate. If the probability of a candidate is below a given threshold (0.2 for submission run 1 and 2), it is discarded. The random forest model was trained on concatenated training sets of the same language across datasets.</p><p>There are no conclusive insights from HIPE-2022 EL-only results whether run 1 or 2 settings are preferable. Post-submission experiments in their system description paper investigate the influence of specific hyperparameter settings on the system performances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results and Discussion</head><p>We report results for the best run of each team and consider micro Precision, Recall and F1-score exclusively. Results for NERC-Coarse and NERC-Fine for all languages and datasets according to both evaluation regimes are presented in Table <ref type="table" coords="17,369.11,324.99,5.17,4.94" target="#tab_7">7</ref> and 8 respectively. Table <ref type="table" coords="17,495.64,324.99,10.35,4.94" target="#tab_9">10</ref> reports performances for EL-only, with a cut-off @1. We refer the reader to the HIPE-2022 website and the evaluation toolkit for more detailed results <ref type="foot" coords="17,357.95,349.46,7.41,3.61" target="#foot_19">21</ref> , and to the extended overview paper for further discussion of the results <ref type="bibr" coords="17,276.74,365.64,16.25,4.94" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">General Observations</head><p>All systems now use transformer-based approaches with strong pre-trained models. The choice of the pre-trained model -and the corresponding text types used in pre-training -have a strong influence on performance.</p><p>The quality of available multilingual pre-trained models for fine-tuning on NER tasks proved to be competitive compared to training individual monolingual models. However, to get the maximum performance out of it, the multilingual fine-tuning in a first phase must be complemented by a monolingual second phase. NERC. In general, the systems demonstrated a good ability to adapt to heterogeneous annotation guidelines. They achieved their highest F1-scores for the NERC-Coarse task on ajmc, a dataset annotated with domain-specific entities and of relatively small size compared to the newspaper datasets, thus confirming the ability of strong pre-trained models to achieve good results when fine-tuned on relatively small datasets. The good results obtained on ajmc, however, may be partly due to the relatively high mention overlap between train and test sets (see Section 3.2). Moreover, it is worth noting that performances on the French subset of the ajmc dataset do not substantially degrade despite the high rate of noisy mentions (three times higher than English and German), which shows a good resilience of transformer-based models to OCR noise on this specific dataset.  F1-scores compared to the other datasets.</p><p>The EL-only performances of the SBB system on the ajmc dataset deserve some further considerations, as they are well representative of the challenges faced when applying a generic entity linking system to a domain-specific dataset. Firstly, SBB team reported that ajmc is the dataset with the lowest Wikidata coverage: only 57% of the Wikidata IDs in the test set are found in the knowledge base used by their system (a combination of Wikidata record and Wikipedia textual content), whereas the coverage for all other datasets ranges between 86% (hipe2020) and 99% (topres19th). The reason for the low coverage in ajmc is that, when constructing the knowledge base, only Wikidata records describing persons, locations and organisations were kept. In contrast, a substantial number of entities in ajmc are literary works, which would have required to retain also records with Wikidata type "literary work" (Q7725634) when building the KB.</p><p>Secondly, a characteristic of ajmc is that both person and work mentions are frequently abbreviated, and these abbreviations tend to be lacking as lexical information in large-scale KBs such as Wikidata. Indeed, an error analysis of SBB's system results shows that only 1.4% of the correctly predicted entity links (true positives) correspond to abbreviated mentions, which nevertheless represent about 47% of all linkable mentions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Observations on Challenges</head><p>A complementary way of looking at the results is to consider them in light of the specific challenges raised by historical documents. Such challenges are one of the novelties of HIPE-2022 and were introduced as "thematic aggregations" of system rankings across datasets and languages (see Section 4). <ref type="foot" coords="21,202.72,191.52,7.41,3.61" target="#foot_20">22</ref>Multilingual Newspaper Challenge (MNC). Overall, four teams participated in this challenge: three teams in the NERC-Coarse task, two in EL-only and one team in end-to-end EL. The top-ranked team, Aauzh, was able to tackle five different newspaper datasets in five languages in total, with performances above the strong neural baseline in 6 out of 10 cases. However, it should be noted that they used two different systems, one based on the best fine-tuned model (selected by development set performance) and another one being an ensemble of all their fine-tuned models. Thus, despite leading in the MNC challenge, their work does not answer the question of which single system works best across datasets and in different languages. Conversely, the second-ranked system by L3I team submitted for fewer datasets and languages, but showed an overall higher quality of predictions both for NERC-Coarse and EL-only for languages they covered. It would be interesting to see how this system performs on the remaining languages and datasets, especially in comparison with the baseline. In general, one aspect of the MNC challenge which remained unexplored is entity linking beyond a standard set of languages such as English, German and French, as no runs for EL-only on Finnish and Swedish newspapers were submitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multilingual Classical Commentary Challenge (MCC).</head><p>This challenge had in total three participants: two teams participated in this challenge in the NERC-Coarse task, and one team participated in the end-to-end EL and EL-only. Given the overlap between MCC and GAC challenges in terms of languages and datasets, teams participating in the latter were also considered for the former.</p><p>The NERC-Coarse results showed how a BERT-based multilingual model pre-trained on large corpora of historical documents and fine-tuned on domain-specific data performs better or on-par with a system implementing a more complex transformer-based architecture. An interesting insight which emerged from this challenge is that methods employing context enrichment techniques which rely on lexical information from Wikipedia do not yield performances improvements as they do when applied to other document types, such as newspapers.</p><p>Regarding EL, MCC exemplified well some characteristics an EL system needs to have for it to be applied successfully across different domains. In particular, assumptions about which entities are to be retained when constructing a knowledge base for this task need to be relaxed. Moreover, an aspect that emerged from this challenge and will deserve more research in the future is the linking of abbreviated entities (e.g. mentions of literary works in commentaries), which proved to be challenging for participating systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Global Adaptation Challenge (GAC).</head><p>The high level of difficulty entailed by this challenge is reflected by the number of participants: one team for the NERC-Coarse task and one team for end-to-end EL and EL-only. Both teams had already participated in the first edition of HIPE with very good results, and tackled this year the challenge of adapting their systems to work in a multi-domain and multilingual scenario. In general, the results of this challenge confirm that the systems proposed by L3I and SBB respectively for the tasks of NERC-Coarse and EL are suitable to be applied to data originating from heterogeneous domains. They also show that EL across languages and domains remains a more challenging task than NERC, calling for more future research on this topic. Moreover, no team has worked on adapting annotation models to be able to combine different NER training datasets with sometimes incompatible annotations and benefit from a larger dataset overall. This data augmentation strategy to global adaptation, which could be beneficial for underrepresented entity types (e.g. dates or locations in the ajmc dataset), remains to be explored in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion and Perspectives</head><p>From the perspective of natural language processing, this second edition of HIPE provided the possibility to test the robustness of existing approaches and to experiment with transfer learning and domain adaptation methods, whose performances could be systematically evaluated and compared on broad historical and multilingual data sets. Besides gaining new insights with respect to domain and language adaptation and advancing the state of the art in semantic indexing of historical material, the lab also contributed an unprecedented set of multilingual and historical NE-annotated datasets that can be used for further experimentation and benchmarking.</p><p>From the perspective of digital humanities, the lab's outcomes will help DH practitioners in mapping state-of-the-art solutions for NE processing of historical texts, and in getting a better understanding of what is already possible as opposed to what is still challenging. Most importantly, digital scholars are in need of support to explore the large quantities of digitised text they currently have at hand, and NE processing is high on the agenda. Such processing can support research questions in various domains (e.g. history, political science, literature, historical linguistics) and knowing about their performance is crucial in order to make an informed use of the processed data.</p><p>From the perspective of cultural heritage professionals, who increasingly focus on advancing the usage of artificial intelligence methods on cultural heritage text collections <ref type="bibr" coords="22,452.13,528.23,16.56,4.94" target="#b33">[34,</ref><ref type="bibr" coords="22,471.78,528.23,12.42,4.94" target="#b34">35]</ref>, the HIPE-2022 shared task and datasets represent an excellent opportunity to experiment with multilingual and multi-domain data of various quality and annotation depth, a setting close to the real-world scenarios they are often confronted with.</p><p>Overall, HIPE-2022 has contributed to further advance the state of the art in semantic indexing of historical documents. By expanding the language spectrum and document types and integrating datasets with various annotation tag sets, this second edition has set the bar high, and there remains much to explore and experiment.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="12,89.29,498.99,215.54,4.82;12,89.29,84.19,416.70,400.41"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of HIPE-2022 evaluation setting.</figDesc><graphic coords="12,89.29,84.19,416.70,400.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,88.99,92.50,417.00,138.42"><head>Table 1</head><label>1</label><figDesc>Overview of HIPE-2022 datasets with an indication of which tasks they are suitable for according to their annotation types.</figDesc><table coords="4,111.04,134.16,356.12,96.76"><row><cell>Dataset alias</cell><cell>Document type</cell><cell>Languages</cell><cell>Suitable for</cell></row><row><cell>hipe2020</cell><cell>historical newspapers</cell><cell>de, fr, en</cell><cell>NERC-Coarse, NERC-Fine, EL</cell></row><row><cell>newseye</cell><cell>historical newspapers</cell><cell>de, fi, fr, sv</cell><cell>NERC-Coarse, NERC-Fine, EL</cell></row><row><cell>sonar</cell><cell>historical newspapers</cell><cell>de</cell><cell>NERC-Coarse, EL</cell></row><row><cell>letemps</cell><cell>historical newspapers</cell><cell>fr</cell><cell>NERC-Coarse, NERC-Fine</cell></row><row><cell>topres19th</cell><cell>historical newspapers</cell><cell>en</cell><cell>NERC-Coarse, EL</cell></row><row><cell>ajmc</cell><cell>classical commentaries</cell><cell>de, fr, en</cell><cell>NERC-Coarse, NERC-Fine, EL</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.99,92.50,418.53,629.37"><head>Table 2</head><label>2</label><figDesc>Entity types used for NERC tasks, per dataset and with information whether nesting and linking apply. *: these types are not present in letemps data. **: linking applies, unless the token is flagged as InSecondaryReference.</figDesc><table coords="6,110.74,148.53,363.16,573.33"><row><cell>Dataset</cell><cell>Coarse tag set</cell><cell>Fine tag set</cell><cell>Nesting</cell><cell>Linking</cell></row><row><cell>hipe2020</cell><cell>pers</cell><cell>pers.ind</cell><cell>yes</cell><cell>yes</cell></row><row><cell>letemps</cell><cell></cell><cell>pers.coll</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>pers.ind.articleauthor</cell><cell></cell><cell></cell></row><row><cell></cell><cell>org*</cell><cell>org.adm</cell><cell>yes</cell><cell>yes</cell></row><row><cell></cell><cell></cell><cell>org.ent</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>org.ent.pressagency</cell><cell></cell><cell></cell></row><row><cell></cell><cell>prod*</cell><cell>prod.media</cell><cell>no</cell><cell>yes</cell></row><row><cell></cell><cell></cell><cell>prod.doctr</cell><cell></cell><cell></cell></row><row><cell></cell><cell>time*</cell><cell>time.date.abs</cell><cell>no</cell><cell>no</cell></row><row><cell></cell><cell>loc</cell><cell>loc.adm.town</cell><cell>yes</cell><cell>yes</cell></row><row><cell></cell><cell></cell><cell>loc.adm.reg</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>loc.adm.nat</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>loc.adm.sup</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>loc.phys.geo</cell><cell>yes</cell><cell>yes</cell></row><row><cell></cell><cell></cell><cell>loc.phys.hydro</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>loc.phys.astro</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>loc.oro</cell><cell>yes</cell><cell>yes</cell></row><row><cell></cell><cell></cell><cell>loc.fac</cell><cell>yes</cell><cell>yes</cell></row><row><cell></cell><cell></cell><cell>loc.add.phys</cell><cell>yes</cell><cell>yes</cell></row><row><cell></cell><cell></cell><cell>loc.add.elec</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>loc.unk</cell><cell>no</cell><cell>no</cell></row><row><cell>newseye</cell><cell>pers</cell><cell>pers.articleauthor</cell><cell>yes</cell><cell>yes</cell></row><row><cell></cell><cell>org</cell><cell>-</cell><cell>yes</cell><cell>yes</cell></row><row><cell></cell><cell>humanprod</cell><cell>-</cell><cell>yes</cell><cell>yes</cell></row><row><cell></cell><cell>loc</cell><cell>-</cell><cell>no</cell><cell>yes</cell></row><row><cell>topres19th</cell><cell>loc</cell><cell>-</cell><cell>no</cell><cell>yes</cell></row><row><cell></cell><cell>building</cell><cell>-</cell><cell>no</cell><cell>yes</cell></row><row><cell></cell><cell>street</cell><cell>-</cell><cell>no</cell><cell>yes</cell></row><row><cell>ajmc</cell><cell>pers</cell><cell>pers.author</cell><cell>yes</cell><cell>yes**</cell></row><row><cell></cell><cell></cell><cell>pers.editor</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>pers.myth</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>pers.other</cell><cell></cell><cell></cell></row><row><cell></cell><cell>work</cell><cell>work.primlit</cell><cell>yes</cell><cell>yes**</cell></row><row><cell></cell><cell></cell><cell>work.seclit</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>work.fragm</cell><cell></cell><cell></cell></row><row><cell></cell><cell>loc</cell><cell>-</cell><cell>yes</cell><cell>yes**</cell></row><row><cell></cell><cell>object</cell><cell>object.manuscr</cell><cell>yes</cell><cell>no</cell></row><row><cell></cell><cell></cell><cell>object.museum</cell><cell></cell><cell></cell></row><row><cell></cell><cell>date</cell><cell>-</cell><cell>yes</cell><cell>no</cell></row><row><cell></cell><cell>scope</cell><cell>-</cell><cell>yes</cell><cell>no</cell></row><row><cell>sonar</cell><cell>pers</cell><cell>-</cell><cell>no</cell><cell>yes</cell></row><row><cell></cell><cell>loc</cell><cell>-</cell><cell>no</cell><cell>yes</cell></row><row><cell></cell><cell>org</cell><cell>-</cell><cell>no</cell><cell>yes</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,88.99,92.50,421.38,680.42"><head>Table 3</head><label>3</label><figDesc>Overview of newspaper corpora statistics (hipe-2022 release v2.1). NIL percentages are computed based on linkable entities (i.e., excluding time entities for hipe2020).</figDesc><table coords="8,89.29,136.52,421.08,636.40"><row><cell>Dataset</cell><cell>Lang.</cell><cell>Fold</cell><cell>Docs</cell><cell>Tokens</cell><cell></cell><cell cols="2">Mentions</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>All</cell><cell>Fine</cell><cell cols="3">Nested %noisy %NIL</cell></row><row><cell>hipe2020</cell><cell>de</cell><cell>Train</cell><cell>103</cell><cell>86,446</cell><cell>3,494</cell><cell>3,494</cell><cell>158</cell><cell>-</cell><cell>15.70</cell></row><row><cell></cell><cell></cell><cell>Dev</cell><cell>33</cell><cell>32,672</cell><cell>1,242</cell><cell>1,242</cell><cell>67</cell><cell>-</cell><cell>18.76</cell></row><row><cell></cell><cell></cell><cell>Test</cell><cell>49</cell><cell>30,738</cell><cell>1,147</cell><cell>1,147</cell><cell>73</cell><cell>12.55</cell><cell>17.40</cell></row><row><cell></cell><cell>Total</cell><cell></cell><cell>185</cell><cell>149,856</cell><cell>5,883</cell><cell>5,883</cell><cell>298</cell><cell>-</cell><cell>16.66</cell></row><row><cell></cell><cell>en</cell><cell>Train</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>Dev</cell><cell>80</cell><cell>29,060</cell><cell>966</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>44.18</cell></row><row><cell></cell><cell></cell><cell>Test</cell><cell>46</cell><cell>16,635</cell><cell>449</cell><cell>-</cell><cell>-</cell><cell>5.57</cell><cell>40.28</cell></row><row><cell></cell><cell>Total</cell><cell></cell><cell>126</cell><cell>45,695</cell><cell>1,415</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>42.95</cell></row><row><cell></cell><cell>fr</cell><cell>Train</cell><cell>158</cell><cell>166,218</cell><cell>6,926</cell><cell>6,926</cell><cell>473</cell><cell>-</cell><cell>25.26</cell></row><row><cell></cell><cell></cell><cell>Dev</cell><cell>43</cell><cell>37,953</cell><cell>1,729</cell><cell>1,729</cell><cell>91</cell><cell>-</cell><cell>19.81</cell></row><row><cell></cell><cell></cell><cell>Test</cell><cell>43</cell><cell>40,855</cell><cell>1,600</cell><cell>1,600</cell><cell>82</cell><cell>11.25</cell><cell>20.23</cell></row><row><cell></cell><cell>Total</cell><cell></cell><cell>244</cell><cell>245,026</cell><cell>10,255</cell><cell>10,255</cell><cell>646</cell><cell>-</cell><cell>23.55</cell></row><row><cell>Total</cell><cell></cell><cell></cell><cell>555</cell><cell>440,577</cell><cell>17,553</cell><cell>16,138</cell><cell>944</cell><cell>-</cell><cell>22.82</cell></row><row><cell>newseye</cell><cell>de</cell><cell>Train</cell><cell>7</cell><cell>374,250</cell><cell>11,381</cell><cell>21</cell><cell>876</cell><cell>-</cell><cell>51.07</cell></row><row><cell></cell><cell></cell><cell>Dev</cell><cell>12</cell><cell>40,046</cell><cell>539</cell><cell>5</cell><cell>27</cell><cell>-</cell><cell>22.08</cell></row><row><cell></cell><cell></cell><cell>Dev2</cell><cell>12</cell><cell>39,450</cell><cell>882</cell><cell>4</cell><cell>64</cell><cell>-</cell><cell>53.74</cell></row><row><cell></cell><cell></cell><cell>Test</cell><cell>13</cell><cell>99,711</cell><cell>2,401</cell><cell>13</cell><cell>89</cell><cell>-</cell><cell>48.52</cell></row><row><cell></cell><cell>Total</cell><cell></cell><cell>44</cell><cell>553,457</cell><cell>15,203</cell><cell>43</cell><cell>1,056</cell><cell>-</cell><cell>49.79</cell></row><row><cell></cell><cell>fi</cell><cell>Train</cell><cell>24</cell><cell>48,223</cell><cell>2,146</cell><cell>15</cell><cell>224</cell><cell>-</cell><cell>40.31</cell></row><row><cell></cell><cell></cell><cell>Dev</cell><cell>24</cell><cell>6,351</cell><cell>223</cell><cell>1</cell><cell>25</cell><cell>-</cell><cell>40.36</cell></row><row><cell></cell><cell></cell><cell>Dev2</cell><cell>21</cell><cell>4,705</cell><cell>203</cell><cell>4</cell><cell>22</cell><cell>-</cell><cell>42.86</cell></row><row><cell></cell><cell></cell><cell>Test</cell><cell>24</cell><cell>14,964</cell><cell>691</cell><cell>7</cell><cell>42</cell><cell>-</cell><cell>47.47</cell></row><row><cell></cell><cell>Total</cell><cell></cell><cell>93</cell><cell>74,243</cell><cell>3,263</cell><cell>27</cell><cell>313</cell><cell>-</cell><cell>41.99</cell></row><row><cell></cell><cell>fr</cell><cell>Train</cell><cell>35</cell><cell>255,138</cell><cell>10,423</cell><cell>99</cell><cell>482</cell><cell>-</cell><cell>42.42</cell></row><row><cell></cell><cell></cell><cell>Dev</cell><cell>35</cell><cell>21,726</cell><cell>752</cell><cell>3</cell><cell>29</cell><cell>-</cell><cell>30.45</cell></row><row><cell></cell><cell></cell><cell>Dev2</cell><cell>35</cell><cell>30,457</cell><cell>1,298</cell><cell>10</cell><cell>63</cell><cell>-</cell><cell>38.91</cell></row><row><cell></cell><cell></cell><cell>Test</cell><cell>35</cell><cell>70,790</cell><cell>2,530</cell><cell>34</cell><cell>131</cell><cell>-</cell><cell>44.82</cell></row><row><cell></cell><cell>Total</cell><cell></cell><cell>140</cell><cell>378,111</cell><cell>15,003</cell><cell>146</cell><cell>705</cell><cell>-</cell><cell>41.92</cell></row><row><cell></cell><cell>sv</cell><cell>Train</cell><cell>21</cell><cell>56,307</cell><cell>2,140</cell><cell>16</cell><cell>110</cell><cell>-</cell><cell>32.38</cell></row><row><cell></cell><cell></cell><cell>Dev</cell><cell>21</cell><cell>6,907</cell><cell>266</cell><cell>1</cell><cell>7</cell><cell>-</cell><cell>25.19</cell></row><row><cell></cell><cell></cell><cell>Dev2</cell><cell>21</cell><cell>6,987</cell><cell>311</cell><cell>1</cell><cell>20</cell><cell>-</cell><cell>37.30</cell></row><row><cell></cell><cell></cell><cell>Test</cell><cell>21</cell><cell>16,163</cell><cell>604</cell><cell>0</cell><cell>26</cell><cell>-</cell><cell>35.43</cell></row><row><cell></cell><cell>Total</cell><cell></cell><cell>84</cell><cell>86,364</cell><cell>3,321</cell><cell>18</cell><cell>163</cell><cell>-</cell><cell>32.82</cell></row><row><cell>Total</cell><cell></cell><cell></cell><cell>361</cell><cell>1,092,175</cell><cell>36,790</cell><cell>234</cell><cell>2,237</cell><cell>-</cell><cell>44.36</cell></row><row><cell>letemps</cell><cell>fr</cell><cell>Train</cell><cell>414</cell><cell>379,481</cell><cell>9,159</cell><cell>9,159</cell><cell>69</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>Dev</cell><cell>51</cell><cell>38,650</cell><cell>869</cell><cell>869</cell><cell>12</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>Test</cell><cell>51</cell><cell>48,469</cell><cell>1,017</cell><cell>1,017</cell><cell>12</cell><cell>-</cell><cell>-</cell></row><row><cell>Total</cell><cell></cell><cell></cell><cell>516</cell><cell>466,600</cell><cell>11,045</cell><cell>11,045</cell><cell>93</cell><cell>-</cell><cell>-</cell></row><row><cell>topres19th</cell><cell>en</cell><cell>Train</cell><cell>309</cell><cell>123,977</cell><cell>3,179</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>18.34</cell></row><row><cell></cell><cell></cell><cell>Dev</cell><cell>34</cell><cell>11,916</cell><cell>236</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>13.98</cell></row><row><cell></cell><cell></cell><cell>Test</cell><cell>112</cell><cell>43,263</cell><cell>1,186</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>17.2</cell></row><row><cell></cell><cell>Total</cell><cell></cell><cell>455</cell><cell>179,156</cell><cell>4,601</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>17.82</cell></row><row><cell>Total</cell><cell></cell><cell></cell><cell>455</cell><cell>179,156</cell><cell>4,601</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>17.82</cell></row><row><cell>sonar</cell><cell>de</cell><cell>Train</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>Dev</cell><cell>10</cell><cell>17,477</cell><cell>654</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>22.48</cell></row><row><cell></cell><cell></cell><cell>Test</cell><cell>10</cell><cell>15,464</cell><cell>471</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>33.33</cell></row><row><cell></cell><cell>Total</cell><cell></cell><cell>20</cell><cell>32,941</cell><cell>1,125</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>27.02</cell></row><row><cell>Total</cell><cell></cell><cell></cell><cell>20</cell><cell>32,941</cell><cell>1,125</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>27.02</cell></row><row><cell cols="2">Grand Total (newspapers)</cell><cell></cell><cell>1,907</cell><cell>2,211,449</cell><cell>71,114</cell><cell>27,417</cell><cell>3,274</cell><cell></cell><cell>30.23</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,88.99,92.50,413.21,244.07"><head>Table 4</head><label>4</label><figDesc>Corpus statistics for the ajmc dataset (HIPE-2022 release v2.1).</figDesc><table coords="9,93.08,125.89,409.12,210.68"><row><cell>Dataset</cell><cell>Lang.</cell><cell cols="2">Fold Docs</cell><cell>Tokens</cell><cell></cell><cell cols="2">Mentions</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>All</cell><cell>Fine</cell><cell cols="2">Nested %noisy %NIL</cell></row><row><cell>ajmc</cell><cell>de</cell><cell>Train</cell><cell>76</cell><cell>22,694</cell><cell>1,738</cell><cell>1,738</cell><cell>13.81</cell><cell>0.92</cell></row><row><cell></cell><cell></cell><cell>Dev</cell><cell>14</cell><cell>4,703</cell><cell>403</cell><cell>403</cell><cell>11.41</cell><cell>0.74</cell></row><row><cell></cell><cell></cell><cell>Test</cell><cell>16</cell><cell>4,846</cell><cell>382</cell><cell>382</cell><cell>10.99</cell><cell>1.83</cell></row><row><cell></cell><cell>Total</cell><cell></cell><cell>106</cell><cell>32,243</cell><cell>2,523</cell><cell>2,523</cell><cell>13.00</cell><cell>1.03</cell></row><row><cell></cell><cell>en</cell><cell>Train</cell><cell>60</cell><cell>30,929</cell><cell>1,823</cell><cell>1,823</cell><cell>10.97</cell><cell>1.66</cell></row><row><cell></cell><cell></cell><cell>Dev</cell><cell>14</cell><cell>6,507</cell><cell>416</cell><cell>416</cell><cell>16.83</cell><cell>1.70</cell></row><row><cell></cell><cell></cell><cell>Test</cell><cell>13</cell><cell>6,052</cell><cell>348</cell><cell>348</cell><cell>10.34</cell><cell>2.61</cell></row><row><cell></cell><cell>Total</cell><cell></cell><cell>87</cell><cell>43,488</cell><cell>2,587</cell><cell>2,587</cell><cell>11.83</cell><cell>1.79</cell></row><row><cell></cell><cell>fr</cell><cell>Train</cell><cell>72</cell><cell>24,670</cell><cell>1,621</cell><cell>1,621</cell><cell>30.72</cell><cell>0.99</cell></row><row><cell></cell><cell></cell><cell>Dev</cell><cell>17</cell><cell>5,426</cell><cell>391</cell><cell>391</cell><cell>36.32</cell><cell>2.56</cell></row><row><cell></cell><cell></cell><cell>Test</cell><cell>15</cell><cell>5,391</cell><cell>360</cell><cell>360</cell><cell>27.50</cell><cell>2.80</cell></row><row><cell></cell><cell>Total</cell><cell></cell><cell>104</cell><cell>35,487</cell><cell>2,372</cell><cell>2,372</cell><cell>31.16</cell><cell>1.52</cell></row><row><cell cols="2">Grand Total (ajmc)</cell><cell></cell><cell>297</cell><cell>111,218</cell><cell>7,482</cell><cell>7,482</cell><cell></cell><cell>1.45</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,88.99,371.48,418.08,221.79"><head>Table 5</head><label>5</label><figDesc>Entity</figDesc><table coords="9,94.72,414.27,409.45,179.00"><row><cell></cell><cell></cell><cell></cell><cell>hipe2020</cell><cell></cell><cell>letemps</cell><cell></cell><cell cols="2">newseye</cell><cell></cell><cell>sonar</cell><cell>topsres19th</cell><cell></cell><cell>ajmc</cell></row><row><cell></cell><cell></cell><cell>de</cell><cell>en</cell><cell>fr</cell><cell>fr</cell><cell>de</cell><cell>fi</cell><cell>fr</cell><cell>sv</cell><cell>de</cell><cell>en</cell><cell>de</cell><cell>en</cell><cell>fr</cell></row><row><cell>Universal</cell><cell>pers loc org</cell><cell>1849 2923 652</cell><cell>558 565 194</cell><cell>3706 4717 1125</cell><cell>4086 6367 592</cell><cell cols="4">4061 1212 6201 1132 6620 1338 5502 1446 3584 350 1758 230</cell><cell>399 477 249</cell><cell>3727</cell><cell cols="2">910 844 839 43 45 24</cell></row><row><cell>Space</cell><cell>building street</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>563 316</cell><cell></cell></row><row><cell>Time</cell><cell>time date</cell><cell>236</cell><cell>46</cell><cell>397</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2</cell><cell>20</cell><cell>5</cell></row><row><cell>Man-made</cell><cell>prod humanprod object work</cell><cell>223</cell><cell>52</cell><cell>310</cell><cell></cell><cell cols="2">6620 1338</cell><cell cols="2">5502 1446</cell><cell></cell><cell></cell><cell cols="2">12 465 678 557 3 10</cell></row><row><cell></cell><cell>scope</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note coords="9,117.91,383.25,389.17,4.79;9,89.29,395.20,303.40,4.79"><p>counts by coarse type (HIPE-2022 release v2.1). Although they appear under the same label, identical types present in different data sets may be annotated differently.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="10,88.99,92.50,418.52,283.42"><head>Table 6</head><label>6</label><figDesc>Overlap of mentions between test and train (plus dev) sets as percentage of the total number of mentions.</figDesc><table coords="10,186.16,125.89,208.88,229.85"><row><cell>Dataset</cell><cell>Lang.</cell><cell>% overlap Folds</cell></row><row><cell>ajmc</cell><cell>de</cell><cell>31.43 train+dev vs test</cell></row><row><cell></cell><cell>en</cell><cell>30.50 train+dev vs test</cell></row><row><cell></cell><cell>fr</cell><cell>27.53 train+dev vs test</cell></row><row><cell></cell><cell>Total</cell><cell>29.87</cell></row><row><cell>hipe2020</cell><cell>de</cell><cell>16.22 train+dev vs test</cell></row><row><cell></cell><cell>en</cell><cell>6.22 dev vs test</cell></row><row><cell></cell><cell>fr</cell><cell>19.14 train+dev vs test</cell></row><row><cell></cell><cell>Total</cell><cell>17.12</cell></row><row><cell>letemps</cell><cell>fr</cell><cell>25.70 train+dev vs test</cell></row><row><cell>sonar</cell><cell>de</cell><cell>10.13 dev vs test</cell></row><row><cell>newseye</cell><cell>fr</cell><cell>14.79 train+dev vs test</cell></row><row><cell></cell><cell>de</cell><cell>20.77 train+dev vs test</cell></row><row><cell></cell><cell>fi</cell><cell>6.63 train+dev vs test</cell></row><row><cell></cell><cell>sv</cell><cell>10.36 train+dev vs test</cell></row><row><cell></cell><cell>Total</cell><cell>16.18</cell></row></table><note coords="10,186.16,369.47,40.78,6.44;10,269.58,370.60,7.91,3.83;10,309.72,370.60,85.33,3.83"><p>topres19th en 32.33 train+dev vs test</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="18,88.99,92.50,416.99,334.41"><head>Table 7</head><label>7</label><figDesc>Results for NERC-Coarse (micro P, R and F1-score). Bold font indicates the highest, and underlined font the second-highest value.</figDesc><table coords="18,90.82,135.50,413.12,291.41"><row><cell></cell><cell></cell><cell>Strict</cell><cell></cell><cell></cell><cell>Fuzzy</cell><cell></cell><cell></cell><cell>Strict</cell><cell></cell><cell></cell><cell>Fuzzy</cell><cell></cell><cell></cell><cell>Strict</cell><cell></cell><cell></cell><cell>Fuzzy</cell><cell></cell></row><row><cell></cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">hipe2020</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">French</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">German</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">English</cell><cell></cell><cell></cell></row><row><cell>Aauzh</cell><cell>.718</cell><cell>.675</cell><cell>.696</cell><cell>.825</cell><cell>.776</cell><cell>.800</cell><cell>.716</cell><cell>.735</cell><cell>.725</cell><cell>.812</cell><cell>.833</cell><cell>.822</cell><cell>.538</cell><cell>490</cell><cell>.513</cell><cell>.726</cell><cell>.661</cell><cell>.692</cell></row><row><cell>L3i</cell><cell>.786</cell><cell>.831</cell><cell>.808</cell><cell>.883</cell><cell>.933</cell><cell>.907</cell><cell>.784</cell><cell>.805</cell><cell>.794</cell><cell>.865</cell><cell>.888</cell><cell>.876</cell><cell>.624</cell><cell>.617</cell><cell>.620</cell><cell>.793</cell><cell>.784</cell><cell>.788</cell></row><row><cell>Neur-bsl</cell><cell>.730</cell><cell>.785</cell><cell>.757</cell><cell>.836</cell><cell>.899</cell><cell>.866</cell><cell>.665</cell><cell>.746</cell><cell>.703</cell><cell>.750</cell><cell>.842</cell><cell>.793</cell><cell>.432</cell><cell>.532</cell><cell>.477</cell><cell>.564</cell><cell>.695</cell><cell>.623</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">letemps</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">sonar</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">topRes19th</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">French</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">German</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">English</cell><cell></cell><cell></cell></row><row><cell>Aauzh</cell><cell>.589</cell><cell>.710</cell><cell>.644</cell><cell>.642</cell><cell>.773</cell><cell>.701</cell><cell>.512</cell><cell>.548</cell><cell>.529</cell><cell>.655</cell><cell>.741</cell><cell>.695</cell><cell>.816</cell><cell>.760</cell><cell>.787</cell><cell>.869</cell><cell>.810</cell><cell>.838</cell></row><row><cell>Neur-bsl</cell><cell>.595</cell><cell>.744</cell><cell>.661</cell><cell>.639</cell><cell>.800</cell><cell>.711</cell><cell>.267</cell><cell>.361</cell><cell>.307</cell><cell>.410</cell><cell>.554</cell><cell>.471</cell><cell>.747</cell><cell>.782</cell><cell>.764</cell><cell>.798</cell><cell>.836</cell><cell>.816</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ajmc</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">French</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">German</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">English</cell><cell></cell><cell></cell></row><row><cell>HISTeria</cell><cell>.834</cell><cell>.850</cell><cell>.842</cell><cell>.874</cell><cell>.903</cell><cell>.888</cell><cell>.930</cell><cell>.898</cell><cell>.913</cell><cell>.938</cell><cell>.953</cell><cell>.945</cell><cell>.826</cell><cell>.885</cell><cell>.854</cell><cell>.879</cell><cell>.943</cell><cell>.910</cell></row><row><cell>L3i</cell><cell>.810</cell><cell>.842</cell><cell>.826</cell><cell>.856</cell><cell>.889</cell><cell>.872</cell><cell>.946</cell><cell>.921</cell><cell>.934</cell><cell>.965</cell><cell>.940</cell><cell>.952</cell><cell>.824</cell><cell>.876</cell><cell>.850</cell><cell>.868</cell><cell>.922</cell><cell>.894</cell></row><row><cell>Neur-bsl</cell><cell>.707</cell><cell>.778</cell><cell>.741</cell><cell>.788</cell><cell>.867</cell><cell>.825</cell><cell>.792</cell><cell>.846</cell><cell>.818</cell><cell>.846</cell><cell>.903</cell><cell>.873</cell><cell>.680</cell><cell>.802</cell><cell>.736</cell><cell>.766</cell><cell>.902</cell><cell>.828</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">newseye</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">French</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">German</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aauzh</cell><cell>.655</cell><cell>.657</cell><cell>.656</cell><cell>.785</cell><cell>.787</cell><cell>.786</cell><cell>.395</cell><cell>.421</cell><cell>.408</cell><cell>.480</cell><cell>.512</cell><cell>.495</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Neur-bsl</cell><cell>.634</cell><cell>.676</cell><cell>.654</cell><cell>.755</cell><cell>.805</cell><cell>.779</cell><cell>.429</cell><cell>.537</cell><cell>.477</cell><cell>.512</cell><cell>.642</cell><cell>.570</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Finnish</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Swedish</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aauzh</cell><cell>.618</cell><cell>.524</cell><cell>.567</cell><cell>.730</cell><cell>.619</cell><cell>.670</cell><cell>.686</cell><cell>.604</cell><cell>.643</cell><cell>.797</cell><cell>.702</cell><cell>.746</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Neur-bsl</cell><cell>.605</cell><cell>.687</cell><cell>.644</cell><cell>.715</cell><cell>.812</cell><cell>.760</cell><cell>.588</cell><cell>.728</cell><cell>.651</cell><cell>.675</cell><cell>.836</cell><cell>.747</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="18,88.99,456.65,418.20,218.30"><head>Table 8</head><label>8</label><figDesc>Results for NERC-Fine and Nested (micro P, R and F1-score).</figDesc><table coords="18,89.29,487.13,417.90,187.82"><row><cell></cell><cell></cell><cell></cell><cell cols="2">French</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">German</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">English</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Strict</cell><cell></cell><cell></cell><cell>Fuzzy</cell><cell></cell><cell></cell><cell>Strict</cell><cell></cell><cell></cell><cell>Fuzzy</cell><cell></cell><cell></cell><cell>Strict</cell><cell></cell><cell></cell><cell>Fuzzy</cell><cell></cell></row><row><cell></cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell></row><row><cell>hipe2020 (Fine)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>L3i</cell><cell>.702</cell><cell>.782</cell><cell>.740</cell><cell>.784</cell><cell>.873</cell><cell>.826</cell><cell>.691</cell><cell>.747</cell><cell>.718</cell><cell>.776</cell><cell>.840</cell><cell>.807</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Neur-bsl</cell><cell>.685</cell><cell>.733</cell><cell>.708</cell><cell>.769</cell><cell>.822</cell><cell>.795</cell><cell>.584</cell><cell>.673</cell><cell>.625</cell><cell>.659</cell><cell>.759</cell><cell>.706</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>hipe2020 (Nested)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>L3i</cell><cell>.390</cell><cell>.366</cell><cell>.377</cell><cell>.416</cell><cell>.390</cell><cell>.403</cell><cell>.714</cell><cell>.411</cell><cell>.522</cell><cell>.738</cell><cell>.425</cell><cell>.539</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>ajmc (Fine)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>L3i</cell><cell>.646</cell><cell>.694</cell><cell>.669</cell><cell>.703</cell><cell>.756</cell><cell>.728</cell><cell>.915</cell><cell>.898</cell><cell>.906</cell><cell>.941</cell><cell>.924</cell><cell>.933</cell><cell>.754</cell><cell>.848</cell><cell>.798</cell><cell>.801</cell><cell>.899</cell><cell>.847</cell></row><row><cell>Neur-bsl</cell><cell>.526</cell><cell>.567</cell><cell>.545</cell><cell>.616</cell><cell>.664</cell><cell>.639</cell><cell>.819</cell><cell>.817</cell><cell>.818</cell><cell>.866</cell><cell>.864</cell><cell>.865</cell><cell>.600</cell><cell>.744</cell><cell>.664</cell><cell>.676</cell><cell>.839</cell><cell>.749</cell></row><row><cell cols="19">EL-only. Entity linking on already identified mentions appears to be considerably more</cell></row><row><cell cols="19">challenging than NERC, with F1-scores varying considerably across datasets. The linking of</cell></row><row><cell cols="19">toponyms in topres19th is where systems achieved the overall best performances. Conversely,</cell></row><row><cell cols="19">EL-only on historical commentaries (ajmc) appears to be the most difficult, with the lowest</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="20,88.99,92.50,417.57,355.96"><head>Table 10</head><label>10</label><figDesc>Results for EL-only and End-to-end EL (micro P, R and F1-score @1). For End-to-end EL, only Team L3i submitted runs for hipe-2020. Bold font indicates the highest value.</figDesc><table coords="20,91.04,136.67,415.52,311.79"><row><cell></cell><cell></cell><cell>Strict</cell><cell></cell><cell></cell><cell>Relaxed</cell><cell></cell><cell></cell><cell>Strict</cell><cell></cell><cell></cell><cell>Relaxed</cell><cell></cell><cell></cell><cell>Strict</cell><cell></cell><cell cols="2">Relaxed</cell></row><row><cell></cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">hipe2020</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">French</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">German</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>English</cell><cell></cell><cell></cell></row><row><cell>EL-only</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>L3i</cell><cell cols="18">.602 .602 .602 .620 .620 .620 .481 .481 .481 .497 .497 .497 .546 .546 .546 .546 .546 .546</cell></row><row><cell>SBB</cell><cell cols="18">.707 .515 .596 .730 .532 .616 .603 .435 .506 .626 .452 .525 .503 .323 .393 .503 .323 .393</cell></row><row><cell>Nil-bsl</cell><cell cols="18">.209 .209 .209 .209 .209 .209 .481 .314 .380 .481 .314 .380 .228 .228 .228 .228 .228 .228</cell></row><row><cell>End-to-end EL</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>L3i</cell><cell cols="18">.546 .576 .560 .563 .594 .578 .446 .451 .449 .462 .466 .464 .463 .474 .469 .463 .474 .469</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">sonar</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">topres19th</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">German</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">English</cell><cell></cell></row><row><cell>SBB</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>.616</cell><cell cols="11">.446 .517 .616 .446 .517 .778 .559 .651 .781 .562 .654</cell></row><row><cell>Nil-bsl</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">333 .333 .333 .333 .333 .333</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">newseye</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">French</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">German</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SBB</cell><cell cols="12">.534 .361 .431 .539 .364 .435 .522 .387 .444 .535 .396 .455</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Nil-bsl</cell><cell cols="12">.448 .448 .448 .448 .448 .448 .485 .485 .485 .485 .485 .485</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ajmc</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">French</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">German</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>English</cell><cell></cell><cell></cell></row><row><cell>SBB</cell><cell cols="18">.621 .378 .470 .614 .373 .464 .712 .389 .503 .712 .389 .503 .578 .284 .381 .578 .284 .381</cell></row><row><cell>Nil-bsl</cell><cell cols="18">.037 .037 .037 .037 .037 .037 .049 .049 .049 .049 .049 .049 .046 .046 .046 .046 .046 .046</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,108.93,640.81,159.43,4.06"><p>https://impresso.github.io/CLEF-HIPE-2020</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,108.93,651.77,140.44,4.06"><p>https://hipe-eval.github.io/HIPE-2022/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,108.93,662.73,397.05,4.06;2,89.29,673.69,365.99,4.06"><p>Classical commentaries are scholarly publications dedicated to the in-depth analysis and explanation of ancient literary works. As such, they aim to facilitate the reading and understanding of a given literary text.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="3,108.93,673.72,389.12,4.06"><p>For space reasons, the discussion of related work is included in the extended version of this overview<ref type="bibr" coords="3,481.36,673.72,13.36,4.06" target="#b11">[12]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,108.93,673.66,99.28,4.06"><p>https://impresso-project.ch</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="5,108.93,640.81,93.40,4.06"><p>https://www.newseye.eu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="5,108.93,651.77,103.62,4.06"><p>https://sonar.fh-potsdam.de/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="5,108.93,662.73,123.13,4.06"><p>https://livingwithmachines.ac.uk/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="5,108.93,673.69,374.50,4.06"><p>Additional information is available online by following the links indicated for each datasets in Table1.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9" coords="10,108.93,651.80,170.53,4.06"><p>https://universaldependencies.org/format.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10" coords="10,108.93,662.76,232.22,4.06"><p>https://github.com/impresso/CLEF-HIPE-2020/tree/master/data</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_11" coords="10,108.93,673.71,142.50,4.06"><p>https://doi.org/10.5281/zenodo.6579950</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_12" coords="13,108.93,662.67,152.74,4.06"><p>https://github.com/hipe-eval/HIPE-scorer</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_13" coords="14,108.93,651.78,168.45,4.06"><p>https://github.com/huggingface/transformers/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_14" coords="14,108.93,662.74,183.08,4.06"><p>https://github.com/hipe-eval/HIPE-2022-baseline/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_15" coords="14,108.93,672.19,271.80,7.25"><p>The EL results for ajmc were low, probably due to some processing issues.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_16" coords="15,108.93,617.06,397.06,7.99;15,89.29,628.36,416.69,7.25;15,89.29,640.83,77.73,4.06"><p>Note that these experiments are evaluated using the officially published Newseye test sets<ref type="bibr" coords="15,445.46,618.91,14.85,4.06" target="#b14">[15]</ref> (released as dev2 dataset as part of HIPE-2022) and not the HIPE-2022 newseye test sets, which were unpublished prior to the HIPE 2022 campaign.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_17" coords="15,108.93,651.79,397.23,4.06;15,89.29,662.75,33.79,4.06"><p>For English data, they used the Digitised Books. c. 1510 -c. 1900, all other languages use Europeana newspaper text data.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20" xml:id="foot_18" coords="15,108.93,673.71,250.63,4.06"><p>This improves the results by 1.2% on average on the HIPE-2022 data.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="21" xml:id="foot_19" coords="17,108.93,673.71,335.55,4.06"><p>See https://hipe-eval.github.io/HIPE-2022 and https://github.com/hipe-eval/HIPE-2022-eval</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="22" xml:id="foot_20" coords="21,108.93,660.91,397.05,7.99;21,89.29,671.87,208.86,7.99"><p>The challenge leaderboards can be found at the HIPE-2022 results page in the Challenge Evaluation Results section, see https://hipe-eval.github.io/HIPE-2022/results.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="8.">Acknowledgments</head><p>The HIPE-2022 team expresses her greatest appreciation to the HIPE-2022 partnering projects, namely AjMC, impresso-HIPE-2020, Living with Machines, NewsEye, and <rs type="funder">SoNAR</rs>, for contributing (and hiding) their NE-annotated datasets. We particularly thank <rs type="person">Mariona Coll-Ardanuy</rs> (<rs type="affiliation">LwM</rs>), <rs type="person">Ahmed Hamdi</rs> (<rs type="affiliation">NewsEye</rs>) and <rs type="person">Clemens Neudecker</rs> (<rs type="affiliation">SoNAR</rs>) for their support regarding data provision, and the members of the HIPE-2022 advisory board, namely <rs type="person">Sally Chambers</rs>, <rs type="person">Fr√©d√©ric Kaplan</rs> and <rs type="person">Clemens Neudecker</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="23,112.66,240.91,395.17,4.94;23,112.66,254.46,394.61,4.94;23,112.28,268.01,394.91,4.94;23,112.28,281.56,394.91,4.94;23,112.66,295.11,393.33,4.94;23,112.66,308.66,394.53,4.94;23,112.66,322.21,22.69,4.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="23,424.19,240.91,83.64,4.94;23,112.66,254.46,373.61,4.94">Overview of HIPE-2022: Named Entity Recognition and Linking in Multilingual Historical Documents</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Najem-Meyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="23,339.03,281.56,168.16,4.94;23,112.66,295.11,393.33,4.94;23,112.66,308.66,125.83,4.94">Proceedings of the Thirteenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="23,269.88,308.66,184.66,4.94">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Barr√≥n-Cede√±o</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Degli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Esposti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Sebastiani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Pasi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Thirteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="23,112.66,335.76,394.53,4.94;23,112.66,349.31,394.44,4.94;23,112.66,361.02,184.59,8.82" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="23,221.59,335.76,86.75,4.94">Big Data of the Past</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Di Lenardo</surname></persName>
		</author>
		<idno type="DOI">10.3389/fdigh.2017.00012</idno>
		<ptr target="https://www.frontiersin.org/articles/10.3389/fdigh.2017.00012/full.doi:10.3389/fdigh.2017.00012" />
	</analytic>
	<monogr>
		<title level="j" coord="23,316.48,335.76,139.56,4.94">Frontiers in Digital Humanities</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2017">2017</date>
			<publisher>Frontiers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,376.41,393.32,4.94;23,112.66,389.95,394.53,4.94;23,112.66,403.50,383.93,4.94" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ridge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Colavizza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Brake</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-P</forename><surname>Moreux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Prescott</surname></persName>
		</author>
		<ptr target="http://infoscience.epfl.ch/record/271329" />
		<title level="m" coord="23,430.75,376.41,75.23,4.94;23,112.66,389.95,257.38,4.94;23,391.47,389.95,37.46,4.94">The past, present and future of digital scholarship with newspaper collections</title>
		<meeting><address><addrLine>Utrecht, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
	<note>DH 2019. book of abstracts</note>
</biblStruct>

<biblStruct coords="23,112.66,417.05,393.33,4.94;23,112.66,430.60,393.33,4.94;23,112.33,444.15,395.33,4.94;23,112.66,457.70,207.07,4.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="23,324.56,417.05,181.42,4.94;23,112.66,430.60,66.25,4.94">Diachronic evaluation of NER systems on old newspapers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Colavizza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Rochat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kaplan</surname></persName>
		</author>
		<ptr target="https://infoscience.epfl.ch/record/221391" />
	</analytic>
	<monogr>
		<title level="m" coord="23,202.33,430.60,303.65,4.94;23,112.33,444.15,266.67,4.94">Proceedings of the 13th Conference on Natural Language Processing (KONVENS 2016), Bochumer Linguistische Arbeitsberichte</title>
		<meeting>the 13th Conference on Natural Language Processing (KONVENS 2016), Bochumer Linguistische Arbeitsberichte<address><addrLine>Bochum</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="97" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,471.25,393.33,4.94;23,112.66,484.80,393.33,4.94;23,112.66,496.10,394.53,9.72;23,112.66,511.90,80.84,4.94" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="23,390.16,471.25,115.82,4.94;23,112.66,484.80,244.32,4.94">Named Entity Recognition and Classification on Historical Documents: A Survey</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">L</forename><surname>Pontes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.11406[cs</idno>
		<idno>arXiv: 2109.11406</idno>
		<ptr target="http://arxiv.org/abs/2109.11406" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>to appear in ACM journal Computing Surveys in 2022</note>
</biblStruct>

<biblStruct coords="23,112.66,525.45,394.62,4.94;23,112.66,539.00,394.53,4.94;23,112.66,552.55,395.16,4.94;23,112.66,566.09,394.53,4.94;23,112.66,579.64,395.01,4.94;23,112.66,593.19,38.81,4.94" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="23,369.83,525.45,137.44,4.94;23,112.66,539.00,293.93,4.94">Overview of CLEF HIPE 2020: Named entity recognition and linking on historical newspapers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fl√ºckiger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="23,200.57,566.09,302.42,4.94">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<title level="s" coord="23,112.66,579.64,160.81,4.94">Lecture Notes in Computer Sciences</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lioma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>N√©v√©ol</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="288" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,606.74,393.33,4.94;23,112.66,620.29,394.53,4.94;23,112.66,633.84,393.33,4.94;23,112.66,647.39,394.62,4.94;23,112.31,660.94,301.62,4.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="23,356.51,606.74,149.48,4.94;23,112.66,620.29,254.63,4.94">Extended Overview of CLEF HIPE 2020: Named Entity Processing on Historical Newspapers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fl√ºckiger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.4117566</idno>
		<ptr target="https://infoscience.epfl.ch/record/281054.doi:10.5281/zenodo.4117566" />
	</analytic>
	<monogr>
		<title level="m" coord="23,235.82,633.84,270.17,4.94;23,112.66,647.39,76.83,4.94">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>N√©v√©ol</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2696</biblScope>
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,90.23,393.53,4.94;24,112.66,103.78,393.33,4.94;24,112.66,117.33,395.01,4.94;24,112.66,130.88,177.89,4.94" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="24,364.62,90.23,141.57,4.94;24,112.66,103.78,220.27,4.94">A joint named-entity recognizer for heterogeneous tag-sets using a tag hierarchy</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Beryozkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Drori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Gilon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hartman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Szpektor</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/P19-1014" />
	</analytic>
	<monogr>
		<title level="m" coord="24,360.14,103.78,145.85,4.94;24,112.66,117.33,245.46,4.94">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="140" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,144.43,394.53,4.94;24,112.66,157.97,299.37,4.94" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="24,261.03,144.43,241.42,4.94">Few-shot named entity recognition via meta-learning</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="24,112.66,157.97,248.60,4.94">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,171.52,393.33,4.94;24,112.66,185.07,393.57,4.94;24,112.33,198.62,196.41,4.94" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="24,399.14,171.52,106.84,4.94;24,112.66,185.07,291.74,4.94">Enhanced meta-learning for cross-lingual named entity recognition with minimal resources</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">F</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<idno>CoRR abs/1911.06161</idno>
		<ptr target="http://arxiv.org/abs/1911.06161" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,212.17,394.62,4.94;24,112.66,225.72,395.17,4.94;24,112.66,239.27,395.01,4.94;24,112.66,252.82,147.34,4.94" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="24,228.26,212.17,254.70,4.94">Metaner: Named entity recognition with meta-learning</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<idno type="DOI">10.1145/3366423.3380127</idno>
		<ptr target="https://doi.org/10.1145/3366423.3380127.doi:10.1145/3366423.3380127" />
	</analytic>
	<monogr>
		<title level="m" coord="24,112.66,225.72,231.26,4.94">Proceedings of The Web Conference 2020, WWW &apos;20</title>
		<meeting>The Web Conference 2020, WWW &apos;20<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="429" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,266.37,393.72,4.94;24,112.66,279.92,395.17,4.94;24,112.66,293.47,393.59,4.94;24,112.66,307.02,312.40,4.94" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="24,420.38,266.37,86.01,4.94;24,112.66,279.92,395.17,4.94;24,112.66,293.47,24.89,4.94">Extended Overview of HIPE-2022: Named Entity Recognition and Linking on Multilingual Historical Documents</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Najem-Meyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="24,399.17,293.47,107.08,4.94;24,112.66,307.02,231.02,4.94">Working Notes of CLEF 2022 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,320.56,393.53,4.94;24,112.66,331.87,395.17,9.72;24,112.66,347.66,394.52,4.94;24,112.66,361.21,115.49,4.94" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="24,402.84,320.56,103.35,4.94;24,112.66,331.87,207.08,9.72">Language Resources for Historical Newspapers: The Impresso Collection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">B</forename><surname>Str√∂bel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Barman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="24,342.35,334.11,165.48,4.94;24,112.66,347.66,151.82,4.94">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="958" to="968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,374.76,393.33,4.94;24,112.66,388.31,393.32,4.94;24,112.66,401.86,394.44,4.94;24,112.66,413.57,80.55,8.82" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fl√ºckiger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.3604227</idno>
		<ptr target="https://zenodo.org/record/3585750.doi:10.5281/zenodo.3604227" />
		<title level="m" coord="24,351.67,374.76,154.32,4.94;24,112.66,388.31,149.39,4.94">Impresso Named Entity Annotation Guidelines, Annotation Guidelines</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
		<respStmt>
			<orgName>Ecole Polytechnique F√©d√©rale de Lausanne (EPFL) and Zurich University (UZH)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,428.96,393.70,4.94;24,112.66,442.51,393.33,4.94;24,112.66,456.06,393.33,4.94;24,112.66,469.61,393.33,4.94;24,112.66,483.16,386.62,4.94" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="24,498.93,428.96,7.43,4.94;24,112.66,442.51,393.33,4.94;24,112.66,456.06,95.33,4.94">A Multilingual Dataset for Named Entity Recognition, Entity Linking and Stance Detection in Historical Newspapers</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Linhares Pontes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Boros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">T H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hackl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<idno type="DOI">10.1145/3404835.3463255</idno>
	</analytic>
	<monogr>
		<title level="m" coord="24,229.66,456.06,276.33,4.94;24,112.66,469.61,269.33,4.94">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;21</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;21<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2328" to="2334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,496.70,393.33,4.94;24,112.66,510.25,394.04,4.94;24,112.41,523.80,212.21,4.94" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="24,409.11,496.70,96.87,4.94;24,112.66,510.25,240.54,4.94">Dataset for Toponym Resolution in Nineteenth-Century English Newspapers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Coll Ardanuy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Beavan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Beelen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lawrence</surname></persName>
		</author>
		<idno type="DOI">10.23636/b1c4-py78</idno>
		<ptr target="https://https//doi.org/10.23636/b1c4-py78.doi:10.23636/b1c4-py78" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,537.35,393.61,4.94;24,112.66,550.90,393.33,4.94;24,112.66,564.45,393.33,4.94;24,112.66,578.00,394.44,4.94;24,112.66,589.71,86.13,8.82" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="24,297.43,537.35,208.84,4.94;24,112.66,550.90,229.02,4.94">Optical Character Recognition of 19th Century Classical Commentaries: the Current State of Affairs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N.-M</forename><surname>Sven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Robertson</surname></persName>
		</author>
		<idno type="DOI">10.1145/3476887.3476911</idno>
		<ptr target="https://doi.org/10.1145/3476887.3476911.doi:10.1145/3476887.3476911" />
	</analytic>
	<monogr>
		<title level="m" coord="24,364.14,550.90,141.85,4.94;24,112.66,564.45,263.08,4.94">The 6th International Workshop on Historical Document Imaging and Processing (HIP &apos;21)</title>
		<meeting><address><addrLine>Lausanne</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,605.10,393.33,4.94;24,112.66,618.65,365.62,4.94" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Cyril</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Zweigenbaum</surname></persName>
		</author>
		<idno>2011-04</idno>
		<title level="m" coord="24,331.92,605.10,174.06,4.94;24,112.66,618.65,89.88,4.94">Entit√©s Nomm√©es Structur√©es : Guide d&apos;annotation Quaero</title>
		<meeting><address><addrLine>Orsay, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
		<respStmt>
			<orgName>LIMSI-CNRS</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="24,112.66,632.20,393.33,4.94;24,112.66,645.75,394.44,4.94;24,112.66,657.45,80.55,8.82" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="24,257.55,632.20,248.44,4.94;24,112.66,645.75,87.54,4.94">Guidelines for the Annotation of Named Entities in the Domain of Classics</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Najem-Meyer</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.6368101</idno>
		<ptr target="https://doi.org/10.5281/zenodo.6368101.doi:10.5281/zenodo.6368101" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,672.84,393.70,4.94;25,112.66,90.23,395.01,4.94;25,112.66,103.78,397.23,4.94;25,112.66,115.49,19.15,8.82" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="24,304.66,672.84,201.71,4.94;25,112.66,90.23,91.59,4.94">Generalisation in named entity recognition: A quantitative analysis</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bontcheva</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.csl.2017.01.012</idno>
		<ptr target="http://www.sciencedirect.com/science/article/pii/S088523081630002X.doi:10.1016/j.csl.2017.01.012" />
	</analytic>
	<monogr>
		<title level="j" coord="25,212.50,90.23,137.37,4.94">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="61" to="83" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,130.88,394.61,4.94;25,112.28,144.43,394.90,4.94;25,112.66,157.97,393.33,4.94;25,112.66,171.52,397.23,4.94;25,112.38,181.04,143.95,11.01" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="25,253.26,130.88,254.02,4.94;25,112.28,144.43,168.74,4.94">Contextualized Embeddings in Named-Entity Recognition: An Empirical Study on Generalization</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Taill√©</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Guigue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gallinari</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-45442-5_48</idno>
	</analytic>
	<monogr>
		<title level="m" coord="25,278.24,157.97,148.76,4.94">Advances in Information Retrieval</title>
		<title level="s" coord="25,433.87,157.97,72.12,4.94;25,112.66,171.52,80.61,4.94">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Jose</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Magalh√£es</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Castells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Martins</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="383" to="391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,198.62,393.33,4.94;25,112.66,212.17,388.84,4.94" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="25,335.50,198.62,170.49,4.94;25,112.66,212.17,43.20,4.94">Performance measures for information extraction</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Makhoul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kubala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="25,190.62,212.17,222.23,4.94">Proceedings of DARPA Broadcast News Workshop</title>
		<meeting>DARPA Broadcast News Workshop</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="249" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,225.72,395.17,4.94;25,112.66,239.27,395.01,4.94;25,112.66,252.82,141.76,4.94" xml:id="b22">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.6045662</idno>
		<ptr target="https://zenodo.org/record/6045662.doi:10.5281/zenodo.6045662" />
		<title level="m" coord="25,355.70,225.72,152.13,4.94;25,112.66,239.27,65.41,4.94">HIPE 2022 Shared Task Participation Guidelines</title>
		<meeting><address><addrLine>Zenodo</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="25,112.66,266.37,394.53,4.94;25,112.66,279.92,393.33,4.94;25,112.66,291.63,156.12,8.82" xml:id="b23">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Guzm√°n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.02116</idno>
		<title level="m" coord="25,272.40,279.92,233.58,4.94;25,112.66,293.47,32.08,4.94">Unsupervised Cross-lingual Representation Learning at Scale</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,307.02,394.53,4.94;25,112.66,320.56,394.53,4.94;25,112.66,334.11,395.17,4.94;25,112.66,347.66,393.33,4.94;25,112.66,361.21,394.53,4.94;25,112.66,374.76,385.60,4.94" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="25,315.63,334.11,192.20,4.94;25,112.66,347.66,72.82,4.94">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.emnlp-demos.6" />
	</analytic>
	<monogr>
		<title level="m" coord="25,207.25,347.66,298.74,4.94;25,112.66,361.21,390.37,4.94">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,388.31,395.17,4.94;25,112.66,401.86,282.97,4.94" xml:id="b25">
	<monogr>
		<title level="m" coord="25,364.15,388.31,143.69,4.94;25,112.66,401.86,201.59,4.94">Working Notes of CLEF 2022 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,415.41,394.53,4.94;25,112.28,428.96,393.71,4.94;25,112.66,442.51,393.32,4.94;25,112.66,456.06,397.23,4.94;25,112.38,467.77,136.87,8.82" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="25,170.39,428.96,335.59,4.94;25,112.66,442.51,45.82,4.94">Alleviating digitization errors in named entity recognition for historical documents</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Boros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Linhares Pontes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Cabrera-Diego</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Sidere</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.conll-1.35</idno>
	</analytic>
	<monogr>
		<title level="m" coord="25,182.16,442.51,323.82,4.94;25,112.66,456.06,235.86,4.94">Proceedings of the 24th Conference on Computational Natural Language Learning, Association for Computational Linguistics</title>
		<meeting>the 24th Conference on Computational Natural Language Learning, Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="431" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,483.16,394.53,4.94;25,112.66,496.70,394.53,4.94;25,112.66,510.25,393.33,4.94;25,112.66,521.55,394.52,9.72;25,112.66,537.35,277.66,4.94" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="25,217.30,496.70,201.46,4.94">Parameter-efficient transfer learning for NLP</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giurgiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Morrone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>De Laroussilhe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gesmundo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Attariyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<ptr target="https://proceedings.mlr.press/v97/houlsby19a.html" />
	</analytic>
	<monogr>
		<title level="m" coord="25,223.91,510.25,282.08,4.94;25,112.66,523.80,37.69,4.94;25,218.10,521.55,181.33,9.72">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</editor>
		<meeting>the 36th International Conference on Machine Learning<address><addrLine>PMLR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="2790" to="2799" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct coords="25,112.66,550.90,394.53,4.94;25,112.14,564.45,394.06,4.94;25,112.66,578.00,397.23,4.94;25,112.38,589.71,125.21,8.82" xml:id="b28">
	<monogr>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2203.00545</idno>
		<ptr target="https://arxiv.org/abs/2203.00545.doi:10.48550/ARXIV.2203.00545" />
		<title level="m" coord="25,186.58,564.45,319.62,4.94;25,112.66,578.00,164.56,4.94">DAMO-NLP at SemEval-2022 task 11: A knowledge-based system for multilingual named entity recognition</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,605.10,393.32,4.94;25,112.66,618.65,393.33,4.94;25,112.66,632.20,394.53,4.94;25,112.66,645.75,394.44,4.94;25,112.38,657.45,125.71,8.82" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="25,226.50,605.10,279.48,4.94;25,112.66,618.65,98.00,4.94">Making monolingual sentence embeddings multilingual using knowledge distillation</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.365</idno>
		<ptr target="https://aclanthology.org/2020.emnlp-main.365.doi:10.18653/v1/2020.emnlp-main.365" />
	</analytic>
	<monogr>
		<title level="m" coord="25,233.11,618.65,272.88,4.94;25,112.66,632.20,356.10,4.94">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4512" to="4525" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,672.84,393.53,4.94;26,112.66,90.23,395.01,4.94;26,112.66,101.94,199.56,8.82" xml:id="b30">
	<monogr>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.06136</idno>
		<ptr target="https://arxiv.org/pdf/1911.06136.pdf" />
		<title level="m" coord="25,378.41,672.84,127.77,4.94;26,112.66,90.23,279.98,4.94">Kepler: A unified model for knowledge embedding and pre-trained language representation</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="26,112.66,117.33,393.33,4.94;26,112.41,130.88,394.87,4.94;26,112.66,144.43,394.61,4.94;26,112.66,157.97,386.71,4.94" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="26,237.33,117.33,161.93,4.94">Subword pooling makes a difference</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>√Åcs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">√Å</forename><surname>K√°d√°r</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kornai</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.eacl-main.194</idno>
		<ptr target="https://aclanthology.org/2021.eacl-main.194.doi:10.18653/v1/2021.eacl-main.194" />
	</analytic>
	<monogr>
		<title level="m" coord="26,422.26,117.33,83.73,4.94;26,112.41,130.88,394.87,4.94;26,112.66,144.43,242.96,4.94">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, Association for Computational Linguistics</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2284" to="2295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="26,112.66,171.52,393.53,4.94;26,112.66,185.07,393.33,4.94;26,112.66,198.62,395.01,4.94;26,112.66,212.17,127.36,4.94" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="26,227.86,171.52,278.33,4.94;26,112.66,185.07,67.53,4.94">Named entity disambiguation and linking on historic newspaper OCR with BERT</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Labusch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Neudecker</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/paper_163.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="26,203.45,185.07,302.54,4.94;26,112.66,198.62,25.85,4.94">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="26,213.91,198.62,173.45,4.94">CEUR Workshop Proceedings, CEUR-WS</title>
		<imprint>
			<date type="published" when="2020">2696. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="26,112.66,225.72,394.52,4.94;26,112.33,239.27,326.42,4.94" xml:id="b33">
	<monogr>
		<title level="m" type="main" coord="26,159.20,225.72,343.78,4.94">Responsible Operations: Data Science, Machine Learning, and AI in Libraries</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Padilla</surname></persName>
		</author>
		<idno type="DOI">10.25333/xk7z-9g97</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>OCLC Research</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="26,112.66,252.82,393.33,4.94;26,110.82,266.37,396.85,4.94;26,112.66,279.92,277.94,4.94" xml:id="b34">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Neudecker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Isaac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Bergel</surname></persName>
		</author>
		<ptr target="https://pro.europeana.eu/project/ai-in-relation-to-glams" />
		<title level="m" coord="26,313.20,252.82,192.79,4.94;26,110.82,266.37,136.62,4.94">AI in Relation to GLAMs Task FOrce -Report and Recommendations</title>
		<imprint>
			<publisher>Europeana Network ASsociation</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>Others</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
