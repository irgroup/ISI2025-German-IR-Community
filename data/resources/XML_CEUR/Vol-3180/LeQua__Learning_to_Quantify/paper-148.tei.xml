<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,405.90,15.42;1,89.29,106.66,265.25,15.42">UniPadova @ LeQua 2022: A Preliminary Study of a BM25 Approach to Quantification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,89.29,134.97,83.39,11.96"><forename type="first">Giorgio</forename><forename type="middle">Maria</forename><surname>Di</surname></persName>
							<email>giorgiomaria.dinunzio@unipd.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padova</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">University of Padova</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,405.90,15.42;1,89.29,106.66,265.25,15.42">UniPadova @ LeQua 2022: A Preliminary Study of a BM25 Approach to Quantification</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">8A4E23BC63D81AA8679F51969E5AA023</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Quantification</term>
					<term>Two-dimensional BM25</term>
					<term>R Tidyverse</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our participation to the LeQua lab continues the sequence of experiments dedicated to minimal coding that use the R Tidyverse packages to build reproducible source code for experiments in IR related tasks. In this specific case, we focused on the two-dimensional interpretation of the BM25 ranking formula that studies the distribution of documents on a two-dimensional space to study the quantification task without any type of optimization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The Learning to Quantify lab (LeQua) at the Conference and Labs Evaluation Forum (CLEF) 2022, is the first edition of a laboratory dedicated to the evaluation of methods for text quantification <ref type="bibr" coords="1,120.10,386.71,11.59,10.91" target="#b0">[1]</ref>. The four subtasks available differ in the number of classes (binary or multi-class) and in the data source for training and testing (numerical matrices or raw textual documents).</p><p>Our participation to the LeQua lab continues the sequence of experiments dedicated to minimal coding that use the R Tidyverse 1 approach to build the software for the research setting and experimental analysis <ref type="bibr" coords="1,242.89,440.90,11.43,10.91" target="#b1">[2,</ref><ref type="bibr" coords="1,257.06,440.90,7.62,10.91" target="#b2">3]</ref>. In this specific case, our experiments focused on the two-dimensional interpretation of the BM25 ranking formula that studies the distribution of documents on a two-dimensional space to optimize the classification model <ref type="bibr" coords="1,427.96,468.00,11.43,10.91" target="#b3">[4]</ref>.</p><p>Given the time constraints, we could participate only to Subtask T2A. This task focuses on the evaluation of binary quantifiers starting from raw text. For this reason, our main contribution with these experiments is summarized as follows:</p><p>• A study of a minimal binary quantifier based on BM25 without feature selection; • A comparison with the QuaPy baseline w/out feature selection.</p><p>The remainder of the paper will introduce the methodology and a brief summary of the experimental settings that we used in order to create the official run submitted for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Method</head><p>Our method follows the principles described by <ref type="bibr" coords="2,305.28,111.28,12.90,10.91" target="#b4">[5]</ref> where a collection of textual document is processed through "pipelines", a sort of organized workflow split into steps where the output of one step is the input for the subsequent step. The R programming language has a set of packages named Tidyverse that implements this idea of pipelines. The additional value of this approach is that it is easily reproducible and easily readable.<ref type="foot" coords="2,357.16,163.72,3.71,7.97" target="#foot_0">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Pipeline for Importing Data</head><p>In order to preprocess the dataset of raw documents, we used the following pipeline:</p><p>1. start from raw data; 2. split text into words; <ref type="foot" coords="2,208.68,248.61,3.71,7.97" target="#foot_1">3</ref>3. transform to lowercase; 4. remove stopwords; 5. remove words with less than (or with exactly) two characters and keep only words without any number; 6. compute tf.</p><p>The corresponding six lines of code are shown in Listing 1 while the result of these passages for the ten most frequent words and their frequencies are shown in Listing 2.</p><p>Listing 1: Extraction of terms and term frequencies from raw data r a w _ d a t a %&gt;% u n n e s t _ t o k e n s ( word , t e x t ) %&gt;% m u t a t e ( word = t o l o w e r ( word ) ) %&gt;% a n t i _ j o i n ( g e t _ s t o p w o r d s ( ) ) %&gt;% f i l t e r ( n c h a r ( word ) &gt; 2 &amp; s t r _ d e t e c t ( word , " ^[ a -z ]+ $ " ) ) %&gt;% c o u n t ( l a b e l , d o c i d , word , name = " t f " ) Listing 2: Top ten term and their frequencies </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Computing BM25</head><p>BM25 ranks documents according to the probability of relevance (𝑅 = 1) given a document 𝑑 and a query 𝑞, 𝑃 (𝑅 = 1|𝑑, 𝑞). This probability can be approximated by the sum of the words 𝑤 𝑖 (see <ref type="bibr" coords="3,123.14,134.63,12.84,10.91" target="#b5">[6]</ref> for the derivation of the following equations):</p><formula xml:id="formula_0" coords="3,238.80,157.35,267.19,26.53">𝑃 (𝑅 = 1|𝑑, 𝑞) ≈ ∑︁ 𝑡 𝑖 ∈𝑑∩𝑞 𝑤 𝑖<label>(1)</label></formula><p>where</p><formula xml:id="formula_1" coords="3,216.81,204.23,289.17,26.48">𝑤 𝑖 = 𝑡𝑓 𝑖 𝑡𝑓 𝑖 + 𝐾 • 𝑙𝑜𝑔 (︂ 𝑝 𝑖 𝑞 𝑖 (1 -𝑞 𝑖 ) (1 -𝑝 𝑖 ) )︂ ,<label>(2)</label></formula><p>𝑝 𝑖 (or 𝑞 𝑖 ) is the probability, estimated on the training data, that a relevant (or non-relevant) document contains the word 𝑤 𝑖 and 𝑡𝑓 𝑖 is the term frequency of 𝑤 𝑖 in the document 𝑑 and 𝐾 a function of some parameters about the global statistics of the collection of documents.</p><p>In the two-dimensional representation of probabilities, we keep 𝑃 (𝑅 = 1|𝑑, 𝑞) distinct from the probability of a document being not relevant 𝑃 (𝑅 = 0|𝑑, 𝑞). 4 For the quantification task, we will drop the variable 𝑞 and turn this model into a classification problem where a document 𝑑 is either member of a class or not (relevant or not for that class). In this way, the sum of the terms 𝑡 𝑖 (see Eq. ( <ref type="formula" coords="3,168.11,331.88,3.71,10.91" target="#formula_0">1</ref>)) is computed across all the terms of the document (𝑡 𝑖 ∈ 𝑑).</p><p>With some algebraic manipulation -see <ref type="bibr" coords="3,285.09,345.43,12.87,10.91" target="#b6">[7]</ref> for an explanation of how these two parts can be derived from the original BM25 formulation -we obtain the following decision function (we hide some constant factors for a cleaner presentation):</p><formula xml:id="formula_2" coords="3,203.20,394.59,302.78,46.22">∑︁ 𝑡 𝑖 log (︂ 𝑝 𝑖 1 -𝑝 𝑖 )︂ ⏟ ⏞ 𝑥 - ∑︁ 𝑡 𝑖 log (︂ 𝑞 𝑖 1 -𝑞 𝑖 )︂ ⏟ ⏞ 𝑦 &gt; 0<label>(3)</label></formula><p>If the inequality is true, the document is classified in the relevant category (R = 1), otherwise it w-ll be classified as non relevant (R = 0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Plotting Predictions</head><p>The advantage of this BM25 reformulation is its geometric interpretation. The two sums, 𝑥 and 𝑦, can be rendered as two coordinates in a two-dimensional space. 5 In Figure <ref type="figure" coords="3,438.63,529.42,3.79,10.91" target="#fig_0">1</ref>, we show the result of the two-dimensional interpretation for the training set. Each point is a document and the two coordinates represent the BM25 weight decomposed in the two parts <ref type="bibr" coords="3,431.23,556.51,11.34,10.91" target="#b7">[8]</ref>. Points below the line are classified as 'positive' (class 1), points above the line as 'negative' (class 0). The color of each point shows the true label of the document. It is possible to see some misclassified 4 While it is true that 𝑃 (𝑅 = 1|𝑑, 𝑞) = 1 -𝑃 (𝑅 = 0|𝑑, 𝑞), there are probabilistic and implementation reasons that explain this more elaborate description <ref type="bibr" coords="3,254.07,616.02,9.38,8.97" target="#b5">[6]</ref>. In Eq. ( <ref type="formula" coords="3,295.85,616.02,2.86,8.97" target="#formula_0">1</ref>), the "approxiametly equal to" derives from the fact that the documents ordered by the probability 𝑃 (𝑅 = 1|𝑑, 𝑞) are ordered in the same way by log (︁</p><formula xml:id="formula_3" coords="3,92.57,625.86,413.42,31.65">𝑃 (𝑅=1|𝑑,𝑞) 1-𝑃 (𝑅=1|𝑑,𝑞) )︁ = log (︁ 𝑃 (𝑅=1|𝑑,𝑞) 𝑃 (𝑅=0|𝑑,𝑞)</formula><p>)︁ . 5 In this paper, we are using 𝑥 and 𝑦 in traditional sense, i.e. coordinates of a two-dimensional Cartesian space, and not in a Machine Learning sense where 𝑥 is the input and 𝑦 is the output that the model has to predict. points along the line (a red dot below the line or a cyan dot above it). In quantification task, it is not important to have a perfect classifier (all the red points above the line and all the cyan points below it), but rather to keep these misclassified points balanced: the number of false positives should equal the number of false negatives to achieve a perfectthe prediction in terms of proportions of the two classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>In our experiments, we run the two-dimensional BM25 and compare it with the QuaPy baseline trained with a Logistic Regression classifier and optimized with the all the classify and counts variants: CC, ACC, PCC, PACC. <ref type="foot" coords="4,230.54,582.51,3.71,7.97" target="#foot_2">6</ref>In the following items, we discuss our preliminary considerations about the analysis of the results:</p><p>• The unbalancedness in the training and development sets between the classes were never used to optof imize the probabilities the BM25.</p><p>• The number of unique terms we found is 41,905 which is almost four times the number of unique terms found with the QuaPy baseline (12,301 in total). If we filter the terms with document frequency greater or equal 3 (which is the default value for QuaPy) we get a comparable number of tokens (14,179). • The absolute error AE on the training set (an overestimation of the goodness of the quantifier) is very small for BM25, AE = 0.0062. It is also interesting to note that the classifier is far from being perfect (accuracy of .85) but the proportion of false positives and false negatives is very good (348 against 379) without any optimization. • The situation changes drastically in the development and in the test set, as shown in the overview results provided by the organizers of the Lab. We will investigate the amount of error due to the topic drift, change in the vocabulary, and the approach to count the proportions (in this version, we only performed a classify and count). • We also found that the QuaPy tfidf baseline was different from the official results. For example, the best baseline with tfidf is PACC (we agree with this result)A the offEcial Relative absolute error is RAE = 0.138 (AE = 0.026) while our baseline is RAE = 0.294 (AE = 0.036), the worst tfidf baseline is PCC (while ours is CC), the official results are RAE = 1.362 (AE = 0.144) while our results are RAE = 2.615 (AE = 0.261).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Future Work</head><p>In the previous section, we highlighted some points that will drive our next steps. In particular, we know that the size of the vocabulary we used was much larger than the baselines, we also think that there is some additional feature selection that can give some additional value and level the results between the baselines. The additional part for improving the BM25 approach is the fact that we only used the classify and count (CC) approach which is almost the worst among all the baselines. At the end, even though the results were not good at all, the exercise has been very stimulating for clarifying some steps, think about some new ideas of how to tackle the quantification approach, and see at work the QuaPy framework which is an excellent baseline for this task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,89.29,385.05,416.69,8.93;4,89.29,397.06,416.69,8.87;4,89.29,409.02,154.95,8.87"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Visualization of the training documents on the two-dimensional space. Points below the line are classified as 'positive' (class 1), points above the line as 'negative' (class 0). The color of each point shows the true label of the document.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,92.57,660.08,280.34,8.97"><p>The source code of the experiments is available at: https://github.com/gmdn.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="2,92.57,671.04,120.34,8.97"><p>https://www.tidytextmining.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="4,92.57,660.08,413.41,8.97;4,92.57,671.04,44.98,8.97"><p>The Python code that we run ourselves to have the QuaPy baseline will be made available together with the R source code.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>It is one of those cases where the anonymous reviewers were very engaging and made us think about how some parts of the paper could be improved and made clearer. We really want to thank them for all the comments and suggestions.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="5,107.59,634.09,399.59,10.91;5,107.59,647.64,399.60,10.91;5,107.59,661.19,79.06,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,306.91,634.09,195.99,10.91">Overview of lequa 2022: Learning to quantify</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moreo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sperduti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,122.23,647.64,380.64,10.91">Working Notes of the 2022 Conference and Labs of the Evaluation Forum (CLEF 2022)</title>
		<meeting><address><addrLine>Bologna, IT</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,107.59,86.97,398.40,10.91;6,107.59,100.52,398.40,10.91;6,107.59,114.06,399.60,10.91;6,107.59,127.61,399.69,10.91;6,107.59,141.16,173.87,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,196.13,86.97,309.86,10.91;6,107.59,100.52,39.84,10.91">A study on lemma vs stem for legal information retrieval using R tidyverse</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">M D</forename><surname>Nunzio</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2826/T1-10.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="6,400.50,100.52,105.49,10.91;6,107.59,114.06,229.95,10.91">Working Notes of FIRE 2020 -Forum for Information Retrieval Evaluation</title>
		<title level="s" coord="6,206.53,127.61,155.15,10.91">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Mehta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Mandl</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Majumder</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Mitra</surname></persName>
		</editor>
		<meeting><address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">December 16-20, 2020. 2020</date>
			<biblScope unit="volume">2826</biblScope>
			<biblScope unit="page" from="54" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,107.59,154.71,398.40,10.91;6,107.59,168.26,399.60,10.91;6,107.20,181.81,398.78,10.91;6,107.59,195.36,398.40,10.91;6,107.59,208.91,367.51,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,184.78,154.71,321.20,10.91;6,107.59,168.26,42.90,10.91">As simple as possible: Using the R tidyverse for multilingual information extraction</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">M D</forename><surname>Nunzio</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/paper_137.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="6,157.50,168.26,171.47,10.91;6,186.14,181.81,319.84,10.91;6,107.59,195.36,26.91,10.91">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="6,432.30,196.37,73.68,9.72;6,107.59,208.91,77.32,10.91">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">September 22-25, 2020. 2696. 2020</date>
		</imprint>
	</monogr>
	<note>IMS unipd ad CLEF ehealth 2020 task 1</note>
</biblStruct>

<biblStruct coords="6,107.59,222.46,399.60,10.91;6,107.59,236.01,398.40,10.91;6,107.59,249.56,399.60,10.91;6,107.20,263.11,399.97,10.91;6,107.59,279.10,91.42,7.90" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,186.46,222.46,130.51,10.91">Shiny on your crazy diagonal</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">M D</forename><surname>Nunzio</surname></persName>
		</author>
		<idno type="DOI">10.1145/2766462.2767867</idno>
		<ptr target="https://doi.org/10.1145/2766462.2767867.doi:10.1145/2766462.2767867" />
	</analytic>
	<monogr>
		<title level="m" coord="6,220.65,236.01,285.34,10.91;6,107.59,249.56,235.07,10.91">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Lalmas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Moffat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Ribeiro-Neto</surname></persName>
		</editor>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Santiago, Chile</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">August 9-13, 2015. 2015</date>
			<biblScope unit="page" from="1031" to="1032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,107.59,290.20,398.40,10.91;6,107.59,303.75,399.10,10.91;6,107.59,317.30,257.12,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,177.45,290.20,288.72,10.91">Text Analysis Pipelines -Towards Ad-hoc Large-Scale Text Mining</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-25741-9</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-25741-9.doi:10.1007/978-3-319-25741-9" />
	</analytic>
	<monogr>
		<title level="s" coord="6,144.18,304.77,152.22,9.72">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2015">9383. 2015</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,107.59,330.85,399.60,10.91;6,107.59,344.40,399.11,10.91;6,107.34,357.95,217.99,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,242.46,330.85,259.61,10.91">The probabilistic relevance framework: BM25 and beyond</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<idno type="DOI">10.1561/1500000019</idno>
		<ptr target="http://dx.doi.org/10.1561/1500000019.doi:10.1561/1500000019" />
	</analytic>
	<monogr>
		<title level="j" coord="6,107.59,344.40,217.32,10.91">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,107.59,371.50,398.40,10.91;6,107.26,385.05,399.01,10.91;6,107.59,398.60,399.68,10.91;6,107.24,412.15,162.64,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,184.95,371.50,156.74,10.91">Geometric perspectives of the BM25</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">M D</forename><surname>Nunzio</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1404/paper_4.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="6,137.21,385.05,275.88,10.91">Proceedings of the 6th Italian Information Retrieval Workshop</title>
		<title level="s" coord="6,234.38,398.60,153.61,10.91">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Boldi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Perego</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</editor>
		<meeting>the 6th Italian Information Retrieval Workshop<address><addrLine>Cagliari, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">May 25-26, 2015. 2015</date>
			<biblScope unit="volume">1404</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,107.59,425.70,399.68,10.91;6,107.59,439.25,398.78,10.91;6,107.59,452.79,398.40,10.91;6,107.59,466.34,398.39,10.91;6,107.59,479.89,402.55,10.91;6,107.29,495.88,152.76,7.90" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,188.61,425.70,297.54,10.91">Interactive text categorisation: The geometry of likelihood spaces</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">M D</forename><surname>Nunzio</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46135-9_2</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-46135-9_2.doi:10.1007/978-3-319-46135-9" />
	</analytic>
	<monogr>
		<title level="m" coord="6,279.20,439.25,227.16,10.91;6,107.59,452.79,398.40,10.91;6,107.59,466.34,59.45,10.91">Information Filtering and Retrieval -DART@AI*IA 2014: Revised and Invited Papers, 8th International Workshop on Information Filtering and Retrieval</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Lai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Giuliani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Semeraro</surname></persName>
		</editor>
		<meeting><address><addrLine>Pisa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-12-10">December 10, 2014. 2014</date>
			<biblScope unit="volume">668</biblScope>
			<biblScope unit="page" from="13" to="34" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
