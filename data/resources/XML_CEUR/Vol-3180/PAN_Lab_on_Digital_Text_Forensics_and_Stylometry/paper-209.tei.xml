<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,90.00,72.43,304.52,15.63;1,90.00,88.13,147.73,10.70">Application of BERT in author verification task Notebook for PAN at CLEF 2022</title>
				<funder ref="#_nBhc7RJ">
					<orgName type="full">Social Science Foundation of Guangdong Province</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,90.00,113.43,53.82,11.62"><forename type="first">Ziwang</forename><surname>Lei</surname></persName>
							<email>leiziwang@163.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,151.56,113.43,57.54,11.62"><forename type="first">Haoliang</forename><surname>Qi</surname></persName>
							<email>qihaoliang@fosu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,258.24,113.43,60.60,11.62"><forename type="first">Zeyang</forename><surname>Peng</surname></persName>
							<email>pengzeyang008@163.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,327.24,113.43,72.96,11.62"><forename type="first">Mingjie</forename><surname>Huang</surname></persName>
							<email>mingjiehuang007@163.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,90.00,72.43,304.52,15.63;1,90.00,88.13,147.73,10.70">Application of BERT in author verification task Notebook for PAN at CLEF 2022</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EA3471751361471651F2BE6DA038D8AD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Authorship Verification</term>
					<term>Pre-trained language model</term>
					<term>Classification task</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Authorship verification is the task of deciding whether two texts have been written by the same author based on comparing the texts' writing styles. Authorship verification task for the competition PAN@CLEF 2022 is that given two texts belonging to different Discourse Types (DT), determine if they are written by the same author (cross-DT authorship verification). We propose a long text encoding method based on BERT, a pre-trained language model, to solve this task. We cut text1 in a text pair into five segments. And text2 is reserved when it is less than 510 characters, only the first 510 characters are reserved when text2 is longer than 510 characters. Then each segment of text1 is combined with text2 to form a new text pair and input them into BERT for encoding. Finally, a classifier is used to get the classification label. The final score of our model in the test dataset is AUC=0.539,</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.3" lry="841.9"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.3" lry="841.9"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.3" lry="841.9"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.3" lry="841.9"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.3" lry="841.9"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Authorship verification technology has been applied in various fields. How to improve the accuracy of authorship verification has attracted more and more attention. The task of the PAN 2022 Authorship Verification <ref type="bibr" coords="1,245.53,462.53,12.93,10.70" target="#b0">[1]</ref> <ref type="bibr" coords="1,258.46,462.53,12.93,10.70" target="#b1">[2]</ref> focuses on more challenging scenarios where each author verification case considers two texts that belong to different DTs (cross-DT authorship verification). the author sets of training and test dataset do not overlap, so it is difficulty to solve the problem for this task if we only model the author's writing style. We think that the pre-trained language model BERT <ref type="bibr" coords="1,243.34,514.49,17.26,10.70" target="#b2">[3]</ref> is an effective method to encode text features. Our motivation is to use Self-attention based BERT to capture more text feature information than traditional neural networks. Because BERT input can only be up to 512 tokens, we propose a strategy of text segmentation and interaction to input text data into BERT for encoding. Then we use the text feature information to judge whether the text pair comes from the same author. Authorship verification task is a binary classification problem <ref type="bibr" coords="1,358.73,579.53,14.27,10.70" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Datasets</head><p>The PAN 2022 provides cross-DT authorship verification cases using four DTs, they are essays, emails, text messages and business memos. The datasets has 12,264 pairs of texts. The train and test dataset consist of pairs of texts belonging to two different DTs. This means that all authors in the test dataset have not appeared in the training dataset. We counted the characters of text1 and text2, the statistical results are shown in the table 1. The length relationship of all sentence pairs is text1 greater than text2 in dataset. Since the text length of texts of emails and text messages can be very small, each text belonging to these DTs is actually a concatenation of different messages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Model framework</head><p>Since BERT can only accept 512 tokens as input at most, we propose a method of text slicing to solve the problem that the number of input text characters is out of range. Suppose text1 is the first of the text pair, text2 is the second of the text pair. We found that the length of text1 in all text pairs is longer than that of text2. According to the text length characteristics of text1 and text2, we use punctuation as a separator to divide text1 into 5 segments to make sure each segment consists of several complete sentences. And text2 is reserved when it is less than 510 characters, only the first 510 characters are reserved when text2 is longer than 510 characters.</p><p>Figure <ref type="figure" coords="2,121.44,457.49,5.53,10.70">1</ref> shows the framework of our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1: Model framework diagram of our method</head><p>After splitting, suppose text1 = {t11, t12, t13, t14, t15}, text2 = {t2}. We spliced the tokens of the five tokenized fragments with t2 respectively, and we use the special separator &lt;SEP&gt; as their boundary. Then we input the restructured text pair into Bert for encoding. These five fragment pairs have the same classification tags. All N text pairs are processed in the above way, where N is 12,264. In this way, we can get the representation of the text. We put the representation of the text into a global average pooling layer to reduce the dimension. The output of pooling layer will be put into the fully connected neural network, and using softmax as the activation function to get a binary label. From this classifier, we can get the answer whether the two paragraphs of text are the same author. Inspired by the method of Peng <ref type="bibr" coords="3,486.48,179.09,14.13,10.70" target="#b4">[5]</ref>. The difference from his method is that we use different data segmentation strategies, and different ways of recombining the data after segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data preprocessing</head><p>For the emails and text messages DTs, text is composed of multiple original messages through &lt;new&gt;tag, and new lines within a text are denoted with the &lt;nl&gt;tag. We think these tags have no contribution to extracting text feature information. Therefore, we removed these tags from all text. And we deleted all Emoji expressions contained in the text.</p><p>After the above preprocessing, we get the clean text. The average number of characters for text1 is 4,043, the average number of characters for text2 is 960, the average characters of text1 and text2 are 310 and 23 less than the original respectively. The pretrained language model we use is BERTBASE(L=12, H=768, A=12, Total Parameters=110M). and we use Keras to construct BERT and fully connected network classification model. We split text1 into five segments, no more than 510 characters per segment, and text2 is reserved when it is less than 510 characters, only the first 510 characters are reserved when text2 is longer than 510 characters. We use these fragments to restructure text pairs. We obtain the feature vector and reshape it to (12264, 5, 768). Then we reshape it to (12264, 768) by a global average pooling. The final fully connected network is trained for 100 epochs. We set batch_size = 16 and the optimization method is Adam with a 2e-5 learning rate. We use sparse categorical cross-entropy as the loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>We input the segmented training data and test data into our model for training and testing, then we use the official evaluation program to evaluate the results, The evaluation score is shown in table <ref type="table" coords="3,156.84,675.65,4.14,10.70" target="#tab_1">2</ref>. Table <ref type="table" coords="4,133.32,75.05,5.53,10.70" target="#tab_2">3</ref> shows the final evaluation results on the dataset of the PAN 2022 authorship verification task evaluated on the TIRA platform <ref type="bibr" coords="4,306.96,88.13,11.70,10.70" target="#b5">[6]</ref>. Our team name is lei22. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper, We propose a method based on pre-trained language model to solve the task of the PAN 2022. We use BERT to encode text information, since BERT can only receive no more than 512 characters, We split text1 and text2,reorganize fragment pairs, and then input them into BERT. This solves the problem that BERT cannot encode long text. Finally, the text feature information is put into a fully connected neural network, Make a binary classifier to identify whether two paragraphs of text are the same author.</p><p>However, our final experimental results are not good. One possibility is that the sentence pair loses too much information when entering BERT after splitting into fragments. Another possibility is that using BERT to encode text information is not suitable for authorship verification on open-sets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,104.16,415.73,401.10,10.70;3,90.00,428.69,415.32,10.70;3,90.00,441.65,415.32,10.70;3,90.00,454.73,415.32,10.70;3,90.00,467.69,79.44,10.70"><head></head><label></label><figDesc>There are 12,264 text pairs in the training dataset. In order to test the effect of our model on open-set, we divide the training dataset into two parts: 11,000 pairs of training data and 1,264 pairs of test data. The authors of the text pairs of the segmented test data do not overlap with the training data. Before the final submission, we use the segmented dataset to train and test on our model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="2,90.00,486.60,415.20,241.20"><head></head><label></label><figDesc></figDesc><graphic coords="2,90.00,486.60,415.20,241.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,90.00,193.86,395.88,81.91"><head>Table 1</head><label>1</label><figDesc>Statistics on the number of characters of sentence pairs in the dataset</figDesc><table coords="2,123.48,227.13,362.40,48.63"><row><cell>Datasets</cell><cell>max character</cell><cell>min character</cell><cell>mean character</cell></row><row><cell>text1</cell><cell>22,160</cell><cell>230</cell><cell>4,353</cell></row><row><cell>text2</cell><cell>6,159</cell><cell>230</cell><cell>983</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,90.00,690.28,400.33,64.06"><head>Table 2</head><label>2</label><figDesc>Test results on dataset after segmentation, where D is the dataset after segmentation.</figDesc><table coords="3,101.40,723.64,388.93,30.70"><row><cell>Datasets</cell><cell>AUC</cell><cell>c@1</cell><cell>f_05_u</cell><cell>F1</cell><cell>Brier</cell><cell>Overall</cell></row><row><cell>D</cell><cell>0.637</cell><cell>0.693</cell><cell>0.530</cell><cell>0.506</cell><cell>0.693</cell><cell>0.612</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,90.00,115.60,400.33,64.18"><head>Table 3</head><label>3</label><figDesc>Test results on dataset after segmentation, where D is the dataset after segmentation.</figDesc><table coords="4,109.08,149.08,381.25,30.70"><row><cell>team</cell><cell>AUC</cell><cell>c@1</cell><cell>f_05_u</cell><cell>F1</cell><cell>Brier</cell><cell>Overall</cell></row><row><cell>lei22</cell><cell>0.539</cell><cell>0.539</cell><cell>0.488</cell><cell>0.399</cell><cell>0.539</cell><cell>0.501</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6.">Acknowledgments</head><p>This work is supported by the <rs type="funder">Social Science Foundation of Guangdong Province</rs> (No. <rs type="grantNumber">GD20CTS02</rs>).</p></div>
<div><head n="7.">References</head></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_nBhc7RJ">
					<idno type="grant-number">GD20CTS02</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,126.24,487.73,381.72,10.70;4,126.24,500.81,379.08,10.70;4,126.24,513.77,379.08,10.70;4,126.24,526.73,379.08,10.70;4,126.24,539.81,379.08,10.70;4,126.24,552.77,379.17,10.70;4,126.24,565.73,379.08,10.70;4,126.24,578.81,24.84,10.70" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,318.36,513.77,186.96,10.70;4,126.24,526.73,374.52,10.70">Overview of PAN 2022: Authorship Verification, Profiling Irony and Stereotype Spreaders, and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ortega-Bueno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pezik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,418.08,552.77,87.33,10.70;4,126.24,565.73,304.46,10.70">Proceedings of the Thirteenth International Conference of the CLEF Association (CLEF</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Cedeno</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">D S</forename><surname>Martino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Esposti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Pasi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Thirteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,126.24,591.77,379.08,10.70;4,126.24,604.73,379.08,10.70;4,126.24,617.81,378.96,10.70;4,126.24,630.77,99.08,10.70" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,216.48,604.73,258.54,10.70">Overview of the Authorship Verification Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pezik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="4,126.24,617.81,373.62,10.70">Working Notes of CLEF 2022 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,126.24,643.73,379.02,10.70;4,126.24,656.81,379.04,10.70;4,126.24,669.77,379.02,10.70;4,126.24,682.73,232.44,10.70" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,348.84,643.73,156.42,10.70;4,126.24,656.81,180.59,10.70">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,330.41,656.81,174.87,10.70;4,126.24,669.77,379.02,10.70;4,126.24,682.73,138.51,10.70">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,126.24,695.81,379.14,10.70;4,126.24,708.77,379.02,10.70;4,126.24,721.73,379.06,10.70;4,126.24,734.81,109.65,10.70" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,221.76,695.81,264.12,10.70">Authorship verification as a one-class classification problem</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,218.88,708.77,286.38,10.70;4,126.24,721.73,108.18,10.70">Machine Learning, Proceedings of the Twenty-first International Conference(ICML 2004)</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Brodley</surname></persName>
		</editor>
		<meeting><address><addrLine>Banff, Alberta, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM International Conference</publisher>
			<date type="published" when="2004">July 4-8, 2004</date>
			<biblScope unit="volume">69</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,126.24,75.05,379.08,10.70;5,126.24,88.13,379.08,10.70;5,126.24,101.09,379.08,10.70;5,126.24,114.05,97.08,10.70" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,364.08,75.05,141.24,10.70;5,126.24,88.13,200.60,10.70">Encoding text information by pre-trained model for authorship verification</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="5,249.96,101.09,160.75,10.70">CLEF 2021 Labs and Workshops</title>
		<title level="s" coord="5,422.88,101.09,82.44,10.70;5,126.24,114.05,23.16,10.70">Notebook Papers, CEUR</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,126.24,127.13,379.08,10.70;5,126.24,140.09,379.05,10.70;5,126.24,153.05,379.02,10.70;5,126.24,166.13,90.24,10.70" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,379.56,127.13,125.76,10.70;5,126.24,140.09,53.39,10.70">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,205.44,140.09,299.85,10.70;5,126.24,153.05,129.69,10.70">Information Retrieval Evaluation in a Changing World, ser. The Information Retrieval Series</title>
		<meeting><address><addrLine>N. Ferro, C. Peters; Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09">Sep. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
