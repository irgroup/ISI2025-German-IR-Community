<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.02,75.44,382.27,17.04;1,72.02,96.20,69.00,17.04;1,72.02,116.20,148.90,9.94">Authorship verification Based On Fully Interacted Text Segments Notebook for PAN at CLEF 2022</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,72.02,141.82,70.22,10.80"><forename type="first">Mingjie</forename><surname>Huang</surname></persName>
							<email>mingjiehuang007@163.com</email>
						</author>
						<author>
							<persName coords="1,151.18,141.82,57.72,10.80"><forename type="first">Leilei</forename><surname>Kong</surname></persName>
							<email>kongleilei@fosu.edu.cn</email>
						</author>
						<author>
							<persName coords="1,219.16,141.82,60.58,10.80"><forename type="first">Zeyang</forename><surname>Peng</surname></persName>
							<email>pengzeyang008@163.com</email>
						</author>
						<author>
							<persName coords="1,288.24,141.82,41.75,10.80"><forename type="first">Yihui</forename><surname>Ye</surname></persName>
						</author>
						<author>
							<persName coords="1,338.74,141.82,54.10,10.80"><forename type="first">Zengyao</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName coords="1,400.51,141.82,60.08,10.80"><forename type="first">Xinyin</forename><surname>Jiang</surname></persName>
						</author>
						<author>
							<persName coords="1,468.41,141.82,54.60,10.80;1,72.02,155.62,19.92,10.80"><forename type="first">Zhongyuan</forename><surname>Han</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">CLEF</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.02,75.44,382.27,17.04;1,72.02,96.20,69.00,17.04;1,72.02,116.20,148.90,9.94">Authorship verification Based On Fully Interacted Text Segments Notebook for PAN at CLEF 2022</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E8E17806485DB79E7B3369A4ECBCC567</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Authorship verification</term>
					<term>Pre-trained model</term>
					<term>Long text</term>
					<term>Open set</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Authorship verification is the task of deciding whether two texts have been written by the same author based on comparing the texts' writing styles. We propose a method to extract the interactive relationship between text pairs with texts separated into segments and combined in a specific order. The features of text pairs are extracted with a pre-trained model. The experiment in this paper is based on the open set, where part of authors doesn't appear in training dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The authorship verification task in this paper is one of the sharing tasks at PAN 2022 <ref type="bibr" coords="1,486.34,385.99,11.70,9.94" target="#b0">[1]</ref>. The purpose of the authorship verification task is to determine whether two texts share the same author <ref type="bibr" coords="1,507.46,398.59,11.70,9.94" target="#b2">[3]</ref>. The authorship verification task this year is defined as cross-DT task which means two texts within each text pair belong to different discourse types (DT) <ref type="bibr" coords="1,322.99,423.93,11.70,9.94" target="#b1">[2]</ref>. The authorship verification task at PAN 2022 is based on an open set. Specifically, the author sets in training and test datas sets are not overlapping. This means that the author's writing styles learned in the training set may not be sufficient for prediction in the test set. Therefore, we are more inclined to analyze the texts' writing styles rather than specific authors' writing styles.</p><p>In recent years, neural networks have had many practices for judging text author attribution <ref type="bibr" coords="1,507.58,487.17,11.70,9.94" target="#b3">[4]</ref>. Since pre-trained model BERT <ref type="bibr" coords="1,212.81,499.77,12.91,9.94" target="#b4">[5]</ref> have excellent performance in text classification, we use BERT to extract stylistic similarity between texts. In this work, we divided the text into segments and let the text segments fully interact. We take this approach for two reasons. Firstly, we try to use this method to allow the model to learn the features between texts without discarding any segment fully. Secondly, this task is based on cross-DT text pairs, where some texts of message or email type are originally spliced from concise segments. So we try to extract the features behind short texts with this fully interactive method and use these features to infer the authorship of the two spliced texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Datasets</head><p>The authorship verification task at PAN 2022 is based on an open set of texts written by 100 different authors, and some authors do not appear in the training set. In general, there are four DTs: essays, emails, text messages, and business memos. In order to protect the author's privacy, author-specific and topic-specific information in the text has been replaced with special tags. In addition, emojis or expressions consisting of punctuation marks are also preserved in email, message, and memo types.</p><p>There are 12,264 pieces of data in the training dataset containing ids, authors, text pairs, DTs, and labels. The lengths of the texts taken from essays are mostly more extended than that of the other three DTs. Specifically, the lengths of the text of essay type are mostly more than 1,000 characters, and the lengths of other three types are the opposite. Apart from essay type, texts of the other three DTs are composed of multiple short-length texts, separated by &lt;new&gt; tag. This means that the semantics of essay types of texts will be more coherent, while the semantics of the other three types of texts are more scattered.</p><p>The types and quantities of special symbols and emoticons in all texts of training datasets are listed in the table below. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method 3.1. Text Preprocessing</head><p>The emojis in the text can be used as a style feature of the text, but not all emojis can be encoded using the pre-trained model BERT as those special symbols. As cleaning of the data, these symbols and emojis are removed from the texts.</p><p>Texts vary in length for different discourse types. Specifically, the texts of the essay type are much longer than other three types. Therefore, the task can be divided into two parts, one part is the discrimination between long text and short text, and the other part is the discrimination between two short texts. We divide the texts into short segments and this approach has two benefits. First of all, after the texts divided into shorter segments with less than 510 characters, these two parts of tasks can be handled in the same way, i.e., author identification between text segments. Secondly, There is a fuller and more efficient interaction between text pairs, specifically, taking 90% part of training datasets as an example. The original datasets consisting of 11,000 text pairs have been expanded to 301,764 shorter text pairs. At the same time, the ratio of positive and negative samples is kept at about 1:1. For each text pair, denoted as text1 and text2, suppose text1 = { ğ‘¡ 11 , ğ‘¡ 12 , â€¦ , ğ‘¡ 1ğ‘š } and text2 = {ğ‘¡ 21 , ğ‘¡ 22 , â€¦ , ğ‘¡ 2ğ‘› }, where ğ‘¡ 11 is the first segment of text1 and ğ‘š is the maximum amount of segments that text1 can be devided into. Then ğ‘š segments of text1 and ğ‘› segments of text2 are combined in pairs to form ğ‘š * ğ‘› new data sets. In this way, all segments of text1 can fully interact with those of text2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Neural Network Architecture</head><p>Limit maximum length to 510 characters, and all texts are splited into segments. Assuming that text1 is divided into ğ‘š segments and text2 is divided into ğ‘› segments, then ğ‘š * ğ‘› new text pairs formed by pairwise combination will be fed into a pre-trained model BERT, where each text pair would be encoded and computed. During this process, each segment of text1 has an interaction with all segments of text2. Encoded with BERT, original text pairs turn into ğ‘š * ğ‘› features in the form of ğ‘“ğ‘’ğ‘ğ‘¡ğ‘¢ğ‘Ÿğ‘’ğ‘  = {ğ‘“ ğ‘¡ 11 ğ‘¡ 21 , â€¦ , ğ‘“ ğ‘¡ 1ğ‘– ğ‘¡ 2ğ‘— , â€¦ , ğ‘“ ğ‘¡ 1ğ‘š ğ‘¡ 2ğ‘› }, where ğ‘“ ğ‘¡ 1ğ‘– ğ‘¡ 2ğ‘— represents the feature of pair ğ‘¡ 1ğ‘– ğ‘¡ 2ğ‘— . Then we will do average pooling over all features and get the represent of original text pairs. In this process, a feature array in shape of (1, mn, 768) will be averaged and compressed to a new array in shape of (1, 768). Finally, the represent will be fed into a fully connected neural network to determine whether this two original texts share the same author. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data Partition</head><p>In order to simulate the test environment of the open set, we randomly selected six authors from the data set and took their corresponding texts as the test set. After that, we randomly select 70% of the remaining dataset as the training set and 30% of the remaining dataset as the validation set. The training dataset and valid dataset contain text pairs written by 50 authors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experiment setup</head><p>In this paper, we choose BERT-base cased as an encoder with 12-layer, 768-hidden, 12-heads, and 110M parameters. The vocab size is 28,996. After division, 7381 text pairs are extended to 50805 pairs. The training batch size is set to 16, and the maximum length of the encoder is set to 256. We use Adam optimizer, learning rate set to 2e-5, and dropout layer, the rate set to 0.5, to avoid overfitting during fine tuning. One epoch is enough to fit the model to fine tune on the training dataset.</p><p>Vectors of the last layer of BERT except for cls and last terminator are extracted and average pooled into a new vector of 768 dimensions. In other words, the CLS embedding (of BERT's output) is not used to represent the text segment pair of the input. Instead, all token embeddings except CLS and SEP are average pooled. As we use BERT an encoder, we believe the described method could obtain more comprehensive sentences features than taking CLS embedding <ref type="bibr" coords="4,348.55,125.32,11.70,9.94" target="#b5">[6]</ref>. All these 50805 new vectors will be average pooled and reshaped into a numpy array with a shape of (7381, 1, 768). Then this array will be fed to two fully connected layers. There are 16 units in the first dense layer with activation of ReLU and two units in the second dense layer with activation of softmax. Sparse categorical cross-entropy is used as the loss function for our model <ref type="bibr" coords="4,245.69,175.84,11.70,9.94" target="#b6">[7]</ref>. We set 500 epochs to fit the MLP to the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results</head><p>We test the performance of our model on 1,719 text pairs split from the training dataset and also test our model on the PAN22 authorship verification test dataset. There are 10,478 text pairs in this test dataset, including texts that are written by 44 authors who do not appear in training dataset.</p><p>The models are tested on TIRA <ref type="bibr" coords="4,235.25,271.63,12.91,9.94" target="#b7">[8]</ref> and evaluated on five measures: area under the ROC curve (AUC), F1-score, c@1 (a variant of the F1-score, which rewards systems that leave complex problems unanswered <ref type="bibr" coords="4,127.70,296.83,11.51,9.94" target="#b8">[9]</ref>), F_0.5u (a measure that puts more emphasis on deciding same-author cases correctly <ref type="bibr" coords="4,72.02,309.55,16.55,9.94" target="#b9">[10]</ref>), and the complement of the Brier score <ref type="bibr" coords="4,270.89,309.55,35.11,9.94">[11][12]</ref>. The results are shown in the table below. From the data above, we can observe that the more text pairs in the test dataset and the more unknown authors, the worse our model performance will be. This may indicate that models trained on closed sets may not be powerful enough to capture textual features on open sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we present our approach for authorship verification at PAN 2022. We split the text into shorter segments and let these segments interact in pairs. In this way, we hope to be able to augment the data and make the text pairs sufficiently interactive. Then the features between text pairs will be extracted with the pre-trained language model BERT. Finally, we will integrate these features to determine whether two texts belong to the same author. As seen from the results, this method does not perform well on an open dataset containing unknown authors.</p><p>In the follow-up work, we should use a more effective method to extract the author's style characteristics in the text, and it is not enough to make the text interact between fragments simply by the way of manual combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgment</head><p>This research was supported by the Natural Science Foundation of Guangdong Province, China (No. 2022A1515011544).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,72.02,372.89,171.32,11.04;3,72.00,189.17,451.00,181.30"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Neural Network Architecture</figDesc><graphic coords="3,72.00,189.17,451.00,181.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,72.02,225.98,436.49,69.15"><head>Table 1</head><label>1</label><figDesc>Types and quantities of special symbols and emojis</figDesc><table coords="2,82.10,255.05,426.41,40.08"><row><cell>symbol type</cell><cell>examples</cell><cell>types</cell><cell>quantities</cell></row><row><cell>author-specific and topic-specific</cell><cell>&lt;email_address&gt;</cell><cell>372</cell><cell>3,153,444</cell></row><row><cell>emojis</cell><cell></cell><cell>132</cell><cell>68,962</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,72.02,526.99,451.03,81.99"><head>Table 2</head><label>2</label><figDesc>Quantities of 11,000 text pairs before and after division, the ratio (number of true samples/number of false samples), and the total count of all samples</figDesc><table coords="2,99.14,569.47,399.37,39.51"><row><cell></cell><cell>false (label = 0)</cell><cell>true (label = 1)</cell><cell>rate</cell><cell>total</cell></row><row><cell>before</cell><cell>5528</cell><cell>5472</cell><cell>1 : 1.01</cell><cell>11,000</cell></row><row><cell>after</cell><cell>147482</cell><cell>154282</cell><cell>1 : 0.96</cell><cell>301,764</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,72.02,524.35,451.08,120.87"><head>Table 3</head><label>3</label><figDesc>The partition of the training dataset into a new training dataset, valid datasets, and text dataset. The fourth line is the true test dataset of PAN 22.</figDesc><table coords="3,83.54,566.95,425.56,78.26"><row><cell>dataset</cell><cell>proportion</cell><cell>number of authors</cell><cell>number of text pairs</cell></row><row><cell>training dataset</cell><cell>60%</cell><cell>---</cell><cell>7,381</cell></row><row><cell>valid dataset</cell><cell>26%</cell><cell>---</cell><cell>3,164</cell></row><row><cell>test dataset</cell><cell>14%</cell><cell>6</cell><cell>1,719</cell></row><row><cell>PAN22 authorship verification test dataset</cell><cell>---</cell><cell>44</cell><cell>10,478</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,72.02,334.37,451.10,93.13"><head>Table 4</head><label>4</label><figDesc>Line 1 is the results of 1,719 text pairs split from the training dataset. Line 2 is the results of 10,478 text pairs of the PAN22 authorship verification test dataset.</figDesc><table coords="4,84.86,376.13,425.03,51.38"><row><cell>dataset</cell><cell>auc</cell><cell>c@1</cell><cell>f_05_u</cell><cell>F1</cell><cell>brier</cell><cell>overall</cell></row><row><cell>1719 text pairs</cell><cell>0.56</cell><cell>0.694</cell><cell>0.408</cell><cell>0.253</cell><cell>0.694</cell><cell>0.522</cell></row><row><cell>PAN22 authorship verification test dataset</cell><cell>0.519</cell><cell>0.519</cell><cell>0.328</cell><cell>0.196</cell><cell>0.519</cell><cell>0.416</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,105.86,105.76,417.32,9.94;5,108.02,118.36,415.16,9.94;5,108.02,131.08,414.97,9.94;5,108.02,143.68,415.12,9.94;5,108.02,156.40,414.81,9.94;5,108.02,169.00,414.97,9.94;5,108.02,181.72,187.49,9.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,288.89,131.08,234.10,9.94;5,108.02,143.68,305.47,9.94">Overview of PAN 2022: Authorship Verification, Profiling Irony and Stereotype Spreaders, and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ortega-Bueno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pezik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,222.53,169.00,300.46,9.94;5,108.02,181.72,85.29,9.94">Proceedings of the Thirteenth International Conference of the CLEF Association (CLEF</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Cedeno</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">D S</forename><surname>Martino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Esposti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Pasi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Thirteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.86,194.32,417.32,9.94;5,108.02,206.92,415.10,9.94;5,108.02,219.64,339.82,9.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,136.82,206.92,243.79,9.94">Overview of the Authorship Verification Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pezik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="5,412.18,206.92,110.94,9.94;5,108.02,219.64,232.63,9.94">Working Notes of CLEF 2022 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.86,232.24,417.05,9.94;5,108.02,244.99,352.16,9.94" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,202.92,232.24,268.62,9.94">Determining if two documents are written by the same author</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Winter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,478.69,232.24,44.22,9.94;5,108.02,244.99,247.58,9.94">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="178" to="187" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.86,257.59,417.02,9.94;5,108.02,270.19,414.69,9.94;5,108.02,282.91,414.96,9.94;5,108.02,295.51,51.68,9.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,374.95,257.59,147.94,9.94;5,108.02,270.19,71.33,9.94">Authorship Attribution for Neural Text Generation</title>
		<author>
			<persName coords=""><forename type="first">Adaku</forename><surname>Uchendu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thai</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dongwon</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,201.53,270.19,321.19,9.94;5,108.02,282.91,141.59,9.94">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8384" to="8395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.86,308.23,417.05,9.94;5,108.02,320.83,414.90,9.94;5,108.02,333.43,414.88,9.94;5,108.02,346.15,47.76,9.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,301.08,308.23,221.83,9.94;5,108.02,320.83,104.04,9.94">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,221.46,320.83,301.46,9.94;5,108.02,333.43,369.13,9.94">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.86,358.64,416.99,10.04;5,108.02,371.36,414.84,10.04;5,108.02,384.07,187.02,9.94" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,409.63,358.64,113.22,10.04;5,108.02,371.36,347.27,10.04">Evaluation of BERT and ALBERT Sentence Embedding Performance on Downstream NLP Tasks</title>
		<author>
			<persName coords=""><forename type="first">Youngjune</forename><surname>Gwon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hyunjin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Judong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Seongho</forename><surname>Joe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,466.76,371.36,56.09,10.04;5,108.02,384.07,155.04,9.94">International Conference on Pattern Recognition</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.86,396.67,417.24,9.94;5,108.02,409.41,410.60,9.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,403.27,396.67,119.83,9.94;5,108.02,409.41,220.62,9.94">Encoding Text Information By Pre-trained Model For Authorship Verification</title>
		<author>
			<persName coords=""><forename type="first">Zeyang</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Leilei</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhijie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhongyuan</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,335.70,409.41,99.55,9.94">CLEF (Working Notes</title>
		<imprint>
			<biblScope unit="page" from="2103" to="2107" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.86,422.01,417.15,9.94;5,108.02,434.73,414.84,9.94;5,108.02,447.33,311.89,9.94" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,328.32,422.01,175.06,9.94">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,108.02,434.73,410.62,9.94">Information Retrieval Evaluation in a Changing World, ser. The Information Retrieval Series</title>
		<meeting><address><addrLine>N. Ferro, C. Peters; Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09">Sep. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.86,459.93,417.32,9.94;5,108.02,472.65,252.41,9.94" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,224.35,459.93,178.96,9.94">A simple measure to assess non-response</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>PeÃ±as</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ãlvaro</forename><surname>Rodrigo</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P11-1142" />
	</analytic>
	<monogr>
		<title level="m" coord="5,424.72,459.93,18.56,9.94">ACL</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1415" to="1424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,111.38,485.25,411.33,9.94;5,108.02,497.97,414.70,9.94;5,108.02,510.57,415.11,9.94;5,108.02,523.29,415.16,9.94;5,108.02,535.89,381.56,9.94" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,329.96,485.25,173.73,9.94">Generalizing unmasking for short texts</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1068</idno>
		<ptr target="https://www.aclweb.org/anthology/N19-1068.doi:10.18653/v1/N19-1068" />
	</analytic>
	<monogr>
		<title level="m" coord="5,108.02,497.97,414.70,9.94;5,108.02,510.57,278.31,9.94;5,146.53,523.29,191.55,9.94">Pro-ceedings of t he 2019 Conference of the North American Chapter of the Association for Com-putational Linguistics: Human Language Technologies</title>
		<meeting><address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="654" to="659" />
		</imprint>
	</monogr>
	<note>As-sociation for Computational Linguistics</note>
</biblStruct>

<biblStruct coords="5,111.38,548.49,411.74,9.94;5,108.02,561.21,97.95,9.94" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,173.60,548.49,263.72,9.94">Verification of forecasts expressed in terms of probability</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Brier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,445.76,548.49,77.36,9.94;5,108.02,561.21,30.02,9.94">Monthly weather review</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,111.38,573.81,411.44,9.94;5,108.02,586.56,415.24,9.94;5,108.02,599.16,24.84,9.94" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="5,374.00,573.81,148.82,9.94;5,108.02,586.56,209.05,9.94">Feature vector difference based authorship verification for open-world settings</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Weerasinghe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Greenstadt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,325.08,586.56,134.79,9.94">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2021">2021. 2936</date>
			<biblScope unit="page" from="2201" to="2207" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
