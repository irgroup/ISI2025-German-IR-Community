<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.69,84.74,337.68,15.42;1,89.29,106.66,76.47,15.43;1,89.29,133.64,157.29,14.16">An Unorthodox Approach for Style Change Detection Notebook for PAN at CLEF 2022</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,166.32,64.04,14.16"><forename type="first">Lukas</forename><surname>Graner</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Fraunhofer Institute for Secure Information Technology SIT</orgName>
								<address>
									<addrLine>RheinstraÃŸe 75</addrLine>
									<postCode>64295</postCode>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,164.67,166.32,52.70,14.16"><forename type="first">Paul</forename><surname>Ranly</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Fraunhofer Institute for Secure Information Technology SIT</orgName>
								<address>
									<addrLine>RheinstraÃŸe 75</addrLine>
									<postCode>64295</postCode>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.69,84.74,337.68,15.42;1,89.29,106.66,76.47,15.43;1,89.29,133.64,157.29,14.16">An Unorthodox Approach for Style Change Detection Notebook for PAN at CLEF 2022</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">CCB4C8F6C82B7164DC9635D426024247</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Style Change Detection</term>
					<term>Multi Author Detection</term>
					<term>Half-blind Task</term>
					<term>Crawling</term>
					<term>Recovering Test Labels</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The PAN shared tasks include tasks from a variety of disciplines, including authorship analysis, and are held annually. Participants are able to compete with each other by proposing approaches for a task, which are then compared and evaluated on a test dataset with predefined performance metrics. So far, the test datasets have traditionally been withheld, so that participants may only train and optimize approaches on the training and validation sets. In this year's Style Change Detection task, the objective of which is to locate author changes in multi-author text documents, PAN has also published the test set built from publicly available Q&amp;A platform posts, albeit without ground truth labels. In this paper, we show that the ground truth of the test set can be recovered almost entirely by querying search engines with paragraph excerpts from the test set, crawling the query results and parsing author information of corresponding posts. We point out that this allows others to secretly tailor their approaches to the recovered test labels and thus gain an unfair advantage. Furthermore, as part of an in-depth data analysis, we address a variety of issues and finally suggest improvements for future Style Change Detection tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The PAN Shared Tasks were introduced over a decade ago and span a variety of topics such as authorship analysis, computational ethics and plagiarism detection. One of these tasks is Style Change Detection (SCD) as first introduced in 2017, where the goal is to find changes of writing style inside a given document <ref type="bibr" coords="1,262.42,584.66,11.57,12.92" target="#b0">[1]</ref>. This task may help detecting documents or locate sections inside documents written by different authors and possibly provide evidence in those documents, among other use cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head><p>The shared PAN 2022 SCD task poses three sub-tasks to solve, namely basic, advanced, and real-world representing different scenarios. The specific tasks are as taken from the PAN website 2 :</p><p>1. Style Change Basic (ğ’¯ 1 ): for a text written by two authors that contains a single style change only, find the position of this change (i.e., cut the text into the two authors' texts on the paragraph-level), 2. Style Change Advanced (ğ’¯ 2 ): for a text written by two or more authors, find all positions of writing style change (i.e., assign all paragraphs of the text uniquely to some author out of the number of authors assumed for the multi-author document) 3. Style Change Real-World (ğ’¯ 3 ): for a text written by two or more authors, find all positions of writing style change, where style changes now not only occur between paragraphs, but at the sentence level.</p><p>For each of the sub-tasks a separate dataset is provided (ğ’Ÿ 1 , ğ’Ÿ 2 and ğ’Ÿ 3 , respectively), each being split disjointed into 70% labeled training (ğ’Ÿ train * ), 15% validation (ğ’Ÿ valid</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>*</head><p>) and 15% unlabeled test data (ğ’Ÿ test * ). Their intended uses are for training a model, optional (hyperparameter) tuning and final evaluation of the model, respectively. The datasets contain a large number of SCD problems, where each problem is structured as a list of text paragraphs (statistics are shown in Table <ref type="table" coords="2,116.43,634.13,3.65,12.92" target="#tab_3">2</ref>). For simplicity, we will also refer to sentences in ğ’¯ 3 as paragraphs henceforth. Two consecutive paragraphs may be written by different authors, signifying a style change. For ğ’¯ 1 and ğ’¯ 3 the task is to predict for each pair of consecutive paragraphs, if a style change is present. For ğ’¯ 2 each paragraph has, furthermore, to be assigned uniquely to an author.</p><p>As stated in the task description all problems in the datasets were assembled from questions and answers from the Q&amp;A platform Stack Exchange, which comprises a variety of websites dedicated to diverse topics<ref type="foot" coords="3,207.31,158.31,3.71,9.44" target="#foot_0">3</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>Since all Stack Exchange websites are publicly accessible and indexed by common search engines, a paragraph can be traced back to its originating post. In the following we describe our straightforward approach for finding the source threads in the Stack Exchange network and assigning an author to each paragraph. This approach can be applied to all sub-tasks equally, followed by converting the author names into the output format of the respective sub-task. A corresponding pseudocode is given in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Finding source threads</head><p>Upon manual inspection of the data, we discovered that for the majority of the problems in the datasets, all their respective paragraphs originated from a single Stack Exchange thread. Tracing back each paragraph independently would, therefore, lead to unnecessary search queries yielding redundant results. Instead, we decided to cache the post contents of found threads, so that, while iterating over the paragraphs, we only query a search engine when a paragraph is not already present in the cache (cf. Algorithm 1 Line 5). Furthermore, we discovered that a small portion of the original posts had been edited since the creation of the datasets. An exact phrase search for an entire paragraph, whose originating post has already been edited, would potentially yield no results <ref type="foot" coords="3,352.40,463.13,3.71,9.44" target="#foot_1">4</ref> . To overcome this issue, we only use a substring of the paragraph, specifically the first tokens that add up to 150 (or 100 and further 75 if no results are yielded, cf. Algorithm 1 Line 6) characters.</p><p>Among a number of popular search engines we considered, we chose AOL Search <ref type="foot" coords="3,452.40,510.55,3.71,9.44" target="#foot_2">5</ref> and Yahoo Search<ref type="foot" coords="3,119.55,524.10,3.71,9.44" target="#foot_3">6</ref> , as we empirically found them best suited for our use case in terms of accuracy and throughput. For each search query (cf. Algorithm 1, function querySearchEngine) we randomly sample one engine out of the two and query it with the search string enclosed by quotation marks Â»"Â«, indicating an exact phrase search.</p><p>The first resulting URL that is part of the Stack Exchange network is then requested, its HTML content parsed, and finally the names of the post authors along with the corresponding text Algorithm 1: Python inspired pseudocode to search for paragraphs, fill a cache holding all found posts and finally assigning authors to each paragraph. Hereby, ğ’« denotes the set of problems in a given dataset, querySearchEngine is a function which queries a search engine with the given text and returns the first URL of a Stack Exchange result or None if none was found. The function extractPostsFromStackExchangeURL requests the HTML content, parses it and returns all posts of the given Stack Exchange URL, where a returned post holds information about the content, author name and previous edited versions of the post. outputSolution then finally converts the given list of author names to the according output format of the sub-task and outputs the result. contents extracted, including older versions if edited (cf. Algorithm 1, function extractPosts-FromStackExchangeURL).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Assigning authors</head><p>Having populated the post cache, authors can now be assigned to each paragraph. This would be a trivial task if for each paragraph there exists one and only one source post. However, there are three issues we need to address:</p><p>1. Some paragraphs can not be found by any means. We suspect that the source post has since been deleted, for example due to being flagged as spam or rudeness. An example is the last paragraph in problem 12 of ğ’Ÿ test 2 :</p><p>"this program holds the left button down -Mouse Emulator [. . . ]"</p><p>To one such paragraph we assign the found author of the previous paragraph in the corresponding problem, or next paragraph, if said paragraph is the first one in the problem (cf. Algorithm 1 Line 22-27). 2. A few paragraphs were present more than once in the cache but with varying authors.</p><p>These different authors either copied content from an external source (such as documentation), one author adopted parts of another author's post, or multiple authors authored the same text purely by coincidence. Although our crawling algorithm would skip the search for paragraphs already cached, it may still crawl said posts as a by-product in an unrelated thread. An example is the 13th paragraph in problem 987 in ğ’Ÿ train which can be found both in the Raspberry Pi Stack Exchange as well as Stack Overflow in Spanish 7 . In such a case, it is not possible to unambiguously specify which post is the original one, so we simply assign the author of the lastly found matching post (cf. Algorithm 1 Line 19-21 and 24). 3. Although all paragraphs in the datasets represent disjoint posts, there are still paragraphs present multiple times, even within a single problem. This reflects a more intricate situation similar to the previous issue, as these paragraphs could not be considered a by-product of the crawling. Such cases occur, for instance, when an answer responds to a question while quoting the question. An example is problem 879 in ğ’Ÿ test 3 , whose third and ninth paragraphs:</p><p>"What filesystem layout will give the best performance?" are equal while their authors are different 8 . We also assign these paragraphs to the authors of the lastly found matching post, although without considering a post multiple times (cf. Algorithm 1 Line 19-21 and 24-25).</p><p>Once authors have been assigned to all sections, it is straightforward to output the solutions. For ğ’¯ 1 and ğ’¯ 3 , only binary outputs representing the style changes are required, which can be easily generated by checking for inequality of the author names of each consecutive paragraphs. For ğ’¯ 2 , each author name will be transformed to an identifier number in order of occurrence starting at 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Analysis</head><p>In the following, we present our results on the three tasks presented in Section 2. Further, we will go through an analysis of the provided datasets and some challenges a SCD model might face on them. Final results of our submission on the respective train, validation and test sets of the three sub-tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Results</head><p>Solutions of all tasks ğ’¯ 1 , ğ’¯ and ğ’¯ 3 are evaluated using macro-averaged F1 (Macro-F1) as well as for ğ’¯ 2 additionally with Diarization Error Rate (DER) <ref type="bibr" coords="6,322.14,415.45,12.68,12.92" target="#b3">[4]</ref> and Jaccard Error Rate (JER) <ref type="bibr" coords="6,462.74,415.45,11.28,12.92" target="#b4">[5]</ref>.</p><p>Table <ref type="table" coords="6,117.23,435.77,5.17,12.92" target="#tab_1">1</ref> shows the results of our approach for the test set evaluated by the TIRA research architecture <ref type="bibr" coords="6,147.51,449.32,13.00,12.92" target="#b2">[3]</ref> and for the training and validation sets, which we evaluated based on the provided ground truth labels. As can be observed, the results are consistently near-perfect across all sub-tasks and datasets. The issues stated in Section 3.2, such as presumably deleted source posts, prevent the approach to achieve actual perfect results (i.e., values of 1.0 for Macro-F1 and 0.0 for DER and JER).</p><p>We would like to emphasize that we do not consider our approach as an appropriate submission for the PAN shared tasks, since it effectively resembles an act of cheating. The purpose of this approach and paper is not to compete against other participants, but to show that it is possible (cf. Table <ref type="table" coords="6,173.68,564.49,4.25,12.92" target="#tab_1">1</ref>) for any participant to uncover the true labels of the test sets with little effort. Participants who do so may then (in addition to training a model on the training set) optimize or manually finetune their model on test labels without disclosing this action, gaining an unfair advantage over other participants, who do not. Moreover, this harms the research community by potentially incorrectly suggesting that some approaches are preferable to others. At this point the final evaluation result is then skewed and, thus, of no use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Data</head><p>For each shared task, the type of the provided data affects the results, as different source data can vary in complexity, size and significance among other factors. In this section, we will provide a quantitative and qualitative insight into the datasets of the PAN 2022 SCD task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Quantitative Analysis</head><p>We formulated different categories of potential challenges for SCD approaches (and for style analysis in general), representing phrases and character strings that complicate the author inference or add noise to the data. The categories are URLs, file paths, citations, code (such as HTML, SQL, shell or LaTeX-commands) and non-English text. Furthermore, we inspected individual paragraphs regarding formatting, punctuation quantity as well as the presence of short paragraphs of less than 50 characters and duplicates.  As shown in Table <ref type="table" coords="7,175.05,516.44,3.78,12.92" target="#tab_3">2</ref>, the different datasets contain varying amounts of phrases fitting in one of the categories. The absolute counts for ğ’Ÿ 1 are smaller as this dataset consists of only one fifth of the problems in ğ’Ÿ 2 or ğ’Ÿ 3 . We used a simple pattern search for URLs 9 and citations 10 and found a surprisingly high amount of each present in the problems. While URLs do not contribute to an authors style at all, citations may in fact represent the style of another entity.</p><p>With up to 21% of problems and 2% of all paragraphs affected by at least one of these phrases, 9 Regex pattern to detect URLs: Note, that this is only a naive approach, since not all texts enclosed by quotation marks indicate a citation. Furthermore, we only counted a citation if it covered more than 25% of the paragraph.</p><p>all three SCD tasks become more demanding. Moreover, we observed paragraphs that contain multiple URLs and citations or even solely consist of those.</p><p>The proportion of code listings present in the data was more difficult to determine. Firstly we also inlcuded HTML, SQL, LaTeX and shell commands. Secondly, we focused on formatted listings, i.e. code snippets that were in the Stack Exchange format of four leading whitespaces followed by the actual code. For this work we took neither code in plain text nor code snippets encapsulated by text phrases into account, even though we occasionally found similar examples in the data files.</p><p>In order to detect non-English texts in paragraphs we used the language detection tool langdetect 11 . It should be noted here, that a small portion of nonhuman phrases (e.g. code listings and command line outputs) were also considered non-English, as they were assigned to languages such as Swedish. This results in most of the detected non-English phrases being such nonhuman code with only very few phrases originating other languages. Nevertheless, this proposes another difficulty, as participating models are forced to compare the writing style of texts in different languages, not to mention analyzing nonhuman texts, such as URLs, file paths, logged metadata or error reports. A more in-depth look on those will be given in the qualitative analysis in the next section.</p><p>In general, as all datasets are taken from the same network, we assume that the allocation of problems to datasets is somewhat arbitrary. Still it is worth mentioning that ğ’Ÿ 3 contains more problems with at least one URL, citation, code and non detectable English sentence compared to ğ’Ÿ 1 and ğ’Ÿ 2 , while the problems in ğ’Ÿ 2 and ğ’Ÿ 3 are of similar average size. As the paragraphs in ğ’Ÿ 3 are single sentences, they are much shorter (on average 114 characters per paragraph, in contrast to 199 for ğ’Ÿ 1 and 249 for ğ’Ÿ 2 ), hence problems in ğ’Ÿ 3 contain more paragraphs on average. Table <ref type="table" coords="8,155.21,416.98,4.99,12.92" target="#tab_3">2</ref> shows that the quantity of challenging phrases in paragraphs are similar in all datasets. Considering this and the short length of paragraphs in ğ’Ÿ 3 , ğ’¯ 3 is thus more affected by the phrase induced noise and consequently even more challenging than ğ’¯ 1 and ğ’¯ 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Qualitative Analysis</head><p>In this section we will discuss specifically selected excerpts of SCD problems, which are listed and categorized in Table <ref type="table" coords="8,203.51,513.73,33.34,12.92">3 along</ref>   </p><formula xml:id="formula_0" coords="9,226.03,412.32,260.14,17.91">[Nul][Nul][Nul][Nul][Nul][Nul][Nul][Nul][Nul][Del][Del][Del] [Blank][Blank][Blank][Blank][Blank][Blank][Blank][Blank][. . .</formula><formula xml:id="formula_1" coords="9,226.03,475.08,269.73,18.81">+----------+-----------------------------+------+--------+-[. . . ] | 1576128 | database_name/#sql-4593_1e9 | 1 |</formula><p>118 | [. . . ] Source: https://dba.stackexchange.com/questions/248723</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 3</head><p>Example excerpts from problems on which challenges might arise for SCD approaches. For each problem, indicated as ğ’Ÿ-problem number, the alleged source URL, as well as a categorization for the underlying issue are given.</p><p>problems contained at least one citation<ref type="foot" coords="9,266.96,579.88,7.41,9.44" target="#foot_4">12</ref> .</p><p>Example 5 shows a rare case of non-English text, namely an error report in German. While this is one of few problems where we found text in non-English (even though it is machine generated text and thus not truly authored by the posts author), it becomes increasingly more difficult as the German paragraphs are shuffled within the English answers, creating a bilingual incoherent problem.</p><p>Examples 6 to 12 depict different types of nonhuman texts that could pose challenges for reliable SCD. Represented in Example 6 is source code in plain text. Interestingly, the code listings kept their order while the problems were shuffled and the typical Stack Exchange formatting (multiples of four leading spaces indicating a code listing) remained the same. It could be argued that coding style is another form of writing style and thus should remain in the data. However, as it is written plainly in between paragraphs and even being shuffled along normal texts, a significant gain in information is unlikely. Example 7 shows a whole paragraph consisting of a single URL, which effectively represents pure noise, as it does not contain any style information and can be posted by any author. Among all datasets, we found 1, 469 problems where at least one paragraph exclusively consisted of an URL.</p><p>The text excerpt in Example 8 shows a short paragraph of only 38 characters (50 with leading spaces) containing HTML. In Example 9 multiple LaTeX math commands are present. The task of finding all code listings in the data is less trivial, hence we recognize the difficulty of removing all code from the problem files. Still, with all the examples found as shown in Table <ref type="table" coords="10,499.87,315.36,3.66,12.92" target="#tab_3">2</ref>, some data cleaning would be advisable in order to properly execute SCD. Regarding the short paragraphs, in total we found 235 paragraphs with less than 50 characters excluding leading white spaces. Short paragraphs further increase the difficulty, as they offer less content to detect style on. Moreover, we found that most of the short paragraphs could be omitted from the data as they contained source code, machine outputs or generated logs.</p><p>Lastly, in our analysis we searched for repeated sequences and table-style-formatted content. The repetition of words does not pose a challenge for SCD in general, but some examples as the one shown in Example 10 can be effectively classified as noise. Similarly, the table formatted content shown in Example 11 does not provide any information regarding writing style. Without any notion that the underlying concept of the paragraphs is a table formatted with spaces, it could be misinterpreted as a generic sequence of words without any deeper sense to it. Furthermore, we want to note that each table row is a seperate paragraph and shuffled in the problem. Finally, Example 12 shows an SQL table, where table borders are still present and even shuffled between text paragraphs in the problem. Hence, some paragraphs have no individual style, consisting solely of punctuation. In total we discovered 1, 180 paragraphs that consist of more than 20% punctuation. A human author is unlikely to exceed this threshold, especially considering statistics about average usage of punctuation <ref type="bibr" coords="10,392.85,552.47,11.41,12.92" target="#b5">[6]</ref>. Most of the examples found can be assigned to one of the previously described categories, as e.g. logs and LaTeX formulas contain a comparatively high amount of punctuation characters. However, other results like the one shown in Example 12 indicate that there are also paragraphs present not covered by any other category.</p><p>As shown in the analysis, the datasets proposed for the 2022 PAN SCD shared task show various degrees of noisy data, ranging from minor formatting styles not necessarily attributable to specific authors, over different languages including programming languages up to machine outputs absent of any writing style or even citations that in fact resemble style of other authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Task Definition</head><p>We would like to point out, that in this years shared task (contrary to previous competitions) the definition and problem structure of the SCD sub-tasks ğ’¯ 1 and ğ’¯ 3 (and ğ’¯ 2 only partly, since it further requires assigning author identifiers) essentially resemble an Authorship Verification (AV) Task: The set of viable locations where a style change may occur is given, since the problems are structured as separated paragraphs. Furthermore, we found, that these paragraphs have presumably been randomly shuffled, which makes their (semantic) order meaningless. Thus, paragraphs do not depend on preceding ones in any way different than on subsequent ones, as it would be the case in continuous text. Each pair of consecutive paragraphs is, therefore, independent of each other (apart from the fact that they might originate from the same Stack Exchange thread and that for ğ’¯ 1 , there can only be one style change inside one problem). The objective of the tasks is to detect if a style change between two paragraphs of such a pair occurs (or not), which then is equal to classifying if the two paragraphs were written by different authors (or not), which again is the objective of AV. Further, all outputs of an SCD approach over all dataset problems are flattened to a list and evaluated against the ground truth, which weighs them all equally. Consequently, without making any intrinsic change to the data, the current ğ’¯ 1 and ğ’¯ 3 can be reformulated to AV tasks, not only from a technical standpoint (regarding the approach or algorithm<ref type="foot" coords="11,187.24,321.15,7.41,9.44" target="#foot_5">13</ref> ), but also from a semantic one (regarding the structure and meaning of the used texts). This raises the question of the role of SCD in this year's competition, especially when considering that AV is a dedicated shared task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper we describe a simple method to efficiently recover author labels for publicly available Stack Exchange posts. Based on this and the preliminary availability of the test set, albeit without labels, our submission achieves almost perfect test scores for this year's PAN Style Change Detection task, without performing actual style analysis. Naturally, this is not in the spirit of the competition as such. Nevertheless, this work shows that any participant can recover the test labels and secretly tune their approach based on these, gaining an unfair advantage and skewing research results. Additionally, we present an in-depth analysis of the available data and some issues we see with its compilation, such as individual data instances to be classified that do not contain any stylistic information.</p><p>To address the stated issues for the future, we firstly propose to adapt the submission model used in previous years, i.e., no test data on which submissions will be scored should be published before the submission deadline. This prevents all participants from obtaining advantageous information about the data that can potentially be abused. Second, to establish a genuine SCD task that sufficiently separates itself from the other PAN shared task Authorship Verification, we advice that text units (i.e. paragraphs or sentences in this years SCD task) are not arbitrarily shuffled inside problems and instead preserve the semantic flow of the originating text. Staying with Stack Exchange: Posts that were partly edited by other authors could, for example, provide an appropriate data foundation, as precise character positions of author information are accessible. Additionally, more flexible style change positions would enhance the focus on the style change itself. In the 2017 PAN SCD task, the task was to find borders in a document where a change in style can be noticed. This emphasis on varied style change possibilities could help shaping more realistic scenarios, towards which ğ’¯ 3 is already pointing.</p><p>Addressing issues in the given data, simple preprocessing can improve its quality in respect to a style analysis task. Although textual content of the Stack Exchange network is generally appropriate, one needs to keep in mind that expert communities not only use different writing styles, but also different topic-and domain-related content, such as code listings, documentation or citations. This is particularly critical if text units exclusively consist of such content. A first step to tackle said issues, is to remove content of code cells in Stack Exchange posts and skip any thread comprising clear citations of other authors or websites. For future SCD tasks this will significantly lessen the probability of falsely attributing mixed authorships and the amount of noise that is unrelated to writing style.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,439.80,253.48,4.23,6.99;5,456.21,245.78,2.57,12.92;5,140.56,273.40,346.86,10.45;5,140.56,285.35,346.86,10.45;5,140.56,297.31,32.52,10.45"><head>1 :"</head><label>1</label><figDesc>Raspbian has 100MB of swap by default. You should change it to 2000MB in the configuration file. So you will have to find this line:"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,97.80,638.44,390.22,8.36;7,89.29,646.45,5.56,7.08;7,97.80,647.48,366.23,10.62"><head></head><label></label><figDesc>https?://(www\.)?[-a-zA-Z0-9@:%._+~#=]+\.[a-zA-Z0-9()]{1,6}\b([-a-zA-Z0-9()@:%_+.~#?&amp;/=]*) 10 Regex pattern to detect citations (simplified): (\x22.*?\x22|(?&lt;=^| )\x27.*?\x27(?=[.,;:\s)]))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,100.57,88.47,392.00,305.30"><head></head><label></label><figDesc>if not any(post.content.contains(paragraph) for post in cachedPosts):</figDesc><table coords="4,100.57,88.47,392.00,305.30"><row><cell cols="2">1 # Finding source threads</cell></row><row><cell cols="2">2 cachedPosts = []</cell></row><row><cell>6</cell><cell>for subLength in [150, 100, 75]:</cell></row><row><cell>7</cell><cell>queryResult = querySearchEngine(paragraph[:subLength])</cell></row><row><cell>8</cell><cell>if queryResult is not None:</cell></row><row><cell>9</cell><cell>for post in extractPostsFromStackExchangeURL(queryResult):</cell></row><row><cell>10</cell><cell>for editedPost in post.editedVersions:</cell></row><row><cell>11</cell><cell>cachedPosts.append(editedPost)</cell></row><row><cell>12</cell><cell>cachedPosts.append(post)</cell></row><row><cell>13</cell><cell></cell></row><row><cell cols="2">14 # Assigning authors</cell></row><row><cell cols="2">15 for problem in ğ’« : 16 paragraphAuthors = []</cell></row><row><cell>17</cell><cell>for i, paragraph in enumerate(problem.paragraphs):</cell></row><row><cell>18</cell><cell>matchingPost = None</cell></row><row><cell>19</cell><cell>for post in cachedPosts:</cell></row><row><cell>20</cell><cell>if post.contains(paragraph):</cell></row><row><cell>21</cell><cell>matchingPost = post</cell></row><row><cell>22</cell><cell>if matchingPost is not None:</cell></row><row><cell>23</cell><cell>while len(paragraphAuthors) &lt;= i:</cell></row><row><cell>24</cell><cell>paragraphAuthors.append(matchingPost.author)</cell></row><row><cell>25</cell><cell>cachedPosts.remove(matchingPost)</cell></row><row><cell>26</cell><cell>elif len(paragraphAuthors) &gt; 0:</cell></row><row><cell>27</cell><cell>paragraphAuthors.append(paragraphAuthors[-1])</cell></row><row><cell>28</cell><cell>outputSolution(problem, paragraphAuthors)</cell></row></table><note coords="4,103.35,110.39,77.05,9.40;4,185.27,110.63,6.43,15.56;4,197.32,110.39,4.88,9.40;4,103.35,123.01,2.78,7.08;4,131.62,121.34,175.60,9.40;4,103.35,133.97,2.78,7.08"><p>3 for problem in ğ’« : 4 for paragraph in problem.paragraphs: 5</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,88.99,164.13,287.53,170.40"><head>Table 1</head><label>1</label><figDesc></figDesc><table coords="6,214.27,164.13,162.25,150.17"><row><cell></cell><cell></cell><cell>ğ’¯ 1</cell><cell>ğ’¯ 2</cell><cell>ğ’¯ 3</cell></row><row><cell>ğ’Ÿ train *</cell><cell cols="4">Macro-F1 0.970 0.987 0.984 DER -0.006 -</cell></row><row><cell></cell><cell>JER</cell><cell>-</cell><cell>0.008</cell><cell>-</cell></row><row><cell>ğ’Ÿ valid *</cell><cell cols="4">Macro-F1 0.958 0.990 0.985 DER -0.006 -</cell></row><row><cell></cell><cell>JER</cell><cell>-</cell><cell>0.008</cell><cell>-</cell></row><row><cell>ğ’Ÿ test *</cell><cell cols="4">Macro-F1 0.993 0.986 0.993 DER -0.004 -</cell></row><row><cell></cell><cell>JER</cell><cell>-</cell><cell>0.004</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,88.98,466.81,417.00,32.83"><head>Table 2</head><label>2</label><figDesc>Absolute number of occurrences (and percentage with respect to the total) of different phrases present in entire problems (upper block) and paragraphs (lower block).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,89.29,513.73,416.70,121.31"><head></head><label></label><figDesc>their alleged source URLs. As the datasets provided by the shared task are taken from the publicly available Stack Exchange network, they are subject to their individual authors. This leads to not only different writing styles of the network's members but also different formatting and best practices. The first two examples show duplicates occurring in single problems. While in Example 1 the paragraph is present both in the question and a response by another author, the excerpt found in Example 2 is a repetition of source code from a single author. For both examples, along with direct citations as in Example 3 and automated console outputs as in Example 4, a correct SCD prediction is intractable. In total, we found 92 examples of duplicated texts over all datasets and on average more than one in eight What filesystem layout will give the best performance?[. . . ]    </figDesc><table coords="9,95.27,86.02,410.13,253.51"><row><cell>#</cell><cell>Problem</cell><cell>Category</cell><cell>Excerpt and Source Stack Exchange URL</cell></row><row><cell>1</cell><cell>ğ’Ÿ test 3 -879</cell><cell>duplicate (different authors)</cell><cell>What filesystem layout will give the best performance? Source: https://serverfault.com/questions/243920</cell></row><row><cell>2</cell><cell>ğ’Ÿ test 3 -283</cell><cell>duplicate (same author)</cell><cell>def advance_to_first_non_white_space_on_line(view, pt): def advance_to_first_non_white_space_on_line(view, pt): Source: https://superuser.com/questions/9941833</cell></row><row><cell></cell><cell></cell><cell></cell><cell>"Flame was a failure for the antivirus industry. We really</cell></row><row><cell>3</cell><cell cols="2">ğ’Ÿ train 1 -1111 citation</cell><cell>should have been able to do better. But we didn't. We were out of our league, in our own game."</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Source: https://superuser.com/questions/1356507</cell></row><row><cell>4</cell><cell>ğ’Ÿ test 3 -1469</cell><cell>command line output</cell><cell>Setting up mysql-client-5.1 (5.1.37-1ubuntu5.1) ... [. . . ] Selecting previously deselected package mysql-server-5.1. Source: https://serverfault.com/questions/114974</cell></row><row><cell>5</cell><cell>ğ’Ÿ test 1 -109</cell><cell>german text</cell><cell>Die folgenden teilweise installierten Pakete werden konfiguriert: Source: https://serverfault.com/questions/265372</cell></row><row><cell>6</cell><cell>ğ’Ÿ train 1 -585</cell><cell>code</cell><cell>tempArray(2) = sourceSheet.Range("RF_INV_Axial").Value2 tempArray(3) = sourceSheet.Range("RF_INV_Major").Value2 [. . . ] Source: https://serverfault.com/questions/265372</cell></row><row><cell>7</cell><cell cols="2">ğ’Ÿ train 2 -1692 URL only</cell><cell></cell></row></table><note coords="9,226.03,318.74,277.49,8.36;9,226.03,328.20,173.43,8.36;9,269.74,336.68,235.47,9.44;9,95.27,360.22,4.63,8.87;9,116.49,356.67,21.62,12.02;9,124.17,364.54,3.97,6.12;9,138.60,360.22,60.74,9.61;9,225.17,349.87,95.39,8.36;9,225.17,359.34,225.46,8.36;9,295.34,367.81,209.87,9.44;9,95.27,391.44,4.63,8.87;9,116.49,387.89,21.62,12.02;9,124.17,395.77,3.97,6.12;9,138.60,391.44,58.78,9.59;9,226.03,381.19,247.14,8.36;9,225.60,390.65,60.70,8.36;9,307.97,399.13,197.25,9.44;9,95.27,419.12,39.43,12.42;9,124.17,426.99,3.97,6.12;9,135.19,422.67,21.85,8.87;9,172.41,416.55,35.81,8.87;9,172.41,428.50,37.75,8.87"><p>https://physics.stackexchange.com/questions/80043/how-fast-doeslight-travel-through-a-fibre-optic-cable Source: https://networkengineering.stackexchange.com/questions/16438 8 ğ’Ÿ train 3 -1207 HTML &lt;div class="cont b-1"&gt; &lt;button class="padded" data-type="number"&gt;0&lt;/button&gt; Source: https://codereview.stackexchange.com/questions/100643 9 ğ’Ÿ train 1 -1292 LaTeX $$ \frac{\Gamma \vdash t : T}{\Gamma, x:A \vdash t : T} \;\mathtt{W}$$ Source: https://cstheory.stackexchange.com/questions/41505 10 ğ’Ÿ test 3 -1229 repeated sequence</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="3,97.80,625.60,257.20,10.62"><p>Total list of Stack Exchange websites: https://data.stackexchange.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="3,97.80,636.56,408.19,10.62;3,97.80,647.52,87.52,10.62"><p>Whether old versions of edited posts are indexed depends on the given search engine, although we found that this was rarely the case.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="3,97.80,658.48,131.73,10.62"><p>AOL Search: https://search.aol.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="3,97.80,669.44,149.07,10.62"><p>Yahoo Search: https://search.yahoo.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_4" coords="9,97.80,647.50,408.19,10.62;9,97.80,658.46,408.19,10.62;9,97.80,669.42,199.04,10.62"><p>As we used a pattern search to filter the citations, paragraphs such as Example 8 in Table3might also be included in this category. Though this does not represent a citation in the proper sense, we decided to include these kinds of problems as they display further challenges to SCD.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_5" coords="11,97.80,658.46,409.17,10.62;11,97.46,669.42,408.52,10.62"><p>On a technical level, almost all authorship analysis tasks can interchangeably be transformed into each other, whereby authorship verification may arguably be considered as the core branch or a "fundamental problem"<ref type="bibr" coords="11,493.46,669.42,9.39,10.62" target="#b6">[7]</ref>.</p></note>
		</body>
		<back>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>https://stackexchange.com/ https://pan.webis.de/clef22///raspberrypi.stackexchange.com/questions</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="12,107.59,342.90,400.25,12.92;12,107.59,356.45,399.60,12.92;12,107.59,370.00,398.40,12.92;12,107.59,383.55,399.60,12.92;12,107.59,397.10,399.60,12.92;12,107.59,410.64,400.08,12.92;12,107.59,424.19,398.66,12.92;12,107.59,437.74,323.15,12.92" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,212.81,370.00,293.18,12.92;12,107.59,383.55,218.63,12.92">Overview of PAN 2022: Authorship Verification, Profiling Irony and Stereotype Spreaders, and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ortega-Bueno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pezik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,180.88,410.64,322.42,12.92;12,107.59,424.19,398.66,12.92">Proceedings of the Thirteenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="12,211.68,440.70,146.73,9.72">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Barron-Cedeno</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">D S</forename><surname>Martino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Esposti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Pasi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Thirteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022. 2022</date>
			<biblScope unit="volume">13390</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="12,107.59,451.29,398.40,12.92;12,107.26,464.84,398.73,12.92;12,107.59,478.39,81.94,12.92" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,320.30,451.29,185.69,12.92;12,107.26,464.84,54.53,12.92">Overview of the Style Change Detection Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,205.32,464.84,300.67,12.92;12,107.59,478.39,51.81,12.92">CLEF 2022 Labs and Workshops, Notebook Papers, CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,107.59,491.94,399.60,12.92;12,107.59,505.49,398.40,12.92;12,107.59,519.04,398.69,12.92;12,107.59,533.94,111.21,11.44" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,326.42,491.94,176.17,12.92">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-22948-1_5</idno>
	</analytic>
	<monogr>
		<title level="m" coord="12,237.51,505.49,268.48,12.92;12,107.59,519.04,121.14,12.92">Information Retrieval Evaluation in a Changing World, The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,107.59,546.14,398.40,12.92;12,107.24,559.69,277.29,12.92" xml:id="b3">
	<monogr>
		<ptr target="http://www.itl.nist.gov/iad/mig/tests/rt/2003-spring/docs/rt03-spring-eval-plan-v4.pdf/" />
		<title level="m" coord="12,107.59,546.14,253.95,12.92">The rich transcription spring 2003 (rt-03s) evaluation plan</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,107.59,573.24,398.40,12.92;12,107.59,586.78,398.39,12.92;12,107.26,600.33,29.19,12.92" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ryant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cieri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cristia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ganapathy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Liberman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.07839</idno>
		<title level="m" coord="12,453.98,573.24,52.01,12.92;12,107.59,586.78,249.00,12.92">The second dihard diarization challenge: Dataset, task, and baselines</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,107.59,613.88,398.40,12.92;12,107.20,627.43,307.60,12.92" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,149.78,613.88,248.76,12.92">Standard punctuation and the punctuation of the street</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,421.52,613.88,84.47,12.92;12,107.20,627.43,176.97,12.92">Essential Topics in Applied Linguistics and Multilingualism</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="267" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,107.59,640.98,398.40,12.92;12,107.59,654.53,206.41,12.92" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,313.83,640.98,192.16,12.92;12,107.59,654.53,46.09,12.92">The &quot;fundamental problem&quot; of authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Winter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,161.79,654.53,68.27,12.92">English Studies</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="284" to="291" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
