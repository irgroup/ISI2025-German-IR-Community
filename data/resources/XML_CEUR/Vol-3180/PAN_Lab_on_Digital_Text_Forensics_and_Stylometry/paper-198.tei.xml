<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,85.05,385.47,15.39;1,89.29,106.97,372.92,15.39;1,89.29,128.89,403.00,15.39;1,89.29,150.80,81.41,15.39">BERT Sentence Embeddings in different Machine Learning and Deep Learning Models for Author Profiling applied to Irony and Stereotype Spreaders on Twitter</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,89.29,180.13,65.79,10.68"><forename type="first">Daniel</forename><surname>Parres</surname></persName>
							<email>dparres@prhlt.upv.es</email>
							<affiliation key="aff0">
								<orgName type="institution">Universitat Polit√®cnica de Valencia</orgName>
								<address>
									<addrLine>Cam√≠ de Vera, s/n</addrLine>
									<postCode>46022</postCode>
									<settlement>Val√®ncia, Valencia</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,174.18,180.13,74.50,10.68"><forename type="first">Claudia</forename><surname>Gomez</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universitat Polit√®cnica de Valencia</orgName>
								<address>
									<addrLine>Cam√≠ de Vera, s/n</addrLine>
									<postCode>46022</postCode>
									<settlement>Val√®ncia, Valencia</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,85.05,385.47,15.39;1,89.29,106.97,372.92,15.39;1,89.29,128.89,403.00,15.39;1,89.29,150.80,81.41,15.39">BERT Sentence Embeddings in different Machine Learning and Deep Learning Models for Author Profiling applied to Irony and Stereotype Spreaders on Twitter</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">4B0DFE59C3A17CEC170856CDDEFB4887</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>profiling</term>
					<term>Sentence Embeddings</term>
					<term>Machine Learning</term>
					<term>Deep Learning</term>
					<term>BERT</term>
					<term>Irony</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Irony detection is an interesting problem with different fields of application, both for managing social media and for studying people's behavior and opinions. This paper focuses on classifying Twitter author profiles as ironic or non-ironic based on their tweets. For this purpose, different types of feature extraction are applied to each author's tweets, from classical techniques to the most recent ones that are part of the state of the art. Furthermore, once the feature extraction has been performed, classical Machine Learning techniques such as SVM, Random Forest, and Logistic Regression are applied, up to more recent methods such as artificial neural networks with Self Attention mechanisms. Finally, a discussion is opened on the methods used and what each technique can contribute to solving this task. As it happens in most of the tasks where Embedding techniques are applied in natural language, new frontiers of study, analysis, and application are opened. Therefore, this study provides different brushstrokes for the development of robust systems for the detection of ironic and non-ironic authors.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This work focuses on profiling authors based on their tweets into ironic or non-ironic, emphasizing authors who employ irony to spread stereotypes. With this objective we use data provided by PAN'22 <ref type="bibr" coords="1,179.18,484.75,11.28,9.74" target="#b0">[1]</ref>. This data is composed of 420 Twitter profiles and 200 tweets from each of them; each user is labeled as ironic or non-ironic.</p><p>The task of classifying authors as ironic or non-ironic based on their tweets is very interesting due to the current context in which we find ourselves, where anyone has access to social media and the freedom to share and spread their ideas. Because of this, identifying which authors are spreading comments that can be considered harmful from an assertive perspective is important both for managing and administering social media and sociological or psychological studies.</p><p>Thanks to the emergence of different Artificial Intelligence techniques and algorithms, this task can be covered by Machine Learning. This work first performs a study of the data, analyzing tweets and preprocessing them. Once the data is studied, different classical techniques and state-of-the-art algorithms such as artificial neural networks are applied. And finally, the results obtained are evaluated and discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Since 2013, there are works focused on the detection of irony, an example is <ref type="bibr" coords="2,421.03,173.81,12.69,9.74" target="#b1">[2]</ref> which describes a set of textual characteristics to recognize irony at the linguistic level, focusing on short texts, such as tweets. The proposed model is evaluated in two dimensions: representativeness and relevance.</p><p>In <ref type="bibr" coords="2,112.30,228.01,13.00,9.74" target="#b2">[3]</ref> encouraging results are demonstrated for deriving pragmatic contextual models for irony detection, which provides the application of a new approach beyond the use of features. While on the other hand, in <ref type="bibr" coords="2,213.35,255.11,11.32,9.74" target="#b3">[4]</ref>, in a contest to detect ironic tweets in the Arabic language, it is shown that classical feature-based models are superior to neural ones.</p><p>The task of author profiling is applied to different areas, such as detecting hate speech <ref type="bibr" coords="2,491.79,282.21,11.55,9.74" target="#b4">[5]</ref>, gender <ref type="bibr" coords="2,122.12,295.76,12.70,9.74" target="#b5">[6]</ref> and age of authors <ref type="bibr" coords="2,221.57,295.76,11.29,9.74" target="#b6">[7]</ref>, by analyzing their tweets, but this work focuses on detecting whether an author is ironic or not.</p><p>In author profiling, different features have been used for years, such as text length, cosine similarity ranking, word retrieval, Okapi BM25 ranking, and NRC emotions, as proposed in <ref type="bibr" coords="2,89.29,349.95,11.52,9.74" target="#b7">[8]</ref>. With the approach of using different features, in <ref type="bibr" coords="2,328.73,349.95,12.94,9.74" target="#b8">[9]</ref> for irony detection, classical models and Multilayer Perceptron are used, together with statistical techniques such as counting, post-tagger, textual markers, and lexicon-based as wordnet similarity. But the best performing models are SVM, MLP, and Random Forest, while the best performing features are textual markers, sentiment score, and polarity value.</p><p>In <ref type="bibr" coords="2,112.08,417.70,17.93,9.74" target="#b9">[10]</ref> and <ref type="bibr" coords="2,151.88,417.70,17.93,9.74" target="#b10">[11]</ref> the techniques and preprocessing that have obtained the best results in the PAN'19 and 20 contests for gender, bots and hate speech profiling are presented, where the extensive use of BERT word embeddings <ref type="bibr" coords="2,273.27,444.80,17.91,9.74" target="#b11">[12]</ref> and their use in neural models are highlighted.</p><p>It can be seen from all the literature to date that in author profiling problems, the use of classical versus neural models tends to perform better. Although this is with the help of BERT word embeddings, without preprocessing techniques given that they usually do not improve accuracy rates as discussed in <ref type="bibr" coords="2,224.28,498.99,17.91,9.74" target="#b12">[13]</ref> with multiple experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>This section is divided into 2 subsections. The first one focuses on the analysis of the data and the study of the balancing of the two classes to know which metric is the most representative for the training of the algorithms, if there are repeated tweets and the most used words in each class.</p><p>In the second subsection, the treatment of the data and the different models used are presented. To compare the models, 10-Fold Cross-Validation is used, with 90% for training and 10% test for classical models and 80% for training, 10% validation, and 10</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data Analysis</head><p>The data provided by PAN'22 is composed of 420 users, with 200 tweets each, where each profile is labeled as ironic or non-ironic. The distribution of the two classes is 210 ironic and 210 non-ironic authors, so we have a balanced problem, and a good metric for the analysis and comparison of models is the accuracy. Another feature of the dataset is found in the tweets where USER, HASHTAG, and URL tags are used to refer to users, hashtags, and URLs within the tweets themselves.</p><p>Analyzing the tweets, being a task with 200 tweets for each user, we have a total of 84,000 tweets, where we have 749 repeated tweets. In the case of the repeated tweets, since they are so few in proportion to the data set, they do not negatively affect the performance of the models.</p><p>On the other hand, the most used words by class have been analyzed, to observe if there is any pattern that repeats significantly in ironic or non-ironic authors. Eliminating USER, HASHTAG, URL, and stopwords, the texts have been used to construct the word clouds for ironic and non-ironic authors (Figure <ref type="figure" coords="3,266.15,271.25,3.65,9.74" target="#fig_0">1</ref>). There is hardly any difference in the words most frequently used for each type of author, although in non-ironic authors the word "women" is quite frequent, while in ironic authors the word "Trump" is one of the most repeated. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Models and Evaluation</head><p>Before presenting the different Machine Learning models for the task of author profiling, it is necessary to study which forms of tweet preprocessing best fit the task. Two different approaches have been used, the first one is the use of the classical TF-IDF vectorizer, the second one is the BERT tokenizer, and finally the BERT Sentence Embedding. For comparison, the experiments performed are presented in Table <ref type="table" coords="3,302.39,554.26,3.81,9.74" target="#tab_0">1</ref>, where they have been tested with Support Vector Machines (SVM), Multilayer Perceptron (MLP), and Recurrent Neural Network (RNN).</p><p>It should be noted, as mentioned in the Methodology section, that the experiments were performed using 10-Fold Cross-Validation. It can be seen from the results of Table <ref type="table" coords="3,455.10,594.91,3.72,9.74" target="#tab_0">1</ref>, that with the use of BERT Sentence Embedding better results are obtained. Since the model is trained for capturing the relationship between words taking into account the context, and performance is achieved that in comparison to the TF-IDF Vectorizer and BERT Tokenizer techniques is much higher. Therefore in the following experiments it was decided to use BERT Sentence Embedding for feature extraction.  Currently, the best performing models are artificial neural networks due to their great generalization capacity and high performance, so a wide family of neural models is applied in this task. Five different types of architectures have been developed, a 5-layer Multilayer Perceptron, a bilinear convolutional neural network, and three different types of bidirectional LSTM RNN, a simple one, one with 1D Convolution mechanisms and another with 1D Convolutions and Self-Attention.</p><p>Table <ref type="table" coords="5,130.16,101.64,5.16,9.74" target="#tab_2">3</ref> presents the different architectures with their corresponding accuracies. It can be seen that the neural methods obtain more or less the same results among them, surpassing on average the classical methods in Table <ref type="table" coords="5,267.03,128.74,3.81,9.74" target="#tab_1">2</ref>. Despite being better on average than the classical methods, the highest accuracy reached is 0.94 for the classical Logistic Regression algorithm. The main idea when training the Multilayer Perceptron or the classical methods is to average the vectors calculated by BERT for each author. That is, as each author has 200 tweets, BERT returns 200 vectors of dimension 784, so an average of these 200 vectors is performed to obtain only one. While in the rest of the neural models, the 200 BERT vectors have been used, an architecture that can perform well for this task it's the Convolutional 1D with Bidirectional LSTM layers, presented in Figure <ref type="figure" coords="5,239.31,363.56,3.74,9.74">3</ref>, called Iro-Net for simplicity.</p><p>Using all BERT vectors is enriching. All state-of-the-art neural models are able to achieve better results due to the large amount of information. Because of this, it has been decided to develop a neural network using convolution mechanisms together with a bidirectional LSTM layer, named Iro-Net and inspired by the model proposed by <ref type="bibr" coords="5,403.19,417.75,16.42,9.74" target="#b13">[14]</ref>. Moreover, in the field of Natural Language Processing, models that implement attention mechanisms such as Transformers are the standard. Therefore Iro-Net incorporates a Self-Attention layer after the recurrent LSTM layer. The Iro-Net architecture is shown in Figure <ref type="figure" coords="5,395.72,458.40,5.17,9.74" target="#fig_1">2</ref> and has been designed specifically for this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Iro-Net Architecture</head><p>The Iro-Net architecture and its corresponding hyperparameters are presented in this section. It should be noted that the parametrization described corresponds to the best model submitted to Tira <ref type="bibr" coords="5,122.20,548.76,16.25,9.74" target="#b14">[15]</ref>.</p><p>This artificial neural network is composed of different layers that perform different functions. The first layer corresponds to the Sentence Embedding of BERT and is in charge of handling the 200 tweets of each user and obtaining an interesting representation of them. A Bidirectional LSTM layer is applied to the Embeddings of the tweets and tries to perform a context-aware representation of the tweets. At the output of the Bidirectional LSTM layer is a Self-Attention layer, in order to discriminate which words or conditions are the most important when detecting irony. The next layer is a 1D Convolutional with a corresponding Max-Pooling layer that performs well for pattern recognition. A Residual connection from the output of the Bidirectional LSTM is added to the Max-Pooling output. Residual connections are widely used in Deep Learning. Specifically, this design achieves a more discriminative representation, because of this it has been considered interesting to apply it. Finally, a Global Max-Pooling layer, a layer of 256 neurons and a Softmax output in charge of calculating the probability of whether the author is ironic or not are added.</p><p>Regarding the Hyperparameters used it is interesting to mention the following. All layers use Glorot weight initialization. In Glorot initialization the biases are initialized to 0 and the weights are calculated with the uniform distribution taking into account the size of the previous layer. The layers: Bidirectonal LSTM, Max-Pooling and the penultimate layer with 256 neurons use the Dropout technique with values between 0.2 and 0.3. In addition, it is interesting to mention that all layers use the L2 regularizer with a value of 0.00005.</p><p>As for the Hyperparameters of the training, the Adam optimizer with a learning rate of 0.001 has been used. During training it is important to use a Learning Rate Annealing technique because changing the learning rate can improve the performance of the model and not stagnate at local minima. The best performing technique is Learning Rate On Plateau with a minimum learning rate value of 0.000001. Finally, the training consists of 100 epochs and a batch size of 16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Discussion and Conclusion</head><p>As has been studied in the Related Work section, the use of BERT embeddings and the contextual relationship that can be obtained by using them is a key point in any natural language task. In this work, BERT's Sentence Embeddings have been compared against TF-IDF vectorizer and BERT's tokenizer, with Sentence Embedding being the best representation with a significant difference.</p><p>Furthermore, it's worth noting that the power of BERT's Sentence Embeddings representation is so powerful, that such a process does not need any kind of preprocessing. This opens new application frontiers, which in the not too distant future will allow Embeddings techniques to be used for other types of problems in the Machine Learning field.</p><p>With the reviewed bibliography, the classical models in the task of author profiling seem to have in their majority better performance than the neural ones, but we think that the cause of this is due to the reduced number of data that we have. If in the future we get more Twitter profiles labeled as ironic or non-ironic, it would be interesting to replicate the experiments corresponding to Tables <ref type="table" coords="7,199.57,288.54,5.10,9.74" target="#tab_1">2</ref> and<ref type="table" coords="7,226.62,288.54,3.76,9.74" target="#tab_2">3</ref>, but for the moment, the best accuracy obtained is 0.94 using BERT's Sentence Embedding and Logistic Regression classifier.</p><p>As already mentioned, the detection of ironic profiles is an important task with many applications, both for directing and managing social media, as well as for sociological studies. Therefore, stressing the importance of a necessary continuous and in-depth improvement in this area is necessary.</p><p>In addition, another point to highlight about the work done is that despite how mainstream artificial neural network methods have become, for the moment we should not forget the classic algorithms, such as SVM, Decision Trees, Logistic Regression, and so on.</p><p>Since the PAN contest for irony detection consists of two phases, in the first phase (early bird) it has been decided to deliver two models, a classical one and a neural one. The classical algorithm delivered is Logistic Regression, with the parameterization presented in Table <ref type="table" coords="7,481.88,437.58,5.04,9.74" target="#tab_1">2</ref> and the neural network presented is Iro-Net, whose architecture is shown in Figure <ref type="figure" coords="7,437.74,451.13,3.67,9.74">3</ref>. In the results of the first phase, the best model among the two phases was Iro-Net with 96.11% accuracy, so in the second phase (final submission) the Iro-Net model will be presented as the definitive model.</p><p>As future work and possible extensions, using BERT as a pre-trained model and performing fine-tuning with different variations of BERT, such as distilled BERT, could bring improvements in the performance of ironic profile detection models based on tweets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,433.19,299.22,8.91;3,89.29,319.91,416.70,100.70"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Wordclouds for ironic (left) and non-ironic (right) user tweets.</figDesc><graphic coords="3,89.29,319.91,416.70,100.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,89.29,397.11,131.38,8.91;6,187.64,84.18,220.00,300.40"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Iro-Net Architecture.</figDesc><graphic coords="6,187.64,84.18,220.00,300.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,88.91,90.67,418.91,358.95"><head>Table 1</head><label>1</label><figDesc>Accuracy of different feature extraction for tweets.Having studied that BERT Sentence Embedding is the best text representation, it is interesting to analyze if the preprocessing of USER, HASHTAG, and URL tags can provide any improvement compared to no preprocessing. The removal of these terms cause a worsening in the accuracy of 1% in the models of Table1, which may be because in the cases of ironic users, the use of hashtags is quite widespread and this helps the classifiers to find patterns and improve the understanding of what is irony detection.Regarding the Machine Learning models used, two different scenarios are presented: on one hand, classical techniques are applied, and on the other one, more advanced techniques such as Artificial Neural Networks.For the classical models, about 10,000 experiments have been carried out comparing different techniques such as Decision Trees, Logistic Regression, Gaussian Naive Bayes, Multinomial Naive Bayes, Support Vector Machine, Bernoulli Naive Bayes, K-Nearest Neighbors, Logistic Regression with different preprocessing techniques on the BERT Sentence Embedding vector such as Binarizer, Feature Agglomeration, MaxAbsScaler, MinMaxScaler, Normalizer, Principal Component Analysis, RBFSampler, Robust Scaler, StandardScaler, ZeroCount. The most significant results of the different combinations are presented in Table2, where the best accuracy obtained by far is 0.94 using Logistic Regression with Normalizer L2, Robust Scaler and a Variance Threshold of 0.005.</figDesc><table coords="4,114.48,120.45,366.32,62.56"><row><cell></cell><cell>Accuracy using</cell><cell>Accuracy using</cell><cell>Accuracy using BERT</cell></row><row><cell>Model</cell><cell>TF-IDF Vectorizer</cell><cell>BERT Tokenizer</cell><cell>Sentence Embedding</cell></row><row><cell>SVM</cell><cell>0.67</cell><cell>0.72</cell><cell>0.93</cell></row><row><cell>MLP(5 layers)</cell><cell>0.76</cell><cell>0.79</cell><cell>0.92</cell></row><row><cell cols="2">RNN(Bidirectional LSTM) 0.82</cell><cell>0.83</cell><cell>0.93</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.99,464.91,352.04,130.00"><head>Table 2</head><label>2</label><figDesc>Most relevant experiments with classical algorithms.</figDesc><table coords="4,154.25,496.50,286.79,98.40"><row><cell>Model</cell><cell>Accuracy</cell></row><row><cell>Decision Tree gini and max-depth=3</cell><cell>0.89</cell></row><row><cell>K-NearestNeighbors k=70, weights=distance and power=1</cell><cell>0.75</cell></row><row><cell>Gaussian Naive Bayes</cell><cell>0.88</cell></row><row><cell>MultinomialNB alpha=1 and fit ùëù ùëüùëñùëúùëü = ùêπ ùëéùëôùë†ùëí</cell><cell>0.88</cell></row><row><cell>Logistic Regression penalty=l2, C=5 and dual=False</cell><cell>0.94</cell></row><row><cell>BernoulliNB alpha=100 and fit ùëù ùëüùëñùëúùëü = ùëá ùëüùë¢ùëí</cell><cell>0.90</cell></row><row><cell>Support Vector Machine C=10 y kernel=rbf</cell><cell>0.93</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,88.99,170.34,339.99,105.76"><head>Table 3</head><label>3</label><figDesc>Most relevant experiments with neural algorithms.</figDesc><table coords="5,166.30,201.94,262.68,74.16"><row><cell>Model Architecture</cell><cell>Accuracy</cell></row><row><cell>Multilayer Perceptron (5 layers)</cell><cell>0.92</cell></row><row><cell>Bilineal CNN (BERT Sentence Embedding to Image)</cell><cell>0.93</cell></row><row><cell>Bidirectional LSTM</cell><cell>0.93</cell></row><row><cell>Conv. 1D + Bidirectional LSTM</cell><cell>0.93</cell></row><row><cell>Bidirectional LSTM + Self Attention + Conv. 1D</cell><cell>0.92</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,112.66,577.50,393.32,9.74;7,112.66,591.05,394.03,9.74;7,112.66,604.60,150.97,9.74" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="7,372.79,577.50,133.19,9.74;7,112.66,591.05,213.49,9.74">Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO) at PAN 2022</title>
		<author>
			<persName coords=""><forename type="first">O.-B</forename><surname>Reynier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Berta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Paolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Elisabetta</surname></persName>
		</author>
		<ptr target="https://pan.webis.de/clef22/pan22-web/author-profiling.html" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,618.15,394.53,9.74;7,112.66,631.70,240.60,9.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,239.99,618.15,263.15,9.74">A multidimensional approach for detecting irony in twitter</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Veale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,112.66,631.70,156.67,9.74">Language resources and evaluation</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="239" to="268" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,645.25,395.17,9.74;8,112.66,88.09,393.32,9.74;8,112.66,101.64,267.83,9.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,427.15,645.25,80.68,9.74;8,112.66,88.09,197.89,9.74">Towards a contex-tual pragmatic model to detect irony in tweets</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Karoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Benamara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Moriceau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Aussenac-Gilles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">H</forename><surname>Belguith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,332.96,88.09,173.02,9.74;8,112.66,101.64,183.62,9.74">53rd Annual Meeting of the Association for Computational Linguistics (ACL 2015)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page">644</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,115.19,393.74,9.74;8,112.66,128.74,393.53,9.74;8,112.66,142.29,222.31,9.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,385.64,115.19,120.75,9.74;8,112.66,128.74,212.37,9.74">Overview of the track on irony detection in arabic tweets</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Karoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Benamara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Moriceau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,349.97,128.74,156.22,9.74;8,112.66,142.29,144.57,9.74">Proceedings of the 11th Forum for Information Retrieval Evaluation</title>
		<meeting>the 11th Forum for Information Retrieval Evaluation</meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="10" to="13" />
		</imprint>
	</monogr>
	<note>Idat at fire</note>
</biblStruct>

<biblStruct coords="8,112.66,155.84,393.32,9.74;8,112.66,169.38,384.62,9.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,412.23,155.84,93.74,9.74;8,112.66,169.38,160.61,9.74">Profiling hate speech spreaders on twitter task at pan 2021</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L</forename><surname>De La Pe√±a Sarrac√©n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,300.63,169.38,98.72,9.74">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1772" to="1789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,182.93,394.61,9.74;8,112.31,196.48,278.73,9.74" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.3692340</idno>
		<ptr target="https://doi.org/10.5281/zenodo.3692340.doi:10.5281/zenodo.3692340" />
		<title level="m" coord="8,201.57,182.93,222.17,9.74">Pan19 author profiling: Bots and gender profiling</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,210.03,393.33,9.74;8,112.66,223.58,393.33,9.74;8,112.66,237.13,170.54,9.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,361.72,210.03,144.27,9.74;8,112.66,223.58,67.11,9.74">Overview of the author profiling task at pan 2013</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Inches</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,202.10,223.58,303.89,9.74;8,112.66,237.13,45.78,9.74">CLEF Conference on Multilingual and Multimodal Information Access Evaluation</title>
		<imprint>
			<publisher>CELCT</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="352" to="365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,250.68,395.17,9.74;8,112.66,264.23,393.32,9.74;8,112.66,277.78,76.13,9.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,479.69,250.68,28.14,9.74;8,112.66,264.23,186.48,9.74">Examining multiple features for author profiling</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">R</forename><surname>Weren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">U</forename><surname>Kauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Mizusaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">P</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P M</forename><surname>De Oliveira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">K</forename><surname>Wives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,307.12,264.23,198.85,9.74">Journal of information and data management</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="266" to="266" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,291.33,245.37,9.74" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="8,152.18,291.33,173.92,9.74">Pattern recognition and image analysis</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gose</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,304.88,393.53,9.74;8,112.66,318.43,393.33,9.74;8,112.66,331.98,137.73,9.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,199.05,304.88,307.14,9.74;8,112.66,318.43,81.02,9.74">Overview of the 7th author profiling task at pan 2019: bots and gender profiling in twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,216.71,318.43,252.59,9.74;8,147.28,331.98,72.33,9.74">Working Notes Papers of the CLEF 2019 Evaluation Labs</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">2380</biblScope>
		</imprint>
	</monogr>
	<note>CEUR Workshop</note>
</biblStruct>

<biblStruct coords="8,112.66,345.52,393.33,9.74;8,112.66,359.07,394.52,9.74;8,112.39,372.62,243.38,9.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,345.20,345.52,160.79,9.74;8,112.66,359.07,243.00,9.74">Overview of the 8th author profiling task at pan 2020: Profiling fake news spreaders on twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">H H</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,376.70,359.07,125.86,9.74">CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Sun SITE Central Europe</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2696</biblScope>
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,386.17,393.32,9.74;8,112.66,399.72,363.59,9.74" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="8,353.51,386.17,152.47,9.74;8,112.66,399.72,181.08,9.74">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,413.27,393.32,9.74;8,112.66,426.82,344.28,9.74" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Alzahrani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jololian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.13890</idno>
		<title level="m" coord="8,220.56,413.27,285.41,9.74;8,112.66,426.82,162.02,9.74">How different text-preprocessing techniques using the bert model affect the gender profiling of authors</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,440.37,393.52,9.74;8,112.66,453.92,393.32,9.74;8,112.66,467.47,253.71,9.74" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,304.86,440.37,201.33,9.74;8,112.66,453.92,181.33,9.74">Contextualized bert sentence embeddings for author profiling: The cost of performances</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Polignano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Gemmis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Semeraro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,316.18,453.92,189.80,9.74;8,112.66,467.47,123.13,9.74">International Conference on Computational Science and Its Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="135" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,481.02,394.53,9.74;8,112.66,494.57,393.31,9.74;8,112.66,508.11,393.32,9.74;8,112.66,522.91,92.88,8.14" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,327.54,481.02,175.06,9.74">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-22948-1_5</idno>
	</analytic>
	<monogr>
		<title level="m" coord="8,241.29,494.57,264.68,9.74;8,112.66,508.11,126.51,9.74">Information Retrieval Evaluation in a Changing World, The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
