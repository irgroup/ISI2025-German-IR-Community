<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.78,84.74,414.46,15.42;1,89.29,106.66,161.79,15.42;1,89.29,129.00,157.29,11.96">T100: A modern classic ensemble to profile irony and stereotype spreaders Notebook for PAN at CLEF 2022</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,89.29,154.90,57.24,11.96"><forename type="first">Marco</forename><surname>Siino</surname></persName>
							<email>marco.siino@unipa.it</email>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Ingegneria</orgName>
								<orgName type="institution">Universit√† degli Studi di Palermo</orgName>
								<address>
									<postCode>90128</postCode>
									<settlement>Palermo</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,157.16,154.90,78.83,11.96"><forename type="first">Ilenia</forename><surname>Tinnirello</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Ingegneria</orgName>
								<orgName type="institution">Universit√† degli Studi di Palermo</orgName>
								<address>
									<postCode>90128</postCode>
									<settlement>Palermo</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,263.44,154.90,80.41,11.96"><forename type="first">Marco</forename><forename type="middle">La</forename><surname>Cascia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Ingegneria</orgName>
								<orgName type="institution">Universit√† degli Studi di Palermo</orgName>
								<address>
									<postCode>90128</postCode>
									<settlement>Palermo</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.78,84.74,414.46,15.42;1,89.29,106.66,161.79,15.42;1,89.29,129.00,157.29,11.96">T100: A modern classic ensemble to profile irony and stereotype spreaders Notebook for PAN at CLEF 2022</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">5C49C7F31059C5B648B64B15445E52DD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>irony</term>
					<term>stereotypes</term>
					<term>author profiling</term>
					<term>text classification</term>
					<term>Twitter</term>
					<term>ensemble</term>
					<term>logistic regressor</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this work we propose a novel ensemble model based on deep learning and non-deep learning classifiers. The proposed model was developed by our team for participating at the Profiling Irony and Stereotype Spreaders (ISSs) task hosted at PAN@CLEF2022. Our ensemble (named T100), include a Logistic Regressor (LR) that classifies an author as ISS or not (nISS) considering the predictions provided by a first stage of classifiers. All these classifiers are able to reach state-of-the-art results on several text classification tasks. These classifiers (namely, the voters) are a Convolutional Neural Network (CNN), a Support Vector Machine (SVM), a Decision Tree (DT) and a Naive Bayes (NB) classifier. The voters are trained on the provided dataset and then generate predictions on the training set. Finally, the LR is trained on the predictions made by the voters. For the simulation phase the LR considers the predictions of the voters on the unlabelled test set to provide its final prediction on each sample. To develop and test our model we used a 5-fold cross validation on the labelled training set. Over the five validation splits, the proposed model achieves a maximum accuracy of 0.9342 and an average accuracy of 0.9158. As announced by the task organizers, the trained model presented here is able to reach an accuracy of 0.9444 on the unlabelled test set provided for the task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The task proposed at PAN@CLEF2022 <ref type="bibr" coords="1,261.75,465.26,12.80,10.91" target="#b0">[1]</ref> was about Profiling Irony and Stereotype Spreaders (ISSs) on Twitter <ref type="bibr" coords="1,165.68,478.81,11.39,10.91" target="#b1">[2]</ref>. The task was to investigate whether or not an author of a Twitter feed is likely to spread tweets containing irony and stereotypes. The organizers provided a labelled English dataset, consisting of 420 authors. In the dataset, each sample represents a single author's feed. For each author a set of 200 tweets is provided. The unlabelled test set provided consists of 180 samples. The model we used to compete for the task consists of a Logistic Regressor (LR) that get as input the predictions provided by a first stage of classifiers (named the voters). The voters are a Convolutional Neural Network (CNN), a Support Vector Machine (SVM), a Naive Bayes classifier (NB) and a Decision Tree (DT).</p><p>Our paper is organized as follows. In Section 2 related works about deep and non-deep methods for text classification are presented. In Section 3 we describe our model (T100), including the training and the simulation steps. In Section 4 we discuss the experimental evaluation of our model, reporting the results of our tests on the 5-fold cross validation and on the test set. In Section 5 we propose future works and conclude the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Recent approaches to the detection of stereotypes are proposed in <ref type="bibr" coords="2,380.58,199.79,11.24,10.91" target="#b2">[3,</ref><ref type="bibr" coords="2,394.56,199.79,8.89,10.91" target="#b3">4]</ref> while some interesting methods and discussions about irony detection are proposed in <ref type="bibr" coords="2,368.22,213.34,11.25,10.91" target="#b4">[5,</ref><ref type="bibr" coords="2,382.18,213.34,7.50,10.91" target="#b5">6]</ref>. However, to build up our model we investigated the best performing models participating at the shared tasks organized by PAN. Specifically, we looked at the last year author profiling task hosted at PAN@CLEF 2021, where the best performing model consisted of a shallow CNN presented in <ref type="bibr" coords="2,440.34,253.99,11.28,10.91" target="#b6">[7]</ref>. A previous edition of the author profiling task is discussed in <ref type="bibr" coords="2,320.24,267.54,11.59,10.91" target="#b7">[8]</ref>, where the goal is to identify authors prone to spread fake news based on their last 100 tweets. The winners at the shared task were <ref type="bibr" coords="2,89.29,294.63,13.00,10.91" target="#b8">[9]</ref> and <ref type="bibr" coords="2,124.53,294.63,16.41,10.91" target="#b9">[10]</ref>. Their models obtained an overall accuracy of 0.77 on the provided test set. The approaches used by the winners are based on an SVM and n-grams and on an ensemble of different machine learning models.</p><p>Furthermore, we looked at common several state-of-the-art models on text classification tasks. It is worth reporting a significant increase in the use of Explainable Artificial Intelligence (XAI) methods in place of black box-based approaches. A few of these methods are based on graphs and used in real-world applications such as text classification <ref type="bibr" coords="2,406.13,375.93,16.41,10.91" target="#b10">[11]</ref>, traffic prediction <ref type="bibr" coords="2,89.29,389.48,16.25,10.91" target="#b11">[12]</ref>, computer vision <ref type="bibr" coords="2,187.43,389.48,17.91,10.91" target="#b12">[13]</ref> and social networking <ref type="bibr" coords="2,309.79,389.48,16.25,10.91" target="#b13">[14]</ref>. In <ref type="bibr" coords="2,345.19,389.48,17.91,10.91" target="#b14">[15]</ref> authors comparatively evaluate common machine learning algorithms (i.e., SVM, Naive Bayes, Logistic Regression and Recurrent Neural Networks (RNN)). On the dataset used, experimental results show that SVM and Naive Bayes outperform other methods. They do not report evaluation of CNN nor deep learningbased models in addition to the RNN. In another relevant comparative study <ref type="bibr" coords="2,447.17,443.67,16.42,10.91" target="#b15">[16]</ref>, authors evaluate seven machine learning models on three different datasets. The models used are based on Random Forest, SVM, Gaussian Naive Bayes, AdaBoost, KNN, Multi-Layer Perceptron and Gradient Boosting Algorithm. In terms of accuracy and F1 score, the Gradient Boosting Algorithm outperforms the other tested models. However, also in this study, further experiments on deep models are missing.</p><p>In <ref type="bibr" coords="2,111.38,524.97,17.76,10.91" target="#b16">[17]</ref> the authors extend the CoAID dataset <ref type="bibr" coords="2,295.84,524.97,17.76,10.91" target="#b17">[18]</ref> to address the task of automatic detection of fake news spreaders of COVID-19 news. The authors present a stacked and Transformer-based neural network that combines the Transformer capabilities of computing sentence embeddings with a deep learning model. In <ref type="bibr" coords="2,231.73,565.62,16.41,10.91" target="#b18">[19]</ref>, the authors use psycholinguistic and linguistic features as input to a CNN to profile fake news spreaders. The experimental results show that their proposed model is effective in classifying a user as a fake news spreader. The authors compare their results on a dataset specifically built for their task. However, the only Transformer tested is BERT and deep models performance is not widely explored. In addition, their proposed model is tested in <ref type="bibr" coords="2,139.14,633.36,17.76,10.91" target="#b19">[20]</ref> (where the PAN@CLEF2020 dataset is used) reporting poor results. Specifically, the model tested reaches a binary accuracy of 0.52 and of 0.51 on the English and Spanish dataset, respectively. In the same work <ref type="bibr" coords="2,261.13,660.46,16.09,10.91" target="#b19">[20]</ref>, authors propose a new model that uses personality information and visual features, outperforming the two winning models at PAN@CLEF2020 on both languages.</p><p>In the work conducted in <ref type="bibr" coords="3,212.17,114.06,16.09,10.91" target="#b20">[21]</ref>, authors propose a CNN for the task of sentiment classification. Through experiments with three well-known datasets, authors show that employing consecutive convolutional layers is effective in classifying long texts.</p><p>Finally, the survey in <ref type="bibr" coords="3,196.19,154.71,17.88,10.91" target="#b21">[22]</ref> provides a brief overview of several text classification algorithms. This overview covers different text features extraction techniques, dimensionality reduction methods, existing algorithms and techniques, and evaluation methods.</p><p>Given the performances reached in a similar text classification task <ref type="bibr" coords="3,398.88,195.36,17.84,10.91" target="#b22">[23]</ref> and, as discussed in <ref type="bibr" coords="3,89.29,208.91,16.39,10.91" target="#b23">[24,</ref><ref type="bibr" coords="3,108.41,208.91,12.29,10.91" target="#b24">25]</ref>, assuming that deep AI models are actually able to outperform classic techniques used in the field of natural language processing, we decided to include a deep learning-based model (i.e., a CNN) in our novel architecture.</p><p>The various and heterogeneous results of any of the state-of-the-art model discussed above, lead our team to develop an ensemble model able to classify a sample based on the predictions provided by a first stage of classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The proposed model: T100</head><p>The model proposed and described in this section is named T100. This name is motivated by the modern classic class of motorcycles produced by the UK-owned manufacturer <ref type="foot" coords="3,442.25,347.08,3.71,7.97" target="#foot_0">1</ref> . In fact, T100 consists of both modern and classic elements to perform its task <ref type="foot" coords="3,378.67,360.62,3.71,7.97" target="#foot_1">2</ref> . T100 include an LR model trained on the predictions provided by a first stage of classifiers. Details about the training phase of T100 are provided in the following subsection.</p><p>As a first step we preprocess each sample in our dataset to remove information common to all samples. More specifically we remove the tag CDATA before each tweet of any author's feed. Then we remove the starting tag &lt;documents&gt; opening each sample. Finally we remove the opening and closing tag &lt;author lang="en"&gt;. Finally we lowercase all the text. The resulting text is then vectorized using the Keras Text Vectorization layer 3 . The preprocessing discussed above is performed by the text vectorization layer. Therefore, the text vectorization layer performs the following operations:</p><p>1. Preprocess the text of each sample 2. Split the text in each preprocessed sample into words (at each space character) 3. Recombine words into tokens (ngrams) 4. Index tokens (associate a unique int value with each token) 5. Transform each sample using this index, into a vector of ints.</p><p>While the vectorized text is provided as-is to the word embedding layer inside the CNN, another step is performed for other voters. The vectorized text is translated into a Bag-of-Words (BoW) representation and provided as input to the other voters (i.e., NB, SVM and DT). It is worth noting that the outputs from the first stage of classifiers have different meanings. In fact, the CNN outputs a float value in the range (-‚àû,+‚àû), while other classifiers output the probability that a given sample is an ISS. In the case of the CNN the threshold value is set equal to 0, therefore any negative value corresponds to a nISS while a positive one corresponds to an ISS.</p><p>The CNN network is implemented accordingly to the work discussed in <ref type="bibr" coords="4,419.50,472.00,12.77,10.91" target="#b6">[7]</ref> and in <ref type="bibr" coords="4,465.48,472.00,16.18,10.91" target="#b22">[23]</ref>. The network consists of a word embedding layer followed by a convolutional layer, an average pooling layer, a global average pooling layer and a single dense unit as output. The other voters are implemented using the scikit-learn packages <ref type="foot" coords="4,302.67,510.89,3.71,7.97" target="#foot_2">4</ref> .</p><p>At a very first implementation we tried to normalize each voter's output. Specifically we performed several experiments; as an instance, using the normalization techniques discussed in <ref type="bibr" coords="4,89.29,553.29,16.30,10.91" target="#b25">[26,</ref><ref type="bibr" coords="4,108.04,553.29,12.23,10.91" target="#b26">27]</ref>. However we discovered that keeping the original output range from each voter notably increases the performance of T100. So we lastly did not make use of any kind of normalization technique for any voter's output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Model training</head><p>In this subsection we describe the training and the simulation phase of our novel architecture.</p><p>The training of our model is based on a 5-fold strategy. As a first step we train each voter using the k-training fold. Then we let each voter predicts on the corresponding k-validation fold. Then we merge the five sets of predictions on the validation folds. In such a way, a new predictions dataset is generated. In this new generated predictions dataset, samples consist of voter's predictions and of the original corresponding label (i.e., nISS or ISS) of the input sample. This new predictions dataset is used to train the LR.</p><p>After the training phase, the simulation phase is performed as follows. Using the official test set, we provide the unlabelled samples to the voters. Predictions of the voters are provided as input to the LR, then we collect and submit the final predictions made by the LR. This last prediction phase is depicted in Figure <ref type="figure" coords="5,258.87,195.36,3.74,10.91" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental evaluation</head><p>Our model, developed in TensorFlow, is publicly available as a Jupyter Notebook on GitHub <ref type="foot" coords="5,501.04,252.22,3.71,7.97" target="#foot_3">5</ref> . The architecture of the CNN-based model used in our work is very similar to the one discussed in <ref type="bibr" coords="5,101.16,281.08,11.58,10.91" target="#b6">[7]</ref>. It is a shallow CNN compiled with a binary cross entropy loss function; this function calculates loss with respect to two classes (i.e., 0 and 1). Optimization is performed with an Adamic optimizer <ref type="bibr" coords="5,173.11,308.18,18.06,10.91" target="#b27">[28]</ref> after giving each batch of data as input. For each fold we trained the CNN for five epochs. That is motivated by the fact that some overfitting starts after the fifth epoch. We performed a binary search to find the optimal batch size. The model achieved the best overall accuracy with a batch size equal to 1. For the NB voter we use MultinomialNB from the scikit-learn package. The SVM voter uses a linear kernel with a C-value equal to 0.5. Finally for the DT classifier we set a random_state equal to 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">The dataset</head><p>The dataset provided by the PAN organizers consists of a set of 600 Twitter authors. For each author a set of 200 tweets is provided. A single XML file corresponds to an author and contains 200 tweets of the author. The labelled training set provided by the organizers contains 420 authors. The test set consists of the remaining 180 ones. Authors in the training set are labelled as "I" (ISS) or "NI" (nISS). Our final submission consists of a zip file containing predictions for each non-labelled author in the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results</head><p>The official metric used for the author profiling task at PAN@CLEF2022 is the accuracy. This metric is the same used in the rest of this section and defined in <ref type="bibr" coords="5,375.64,556.66,10.48,10.91" target="#b0">(1)</ref>.</p><formula xml:id="formula_0" coords="5,218.67,579.51,287.32,24.43">ùê¥ùëêùëêùë¢ùëüùëéùëêùë¶ = ùê∂ùëúùëüùëüùëíùëêùë°ùëÉ ùëüùëíùëëùëñùëêùë°ùëñùëúùëõùë† ùëá ùëúùë°ùëéùëôùëÉ ùëüùëíùëëùëñùëêùë°ùëñùëúùëõùë†<label>(1)</label></formula><p>Before performing the 5-fold cross validation we shuffled the 420 labelled samples and then we left out the last 40 samples as a labelled test set. In Table <ref type="table" coords="5,354.99,622.29,5.00,10.91" target="#tab_0">1</ref> are reported the results obtained by the single voters both on the test set and adopting a 5-fold cross validation on the labelled training set. In the table are reported the arithmetic mean and the standard deviation over the 5-folds. Table <ref type="table" coords="6,172.10,403.13,5.17,10.91" target="#tab_1">2</ref> reports the results of T100 on the validation set at each fold and on the labelled 40 samples we used as a test set. In terms of accuracy, each classifier used individually performs worse than T100. Furthermore, standard deviation of the single voters and of T100 is comparable on the validation sets. However, the standard deviation is equal to 0 on the test set for T100 and higher for the single voters. We performed several tests to investigate the best classifier as the very last predictor of T100. From Table <ref type="table" coords="6,142.22,484.43,5.07,10.91">3</ref> to Table <ref type="table" coords="6,188.52,484.43,5.07,10.91">5</ref> these results are reported.</p><p>How it is shown in the tables, the LR is consistent over different training fold, with a null standard deviation on the test set. In terms of consistency the Gradient Boosting Classifier performs similarly with a standard deviation of 0.010. However, results in term of binary accuracy are poor using Gradient Boosting Classifier as long as the other models tested.</p><p>Finally, we used the T100 trained at the fifth fold to generate the predictions on the official unlabelled test set provided by the organizers. As announced by the organizers, such a final version of our model is able to reach an accuracy of 0.9444 with respect to the official test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and future works</head><p>In this paper we have described our submitted model for our participation at the Profiling ISSs on Twitter task at PAN 2022. It consists of an ensemble, T100, trained on the predictions of a first layer of classifiers. To get consistent evaluation of the model performance, we run several </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5</head><p>Results achieved by a T100 ensemble using a Gradient Boosting Classifier at the final prediction stage.</p><p>5-fold cross validations for each different hyperparameter configurations. After finding the model achieving the highest accuracy during our cross validation tests, we train such a model on the best train fold to submit our predictions on the unlabelled test set.</p><p>In future works, we expect to evaluate performance of our model increasing the number and the diversity of the voter classifiers employed at the first prediction stage. A detailed error analysis on misclassified samples could lead to improved performance on the classification task proposed. Given the dimension of the dataset provided some techniques of data augmentation could be also used. Finally, some investigation on the content of each tweet could guide us in applying some techniques to remove not relevant features from the input samples, before training and testing our proposed model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,89.29,330.78,416.70,9.43;4,89.29,342.79,416.69,8.87;4,89.29,354.69,353.67,8.96;4,442.96,359.35,2.82,6.12;4,448.61,354.74,57.38,8.87;4,89.29,366.65,93.45,9.43;4,89.29,84.19,425.18,239.17"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The overall architecture of T100. The sample x ùëñ is the Twitter feed of the i-th author. The shallow CNN used in this work is built as discussed in [7]. Other classifiers are included into the scikit-learn package. LR uses the predictions provided by the voters to predict the label y ùëñ corresponding to the input sample x ùëñ .</figDesc><graphic coords="4,89.29,84.19,425.18,239.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,88.99,86.42,417.00,248.24"><head>Table 1</head><label>1</label><figDesc>Results in terms of accuracy achieved by each voter of T100 at each fold. Models are evaluated on the corresponding validation set at each fold and on the same test set. Performance of the classifiers at the first stage of T100 are lower compared to the ensemble model presented in this work. In the last two columns we report the values of the arithmetic mean and the standard deviation over the five folds.</figDesc><table coords="6,116.16,86.42,362.95,248.24"><row><cell cols="2">Voter Set</cell><cell></cell><cell></cell><cell>Fold Nr.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>AVG</cell><cell>ùúé</cell></row><row><cell>CNN</cell><cell>Val Test</cell><cell>0.8947 0.9000</cell><cell>0.8684 0.8750</cell><cell>0.9079 0.9250</cell><cell>0.8684 0.9250</cell><cell>0.8947 0.9500</cell><cell>0.8868 0.9150</cell><cell>0.0158 0.0255</cell></row><row><cell>NB</cell><cell>Val Test</cell><cell>0.8947 0.9000</cell><cell>0.8553 0.9000</cell><cell>0.8816 0.9000</cell><cell>0.8289 0.8750</cell><cell>0.8289 0.8750</cell><cell>0.8579 0.8900</cell><cell>0.0268 0.0122</cell></row><row><cell>SVM</cell><cell>Val Test</cell><cell>0.9210 0.8750</cell><cell>0.9342 0.8500</cell><cell>0.9079 0.8750</cell><cell>0.8816 0.8750</cell><cell>0.8947 0.8500</cell><cell>0.9079 0.8650</cell><cell>0.0186 0.0122</cell></row><row><cell>DT</cell><cell>Val Test</cell><cell>0.7368 0.7750</cell><cell>0.8421 0.8000</cell><cell>0.8684 0.7500</cell><cell>0.7631 0.8500</cell><cell>0.8816 0.8750</cell><cell>0.8184 0.8100</cell><cell>0.0579 0.0464</cell></row><row><cell cols="3">T100 -Logistic Regressor</cell><cell></cell><cell cols="2">Fold Nr.</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>AVG</cell><cell>ùúé</cell></row><row><cell>Val</cell><cell></cell><cell></cell><cell cols="7">0.9210 0.9342 0.9342 0.8553 0.9342 0.9158 0.0307</cell></row><row><cell>Test</cell><cell></cell><cell></cell><cell cols="7">0.9250 0.9250 0.9250 0.9250 0.9250 0.9250 0.0000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,88.99,343.61,417.00,32.83"><head>Table 2</head><label>2</label><figDesc>Results achieved by the model on a 5-fold cross validation on the training set provided. The results shown in the table are obtained using a Logistic Regressor as a final classifier of T100.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,88.99,86.42,390.79,233.56"><head>Table 4</head><label>4</label><figDesc>Results achieved by a T100 ensemble using a Random Forest at the final prediction stage.</figDesc><table coords="7,88.99,86.42,390.79,233.56"><row><cell>T100 -Decision Tree</cell><cell></cell><cell></cell><cell>Fold Nr.</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>AVG</cell><cell>ùúé</cell></row><row><cell>Val</cell><cell cols="7">0.8421 0.8158 0.8947 0.8421 0.8158 0.8421 0.0288</cell></row><row><cell>Test</cell><cell cols="7">0.9000 0.8000 0.8500 0.8250 0.8500 0.8450 0.0331</cell></row><row><cell>Table 3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">Results achieved by a T100 ensemble using a Decision Tree at the final prediction stage.</cell></row><row><cell>T100 -Random Forest</cell><cell></cell><cell></cell><cell>Fold Nr.</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>AVG</cell><cell>ùúé</cell></row><row><cell>Val</cell><cell cols="7">0.9079 0.9342 0.9210 0.8816 0.9210 0.9131 0.0178</cell></row><row><cell>Test</cell><cell cols="7">0.8750 0.9000 0.9000 0.8750 0.8750 0.8850 0.0122</cell></row><row><cell>T100 -Gradient Boosting</cell><cell></cell><cell></cell><cell>Fold Nr.</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>AVG</cell><cell>ùúé</cell></row><row><cell>Val</cell><cell cols="7">0.8816 0.9079 0.9210 0.8684 0.9210 0.9000 0.0214</cell></row><row><cell>Test</cell><cell cols="7">0.8750 0.8500 0.8500 0.8500 0.8500 0.8550 0.0100</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,108.93,649.09,147.05,8.97"><p>https://www.triumphmotorcycles.co.uk/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,108.93,660.05,248.93,8.97"><p>...that is text classification, not yet able to run at 100 MPH. Not yet...</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="4,108.93,671.03,109.69,8.97"><p>https://scikit-learn.org/stable/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="5,108.93,671.04,172.28,8.97"><p>https://github.com/marco-siino/T100-PAN2022</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We would like to thank anonymous reviewers for their comments and suggestions that have helped to improve the presentation of the paper.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CRediT Authorship Contribution Statement</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Online Resources</head><p>The source code of our model is available via ‚Ä¢ GitHub</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,111.28,394.53,10.91;8,112.66,124.83,395.17,10.91;8,112.66,138.38,393.32,10.91;8,112.66,151.93,395.01,10.91;8,112.66,165.48,394.53,10.91;8,112.66,179.03,395.17,10.91;8,112.66,192.57,393.33,10.91;8,112.33,206.12,353.19,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,251.61,138.38,254.37,10.91;8,112.66,151.93,258.70,10.91">Overview of PAN 2022: Authorship Verification, Profiling Irony and Stereotype Spreaders, and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ortega-Bueno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pezik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,233.97,179.03,273.86,10.91;8,112.66,192.57,393.33,10.91;8,112.33,206.12,27.32,10.91">Proceedings of the Thirteenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="8,246.47,207.14,146.73,9.72">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Barron-Cedeno</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">D S</forename><surname>Martino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Esposti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Pasi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Thirteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022. 2022</date>
			<biblScope unit="volume">13390</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="8,112.66,219.67,393.33,10.91;8,112.66,233.22,394.53,10.91;8,112.66,246.77,172.05,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,373.25,219.67,132.74,10.91;8,112.66,233.22,219.45,10.91">Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO) at PAN 2022</title>
		<author>
			<persName coords=""><forename type="first">O.-B</forename><surname>Reynier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Berta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Paolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Elisabetta</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,358.04,233.22,143.79,10.91">CLEF 2022 Labs and Workshops</title>
		<title level="s" coord="8,112.66,246.77,103.05,10.91">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,260.32,395.17,10.91;8,112.66,273.87,393.33,10.91;8,112.66,287.42,200.85,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,373.65,260.32,134.18,10.91;8,112.66,273.87,393.33,10.91;8,112.66,287.42,48.78,10.91">How do you speak about immigrants? taxonomy and stereoimmigrants dataset for identifying stereotypes about immigrants</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>S√°nchez-Junquera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">P</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,170.25,287.42,75.45,10.91">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">3610</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,300.97,393.33,10.91;8,112.66,314.52,359.73,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,368.12,300.97,137.87,10.91;8,112.66,314.52,116.34,10.91">Masking and bert-based models for stereotype identication</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>S√°nchez-Junquera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,237.20,314.52,161.40,10.91">Procesamiento del Lenguaje Natural</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="83" to="94" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,328.07,394.53,10.91;8,112.66,341.62,269.51,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,275.18,328.07,227.71,10.91">Irony detection via sentiment-based transfer learning</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,112.66,341.62,175.43,10.91">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="1633" to="1644" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,355.17,394.61,10.91;8,112.66,368.71,393.98,10.91;8,112.41,382.26,38.81,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,329.42,355.17,177.85,10.91;8,112.66,368.71,213.44,10.91">Figurative messages and affect in twitter: Differences between# irony,# sarcasm and# not</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sulis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">I H</forename><surname>Far√≠as</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ruffo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,335.87,368.71,121.71,10.91">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="132" to="143" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,395.81,393.33,10.91;8,112.66,409.36,393.32,10.91;8,112.33,422.91,258.17,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,345.70,395.81,160.29,10.91;8,112.66,409.36,163.64,10.91">Detection of hate speech spreaders using convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Di Nuovo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">La</forename><surname>Cascia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,299.96,409.36,206.03,10.91;8,112.33,422.91,66.45,10.91">PAN 2021 Profiling Hate Speech Spreaders on Twitter@ CLEF</title>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2021">2936. 2021</date>
			<biblScope unit="page" from="2126" to="2136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,436.46,393.33,10.91;8,112.66,450.01,394.53,10.91;8,112.39,463.56,243.38,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,345.21,436.46,160.78,10.91;8,112.66,450.01,243.15,10.91">Overview of the 8th author profiling task at pan 2020: Profiling fake news spreaders on twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">H H</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,376.55,450.01,126.02,10.91">CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Sun SITE Central Europe</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2696</biblScope>
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,477.11,386.41,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,159.51,477.11,244.37,10.91">Using n-grams to detect fake news spreaders on twitter</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pizarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,426.46,477.11,21.05,10.91">CLEF</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,490.66,393.61,10.91;8,112.66,504.21,209.15,10.91" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Buda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bolonyai</surname></persName>
		</author>
		<title level="m" coord="8,204.14,490.66,302.13,10.91;8,112.66,504.21,134.84,10.91">An ensemble model using n-grams and statistical features to identify fake news spreaders on twitter</title>
		<imprint>
			<publisher>CLEF</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,517.76,393.33,10.91;8,112.66,531.30,393.33,10.91;8,112.66,544.85,300.21,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,276.68,517.76,229.31,10.91;8,112.66,531.30,180.65,10.91">Courage at checkthat! 2022: Harmful tweet detection using graph neural networks and electra</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Lomonaco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Donabauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,316.04,531.30,189.95,10.91;8,112.66,544.85,204.09,10.91">Working Notes of CLEF 2022-Conference and Labs of the Evaluation Forum, CLEF &apos;2022</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,558.40,395.17,10.91;8,112.66,571.95,289.92,10.91" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Shahabi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.01926</idno>
		<title level="m" coord="8,252.12,558.40,255.71,10.91;8,112.66,571.95,107.88,10.91">Diffusion convolutional recurrent neural network: Datadriven traffic forecasting</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,585.50,395.17,10.91;8,112.66,599.05,395.17,10.91;8,112.66,612.60,394.52,10.91;8,112.66,626.15,90.72,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,261.82,585.50,246.02,10.91;8,112.66,599.05,277.34,10.91">Graph neural network (gnn) in image and video understanding using deep learning for computer vision applications</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pradhyumna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Shreya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,413.12,599.05,94.71,10.91;8,112.66,612.60,363.55,10.91">2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1183" to="1189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,639.70,393.73,10.91;8,112.66,653.25,393.33,10.91;8,112.66,666.80,272.03,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,279.25,639.70,227.14,10.91;8,112.66,653.25,235.00,10.91">Whosnext: Recommending twitter users to follow using a spreading activation network based approach</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>La Cascia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,371.10,653.25,134.89,10.91;8,112.66,666.80,166.48,10.91">2020 International Conference on Data Mining Workshops (ICDMW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="62" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,86.97,393.33,10.91;9,112.66,100.52,393.33,10.91;9,112.66,114.06,207.08,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,291.57,86.97,214.41,10.91;9,112.66,100.52,109.94,10.91">Detecting fake news using machine learning and deep learning algorithms</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Mahir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Akhter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Huq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,245.81,100.52,260.17,10.91;9,112.66,114.06,112.65,10.91">2019 7th International Conference on Smart Computing &amp; Communications (ICSCC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,127.61,393.32,10.91;9,112.66,141.16,393.32,10.91;9,112.66,154.71,256.47,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,333.97,127.61,172.01,10.91;9,112.66,141.16,192.37,10.91">Comparative performance of machine learning algorithms for fake news detection</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P S</forename><surname>Bali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Choubey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Goel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,327.91,141.16,178.07,10.91;9,112.66,154.71,126.10,10.91">International conference on advances in computing and data sciences</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="420" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,168.26,393.61,10.91;9,112.66,181.81,235.67,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,259.84,168.26,246.43,10.91;9,112.66,181.81,111.03,10.91">Automated classification of fake news spreaders to break the misinformation chain</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Leonardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rizzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Morisio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,232.08,181.81,53.51,10.91">Information</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">248</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,195.36,393.33,10.91;9,112.66,208.91,107.17,10.91" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.00885</idno>
		<title level="m" coord="9,189.55,195.36,236.40,10.91">Coaid: Covid-19 healthcare misinformation dataset</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,222.46,393.33,10.91;9,112.66,236.01,394.53,10.91;9,112.66,249.56,224.61,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="9,443.62,222.46,62.37,10.91;9,112.66,236.01,390.03,10.91">The impact of psycholinguistic patterns in discriminating between fake news spreaders and fact checkers</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>R√≠ssola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Oberski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,112.66,249.56,141.58,10.91">Data &amp; Knowledge Engineering</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="page">101960</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,263.11,393.33,10.91;9,112.66,276.66,393.33,10.91;9,112.66,290.20,221.05,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="9,253.78,263.11,252.21,10.91;9,112.66,276.66,82.93,10.91">Profiling Fake News Spreaders: Personality and Visual Information Matter</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cervero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,218.58,276.66,287.41,10.91;9,112.66,290.20,90.15,10.91">International Conference on Applications of Natural Language to Information Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="355" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,303.75,393.33,10.91;9,112.66,317.30,100.24,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="9,200.26,303.75,263.05,10.91">Sentiment classification using convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y.-S</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,471.48,303.75,34.51,10.91;9,112.66,317.30,37.51,10.91">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">2347</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,330.85,393.33,10.91;9,112.66,344.40,276.35,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="9,486.17,330.85,19.82,10.91;9,112.66,344.40,151.63,10.91">Text classification algorithms: A survey</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kowsari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Jafari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Meimandi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Heidarysafa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Mendu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,272.76,344.40,53.51,10.91">Information</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">150</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,357.95,393.33,10.91;9,112.66,371.50,395.17,10.91;9,112.66,385.05,394.53,10.91;9,112.28,398.60,216.04,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="9,280.44,357.95,225.55,10.91;9,112.66,371.50,352.53,10.91">McRock at SemEval-2022 Task 4: Patronizing and Condescending Language Detection using Multi-Channel CNN and DistilBERT</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>La Cascia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,488.58,371.50,19.25,10.91;9,112.66,385.05,389.70,10.91">Proceedings of the 16th International Workshop on Semantic Evaluation (SemEval-2022)</title>
		<meeting>the 16th International Workshop on Semantic Evaluation (SemEval-2022)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,412.15,395.17,10.91;9,112.66,425.70,244.76,10.91" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="9,223.22,412.15,247.47,10.91">Review of text classification methods on deep learning</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,480.36,412.15,27.47,10.91;9,112.66,425.70,150.68,10.91">CMC-Computers, Materials &amp; Continua</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="1309" to="1321" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,439.25,393.33,10.91;9,112.26,452.79,393.93,10.91;9,112.66,466.34,107.04,10.91" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="9,257.56,439.25,248.43,10.91;9,112.26,452.79,199.87,10.91">Classifying tweets using convolutional neural networks with multi-channel distributed representation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hashida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,320.53,452.79,185.66,10.91;9,112.66,466.34,33.25,10.91">IAENG International Journal of Computer Science</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="68" to="75" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,479.89,393.32,10.91;9,112.66,493.44,290.09,10.91" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="9,225.25,479.89,280.73,10.91;9,112.66,493.44,81.10,10.91">Feature normalization and likelihood-based similarity measures for image retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Aksoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,201.67,493.44,117.15,10.91">Pattern recognition letters</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="563" to="582" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,506.99,393.33,10.91;9,112.33,520.54,29.19,10.91" xml:id="b26">
	<monogr>
		<title level="m" type="main" coord="9,199.55,506.99,161.38,10.91">Normalization: A preprocessing stage</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Patro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">K</forename><surname>Sahu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.06462</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,534.09,395.01,10.91" xml:id="b27">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m" coord="9,227.57,534.09,157.91,10.91">A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
