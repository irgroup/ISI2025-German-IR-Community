<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,409.95,15.42;1,89.29,106.66,285.72,15.42">Profiling Irony and Stereotype Spreaders on Twitter: PAN Shared Task (IROSTEREO) 2022</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,88.87,134.97,128.53,11.96"><forename type="first">Álvaro</forename><surname>Rodríguez Sánchez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Student at the Master&apos;s Degree in Artificial Intelligence, Pattern Recognition and Digital Imaging</orgName>
								<orgName type="department" key="dep2">Department of Computer Systems and Computation (DSIC)</orgName>
								<orgName type="institution">Polytechnic University of Valencia (UPV)</orgName>
								<address>
									<settlement>Valencia</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,230.05,134.97,119.13,11.96"><forename type="first">Martín</forename><surname>Barroso Ordóñez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Student at the Master&apos;s Degree in Artificial Intelligence, Pattern Recognition and Digital Imaging</orgName>
								<orgName type="department" key="dep2">Department of Computer Systems and Computation (DSIC)</orgName>
								<orgName type="institution">Polytechnic University of Valencia (UPV)</orgName>
								<address>
									<settlement>Valencia</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,409.95,15.42;1,89.29,106.66,285.72,15.42">Profiling Irony and Stereotype Spreaders on Twitter: PAN Shared Task (IROSTEREO) 2022</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">B574FD86BC26D2E46A2003FA6C8ED063</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Author profiling</term>
					<term>Irony detection</term>
					<term>Twitter</term>
					<term>Natural language processing</term>
					<term>Sentence embeddings</term>
					<term>BERT</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present our solution to the problem proposed by IROSTEREO's PAN Shared Task in 2022. It proposes the detection of irony and stereotype spreaders on Twitter. Throughout the memory, we will show how through: the technique based on neural networks for the pre-training of natural language processing such as BERT, the use of sentence embeddings, and two alternatives to put them together; it will be achieved from a set of tweets associated with a set of authors, predict whether an author is ironic or not. Lastly, it will be presented a model that achieves high accuracy and with which finally participated in the competition.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In this paper, we present our participation in the task proposed by the PAN in the year 2022 <ref type="bibr" coords="1,89.29,392.37,12.88,10.91" target="#b0">[1]</ref>  <ref type="bibr" coords="1,104.90,392.37,11.47,10.91" target="#b1">[2]</ref>. This task, Profiling Irony and Stereotype Spreaders on Twitter, as well as some others <ref type="bibr" coords="1,89.29,405.92,11.35,10.91" target="#b2">[3]</ref>, proposes the objective of determining whether an author is ironic or not by re-collecting a series of tweets associated with him/her. This challenge has been addressed by creating several models based on Machine Learning and Natural Language Processing techniques.</p><p>For the past few years, Author profiling has become highly relevant due to its potential applications <ref type="bibr" coords="1,124.39,464.48,11.58,10.91" target="#b3">[4]</ref>, for example, in forensic linguistic studies, marketing analysis and verification of authorship of historical/literary texts. The aim of author profiling is to automatically extract demographic characteristics of the author of a text, such as gender, age, mother tongue or sexual orientation. Nowadays, there are some Author profiling related to irony, for example, the detection of irony and humor from social networks <ref type="bibr" coords="1,233.59,532.23,11.28,10.91" target="#b4">[5]</ref>, where a series of components that are the key to achieving their automatic processing are identified; finally, it is possible to relate that humorous texts are certainly positive, while ironic texts tend to be a bit more threatening. Nevertheless, there are sometimes that one of the concepts may have the characteristics of the other; this is why this task is so intriguing.</p><p>The following sections present the procedure and strategies that have been carried out and the different experiments that have been performed to reach a final model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Dataset</head><p>The data, for creating the first models, is located inside a folder, it contains 420 XML files, each of them referring to different authors; these authors are represented with an id. Each XML file is composed of 200 tweets from the author, these are in the English language. A truth.txt file is also provided which contains the tag associated with each author, this tag can be I if the author is ironic, or NI if the author is not ironic.</p><p>After performing the different experiments with the previous dataset, we were provided with a test dataset, which consists of 180 authors with 200 tweets each. Unlike the previous dataset, this one does not contain the truth.txt, since this is the one that will be taken into account to be evaluated by the contest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed solution</head><p>It has been proposed to solve this problem by using Machine Learning based models and without the use of a pre-processing, as the tweets are already pre-processed. Firstly, the sentence embedding representation is going to be used through BERT <ref type="bibr" coords="2,397.19,311.27,11.28,10.91" target="#b5">[6]</ref>, during this process 2 alternatives were chosen:</p><p>• Average the 200 tweets of each author just before passing them through BERT, i.e., having applied all the necessary pre-processes to be able to enter them in BERT (this representation is shown in Figure <ref type="figure" coords="2,267.44,374.22,5.02,10.91" target="#fig_1">1</ref> as the Model Input), all the 200 tweets are converted into array (Word2vec), then applied a padding and mask for each tweet to make all the same length and finally average all the 200 tweets into a final average vector. Once this average is obtained, pass it through BERT to subsequently use the result as a representation of that author. • Pass every single tweet of each author through BERT and average the sentence embeddings obtained from BERT of all the tweets associated with each author to obtain a final sentence embedding per author that describes it.</p><p>After obtaining a sentence embedding for each of the authors (with either of the two methods), we will proceed to the training of a classical model. In our case, we have chosen to use the sklearn library, which offers a set of classical models; we will pass these sentence embeddings and the associated author label to these models for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>This section shows the results, using accuracy as a metric, of both methods presented in the previous section for different classical classifiers. The classifiers that have been used are the SVM<ref type="foot" coords="2,110.61,623.18,3.71,7.97" target="#foot_0">1</ref> , MLP 2 , GaussianNB and RandomForest. It is important to note that all experiments have been performed using 10-fold cross-validation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Pre-BERT average embeddings method</head><p>The best result obtained from each of the classifiers and the value of their hyperparameters are shown below. As shown in Table <ref type="table" coords="3,176.31,469.67,3.81,10.91" target="#tab_0">1</ref>, the model with the highest accuracy is the MLP model when 3 hidden layers are incorporated between the input and output layers. Despite this, the accuracy value obtained is not entirely promising, since accuracy of 0.64286 in the classification of 2 different classes is not a very optimistic value. In the following method, the strategy implemented in this method will be improved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Post average embeddings method</head><p>The best result obtained from each of the pre-trained models used, the best classifier obtained with each one, and the value of its hyperparameters are shown below.</p><p>As we can see in Table <ref type="table" coords="3,189.54,606.67,4.97,10.91" target="#tab_1">2</ref> , we got a great improvement in the results achieved by averaging after (and not before) putting the data into the pre-training model. The best performer was given by the Multilingual Universal Sentence Encoder, although the difference is not significant. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Final model and conclusion</head><p>Finally, we have to train a final model with all the data with the characteristics that we have seen that have performed best in the experiments. In order not to over-fit we are going to put only a few iterations, 250, since we have observed that if we do more we easily reach 100% accuracy in the training samples, which is not desirable. So we have trained a final MLP with 4, 64, and 32 hidden units for 250 iterations that receive as input the averaged embeddings of a user's tweets that have been taken as input from the MUSE.</p><p>In the first submission to the TIRA platform <ref type="bibr" coords="4,289.27,297.43,12.91,10.91" target="#b6">[7]</ref> the test dataset predictions were uploaded in the requested XML format; an accuracy of 0.9556 was achieved.</p><p>As shown throughout the experiments and results, the use of MUSE together with an MLP has proven to be the most successful case for maximizing accuracy and detecting the presence of irony or non-irony of an author within a set of tweets associated with him/her.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,89.29,638.77,333.02,7.99;1,100.50,649.07,264.78,8.97"><head>CLEF 2022 :</head><label>2022</label><figDesc>Conference and Labs of the Evaluation Forum, September 5-8, 2022, Bologna, Italy alrodsa2@inf.upv.es ( R. Sánchez); marbaro1@inf.upv.es (M. B. Ordóñez)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,89.29,269.59,295.37,8.93;3,127.56,84.19,340.15,172.83"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Tweet to sentence embedding conversion process using BERT.</figDesc><graphic coords="3,127.56,84.19,340.15,172.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.98,363.75,381.11,86.95"><head>Table 1</head><label>1</label><figDesc>Accuracies of the best classifiers in the Pre-BERT method.</figDesc><table coords="3,125.18,363.75,344.92,57.15"><row><cell>Classifier</cell><cell>Hyperparameters</cell><cell>Accuracy</cell></row><row><cell>SVM</cell><cell>C=0.0001</cell><cell>0.53809</cell></row><row><cell>MLP</cell><cell>hl1=128, hl2=64, hl3=32</cell><cell>0.64286</cell></row><row><cell>GaussianNB</cell><cell>smoothing=0.0001</cell><cell>0.63095</cell></row><row><cell cols="3">RandomForest max_depth=10, n_estimators=100, max_features=50 0.64248</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.98,86.37,326.81,75.00"><head>Table 2</head><label>2</label><figDesc>Accuracies of the best classifiers in the Post-BERT method.</figDesc><table coords="4,179.48,86.37,236.31,45.19"><row><cell>Classifier</cell><cell>Hyperparameters</cell><cell>Accuracy</cell></row><row><cell cols="3">BERT MLP hl1=32, hl2=32, hl3=16 0.933</cell></row><row><cell>Distill BERT SVM</cell><cell>C=21</cell><cell>0.933</cell></row><row><cell cols="3">MUSE MLP hl1=4, hl2=64, hl3=32 0.935</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,108.93,660.08,88.96,8.97"><p>Support Vector Machine</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,107.59,111.28,398.40,10.91;5,107.59,124.83,399.60,10.91;5,107.59,138.38,172.05,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,371.48,111.28,134.50,10.91;5,107.59,124.83,221.38,10.91">Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO) at PAN 2022</title>
		<author>
			<persName coords=""><forename type="first">O.-B</forename><surname>Reynier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Berta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Paolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Elisabetta</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="5,356.76,124.83,145.06,10.91">CLEF 2022 Labs and Workshops</title>
		<title level="s" coord="5,107.59,138.38,103.05,10.91">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,107.59,151.93,400.25,10.91;5,107.59,165.48,399.60,10.91;5,107.59,179.03,398.69,10.91;5,107.59,192.57,400.08,10.91;5,107.59,206.12,398.40,10.91;5,107.59,219.67,398.40,10.91;5,107.59,233.22,398.40,10.91;5,107.59,246.77,181.05,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,218.54,179.03,287.73,10.91;5,107.59,192.57,248.22,10.91">Overview of PAN 2022: Authorship Verification, Profiling Irony and Stereotype Spreaders, and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ortega-Bueno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pezik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,445.80,206.12,60.19,10.91;5,107.59,219.67,398.40,10.91;5,107.59,233.22,257.15,10.91">Proceedings of the Thirteenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="5,473.78,234.24,32.20,9.72;5,107.59,247.79,112.43,9.72">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">D E F S C M G P A H M P G F N F</forename><surname>Alberto Barron-Cedeno</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Giovanni</forename><surname>Da San</surname></persName>
		</editor>
		<editor>
			<persName><surname>Martino</surname></persName>
		</editor>
		<meeting>the Thirteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13390</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="5,107.59,260.32,400.25,10.91;5,107.59,273.87,400.08,10.91;5,107.18,287.42,175.84,10.91" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="5,348.28,260.32,159.55,10.91;5,107.59,273.87,211.46,10.91">A survey on author profiling, deception, and irony detection for the arabic language</title>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H F L C W Z A C</forename><surname>Paolo Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><surname>Rangel</surname></persName>
		</author>
		<idno type="DOI">10.1111/lnc3.12275</idno>
		<ptr target="https://compass.onlinelibrary.wiley.com.doi:10.1111/lnc3.12275" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,107.59,300.97,398.40,10.91;5,107.59,314.52,400.24,10.91;5,107.59,328.07,399.60,10.91;5,107.59,341.62,257.32,10.91" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wanner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Soler</surname></persName>
		</author>
		<ptr target="http://hdl.handle.net/10803/404984" />
		<title level="m" coord="5,201.30,300.97,304.69,10.91;5,107.59,314.52,151.36,10.91">Feature engineering for author profiling and identification: on the relevance of syntax and discourse</title>
		<imprint>
			<publisher>Departament de Tecnologies de la Informació i les Comunicacions</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
		<respStmt>
			<orgName>Universitat Pompeu Fabra</orgName>
		</respStmt>
	</monogr>
	<note>applications of Natural Language to Information Systems</note>
</biblStruct>

<biblStruct coords="5,107.59,355.17,400.24,10.91;5,107.59,368.71,399.68,10.91;5,107.59,382.26,402.55,10.91;5,107.59,395.81,398.40,10.91;5,107.59,409.36,38.76,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,261.75,355.17,246.07,10.91;5,107.59,368.71,148.14,10.91">From humor recognition to irony detection: The figurative language of social media</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Buscaldi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.datak.2012.02.005</idno>
		<ptr target="https://doi.org/10.1016/j.datak.2012.02.005" />
	</analytic>
	<monogr>
		<title level="j" coord="5,268.65,368.71,139.47,10.91">Data Knowledge Engineering</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>applications of Natural Language to Information Systems</note>
</biblStruct>

<biblStruct coords="5,107.59,422.91,398.40,10.91;5,107.59,436.46,400.08,10.91;5,107.59,450.01,167.31,10.91" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="5,351.81,422.91,154.18,10.91;5,107.59,436.46,189.33,10.91">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1810.04805</idno>
		<ptr target="https://arxiv.org/abs/1810.04805.doi:10.48550/ARXIV.1810.04805" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,107.59,463.56,399.60,10.91;5,107.59,477.11,398.40,10.91;5,107.59,490.66,399.59,10.91;5,107.59,506.65,123.08,7.90" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,326.42,463.56,176.17,10.91">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-22948-1_5</idno>
	</analytic>
	<monogr>
		<title level="m" coord="5,237.51,477.11,268.48,10.91;5,107.59,490.66,125.79,10.91">Information Retrieval Evaluation in a Changing World, The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
