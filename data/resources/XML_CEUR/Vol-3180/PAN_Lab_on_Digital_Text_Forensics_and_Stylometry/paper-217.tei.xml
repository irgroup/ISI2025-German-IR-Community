<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,416.60,15.42;1,89.29,106.66,55.66,15.43;1,89.29,129.00,371.69,11.96">Irony &amp; Stereotype Spreader Detection using Random Forests Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO) PAN2022</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,88.93,154.90,57.55,11.96"><forename type="first">Tiago</forename><surname>Filipe</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Nordic Studies and Linguistics (NorS)</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<addrLine>Nørregade 10</addrLine>
									<postCode>1165</postCode>
									<settlement>København</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,149.47,154.90,67.34,11.96"><forename type="first">Nunes</forename><surname>Ribeiro</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Nordic Studies and Linguistics (NorS)</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<addrLine>Nørregade 10</addrLine>
									<postCode>1165</postCode>
									<settlement>København</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,227.53,154.90,122.08,11.96"><forename type="first">Yana</forename><forename type="middle">Nikolaeva</forename><surname>Nikolova</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Nordic Studies and Linguistics (NorS)</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<addrLine>Nørregade 10</addrLine>
									<postCode>1165</postCode>
									<settlement>København</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,376.92,154.90,73.04,11.96"><forename type="first">Kaja</forename><surname>Seraphina</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Nordic Studies and Linguistics (NorS)</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<addrLine>Nørregade 10</addrLine>
									<postCode>1165</postCode>
									<settlement>København</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,452.94,154.90,52.55,11.96"><forename type="first">Elisa</forename><surname>Hano</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Nordic Studies and Linguistics (NorS)</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<addrLine>Nørregade 10</addrLine>
									<postCode>1165</postCode>
									<settlement>København</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,416.60,15.42;1,89.29,106.66,55.66,15.43;1,89.29,129.00,371.69,11.96">Irony &amp; Stereotype Spreader Detection using Random Forests Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO) PAN2022</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">30B4E17DCF5B12CD619E0EFCC338EDC8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>irony detection</term>
					<term>classification</term>
					<term>random forest</term>
					<term>Twitter</term>
					<term>PAN</term>
					<term>IROSTEREO</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a model for classifying irony and stereotype spreaders on Twitter based on the dataset provided for the PAN2022 task IROSTEREO for this purpose. We take a feature engineering approach focusing on lexical and stylistic features and improve on the character n-gram baseline F1-score by 9% on cross-validation. Of the classification algorithms considered, we find that the Random Forest classifier performs the best, achieving a final F1-score of 96.04% with a 70/30 split on the train set and a final accuracy of 95.56% on the test data provided by PAN.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This project aims to solve the task presented at PAN2022 <ref type="bibr" coords="1,343.63,377.54,15.55,10.91" target="#b0">[1]</ref>, Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO) 2022 1 , which consists of classifying authors as irony and stereotype spreaders given a set of English tweets. Because irony is employed "to mean the opposite to what is literally stated", per the task authors, it can be used to scorn or stereotype vulnerable groups in ways that avoid conventional moderation techniques <ref type="bibr" coords="1,413.94,431.74,11.28,10.91" target="#b1">[2]</ref>. Identifying irony and stereotype spreaders could help improve the identification of hate speech and cyberbullying for moderation purposes <ref type="bibr" coords="1,205.99,458.83,11.48,10.91" target="#b2">[3,</ref><ref type="bibr" coords="1,220.84,458.83,9.03,10.91" target="#b3">4]</ref> and contribute to the problem of disambiguation in natural language processing <ref type="bibr" coords="1,183.90,472.38,11.44,10.91" target="#b4">[5,</ref><ref type="bibr" coords="1,198.07,472.38,7.63,10.91" target="#b5">6]</ref>. Our code is available on GitHub 2 . The results were submitted via the TIRA platform <ref type="bibr" coords="1,172.05,485.93,12.68,10.91" target="#b6">[7]</ref> and the overview paper detailing all the systems used for this task can be found at <ref type="bibr" coords="1,129.28,499.48,11.43,10.91" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Irony and sarcasm</head><p>The most common definition of verbal irony centers on the incongruity of the literal and intended meaning of an utterance <ref type="bibr" coords="1,239.18,592.63,11.23,10.91" target="#b4">[5,</ref><ref type="bibr" coords="1,253.01,592.63,8.88,10.91" target="#b8">9]</ref> for the purpose of expressing i.a. humor, sophistication, group affiliation or retractability <ref type="bibr" coords="2,236.48,86.97,11.43,10.91" target="#b8">[9]</ref>.</p><p>The task authors, as well as some previous research <ref type="bibr" coords="2,325.65,100.52,11.28,10.91" target="#b5">[6]</ref>, identify sarcasm as a more aggressive and bitter subset of irony, even though the task does not require distinguishing between the two in classification. However, we can assume that irony in conjunction with stereotypes will often have a ridiculing and aggressive attitude towards the stereotyped groups and thus qualify as sarcasm. In this paper, we consider methods and previous work related to both irony and sarcasm detection without distinction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Irony and Sarcasm Detection</head><p>Despite the complexity of irony and sarcasm as linguistic phenomena, a large variety of methods have been developed to solve classification and disambiguation tasks related to them.</p><p>In their survey of sarcasm detection methods, <ref type="bibr" coords="2,297.76,245.09,12.69,10.91" target="#b5">[6]</ref> distinguish two main types of methods. Rulebased methods identify indicators of sarcasm, for example hashtag sentiment <ref type="bibr" coords="2,438.99,258.64,16.35,10.91" target="#b9">[10]</ref>, particular phrases <ref type="bibr" coords="2,124.66,272.19,17.76,10.91" target="#b10">[11]</ref> or situation phrases containing words with an incongruous sentiment <ref type="bibr" coords="2,446.71,272.19,11.27,10.91" target="#b5">[6]</ref>. Using the latter approach, <ref type="bibr" coords="2,160.81,285.73,17.75,10.91" target="#b11">[12]</ref> achieve a high F1-score of 0.90, but their method requires computationally intensive parsing and a more precise distinction between subtypes of irony and sarcasm.</p><p>More popular are feature-based approaches using supervised learning algorithms <ref type="bibr" coords="2,469.85,312.83,11.55,10.91" target="#b5">[6]</ref>. The literature attests to a wide variety of features. Bag-of-Words n-gram representations are most common for representing lexical information and some degree of context in irony detection <ref type="bibr" coords="2,89.29,353.48,16.56,10.91" target="#b12">[13,</ref><ref type="bibr" coords="2,109.18,353.48,12.42,10.91" target="#b13">14]</ref>, although recently probabilistic language models have also been used to this effect <ref type="bibr" coords="2,89.29,367.03,16.41,10.91" target="#b14">[15]</ref>. This lexical base is usually supplemented with a variety of stylistic features relating to punctuation, emoji and hashtag use, as well as general stylistic features like type-token ratios and average word lengths <ref type="bibr" coords="2,239.85,394.13,11.48,10.91" target="#b5">[6,</ref><ref type="bibr" coords="2,254.53,394.13,12.59,10.91" target="#b14">15,</ref><ref type="bibr" coords="2,270.32,394.13,12.42,10.91" target="#b15">16]</ref>. Features related to POS-tags, affective features, and polarity contrast are also common <ref type="bibr" coords="2,264.21,407.68,11.38,10.91" target="#b5">[6,</ref><ref type="bibr" coords="2,278.30,407.68,12.55,10.91" target="#b16">17,</ref><ref type="bibr" coords="2,293.57,407.68,12.34,10.91" target="#b17">18]</ref>. Word embeddings are the most widespread technique for encoding semantic similarity, particularly in deep-learning approaches, which have been gaining traction in the field <ref type="bibr" coords="2,261.73,434.78,16.43,10.91" target="#b18">[19,</ref><ref type="bibr" coords="2,280.89,434.78,12.32,10.91" target="#b19">20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Challenges</head><p>Identifying irony in textual media, and especially in microblog formats like tweets, is a difficult task because the incongruity it exploits is often contextual and paralinguistic in nature <ref type="bibr" coords="2,492.22,498.05,11.58,10.91" target="#b5">[6]</ref>. For example, What lovely weather may be an ironic utterance in a downpour, but it is not immediately identifiable as such in isolation <ref type="bibr" coords="2,294.16,525.15,16.42,10.91" target="#b20">[21]</ref>. In recent years, researchers have tried to incorporate topical and conversational context, in particular when dealing with data from social media or forums, into irony detection to improve classification <ref type="bibr" coords="2,409.67,552.25,11.58,10.91" target="#b5">[6]</ref>. This could be an incorporation of previous replies as a feature <ref type="bibr" coords="2,291.29,565.80,16.41,10.91" target="#b17">[18,</ref><ref type="bibr" coords="2,310.42,565.80,14.02,10.91" target="#b21">22]</ref> or identifying topics that are most likely to elicit sarcasm <ref type="bibr" coords="2,163.94,579.35,16.25,10.91" target="#b22">[23]</ref>.</p><p>Another issue is that many markers of irony in spoken language, like pitch, nasalization and other spectral markers <ref type="bibr" coords="2,189.43,606.45,11.23,10.91" target="#b8">[9,</ref><ref type="bibr" coords="2,202.95,606.45,12.23,10.91" target="#b23">24]</ref>, are not available in a textual modality. Punctuation, capitalization and emoji usage have been used as textual correlates of such markers <ref type="bibr" coords="2,414.23,619.99,16.56,10.91" target="#b14">[15,</ref><ref type="bibr" coords="2,434.16,619.99,12.42,10.91" target="#b24">25]</ref>. Contextual information, as described above, can also be used to compensate for "missing" irony cues in a text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Twitter as Data Source</head><p>Twitter is one of the most popular data sources in the field of irony and sarcasm detection <ref type="bibr" coords="3,89.29,121.08,11.39,10.91" target="#b5">[6,</ref><ref type="bibr" coords="3,103.41,121.08,12.56,10.91" target="#b22">23,</ref><ref type="bibr" coords="3,118.69,121.08,12.35,10.91" target="#b24">25]</ref>. The size of the social media platform, combined with the short format of the posts and its easy-to-use API makes it an obvious choice for this type of research.</p><p>The most common and efficient way of annotating tweets for classification tasks is by scraping based on #sarcasm and #irony hashtags <ref type="bibr" coords="3,300.71,161.73,11.23,10.91" target="#b4">[5,</ref><ref type="bibr" coords="3,314.44,161.73,13.95,10.91" target="#b13">14]</ref> and assuming un-tagged tweets are nonironic/sarcastic. This method has obvious downsides and tends to produce non-representative datasets that are easier to categorize than manually annotated tweet sets <ref type="bibr" coords="3,419.67,188.83,11.54,10.91" target="#b5">[6]</ref>. We assume the data used in the present study are manually annotated, so we might expect lower performance than we see in the literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Data</head><p>The data provided by PAN consists of 420 XML files, where each file is named for the user ID and contains 200 tweets. The tweets are anonymized, so hashtag, user and URL information is replaced by generic tags. Another file contains the author IDs and the ground truth labelseither I (ironic) or NI (non-ironic). The dataset is balanced. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Challenges of Data</head><p>In manual irony annotation of tweets, <ref type="bibr" coords="3,264.35,552.25,18.07,10.91" target="#b14">[15]</ref> found that among ironic tweets realized through polarity contrast (71% of all ironic tweets), half were only identifiable as such by hashtag use. This means that the absence of hashtags in the data will likely increase the difficulty of the task (see also <ref type="bibr" coords="3,129.24,592.90,17.91,10.91" target="#b9">[10]</ref> on hashtag-based classification).</p><p>Another limitation of the dataset is the fact that we have no way of accessing conversational context for reply tweets, which has been shown to be significant for identifying irony <ref type="bibr" coords="3,472.13,620.00,16.41,10.91" target="#b17">[18,</ref><ref type="bibr" coords="3,491.25,620.00,12.31,10.91" target="#b21">22]</ref>. Single tweets and reply tweets are treated the same in the dataset, even though we might expect that irony would function differently for them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Data Pre-Processing</head><p>Our pre-processing methods are dependent on which features are being generated. However, for most features, we remove the generic hashtag, user and URL tags from the tweets before processing them. These are then tokenized by the TweetTokenizer provided by NLTK <ref type="foot" coords="4,467.03,132.88,3.71,7.97" target="#foot_0">3</ref> . This is optimized to capture smileys and long words which are not standard English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Features</head><p>We took a feature engineering approach to the task, as such approaches have yielded good results in the past <ref type="bibr" coords="4,174.43,220.36,11.48,10.91" target="#b5">[6,</ref><ref type="bibr" coords="4,189.11,220.36,14.11,10.91" target="#b24">25]</ref> and have the benefit of being more interpretable than end-to-end embedding approaches. We explain how the features were generated and our hypotheses about how they might contribute to distinguishing ironic and non-ironic users.</p><p>We divide this section into two sub-sections, the first detailing the features used in the final model as in Fig. <ref type="figure" coords="4,160.32,274.56,4.01,10.91" target="#fig_1">2</ref>, and the second describing the features we experimented with but decided against using as part of the final feature vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Model Features</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">Stylistic Features</head><p>Our first approach was centered around creating features that represent the profile's style. To do this, we perform simple counts on each author's output, which are then divided by the total number of tweets by the author (200 in this task). We generated the features displayed in Table <ref type="table" coords="4,89.04,399.05,3.74,10.91">1</ref>.</p><p>The intuition behind these features is to portray some of the main trends between the userprofiles. <ref type="bibr" coords="4,127.84,426.15,17.85,10.91" target="#b24">[25]</ref> argue that due to character limit restraints ironic tweets might achieve their goal by creative use of fewer words. We also believe that ironic users might use shorter replies and abbreviations to express irony. Structural features have also been used before in similar tasks <ref type="bibr" coords="4,89.29,466.79,16.22,10.91" target="#b24">[25]</ref>. All hashtags and Twitter handles have been replaced by generic markers in our data, but previous studies have found that hashtag use is connected to sarcasm <ref type="bibr" coords="4,398.33,480.34,16.18,10.91" target="#b14">[15]</ref>, so we believe these counts would still be relevant for this task <ref type="bibr" coords="4,279.25,493.89,11.43,10.91" target="#b5">[6]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">LiX Score</head><p>LiX is a readability score developed in Sweden by <ref type="bibr" coords="5,313.94,107.54,17.98,10.91" target="#b25">[26]</ref> that uses a combination of a word and sentence factors to measure text complexity. LiX is calculated by the following formula:</p><formula xml:id="formula_0" coords="5,196.24,145.59,202.81,11.51">LiX = (%𝑁 𝐿𝑜𝑛𝑔𝑊 𝑜𝑟𝑑𝑠 ) + (𝑁 𝑤𝑜𝑟𝑑𝑠 /𝑁 𝑠𝑒𝑛𝑡𝑒𝑛𝑐𝑒 )</formula><p>We have set the threshold for long words at 𝑡 = 7, following <ref type="bibr" coords="5,369.76,170.10,16.17,10.91" target="#b26">[27]</ref>, and we count the number of sentences by using a regular expression to find punctuation followed by a space or a new line:</p><formula xml:id="formula_1" coords="5,208.62,213.19,178.04,7.90">[ ]+[.;?!]|[.;?!][ ]+|[.;?!]\n</formula><p>While there might be a risk of underestimating the number of sentences, we obtain the following LiX statistics on our dataset: 𝜇 = 33.3; 𝜎 = 6.3; 𝑚𝑎𝑥 = 61.6; 𝑚𝑖𝑛 = 16.7. The mean corresponds to a 7th-grade lexical complexity, which seems adequate for a social media with a microblog format.</p><p>Our intention with this metric, similar to the stylistic features, is to model that ironic profiles might use less complex vocabulary to reach a wider audience with an easier-to-understand tone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3.">TF-IDF Unigrams</head><p>Words frequencies have been used to model sarcasm <ref type="bibr" coords="5,326.17,361.40,11.45,10.91" target="#b5">[6]</ref>, and it makes intuitive sense that the use of certain words might be indicative of irony. To model this problem, we implemented the Term-Frequency-Inverted-Document-Frequency (TF-IDF) statistic.</p><p>TF-IDF is based on the intuition that tokens which are rare in a corpus might contain more information if they appear in higher counts in a specific document. For this task, we implemented a parameter to allow switching between an author's whole output or a single tweet as a document. For the final feature vector, we used single tweets as documents and our entire training data as a corpus, as we found this improved performance relative to using author documents.</p><p>There are different approaches to TF-IDF when it comes to normalizing term frequency (TF). In our implementation, we use the 𝑙𝑜𝑔 2 scale, which means that eventually more counts contribute less and less.</p><p>IDF is calculated by first creating an encoding vector, where each position corresponds to a term in the corpus. We count in how many documents of the corpus each term occurs. We then can calculate the idf vector:</p><formula xml:id="formula_2" coords="5,258.77,562.82,243.36,26.48">𝑖𝑑𝑓 = 𝑙𝑜𝑔 2 (︂ 𝑁 𝑛 𝑡 )︂ (<label>1</label></formula><formula xml:id="formula_3" coords="5,502.13,570.46,3.86,10.91">)</formula><p>where 𝑁 is the number of documents and 𝑛 𝑡 is the number of documents where 𝑡 occurs. Note that we don't smooth out the division, as we only consider terms that are present in the corpus. The term tf is calculated by counting the number of terms which are present in the 𝑖𝑑𝑓 vector of size 𝑚 for each tweet, and this is saved into a matrix of size 𝑑𝑜𝑐𝑢𝑚𝑒𝑛𝑡𝑠 × 𝑚. We then want to ensure that terms are scaled to a logarithmic scale, and to do this we perform the following operation on the matrix:</p><formula xml:id="formula_4" coords="6,242.24,98.72,263.75,30.93">{︃ 0, 𝑡𝑓 = 0 1 + 𝑙𝑜𝑔 2 (𝑡𝑓 ), 𝑡𝑓 &gt; 0 (2)</formula><p>We then multiply each of the document vectors by the 𝑖𝑑𝑓 to obtain the final tf-idf vector for a specific author. In the case of using tweets as a document, we obtain the average tweet tf-idf vector for each author. We also use this methodology for profanity and emojis. For the profanity TF-IDF, we lowercase all the tweets and stem the words to match the same root, while for unigram TF-IDF we simply lowercase and remove any hashtags in the set. As the resulting vector is the size of corpus vocab, ≈ 77162, we decided to reduce the dimensionality using PCA, to capture the main variance in the TF-IDF vectors in the first 20 components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4.">TF-IDF Profanity</head><p>Some of the earliest works on irony detection <ref type="bibr" coords="6,295.76,269.01,17.95,10.91" target="#b27">[28]</ref> used the presence of profanity as a feature to identify irony in news headlines, and research has since shown that online communities use profanity in different ways and could be used to distinguish them <ref type="bibr" coords="6,417.87,296.11,16.41,10.91" target="#b28">[29]</ref>. Therefore we hypothesized that profanity use might also be different for ironic and non-ironic users, for example in the frequency and types of words used.</p><p>We implemented this feature based on a profanity list on GitHub<ref type="foot" coords="6,376.11,335.00,3.71,7.97" target="#foot_1">4</ref> with 2864 words. We created TF-IDF vectors for the data and reduced dimensionality via PCA to 14 principal components. The data was pre-processed with tokenizing and stemming before creating the count vectors, as our profanity list only contained lemmas.</p><p>This feature obviously overlaps with TF-IDF unigrams, which also counts profanity along with all other words, but we hoped that isolating this lexical group might help us find patterns that would otherwise be lost in the unigram TF-IDF features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.5.">TF-IDF Emojis</head><p>Face with tears of joy, the most popular emoji in our dataset with 1497 counts, was considered the "word of the year" in 2015 by the Oxford dictionary. It's no secret that emojis are used and are now commonplace in social media, and the research community has investigated these to evaluate their usefulness for classifiers or the meanings they encode <ref type="bibr" coords="6,403.59,508.03,16.55,10.91" target="#b29">[30,</ref><ref type="bibr" coords="6,423.13,508.03,12.59,10.91" target="#b30">31,</ref><ref type="bibr" coords="6,438.72,508.03,12.42,10.91" target="#b31">32]</ref>. <ref type="bibr" coords="6,459.25,508.03,18.07,10.91" target="#b31">[32]</ref> argue that some emojis might be redundant as they are just repeating the meaning of the message, while others might be replacing a word or a POS. <ref type="bibr" coords="6,305.87,535.13,16.31,10.91" target="#b29">[30,</ref><ref type="bibr" coords="6,324.80,535.13,13.95,10.91" target="#b30">31]</ref> both show that different communities might develop a particular emoji language to express different ideas through the usage of these pictograms.</p><p>As such, we believe that irony and stereotypes might also be expressed by the usage of certain emojis. At first, we encoded this information by having counts of the emoji usage, but in general emoji, tokens are more sparse than words so this didn't yield very good results. As emojis behave similarly to words when they are most meaningful, we decided to encode them using the same TF-IDF methods we used for unigrams. We then perform PCA to capture the variance across users and use this in our final classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.6.">POS Tag Counts</head><p>We use POS tag counts for a rough representation of syntactic information and complexity. To obtain POS tags we decided to use the Universal Part-of-Speech Tagset, which is described in NLTK's documentation <ref type="foot" coords="7,195.59,132.88,3.71,7.97" target="#foot_2">5</ref> . It consists of 12 different POS tags which are counted across each author, after tokenization and removal of tweeter tags, averaged to obtain the average POS counts for each author. Some parts of speech tags like ADVs and ADJs have been shown to be lexical markers of irony <ref type="bibr" coords="7,214.85,175.28,16.41,10.91" target="#b24">[25]</ref>. We decided to drop the tags NOUN, X, and PUNC, as they are already encoded in other features. Nouns tend to correlate strongly with token counts, punctuation is encoded in its own feature as described in 4.1.8 and X, representing words that the model couldn't assign a POS to, are usually few and not relevant for classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.7.">Sentiment Analysis</head><p>Irony can be used to attribute a sentiment value towards a specific target <ref type="bibr" coords="7,434.36,265.26,16.41,10.91" target="#b24">[25]</ref>, and so we would imagine that this would also be a feature that helps distinguish an ironic user from a non-ironic one. Furthermore, this feature could uncover sentiment polarity, as features based on incongruous sentiment have been used as an irony marker in previous work <ref type="bibr" coords="7,445.78,305.91,16.25,10.91" target="#b16">[17]</ref>.</p><p>For this feature we used the framework VADER-Sentiment-Analysis<ref type="foot" coords="7,397.53,317.70,3.71,7.97" target="#foot_3">6</ref> , which is a lexicon and rule based sentiment analysis tool which returns 4 features: positive, negative, neutral and compound values. The latter is describe as "normalized, weighted composite score" by the authors, as it is a normalized metric between -1 (most negative) to 1 (most positive) across all the words in the lexicon.</p><p>Initially, we attempted to model sentiment by creating a metric which would count the number of sentences that have high polarity in sentiment (high values in both positive and negative sentiment). However, this method seem to filter out too much information and the results weren't too promising.</p><p>For this reason, we decided to instead calculate sentiment for each tweet and proceed to combine the scores using statistical methods. We attempted both the average vector across all tweets (M) as well as the standard deviation (SD) for each metric. From our experimentation, the latter seemed to perform better, and we speculate it is due to the fact it captures information about how a user usually tends to deviate from his average expression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.8.">Punctuation</head><p>We also included several punctuation features. These are features often used for irony detection as in <ref type="bibr" coords="7,113.50,558.47,16.41,10.91" target="#b10">[11]</ref>. We counted each type of common multiple punctuation mark such as !!!, ??? and ... as well as "" and single punctuation marks. They were expected to be used differently in ironic versus non-ironic text. We filtered these patterns by using the python regular expression library re 7 . In the end, we averaged each punctuation per tweet for each user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Unused features 4.2.1. Word Embedding</head><p>We also experimented with word embeddings as our model did not have any features that would encode the context or semantic meaning of words. We assume that the semantics of certain words might be important to discern irony, namely when synonyms/antonyms are used to express a certain opinion. We experimented with the word embeddings provided by Gensim 8 . These are GloVe embeddings trained on a Twitter corpus and we tested with different embedding sizes (𝑛 ∈ 25, 50, 100).</p><p>In the model, we average the embeddings for each word in an author's tweet to represent it by its average embedding. We collect all of these representations for each of the author's tweets and then average them to collect the final embedding vector for the author.</p><p>We then concatenate this vector with the other features to be used by the classifier. The results we obtained using these embeddings resulted in generally worse performance when performing cross-validation. We also tested these features in isolation, and we could see that they did achieve about 80% accuracy, but when combined with the other features they didn't help the classifiers. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Misspelling</head><p>We thought that misspelling might be a good indicator of irony, as it can be used intentionally for humoristic effect. By using PySpellchecker 9 we found the misspelled words and divided them by the total number of words. However, it the results greatly overlapped for both classes and it was not a very practical feature for the classification. Because the misspellings did not add significant information, we did not use this feature for our model training. We suspect that misspellings are in general very common on social media.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">Syntactic Complexity</head><p>Another type of feature we considered was syntactic complexity, which we hypothesized could be higher for non-ironic users.</p><p>Syntactic complexity can be estimated in a number of ways including NP density, tree height and the number of high-level constituents per sentence <ref type="bibr" coords="9,341.44,265.25,16.38,10.91" target="#b32">[33]</ref>. All of these approaches require parsing, which we did with spacy's Dependency Parser 10 . We tried implementing tree height, but the process proved very slow and expensive, and we dropped the feature so we could keep our model lightweight. We incorporate some syntactic information with POS counts, so it is not totally absent from our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Baseline</head><p>In the task webpage <ref type="bibr" coords="9,183.04,399.03,16.42,10.91" target="#b24">[25]</ref>, the suggested baseline indicated was a char-or word-gram model, classified by an SVM. We followed this recommendation to create our own baseline, by using the CountVectorizer class and the SVC as implemented by scikit-learn. We experimented with different 𝑛 using cross-validation and found that a 4-gram character model worked best. This will be used in our results as the baseline for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Experiments</head><p>For all our classifiers and different features we followed the methodology of creating a 70 -30 split of the training data, where 70% of the data was used for training/cross-validation and the last 30% was used to test the classifiers.</p><p>To select different features, we would start by using them in isolation with the different classifiers and see the results on the cross-validation. If the accuracy was &gt; 70% then the features would be considered to be concatenated to the final feature vector. The features that weren't included often meant that the models would perform the same or worse if they were added.</p><p>We also considered different dimensional reduction methods, namely PCA and SparsePCA for the TF-IDF vectors due to their large dimensions. It is also desirable that the final vector is somewhat interpretable, so we only applied these to the TF-IDF vectors, by far the largest 9 PySpellchecker 10 https://spacy.io/usage/linguistic-features#dependency-parse dimensional features in our model. PCA was cheaper and the results were comparable to SparsePCA so this was used as our reduction method.</p><p>We found the best performing PCA dimensions for each of feature by performing a gridsearch with cross-validation on the training data and the values found were emoji-PCA 𝑛 = 4, profanity-PCA 𝑛 = 14, word-PCA 𝑛 = 20. These results make intuitive sense, as the dimensions increase in terms of complexity of the features and their importance for the final classification.</p><p>In terms of classifiers, we used 4 different methods: random forest (RandomForestClassifier), support vector machines (SVM) (svm.SVC(gamma="auto")), logistic regression (LogisticRegression) and nearest neighbour (NN) (KNeighborsClassifier) for our task. All classifiers with the exception of random forests are sensitive to highly different scaled values, so we normalize all features using the StandardScaler, which subtracts the mean and divides by standard deviation, from SKLearn. When doing cross-validation, we always reported the values for each of these classifiers and we could see that each feature tended to impact them in different ways.</p><p>The RandomForestClassifier is the best performing across all metrics and features. For this reason, we attempted to do parameter tuning for this particular model. We did this by using gridsearch but found no parameters which performed better than those provided by scikit-learn, so the parameters were left unchanged.</p><p>We present results for both the cross-validation and test splits. For the test, we chose the models which performed the best in the cross-validation. The final model we use is displayed in fig. <ref type="figure" coords="10,117.57,357.95,3.66,10.91" target="#fig_1">2</ref>. We also report the performance of our best classifier (Random Forests) on the task test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results</head><p>We find that all classifiers except NN perform better than the baseline in both cross validation and on the test data we separated from the training data.</p><p>Tab. 2 shows the average test and train scores based on 7-fold cross validation using 70% of the data provided by PAN.</p><p>Our results show that all models, with the exception of 1-NN and 5-NN, outperform the baseline (Tab. 2). The best baseline model (4-Char) performs with an accuracy of 87.24% on the training set and on the test set with an accuracy of 84.35% and an F1-score of 84.36%. We see that the random forest classifier obtains the best results. It performs with 100% accuracy on the train data and 91.84% accuracy on the test data, as well as an F1-Score of 91.83% during cross validation using standard deviation on the sentiment (SD) across the user's tweets. The scores using the mean sentiment (M) per the user's tweets performs a little lower on the test set but still over 91%. The other models do not perform as well. Logistic regression and SVM outperform the baseline models with over 89% in both accuracy and F1-Score. NN performs the worst of all classifiers with the best, 3-NN, only achieving an accuracy and F1-score of 87.76% and 87.79%, respectively, on the test split. It is the only NN that outperforms the baseline in both accuracy and F1-score. Because of their comparatively worse performance, we left them out of further evaluation. We continued our work on the best baseline and the three best classifiers.</p><p>Our models also outperform the best baseline when we trained on 70% of the provided training Cross-validation on 70% of the train data, n splits = 7. In bold, the best performing metrics. (M) denotes that the mean sentiment was used to combine the Tweet Sentiment, while (SD) denotes standard deviation was used.</p><p>data and tested on the remaining 30% (Tab. 3). The baseline model performs with an accuracy of 84.92% and an F1-score of 84.96%. All classifiers, except NN, outperform the baseline with our features both using sentiment M and SD. The best performing classifier is again random forest using SD for the sentiment with an accuracy and F1-score of 96.03% and 96.04% respectively. The same classifier using mean sentiment is close behind. Both logistic regression and SVM achieve accuracies and F1-scores above 90%. Random forest is the best performing classifier in all cases.</p><p>The results for the PAN task's test dataset was an accuracy of 95.56% , using the Random Forest and averaging the sentiments in tweets with VADER [(M) Random Forest]. These results are similar to the performance of the same classifier on our 70/30 split of the training data (acc: 95.24%, see tab. 3).</p><p>It seems that the performance on the 30% test split is a good indicator for performance on the official test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Feature Importance</head><p>We also discovered that not all features have the same importance, and that there are differences between classifiers. To investigate this we used permutation_importance from sklearn.inspection 11 to calculate the importance of each feature. This method calculates the influence each feature has by comparing the original accuracy score with the score obtained if different features are shuffled. The figures resulting from this analysis can be found in the Appendix.</p><p>For random forest avg_user_hashtag_count and auth_vocabsize seem to be the most important, while the other features have noticeably less influence, see Fig. <ref type="figure" coords="12,435.75,259.20,3.81,10.91">4</ref>. Both logistic regression and SVM have the highest importance for word_pca11, auth_vocabsize and qu (average number of question marks), Figs. <ref type="figure" coords="12,282.51,286.29,5.17,10.91">6</ref> and<ref type="figure" coords="12,309.94,286.29,3.81,10.91">7</ref>. The feature importance for 1-NN is most equally distributed among features. The most important features are qu (single question marks), LixScore, word_pca11 and word_pca20 (see Fig. <ref type="figure" coords="12,321.52,313.39,4.08,10.91">5</ref>) but the other features are not far behind. We see that different features are more important than others for different classifiers but there is some overlap between classifiers. Random forest concentrates only on a few features while the other classifiers take more features into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Model Performance</head><p>Our results show that the classifiers SVM, logistic regression and especially random forest perform very well with our features. Of the NN-classifiers, 3-NN performs best, but still lags a couple of percentage points behind the better-performing models. Our highest F1-score with the random forest is 96.04%, an F1-score that according to <ref type="bibr" coords="12,341.27,474.28,11.83,10.91" target="#b5">[6]</ref>'s survey of the field is only topped by <ref type="bibr" coords="12,103.27,487.83,16.41,10.91" target="#b33">[34]</ref>, who obtain a score of 97.5% with a distributional semantics approach (on individual tweets). Such high results are rather surprising considering the relative simplicity of the features used in our model. Especially the lack of semantic similarity or incongruity features (although perhaps sentiment could be interpreted as such), which are otherwise widely used <ref type="bibr" coords="12,447.38,542.03,11.23,10.91" target="#b4">[5,</ref><ref type="bibr" coords="12,461.04,542.03,12.50,10.91" target="#b16">17,</ref><ref type="bibr" coords="12,475.96,542.03,12.50,10.91" target="#b17">18,</ref><ref type="bibr" coords="12,490.88,542.03,12.23,10.91" target="#b18">19]</ref>, makes this a remarkable result.</p><p>However, considering that a simple char-gram model paired with SVM is able to obtain an F1-score of 84.36%, we suspect that this dataset is simply easier to classify than previous datasets in similar tasks. This might have to do with how this dataset was annotated and how the Twitter users were sampled. Unfortunately, the task authors do not provide us with this information, so it's unclear what makes this dataset unusual. Nevertheless, we do know that some ways of collecting Twitter data, for example, based on #irony hashtags, can create datasets that are easier to classify <ref type="bibr" coords="12,165.43,650.42,11.43,10.91" target="#b5">[6]</ref>, so data collection and sampling methods likely play a role here as well.</p><p>Unlike most previous research that focuses on tweet-level irony detection <ref type="bibr" coords="12,422.97,663.97,11.28,10.91" target="#b5">[6]</ref>, we are classify-ing irony on the user level. This is significant, as previous research <ref type="bibr" coords="13,385.89,86.97,12.74,10.91" target="#b2">[3]</ref> shows that the majority of hate speech is produced by a small minority of people. It might therefore be more effective to identify hateful/sarcastic users than individual utterances. It might also be the case that identifying irony on the user level (both in terms of annotation and prediction) is more robust than doing so for individual tweets and that this is partly responsible for the high F1-score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Feature Performance</head><p>While developing our different features we found that even the stylistic count features on their own performed similarly (about 80% accuracy) to the Baseline model, despite being quite primitive. This means that simply by looking at the general stylistic characteristics of an author a machine learning model is able to separate the two classes. This indicates that the difference between ironic and non-ironic tweeting styles really is very distinct on the user level. Every other feature yielded small improvements, with TF-IDF being the highest contributor.</p><p>Based on feature permutation (see Appendix), we found that vocabulary size, hashtag counts and question marks were among the most significant features, as well as some TF-IDF PCA vectors, i.e. stylistic and lexical features. This is consistent with previous studies <ref type="bibr" coords="13,443.04,299.28,16.31,10.91" target="#b17">[18,</ref><ref type="bibr" coords="13,462.08,299.28,13.96,10.91" target="#b34">35]</ref> where lexical features (especially unigrams) are used as a baseline and core of more complex models. Studies that find strong effects of punctuation and similar stylistic features include <ref type="bibr" coords="13,468.25,326.38,18.07,10.91" target="#b35">[36]</ref> and <ref type="bibr" coords="13,89.29,339.93,16.41,10.91" target="#b14">[15]</ref>. Per Tab. 2, using the sentiment standard deviation rather than the mean also generally improved results by a small amount. The standard deviation might be better than the mean at capturing incongruities in polarity, which are often indicative of irony. By comparing the difference in the standardized mean we see that some features are higher for the irony spreader and their counterparts. Non-ironic users (NI) especially seem to have a higher LixScore and auth_vocabsize while irony spreaders have a high number of qu, Fig. <ref type="figure" coords="13,414.47,407.68,3.74,10.91" target="#fig_2">3</ref>. Longer words and tweets are also associated with non-ironic users. In general, the pattern points to non-ironic users using more complex and diverse language than ironic users. On the other hadn, ironic users use more question marks, hashtags and user tags -this points to ironic users possibly being more interactive in their Twitter usage.</p><p>We were also curious about the significant PCA features, which are a bit harder to interpret. While looking into the values of different words in the TF-IDF, we noticed that sometimes words specific to a single user, as for instance a promotion code, will have very high values in the TF-IDF vector, as they fit the criteria of being used by only a single user multiple times. For instance, in word_pca_10 when trained on 70% of the data, we can softmax the weights on the component and sort them according to their scores, to see what contributes to this component. The following word features score highest: "women", ":", "and", "men", "calm", "gay", "guard", "code", "USER-PROMO-CODE". As we can see, some words here might be related with irony and stereotypes, like "gay" and "women", but the "USER-PROMO-CODE" is not related at all to the task and might add noise. To ensure a better quality of these features, we could have opted for stemming and removing stop words or words that only appear in a single user (to capture cases like promotional posts), while accepting that we might lose some information.</p><p>Due to the nature of the task as an author classification task, we cannot say if a particular tweet is ironic. Instead, we are only able to classify by all their tweets, but not exactly point out where irony or stereotypes are present. However given the annotations for the dataset, one would have to identify specific cases of irony/stereotypes manually to allow for this type of classification. It is also not clear how many ironic tweets make a user an irony-spreader or not. Therefore is unclear how the system would perform on smaller or larger datasets, when the annotation is not as clear or generated in other ways.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.">Limitations</head><p>Our model has several limitations and areas for improvement. A general drawback is the time it takes to generate the features for the training and test data, particularly for the different TF-IDF features. This means the model would not scale well in terms of time and space usage. To avoid this scalability problem the number of terms for TF-IDF could partially be reduced by clipping the vocabulary or stemming the words in each tweet and accepting some information loss in exchange for a faster performing system. Removing the profanity and emoji TF-IDF features is another strategy. When optimizing for the number of PCA dimensions, we did find that these features added information to the model and slightly improved performance, but the difference is very small (about 1% accuracy was gained by optimizing), indicating that there probably is a large degree of redundancy.</p><p>Currently, our model does not consider context. Our features at most capture a unigram language model by the usage of TF-IDF, but even then it's distorted by PCA. While we attempted embeddings, these were not beneficial to the task. This is a bit surprising considering the success others have had with word embedding-based features in conventional ML <ref type="bibr" coords="14,457.82,651.30,16.29,10.91" target="#b18">[19]</ref>. Word embeddings in isolation might not capture enough information and would need to be processed in some way before being used in the model. They would also likely be more useful with a deep-learning approach, which is their more conventional application <ref type="bibr" coords="15,402.94,100.52,11.36,10.91" target="#b5">[6,</ref><ref type="bibr" coords="15,417.02,100.52,12.32,10.91" target="#b19">20]</ref>.</p><p>That being said, we believe our model would require features that encode semantic and pragmatic information, incongruities or even ontologies to interpret if some words are being used out of the expected context.</p><p>Another direction for future work relates to the fact that the different classifiers appear to rely on different features (see Appendix). Considering this, an ensemble method could be used to combine different classifiers to optimally use more of the features. Different models could also be optimized to for different feature subsets to find the best combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>We tackled the challenge of detecting irony and stereotype spreaders by focusing on creating stylistic and lexical features. We compared the performance of our features with the suggested baseline for the task, a 4-char gram model followed by an SVM, with our own features. Our features combined with a random forest classifier outperform the baseline by ≈ 9% on cross validation and ≈ 11% on a 30% split of the training data. We also obtained 95.56% accuracy on the task's test set, by using a random forest classifier with our features. We see room for improvement in identifying passages for irony and sarcasm usage and developing features that focus on encoding context and semantic relationship between words.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,486.05,384.77,8.93;3,89.29,337.54,416.69,135.95"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Bar plots for the top 20 most used words in the corpus according to the two classes.</figDesc><graphic coords="3,89.29,337.54,416.69,135.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="8,89.29,573.52,259.91,8.93;8,89.29,326.96,416.68,234.00"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Final Model Used and Baseline Model representation</figDesc><graphic coords="8,89.29,326.96,416.68,234.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="14,89.29,347.18,392.31,8.93;14,141.38,84.19,312.53,250.43"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Differences between the Mean/Std normalization mean values of the NI and I classes.</figDesc><graphic coords="14,141.38,84.19,312.53,250.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="18,89.29,121.23,416.70,204.69"><head></head><label></label><figDesc></figDesc><graphic coords="18,89.29,121.23,416.70,204.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="18,89.29,380.12,416.70,204.69"><head></head><label></label><figDesc></figDesc><graphic coords="18,89.29,380.12,416.70,204.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="19,89.29,114.51,416.70,204.69"><head></head><label></label><figDesc></figDesc><graphic coords="19,89.29,114.51,416.70,204.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="19,89.29,415.28,416.70,204.69"><head></head><label></label><figDesc></figDesc><graphic coords="19,89.29,415.28,416.70,204.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,88.99,517.91,378.53,133.98"><head>Avg. Vocab Size: Number of unique tokens per tweet Avg. Token Number: Number of tokens on average per tweet Vocab/Token Ratio: Number of Vocab divided by tokens Avg. Tweet Length: Number of characters on average per tweet Avg. HASHTAG Counts Number of HASHTAGs on average per tweet Avg. USERTAG Counts Number of USERTAGs on average per tweet Avg. URL Counts Number of URLs on average per tweet Avg. Emoji Counts Number of Emojis on average per tweet Avg. Capital/Lower Case Ratio Ratio between upper and lower case per tweet Table 1</head><label></label><figDesc>Count features used in the final classifier.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="11,88.99,89.90,352.55,202.39"><head>Table 2</head><label>2</label><figDesc></figDesc><table coords="11,153.73,89.90,287.81,182.17"><row><cell></cell><cell>Train</cell><cell>Test</cell><cell></cell></row><row><cell>Classifier</cell><cell cols="3">Accuracy (%) Accuracy (%) F1-Score (%)</cell></row><row><cell cols="2">(SD) Random Forest 100</cell><cell>91.84</cell><cell>91.83</cell></row><row><cell>(SD) Log. Reg.</cell><cell>97.51</cell><cell>89.79</cell><cell>89.83</cell></row><row><cell>(SD) SVM</cell><cell>97.22</cell><cell>89.12</cell><cell>89.12</cell></row><row><cell>(SD) 1-NN</cell><cell>100</cell><cell>81.97</cell><cell>82.01</cell></row><row><cell>(SD) 3-NN</cell><cell>92.23</cell><cell>87.76</cell><cell>87.79</cell></row><row><cell>(SD) 5-NN</cell><cell>88.83</cell><cell>82.65</cell><cell>85.71</cell></row><row><cell>(M) Random Forest</cell><cell>100</cell><cell>91.50</cell><cell>91.49</cell></row><row><cell>(M) SVM</cell><cell>97.00</cell><cell>88.78</cell><cell>88.78</cell></row><row><cell>(M) Log. Reg.</cell><cell>97.78</cell><cell>90.14</cell><cell>90.16</cell></row><row><cell>Baseline (2-Char)</cell><cell>85.09</cell><cell>82.65</cell><cell>82.39</cell></row><row><cell>Baseline (3-Char)</cell><cell>87.24</cell><cell>83.67</cell><cell>83.60</cell></row><row><cell>Baseline (4-Char)</cell><cell>87.24</cell><cell>84.35</cell><cell>84.36</cell></row><row><cell>Baseline (5-Char)</cell><cell>88.89</cell><cell>82.65</cell><cell>82.70</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="12,88.99,89.90,416.99,142.61"><head>Table 3</head><label>3</label><figDesc>Test results on the remaining 30% of the data. The baseline model is a 4-gram char BOW model followed by a SVM for classification. In bold, the best performing metrics.</figDesc><table coords="12,188.28,89.90,218.72,98.48"><row><cell>Classifier</cell><cell cols="2">Accuracy (%) F1-Score (%)</cell></row><row><cell cols="2">(SD) Random Forest 96.03</cell><cell>96.04</cell></row><row><cell>(SD) Log. Reg.</cell><cell>90.47</cell><cell>90.49</cell></row><row><cell>(SD) SVM</cell><cell>92.06</cell><cell>92.08</cell></row><row><cell>(M) Random Forest</cell><cell>95.24</cell><cell>95.25</cell></row><row><cell>(M) Log. Reg.</cell><cell>90.47</cell><cell>90.50</cell></row><row><cell>(M) SVM</cell><cell>92.06</cell><cell>92.08</cell></row><row><cell>Baseline (4-Char)</cell><cell>84.92</cell><cell>84.96</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="4,108.93,671.03,185.59,8.97"><p>https://www.nltk.org/api/nltk.tokenize.casual.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="6,108.93,671.02,160.01,8.97"><p>https://github.com/zacanger/profane-words</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="7,108.93,649.06,215.46,8.97"><p>https://www.nltk.org/book/ch05.html#tab-universal-tagset</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="7,108.93,660.02,157.07,8.97"><p>https://github.com/cjhutto/vaderSentiment</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="15,112.66,407.46,394.53,10.91;15,112.66,421.01,395.17,10.91;15,112.66,434.55,393.32,10.91;15,112.66,448.10,394.53,10.91;15,112.66,461.65,394.53,10.91;15,112.66,475.20,395.17,10.91;15,112.66,488.75,393.33,10.91;15,112.33,502.30,353.19,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="15,251.61,434.55,254.37,10.91;15,112.66,448.10,279.35,10.91">Overview of PAN 2022: Authorship Verification, Profiling Irony and Stereotype Spreaders, and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ortega-Bueno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pezik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,233.97,475.20,273.86,10.91;15,112.66,488.75,393.33,10.91;15,112.33,502.30,27.32,10.91">Proceedings of the Thirteenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="15,246.47,503.31,146.73,9.72">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Barron-Cedeno</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">D S</forename><surname>Martino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Mirko Degli Esposti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Pasi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Thirteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022. 2022</date>
			<biblScope unit="volume">13390</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="15,112.66,515.85,393.33,10.91;15,112.66,529.40,236.00,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="15,177.22,515.85,328.76,10.91;15,112.66,529.40,33.75,10.91">deplorable&quot; satire: Alt-right memes, white genocide tweets, and redpilling normies</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">S</forename><surname>Greene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,155.16,529.40,124.78,10.91">Studies in American Humor</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="31" to="69" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,542.95,394.53,10.91;15,112.14,556.50,393.85,10.91;15,112.66,570.05,104.19,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="15,224.34,556.50,254.16,10.91">Automatic detection of cyberbullying in social media text</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Van Hee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Emmery</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Desmet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Lefever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>De Pauw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Hoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,486.28,556.50,19.70,10.91;15,112.66,570.05,16.29,10.91">PloS one</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">203794</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,583.60,393.33,10.91;15,112.66,597.15,394.52,10.91;15,112.66,610.69,70.43,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="15,215.56,583.60,290.42,10.91;15,112.66,597.15,121.39,10.91">Hateful symbols or hateful people? predictive features for hate speech detection on twitter</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,256.85,597.15,245.04,10.91">Proceedings of the NAACL student research workshop</title>
		<meeting>the NAACL student research workshop</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="88" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,624.24,393.33,10.91;15,112.66,637.79,326.38,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="15,250.83,624.24,255.16,10.91;15,112.66,637.79,107.25,10.91">From humor recognition to irony detection: The figurative language of social media</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Buscaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,228.74,637.79,141.58,10.91">Data &amp; Knowledge Engineering</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,651.34,393.32,10.91;15,112.66,664.89,388.05,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="15,300.04,651.34,173.83,10.91">Automatic sarcasm detection: A survey</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Carman</surname></persName>
		</author>
		<idno type="DOI">10.1145/3124420</idno>
		<ptr target="https://doi.org/10.1145/3124420.doi:10.1145/3124420" />
	</analytic>
	<monogr>
		<title level="j" coord="15,482.36,651.34,23.62,10.91;15,112.66,664.89,63.68,10.91">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,86.97,394.53,10.91;16,112.66,100.52,393.33,10.91;16,112.66,114.06,394.51,10.91;16,112.66,130.06,123.08,7.90" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="16,327.46,86.97,175.13,10.91">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-22948-1_5</idno>
	</analytic>
	<monogr>
		<title level="m" coord="16,240.99,100.52,264.99,10.91;16,112.66,114.06,123.97,10.91">Information Retrieval Evaluation in a Changing World, The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,141.16,393.33,10.91;16,112.66,154.71,394.53,10.91;16,112.66,168.26,172.05,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="16,373.25,141.16,132.74,10.91;16,112.66,154.71,219.45,10.91">Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO) at PAN 2022</title>
		<author>
			<persName coords=""><forename type="first">O.-B</forename><surname>Reynier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Berta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Paolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Elisabetta</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="16,358.04,154.71,143.79,10.91">CLEF 2022 Labs and Workshops</title>
		<title level="s" coord="16,112.66,168.26,103.05,10.91">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,181.81,393.32,10.91;16,112.66,195.36,75.40,10.91" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="16,162.44,181.81,343.55,10.91;16,112.66,195.36,45.44,10.91">Irony markers and functions: Towards a goal-oriented theory of irony and its processing</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Attardo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,208.91,393.33,10.91;16,112.66,222.46,358.85,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="16,271.02,208.91,234.96,10.91;16,112.66,222.46,178.30,10.91">Who cares about sarcastic tweets? investigating the impact of sarcasm on sentiment analysis</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Maynard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Greenwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,313.77,222.46,96.69,10.91">Lrec 2014 proceedings</title>
		<imprint>
			<publisher>ELRA</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,236.01,393.33,10.91;16,112.66,249.56,393.33,10.91;16,112.28,263.11,174.03,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="16,461.91,236.01,44.08,10.91;16,112.66,249.56,127.75,10.91">Pathways for irony detection in tweets</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>De Freitas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A</forename><surname>Vanin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">N</forename><surname>Hogetop</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">N</forename><surname>Bochernitsan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Vieira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,264.62,249.56,241.36,10.91;16,112.28,263.11,85.45,10.91">Proceedings of the 29th Annual ACM Symposium on Applied Computing</title>
		<meeting>the 29th Annual ACM Symposium on Applied Computing</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="628" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,276.66,393.53,10.91;16,112.66,290.20,393.33,10.91;16,112.28,303.75,268.96,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="16,263.96,276.66,242.24,10.91;16,112.66,290.20,17.41,10.91">Parsing-based sarcasm sentiment recognition in twitter data</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Bharti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">S</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Jena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,183.46,290.20,322.52,10.91;16,112.28,303.75,142.97,10.91">IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="1373" to="1380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,317.30,393.33,10.91;16,112.66,330.85,282.63,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="16,200.42,317.30,305.57,10.91;16,112.66,330.85,76.10,10.91">Making objective decisions from subjective data: Detecting irony in customer reviews</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,197.28,330.85,114.08,10.91">Decision support systems</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="754" to="760" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,344.40,393.33,10.91;16,112.66,357.95,95.21,10.91" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Liebrecht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kunneman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bosch</surname></persName>
		</author>
		<title level="m" coord="16,319.87,344.40,186.12,10.91;16,112.66,357.95,63.29,10.91">The perfect solution for detecting sarcasm in tweets# not</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,371.50,393.33,10.91;16,112.66,385.05,376.81,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="16,273.72,371.50,232.27,10.91;16,112.66,385.05,124.56,10.91">Exploring the fine-grained analysis and automatic detection of irony on twitter</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Van Hee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Lefever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Hoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,245.16,385.05,160.38,10.91">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="707" to="731" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,398.60,393.33,10.91;16,112.66,412.15,393.33,10.91;16,112.66,425.70,122.74,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="16,268.02,398.60,237.97,10.91;16,112.66,412.15,31.29,10.91">Semi-supervised recognition of sarcasm in twitter and amazon</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Davidov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Tsur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,167.53,412.15,338.46,10.91;16,112.66,425.70,35.05,10.91">Proceedings of the fourteenth conference on computational natural language learning</title>
		<meeting>the fourteenth conference on computational natural language learning</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="107" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,439.25,393.33,10.91;16,112.66,452.79,393.33,10.91;16,112.66,466.34,308.02,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="16,380.58,439.25,125.40,10.91;16,112.66,452.79,194.11,10.91">Sarcasm as contrast between a positive sentiment and negative situation</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Surve</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">De</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,330.81,452.79,175.18,10.91;16,112.66,466.34,220.17,10.91">Proceedings of the 2013 conference on empirical methods in natural language processing</title>
		<meeting>the 2013 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="704" to="714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,479.89,395.17,10.91;16,112.66,493.44,393.32,10.91;16,112.66,506.99,393.32,10.91;16,112.33,520.54,196.37,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="16,284.00,479.89,223.83,10.91;16,112.66,493.44,16.45,10.91">Harnessing context incongruity for sarcasm detection</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,151.96,493.44,354.03,10.91;16,112.66,506.99,393.32,10.91">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="757" to="762" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct coords="16,112.66,534.09,393.33,10.91;16,112.66,547.64,347.81,10.91" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Tripathi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Carman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.00883</idno>
		<title level="m" coord="16,382.63,534.09,123.36,10.91;16,112.66,547.64,165.74,10.91">Are word embedding-based features useful for sarcasm detection?</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="16,112.66,561.19,394.53,10.91;16,112.66,574.74,269.51,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="16,275.18,561.19,227.71,10.91">Irony detection via sentiment-based transfer learning</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,112.66,574.74,175.43,10.91">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="1633" to="1644" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,588.29,281.67,10.91" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="16,178.61,588.29,183.80,10.91">The definition and processing of irony 40</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Østergaard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,601.84,394.61,10.91;16,112.66,615.39,393.32,10.91;16,112.66,628.93,393.32,10.91;16,112.66,642.48,395.01,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="16,257.21,601.84,250.06,10.91;16,112.66,615.39,229.57,10.91">Sparse, contextually informed models for irony detection: Exploiting user communities, entities and sentiment</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,365.43,615.39,140.55,10.91;16,112.66,628.93,393.32,10.91;16,112.66,642.48,193.10,10.91">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1035" to="1044" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="16,112.66,656.03,393.33,10.91;16,112.66,669.58,394.52,10.91;17,112.66,86.97,70.43,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="16,267.36,656.03,238.63,10.91;16,112.66,669.58,25.34,10.91">Twitter sarcasm detection exploiting a context-based model</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,161.82,669.58,297.15,10.91">international conference on web information systems engineering</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="77" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,100.52,393.33,10.91;17,112.66,114.06,395.01,10.91" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="17,303.97,100.52,202.02,10.91;17,112.66,114.06,72.06,10.91">yeah right&quot;: Sarcasm recognition for spoken dialogue systems</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tepperman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Traum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,207.22,114.06,271.20,10.91">Ninth international conference on spoken language processing</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,127.61,394.52,10.91;17,112.28,141.16,397.86,10.91;17,112.36,157.15,73.62,7.90" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="17,259.07,127.61,243.57,10.91">Irony detection in twitter: The role of affective content</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">I H</forename><surname>Farías</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<idno type="DOI">10.1145/2930663</idno>
		<ptr target="https://doi.org/10.1145/2930663.doi:10.1145/2930663" />
	</analytic>
	<monogr>
		<title level="j" coord="17,112.28,141.16,138.39,10.91">ACM Trans. Internet Technol</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,168.26,393.32,10.91;17,112.66,181.81,393.58,10.91;17,112.66,195.36,152.62,10.91" xml:id="b25">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>Björnsson</surname></persName>
		</author>
		<title level="m" coord="17,186.71,168.26,319.27,10.91;17,112.66,181.81,82.82,10.91">Lix och läsbarhetsprövade skolböcker, Pedagogiskt utvecklingsarbete vid Stockholms skolor</title>
		<meeting><address><addrLine>Pedagogiskt centrum i Stockholm</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1968">1968</date>
			<biblScope unit="page" from="2" to="12" />
		</imprint>
	</monogr>
	<note>Publication Title: Lix och läsbarhetsprövade skolböcker</note>
</biblStruct>

<biblStruct coords="17,112.66,208.91,393.33,10.91;17,112.66,222.46,81.21,10.91" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="17,169.40,208.91,247.83,10.91">Lix and rix: Variations on a little-known readability index</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,425.06,208.91,80.93,10.91">Journal of Reading</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="490" to="496" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,236.01,395.17,10.91;17,112.66,249.56,324.87,10.91" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="17,217.41,236.01,228.59,10.91">Automatic satire detection: Are you having a laugh?</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Burfoot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,468.95,236.01,38.88,10.91;17,112.66,249.56,237.00,10.91">Proceedings of the ACL-IJCNLP 2009 conference short papers</title>
		<meeting>the ACL-IJCNLP 2009 conference short papers</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="161" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,263.11,394.62,10.91;17,112.66,276.66,393.33,10.91;17,112.66,290.20,161.76,10.91" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="17,349.71,263.11,133.65,10.91">Cursing in english on twitter</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Thirunarayan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Sheth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,112.66,276.66,393.33,10.91;17,112.66,290.20,73.42,10.91">Proceedings of the 17th ACM conference on Computer supported cooperative work &amp; social computing</title>
		<meeting>the 17th ACM conference on Computer supported cooperative work &amp; social computing</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="415" to="425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,303.75,393.53,10.91;17,112.66,317.30,395.01,10.91;17,112.66,330.85,397.48,10.91;17,112.66,346.84,67.68,7.90" xml:id="b29">
	<monogr>
		<title level="m" type="main" coord="17,296.66,303.75,209.53,10.91;17,112.66,317.30,203.14,10.91">An empirical study of emoji usage on twitter in linguistic and national contexts 24 (????)</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kejriwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.osnem.2021.100149</idno>
		<ptr target="https://doi.org/10.1016/j.osnem.2021.100149" />
		<imprint>
			<biblScope unit="page">100149</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,357.95,394.53,10.91;17,112.48,371.50,394.70,10.91;17,112.66,385.05,395.17,10.91;17,112.66,398.60,394.53,10.91;17,112.66,412.15,395.01,10.91;17,112.66,425.70,155.44,10.91" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="17,241.00,371.50,260.93,10.91">Emoji use in twitter white nationalism communication</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Falling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Lisnichenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A</forename><surname>Elmadany</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Abdul-Mageed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Costakis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">E</forename><surname>Keller</surname></persName>
		</author>
		<idno type="DOI">10.1145/3311957.3359495</idno>
		<ptr target="https://doi.org/10.1145/3311957.3359495.doi:10.1145/3311957.3359495" />
	</analytic>
	<monogr>
		<title level="m" coord="17,129.94,385.05,377.89,10.91;17,112.66,398.60,207.87,10.91">Conference Companion Publication of the 2019 on Computer Supported Cooperative Work and Social Computing, CSCW &apos;19</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="201" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,439.25,393.33,10.91;17,112.66,452.79,395.17,10.91;17,112.66,466.34,395.17,10.91;17,112.66,479.89,395.01,10.91;17,112.66,493.44,138.14,10.91" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="17,212.67,439.25,293.31,10.91;17,112.66,452.79,28.27,10.91">Investigating redundancy in emoji use: Study on a Twitter based corpus</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Donato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Paggio</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-5216</idno>
		<ptr target="https://aclanthology.org/W17-5216.doi:10.18653/v1/W17-5216" />
	</analytic>
	<monogr>
		<title level="m" coord="17,170.40,452.79,337.44,10.91;17,112.66,466.34,395.17,10.91;17,112.66,479.89,14.21,10.91">Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, Association for Computational Linguistics</title>
		<meeting>the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, Association for Computational Linguistics<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="118" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,506.99,395.17,10.91;17,112.66,520.54,393.33,10.91;17,112.66,534.09,261.19,10.91" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="17,238.35,506.99,269.48,10.91;17,112.66,520.54,198.29,10.91">Using psycholinguistic features for the classification of comprehenders from summary speech transcripts</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Barnwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><forename type="middle">S</forename><surname>Tiwary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,333.52,520.54,172.47,10.91;17,112.66,534.09,130.85,10.91">International Conference on Intelligent Human Computer Interaction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="122" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,547.64,393.53,10.91;17,112.66,561.19,393.33,10.91;17,112.66,574.74,232.89,10.91" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="17,251.09,547.64,255.10,10.91;17,112.66,561.19,117.17,10.91">Sarcastic or not: Word embeddings to predict the literal or sarcastic meaning of words</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Muresan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,253.11,561.19,252.88,10.91;17,112.66,574.74,134.90,10.91">proceedings of the 2015 conference on empirical methods in natural language processing</title>
		<meeting>the 2015 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1003" to="1012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,588.29,393.53,10.91;17,112.66,601.84,393.32,10.91;17,112.66,615.39,280.47,10.91" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="17,329.67,588.29,176.51,10.91;17,112.66,601.84,17.76,10.91">Identifying sarcasm in twitter: a closer look</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>González-Ibánez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Wacholder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,153.60,601.84,352.39,10.91;17,112.66,615.39,192.47,10.91">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="581" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,628.93,393.60,10.91;17,112.66,642.48,395.17,10.91;17,112.66,656.03,119.12,10.91" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="17,225.66,628.93,280.61,10.91;17,112.66,642.48,121.09,10.91">Sarcasm detection in twitter:&quot; all your products are incredibly amazing!!!&quot;-are they really?</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bouazizi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ohtsuki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,256.24,642.48,251.58,10.91;17,112.66,656.03,23.61,10.91">2015 IEEE Global Communications Conference (GLOBE-COM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
