<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.00,77.73,443.48,17.64;1,72.00,99.69,296.79,17.64;1,72.00,118.85,148.81,10.70">Use pre-trained models and multi-classifier voting methods to identify the ironic authors on Twitter Notebook for PAN at CLEF 2022</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,72.00,144.51,40.83,11.62"><forename type="first">Jian</forename><surname>Qin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,123.84,144.51,60.36,11.62"><forename type="first">Leilei</forename><surname>Kong</surname></persName>
							<email>kongleilei@fosu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,196.80,144.51,80.20,11.62"><forename type="first">Zhaoqian</forename><surname>Huang</surname></persName>
							<email>zhaoqian543@163.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,288.60,144.51,60.90,11.62"><forename type="first">Jialin</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,361.08,144.51,71.49,11.62"><forename type="first">Yansheng</forename><surname>Guo</surname></persName>
							<email>guoyansheng2021@163.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,444.24,144.51,72.90,11.62"><forename type="first">Mingjie</forename><surname>Huang</surname></persName>
							<email>mingjiehuang007@163.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,72.00,158.31,63.00,11.62"><forename type="first">Zeyang</forename><surname>Peng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.00,77.73,443.48,17.64;1,72.00,99.69,296.79,17.64;1,72.00,118.85,148.81,10.70">Use pre-trained models and multi-classifier voting methods to identify the ironic authors on Twitter Notebook for PAN at CLEF 2022</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">23CFECE335C1750F59733FEDFF640339</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pre-trained model</term>
					<term>Multi-classifier voting</term>
					<term>Ironic authors on Twitter</term>
					<term>Bert</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper focuses on the task published on PAN at CLEF 2022 of profiling the author's tweets to determine whether the author is ironic. This research is aimed identifying those authors that employ irony to spread stereotypes. In this work, we use a pre-trained model to extract the textual features and train multiple classifiers to make the final decision. We divided the training data of 2022 into 80% as the training dataset and 20% as the validation dataset. The best result for a single classifier on the validation dataset is 0.92857. The best result of multi-classifier voting on the verification dataset is 0.98805. In the final results, the accuracy of our method reached 0.95000. This experiment shows that the multiple-classifier voting method can effectively improve prediction accuracy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Nowadays, people's lives are inseparable from the Internet and social media, and satirical language permeates social platforms and everyday speech. Irony and stereotypes often hurt more than general irony. Analyzing the author's tweets, identifying sarcastic sentences from their language and filtering them can help protect victims from discrimination and victimization. Accordingly, it has become one of the staple sharing tasks at PAN <ref type="bibr" coords="1,228.00,469.73,11.70,10.70" target="#b0">[1]</ref>. The work presented in this paper was developed as a solution to the Profiling Irony and Stereotype Spreaders task for the competition PAN @ CLEF 2022 <ref type="bibr" coords="1,487.44,482.33,11.61,10.70" target="#b1">[2]</ref>. Our task is to determine whether the author spreads Irony and Stereotypes through Twitter in English.</p><p>Approaches for irony detection on Twitter can be roughly classified into three classes: rule-based approaches, classical feature-based machine learning methods and deep neural network models. Deep neural network models have recently been applied for irony detection <ref type="bibr" coords="1,381.72,532.97,12.00,10.70" target="#b2">[3,</ref><ref type="bibr" coords="1,396.60,532.97,8.16,10.70" target="#b3">4,</ref><ref type="bibr" coords="1,407.64,532.97,8.28,10.70" target="#b4">5,</ref><ref type="bibr" coords="1,418.80,532.97,8.28,10.70" target="#b5">6,</ref><ref type="bibr" coords="1,429.84,532.97,8.28,10.70" target="#b6">7,</ref><ref type="bibr" coords="1,441.00,532.97,9.20,10.70" target="#b7">8]</ref> and show better performance than classical feature-based machine learning models.</p><p>The profiling Irony and Stereotype Spreaders task belongs to the text classification task. In order to better solve the problem of identifying Irony and Stereotype Spreaders on Twitter, we use the pretraining model such as BERT to encode the text and then make the final decisions by integrating five classifiers. Our model is divided into three parts. The first is an encoder used to encode the input text. The second is a classifier used to classify the text. The third is to use the voting mechanism to make the final decision.1</p><p>The article is organized as follows: Section 2 presents the latest relevant work for this task. Section 3 describes our proposed method and introduces our network architecture, Section 4 shows trials and results, and we make a conclusion about this work in the last section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related works</head><p>To address identifying whether authors use irony to spread stereotypes on Twitter, we first start with state-of-the-art text classification <ref type="bibr" coords="2,256.68,172.37,12.00,10.70" target="#b8">[9,</ref><ref type="bibr" coords="2,274.92,172.37,13.80,10.70" target="#b9">10,</ref><ref type="bibr" coords="2,294.96,172.37,14.72,10.70" target="#b10">11]</ref> techniques and research. Last year, a team consisting of Marco Siino and others won the 2021 PAN competition on profiling HSSs. The team used a deep learning model based on a Convolutional Neural Network (CNN). They used a CNN based on a single convolutional layer to classify authors as Hate Speech Spreader (HSS) or not-Hate Speech Spreader (nHSS) and used 5-fold cross-validation in testing. On that binary classification task, their proposed model achieved a maximum accuracy of 0.80 on a multilingual (i.e. English and Spanish) training set.</p><p>However, to date, most research on hate speech in Natural Language Processing (NLP) has focused on detecting hate speech in a single message <ref type="bibr" coords="2,289.80,273.53,16.90,10.70" target="#b11">[12]</ref>. A Twitter sharing task team participating in PAN@CLEF2021 proposed a method using contextualized word embeddings and statistical feature extraction to find words used by haters and non-haters in different contexts and compared these words to as features to train a classifier. They also used the BERT sequence representation dataset, using the intermediate sequence representations of all the user's tweets as a feature to train a model to classify users as haters and non-haters.In the last SemEval task for detecting offensive language, the best team reached an F1 score of 0.9204, and the other teams mostly achieved very similar performances in a tight competition <ref type="bibr" coords="2,151.68,362.09,16.90,10.70" target="#b11">[12]</ref>. So we considered using this method to explore further the task of identifying stereotype communicators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Network Architecture</head><p>We propose a method based on a pre-trained model and a voting mechanism to solve the identification work. Figure <ref type="figure" coords="2,192.96,481.01,5.53,10.70" target="#fig_0">1</ref> shows the network architecture. In the training dataset, each piece of data consists of an author, 200 tweets he wrote and a label. Suppose author1's twitter= {tweets1, tweets2, ……, tweets200}, where tweets1 is the first tweet of author1 and tweets200 is the 200th tweet of author1. Pre-trained model BERT is used as the encoder to extract features of total of 200 tweets. All tweets were individually sent into the model for encoding. During this process, each tweet would be tokenized and sequence padded into a vector of 768 dimensions, which is regarded as the feature of this piece of the tweet. Then these features were fed to a fully connected layer for classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Voting Mechanism</head><p>The voting mechanism is divided into two steps. The first step is to determine whether the author of these tweets is ironic according to the distribution of ironic tweets. In the second step, we vote again according to the judgment results of multiple classifiers to obtain the final result. The following is the method for judging the writer' s identity by a single classifier. The output of classification is a 2-dimention vector { 1 , 2 } activated with softmax, where 1 is the score indicating this tweet is not ironic and 2 the opposite. When the 2 score is greater than 0.5, this piece of tweet is considered ironic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Step One</head><p>Suppose is the number of tweets written by the i-th author that are judged to be ironic and is the average score of all 2 scores of thses 200 tweets written by the i-th author. And then we set a threshold to compare with the value of ( * ). If ( * ) is greater than , the author is considered to be ironic. Otherwise, the author is considered not ironic</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Step Two</head><p>We use 5-fold cross-validation to improve the accuracy of the model. Specifically, In crossvalidation, we divided the 2022 training dataset into five parts equally, four of which were combined into a new training dataset and the other part was used as a validation dataset. According to different combination orders, we can get five different pairs of training set and validation set. These five datasets were used to train the model to obtain five classifiers. These classifiers form the structure of session3.1. The input test dataset was used to obtain five predicted authorship sets. Based on these five result sets, a hard voting method is used to vote on the authors'identity. Suppose there are classifiers to determine the i-th author of the test set is ironic. A threshold Κ is set and compared with the value of . If is greater than Κ, the author is considered to be ironic. Otherwise, the author is considered not ironic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental setting</head><p>We chose pre-trained model BERT-base (L=12, H=768, A=12, Total Parameters=110M) as the encoder and used Keras to construct BERT and fully connected network. In the fine-tuning pretrained model phase, we set batch_size=20, maxlen=60, epochs=10 and use sparse categorical crossentropy as the loss function, and the optimization method is Adam with a 2e-5 learning rate.</p><p>The following are the loss function and activation function used during training of our model.</p><p>Loss Function：Q=-</p><formula xml:id="formula_0" coords="4,165.84,138.54,338.27,30.52">1   m i 1 ( log + 1 -log 1 -,<label>(1)</label></formula><p>Activation Function:tanh</p><formula xml:id="formula_1" coords="4,186.48,169.60,312.95,22.02">= sinh cosh = -- + -,<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Data processing</head><p>Firstly, we replace all emojis with corresponding words by using emojiswitch. The reviewer provided the identity of each author in the training dataset for 2022. We added the labels NI or I after each tweet of the corresponding author according to their identity, where NI idicates the tweet is not ironic and I indicates the tweet is ironic. if the author is considered ironic, the label I was added after each of his tweets. If the author is considered not ironic, add the label NI to each of his tweets. And then the training data in 2022 is divided into 20% and 80% parts, 80% part is used as a training dataset, and 20% part is used as a validation dataset. We obtained five such training dataset and validation dataset pairs according to different arrangement order combinations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Thresholds</head><p>To get the model we need, we fine-tune the pre-trained model by setting the first threshold in step 1 in the range of 10 to 140. We set epoch=10. A total of 10 rounds are trained, and at the end of each round a validation dataset is used to check the accuracy of the model prediction, and if the accuracy is greater than that of the previous fine-tuned model, the new fine-tuning settings are saved. When 10 rounds of training are completed, let the model predict the validation dataset again and get the final accuracy, recorded as final_val_acc. The accuracy is calculated as the number of correctly predicted authors / total number of authors in the dataset. Table <ref type="table" coords="4,314.40,454.97,5.53,10.70" target="#tab_0">1</ref> records the final_val_acc obtained for one of the pairs of data sets when the threshold takes different values. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">result Table 3</head><p>Accuracy achieved on the 2022 test dataset. 2022 test dataset Accuary 0.9500 We compressed the test results of the test dataset and uploaded them to TIRA <ref type="bibr" coords="5,435.52,281.81,20.80,10.70" target="#b12">[13]</ref>. based on the feedback from the organizers, we achieved an accuracy of 0.9500 for ours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this experiment, we use the method that utilizes a pre-trained model and voting mechanism to solve the Profiling Irony and Stereotype Spreaders in the PAN@CLEF 2022. The tweets of the authors are added with the corresponding labels and fed into the model one by one to get the model we need for training. Then we build multiple datasets to train and get multiple classifiers for voting to improve accuracy and fault tolerance. Finally, our method achieves an accuracy of 0.9500.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgement</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,72.00,728.92,201.86,10.62;2,93.96,503.40,416.76,215.16"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Architecture diagram for our model.</figDesc><graphic coords="2,93.96,503.40,416.76,215.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,72.00,377.92,450.96,10.62;3,72.00,391.36,450.96,10.42;3,72.00,404.80,27.98,10.42;3,83.04,417.65,440.00,10.70;3,72.00,430.33,177.72,11.23;3,249.60,434.49,4.45,8.18;3,254.40,430.33,2.27,11.23;3,264.48,434.49,4.45,8.18;3,269.28,430.33,253.80,12.34;3,72.00,443.33,118.08,10.70;3,198.96,447.45,4.45,8.18;3,207.24,443.33,102.33,10.70;3,318.60,447.45,4.45,8.18;3,326.76,443.33,196.26,10.70;3,72.00,456.05,88.92,10.70;3,83.04,468.89,37.29,10.70;3,136.68,468.89,362.76,10.70;3,515.64,468.89,7.42,10.70;3,72.00,481.85,450.94,12.17;3,72.00,494.69,41.04,10.70;3,133.92,494.53,389.14,11.23;3,72.00,507.41,306.69,10.70;3,129.84,283.20,344.88,90.72"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: This is an example of getting the predictive value of a tweet. The first value of the array is the score indicating this tweet is not ironic, and the second value is the score indicating the tweet is ironic.The following is the method for judging the writer' s identity by a single classifier. The output of classification is a 2-dimention vector { 1 , 2 } activated with softmax, where 1 is the score indicating this tweet is not ironic and 2 the opposite. When the 2 score is greater than 0.5, this piece of tweet is considered ironic.Suppose is the number of tweets written by the i-th author that are judged to be ironic and is the average score of all 2 scores of thses 200 tweets written by the i-th author. And then we set a threshold to compare with the value of ( * ). If ( * ) is greater than , the author is considered to be ironic. Otherwise, the author is considered not ironic</figDesc><graphic coords="3,129.84,283.20,344.88,90.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,72.00,481.12,451.08,227.55"><head>Table 1</head><label>1</label><figDesc>The result obtained in a validation dataset when takes different values. It can be observed that when is set to 50, a better score is obtained on the validation dataset.So we set to 50 and used our five test datasets and valid datasets to get five classifiers.The threshold Κ in the second step is used to compare with the number of votes . When is greater than Κ , i-th author is considered as ironic. A random sample of 20% of the 2022 training dataset is used to test the accuracy of the multi-classifier when Κ takes different values. The experimental data are shown in Table2.</figDesc><table coords="4,125.88,510.28,380.86,105.94"><row><cell></cell><cell>final_val_acc</cell><cell></cell><cell>final_val_acc</cell></row><row><cell>10</cell><cell>0.86904</cell><cell>80</cell><cell>0.90476</cell></row><row><cell>20</cell><cell>0.86904</cell><cell>90</cell><cell>0.91667</cell></row><row><cell>30</cell><cell>0.89286</cell><cell>100</cell><cell>0.86904</cell></row><row><cell>40</cell><cell>0.90467</cell><cell>110</cell><cell>0.85719</cell></row><row><cell>50</cell><cell>0.92857</cell><cell>120</cell><cell>0.76190</cell></row><row><cell>60</cell><cell>0.89286</cell><cell>130</cell><cell>0.71428</cell></row><row><cell>70</cell><cell>0.90476</cell><cell>140</cell><cell>0.71428</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,72.00,711.28,446.97,37.18"><head>Table 2</head><label>2</label><figDesc>The accuracy achieved by the multi-classifier in the random 20% test dataset when Κ takes different values. When Κ is set to 1, 2 or 3, the accuracy rate is high. The data used for testing were randomly selected from the training set, and some of them overlapped with the training data, resulting in high scores. Based on accuracy and fault tolerance considerations, we chose to set Κ to 2 and then tested the 2022 test dataset.</figDesc><table coords="5,369.24,77.29,6.95,11.23"><row><cell>Κ</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0" coords="5,83.04,463.97,442.68,10.70;5,72.00,476.69,91.44,10.70"><p>This research was supported by the Natural Science Foundation of Guangdong Province, China (No. 2022A1515011544).</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,87.60,537.41,435.32,10.70;5,88.44,550.13,434.52,10.70;5,88.44,562.73,434.64,10.70;5,88.44,575.33,350.40,10.70" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="5,193.32,562.73,329.76,10.70;5,88.44,575.33,220.08,10.70">Overview of PAN 2022: Authorship Verification, Profiling Irony and Stereotype Spreaders, and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ortega-Bueno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pezik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">13390</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,90.48,587.93,432.45,10.70;5,88.44,600.65,325.68,10.70" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Reynier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Berta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Paolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Elisabetta</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
		<title level="m" coord="5,380.16,587.93,142.77,10.70;5,88.44,600.65,220.87,10.70">Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO) at PAN 2022</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,87.60,613.25,435.48,10.70;5,88.44,625.97,434.64,10.70;5,88.44,638.57,218.88,10.70" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,297.72,613.25,225.36,10.70;5,88.44,625.97,141.85,10.70">A deeper look into sarcastic tweets using deep convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Vij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,262.32,625.97,260.76,10.70;5,88.44,638.57,115.57,10.70">Proceedings of the 26th International Conference on Computational Linguistics</title>
		<meeting>the 26th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1601" to="1612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,87.60,651.17,435.46,10.70;5,88.44,663.89,434.64,10.70;5,88.44,676.49,231.36,10.70" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,362.64,651.17,160.42,10.70;5,88.44,663.89,129.44,10.70">Are word embedding-based features useful for sarcasm detection?</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Tripathi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Carman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,240.84,663.89,282.24,10.70;5,88.44,676.49,127.67,10.70">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1006" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,87.60,689.21,435.36,10.70;5,88.44,701.81,427.44,10.70" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,271.92,689.21,246.25,10.70">Irony detection with attentive recurrent neural networks</title>
		<author>
			<persName coords=""><forename type="first">Y.-H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H.-H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H.-H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,102.84,701.81,277.79,10.70">Proceedings of European Conference on Information Re trieval</title>
		<meeting>European Conference on Information Re trieval</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="534" to="540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,87.60,714.53,435.46,10.70;5,88.44,727.13,434.52,10.70;5,88.44,739.73,196.56,10.70" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,343.56,714.53,179.50,10.70;5,88.44,727.13,163.32,10.70">Are you serious?: Rhetor ical questions and sarcasm in social media dialog</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Oraby</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,277.80,727.13,245.16,10.70;5,88.44,739.73,103.69,10.70">Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</title>
		<meeting>the 18th Annual SIGdial Meeting on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="310" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.60,74.93,435.48,10.70;6,88.44,87.53,434.52,10.70;6,88.44,100.13,131.16,10.70" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,259.08,74.93,264.00,10.70;6,88.44,87.53,82.96,10.70">The role of conversation context for sar casm detection in online interactions</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Fabbri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Muresan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,198.12,87.53,324.84,10.70;6,88.44,100.13,38.29,10.70">Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</title>
		<meeting>the 18th Annual SIGdial Meeting on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="186" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.60,112.85,435.36,10.70;6,88.44,125.45,434.49,10.70;6,88.44,138.17,135.72,10.70" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,180.12,112.85,342.84,10.70;6,88.44,125.45,35.63,10.70">Magnets for sarcasm: Making sarcasm detection timely, con textual and very personal</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Veale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,149.40,125.45,373.53,10.70;6,88.44,138.17,45.82,10.70">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="482" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.60,150.77,435.36,10.70;6,88.44,163.37,276.00,10.70" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,216.84,150.77,218.31,10.70">Text classification techniques: A literature review</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Thangaraj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sivakami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,447.12,150.77,75.84,10.70;6,88.44,163.37,227.34,10.70">Interdisci plinary Journal of Information, Knowledge &amp; Management</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,93.00,176.09,402.00,10.70;6,88.44,188.69,275.40,10.70" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,201.84,176.09,288.37,10.70">Semantic text classification: A survey of past and recent advances</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Altınel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">C</forename><surname>Ganiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,88.44,188.69,174.42,10.70">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="1129" to="1153" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,93.00,201.41,402.10,10.70;6,88.44,214.01,226.44,10.70" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Oshikawa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.00770</idno>
		<title level="m" coord="6,253.08,201.41,242.02,10.70;6,88.44,214.01,38.77,10.70">A survey on natural language processing for fake news detection</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,93.00,226.73,413.97,10.70;6,88.44,239.33,433.22,10.70;6,88.44,251.93,423.80,10.70;6,92.83,264.65,43.93,10.70" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,246.36,226.73,260.61,10.70;6,88.44,239.33,212.66,10.70">Exploiting Contextualized Word Representations to Profile Haters on Twitter-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Tanise</forename><surname>Ceron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Camilla</forename><surname>Casula</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="6,494.76,239.33,26.90,10.70;6,88.44,251.93,114.71,10.70">CLEF 2021 Labs and Workshops</title>
		<editor>
			<persName><forename type="first">Guglielmo</forename><surname>Faggioli</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021-09">2021. September 2021</date>
		</imprint>
	</monogr>
	<note>Notebook Papers. copylink] publisher</note>
</biblStruct>

<biblStruct coords="6,93.00,277.25,429.97,10.70;6,88.44,289.97,434.64,10.70;6,88.44,302.57,402.12,10.70" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="6,331.92,277.25,174.11,10.70">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,269.88,289.97,253.20,10.70;6,88.44,302.57,143.71,10.70">Information Retrieval Evaluation in a Changing World, The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09">September 2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
