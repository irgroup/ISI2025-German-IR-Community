<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.02,75.32,374.30,17.04;1,72.02,96.08,222.32,17.04;1,72.02,115.96,148.90,9.94">Analysis of Irony and Stereotype Spreaders Based On Convolutional Neural Networks Notebook for PAN at CLEF 2022</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,72.02,141.46,52.74,10.80"><forename type="first">Dong</forename><surname>Yuan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,133.58,141.46,64.34,10.80"><forename type="first">Wenyin</forename><surname>Yang</surname></persName>
							<email>cswyyang@163.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,212.69,141.46,26.20,10.80"><forename type="first">Li</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,248.33,141.46,56.54,10.80"><forename type="first">Zhenlin</forename><surname>Tan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,313.39,141.46,42.84,10.80"><forename type="first">Qidi</forename><surname>Lao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.02,75.32,374.30,17.04;1,72.02,96.08,222.32,17.04;1,72.02,115.96,148.90,9.94">Analysis of Irony and Stereotype Spreaders Based On Convolutional Neural Networks Notebook for PAN at CLEF 2022</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">16631C45E6961665309B4CFC81367AF0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Irony and Stereotype Spreaders</term>
					<term>Convolutional Neural Networks</term>
					<term>Binary Classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In order to solve the task of Profiling Irony and Stereotype Spreaders on Twitter released by PAN 2022 organizers, this paper proposes a two-layer convolutional neural network based on deep learning. This task is essentially a binary classification task.Due to its strong feature extraction ability, the convolutional neural network has been very active in the classification tasks of professional competitions[1]. The proposed model achieves an accuracy of 0.8 and a loss of 0.3 on the training set. The running time of the model is only 2 minutes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the rapid development of the Internet, more and more people are used to expressing their opinions on the Internet. Now the Internet is full of all kinds of speech, there are positive speech, negative speech, hate speech and so on. It is very meaningful to determine what category the speech on the Internet belongs to. Therefore, the Profiling Irony and Stereotype Spreaders on Twitter Task held by PAN 2022, the main purpose of the competition is to judge whether the Twitter user is Irony and Stereotype Spreaders. This paper proposes a model based on convolutional neural network to achieve this purpose <ref type="bibr" coords="1,122.93,447.81,13.75,9.94" target="#b0">[1]</ref>. First, the model preprocesses the original data, including splitting at spaces, removing punctuation, and segmenting words. Data preprocessing maps each word to a positive integer. Next, the model maps the positive integers into a multidimensional vector, which is used as the input to the convolutional neural network. The first layer of the model's convolutional neural network performs preliminary feature extraction on the input tensor, and then inputs the result to the pooling layer for further feature extraction. In order to extract more important semantic features, the model stacks a convolutional neural network and a pooling layer. Finally, classification is performed through a fully connected layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Dataset</head><p>The datasets provided by the Profiling Irony and Stereotype Spreaders on Twitter task are mainly derived from the speeches made by Twitter users. The training set contains 420 xml files named after the user ID-each XML is related to a single author-containing 200 comments made by the user on Twitter. In addition, it contains a truth.txt file, which also contains 200 pieces of information, and each piece of information is marked with an ID corresponding to the label "I" or "NI". The test set contains 180 Twitter users, and each user has a different number of comments Table <ref type="table" coords="2,405.37,74.44,5.52,9.94" target="#tab_0">1</ref> shows the analysis of the training set and test set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Model Architecture</head><p>The model framework proposed in this paper is shown in  For binary classification tasks such as Profiling Irony and Stereotype Spreaders on Twitter, using a combination of 1D convolutional neural networks and pooling layers can get a fairly good accuracy, and the model is less computationally expensive <ref type="bibr" coords="3,279.38,99.76,13.81,9.94" target="#b3">[4]</ref>. Next, the paper will introduce the role of each layer of the model in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Text preprocessing</head><p>The first step of text preprocessing is to convert the XML format dataset into pure text. According to the label "I" or "NI" corresponding to each author id in the truth.txt file, the model stores the 420 xml files in the newly created folder "I" or "NI" in txt format, respectively <ref type="bibr" coords="3,378.63,195.40,12.92,9.94" target="#b4">[5]</ref>. At the same time, the model will read the information in each file. The above work is done by Input Layer. This is convenient for subsequent word segmentation and mapping of the text into integers.</p><p>The model uses the Text Vectorization function in the Tensorflow framework to process text. It lowercases the text, splits it on spaces, strips punctuation, and outputs an integer vocabulary index <ref type="bibr" coords="3,505.21,246.07,13.49,9.94" target="#b5">[6]</ref>. The output result of this layer is a sequence of 9406 positive integers. Each number corresponds to a word, and finally a dictionary can be obtained, where the key is the word and the value is the positive integer corresponding to the word. At the same time, the maximum length of the text processed by the model through the Text Vectorization Layer is 9406. The text larger than this length will be truncated, and the text smaller than this length will be filled <ref type="bibr" coords="3,288.19,309.31,11.70,9.94" target="#b6">[7]</ref>.</p><p>Because the neural network cannot handle integer sequences directly, the model inputs the result of Text Vectorization into the Word Embedding Layer and maps it into a dense vector. The Word Embedding Layer is equivalent to a dictionary that takes integers as input, looks up those integers in the internal dictionary, and returns the associated vector. After training and testing multiple models, we determined that the model is better when the parameter embedding-dimensionality of the Word Embedding Layer is 130.</p><p>Above, we have completed the preprocessing of the text. Next, feature extraction will be performed on the preprocessed text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Feature extraction</head><p>In fact, in order to determine the most suitable hyperparameters (batch size, optimizer, filter size, etc.) and model structure, we conducted multiple tests and repeatedly compared the loss value, accuracy and model calculation cost of each test result. The resulting hyperparameters are detailed in the introduction to each layer of the model.</p><p>For lightweight text sequence processing, this paper selects a one-dimensional convolutional neural network and pooling layer for feature extraction 错误!未找到引用源。. The output of the Word Embedding Layer is <ref type="bibr" coords="3,164.36,545.73,13.76,9.94" target="#b0">(1,</ref><ref type="bibr" coords="3,178.12,545.73,22.93,9.94">9406,</ref><ref type="bibr" coords="3,201.06,545.73,18.35,9.94">130)</ref>, which is a three-dimensional tensor. The first dimension represents the number of data files processed each time, the second dimension represents the maximum length of the text sequence, and the third dimension represents the Word Embedding Layer output dimension. In order to enhance the ability of model feature extraction, we adopt a two-layer one-dimensional convolutional neural network and a two-layer pooling network.</p><p>The output dimension of the first Convolutional Neural Network Layer is 128, and the length of the convolution window is 72, that is, the convolution window scans 72 words each time.The result output by the Word Embedding Layer will get a matrix of size 9335*128 through the first first Convolutional Neural Network Layer. In order to reduce the size of the output data, the output three-dimensional tensor <ref type="bibr" coords="3,72.02,659.64,14.24,9.94" target="#b0">(1,</ref><ref type="bibr" coords="3,86.26,659.64,23.73,9.94">9335,</ref><ref type="bibr" coords="3,109.99,659.64,14.24,9.94">128</ref>) is input to Max Pooling Layer. The role of the Max Pooling Layer is to downsample the feature text sequence and output the maximum value of each channel. The output matrix size of this layer is 583*128.</p><p>So as to further extract the main features in the text sequence, we added a second Convolutional Neural Network Layer (the dimension of the output space is 64, the length of the convolution window is 36), and the output matrix size of this layer is 548*64. This matrix is then passed through the GlobalMaxpooling Layer to extract important semantic information in the text sequence, and the output result is a matrix of size 1*64 错误!未找到引用源。.</p><p>At the end of the model, the model stacks the Fully Connected Layer, and the activation function adopts the Sigmoid Function to determine whether the speech information in the input file is I or NI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>To evaluate the model proposed in this paper, we first learn from 84,000 tweets given by PAN. Among them, the epoch is set to 7, and the value of each epoch is shown in Table <ref type="table" coords="4,431.74,157.48,4.14,9.94" target="#tab_1">2</ref>. We tried to set the epoch to be larger, but when the epoch was greater than 7, the model performance did not change much. To further evaluate the performance of the model, we randomly split the 420 xml files given by PAN as a training set into two parts, of which 320 xml files are used as a new training set and the remaining 100 xml files are used as a test set. According to the result labels output by the comparison model and the labels of these 100 author ids given by PAN, we found that the accuracy of the test set reached 0.85.</p><p>Finally, the running accuracy of the proposed model on the test set given by PAN2022 reaches 0.75.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This paper proposes a model that utilizes a two-layer convolutional neural network and a two-layer pooling network to solve the Profiling Irony and Stereotype Spreaders on Twitter Task in PAN@CLEF 2022. Semantic features can be extracted from text sequences using convolutional neural networks. The two-layer convolutional neural network can further enhance the effect of feature extraction. Applying the model to the PAN 2022 Profiling Irony and Stereotype Spreaders on Twitter Task for binary classification can not only obtain high accuracy, but also has a low computational cost, fast running speed, and strong practical value.</p><p>Experiments show that for lightweight and simple tasks such as text classification and temporal prediction, small one-dimensional convolutional neural networks can replace other complex networks such as recurrent neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgment</head><p>This work was supported by grants from the Basic and Applied Basic Research Fund of Guangdong Province No.2019A1515111080.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,344.94,255.31,177.82,9.94;2,72.02,267.91,450.96,9.94;2,72.02,280.51,450.72,9.94;2,72.02,293.23,450.92,9.94;2,72.02,305.83,450.70,9.94;2,72.02,318.55,453.68,9.94;2,72.02,331.15,450.88,9.94;2,72.02,343.75,450.72,9.94;2,72.02,356.47,450.72,9.94;2,72.02,369.07,118.11,9.94"><head>Figure 1 .</head><label>1</label><figDesc>The model is divided into two modules: text preprocessing and feature extraction. The role of the text preprocessing module is to perform data format conversion, standardization, word segmentation, and vectorization of the original data. The output of this module is a bunch of multidimensional tensors for easy processing by the feature extraction module. The function of the feature extraction module is to extract the semantic features in the text sequence and output the predicted result. Semantic feature extraction is divided into three stages. The first stage is preliminary extraction, which is done by Convolutional Neural Network Layer and Max Pooling Layer. The second stage is depth extraction, which is done by Convolutional Neural Network Layer and GlobalMax Pooling Layer. The third stage is the prediction result, which is done by Fully Connected Layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,72.02,754.08,127.89,11.04;2,149.50,391.92,295.15,358.70"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Model architecture</figDesc><graphic coords="2,149.50,391.92,295.15,358.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,72.02,111.98,432.06,81.96"><head>Table 1</head><label>1</label><figDesc>The detail of Profiling Irony and Stereotype Spreaders on Twitter Task</figDesc><table coords="2,96.38,141.14,407.70,52.80"><row><cell>Dataset</cell><cell cols="2">Number of users Number of tweets</cell><cell>Number of</cell><cell>Number of</cell></row><row><cell></cell><cell></cell><cell></cell><cell>labels I</cell><cell>labels NI</cell></row><row><cell>Training set</cell><cell>420</cell><cell>84000</cell><cell>42000</cell><cell>42000</cell></row><row><cell>Test set</cell><cell>180</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,72.02,195.02,438.86,81.99"><head>Table 2</head><label>2</label><figDesc></figDesc><table coords="4,72.02,208.46,438.86,68.55"><row><cell cols="3">Training set running results</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Metrics</cell><cell>Epoch=1</cell><cell>Epoch=2</cell><cell>Epoch=3</cell><cell>Epoch=4</cell><cell>Epoch=5</cell><cell>Epoch=6</cell><cell>Epoch=7</cell></row><row><cell>Accuracy</cell><cell>0.5594</cell><cell>0.7021</cell><cell>0.7606</cell><cell>0.7783</cell><cell>0.7836</cell><cell>0.7949</cell><cell>0.8143</cell></row><row><cell>Loss</cell><cell>0.6629</cell><cell>0.5749</cell><cell>0.5100</cell><cell>0.4800</cell><cell>0.4471</cell><cell>0.4182</cell><cell>0.3918</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,108.02,642.72,414.72,9.94;4,108.02,655.44,414.86,9.94;4,108.02,668.04,414.84,9.94;4,108.02,680.76,414.93,9.94;4,108.02,693.36,414.81,9.94;4,108.02,705.98,415.13,9.94;4,108.02,718.70,187.36,9.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,288.65,668.04,234.21,9.94;4,108.02,680.76,305.29,9.94">Overview of PAN 2022: Authorship Verification, Profiling Irony and Stereotype Spreaders, and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ortega-Bueno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pezik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,222.44,705.98,300.71,9.94;4,108.02,718.70,85.29,9.94">Proceedings of the Thirteenth International Conference of the CLEF Association (CLEF</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Cedeno</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">D S</forename><surname>Martino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Esposti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Pasi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Thirteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,108.02,731.30,414.85,9.94;4,108.02,744.02,414.87,9.94;4,108.02,756.62,150.74,9.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,388.03,731.30,134.84,9.94;4,108.02,744.02,232.58,9.94">Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO) at PAN 2022</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ortega-Bueno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="4,363.95,744.02,153.65,9.94">CLEF 2022 Labs and Workshops</title>
		<title level="s" coord="4,108.02,756.62,73.73,9.94">Notebook Papers</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,108.02,74.44,414.98,9.94;5,108.02,87.04,255.14,9.94" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="5,336.94,74.44,186.06,9.94;5,108.02,87.04,135.05,9.94">Detection of hate speech spreaders using convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Di Nuovo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">La</forename><surname>Tinnirello</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Cascia</surname></persName>
		</author>
		<ptr target="ceur-ws.org" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>CLEF</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,108.02,99.76,414.72,9.94;5,108.02,112.36,109.83,9.94" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="5,158.73,99.76,282.55,9.94">Convolutional neural networks for sentence classification</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5882</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="5,108.02,125.08,414.73,9.94;5,108.02,137.68,414.81,9.94;5,108.02,150.28,312.08,9.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,328.91,125.08,174.33,9.94">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,108.02,137.68,410.59,9.94">Information Retrieval Evaluation in a Changing World, ser. The Information Retrieval Series</title>
		<meeting><address><addrLine>N. Ferro, C. Peters; Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09">Sep. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,108.02,163.00,323.17,9.94" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="5,189.32,163.00,116.09,9.94">Deep learning with Python</title>
		<author>
			<persName coords=""><forename type="first">Francois</forename><surname>Chollet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>Simon and Schuster</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,108.02,175.60,414.85,9.94;5,108.02,188.32,336.20,9.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,194.28,175.60,328.59,9.94;5,108.02,188.32,50.27,9.94">On the Difficulty of Automatically Detecting Irony: Beyond a Simple Case of Negation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,180.71,188.32,161.80,9.94">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="595" to="614" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,108.02,200.92,415.11,9.94;5,108.02,213.52,321.14,9.94" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,327.29,200.92,195.84,9.94;5,108.02,213.52,38.74,9.94">Overview of the 8th author profiling task at pan 2020</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,154.58,213.52,174.41,9.94">Profiling fake news spreaders on twitter</title>
		<imprint>
			<publisher>CLEF</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
