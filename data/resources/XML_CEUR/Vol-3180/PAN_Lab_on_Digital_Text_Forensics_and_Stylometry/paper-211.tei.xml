<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.02,75.44,386.29,17.04;1,72.02,96.20,148.32,17.04;1,72.02,116.20,148.90,9.94">A BERT-based model for Profiling Irony and Stereotype Spreaders on Twitter Notebook for PAN at CLEF 2022</title>
				<funder ref="#_KrKN3Tr">
					<orgName type="full">Natural Science Foundation of Guangdong Province, China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,72.02,141.82,54.95,10.80"><forename type="first">Wenbin</forename><surname>Lin</surname></persName>
						</author>
						<author>
							<persName coords="1,134.18,141.82,74.50,10.80"><forename type="first">Zhongyuan</forename><surname>Han</surname></persName>
							<email>hanzhongyuan@gmail.com</email>
						</author>
						<author>
							<persName coords="1,222.53,141.82,53.68,10.80"><forename type="first">Jinxi</forename><surname>Zhang</surname></persName>
							<email>zhangjinxi7502@gmail.com</email>
						</author>
						<author>
							<persName coords="1,284.23,141.82,53.39,10.80"><forename type="first">Zengyao</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName coords="1,344.47,141.82,60.44,10.80"><forename type="first">Guiyuan</forename><surname>Cao</surname></persName>
						</author>
						<author>
							<persName coords="1,412.78,141.82,60.38,10.80"><forename type="first">Jianhong</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<persName coords="1,495.10,141.82,27.92,10.80;1,72.02,155.62,26.66,10.80"><forename type="first">Leilei</forename><surname>Kong</surname></persName>
							<email>kongleilei@fosu.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">CLEF</orgName>
								<address>
									<postCode>2022</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.02,75.44,386.29,17.04;1,72.02,96.20,148.32,17.04;1,72.02,116.20,148.90,9.94">A BERT-based model for Profiling Irony and Stereotype Spreaders on Twitter Notebook for PAN at CLEF 2022</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9A7752CC3227310D906A18ABD69B21AD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Irony and Stereotype</term>
					<term>BERT</term>
					<term>Multi-model voting</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The PAN 2022 profiling irony and stereotype spreaders on Twitter(IROSTEREO) challenge focuses on determining whether a person is an irony and stereotype spreader. In this paper, we propose a method based on a BERT model and multi-model voting. The task of "Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO)" is considered as a binary classification task by our team, and a BERT model is used to determine whether an author is an irony and stereotype propagator. By using this model, we can achieve the task of "Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO)". In the end, we achieved an accuracy of 0.9333.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Irony is an ironic tone or writing technique in speech or writing, where the true meaning of the words cannot be understood from the words alone, but in fact, the original meaning is the opposite of the literal meaning and usually needs to be understood in context and context. In real life, there are often irony and stereotype purveyors on social software, and their comments are extremely influential on the social climate, so ifsoftware can accurately determine whether what a person says is sarcastic or not and block his comments in time, it can ensure that those comments will not influence the social climate. At PAN'22, reviewers will focus on profiling ironic authors on Twitter <ref type="bibr" coords="1,367.56,477.22,13.09,10.04" target="#b0">[1]</ref>. Special emphasis will be given to those authors that employ irony to spread stereotypes. Our goal will be to classify authors as ironic or not depending on their number of tweets with ironic content.</p><p>After establishing the goal and after a rigorous discussion among our team, we concluded that the task of "analyzing satirists and stereotypes on Twitter" is a binary classification task, i.e., the goal of the task is for us to determine whether the author is a satirist and stereotypist. Therefore, by analyzing multiple papers, our team felt that using a multi-model voting and BERT model would be a good fit for this task.</p><p>For this task , we will use the BERT model to train and predict the dataset and then apply a multimodel voting approach to improve the accuracy of the final results. For this task, our goal is to analyze which authors belong to the irony and stereotype purveyors and which authors do not belong to the irony and stereotype purveyors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Datasets</head><p>After our team's counting, there are 420 authors in the training set this year, and each author has 200 tweets, which are all XML files, so there are 84,000 tweets in total. Also, the folder contains a list of authors and a "truth.txt" file with basic facts. The first column in the "truth.txt" file corresponds to the author ID, and the second column contains the truth tag. We divided the training set into a training set and a test set; the ratio of the training set to the test set is 4:1. Thus, more test data can be obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>We deem the task as a binary classification task. For each author, each paragraph of sentences is fed into the training model to make predictions, and eventually, an array of predictions with only two elements will be obtained. We believe that the second element of the array can be used as a basis for determining whether a given author is an irony and stereotype purveyor. If the second element of the prediction array has a larger value than the first element, then we can assume that the author is a satirist and stereotype purveyor. If the second element of the prediction array has a smaller value than the first element, then we can assume that the author is not a satirist or stereotype purveyor <ref type="bibr" coords="2,432.34,289.99,13.82,9.94" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Processing of training set data</head><p>The official data is not a straightforward collection of sentences, and the XML file given contains many tags and symbols that are not useful, so we need to do some processing on the official data given.</p><p>During the training set data processing, we removed some useless punctuation and symbols such as "#user", "#RT" and "#CD". Then for each author, we cut operation for each document, that is, every 512 words into a paragraph, followed by "\t" and "1" and "o", the width of "\t" is equivalent to the position of 8 spaces, "1" represents the true value of the paragraph is true at this time because the subsequent model is certain to need a parameter representing the true value, so we first put all sentence parameters are set to "1", "o" on behalf of the paragraph belongs to the author, if the last paragraph is less than 512 words, then we add "\t" and "1" and "n" after the paragraph, "n" on behalf of the next paragraph does not belong to the author. The entire paragraph division is shown in Figure <ref type="figure" coords="2,474.48,461.61,4.68,9.94" target="#fig_0">1</ref>.Next, we put all the authors of the txt file into a txt file inside, and then apply the 5-fold method to all the authors into 5 parts, for each part of the data are rotated as a test set, and the remaining four parts are used as the training set, so we have 5 sets of training and test sets, and then because there is a random function "random.shuffle(xml_list)" in 5-fold, for each author, it will disrupt the order of all the sentences in it, and then repeat the above operation, i.e., for each part of the data is rotated as the test set, and the remaining four parts are used as the training set, so that we have another 5 sets of training and test sets, after this data processing we have a total of 10 sets of training and test sets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Processing of BERT model and multi-model voting</head><p>We trained the above 10 datasets using the popular BERT model. At the end of each epoch of training, the model obtained at that point is predicted for the corresponding test set, and when the prediction results are the best so far, the model is saved. A prediction method is by predicting each segment individually and getting the respective corresponding conformity, and finally calculating their arithmetic mean, when the value is greater than 0.5, then the authors are considered then we consider the authors to be sarcastic and stereotypical authors, and label these authors with the corresponding prediction labels, and get an array of labels about these author categories. A "1" label indicates that the author is an author of that category, and a "0" label indicates that the author is not an author of that category. After the 10 models are trained in multiple rounds by the above method, the authors are predicted by the same prediction method, and the results are voted by adding the 10 labels directly and setting a threshold value, when the number of votes for an author is greater than this threshold value, we consider the author as an irony and stereotypical author, otherwise, the author is not.</p><p>The structure of the whole model is shown in the Figure <ref type="figure" coords="3,338.30,226.48,5.52,9.94" target="#fig_1">2</ref> below. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>The predictions of the 10 models were counted and further differentiated by voting, with 1 vote when the model predicts a satirical author for one of the authors, and no vote otherwise. Then a number of votes is set as a boundary, and only when the number of votes is more than this value can this author be considered a satirical author, and this is taken as the final prediction result. The results of the experiment are shown in the table below.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data set</head><p>Task.F1 Test set 0.9333</p><p>These are the results of our team's work on this year's "Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO)" task. Finally, the top three teams had scores of 0.9944, 0.9778 and 0.9722 respectively. Our team achieved an accuracy of 0.9333 and was ranked 32nd.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we propose an approach based on a BERT model and multi-model voting. The task of "Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO)" is considered as a binary classification task by our team, and is analyzed using a BERT model and a multi-model voting approach for correlation. Using this approach, the task of "Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO)" can be implemented. In the end, we achieved a score of 0.9333 in this method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,72.02,698.02,194.46,11.04;2,114.20,572.74,383.10,123.00"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The process of slicing the datasets</figDesc><graphic coords="2,114.20,572.74,383.10,123.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,72.02,419.35,187.53,11.04;3,171.50,249.08,268.10,167.25"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Architecture of the whole model</figDesc><graphic coords="3,171.50,249.08,268.10,167.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,72.02,541.03,450.70,221.21"><head>Table 1</head><label>1</label><figDesc>Accuracy under different parametersAfter the best model was selected, this model was next used to evaluate the validation set, and the results are shown in the table below.</figDesc><table coords="3,209.57,584.16,211.22,137.88"><row><cell>Votes</cell><cell>Accuracy</cell></row><row><cell>0</cell><cell>0.9444444444444444</cell></row><row><cell>1</cell><cell>0.9523809523809523</cell></row><row><cell>2</cell><cell>0.9603174603174603</cell></row><row><cell>3</cell><cell>0.9761904761904762</cell></row><row><cell>4</cell><cell>0.9761904761904762</cell></row><row><cell>5</cell><cell>0.9761904761904762</cell></row><row><cell>6</cell><cell>0.9761904761904762</cell></row><row><cell>7</cell><cell>0.9682539682539683</cell></row><row><cell>8</cell><cell>0.9444444444444444</cell></row><row><cell>9</cell><cell>0.8809523809523809</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,72.02,86.78,143.42,24.48"><head>Table 2</head><label>2</label><figDesc>Validation set evaluation results</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6.">Acknowledgements</head><p>This work is supported by the <rs type="funder">Natural Science Foundation of Guangdong Province, China</rs> (No. <rs type="grantNumber">2022A1515011544</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_KrKN3Tr">
					<idno type="grant-number">2022A1515011544</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,108.02,438.57,415.03,9.94;4,108.02,451.29,414.81,9.94;4,108.02,463.89,150.86,9.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,389.44,438.57,133.62,9.94;4,108.02,451.29,231.55,9.94">Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO) at PAN 2022</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ortega-Bueno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="4,365.73,451.29,151.81,9.94">CLEF 2022 Labs and Workshops</title>
		<title level="s" coord="4,108.02,463.89,73.73,9.94">Notebook Papers</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,108.02,476.49,414.86,9.94;4,108.02,489.21,415.04,9.94;4,108.02,501.81,415.23,9.94;4,108.02,514.53,283.60,9.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,368.59,489.21,154.47,9.94;4,108.02,501.81,284.04,9.94">Style Change Detection Based On Writing Style Similarity-Notebook for PAN at CLEF 2021</title>
		<author>
			<persName coords=""><forename type="first">Zhijie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhongyuan</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Leilei</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaogang</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zeyang</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jieming</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Haojie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jinxi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ziwei</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xuemei</forename><surname>Peng</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="4,420.34,501.81,102.91,9.94;4,108.02,514.53,47.72,9.94">CLEF 2021 Labs and Workshops</title>
		<imprint>
			<date type="published" when="2021-09">September 2021</date>
		</imprint>
	</monogr>
	<note>Notebook Papers</note>
</biblStruct>

<biblStruct coords="4,108.02,527.13,414.94,9.94;4,108.02,539.73,414.77,9.94;4,108.02,552.48,414.73,9.94;4,108.02,565.08,86.67,9.94" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,302.10,527.13,220.86,9.94;4,108.02,539.73,106.78,9.94">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,238.39,539.73,284.41,9.94;4,108.02,552.48,409.97,9.94">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
