<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,355.45,15.42;1,89.29,106.66,93.20,15.42">Overview of the Authorship Verification Task at PAN 2022</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,138.55,105.05,5.42"><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of the Aegean</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,206.99,138.55,79.96,5.42"><forename type="first">Mike</forename><surname>Kestemont</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Antwerp</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,299.59,138.55,89.45,5.42"><forename type="first">Krzysztof</forename><surname>Kredens</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Aston University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,401.68,138.55,53.19,5.42"><forename type="first">Piotr</forename><surname>Pezik</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Aston University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,88.87,152.50,66.47,5.42"><forename type="first">Annina</forename><surname>Heini</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Aston University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,167.99,152.50,83.69,5.42"><forename type="first">Janek</forename><surname>Bevendorff</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Bauhaus-Universität Weimar</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,264.33,152.50,58.99,5.42"><forename type="first">Benno</forename><surname>Stein</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Bauhaus-Universität Weimar</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,354.32,152.50,76.81,5.42"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Leipzig University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,355.45,15.42;1,89.29,106.66,93.20,15.42">Overview of the Authorship Verification Task at PAN 2022</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">F122B3A5FC6379736A9CFCCBC43B19AA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The authorship verification task at PAN 2022 follows the experimental setup of similar shared tasks in the recent past. However, it focuses on a different, and very challenging scenario: given two texts belonging to different discourse types, the task is to determine whether they are written by the same author. Based on a new corpus in English, we provide pairs of texts using four discourse types: essays, emails, text messages, and business memos. The differences in communicative purpose, intended audience, and the level of formality render the cross-discourse-type authorship verification task very hard. We received 7 submissions and evaluated them using the TIRA integrated research architecture, along with two baseline approaches. This paper reviews the submissions and presents a detailed discussion of the evaluation results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Author identification (or authorship attribution) aims to reveal information about the individual(s) who wrote a text <ref type="bibr" coords="1,214.62,461.46,11.48,4.94" target="#b0">[1,</ref><ref type="bibr" coords="1,229.67,461.46,7.65,4.94" target="#b1">2]</ref>. There are several relevant tasks that emulate real-world conditions, mainly closed-set authorship attribution (where there is a finite list of candidate authors) and open-set authorship attribution (where there is a set of candidate authors but this does not necessarily include the true author(s)) <ref type="bibr" coords="1,318.88,502.10,11.37,4.94" target="#b2">[3]</ref>. The former scenario suits cases where only a short list of persons could eventually be the authors of disputed texts while the latter can be applied to cases where such lists of candidates are not available (or reliable enough). A special case of open-set attribution is authorship verification where there is only one candidate author <ref type="bibr" coords="1,121.06,556.30,11.28,4.94" target="#b3">[4]</ref>. Among author identification tasks, authorship attribution plays a key role since any given case can be decomposed into a series of authorship verification instances.</p><p>In authorship verification, texts of known authorship by one author are presented to a system, which is then tasked to verify whether another text has also been written by that same author <ref type="bibr" coords="1,121.53,610.50,11.32,4.94" target="#b4">[5,</ref><ref type="bibr" coords="1,135.59,610.50,7.55,4.94" target="#b5">6]</ref>. In its simplest form, only one text of known authorship is given <ref type="bibr" coords="1,435.59,610.50,11.39,4.94" target="#b6">[7]</ref>. In that case, for a pair of texts (typically one of known authorship and another of unknown authorship), we are asked to determine whether they are written by the same author.</p><p>During the last decade, an extensive list of authorship verification methods have been proposed <ref type="bibr" coords="2,134.52,130.88,11.48,4.94" target="#b3">[4,</ref><ref type="bibr" coords="2,149.32,130.88,7.52,4.94" target="#b5">6,</ref><ref type="bibr" coords="2,160.16,130.88,7.52,4.94" target="#b7">8,</ref><ref type="bibr" coords="2,170.99,130.88,7.65,4.94" target="#b8">9]</ref>. In addition, several previous PAN editions included a relevant shared task <ref type="bibr" coords="2,110.99,144.43,16.56,4.94" target="#b9">[10,</ref><ref type="bibr" coords="2,130.61,144.43,12.59,4.94" target="#b10">11,</ref><ref type="bibr" coords="2,146.26,144.43,12.59,4.94" target="#b11">12,</ref><ref type="bibr" coords="2,161.92,144.43,12.59,4.94" target="#b12">13,</ref><ref type="bibr" coords="2,177.57,144.43,12.42,4.94" target="#b13">14]</ref>. The effectiveness of authorship verification approaches depends on several factors. Naturally, text length is a crucial factor and usually the effectiveness of systems deteriorates when only short or very short texts are given. Another very challenging form of the task considers cases where texts of known and unknown authorship belong to different domains. In cross-domain authorship verification, texts of known and unknown authorship may differ in topic (politics vs. sports), genre (review vs. essay) or even language (English vs. German). In PAN 2015, Both cross-topic and cross-genre authorship verification were considered, and results were with relatively low accuracy were obtained, especially for a cross-genre dataset of essays and reviews in Dutch <ref type="bibr" coords="2,233.78,252.82,16.41,4.94" target="#b11">[12]</ref>. In the last two editions of PAN <ref type="bibr" coords="2,402.18,252.82,16.55,4.94" target="#b12">[13,</ref><ref type="bibr" coords="2,421.70,252.82,14.11,4.94" target="#b13">14]</ref> fanfiction texts (i.e., non-professional fiction published online by fan authors) belonging to different fandoms (i.e., fanfiction inspired by certain highly popular works) were used. A large training dataset of more than 350,000 verification instances was compiled for this task that enabled the application of powerful deep learning models <ref type="bibr" coords="2,245.86,307.02,16.41,4.94" target="#b14">[15]</ref>. Perhaps surprisingly, the best results obtained were rather high, suggesting that most fanfiction authors may retain their stylistic choices over different fandoms, albeit other factors that may have artificially boosted the results could not be ruled out.</p><p>The current edition of PAN focuses on cross-discourse type authorship verification where texts of known and unknown authorship belong to different discourse types. In particular, these discourse types have significant differences concerning communicative purpose, intended audience, or level of formality. For example, the discourse types of argumentative essays and text messages sent to family members have important stylistic differences imposed by the norms of discourse types. It is therefore very challenging to distinguish authorial characteristics that remain intact across discourse types. In addition, discourse types strongly correlates with text length (e.g., essays are much longer than text messages) and cross-discourse type authorship verification can also be used to study the effect of text length in the effectiveness of authorship verification approaches approaches.</p><p>In this paper, we first present the new datasets and the evaluation framework for the crossdiscourse type authorship verification shared task at PAN 2022. Next, we shall survey the received submissions and evaluate in detail their effectiveness. Finally, we discuss the main conclusions and possible directions for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The PAN Cross-Discourse Type Authorship Verification Corpus 2022</head><p>A novel dataset was created from a subset of the recent Aston 100 Idiolects Corpus in English (Kredens, Heini and Pezik 2021), <ref type="foot" coords="2,229.06,606.89,3.71,3.61" target="#foot_0">1</ref> including a rich set of discourse types authored by 112 individuals. We used the following discourse types of written language: emails, essays, text messages, and business memos. All individuals represented in the corpus have a similar age <ref type="bibr" coords="2,453.98,636.63,14.07,4.94" target="#b17">(18)</ref><ref type="bibr" coords="2,468.05,636.63,4.69,4.94" target="#b18">(19)</ref><ref type="bibr" coords="2,468.05,636.63,4.69,4.94" target="#b19">(20)</ref><ref type="bibr" coords="2,468.05,636.63,4.69,4.94" target="#b20">(21)</ref><ref type="bibr" coords="2,472.74,636.63,14.07,4.94" target="#b21">(22)</ref> and are native speakers of English. The topic of text samples is not restricted, while the level of formality can vary within a certain discourse type (e.g., text messages may be addressed to family members or other acquaintances). Table <ref type="table" coords="3,297.97,337.68,4.99,4.94" target="#tab_0">1</ref> gives an overview of the data and the parts of it used of training and testing different aspects of cross-discourse type authorship verification. This corpus has been anonymized in that named-entities such as mentions of locations, person names, addresses, etc. were manually replaced with generic placeholder tags. This is very useful for evaluating authorship verification methods in cross-discourse type scenarios since the presence of author-specific and topic-specific information is reduced.</p><p>In order to compile the required training and test datasets for the shared task at hand, the corpus needed further preprocessing. First, we split the available individuals into two equal and non-overlapping sets, one to be used for the training dataset and the other for the test dataset. That way, it is ensured that any kind of particularities among the training authors will not affect the effectiveness on the test dataset. In addition, we took advantage of the demographic metadata available and ensured a stable gender distribution of individuals in both the training and test dataset. More specifically, the training and test datasets represent writings by 56 authors each (10 male, 45 female and 1 of unidentified gender).</p><p>The dataset comprises a set of text pairs and in each pair the two texts belong to two different discourse types. All six combinations of the four available discourse types are taken into account. However, the distribution of text pairs over the combination of discourse types is not homogeneous since it depends on the available texts belonging to each discourse type. For example, the corpus comprises only one business memo and multiple email messages per individual. Nevertheless, the distribution of verification instances per discourse type combination is similar in both training and test datasets as can be seen in Table <ref type="table" coords="3,453.19,608.66,3.81,4.94" target="#tab_0">1</ref>. Similarly, both training and test datasets have a balanced distribution of positive/negative verification cases. This is also valid for each combination of discourse types (e.g., half of the pairs belonging to the combination essay-email is positive and the other half is negative).</p><p>Since the length of texts belonging to certain discourse types can be limited, we concatenated multiple texts of the same discourse type to produce longer text samples. In more detail, email messages were concatenated so that a text sample of at least 2,000 characters was obtained. The date of email messages was taken into account so that consecutive messages are concatenated. In the case of text messages, we concatenated messages sent either to friends or to family, so that text samples of at least 500 characters were obtained. We inserted the special tag &lt;new&gt; in the concatenated messages to indicate the original message boundaries. The text lengths in Table <ref type="table" coords="4,115.79,185.07,5.07,4.94" target="#tab_0">1</ref> for email and text messages refer to text samples created in this manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Evaluating Cross-Discourse Type Authorship Verification</head><p>In authorship verification, one has to approximate the target function 𝜑 : (𝐷 𝑘 , 𝑑 𝑢 ) → {𝑇, 𝐹 }, where 𝐷 𝑘 is a set of texts of known authorship and 𝑑 𝑢 is a text of unknown or disputed authorship. In the current edition of the task, we consider 𝐷 𝑘 as singleton. Thus, the task is to approximate the target function 𝜑 : (𝑑 𝑘 , 𝑑 𝑢 ) → {𝑇, 𝐹 } for a pair of texts. If 𝜑(𝑑 𝑘 , 𝑑 𝑢 ) = 𝑇 , then the author of 𝑑 𝑘 is also the author of 𝑑 𝑢 (positive instance) and if 𝜑(𝑑 𝑘 , 𝑑 𝑢 ) = 𝐹 , then the author of 𝑑 𝑘 is not the same as the author of 𝑑 𝑢 (negative instance). The main novelty of the current edition is that 𝑑 𝑘 and 𝑑 𝑢 belong to different discourse types.</p><p>The evaluation framework is similar to the one used in recent shared tasks at PAN <ref type="bibr" coords="4,467.97,338.05,16.21,4.94" target="#b13">[14]</ref>. For each authorship verification instance (a pair of texts) of the test dataset, participants have to produce a scalar score 𝑎 𝑖 (in the [0, 1] range) indicating the probability that the pair was written by the same author. It is possible for participants to leave text pairs unanswered by submitting a score of precisely 𝑎 𝑖 = 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Evaluation Measures</head><p>Similar to recent editions of the authorship verification task <ref type="bibr" coords="4,375.47,441.49,16.42,4.94" target="#b13">[14]</ref>, we adopt a diverse set of effectiveness measures to highlight different aspects of the capabilities of an authorship verification model. We reused the four measures from the 2020 edition, but also included the Brier score <ref type="bibr" coords="4,139.96,482.13,17.84,4.94" target="#b15">[16]</ref> as an additional fifth measure (following discussions with participants and the audience at the 2020 workshop). In total, the following effectiveness measures were used:</p><p>• AUROC: the area under the ROC curve, • c@1: a variant of the conventional accuracy measure, which rewards systems that leave difficult problems unanswered <ref type="bibr" coords="4,254.43,542.64,16.25,4.94" target="#b16">[17]</ref>, • F 1 : the well-known F 1 effectiveness measure (not taking into account non-answers), • F 0.5𝑢 : a newly-proposed F 0.5 -based measure that emphasizes correctly-answered sameauthor cases and rewards non-answers <ref type="bibr" coords="4,292.38,584.24,16.25,4.94" target="#b17">[18]</ref>, • Brier: the complement of the Brier loss function <ref type="bibr" coords="4,334.28,598.27,17.82,4.94" target="#b15">[16]</ref> focusing on the accuracy of probabilistic predictions (as implemented in sklearn <ref type="bibr" coords="4,321.47,611.82,15.71,4.94" target="#b18">[19]</ref>). This measure rewards verifiers that make "bold" but correct predictions (i.e., 𝑎 𝑖 close to 0.0 or 1.0) and it indirectly penalizes less confident ones, including non-answers (𝑎 𝑖 = 0.5). In line with the other measures we take its complement so that higher scores correspond to better effectiveness. • The average of the above measures is used as final score to rank submitted systems.</p><p>We also report runtime on TIRA to give an indication of relative efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Baselines</head><p>In order to facilitate the comparison of the submitted methods with established approaches from the literature in the field, we provide two baseline methods that are based on character n-grams or character sequences. The source code of the following two methods were made available to the participants at the start of the campaign (together with an official implementation of the evaluation measures):</p><p>• Compression-based model. Given a pair of texts 𝑡 1 and 𝑡 2 , the cross-entropy of 𝑡 2 based on the Prediction by Partial Matching (PPM) model of 𝑡 1 is computed, and vice-versa <ref type="bibr" coords="5,487.56,201.06,16.08,4.94" target="#b19">[20]</ref>.</p><p>Then, a logistic regression classifier is trained using the mean and absolute difference of the two cross-entropies. In addition, using a small radius verification scores around 0.5 are set to exactly 0.5. • Distance-based character n-gram model <ref type="bibr" coords="5,317.70,256.61,16.21,4.94" target="#b20">[21]</ref>. The most frequent character 4-grams are extracted from the training texts and used to represent each text. Then, given a pair of texts, the cosine similarity between them is calculated. During training, two threshold values 𝑝 1 and 𝑝 2 are optimized to scale the verification scores. All verification scores lower than 𝑝 1 correspond to negative answers, all scores greater than 𝑝 2 are scaled to positive answers and the remaining scores are set to 0.5, implying that these are hard instances that deliberately are left unanswered.</p><p>The baselines are not tailored to particular discourse types, e.g., by tuning hyperparameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Survey of Submissions</head><p>We received seven submissions and evaluated their effectiveness and efficiency using the TIRA integrated research architecture <ref type="bibr" coords="5,262.70,432.60,16.37,4.94" target="#b21">[22]</ref>. All participants also submitted a notebook paper describing their approach. The main characteristics of each approach are provided in Table <ref type="table" coords="5,496.84,446.15,3.74,4.94" target="#tab_1">2</ref>.</p><p>Most participants followed the recent trend in natural language processing and used pretrained language models like BERT, T5, or MPNET to obtain text embeddings. Konstantinou et al. <ref type="bibr" coords="5,113.44,486.79,17.91,4.94" target="#b22">[23]</ref> report that several such models were compared and the most effective one selected. Approaches not using pre-trained language models exploit graph-based text representations <ref type="bibr" coords="5,487.07,500.34,16.09,4.94" target="#b23">[24]</ref>, spectral analysis <ref type="bibr" coords="5,167.49,513.89,16.41,4.94" target="#b24">[25]</ref>, or representations based on traditional feature engineering including features like frequencies of part-of-speech (POS) tags and word unigrams (najafi22).</p><p>Regarding the classification model, most participants rely on fully-connected layers that combine the information from the text representation step. It is also reported that several traditional machine learning algorithms, such as support vector machines and random forests were examined but their effectiveness was found to be comparatively low <ref type="bibr" coords="5,429.97,581.64,16.41,4.94" target="#b22">[23]</ref>. Other deep learning methods used are convolutional and siamese neural networks. Since the use of deep learning technology usually requires a considerable amount of training and some extra validation data, some participants attempted to augment the provided dataset by generating new authorship verification instances with the help of the available metadata.</p><p>Surprisingly, no participant studied discourse type-specific approaches for the given combinations despite their substantial differences. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Evaluation Results</head><p>This section presents an in-depth analysis of the effectiveness and efficiency of the submitted approaches regarding overall, dependent on discourse type, with respect to bias, runtime, and in comparison to the previous year's participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Overall results</head><p>Table <ref type="table" coords="6,114.45,576.51,4.97,4.94" target="#tab_2">3</ref> shows the overall results of all participants. In general, the effectiveness of all submissions is quite low, reflecting the difficulty of the task. The approaches of najafi22, galicia22, and jinli22 clearly outperform the rest of the submissions. It is also surprising that a naive baseline achieved the best overall score, despite the fact that most participant models are quite sophisticated. On the other hand, the most effective method submitted (najafi22) outperforms all other submissions and baselines in three out of five evaluation measures. Its main weakness seems to be the low Brier score which means that its probabilistic predictions are in need of improvement (even if its binary class assignments are relatively strong). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Results by discourse type</head><p>Table <ref type="table" coords="7,115.15,542.85,4.97,4.94" target="#tab_3">4</ref> shows breaks down the results with respect to the six pairings of discourse types. Recall that each discourse type comes with different average text lengths (see Table <ref type="table" coords="7,435.90,556.40,3.60,4.94" target="#tab_0">1</ref>). For instance, essays are much longer than the rest of the examined discourse types. As Table <ref type="table" coords="7,456.42,569.95,8.60,4.94" target="#tab_3">4b</ref>, c, and f show, when essays are part of a pairing, the submission of galicia22 is the most effective system in terms overall effectiveness. Where essays are excluded (Table <ref type="table" coords="7,423.05,597.05,8.47,4.94" target="#tab_3">4a</ref>, e, and d), their approach is outperformed by that of najafi22. On the shortest discourse types (business memos and text messages; Table <ref type="table" coords="7,237.75,624.15,9.31,4.94" target="#tab_3">4d</ref>) the submission of jinli22 seems to be the most effective. This pairing of discourse type also has the lowest overall effectiveness, indicating that text length (plus cross-discourse verification) remains a crucial factor in authorship verification. The baseline-cngdist22 is relatively stable across combinations of discourse types, while baseline-compressor22 achieves its optimal results when the longest discourse types (essays and emails) are considered. It practically fails, however, when only very short texts are available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Bias</head><p>Table <ref type="table" coords="8,116.82,347.13,10.26,4.94" target="#tab_4">5a</ref> shows the number of positive and negative answers provided by each verification model. Note that these are not necessarily correct predictions: they merely correspond to the test instances where the estimated verification score is lower/greater than 0.5. In addition, the number of test instances with a verification score equal to 0.5 is also presented-these correspond to instances left unanswered according to the definition of the task. These three numbers indicate the bias of each verification model. We reiterate that the actual distribution of positive/negative instances in the test dataset is balanced. As can be seen, very few submissions leave instances unanswered. This means that their effectiveness, especially in terms of c@1, can be significantly improved by incorporating a mechanism to exclude borderline instances from positive/negative answers, similar to the ones used by the baselines.</p><p>It is also remarkable that the approaches of najafi22 and jinli22 (along with baseline-compressor22) are unbiased, providing roughly similar numbers of positive and negative answers. In contrast, the submission of galicia22 as well as baseline-cngdist22 are clearly biased towards positive answers, while huang22, lei22, yihuiye22, and cresposanchez22 are clearly biased towards negative answers. Note that these biases do not affect AUROC measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Efficiency</head><p>Beyond effectiveness, another criterion for evaluating an authorship verification system is in terms of efficiency or its runtime cost. Depending on the application of specific kinds of technology, this is a significant criterion, especially when large volumes of text have to be analyzed. Table <ref type="table" coords="8,159.42,627.20,10.24,4.94" target="#tab_4">5b</ref> shows the elapsed time of the run of each submitted method on TIRA. As can be seen, the approaches that avoid the use of pre-trained language models <ref type="bibr" coords="8,419.96,640.75,16.40,4.94" target="#b24">[25,</ref><ref type="bibr" coords="8,439.09,640.75,14.01,4.94" target="#b23">24]</ref> achieve the lowest runtime by a large margin. The highest runtime is required by the approach of huang22 that splits texts into segments and examines all combinations of segments. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">A Transfer-learning Experiment</head><p>We applied the top-performing approaches from the previous 2021 edition of PAN <ref type="bibr" coords="9,475.11,242.12,18.07,4.94" target="#b29">[30]</ref> to the current test dataset. Thanks to software submissions at TIRA, this can be accomplished with relative ease. This amounts to a transfer-learning experiment, since the three models are trained and fine-tuned on a cross-fandom authorship verification dataset but now tested on our cross-discourse type dataset. The following methods have been employed:</p><p>• boenninghoff21 <ref type="bibr" coords="9,200.56,318.84,16.56,4.94" target="#b30">[31]</ref>: A deep learning-based approach including neural feature extraction and deep metric learning, deep Bayes factor scoring, uncertainty modeling and adaptation, a combined loss function, and an additional out-of-distribution detector for non-responses. In its final step, the model was extended to a majority-voting ensemble. • embarcaderoruiz21 <ref type="bibr" coords="9,215.40,374.39,16.53,4.94" target="#b31">[32]</ref>: Its main idea is similar to that of galicia22. A graph-based representation approach is combined with a Siamese network. • weerasinghe21 <ref type="bibr" coords="9,194.41,402.84,16.56,4.94" target="#b32">[33]</ref>: A variety of stylometric features, including character and POS n-grams, function words, and vocabulary richness measures and a logistic regression classifier, fed with the absolute differences of these features for each text pair.</p><p>We made no attempt to modify these methods before applying them to the new cross-discourse type test dataset.</p><p>The effectiveness of the above-mentioned methods on the PAN 2021 test data was exceptional. All of them obtained an overall score (over the same five evaluation measures used in this paper) of greater than 0.93 <ref type="bibr" coords="9,178.83,506.65,16.27,4.94" target="#b29">[30]</ref>. Table <ref type="table" coords="9,229.26,506.65,10.09,4.94" target="#tab_5">6a</ref> shows the effectiveness of the 2021 models on the 2022 test data. Unsurprisingly, the three models perform much worse. Their overall effectiveness on the cross-discourse type dataset is very low, much lower than all but one of the seven submissions and the two baselines shown in Table <ref type="table" coords="9,257.64,547.30,3.70,4.94" target="#tab_2">3</ref>. This means that fine-tuning such models to particular datasets hurts their generalizability. Moreover, cross-fandom verification and cross-discourse type verification have different characteristics in terms of the two available datasets.</p><p>Table <ref type="table" coords="9,126.42,587.95,10.24,4.94" target="#tab_5">6b</ref> shows the number of positive and negative answers as well as non-answers for each of the three 2021 models, which exert a clear bias of models towards negative answers. Note that in the 2021 cross-fandom dataset, all texts have similar text length. Likely, this factor along with other substantial differences between fanfiction and the discourse types considered in the cross-discourse type dataset confuse these models (or at least that they need appropriate finetuning to improve the scaling of the produced verification scores). Note that the AUROC scores (which do not depend on the scaling of verification scores) are also quite low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>Previous shared tasks on authorship attribution at PAN played a crucial role to advance research in the field of authorship analysis and modern methods have been using the PAN datasets for evaluation purposes extensively and have incrementally improved the state of the art <ref type="bibr" coords="10,481.71,141.64,11.48,4.94" target="#b5">[6,</ref><ref type="bibr" coords="10,496.18,141.64,7.65,4.94" target="#b7">8]</ref>. Recent editions of PAN focused on fanfiction. The very good results obtained by the topperforming submissions there may have given the false impression that authorship verification is an almost solved problem <ref type="bibr" coords="10,216.04,182.29,16.43,4.94" target="#b12">[13,</ref><ref type="bibr" coords="10,235.20,182.29,12.32,4.94" target="#b13">14]</ref>. This is in fact not the case, as our experiment shows.</p><p>This year, we focused on a very challenging version of the authorship verification task where text pairs of different discourse types are used. When texts differ in communicative purpose, intended audience, or level of formality, it is very challenging to identify stable characteristics associated with authors across these discourse types. The effectiveness of all submissions in the cross-discourse type datasets was comparatively low, some as low as a random-guess baseline.</p><p>It is also surprising that all submissions, despite their increased level of sophistication in most of the cases, were outperformed by a naive baseline based on character n-grams and cosine similarity (at least according to the overall effectiveness across all five evaluation measures). This suggests that traditional methods based on well-known stylometric features could still be more effective than deep learning approaches using modern pre-trained language models for this challenging task. Another factor is the volume of data available for training (roughly, 12,000 instances) that can be considered too little for deep learning-based approaches.</p><p>Another crucial issue is text length. It seems that when the relatively long essays were used as inputs, the graph-based approach of galicia22 was more effective. When shorter texts from discourse types like emails, business memos, and text messages were used, the pre-trained language-model-based approaches of najafi22 and jinli22 were more effective.</p><p>The overall low effectiveness achieved shows that there is a lot of room for improvement in cross-discourse type authorship verification. All submitted approaches adopted a unified model that predicts authorship disregarding combinations of discourse types. Having separate models for each combination of discourse types is an obvious next step. This would mean, however, that the training data should also be split into smaller parts based on the combinations of discourse types. An ensemble method combining traditional stylometric models and pre-trained language models appears like a promising approach in this regard.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,100.45,371.63,197.24"><head>Table 1</head><label>1</label><figDesc>Key statistics of the new dataset for 2022 cross-discourse type authorship verification task.</figDesc><table coords="3,188.34,135.13,218.59,162.55"><row><cell>Subset</cell><cell>Training</cell><cell>Test</cell></row><row><cell>Author match</cell><cell cols="2">Text pairs</cell></row><row><cell>Positive (same author)</cell><cell>6,132 (50.0%)</cell><cell>5,239 (50.0%)</cell></row><row><cell>Negative (different author)</cell><cell>6,132 (50.0%)</cell><cell>5,239 (50.0%)</cell></row><row><cell>Discourse type pairings</cell><cell cols="2">Text pairs</cell></row><row><cell>Email-Text message</cell><cell>7,484 (61.0%)</cell><cell>6,092 (58.1%)</cell></row><row><cell>Essay-Email</cell><cell>1,618 (13.2%)</cell><cell>1,454 (13.9%)</cell></row><row><cell>Essay-Text message</cell><cell>1,182 (9.6%)</cell><cell>1,128 (10.8%)</cell></row><row><cell>Business memo-Email</cell><cell>1,014 (8.3%)</cell><cell>900 (8.6%)</cell></row><row><cell>Business memo-Text message</cell><cell>780 (6.4%)</cell><cell>718 (6.9%)</cell></row><row><cell>Essay-Business memo</cell><cell>186 (1.5%)</cell><cell>186 (1.8%)</cell></row><row><cell>Discourse type</cell><cell cols="2">Text length (avg. chars)</cell></row><row><cell>Essay</cell><cell>11,098</cell><cell>10,117</cell></row><row><cell>Email</cell><cell>2,385</cell><cell>2,323</cell></row><row><cell>Business memo</cell><cell>1,255</cell><cell>1,042</cell></row><row><cell>Text message</cell><cell>611</cell><cell>601</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,88.99,90.49,418.66,168.06"><head>Table 2</head><label>2</label><figDesc>Review of the basic characteristics of the submitted approaches: POS, NEs, SOM, and FC denote partof-speech tags, named entities, self-organizing maps, and fully-connected layers, respectively.</figDesc><table coords="6,89.29,137.55,417.07,121.00"><row><cell>System</cell><cell>Ref. Representation</cell><cell>Classification</cell><cell cols="2">Augmentation Type-specific</cell></row><row><cell cols="3">cresposanchez22 [25] word unigrams, doc2vec FC</cell><cell>Yes</cell><cell>No</cell></row><row><cell></cell><cell>(text and POS), SOM</cell><cell>FC</cell><cell>Yes</cell><cell>No</cell></row><row><cell>galicia22</cell><cell>[24] graph-based, POS</cell><cell cols="2">Siamese network Yes</cell><cell>No</cell></row><row><cell>huang22</cell><cell>[26] BERT</cell><cell>FC</cell><cell>No</cell><cell>No</cell></row><row><cell>jinli22</cell><cell>[23] MPNET</cell><cell>FC</cell><cell>No</cell><cell>No</cell></row><row><cell>lei22</cell><cell>[27] BERT</cell><cell>FC</cell><cell>No</cell><cell>No</cell></row><row><cell>najafi22</cell><cell cols="3">[28] T5, word unigrams, POS, CNN, attention No</cell><cell>No</cell></row><row><cell></cell><cell>NEs, Punctuation</cell><cell>block, FC</cell><cell>No</cell><cell>No</cell></row><row><cell>yihuiye22</cell><cell>[29] BERT</cell><cell>TextCNN</cell><cell>Yes</cell><cell>No</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.99,280.59,418.66,168.06"><head>Table 3</head><label>3</label><figDesc>Evaluation results for the cross-discourse type authorship verification task, ranked by overall effectiveness. Bold font highlights best in column.</figDesc><table coords="6,90.88,327.44,413.52,121.22"><row><cell>Participant</cell><cell>AUROC</cell><cell>c@1</cell><cell>F 1</cell><cell>F 0.5𝑢</cell><cell>Brier</cell><cell>Overall</cell></row><row><cell>baseline-cngdist22</cell><cell>0.546</cell><cell>0.496</cell><cell>0.669</cell><cell>0.542</cell><cell>0.749</cell><cell>0.600</cell></row><row><cell>najafi22</cell><cell>0.598</cell><cell>0.571</cell><cell>0.576</cell><cell>0.571</cell><cell>0.618</cell><cell>0.587</cell></row><row><cell>galicia22</cell><cell>0.512</cell><cell>0.499</cell><cell>0.628</cell><cell>0.544</cell><cell>0.741</cell><cell>0.585</cell></row><row><cell>jinli22</cell><cell>0.577</cell><cell>0.557</cell><cell>0.581</cell><cell>0.563</cell><cell>0.589</cell><cell>0.573</cell></row><row><cell>baseline-compressor22</cell><cell>0.541</cell><cell>0.493</cell><cell>0.570</cell><cell>0.478</cell><cell>0.750</cell><cell>0.566</cell></row><row><cell>lei22</cell><cell>0.539</cell><cell>0.539</cell><cell>0.399</cell><cell>0.488</cell><cell>0.539</cell><cell>0.501</cell></row><row><cell>yihuiye22</cell><cell>0.542</cell><cell>0.526</cell><cell>0.398</cell><cell>0.461</cell><cell>0.565</cell><cell>0.499</cell></row><row><cell>huang22</cell><cell>0.519</cell><cell>0.519</cell><cell>0.196</cell><cell>0.328</cell><cell>0.519</cell><cell>0.416</cell></row><row><cell>cresposanchez22</cell><cell>0.500</cell><cell>0.500</cell><cell>0</cell><cell>0</cell><cell>0.748</cell><cell>0.350</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,88.99,90.49,417.00,405.37"><head>Table 4</head><label>4</label><figDesc>Evaluation results for the cross-discourse type authorship verification task, dependent on discourse type pairings, ranked by overall effectiveness on the entire test dataset (see Table3). Bold font highlights best in column.</figDesc><table coords="7,89.29,139.43,416.69,356.42"><row><cell></cell><cell cols="4">(a) Email-Text message</cell><cell></cell><cell></cell><cell cols="2">(b) Essay-Email</cell></row><row><cell>Participant</cell><cell>AUROC c@1</cell><cell cols="4">F 1 F 0.5𝑢 Brier Overall</cell><cell>AUROC c@1</cell><cell cols="3">F 1 F 0.5𝑢 Brier Overall</cell></row><row><cell>baseline-cngdist22</cell><cell cols="5">0.585 0.505 0.672 0.555 0.751 0.614</cell><cell cols="4">0.514 0.489 0.657 0.542 0.740</cell><cell>0.589</cell></row><row><cell>najafi22</cell><cell cols="4">0.613 0.583 0.579 0.581 0.628</cell><cell>0.597</cell><cell cols="4">0.570 0.549 0.583 0.557 0.605</cell><cell>0.573</cell></row><row><cell>galicia22</cell><cell cols="4">0.517 0.502 0.641 0.549 0.740</cell><cell>0.590</cell><cell cols="4">0.496 0.498 0.608 0.537 0.744</cell><cell>0.577</cell></row><row><cell>jinli22</cell><cell cols="4">0.599 0.576 0.603 0.581 0.607</cell><cell>0.593</cell><cell cols="4">0.588 0.559 0.574 0.563 0.600</cell><cell>0.577</cell></row><row><cell>baseline-compressor22</cell><cell cols="5">0.570 0.480 0.661 0.499 0.752 0.592</cell><cell cols="4">0.531 0.481 0.659 0.531 0.750 0.590</cell></row><row><cell>lei22</cell><cell cols="4">0.537 0.537 0.350 0.462 0.537</cell><cell>0.484</cell><cell cols="4">0.585 0.585 0.528 0.575 0.585</cell><cell>0.571</cell></row><row><cell>yihuiye22</cell><cell cols="4">0.547 0.530 0.409 0.470 0.569</cell><cell>0.505</cell><cell cols="4">0.548 0.529 0.371 0.449 0.558</cell><cell>0.491</cell></row><row><cell>huang22</cell><cell cols="4">0.519 0.519 0.197 0.329 0.519</cell><cell>0.417</cell><cell cols="4">0.553 0.553 0.283 0.444 0.553</cell><cell>0.477</cell></row><row><cell>cresposanchez22</cell><cell cols="2">0.500 0.500 0</cell><cell>0</cell><cell>0.748</cell><cell>0.350</cell><cell cols="2">0.500 0.500 0</cell><cell>0</cell><cell>0.748</cell><cell>0.350</cell></row><row><cell></cell><cell cols="4">(c) Essay-Text message</cell><cell></cell><cell cols="4">(e) Business memo-Email</cell></row><row><cell>Participant</cell><cell>AUROC c@1</cell><cell cols="4">F 1 F 0.5𝑢 Brier Overall</cell><cell cols="4">AUROC c@1 F 1 F 0.5𝑢 Brier Overall</cell></row><row><cell>baseline-cngdist22</cell><cell cols="5">0.540 0.493 0.673 0.539 0.750 0.599</cell><cell cols="4">0.509 0.443 0.67 0.500 0.748 0.574</cell></row><row><cell>najafi22</cell><cell cols="4">0.568 0.553 0.567 0.556 0.595</cell><cell>0.568</cell><cell cols="4">0.606 0.586 0.612 0.589 0.633 0.605</cell></row><row><cell>galicia22</cell><cell cols="4">0.513 0.493 0.604 0.534 0.743</cell><cell>0.577</cell><cell cols="4">0.521 0.513 0.647 0.556 0.742</cell><cell>0.596</cell></row><row><cell>jinli22</cell><cell cols="4">0.476 0.483 0.486 0.485 0.520</cell><cell>0.490</cell><cell cols="4">0.562 0.547 0.565 0.552 0.569</cell><cell>0.559</cell></row><row><cell>baseline-compressor22</cell><cell cols="5">0.567 0.513 0.130 0.186 0.751 0.429</cell><cell cols="4">0.514 0.494 0.214 0.269 0.746</cell><cell>0.447</cell></row><row><cell>lei22</cell><cell cols="4">0.519 0.519 0.299 0.412 0.519</cell><cell>0.453</cell><cell cols="4">0.512 0.512 0.497 0.507 0.512</cell><cell>0.508</cell></row><row><cell>yihuiye22</cell><cell cols="4">0.509 0.508 0.336 0.410 0.542</cell><cell>0.461</cell><cell cols="4">0.539 0.520 0.414 0.461 0.571</cell><cell>0.501</cell></row><row><cell>huang22</cell><cell cols="4">0.516 0.516 0.173 0.301 0.516</cell><cell>0.404</cell><cell cols="4">0.493 0.493 0.099 0.185 0.493</cell><cell>0.353</cell></row><row><cell>cresposanchez22</cell><cell cols="2">0.500 0.500 0</cell><cell>0</cell><cell>0.748</cell><cell>0.350</cell><cell cols="2">0.500 0.500 0</cell><cell>0</cell><cell>0.748</cell><cell>0.350</cell></row><row><cell></cell><cell cols="4">(d) Business memo-Text message</cell><cell></cell><cell cols="4">(f) Essay-Business memo</cell></row><row><cell>Participant</cell><cell>AUROC c@1</cell><cell cols="4">F 1 F 0.5𝑢 Brier Overall</cell><cell>AUROC c@1</cell><cell cols="3">F 1 F 0.5𝑢 Brier Overall</cell></row><row><cell>baseline-cngdist22</cell><cell cols="5">0.525 0.376 0.673 0.455 0.748 0.555</cell><cell cols="4">0.474 0.466 0.647 0.512 0.740</cell><cell>0.568</cell></row><row><cell>najafi22</cell><cell cols="4">0.582 0.534 0.515 0.526 0.589</cell><cell>0.549</cell><cell cols="4">0.545 0.538 0.533 0.536 0.572</cell><cell>0.545</cell></row><row><cell>galicia22</cell><cell cols="4">0.487 0.464 0.553 0.503 0.741</cell><cell>0.549</cell><cell cols="4">0.496 0.500 0.635 0.547 0.739 0.584</cell></row><row><cell>jinli22</cell><cell cols="4">0.551 0.535 0.567 0.545 0.566</cell><cell>0.553</cell><cell cols="4">0.528 0.500 0.542 0.516 0.532</cell><cell>0.524</cell></row><row><cell>baseline-compressor22</cell><cell cols="4">0.524 0.518 0.065 0.127 0.746</cell><cell>0.396</cell><cell cols="4">0.474 0.477 0.477 0.446 0.744</cell><cell>0.523</cell></row><row><cell>lei22</cell><cell cols="4">0.539 0.539 0.472 0.517 0.539</cell><cell>0.521</cell><cell cols="4">0.500 0.500 0.367 0.437 0.500</cell><cell>0.461</cell></row><row><cell>yihuiye22</cell><cell cols="4">0.553 0.538 0.463 0.499 0.579</cell><cell>0.526</cell><cell cols="4">0.522 0.492 0.214 0.302 0.545</cell><cell>0.415</cell></row><row><cell>huang22</cell><cell cols="4">0.481 0.481 0.126 0.214 0.481</cell><cell>0.356</cell><cell cols="4">0.527 0.527 0.290 0.415 0.527</cell><cell>0.457</cell></row><row><cell>cresposanchez22</cell><cell cols="2">0.500 0.500 0</cell><cell>0</cell><cell>0.748</cell><cell>0.350</cell><cell cols="2">0.500 0.500 0</cell><cell>0</cell><cell>0.748 0.350</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,88.99,90.49,417.17,180.20"><head>Table 5</head><label>5</label><figDesc>(a) Number of positive and negative answers provided by each verification model along with the number of unanswered instances of the test dataset. (b) Runtime efficiency of the submitted approaches.</figDesc><table coords="8,89.29,130.13,416.69,140.55"><row><cell>(a)</cell><cell></cell><cell></cell><cell></cell><cell>(b)</cell><cell></cell></row><row><cell>System</cell><cell cols="3">Positive Negative Unanswered</cell><cell>System</cell><cell>Run time</cell></row><row><cell>cresposanchez22</cell><cell>0</cell><cell>10,478</cell><cell>0</cell><cell cols="2">cresposanchez22 00:05:36</cell></row><row><cell>galicia22</cell><cell>8,874</cell><cell>1,604</cell><cell>0</cell><cell>galicia22</cell><cell>00:07:22</cell></row><row><cell>huang22</cell><cell>1,031</cell><cell>9,447</cell><cell>0</cell><cell>lei22</cell><cell>06:04:59</cell></row><row><cell>jinli22</cell><cell>5,820</cell><cell>4,658</cell><cell>0</cell><cell>yihuiye22</cell><cell>07:16:59</cell></row><row><cell>lei22</cell><cell>2,805</cell><cell>7,673</cell><cell>0</cell><cell>najafi22</cell><cell>18:18:32</cell></row><row><cell>najafi22</cell><cell>5,355</cell><cell>5,083</cell><cell>40</cell><cell>jinli22</cell><cell>23:25.62</cell></row><row><cell>yihuiye22</cell><cell>2,841</cell><cell>7,116</cell><cell>521</cell><cell>huang22</cell><cell>31:04:56</cell></row><row><cell>baseline-cngdist22</cell><cell>9,199</cell><cell>17</cell><cell>1,262</cell><cell></cell><cell></cell></row><row><cell>baseline-compressor22</cell><cell>3,927</cell><cell>3,268</cell><cell>3,283</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,88.99,90.49,417.00,104.63"><head>Table 6</head><label>6</label><figDesc>(a) Evaluation results of the top-performing models submitted to the PAN 2021 shared task on authorship verification on the cross-discourse type test data. (b) Number of positive and negative answers as well as non-answers provided by these models.</figDesc><table coords="9,89.29,141.65,416.69,53.46"><row><cell></cell><cell>(a)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(b)</cell><cell></cell><cell></cell></row><row><cell>System</cell><cell>AUROC</cell><cell>c@1</cell><cell>F 1</cell><cell>F 0.5𝑢</cell><cell>Brier</cell><cell>Overall</cell><cell>Positive</cell><cell>Negative</cell><cell>Unanswered</cell></row><row><cell>boenninghoff21</cell><cell>0.513</cell><cell>0.501</cell><cell>0.002</cell><cell>0.005</cell><cell>0.531</cell><cell>0.310</cell><cell>10</cell><cell>10,370</cell><cell>98</cell></row><row><cell>embarcaderoruiz21</cell><cell>0.538</cell><cell>0.502</cell><cell>0.063</cell><cell>0.116</cell><cell>0.581</cell><cell>0.360</cell><cell>309</cell><cell>9,295</cell><cell>874</cell></row><row><cell>weerasinghe21</cell><cell>0.488</cell><cell>0.500</cell><cell>0.011</cell><cell>0.027</cell><cell>0.506</cell><cell>0.306</cell><cell>57</cell><cell>10,421</cell><cell>0</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,108.93,673.71,163.01,4.06"><p>https://fold.aston.ac.uk/handle/123456789/17</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,111.10,549.02,383.59,4.51;10,111.11,560.98,267.74,4.51" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,171.83,549.02,209.29,4.51">A survey of modern authorship attribution methods</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<idno type="DOI">10.1002/asi.21001</idno>
		<ptr target="https://doi.org/10.1002/asi.21001.doi:10.1002/asi.21001" />
	</analytic>
	<monogr>
		<title level="j" coord="10,389.34,549.02,28.70,4.51">JASIST</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="538" to="556" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,111.11,572.93,394.88,4.51;10,110.76,584.89,301.51,4.51" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,246.51,572.93,197.08,4.51">Computational methods in authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,450.94,572.93,55.05,4.51;10,110.76,584.89,238.75,4.51">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="9" to="26" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,111.11,596.84,382.11,4.51;10,111.11,608.80,267.97,4.51" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,248.47,596.84,136.98,4.51">Authorship attribution in the wild</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10579-009-9111-2</idno>
	</analytic>
	<monogr>
		<title level="j" coord="10,393.04,596.84,100.17,4.51;10,111.11,608.80,43.80,4.51">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="83" to="94" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,111.11,620.75,377.40,4.51;10,111.11,632.71,97.75,4.51" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,171.83,620.75,213.19,4.51">Authorship verification: A review of recent advances</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,392.97,620.75,95.54,4.51;10,111.11,632.71,30.37,4.51">Research in Computing Science</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page" from="9" to="25" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,111.11,644.66,384.45,4.51;10,111.11,656.62,394.88,4.51;10,110.76,668.57,259.03,4.51" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,242.26,644.66,253.30,4.51;10,111.11,656.62,27.85,4.51">Taveer: an interpretable topic-agnostic authorship verification method</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Halvani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Graner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Regev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,307.07,656.62,198.91,4.51;10,110.76,668.57,143.65,4.51">ARES 2020: The 15th International Conference on Availability, Reliability and Security</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Volkamer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Wressnegger</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,111.10,90.65,385.00,4.51;11,110.76,102.61,299.52,4.51;11,111.11,114.56,196.15,4.51" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,211.63,90.65,220.54,4.51">Improving author verification based on topic modeling</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Potha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<idno type="DOI">10.1002/asi.24183</idno>
		<ptr target="https://doi.org/10.1002/asi.24183" />
	</analytic>
	<monogr>
		<title level="j" coord="11,440.24,90.65,55.86,4.51;11,110.76,102.61,213.60,4.51">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1074" to="1088" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,111.11,126.52,389.48,4.51;11,111.11,138.48,305.70,4.51" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,201.54,126.52,250.95,4.51">Determining if two documents are written by the same author</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Winter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,460.18,126.52,40.41,4.51;11,111.11,138.48,229.05,4.51">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="178" to="187" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,111.11,150.43,395.97,4.51;11,111.11,162.39,215.00,4.51" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,263.20,150.43,240.07,4.51">Learning stylometric representations for authorship analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,111.11,162.39,138.35,4.51">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="107" to="121" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,111.11,174.34,394.87,4.51;11,111.11,186.30,391.62,4.51;11,111.11,198.25,364.72,4.51" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,320.89,174.34,185.09,4.51;11,111.11,186.30,58.60,4.51">Similarity learning for authorship verification in social media</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Boenninghoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kolossa</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICASSP.2019.8683405</idno>
	</analytic>
	<monogr>
		<title level="m" coord="11,191.13,186.30,311.59,4.51;11,111.11,198.25,108.87,4.51">ICASSP 2019 -2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2457" to="2461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,111.11,210.21,394.81,4.51;11,111.11,222.16,394.88,4.51;11,111.11,234.12,392.51,4.51;11,111.11,246.07,394.72,4.51;11,111.11,258.03,391.28,4.51;11,111.11,267.93,252.91,8.88" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,478.41,210.21,27.50,4.51;11,111.11,222.16,394.88,4.51;11,111.11,234.12,63.14,4.51">Recent trends in digital text forensics and its evaluation -plagiarism detection, author identification, and author profiling</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Busse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M R</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,424.70,234.12,78.91,4.51;11,111.11,246.07,394.72,4.51;11,111.11,258.03,106.93,4.51">Information Access Evaluation. Multilinguality, Multimodality, and Visualization -4th International Conference of the CLEF Initiative, CLEF 2013</title>
		<title level="s" coord="11,111.11,267.93,134.00,8.88">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Paredes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Rosso</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Stein</surname></persName>
		</editor>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">September 23-26, 2013. 2013</date>
			<biblScope unit="volume">8138</biblScope>
			<biblScope unit="page" from="282" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,111.11,281.94,346.85,4.51;11,111.11,293.89,379.46,4.51;11,111.11,305.85,380.26,4.51;11,110.81,317.80,393.25,4.51;11,111.11,329.76,394.48,4.51;11,111.11,339.66,371.27,8.88" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,399.90,281.94,58.06,4.51;11,111.11,293.89,379.46,4.51;11,111.11,305.85,33.57,4.51">Improving the reproducibility of pan&apos;s shared tasks: -plagiarism detection, author identification, and author profiling</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M R</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,162.68,317.80,341.38,4.51;11,111.11,329.76,237.63,4.51">Information Access Evaluation. Multilinguality, Multimodality, and Interaction -5th International Conference of the CLEF Initiative, CLEF 2014</title>
		<title level="s" coord="11,229.46,339.66,134.00,8.88">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Lupu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Hall</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Toms</surname></persName>
		</editor>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">September 15-18, 2014. 2014</date>
			<biblScope unit="volume">8685</biblScope>
			<biblScope unit="page" from="268" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,111.11,353.67,380.29,4.51;11,111.11,365.62,374.43,4.51;11,111.11,377.58,359.42,4.51;11,111.11,389.53,394.71,4.51;11,111.11,399.44,385.94,8.88;11,111.11,413.44,73.58,4.51" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,358.10,353.67,133.30,4.51;11,111.11,365.62,55.69,4.51">Overview of the PAN/CLEF 2015 evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M R</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,232.53,377.58,238.00,4.51;11,111.11,389.53,269.51,4.51">Experimental IR Meets Multilinguality, Multimodality, and Interaction -6th International Conference of the CLEF Association</title>
		<title level="s" coord="11,320.21,399.44,134.00,8.88">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Mothe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Savoy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Pinel-Sauvagnat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>CLEF; Toulouse, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015-09-08">2015. September 8-11, 2015. 9283. 2015</date>
			<biblScope unit="page" from="518" to="538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,111.11,425.40,378.33,4.51;11,111.11,437.35,395.86,4.51;11,111.11,449.31,394.88,4.51;11,111.11,461.26,386.14,4.51;11,111.11,473.22,384.87,4.51;11,111.11,485.18,371.40,4.51;11,110.76,497.13,394.31,4.51;11,111.11,507.03,263.51,8.88" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,111.11,449.31,394.88,4.51;11,111.11,461.26,151.38,4.51">Overview of PAN 2020: Authorship verification, celebrity profiling, profiling fake news spreaders on twitter, and style change detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M R</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,403.24,473.22,92.74,4.51;11,111.11,485.18,371.40,4.51;11,110.76,497.13,45.51,4.51">Experimental IR Meets Multilinguality, Multimodality, and Interaction -11th International Conference of the CLEF Association</title>
		<title level="s" coord="11,121.71,507.03,134.00,8.88">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lioma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>CLEF; Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020-09-22">2020. September 22-25, 2020. 2020</date>
			<biblScope unit="volume">12260</biblScope>
			<biblScope unit="page" from="372" to="383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,111.11,521.04,369.44,4.51;11,111.11,533.00,380.79,4.51;11,111.11,544.95,389.29,4.51;11,111.11,556.91,395.97,4.51;11,110.76,568.86,383.78,4.51;11,111.11,580.82,382.71,4.51;11,111.11,590.72,364.08,8.88;11,111.11,602.67,187.04,8.88" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,163.21,544.95,337.18,4.51;11,111.11,556.91,138.30,4.51">Overview of PAN 2021: Authorship verification, profiling hate speech spreaders on twitter, and style change detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L D</forename><surname>La Peña Sarracén</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,336.41,568.86,158.13,4.51;11,111.11,580.82,382.71,4.51;11,111.11,592.77,16.58,4.51">Experimental IR Meets Multilinguality, Multimodality, and Interaction -12th International Conference of the CLEF Association, CLEF 2021</title>
		<title level="s" coord="11,411.81,590.72,63.38,8.88;11,111.11,602.67,68.12,8.88">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Candan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Larsen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Virtual Event</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">September 21-24, 2021. 2021</date>
			<biblScope unit="volume">12880</biblScope>
			<biblScope unit="page" from="419" to="431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,111.11,616.68,392.66,4.51;11,111.11,628.64,384.73,4.51;11,111.11,640.59,154.10,4.51" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="11,488.00,616.68,15.76,4.51;11,111.11,628.64,261.76,4.51">The Importance of Suppressing Domain Style in Authorship Analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bischoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Deckers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schliebs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thies</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<idno>CoRR abs/2005.14714</idno>
		<ptr target="https://arxiv.org/abs/2005.14714" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,111.11,652.55,382.70,4.51;11,111.11,664.50,85.61,4.51" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,185.66,652.55,230.15,4.51">Verification of forecasts expressed in terms of probability</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Brier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,423.24,652.55,70.57,4.51;11,111.11,664.50,27.49,4.51">Monthly weather review</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,111.11,90.65,372.50,4.51;12,110.76,102.61,395.09,4.51;12,109.42,114.56,363.50,4.51" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,200.75,90.65,165.78,4.51">A simple measure to assess non-response</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rodrigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,387.87,90.65,95.74,4.51;12,110.76,102.61,395.09,4.51;12,109.42,114.56,3.37,4.51;12,158.05,114.56,31.57,4.51">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1415" to="1424" />
		</imprint>
	</monogr>
	<note>HLT &apos;11</note>
</biblStruct>

<biblStruct coords="12,111.11,126.52,365.50,4.51;12,110.95,138.48,394.99,4.51;12,111.11,150.43,369.11,4.51;12,111.11,162.39,380.27,4.51;12,110.76,174.34,272.70,4.51;12,111.11,186.30,279.96,4.51" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="12,300.83,126.52,158.14,4.51">Generalizing unmasking for short texts</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1068</idno>
		<ptr target="https://doi.org/10.18653/v1/n19-1068.doi:10.18653/v1/n19-1068" />
	</analytic>
	<monogr>
		<title level="m" coord="12,267.02,138.48,238.92,4.51;12,111.11,150.43,369.11,4.51;12,111.11,162.39,73.08,4.51">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Burstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Doran</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Solorio</surname></persName>
		</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">June 2-7, 2019. 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="654" to="659" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="12,111.11,198.25,345.36,4.51;12,111.11,210.21,369.31,4.51;12,111.11,222.16,392.57,4.51;12,111.11,234.12,122.36,4.51" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="12,214.92,222.16,163.72,4.51">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,386.74,222.16,116.93,4.51;12,111.11,234.12,36.44,4.51">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,111.11,246.07,387.69,4.51;12,111.11,258.03,234.11,4.51;12,111.11,269.98,350.06,4.51" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="12,218.89,246.07,275.76,4.51">Using Compression-Based Language Models for Text Categorization</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Teahan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">J</forename><surname>Harper</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-94-017-0171-6_7</idno>
		<ptr target="https://doi.org/10.1007/978-94-017-0171-6_7.doi:10.1007/978-94-017-0171-6_7" />
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="141" to="165" />
			<pubPlace>Netherlands; Dordrecht</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,111.11,281.94,384.20,4.51;12,111.11,293.89,260.86,4.51" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="12,371.67,281.94,123.64,4.51;12,111.11,293.89,48.15,4.51">Authenticating the writings of julius caesar</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Stover</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Karsdorp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,166.71,293.89,137.87,4.51">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="86" to="96" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,111.11,305.85,395.86,4.51;12,111.11,317.80,394.70,4.51;12,110.82,327.71,382.85,8.88;12,111.11,341.71,355.48,4.51" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="12,301.27,305.85,150.12,4.51">TIRA integrated research architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-22948-1_5</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-22948-1_5.doi:10.1007/978-3-030-22948-1\_5" />
	</analytic>
	<monogr>
		<title level="m" coord="12,176.68,317.80,329.12,4.51;12,110.82,329.76,54.12,4.51">Information Retrieval Evaluation in a Changing World -Lessons Learned from 20 Years of CLEF</title>
		<title level="s" coord="12,227.27,327.71,125.24,8.88">The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="123" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,111.11,353.67,396.06,4.51;12,111.11,365.62,291.80,4.51" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="12,251.08,353.67,238.33,4.51">Different Encoding Approaches for Authorship Verification</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Konstantinou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zinonos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,111.11,365.62,127.39,4.51">CLEF 2022 Labs and Workshops</title>
		<title level="s" coord="12,245.79,365.62,94.11,4.51">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,111.11,377.58,394.81,4.51;12,111.11,389.53,374.04,4.51;12,111.11,401.49,82.91,4.51" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="12,419.12,377.58,86.80,4.51;12,111.11,389.53,146.88,4.51">Graph-Based Siamese Network for Authorship Verification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Martinez-Galicia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Embarcadero-Ruiz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>-O. Na</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Gómez-Adorno</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,278.74,389.53,127.39,4.51">CLEF 2022 Labs and Workshops</title>
		<title level="s" coord="12,413.42,389.53,71.72,4.51;12,111.11,401.49,19.90,4.51">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,111.11,413.44,387.90,4.51;12,110.95,425.40,384.55,4.51;12,111.11,437.35,246.22,4.51" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="12,178.83,425.40,252.82,4.51">A Content Spectral-based Analysis for Authorship Verification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Crespo-Sanchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Gómez-Adorno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Lopez-Arevalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Aldana-Bobadilla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Salas-Jimenez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cortes-Lopez</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,452.39,425.40,43.10,4.51;12,111.11,437.35,81.80,4.51">CLEF 2022 Labs and Workshops</title>
		<title level="s" coord="12,200.20,437.35,94.11,4.51">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,111.11,449.31,394.21,4.51;12,111.11,461.26,390.66,4.51;12,111.11,473.22,20.72,4.51" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="12,345.97,449.31,159.35,4.51;12,111.11,461.26,100.55,4.51">Authorship verification Based On Fully Interacted Text Segments</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,233.18,461.26,127.39,4.51">CLEF 2022 Labs and Workshops</title>
		<title level="s" coord="12,367.86,461.26,94.11,4.51">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,111.11,485.18,395.11,4.51;12,111.11,497.13,267.24,4.51" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="12,268.53,485.18,194.59,4.51">Application of BERT in Author Verification Task</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">Y</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,484.23,485.18,21.99,4.51;12,111.11,497.13,102.82,4.51">CLEF 2022 Labs and Workshops</title>
		<title level="s" coord="12,221.22,497.13,94.11,4.51">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,111.11,509.09,364.19,4.51;12,111.11,521.04,392.94,4.51" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="12,194.12,509.09,281.18,4.51;12,111.11,521.04,80.05,4.51">Text-to-Text Transformer in Authorship Verification Via Stylistic and Semantical Analysis</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Najafi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Tavan</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,212.25,521.04,127.39,4.51">CLEF 2022 Labs and Workshops</title>
		<title level="s" coord="12,346.93,521.04,94.11,4.51">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,111.11,533.00,379.26,4.51;12,111.11,544.95,376.79,4.51" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="12,307.77,533.00,182.59,4.51;12,111.11,544.95,63.29,4.51">Authorship Verification Using Convolutional Neural Network</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">Y</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,196.09,544.95,127.39,4.51">CLEF 2022 Labs and Workshops</title>
		<title level="s" coord="12,330.77,544.95,94.11,4.51">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,111.11,556.91,394.71,4.51;12,110.76,568.86,384.74,4.51;12,110.81,580.82,319.09,4.51" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="12,440.01,556.91,65.80,4.51;12,110.76,568.86,167.87,4.51">Overview of the Authorship Verification Task at PAN 2021</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,138.09,580.82,127.39,4.51">CLEF 2021 Labs and Workshops</title>
		<title level="s" coord="12,272.78,580.82,94.11,4.51">Notebook Papers, CEUR</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,111.11,592.77,359.22,4.51;12,111.11,604.73,392.99,4.51;12,110.81,616.68,319.09,4.51" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="12,284.46,592.77,185.87,4.51;12,111.11,604.73,176.54,4.51">O2D2: Out-of-distribution detector to capture undecidable trials in authorship verification</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Boenninghoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kolossa</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,138.09,616.68,127.39,4.51">CLEF 2021 Labs and Workshops</title>
		<title level="s" coord="12,272.78,616.68,94.11,4.51">Notebook Papers, CEUR</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,111.11,628.64,385.20,4.51;12,111.11,640.59,368.49,4.51;12,111.11,652.55,396.26,4.51" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="12,111.11,640.59,232.15,4.51">Graph-based Siamese network for authorship verification</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Embarcadero-Ruiz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Gómez-Adorno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Reyes-Hernández</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Embarcadero-Ruiz</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,217.75,652.55,126.44,4.51">CLEF 2021 Labs and Workshops</title>
		<title level="s" coord="12,351.45,652.55,93.40,4.51">Notebook Papers, CEUR</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,111.11,664.50,394.97,4.51;13,111.11,90.65,389.35,4.51;13,111.11,102.61,225.11,4.51" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="12,273.28,664.50,232.80,4.51;13,111.11,90.65,78.89,4.51">Feature vector difference based authorship verification for open world settings</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Weerasinghe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Greenstadt</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="13,436.25,90.65,64.20,4.51;13,111.11,102.61,60.70,4.51">CLEF 2021 Labs and Workshops</title>
		<title level="s" coord="13,179.10,102.61,94.11,4.51">Notebook Papers, CEUR</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
