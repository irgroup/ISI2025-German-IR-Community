<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,136.82,150.75,321.50,12.64;1,237.41,169.35,120.49,12.64">Image matching for individual recognition with SIFT, RANSAC and MCL</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,198.05,210.77,49.50,10.04"><forename type="first">Dávid</forename><surname>Papp</surname></persName>
							<email>pappd@tmit.bme.hu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Telecommunications and Media Informatics</orgName>
								<orgName type="institution">Budapest University of Technology and Economics</orgName>
								<address>
									<addrLine>Magyar Tudósok krt. 2</addrLine>
									<postCode>H-1117</postCode>
									<settlement>Budapest</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,255.28,210.77,78.51,10.04"><forename type="first">Ferenc</forename><surname>Mogyorósi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Telecommunications and Media Informatics</orgName>
								<orgName type="institution">Budapest University of Technology and Economics</orgName>
								<address>
									<addrLine>Magyar Tudósok krt. 2</addrLine>
									<postCode>H-1117</postCode>
									<settlement>Budapest</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,341.65,210.77,55.86,10.04"><forename type="first">Gábor</forename><surname>Szűcs</surname></persName>
							<email>szucs@tmit.bme.hu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Telecommunications and Media Informatics</orgName>
								<orgName type="institution">Budapest University of Technology and Economics</orgName>
								<address>
									<addrLine>Magyar Tudósok krt. 2</addrLine>
									<postCode>H-1117</postCode>
									<settlement>Budapest</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,136.82,150.75,321.50,12.64;1,237.41,169.35,120.49,12.64">Image matching for individual recognition with SIFT, RANSAC and MCL</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0971187CE804219CAAF2300AE0917762</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>whale recognition</term>
					<term>similarity</term>
					<term>SIFT</term>
					<term>SeaCLEF</term>
					<term>unsupervised learning 1</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Monitoring the whale individuals in the ocean is a current problem among conservationists. Biologists often use photos of whale caudal for this problem as it is the most discriminant pattern for distinguishing an individual whale from another, but it often requires laborious visual analysis. There was a challenge announced in the SeaCLEF of LifeCLEF campaign for automatic whale individual recognition based on visual contents. We elaborated a solution to compare the photos of individuals by SIFT features (as simple image representation) with spatial consistency refinement method RANSAC (based on a rotation and scale transformation model). After determining the similarity of every pair, to discover the wrong similarity values and correct them, a clustering method was applied on the similarity graph of the dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Analysis of images usually requires very time-consuming and expensive input by human observers, and this is true for sea images as well, although the statistics of data collection would be very useful for exploratory applications, in particular for fisheries and biological areas. This demands effective methods for automatic content analysis to enable proactive provision of analytical information; and in order to solve this problem a challenge is announced in SeaCLEF 13 of the LifeCLEF 3 campaign of ImageCLEF.</p><p>In this challenge there were four subtasks: (1) Automated Fish Identification and Species Recognition on Coral Reef Videos, (2) Automated Frame-level Salmon Identification in Videos for Monitoring Water Turbine, (3) Marine Animal Species Recognition using Weakly-Labelled Images and Relevance Ranking, and (4) Whale Individual Recognition. We enrolled in the last subtask, where the goal was to find the images that correspond to the same individual whale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related works</head><p>The aim is to monitor the organisms at the individual level rather than at the species level in the task of discovering whale individuals in a large collection of pictures collected by nature observers. The process is initiated without any knowledge on the number of individuals and without any training samples of these individuals; thus, the problem is entirely unsupervised. The task was identical to the challenge in the last year, so there are some previous works dealing with this problem.</p><p>In the paper 10 GMM (Gaussian Mixture Model) 12 was used to determine visual codebook with parametric probability density function represented as a weighted sum of Gaussian component densities. According to the codebook the next step was to create a descriptor that specifies the distribution of the visual codewords in any image, called high-level descriptor. To represent an image with high-level descriptor, the GMM based Fisher vector 11 was calculated. These vectors were the final representations (image descriptor) of the images. Finally a kernel matrix was built using RBF (Radial Basis Function) kernel function, an entry of kernel matrix describes how similar the Fisher vector to the Fisher vector (i.e. the image to the image), and the retrieval of predicted pairs was based on these similarity values.</p><p>In another paper 4 a scalable fine-grained matching system was developed to discover small rigid visual patterns in highly clutter background. The work was based on RANSAC algorithm 1, as a solution to perform epipolar geometry estimation. It consists in generating transformation hypotheses using a minimal number of lowlevel visual correspondences and then evaluating each hypothesis based on the number of inliers among all features under that hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method for Whale Individual Recognition</head><p>The aim was to find the images that correspond to the same individual whale; and the basic idea was to create the mathematical representation of each image based on visual content, then calculate the pairwise similarity values (these ideas were different from our previous works 101415).</p><p>We elaborated more alternative ways in the continuation of the process. In one of the alternatives the matching decisions among the images are binary, and in the other there are continuous (presenting the reliability that they are matching pairs).</p><p>We used the segmentation propagation technique introduced in 56 for separating the background (the water) from the whale's caudal fin, and we used the segmented images for further calculations. We used the default configuration of the segmentation technique proposed in 56. As it can be seen in Figure <ref type="figure" coords="2,342.52,661.34,3.76,8.96" target="#fig_0">1</ref>, the algorithm was not able to perfectly separate the fins in all cases. In the first column of the figure, there are a few examples for a perfect segmentation; the second column includes acceptably good segmentations, where a portion of water still present in the masked version of the images; finally, some wrong segmentations can be seen in the last column, but this occurred rarely. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Extracted features and SIFT matching</head><p>Lots of different feature types can be detected in an image, e.g. corners, edges, ridges, as "interesting" part of an image, furthermore many possible feature extraction methods are available for images. We used the Harris-Laplace corner detector 29 for feature (i.e. keypoint) detection and we chose the SIFT (Scale-Invariant Feature Transform) 78 algorithm to create descriptor vectors.</p><p>Our idea was to determine a similarity metric between two images based on their SIFT descriptors, therefore we searched for matching descriptor pairs on the images. Let us consider image and image , in order to avoid time consuming process caused by the large amount of possible pairs an approximate nearest neighbors search (in a k dimensional tree) 7 was used for investigation of matching. Our solution searched for the two nearest neighbors (the nearest and the second nearest one) to apply a ratio test, so the nearest neighbor of a descriptor was rejected as a matching pair if that was not significantly closer than the second nearest. In our experiments a ratio ( ) was used for this purpose, and the condition of acceptance for a matched feature pair can be seen in Equation <ref type="formula" coords="3,205.73,641.87,3.76,8.96">1</ref>.</p><p>(1) where denotes a pair of SIFT descriptors, and are Euclidean distances between the appropriate descriptors ( is the descriptor second closest to ), and denote the number of descriptors on images and respectively. In the examination of an image pair many matched feature pairs can be found, therefore a possible way to decide whether an image pair is a match is setting a minimum required number ( ) of matched features between them. This gives us a binary decision for each pair of images, and we used this during the creation of 'BME_DCLab_whalerun_3' that we discuss later on.</p><p>We define a new metric to measure the similarity between two images ( and ), and we denote it by .</p><p>(2)</p><p>where denotes the number of matched feature pairs. In this expression minimizing the automatically minimizes all the other distances between the matched feature pairs. On the other hand, should be as high as possible, because the more matches of SIFT descriptors are discovered the more likely for the image pair to be a match. Therefore, the aim was to maximize , so higher score represents more confidence. According to this we sorted the image pairs based on the values in a decreasing order, and this was our 'BME_DCLab_whalerun_1' solution. Note that we used as ratio during the calculation of the similarity values. Our solution examined every pair of images to reveal cliques, i.e. images that are mutually the closest to each other according to the similarity values. After that the previous run file was modified by moving the cliques to the beginning of the sorted list, and we submitted this slightly different run file under the name of 'BME_DCLab_whalerun_2'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Homography and clustering</head><p>In the feature matching lot of false matches can occur due to case where the features belong to different parts of the images in the comparison. To decrease the number of these false positive matches, we applied a rotation-and-scale transformation model, which transforms the keypoints of one image to the keypoints of the other; and RANSAC 1 was used for this. The transformation was applied to the corner points of one image and then it was tested on convexity and area. A positive pair can be seen in Figure <ref type="figure" coords="4,238.85,629.03,3.77,8.96" target="#fig_0">1</ref>, there are lots of matched features (linked with green line), and the white line is the border of the transformed rectangle. Fig. <ref type="figure" coords="5,224.18,255.11,4.50,8.10">2</ref> A positive pair with many matched features Now let us consider the binary decisions for each pair of images with (minimum number of SIFT matches). This gives us an addition threshold, therefore we lowered the distance ratio to for balancing the requirement of acceptance. We were able to detect the possible false matches by using rotation-andscale transformation model (i.e. some 1 turned to 0). Regarding the options of RANSAC, the value of maximal difference in pixels was 5, and the values of other parameters were the default ones.</p><p>Nonetheless there still may be some wrong predicted values, and some of them can be corrected if we consider the similarity graph of the images with 1 and 0 weight values. The images of a common whale individual determine a cluster, and in the cluster high weight values (close to 1) and among clusters low weight values (close to 0) are expected. For this unsupervised learning, i.e. clustering we used Markov Cluster Algorithm (MCL) 16, which is a random walks based clustering algorithm. By creating the possible clusters, we further refined the initial decisions, because it was able to discover new connections or to reject existing ones. Note that, we set the "max_loop" parameter of MCL to 30, to increase the chance of detecting hidden relationships between the data points (other parameters were used at their default value). At this point we had a binary score (1 for matches 0 for non matches) and the similarity value for each image pair. Thus we created an ordered list of image pairs based on the metrics with the addition that a pair with 0 binary score can never precedes one with 1 binary score; this concludes the 'BME_DCLab_whalerun_3'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Official evaluation of Whale Individual Recognition</head><p>The metric used for evaluating the submitted run files was the Average Precision (i.e. the precision averaged across all good matches of the ground truth). The following table provides the AP values of our submitted runs. Because of limited number of runs we could not measure contributive ratios of the clustering algorithm and other solution parts separately. However, the combination of solution parts in the 'BME_DCLab_whalerun_3' eventuated the best average precision as can be seen in the Table <ref type="table" coords="6,164.87,163.02,3.76,8.96" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We elaborated three different methods (two of them are only slightly differ) for whale individual recognition. We used SIFT descriptors to represent the visual content of the images, and we searched for matching descriptor vectors between each pair of images. We defined a new metric to measure the similarity of the pairs by a confidence value, and then refined these scores to get even more precise predictions. For this purpose, we used RANSAC and MCL algorithms. The most complex run file that we submitted was able to achieve 0.51 Average Precision in the official evaluation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,206.57,405.02,193.48,8.10;3,157.10,213.52,281.10,187.20"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 Some examples for the segmentation of whales</figDesc><graphic coords="3,157.10,213.52,281.10,187.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,119.78,187.91,293.16,138.18"><head>Table 1</head><label>1</label><figDesc>Results of Whale Individual Recognition</figDesc><table coords="6,119.78,212.22,293.16,113.87"><row><cell>Run name</cell><cell>Average Precision</cell></row><row><cell>BME_DCLab_whalerun_3</cell><cell>0.51</cell></row><row><cell>BME_DCLab_whalerun_1</cell><cell>0.30</cell></row><row><cell>BME_DCLab_whalerun_2</cell><cell>0.30</cell></row><row><cell>4</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,123.67,507.52,346.88,8.10;6,141.86,519.52,328.67,8.10;6,141.86,531.40,94.55,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,289.73,507.52,180.81,8.10;6,141.86,519.52,250.81,8.10">Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Fischler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">C</forename><surname>Bolles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,398.96,519.52,71.58,8.10;6,141.86,531.40,30.28,8.10">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="381" to="395" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,124.03,543.47,346.37,8.96;6,141.86,556.12,242.68,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,235.95,544.12,139.53,8.10">A combined corner and edge detector</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Stephens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,141.86,556.12,173.88,8.10">Proceedings of the Alvey Vision Conference</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</editor>
		<meeting>the Alvey Vision Conference</meeting>
		<imprint>
			<biblScope unit="page" from="1" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,384.54,556.12,86.16,8.10;6,141.86,568.00,135.30,8.10" xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Alvey</forename><surname>Vision</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Club</forename></persName>
		</author>
		<idno type="DOI">10.5244/C.2.23</idno>
		<imprint>
			<date type="published" when="1988-09">September 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,124.03,580.07,346.54,8.96;6,141.86,592.72,328.68,8.10;6,141.86,604.60,246.05,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,304.37,592.72,166.17,8.10;6,141.86,604.60,115.14,8.10">LifeCLEF 2017 Lab Overview: multimedia species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Planqué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Palazzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,262.85,604.60,98.84,8.10">Proceedings of CLEF 2017</title>
		<meeting>CLEF 2017</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,124.03,616.79,346.73,8.96;6,141.86,629.44,329.00,8.10;6,141.86,641.32,219.12,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,380.47,617.44,90.29,8.10;6,141.86,629.44,195.95,8.10">Unsupervised individual whales identification: spot the difference in the ocean</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Champ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Saloma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,355.23,629.44,115.62,8.10;6,141.86,641.32,165.01,8.10">Working Notes of CLEF 2016-Conference and Labs of the Evaluation forum</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="469" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,124.03,653.42,346.73,8.96;6,141.86,666.07,290.14,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,297.43,654.07,173.32,8.10;6,141.86,666.07,41.95,8.10">ImageNet Auto-annotation with Segmentation Propagation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kuettel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Guillaumin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,256.73,666.07,149.12,8.10">International Journal of Computer Vision</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="6,124.03,678.14,346.71,8.96;7,141.86,149.39,255.83,8.10" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kuettel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Guillaumin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
		<title level="m" coord="6,289.88,678.79,180.85,8.10;7,141.86,149.39,145.29,8.10">Segmentation Propagation in ImageNet European Conference on Computer Vision (ECCV)</title>
		<meeting><address><addrLine>Firenze, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-10">October 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,124.03,161.58,346.74,8.96;7,141.86,174.11,195.35,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,195.97,162.23,219.53,8.10">Distinctive Image Features from Scale-Invariant Keypoints</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,423.29,162.23,47.48,8.10;7,141.86,174.11,99.47,8.10">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,124.03,186.30,312.70,8.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,180.33,186.95,191.40,8.10">Object recognition from local scale-invariant features</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,389.95,186.95,20.51,8.10">ICCV</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,124.03,199.14,346.80,8.96;7,141.86,211.79,236.65,8.10" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,269.18,199.79,198.16,8.10">Scale &amp; affine invariant interest point detectors</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,141.86,211.79,151.07,8.10">International Journal on Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="86" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.64,223.86,341.84,8.96;7,141.86,236.51,329.00,8.10;7,141.86,248.39,328.88,8.10;7,141.86,260.27,264.72,8.10" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,295.68,224.42,174.80,8.18;7,141.86,236.51,329.00,8.10;7,141.86,248.39,174.38,8.10">Object Detection, Classification, Tracking and individual Recognition for Sea Images and Videos, Working Notes of CLEF 2016 -Conference and Labs of the Evaluation forum</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Papp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lovas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Szűcs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="7,141.86,260.27,108.38,8.10">CEUR Workshop Proceedings</title>
		<idno type="ISSN">1613-0073</idno>
		<imprint>
			<biblScope unit="volume">1609</biblScope>
			<biblScope unit="page" from="525" to="533" />
			<date type="published" when="2016-05-08">2016. 5-8 September, 2016</date>
			<pubPlace>Évora, Portugal</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,127.84,272.15,342.57,8.10;7,141.86,284.06,328.85,8.10;7,141.86,296.06,24.09,8.10" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,239.06,272.15,227.80,8.10">Fisher kernel on visual vocabularies for image categorization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Dance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,141.86,284.06,324.42,8.10">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.64,308.13,342.19,8.96;7,141.86,320.78,144.59,8.10" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="7,211.28,308.78,255.74,8.10">Gaussian Mixture Models, Encyclopedia of Biometric Recognition</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Reynolds</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009-02">February. 2009</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="659" to="663" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.64,332.85,342.17,8.96;7,141.86,345.50,71.13,8.10" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><surname>Seaclef</surname></persName>
		</author>
		<ptr target="http://www.imageclef.org/lifeclef/2017/sea" />
		<title level="m" coord="7,448.78,333.50,22.03,8.10;7,141.86,345.50,29.57,8.10">CLEF working</title>
		<imprint>
			<date type="published" when="2017">2017. 2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.64,357.57,341.65,8.96;7,141.86,370.22,328.59,8.10;7,141.86,382.10,328.76,8.10;7,141.86,393.98,71.99,8.10" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,259.21,358.13,211.08,8.18;7,141.86,370.22,105.13,8.10">SVM classification of moving objects tracked by Kalman filter and Hungarian method</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Szűcs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Papp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lovas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,141.86,382.10,150.11,8.10">Working Notes of CLEF 2015 Conference</title>
		<editor>
			<persName><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G J F</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E S</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><surname>Juan</surname></persName>
		</editor>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">September 8-11, 2015</date>
			<biblScope unit="page">1391</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.64,406.17,341.98,8.96;7,141.86,418.82,328.62,8.10;7,141.86,430.70,328.96,8.10;7,141.86,442.58,108.79,8.10" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,263.77,406.73,206.85,8.18;7,141.86,418.82,115.19,8.10">Viewpoints Combined Classification Method in Imagebased Plant Identification Task</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Szűcs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Papp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lovas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,141.86,430.70,161.26,8.10">Working Notes for CLEF 2014 Conference</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Halvey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</editor>
		<meeting><address><addrLine>Sheffield, Great Britain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">September 15-18, 2014</date>
			<biblScope unit="page">1180</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,127.84,454.46,342.88,8.10;7,141.86,466.36,18.80,8.10" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,231.62,454.46,108.71,8.10">A cluster algorithm for graphs</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Van Dongen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,346.72,454.46,100.19,8.10">Report-Information systems</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1" to="40" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
