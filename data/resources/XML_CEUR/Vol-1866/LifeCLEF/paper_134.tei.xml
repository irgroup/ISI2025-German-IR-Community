<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,147.75,116.95,319.85,12.62;1,164.30,134.89,286.76,12.62">Residual Network with Delayed Max Pooling for Very Large Scale Plant Identification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,230.03,172.56,48.99,8.74"><forename type="first">Siang</forename><surname>Thye</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="laboratory">Knowledge Data Engineering and Information Retrieval Laboratory</orgName>
								<orgName type="institution">Toyohashi University of Technology</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,328.00,172.56,57.34,8.74"><forename type="first">Masaki</forename><surname>Aono</surname></persName>
							<email>aono@tut.jp</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="laboratory">Knowledge Data Engineering and Information Retrieval Laboratory</orgName>
								<orgName type="institution">Toyohashi University of Technology</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,147.75,116.95,319.85,12.62;1,164.30,134.89,286.76,12.62">Residual Network with Delayed Max Pooling for Very Large Scale Plant Identification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">866EFC525DF368A4E92ABDA7CAD1BC07</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Plant Identification</term>
					<term>Deep Learning</term>
					<term>Down-sampling 1 Namely res{3</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In our approach, we applied a few modifications to the 50layered Residual Network. Our preliminary experiments with the Plant-CLEF 2016 dataset showed that the modifications improved classification performance. We have trained three models based on the modified Residual Network configuration with different combinations of trusted and noisy PlantCLEF 2017 datasets. Using confidence scores extracted from the three models, we have submitted four runs and our methods showed competitive classification performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Residual Network with Delayed Max Pooling</head><p>We applied a few modifications to the 50-layered Residual Network by He et al. <ref type="bibr" coords="1,148.60,433.46,9.96,8.74" target="#b2">[3]</ref>, which is also known as ResNet-50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Max Pooling Based Down-sampling</head><p>In ResNet-50, a total of three convolution operations 1 with stride size 2 but filter size 1 × 1 is used for down-sampling. As the filter size is smaller than stride size, part of the activations may be ignored in the filtering i.e. convolution processes, as demonstrated in Figure <ref type="figure" coords="1,252.68,518.38,3.87,8.74" target="#fig_1">1</ref>.</p><p>Therefore, we reduced stride size of the three convolution operations in ResNet-50 from 2 to 1. In addition to this, max pooling of stride size 2 and filter size 2 × 2 are inserted before these convolution operations. We label this modified configuration as ResNet-50-MP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Delayed Down-sampling</head><p>Down-sampling is an essential element in Convolutional Neural Network, which reduces number of activations (as well as computational complexity). However, applying down-sampling too early may leave too little activations for subsequent convolution operations, thus impacting classification performance. In a paper by He et al. <ref type="bibr" coords="2,259.84,337.10,9.96,8.74" target="#b1">[2]</ref>, delaying down-sampling shows improved classification performance. In their method, stride size of pooling operations are reduced from 2 to 1, and stride size of their subsequent convolution operations are increased from 1 to 2. In our method, we simply switched the position of the newly introduced max pooling operations (in Subsection 1.1) with their subsequent convolution operations. We label this configuration as ResNet-50-MPD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Network Training and Testing</head><p>This section illustrates our implementation for the plant identification task i.e. PlantCLEF. We use the Caffe framework by Jia et al. <ref type="bibr" coords="2,368.72,475.63,10.52,8.74" target="#b4">[5]</ref> to implement all of the configurations. Note that all configurations are trained from scratch i.e. no pretrained weights are used. As for test images, they are scaled such that the shorter sides become 224. The scaled images are then horizontally flipped. Both flipped and non-flipped images are applied into a trained network for prediction. Class-wise outputs (before softmax normalization) of both instances are averaged and then softmax normalized.</p><p>Input Normalization. Mean centering of input is already a common procedure to train or test a network. However, this alone may not be sufficient as variance is not considered in this process.</p><p>Therefore, we attempted to normalize at higher order by applying Batch Normalization <ref type="bibr" coords="3,183.53,167.81,10.52,8.74" target="#b3">[4]</ref> directly onto the (augmented) input. With Batch Normalization, an input is normalized into zero mean and unit variance (and then scaled and shifted accordingly). As the number of filters are quite limited i.e. 64 in the very first convolution layer of ResNet i.e. conv1, such normalization should facilitate this convolution layer to learn filters of more varying features. In summary, batch sizes for both original ResNet-50 and ResNet-50-MP are maximized at 31 and they are trained with learning rates 0.1, 0.01, 0.001 for 208671, 104336, 52168 iterations respectively. As for ResNet-50-MPD, the largest possible batch size is 21 and this configuration is trained with the same learning rates for 308038, 154019, 77010 iterations respectively. Validation accuracy of the whole training process for all three configurations is shown in Figure <ref type="figure" coords="3,454.71,509.21,3.87,8.74">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Preliminary Experiments with</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Experiments with PlantCLEF 2017 Dataset</head><p>Based on the results as shown in Figure <ref type="figure" coords="3,323.38,555.38,3.87,8.74">2</ref>, we selected the ResNet-50-MPD configuration for this year's plant identification task.</p><p>Dataset Preparation. Out of the 256287 trusted training images provided by the task organizers of PlantCLEF 2017 <ref type="bibr" coords="3,311.03,607.36,10.20,8.74" target="#b5">[6]</ref>[1], we randomly selected around 1 10 of the images for validation purpose. Specifically, after separating 25063 images for validation, 231224 images remain for 'trusted' training. As for noisy images, out of the provided 1442642 metadata, we managed to obtain 99.0% of them, specifically 1428395 images. Different combinations of trusted and noisy images are used to train the ResNet-50-MPD configuration. Our first model is trained with trusted training images only<ref type="foot" coords="4,185.70,398.07,3.97,6.12" target="#foot_0">2</ref> , and our second model is trained with noisy training images only 3 , while our third model is trained with both mixed together. We label the first as model T, the second as model N, and the third as model X. All three models are validated with the 25063 validation images. Batch Size. We use a single NVIDIA's Quadro P6000 to train the three models. With 24 GiB memory, we were able to use batch size up to 47.</p><p>Learning Schedule. As the trusted and noisy datasets are a lot larger compared to last year's, we were not able to train for 100 epochs but a fixed amount of training iterations. All three models are trained for 350000 iterations: learning rate 0.1 for 200000 iterations, 0.01 for 100000 iterations and 0.001 for 50000 iterations. In other words, model T was trained for around 71 epochs, model N was trained for around 12 epochs, while model X was trained for around 10 epochs. Validation accuracy of the training processes is summarized in Figure <ref type="figure" coords="4,472.85,576.01,3.87,8.74" target="#fig_2">3</ref>. three models i.e. model T, N and M. For each model, class-wise average of confidence scores (before softmax normalization) extracted from both flipped and non-flipped images is computed. Additionally, class-wise average of confidence scores with the same ObservationId is also computed. The averaged confidence scores are then softmax normalized. We have submitted four runs with team name KDETUT for this year's plant identification task, as summarized below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation Result</head><p>Mean Reciprocal Rank (MRR) is used as evaluation metric. Evaluation results released by the task organizers are shown in Table <ref type="table" coords="5,360.51,564.96,4.98,8.74" target="#tab_2">1</ref> and Figure <ref type="figure" coords="5,420.50,564.96,3.87,8.74">4</ref>. Among the submitted four runs, Run 4, which is average of confidence scores extracted from model T and N, shows the best classification performance. In this paper, we described our approach to PlantCLEF 2017, focusing on some modifications to the 50-layered Residual Network. Nevertheless, there are still rooms for improvements in our approaches, as itemized below.</p><p>-Especially models trained with very large datasets i.e. model N and X, the fixed amount of 350000 training iterations may not be sufficient. For example, as detailed in Subsection 2.3, in fact model X is only trained for around 10 epochs. However, this setup already requires 4 days to train each model.</p><p>More training iterations i.e. longer training time may be required to achieve superior classification performance. -Among the four runs we have submitted, Run 4 yields the highest classification performance. It is based on average of confidence scores computed from model T and N (one each). We believe classification performance can be further improved if the confidence scores are averaged from even more models, for example five model T and five model N. This is however at the cost of multiplied computation time.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,134.77,242.78,345.82,7.89;2,134.77,253.77,345.82,7.86;2,134.77,264.72,345.83,7.86;2,134.77,275.68,131.37,7.86"><head>(a) 3 × 2 Fig. 1 .</head><label>321</label><figDesc>Fig. 1. Coverage of stride 2 based filtering with filter size 3 × 3, 2 × 2, and 1 × 1. When filter size is larger than 2 × 2 e.g. (a), some of the regions are overlapped, as shown in the darker regions. When filter size is smaller than 2 × 2 e.g. (c), some of the regions (in white) are not covered at all.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,134.77,534.91,82.19,8.77;2,134.77,560.34,345.83,8.77;2,134.77,572.33,338.48,8.74;2,473.24,570.75,4.08,6.12;2,477.82,572.33,2.77,8.74;2,134.77,584.28,345.83,8.74;2,134.77,596.24,173.10,8.74"><head>2. 1</head><label>1</label><figDesc>Input Data Data Augmentation. Training images are randomly scaled such that shorter sides are in the range of [224, 336]. Scaled images are randomly rotated for ±45 • . Rotated images are randomly cropped into 224 × 224, and finally the cropped images are randomly horizontal flipped.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,134.77,312.55,345.83,7.89;5,134.77,323.53,345.83,7.86;5,134.77,334.49,345.83,7.86;5,134.77,345.45,185.19,7.86"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Validation accuracy of ResNet-50-MPD trained with different combinations of trusted and noisy PlantCLEF 2017 datasets, namely model T, N and X. All of the models are trained for 350000 iterations (but different number of training epochs due to different number of image in each dataset).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,151.70,461.35,313.76,8.74;5,140.99,473.27,316.14,8.77;5,140.99,485.23,337.48,8.77;5,140.99,497.18,326.28,8.77"><head>KDETUT Run 1 :</head><label>1</label><figDesc>Based on model T (trained with trusted images only) -KDETUT Run 2: Based on model N (trained with noisy images only) -KDETUT Run 3: Based on model X (trained with trusted and noisy img.) -KDETUT Run 4: Average of confidence scores based on model T and N</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,134.77,243.67,345.83,202.55"><head></head><label></label><figDesc>PlantCLEF 2016 Dataset Dataset Preparation. ResNet-50, ResNet-50-MP and ResNet-50-MPD configurations in Section 1 are trained for 100 epochs with PlantCLEF 2016 training dataset. After each training epoch, each configuration is validated with Plant-CLEF 2016 test dataset. Omitting unseen images i.e. of ClassId 9999, a total of 113204 training images and 4510 test images are utilized. Note that data augmentation and normalization as detailed in Section 2.1 are applied to all configurations. Batch Size. The hardware we use for preliminary experiments is a single NVIDIA's Tesla K40. We use largest possible batch sizes i.e. based on the hardware's memory limitation of 12 GiB. Learning Schedule. Initial learning rate is 0.1 and is multiplied by 0.1 twice throughout the training process. Training iterations for each learning rate is divided with ratio 4:2:1 across 100 training epochs.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,134.77,119.56,345.83,231.83"><head></head><label></label><figDesc>Validation accuracy of ResNet-50, ResNet-50-MP and ResNet-50-MPD configurations using PlantCLEF 2016 dataset. Base learning rate 0.1 is dropped to 0.01 at around 57 th epoch, and is further dropped to 0.001 at around 86 th epoch, as indicated by the vertical dotted lines.</figDesc><table coords="4,134.77,119.56,333.48,198.95"><row><cell></cell><cell>1.0</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">original ResNet-50</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell>ResNet-50-MP ResNet-50-MPD</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Accuracy</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>20</cell><cell>40</cell><cell>60</cell><cell>80</cell><cell>100</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Epoch</cell><cell></cell><cell></cell></row><row><cell cols="2">Fig. 2.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,134.77,130.17,345.83,520.48"><head>Table 1 .</head><label>1</label><figDesc>Evaluation results of runs submitted by PlantCLEF 2017 participants, sorted in descending order. Our four submitted runs are highlighted in color.</figDesc><table coords="6,148.27,161.53,318.93,489.12"><row><cell></cell><cell></cell><cell></cell><cell cols="5">Run Name</cell><cell></cell><cell cols="3">MRR</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">Run Name</cell><cell></cell><cell cols="3">MRR</cell></row><row><cell cols="8">MarioTsaBerlin Run 4</cell><cell></cell><cell cols="3">0.920</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="8">KDETUT Run 1</cell><cell></cell><cell cols="3">0.772</cell></row><row><cell cols="8">MarioTsaBerlin Run 2</cell><cell></cell><cell cols="3">0.915</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">CMP Run 2</cell><cell></cell><cell cols="3">0.765</cell></row><row><cell cols="8">MarioTsaBerlin Run 3</cell><cell></cell><cell cols="3">0.894</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">CMP Run 4</cell><cell></cell><cell cols="3">0.733</cell></row><row><cell></cell><cell cols="7">KDETUT Run 4</cell><cell></cell><cell cols="3">0.853</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">UM Run 1</cell><cell></cell><cell cols="3">0.700</cell></row><row><cell cols="8">MarioTsaBerlin Run 1</cell><cell></cell><cell cols="3">0.847</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="11">SabanciUGebzeTU Run 4</cell><cell></cell><cell cols="3">0.638</cell></row><row><cell></cell><cell></cell><cell cols="6">CMP Run 1</cell><cell></cell><cell cols="3">0.843</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="11">SabanciUGebzeTU Run 1</cell><cell></cell><cell cols="3">0.636</cell></row><row><cell></cell><cell cols="7">KDETUT Run 3</cell><cell></cell><cell cols="3">0.837</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="11">SabanciUGebzeTU Run 3</cell><cell></cell><cell cols="3">0.622</cell></row><row><cell></cell><cell cols="7">KDETUT Run 2</cell><cell></cell><cell cols="3">0.824</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="7">PlantNet Run 1</cell><cell></cell><cell cols="3">0.613</cell></row><row><cell></cell><cell></cell><cell cols="6">CMP Run 3</cell><cell></cell><cell cols="3">0.807</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="11">SabanciUGebzeTU Run 2</cell><cell></cell><cell cols="3">0.581</cell></row><row><cell cols="8">FHDO BCSG Run 2</cell><cell></cell><cell cols="3">0.806</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="9">UPB HES SO Run 3</cell><cell></cell><cell cols="3">0.361</cell></row><row><cell cols="8">FHDO BCSG Run 3</cell><cell></cell><cell cols="3">0.804</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="9">UPB HES SO Run 4</cell><cell></cell><cell cols="3">0.361</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">UM Run 2</cell><cell></cell><cell cols="3">0.799</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="9">UPB HES SO Run 1</cell><cell></cell><cell cols="3">0.326</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">UM Run 3</cell><cell></cell><cell cols="3">0.798</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="9">UPB HES SO Run 2</cell><cell></cell><cell cols="3">0.305</cell></row><row><cell cols="8">FHDO BCSG Run 1</cell><cell></cell><cell cols="3">0.792</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="9">FHDO BCSG Run 4</cell><cell></cell><cell cols="3">0.000</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">UM Run 4</cell><cell></cell><cell cols="3">0.789</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Mean Reciprocal Rank</cell><cell>0.2 0.4 0.6 0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>MarioTsaBerlin Run 4</cell><cell>MarioTsaBerlin Run 2</cell><cell>MarioTsaBerlin Run 3</cell><cell>KDETUT Run 4</cell><cell>MarioTsaBerlin Run 1</cell><cell>CMP Run 1</cell><cell>KDETUT Run 3</cell><cell>KDETUT Run 2</cell><cell>CMP Run 3</cell><cell>FHDO BCSG Run 2</cell><cell>FHDO BCSG Run 3</cell><cell>UM Run 2</cell><cell>UM Run 3</cell><cell>FHDO BCSG Run 1</cell><cell>UM Run 4</cell><cell>KDETUT Run 1</cell><cell>CMP Run 2</cell><cell>CMP Run 4</cell><cell>UM Run 1</cell><cell>SabanciUGebzeTU Run 4</cell><cell>SabanciUGebzeTU Run 1</cell><cell>SabanciUGebzeTU Run 3</cell><cell>PlantNet Run 1</cell><cell>SabanciUGebzeTU Run 2</cell><cell>UPB HES SO Run 3</cell><cell>UPB HES SO Run 4</cell><cell>UPB HES SO Run 1</cell><cell>UPB HES SO Run 2</cell><cell>FHDO BCSG Run 4</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="14">Fig. 4. Visualization of Table 1.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="4,144.73,646.84,289.06,8.12"><p>Corresponds to training set E in imageclef.org/lifeclef/2017/plant</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,138.35,376.71,342.25,7.86;7,146.91,387.67,333.68,7.86;7,146.91,398.63,25.60,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,279.00,376.71,201.60,7.86;7,146.91,387.67,208.16,7.86">Plant identification based on noisy web data: The amazing performance of deep learning (lifeclef 2017)</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,375.97,387.67,83.30,7.86">CLEF working notes</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,409.59,342.25,7.86;7,146.91,420.55,327.40,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,213.69,409.59,223.60,7.86">Convolutional neural networks at constrained time cost</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,458.58,409.59,22.02,7.86;7,146.91,420.55,186.64,7.86;7,363.32,420.55,82.33,7.86">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note>IEEE Conference on</note>
</biblStruct>

<biblStruct coords="7,138.35,431.50,342.25,7.86;7,146.91,442.46,333.67,7.86;7,146.91,453.42,25.60,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,297.28,431.50,179.39,7.86">Deep residual learning for image recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,161.18,442.46,206.54,7.86;7,397.88,442.46,82.70,7.86">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note>IEEE Conference on</note>
</biblStruct>

<biblStruct coords="7,138.35,464.38,342.24,7.86;7,146.91,475.34,333.68,7.86;7,146.91,486.30,333.68,7.86;7,146.91,497.26,25.60,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,236.48,464.38,244.11,7.86;7,146.91,475.34,127.45,7.86">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,295.00,475.34,185.59,7.86;7,146.91,486.30,156.56,7.86">Proceedings of the 32nd International Conference on Machine Learning, ICML 2015</title>
		<meeting>the 32nd International Conference on Machine Learning, ICML 2015<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07-11">6-11 July 2015. 2015</date>
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,508.22,342.24,7.86;7,146.91,519.18,333.68,7.86;7,146.91,530.13,333.68,7.86;7,146.91,541.09,69.88,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,235.02,519.18,240.96,7.86">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,160.65,530.13,278.79,7.86">Proceedings of the 22nd ACM international conference on Multimedia</title>
		<meeting>the 22nd ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="675" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,552.05,342.24,7.86;7,146.91,563.01,333.68,7.86;7,146.91,573.97,153.51,7.86" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Planqué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Palazzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<title level="m" coord="7,346.57,563.01,134.02,7.86;7,146.91,573.97,153.51,7.86">Lifeclef 2017 lab overview: Multimedia species identification challenges</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
