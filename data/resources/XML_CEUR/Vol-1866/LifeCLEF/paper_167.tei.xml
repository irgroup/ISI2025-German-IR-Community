<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,164.84,116.95,285.68,12.62;1,182.14,134.89,251.09,12.62">Learning with Noisy and Trusted Labels for Fine-Grained Plant Recognition</title>
				<funder>
					<orgName type="full">Electrolux Student Support Programme</orgName>
				</funder>
				<funder ref="#_esJVxcC">
					<orgName type="full">CTU</orgName>
				</funder>
				<funder ref="#_XA8eM4A">
					<orgName type="full">Czech Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,250.56,170.04,46.77,11.26"><forename type="first">Milan</forename><surname>Šulc</surname></persName>
							<email>sulcmila@cmp.felk.cvut.cz</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Machine Perception</orgName>
								<orgName type="department" key="dep2">Dept. of Cybernetics</orgName>
								<orgName type="department" key="dep3">Faculty of Electrical Eng</orgName>
								<orgName type="institution">Czech Technical University in</orgName>
								<address>
									<settlement>Prague</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,320.03,172.56,44.77,8.74"><forename type="first">Jiří</forename><surname>Matas</surname></persName>
							<email>matas@cmp.felk.cvut.cz</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Machine Perception</orgName>
								<orgName type="department" key="dep2">Dept. of Cybernetics</orgName>
								<orgName type="department" key="dep3">Faculty of Electrical Eng</orgName>
								<orgName type="institution">Czech Technical University in</orgName>
								<address>
									<settlement>Prague</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,164.84,116.95,285.68,12.62;1,182.14,134.89,251.09,12.62">Learning with Noisy and Trusted Labels for Fine-Grained Plant Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D464E399897235EB2E87034544AC4AC5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The paper describes the deep learning approach to automatic visual recognition of 10 000 plant species submitted to the PlantCLEF 2017 challenge. We evaluate modifications and extensions of the state-ofthe-art Inception-ResNet-v2 CNN architecture, including maxout, bootstrapping for training with noisy labels, and filtering the data with noisy labels using a classifier pre-trained on the trusted dataset. The final pipeline consists of a set of CNNs trained with different modifications on different subsets of the provided training data. With the proposed approach, we were ranked as the third best team in the LifeCLEF 2017 challenge.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The plant identification challenge PlantCLEF 2017 <ref type="bibr" coords="1,358.01,405.56,10.52,8.74" target="#b0">[1]</ref> is a part of the LifeCLEF activity <ref type="bibr" coords="1,172.53,417.51,10.51,8.74" target="#b1">[2]</ref> organized within CLEF 2017 -The Conference and Labs of the Evaluation Forum. The task of the challenge is automatic plant identification using computer vision. A similar task has been the subject of previous challenges <ref type="bibr" coords="1,134.77,453.38,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="1,145.28,453.38,7.01,8.74" target="#b3">4]</ref>, yet PlantCLEF 2017 aims at a significantly larger scale: recognizing plants from 10 000 species.</p><p>Two sets of training data, with different properties and sources but both covering the same 10 000 plant species, were provided by the organizers:</p><p>1. A set based on the online collaborative Encyclopedia Of Life (EoL) containing 256 287 images and corresponding xml files with meta-information. An important field in the meta-information is the "Observation ID", which is an identifier connecting images of the same specimen (object of observation). This dataset is considered "trusted", i.e. the ground truth labels should allbe assigned correctly. 2. A noisy training set built using web crawlers, or more precisely, obtained by google and bing image search. It thus contains images not related to the given plant species. This set is provided in the form of a list of more than 1442k image URLs. We obtained nearly 1405k images from the list, the remaining images failed to download.</p><p>The evaluation is performed on a test set containing 25 170 images of 13 471 observations (specimen).</p><p>The rest of the paper is structured as follows: the deep learning approach and all proposed modifications are described in Section 2. Preliminary experiments are described and their evaluation is discussed in Section 3. Post-processing steps are described in Section 4. The runfiles submitted to PlantCLEF are listed in 5. Conclusions are drawn in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Proposed Methods</head><p>In recent years, Deep Convolutional Neural Networks (CNNs) have become the core of state-of-the-art solutions of many computer vision tasks, especially those related to recognition and detection of objects. This is also the case for plant recognition, where in previous PlantCLEF challenges 2015 <ref type="bibr" coords="2,401.97,263.07,10.52,8.74" target="#b3">[4]</ref> and 2016 <ref type="bibr" coords="2,462.32,263.07,10.96,8.74" target="#b4">[5,</ref><ref type="bibr" coords="2,473.28,263.07,7.31,8.74" target="#b2">3]</ref> the deep learning submissions <ref type="bibr" coords="2,271.70,275.03,11.99,8.74" target="#b5">[6,</ref><ref type="bibr" coords="2,283.69,275.03,7.99,8.74" target="#b6">7,</ref><ref type="bibr" coords="2,291.69,275.03,7.99,8.74" target="#b7">8,</ref><ref type="bibr" coords="2,299.68,275.03,7.99,8.74" target="#b8">9,</ref><ref type="bibr" coords="2,307.68,275.03,11.99,8.74" target="#b9">10,</ref><ref type="bibr" coords="2,319.67,275.03,11.99,8.74" target="#b10">11,</ref><ref type="bibr" coords="2,331.66,275.03,11.99,8.74" target="#b11">12]</ref> outperformed combinations of hand-crafted methods significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Inception-ResNet-v2</head><p>The submitted model is based on the state-of-the-art convolutional neural network architecture, the Inception-ResNet-v2 model <ref type="bibr" coords="2,352.05,352.36,15.50,8.74" target="#b12">[13]</ref> which introduced residual Inception modules, i.e.inception modules with residual connections. Both the paper <ref type="bibr" coords="2,153.01,376.27,15.49,8.74" target="#b12">[13]</ref> and our preliminary experiments show that this network architecture leads to superior results compared with other state-of-the-art CNN architectures. The publicly available<ref type="foot" coords="2,262.38,398.60,3.97,6.12" target="#foot_0">1</ref> Tensorflow model pretrained on ImageNet was used for initial values of network parameters. The main hyperparameters were set as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimizer</head><p>RMSProp with momentum 0.9 and decay 0.9. Weight decay 0.00004. Learning rate Starting LR 0.01, decay factor 0.94, exponential decay, ending LR 0.0001. Batch size 32.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">MaxOut</head><p>We experimented with adding maxout to the end of the network, which was helpful in our submission to PlantCLEF 2016: an additional fully-connected (FC) layer was added on top of the network, before the classification FC layer. The activation function in the added layer is maxout <ref type="bibr" coords="2,368.93,581.14,14.61,8.74" target="#b13">[14]</ref>, maximum over slices of the layer:</p><formula xml:id="formula_0" coords="2,269.59,618.45,211.00,15.05">h i (x) = max j∈[1,k] z ij ,<label>(1)</label></formula><p>where</p><formula xml:id="formula_1" coords="3,134.77,118.42,345.83,22.83">z ij = x T W ..ij + b ij is a standard FC layer with parameters W ∈ R d×m×k , b ∈ m×k .</formula><p>One can understand maxout as a piecewise linear approximation to a convex function, specified by the weights of the previous layer. This is illustrated in Figure <ref type="figure" coords="3,166.20,168.07,3.87,8.74" target="#fig_0">1</ref>. We added a FC layer with 4096 units. The maxout activation operates over k = 4 linear pieces of the FC layer, i.e. m = 1024. Dropout with a keep probability of 80% is applied before the FC layers. The final layer is a 10000-way softmax classifier corresponding to the number of plant species needed to be recognized.</p><p>We observed is that the additional FC layer has to be batch normalized <ref type="bibr" coords="3,134.77,410.92,14.61,8.74" target="#b14">[15]</ref>. Without normalization, the architecture becomes unstable with the default setting of hyperparameters, leading to unexpected drop in accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Bootstrapping</head><p>In order to improve learning from noisy labels, Reed et. al. <ref type="bibr" coords="3,385.82,475.32,15.50,8.74" target="#b15">[16]</ref> proposed a simple consistency objective, which does not require an explicit information about the noise distribution.</p><p>Intuitively, the new objective(s) takes into account the current predictions of the network, lowering the damage done by incorrect labels. Reed al. propose two variants of the objective, denoted as Bootstrapping for consistency in multi-class prediction:</p><p>-soft bootstrapping uses the probabilities q k estimated by the network (softmax):</p><formula xml:id="formula_2" coords="3,231.20,594.58,249.39,30.55">L soft (q, t) = N k=1 [βt k + (1 -β)q k ] log q k (2)</formula><p>Reed et al. <ref type="bibr" coords="3,201.90,633.20,15.50,8.74" target="#b15">[16]</ref> point out that the objective is equivalent to softmax regression with minimum entropy regularization, which was previously studied in <ref type="bibr" coords="3,151.70,657.11,14.61,8.74" target="#b16">[17]</ref>; encouraging high confidence in predicting labels.</p><p>-hard bootstrapping uses the strongest prediction</p><formula xml:id="formula_3" coords="4,229.52,120.67,251.07,70.02">z k = 1 if k = argmaxq i 0 otherwise L hard (q, t) = N k=1 [βt k + (1 -β)z k ] log q k (3)</formula><p>The experiments of <ref type="bibr" coords="4,235.84,204.14,15.50,8.74" target="#b15">[16]</ref> show that the two objectives improve learning in the case of label noise, achieving the best accuracy with hard bootstrapping. We decided to follow the result of <ref type="bibr" coords="4,272.21,228.05,15.50,8.74" target="#b15">[16]</ref> and use hard booststrapping with β = 0.8 in our experiments. The search for the optimal value of β was ommited for computational reasons and limited time for the competition, yet the dependence between the amount of label noise and the optimal setting of hyperparameter β is an interesting topic of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We used a subset of the test data from the previous year's PlantCLEF 2016 challenge to thoroughly evaluate the proposed methods. We only used 2583 images from the previous year dataset, for which we found species-correspondences in the 2017 task. This small validation set covers only a small subset of the classes, but should be sufficient for an approximate evaluation of the method.</p><p>The sections below describe the experiments and corresponding design choices:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Fine-tuning vs. Training from Scratch</head><p>The first issue tested was whether the network should be trained from scratch, or fine-tuned from an ImageNet-pretrained model. We compared the two scenarios by training only on the "trusted" dataset. As illustrated in Figure <ref type="figure" coords="4,472.84,480.46,3.87,8.74">2</ref>, training from scratch converges very slow. After 150k iterations (mini-batches) fine-tuning leads to 65.1% accuracy, while training from scratch only gets to 44.5%. For illustration 150k training iterations take ca. 65 hours on an NVIDIA Titan X GPU. Therefore we decided for fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training on Trusted and Noisy Data</head><p>We fine-tuned the system with different settings described in Section 2 on the "trusted" (EOL) data only, as well as on the combination of both "trusted" and "noisy" data (EOL+WEB). The soft-and hard-bootstrapping were used for training with "noisy" data. Figure <ref type="figure" coords="4,308.54,621.25,4.98,8.74">3</ref> shows that after 200k iterations, the networks trained only on the "trusted" data performed slightly better. The two best performing networks trained on the "trusted" (EOL) dataset will be used in the follow-up experiments. Fig. <ref type="figure" coords="5,153.45,340.04,3.87,8.74">2</ref>: Accuracy (solid) and recal@5 (dotted) when fine-tuning (red) and training from scratch (blue).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Filtering the Noisy Data and Further fine-tuning</head><p>In order to filter out wrongly labeled examples from the "noisy" part of the training set, we used the network pretrained on the "trusted set" (from Section 3.2) to predict the labels from images. Only images, where the network prediction was equal to the label were kept in the "filtered noisy" dataset. This reduced the size of the "noisy" set from ca 1405k images to ca 425k images.</p><p>Let us denote the two networks fine-tuned on the "trusted" (EOL) dataset in Section 3.2 as follows:</p><p>-Net #1: Fine-tuned on "trusted" (EOL) set without maxout for 200k iterations. -Net #2: Fine-tuned on "trusted" (EOL) set with maxout for 200k iterations.</p><p>Further fine-tuning was performed from these models pre-trained (fine-tuned) on the "trusted" set. In order to perform bagging from several networks, we divide the data into 3 disjoint folds. Then each setting is used to further finetune three networks, each on different 2 of the 3 folds. Each network is further fine-tuned for 50k iterations.</p><p>-Net #3,#4,#5: Fine-tuned from #1 for 50k iterations on the "trusted" dataset. -Net #6,#7,#8: Fine-tuned from #2 for 50k iterations on the "trusted" dataset, with maxout. Fig. <ref type="figure" coords="6,181.14,340.04,3.87,8.74">3</ref>: Accuracy (solid) and recal@5 (dotted) for different settings.</p><p>-Net #9,#10,#11: Fine-tuned from #1 for 50k iterations on the "trusted" and filteret noisy data. -Net #12,#13,#14: Fine-tuned from #1 for 50k iterations on the "trusted" and filteret noisy data, with hard bootstrapping. -Net #15,#16,#17: Fine-tuned from #2 for 50k iterations on the "trusted" and filteret noisy data, with maxout.</p><p>Figure <ref type="figure" coords="6,181.25,467.63,4.98,8.74">4</ref> shows the validation of the further fine-tuning. Although there are certain differences, all the networks (listed below) are quite precise, yet do not individually bring much improvement compared to the networks from Section 3.2. The strength here is in combination of the differently fine-tuned networks. the red dashed line in 4 shows the final accuracy (after 50k it. of fine-tuning) of their combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Post Processing on the Test Set</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Averaging predictions per observation</head><p>As shown by the previous year's challenge winner <ref type="bibr" coords="6,363.93,621.25,15.50,8.74" target="#b11">[12]</ref> and confirmed by the experiments described in this report, averaging the predictions over images of the same observation (specimen) increases accuracy significantly. Therefore we also average scores per observations in all submitted runfiles. PlantCLEF2017 bags (eval. on 2016 test)</p><p>Sel. 0 (Accuracy) Sel. 0 (Recall@5) Sel. 1 (Accuracy) Sel. 1 (Recall@5) Sel. 2 (Accuracy) Sel. 2 (Recall@5) Sel. 0 bootstrap_hard (Accuracy) Sel. 0 bootstrap_hard (Recall@5) Sel. 1 bootstrap_hard (Accuracy) Sel. 1 bootstrap_hard (Recall@5) Sel. 2 bootstrap_hard (Accuracy) Sel. 2 bootstrap_hard (Recall@5) Sel. 0 maxout_batchnorm (Accuracy) Sel. 0 maxout_batchnorm (Recall@5) Sel. 1 maxout_batchnorm (Accuracy) Sel. 1 maxout_batchnorm (Recall@5) Sel. 2 maxout_batchnorm (Accuracy) Sel. 2 maxout_batchnorm (Recall@5) EOL 0 (Accuracy) EOL 0 (Recall@5) EOL 1 (Accuracy) EOL 1 (Recall@5) EOL 2 (Accuracy) EOL 2 (Recall@5) EOL 0 maxout_batchnorm (Accuracy) EOL 0 maxout_batchnorm (Recall@5) EOL 1 maxout_batchnorm (Accuracy) EOL 1 maxout_batchnorm (Recall@5) EOL 2 maxout_batchnorm (Accuracy) EOL 2 maxout_batchnorm (Recall@5)</p><p>Fig. <ref type="figure" coords="7,153.45,340.67,3.87,8.74">4</ref>: Accuracy (solid) and recal@5 (dotted) for further fine-tuning using different settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Adjusting Test Set Prediction Distribution</head><p>Given the fact that we are evaluating the whole test set of images, we decided to experiment with adjusting the prediction distribution over the test set. Some plant species are certainly much rarer to observe than other. We assumed that the species in the test set might not follow the same distribution as the species in the training set. We computed the prior p(K) for each class K among the observations in the "trusted" dataset, and estimated the prior p t (K) of on the test set. Let q(K|X) be the prediction confidence for class K, given input image X. The final prediction taking into account the possible shift in the distributions was:</p><formula xml:id="formula_4" coords="7,244.93,515.53,235.66,23.22">q * (K|X) = q(K|X) p(K) p t (K) ,<label>(4)</label></formula><p>where the square root is used to make the adjustment less severe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Description of the Submitted Runfiles</head><p>In PlantCLEF 2017, each participant is allowed to submit up to four runfiles with the results. We submitted the following run files:</p><p>-CMP Run 1 combines all 17 networks by summimg their results.</p><p>-CMP Run 2 uses the prediction distribution adjustment from Section 4.2 on top of the results from the first runfile.</p><p>-CMP Run 3 combines only networks trained on the "trusted" data.</p><p>-CMP Run 4 again adds the prediction distribution adjustment on top of results from the third runfile. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>The difficulties of the challenge lie in the high number of classes, high intra-class variations, small inter-class variations, and learning from noisy data downloaded by web crawlers.</p><p>To overcome these difficulties, we employed a state-of-the-art deep learning architecture and compared a number of approaches to increase the accuracy of very fine-grained classification when learning from noisy data. The results of the challenge are depicted in Figure <ref type="figure" coords="8,277.18,569.91,3.87,8.74" target="#fig_2">5</ref>. Based on our evaluation, the following steps increase the classification accuracy:</p><p>-Maxout <ref type="bibr" coords="8,192.11,601.58,15.50,8.74" target="#b13">[14]</ref> with batch normalisation <ref type="bibr" coords="8,323.64,601.58,15.50,8.74" target="#b14">[15]</ref> of the added FC layer.</p><p>-Filtering the noisy data using a model trained on a trusted database.</p><p>-Bagging of several networks fine-tuned under different conditions.</p><p>Adjusting the species distribution on the test set, on the other hand, has decreased the recognition accuracy noticeably.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,183.40,314.08,248.56,8.74;3,137.60,200.02,340.16,102.53"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Illustration of maxout from Goodfellow et al. [14].</figDesc><graphic coords="3,137.60,200.02,340.16,102.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,194.44,416.56,226.48,8.74;8,137.60,183.00,340.16,222.03"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Results of the PlantCLEF 2017 [1] challenge.</figDesc><graphic coords="8,137.60,183.00,340.16,222.03" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,647.48,301.27,7.47;2,144.73,658.44,85.73,7.47"><p>https://github.com/tensorflow/models/blob/master/slim/README.md# pre-trained-models</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>Milan Šulc was supported by <rs type="funder">Electrolux Student Support Programme</rs> and by <rs type="funder">CTU</rs> student grant <rs type="grantNumber">SGS17/185/OHK3/3T/13</rs>, <rs type="person">Jiří Matas</rs> was supported by The <rs type="funder">Czech Science Foundation</rs> Project <rs type="grantNumber">GACR P103/12/G084</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_esJVxcC">
					<idno type="grant-number">SGS17/185/OHK3/3T/13</idno>
				</org>
				<org type="funding" xml:id="_XA8eM4A">
					<idno type="grant-number">GACR P103/12/G084</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,142.96,215.27,337.63,7.86;9,151.52,226.22,329.07,7.86;9,151.52,237.18,104.14,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,340.50,215.27,140.09,7.86;9,151.52,226.22,279.42,7.86">Plant identification based on noisy web data: the amazing performance of deep learning (lifeclef 2017)</title>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,455.98,226.22,24.61,7.86;9,151.52,237.18,75.79,7.86">CLEF working notes 2017</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,247.53,337.63,7.86;9,151.52,258.48,329.07,7.86;9,151.52,269.44,329.07,7.86;9,151.52,280.40,230.65,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,274.06,269.44,206.53,7.86;9,151.52,280.40,77.83,7.86">Lifeclef 2017 lab overview: multimedia species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Concetto</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Willem-Pier</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean-Christophe</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Planqué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Simone</forename><surname>Palazzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,248.84,280.40,105.00,7.86">Proceedings of CLEF 2017</title>
		<meeting>CLEF 2017</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,290.74,337.64,7.86;9,151.52,301.70,329.07,7.86;9,151.52,312.66,329.07,7.86;9,151.52,323.62,133.33,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,209.54,312.66,251.26,7.86">Lifeclef 2016: multimedia life species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Concetto</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Willem-Pier</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Champ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Planqué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Simone</forename><surname>Palazzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,151.52,323.62,105.00,7.86">Proceedings of CLEF 2016</title>
		<meeting>CLEF 2016</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,333.96,337.63,7.86;9,151.52,344.92,329.07,7.86;9,151.52,355.88,267.32,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,349.43,333.96,131.16,7.86">Lifeclef plant identification task</title>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,189.74,344.92,290.85,7.86;9,151.52,355.88,22.25,7.86">Working Notes of CLEF 2015 -Conference and Labs of the Evaluation forum</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2015-09-08">2015. September 8-11, 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,366.22,337.63,7.86;9,151.52,377.18,204.47,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,334.64,366.22,145.95,7.86;9,151.52,377.18,52.74,7.86">Plant identification in an open-world (lifeclef 2016)</title>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,223.96,377.18,103.70,7.86">CLEF working notes 2016</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,387.52,337.64,7.86;9,151.52,398.48,329.07,7.86;9,151.52,409.44,329.07,7.86;9,151.52,420.40,118.88,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,223.04,387.52,257.56,7.86;9,151.52,398.48,187.88,7.86">Plant identification with deep convolutional neural network: Snumedinfo at lifeclef plant identification task</title>
		<author>
			<persName coords=""><forename type="first">Sungbin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,380.78,398.48,99.81,7.86;9,151.52,409.44,207.24,7.86">Working Notes of CLEF 2015 -Conference and Labs of the Evaluation forum</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2015-09-08">2015. September 8-11, 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,430.74,337.63,7.86;9,151.52,441.70,329.07,7.86;9,151.52,452.66,329.07,7.86;9,151.52,463.62,162.98,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,429.28,430.74,51.31,7.86;9,151.52,441.70,231.19,7.86">Content specific feature learning for fine-grained plant classification</title>
		<author>
			<persName coords=""><forename type="first">Zongyuan</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Mccool</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Condrad</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Corke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,407.18,441.70,73.41,7.86;9,151.52,452.66,248.05,7.86">Working Notes of CLEF 2015 -Conference and Labs of the Evaluation forum</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2015">September 8-11, 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,473.96,337.64,7.86;9,151.52,484.92,329.07,7.86;9,151.52,495.88,329.07,7.86;9,151.52,506.84,329.07,7.86;9,151.52,517.80,70.90,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,450.54,473.96,30.05,7.86;9,151.52,484.92,329.07,7.86;9,151.52,495.88,117.87,7.86">A comparative study of fine-grained classification methods in the context of the lifeclef plant identification challenge</title>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Champ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Titouan</forename><surname>Lorieul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maximilien</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,313.80,495.88,166.79,7.86;9,151.52,506.84,156.38,7.86">Working Notes of CLEF 2015 -Conference and Labs of the Evaluation forum</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2015-09-08">2015. September 8-11, 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,528.14,337.63,7.86;9,151.52,539.10,329.07,7.86;9,151.52,550.06,329.07,7.86;9,151.52,561.01,95.35,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,391.75,528.14,88.84,7.86;9,151.52,539.10,168.93,7.86">Fine-tuning deep convolutional networks for plant recognition</title>
		<author>
			<persName coords=""><forename type="first">Angie</forename><forename type="middle">K</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Juan</forename><forename type="middle">C</forename><surname>Caicedo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jorge</forename><forename type="middle">E</forename><surname>Camargo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,346.04,539.10,134.55,7.86;9,151.52,550.06,182.15,7.86">Working Notes of CLEF 2015 -Conference and Labs of the Evaluation forum</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2015">September 8-11, 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,569.09,337.98,10.13;9,151.52,582.32,329.07,7.86;9,151.52,593.27,54.50,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,343.89,571.36,136.71,7.86;9,151.52,582.32,169.53,7.86">Very deep residual networks with maxout for plant identification in the wild</title>
		<author>
			<persName coords=""><forename type="first">Milan</forename><surname>Šulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dmytro</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jirı</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,340.78,582.32,139.81,7.86;9,151.52,593.27,26.63,7.86">Working notes of CLEF 2016 conference</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,603.62,337.98,7.86;9,151.52,614.58,329.07,7.86;9,151.52,625.53,86.29,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,421.20,603.62,59.39,7.86;9,151.52,614.58,285.38,7.86">Open-set plant identification using an ensemble of deep convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">Berrin</forename><surname>Mostafa Mehdipour Ghazi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Erchan</forename><surname>Yanikoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Aptoula</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,446.35,614.58,34.25,7.86;9,151.52,625.53,56.78,7.86">Working notes of CLEF</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,635.88,337.98,7.86;9,151.52,646.84,329.07,7.86;9,151.52,657.79,20.99,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,390.76,635.88,89.84,7.86;9,151.52,646.84,144.22,7.86">Bluefield (kde tut) at lifeclef 2016 plant identification task</title>
		<author>
			<persName coords=""><forename type="first">Siang</forename><surname>Thye</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hang</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Atsushi</forename><surname>Tatsuma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Masaki</forename><surname>Aono</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,314.73,646.84,161.85,7.86">Working notes of CLEF 2016 conference</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,120.67,337.97,7.86;10,151.52,131.63,329.07,7.86;10,151.52,142.59,97.09,7.86" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alex</forename><surname>Alemi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.07261</idno>
		<title level="m" coord="10,427.86,120.67,52.73,7.86;10,151.52,131.63,264.96,7.86">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,142.62,153.55,337.97,7.86;10,151.52,164.51,264.22,7.86" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="10,185.69,164.51,68.27,7.86">Maxout networks</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1302.4389</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,142.62,175.46,171.21,7.86;10,332.89,175.46,147.70,7.86;10,151.52,186.42,329.07,7.86;10,151.52,197.38,97.09,7.86" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="10,332.89,175.46,147.70,7.86;10,151.52,186.42,252.28,7.86">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName coords=""><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,142.62,208.34,337.98,7.86;10,151.52,219.30,329.07,7.86;10,151.52,230.26,216.48,7.86" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="10,275.46,219.30,205.13,7.86;10,151.52,230.26,54.74,7.86">Training deep neural networks on noisy labels with bootstrapping</title>
		<author>
			<persName coords=""><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6596</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,142.62,241.22,337.97,7.86;10,151.52,252.18,121.76,7.86" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="10,314.57,241.22,166.02,7.86;10,151.52,252.18,30.82,7.86">Entropy regularization. Semi-supervised learning</title>
		<author>
			<persName coords=""><forename type="first">Yves</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="151" to="168" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
