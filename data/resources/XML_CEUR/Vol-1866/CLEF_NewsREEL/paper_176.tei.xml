<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,154.03,115.96,307.29,12.62;1,224.74,133.89,165.87,12.62">CLEF NewsREEL 2017: Contextual Bandit News Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,205.21,171.56,39.99,8.74"><forename type="first">Yu</forename><surname>Liang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Delft University of Technology</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,255.75,171.56,50.65,8.74"><forename type="first">Babak</forename><surname>Loni</surname></persName>
							<email>b.loni@tudelft.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">Delft University of Technology</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,333.56,171.56,65.29,8.74"><forename type="first">Martha</forename><surname>Larson</surname></persName>
							<email>m.a.larson@tudelft.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">Delft University of Technology</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Radboud University Nijmegen</orgName>
								<address>
									<country>Netherlands Y.Liang</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,154.03,115.96,307.29,12.62;1,224.74,133.89,165.87,12.62">CLEF NewsREEL 2017: Contextual Bandit News Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BD6C4BDAB2F7F7ADDD9F7658873DAB74</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Recommender System</term>
					<term>Context</term>
					<term>Contextual Bandit</term>
					<term>News</term>
					<term>Evaluation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the CLEF NewsREEL 2017 challenge, we build a delegation model based on the contextual bandit algorithm. Our goal is to investigate whether a bandit approach combined with context extracted from the user side, from the item side and from user-item interaction can help choose the appropriate recommender from a recommender algorithm pool for the incoming recommendation requests. We took part in both tasks: NewsREEL Live and NewsREEL Replay. In the experiment, we test several bandit approaches with two types of context features. The result from NewsREEL Replay suggests that delegation model based on the contextual bandit algorithm can improve the click through rate (CTR). In NewsREEL Live, a similar delegation model is implemented. However, the delegation model from NewsREEL Live is trained by the data stream from NewsREEL Replay. This is due to the fact that the low volume of data received from the online scenario is not enough to support the training of the delegation model. For our future work, we will add more recommender algorithms to the recommender algorithm pool and explores other context features.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The CLEF NewsREEL Challenge <ref type="bibr" coords="1,285.72,512.66,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="1,297.89,512.66,7.75,8.74" target="#b1">2]</ref> is a challenge in which participants are asked to provide effective real-time news recommendation. The challenge provides participants with a platform to evaluate their recommender algorithms with millions of real-world users. We took part in both tasks <ref type="bibr" coords="1,401.80,548.52,9.96,8.74" target="#b2">[3]</ref>: Task 1 (News-REEL Live) <ref type="bibr" coords="1,191.45,560.48,10.52,8.74" target="#b3">[4]</ref> and Task 2 (NewsREEL Replay) <ref type="bibr" coords="1,353.34,560.48,9.96,8.74" target="#b4">[5]</ref>. In the Live task, the recommendation requests are distributed to all participants of the challenge and thus not all traffic is sent to a single participant. This makes it more challenging than the Replay task. In the Live task, we use a trained delegation model that is implemented for the Replay task.</p><p>Our work was initially inspired by Lommatzsch and Albayrak, who, in their work <ref type="bibr" coords="1,159.97,632.21,9.96,8.74" target="#b5">[6]</ref>, combine several recommender algorithms with one delegation model responsible for delegating the incoming recommendation request to the appropriate recommender algorithm. In our work, we also build a similar delegation model with the objective to improve recommendation performance, in other words, to maximize Click Through Rate (CTR). We find that a multi-armed bandit (MAB) algorithm is suited for the purpose. Multi-armed bandit algorithms address the problem of a gambler at a row of slot machines who has to decide which machine to play, in what sequence to play and how many times to play in order to maximize the rewards collecting from the slot machines. The model has been widely used in website optimization <ref type="bibr" coords="2,370.28,190.72,10.52,8.74" target="#b6">[7]</ref> for choosing the right ads for users <ref type="bibr" coords="2,198.04,202.68,10.52,8.74" target="#b7">[8]</ref> and selecting the right advertisement format <ref type="bibr" coords="2,412.70,202.68,9.96,8.74" target="#b8">[9]</ref>. All of these models involve optimization problems, e.g., selecting the suitable ad format in order to maximize the CTR received from users. Another good property of MAB algorithms is that they can continuously learn from the past, such as from user feedback, and then adjust its decisions about which arm to choose. With the feedback, it is able to balance the exploration and exploitation dilemma. Exploitation means the MAB algorithm chooses the arm with the currently best performance from the previous plays, while exploration means it chooses the arm with lower performance in order to learn more from these arms. This kind of trade-off is missing in A/B testing, in which a pure exploration is applied at the initial phase followed by a pure exploitation in a very long period <ref type="bibr" coords="2,446.43,322.23,9.96,8.74" target="#b6">[7]</ref>. The exploration and exploitation trade-off makes MAB algorithm works well for the news recommendation <ref type="bibr" coords="2,233.39,346.14,14.61,8.74" target="#b9">[10]</ref>, in which it is able to recommend popular items most of the time and also explore the news items in the long tail. Further, combined with context, the model works even better. Context is proved to be useful for the optimization <ref type="bibr" coords="2,210.04,382.01,8.07,8.74" target="#b6">[7]</ref><ref type="bibr" coords="2,218.11,382.01,4.03,8.74" target="#b7">[8]</ref><ref type="bibr" coords="2,218.11,382.01,4.03,8.74" target="#b8">[9]</ref><ref type="bibr" coords="2,222.14,382.01,12.10,8.74" target="#b9">[10]</ref>.</p><p>However, our consideration is not directly related to news items, but the recommender algorithms. Given the effective recommender algorithms from previous years, we believe the contextual bandit algorithm is able to combine them in a wise way and ultimately improve the recommendation performance. Our research interest comes with the assumption that given the context of a user, item and user-item interaction, contextual bandit algorithms can help choose appropriate recommender algorithm for each recommendation request and thereby improve the CTR.</p><p>This paper is structured as follows: in Section 2, we discuss the work related to the contextual multi-armed bandit algorithm. In Section 3, we introduce the method that we implemented in this work. Section 4 describes our evaluation methods, including NewsREEL Replay and NewsREEL Live. In Section 5, we analyze the evaluation results. In the last section, we summarize the results and discuss future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related Work</head><p>2.1 Multi-armed Bandit Algorithms epsilon-Greedy Epsilon-Greedy is the simplest algorithm to solve the multiarmed bandit problem. The only parameter in the model is . In the standard settings, is fixed. With probability 1 -, the policy plays the currently best arm, and with probability , it plays a random arm. The algorithms also have several variations, e.g., -decreasing in which decreases over time <ref type="bibr" coords="3,427.48,130.95,14.61,8.74" target="#b10">[11]</ref>.</p><p>Upper Confidence Bound Unlike epsilon-greedy, UCB is not only concerned about the reward from the previous plays, but also about how much it knows about the available arms. At the initial phase, UCB explores each arm at least once. After the initial phase, each time it plays the arm with the highest value from the formula r α + b, where r α is the estimated reward for arm α, and b is a special bonus for the arm α. One widely used UCB variation is UCB1 <ref type="bibr" coords="3,450.77,220.18,14.61,8.74" target="#b11">[12]</ref>, in which b is set to be</p><formula xml:id="formula_0" coords="3,226.96,233.34,42.03,19.28">2ln n i=1 ti tα</formula><p>, t i is the number of plays arm i has been chosen, and t α is the number of plays arm α has been chosen. In UCB, arms that are explored less in the previous plays would receive higher bonus value, while arms that are explored more would receive lower bonus value. This can prevent the under-exploration of potential rewarding arms.</p><p>Thompson Sampling Another widely used multi-armed bandit algorithm is Thompson Sampling. Thompson sampling models the probability distribution of each arm's reward. The reward of arm α follows a probability distribution with mean θ * α <ref type="bibr" coords="3,173.86,357.08,14.61,8.74" target="#b12">[13]</ref>. In the case where bandits are binary, a Beta-Bernoulli distribution <ref type="bibr" coords="3,134.77,369.03,15.50,8.74" target="#b13">[14]</ref> is used. The algorithms repeatedly draw a sample from the distribution of each arm, and it plays the arm with the largest value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Contextual Bandit Algorithms</head><p>Contextual bandit algorithms combine MABs with context features. In our settings, users and news articles are always represented by feature vectors, such as domains. The contextual bandit algorithm chooses arms in such a way that the most appropriate arm for each context is played to maximize the reward. A trivial implementation is to build a MAB model for each context. Another idea is assuming there is a relationship between the expected reward and the context. We implement both ideas.</p><p>Linear UCB Linear UCB is a contextual bandit algorithm first proposed in <ref type="bibr" coords="3,462.33,531.13,14.61,8.74" target="#b9">[10]</ref>. The algorithm assumes that there is a linear relationship between the expected reward and the context. In this algorithm, the context is used to update the rewards and improve its arm selection strategy. In each trial (play) t, the expected payoff of arm α is equal to E[r t,α |x t,α ] = x t,α θ * α , where r t,α specifies the reward of arm α at trial t, x t,α specifies the feature vector for arm α at trial t and θ * α is a coefficient that can be learned from the previous trials. In each trial, the algorithm plays the arm with the highest final score. The final score of each arm is calculated as:</p><formula xml:id="formula_1" coords="3,212.21,649.01,268.39,13.24">α t = argmax α∈A x t,α θα + β x T t,α A -1 α x t,α<label>(1)</label></formula><p>where A is the set of arms, θα is an estimate of coefficients, β is a hyper-parameter and A is the covariance matrix of coefficients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Framework</head><p>Our framework is designed to validate the hypothesis that contextual bandit algorithms can choose the appropriate recommender algorithm from the recommender algorithm pool for the incoming recommendation requests given context from users and items. In NewsREEL Replay, we consider two types of training: the training of the delegation model and the training of the recommender algorithms. The delegation model is trained and updated in batches (a more detailed discussion is presented in Section 3.2). In contrast, the recommender algorithms are trained and are able to update continuously regardless of the batches. The delegation model implemented in the Live task is also trained in the same way, but the data stream for training is from the offline dataset due to the low volume received from the online scenario. The recommender algorithms in the Live scenario also update continuously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Recommender Algorithms</head><p>We build up our delegation recommender based on the recommender developed by recommenders.net. The recommender algorithm pool consists of five simple recommender algorithms:</p><p>-Recent: Recommend the most recently created or updated articles. For the realization, a ring buffer is implemented to store the most recently created or updated articles. The size of the ring buffer is set to 100. When there is a new item, it will be inserted into the ring buffer. If the ring buffer reaches its size, it will drop the least recent news articles. -Path: Given the news articles that the user is currently reading, recommend the most popular<ref type="foot" coords="4,229.01,473.52,3.97,6.12" target="#foot_0">3</ref> news articles requested next by users, referring to the Most Popular Sequence in the work <ref type="bibr" coords="4,318.48,487.05,9.96,8.74" target="#b5">[6]</ref>. In the default settings, for each news article, 100 most recently requested articles are kept. The popularity scores are then computed from the 100 articles. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Delegation Framework</head><p>Our proposed delegation framework is trained and updates only in the Replay task. The low volume of data from the Live task is not enough for training such a framework. However, in NewsREEL Live, we implement the delegation model trained from the NewsREEL Replay. More details about NewsREEL Live can be found in Section 4.1. It is not trivial to implement MAB algorithm in the realworld settings. We first define the reward. In our settings, the reward is defined as clicks received from recommendations. If a user clicks on a recommendation, the reward is 1, otherwise, the reward is 0. Therefore, the reward is a binary value. Given the context, the recommender algorithm, and its corresponding reward, the delegation model is able to update. However, unlike what is implemented in <ref type="bibr" coords="5,181.09,257.66,10.52,8.74" target="#b8">[9,</ref><ref type="bibr" coords="5,193.26,257.66,11.62,8.74" target="#b9">10]</ref>, where rewards can be obtained immediately after each action, rewards in real-world settings are delayed. Specifically, in our case, there would be hundreds of incoming recommendation requests between a recommendation and its corresponding reward. It is unrealistic to suspend the delegation model before receiving the reward or to update the whole delegation model each time a reward is observed. We implement a similar batch update as used in the work <ref type="bibr" coords="5,470.07,317.44,10.52,8.74" target="#b7">[8]</ref> for our delegation model. The basic underlying idea is to update the delegation model in batches, in other words, the model updates only after receiving enough amount of reward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Batch update and assignment</head><p>The whole recommendation process is divided into batches. The contextual bandit algorithm is updated at the end of each batch with the rewards collected in each batch, as illustrated in Figure <ref type="figure" coords="5,423.66,406.30,3.87,8.74" target="#fig_1">1</ref>. After each update, the delegation model will preassign appropriate recommender for each context to serve incoming requests in the next batch.</p><p>Initialization In the first batch, there is no historical data from which the contextual bandit algorithm can learn the model. Therefore, at the initial phase of recommendation, recommender algorithms are randomly selected to serve the incoming recommendation requests. At the end of the first batch, the contextual bandit algorithm is able to update for the first time with the rewards collected in the first batch.</p><p>Rewards Rewards are defined as 'clicks' received from the recommendations. However, in both tasks, we cannot directly track whether our previous recommendations are successful or not. Making use of the evaluator from NewsREEL Replay, the reward is defined, for a given recommendation, based on whether the user interacts with the item in the next 10 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Exploiting Context</head><p>We exploit context with two different methods. In the first method, the context is used to filter the model. For example, if the recommendation request belongs to a domain A, the method chooses the model that is trained from items in A.</p><p>We refer to this method as context pre-filtering. Our second approach exploits context for training the model. We refer to this method as context modeling. We use the Linear UCB algorithm <ref type="bibr" coords="6,274.32,304.17,15.50,8.74" target="#b9">[10]</ref> to exploit context in the model. We use a special case of general contextual bandit algorithm known as K-armed bandit, where the set of arms remains the same in all trials. In our framework, the five algorithms introduced earlier in this section are served as the arms. The score of arms is calculated according to Eq.( <ref type="formula" coords="6,294.13,351.99,4.59,8.74" target="#formula_1">1</ref>) where the feature vectors x t,α are built based on the given context.</p><p>For the contextual bandit algorithm, it is important to find useful context features. Unlike other work <ref type="bibr" coords="6,256.28,390.48,10.52,8.74" target="#b7">[8,</ref><ref type="bibr" coords="6,268.45,390.48,11.62,8.74" target="#b9">10]</ref>, where the user profile is available, we do not have any information about the user profile. Users can only be tracked by their cookies, and some users even do not allow any tracking. All contextual information is encoded in the incoming messages. In addition, not all context features can contribute to the performance of recommender algorithms. We consider two context features, one is Domain, which is also considered as an important context feature in the work <ref type="bibr" coords="6,241.42,462.21,10.52,8.74" target="#b5">[6]</ref> and the other is User-Domain Impressions. Domain refers to different publishers, and User-Domain Impressions refers to the number of impressions the user has with the domain.</p><p>Figure <ref type="figure" coords="6,182.15,500.70,4.98,8.74" target="#fig_3">2</ref> shows the recommender algorithms' performance with respect to different context features using the CTR metric. In domain '418', a general news portal, the recommender Click performs the best. This recommender also shows a good performance in domain '1677', which is also a general news portal. However, the popularity based algorithm does not perform well in domain '35774', a sports news portal. The recommender algorithm Recent shows the best performance in this domain. This can be explained by the fact that people always prefer the newest sports news. Also, the bad performance of PRCate might be due to the reason the sports domain is already very specific, and further specific category would not help. The findings are consistent with the findings in previous work. Figure <ref type="figure" coords="6,234.17,620.25,4.98,8.74" target="#fig_4">3</ref> shows the algorithms performance with respect to the number of user-domain impressions in domain '418'. Normally, with the increase of the number of user-domain impressions, CTR should also be increased as users with more interactions with the publishers would be more willing to click on the recommendations. However, there are some exceptions. With the increase of User-Domain Impressions, CTR observed from the Click algorithm experience a sharp decrease. The decrease can be explained by the fact people with enough interactions with the publisher have already seen the popular articles and prefer the newest news. In  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head><p>In both online and offline scenario, there are four types of messages: recommendation request, item update, event notification and error notification. Specifically, in the Live task, the recommender needs to give recommendations within 100ms, otherwise the recommendations will be regarded as invalid. As the data volume redirected to our recommender is too low in the Live task, the delegation model implemented online is the one with the best performance in NewsREEL Replay. Thus, in the following sections, we will first discuss our experiment in NewsREEL Replay, and then NewsREEL Live.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">NewsREEL Replay</head><p>Our recommendation framework that is used in NewsREEL Replay is described in Section 3. For this task, we are provided a month-long dataset collected during February 2016. Normally, a replay of a daily dump takes about 3-4 hours. Due to the time constraints, data collected from 2016-02-01 to 2016-02-03 is replayed for evaluation. The dataset is not evenly distributed: about 75% traffic is from the domain '35774', a sports domain, followed by two general news domains '1677' and '418'. In the evaluation phase, we only consider the results from the above three domains since a majority of traffic comes from these three domains. The evaluation phase is as follows: Firstly, the daily dump from 2016-02-01 is replayed to prevent the cold-start problem. Then the evaluation phase is implemented in the following way: The rest of the dataset (data from 2016-02-02 to 2016-02-03) is split into N smaller mutually exclusive datasets with the same size. The dataset is replayed in batches. See Figure <ref type="figure" coords="8,403.25,453.83,4.98,8.74" target="#fig_1">1</ref> for clarification. There are two different batch sizes, one containing 100000 line messages, and the other containing 300000 line messages. Next, as explained in Section 3.1, for each batch, rewards are computed at the end of the batch. After that, the contextual bandit algorithm is able to update the model. Finally, the chosen recommender algorithm is assigned for the incoming requests in the next batch. In Table <ref type="table" coords="8,472.84,513.61,3.87,8.74" target="#tab_0">1</ref> results with the best performance in each domain are highlighted. In Table <ref type="table" coords="9,475.61,118.99,4.98,8.74" target="#tab_1">2</ref> and 3, results with similar or better performance than the results in Table <ref type="table" coords="9,475.61,130.95,4.98,8.74" target="#tab_0">1</ref> are also highlighted. For all algorithms, we measure their performance based on average CTR and CTR in the three domains. We also further compare the CTR with the random baseline. The percentage in the tables shows the CTR change comparing to the baseline. With the context given in Section 3.2, we propose two different delegation models in the Replay task. In the first method, referred as context pre-filtering, we only consider the context Domain and implement a separate bandit model in each of the three news domains. In the second approach, referred as contextmodeling, we encode context (Domain and User-domain Impressions) as feature vectors. Then we build a contextual bandit model based on the linucb (Linear UCB) model. The results of the simple baseline recommender algorithms are presented in Table <ref type="table" coords="9,238.59,512.66,3.87,8.74" target="#tab_0">1</ref>, the results of the context pre-filtering model in Table 2, and the results of the context-modeling approach is listed in Table <ref type="table" coords="9,472.84,524.61,3.87,8.74" target="#tab_2">3</ref>. The random algorithm, which randomly selects a recommender algorithm to serve the incoming requests, is set as the baseline, referred to as random in Table <ref type="table" coords="9,163.76,560.48,3.87,8.74" target="#tab_0">1</ref>. The names of the contextual bandit algorithms in Table <ref type="table" coords="9,438.87,560.48,4.98,8.74" target="#tab_1">2</ref> contain algorithm hyperparamter value batch size. There are three different bandit algorithms in context pre-filtering: epsilon-greedy (epsilon), ucb1 and Thompson Sampling (ts). For epsilon-greedy, we tried three different value: 0.5, 0.3 and 0.1. In the experiment, we also tried two batch sizes: b3 means each batch containing 300000 messages and b1 indicating 100000 messages. Contextual bandit algorithms in Table <ref type="table" coords="9,225.89,632.21,4.98,8.74" target="#tab_2">3</ref> are formatted as algorithm hyperparamter value context used batch size. The only algorithm used in context-modeling is linear UCB. In the model, linear UCB is implemented with three different β value in Eq.( <ref type="formula" coords="9,456.62,656.12,4.33,8.74" target="#formula_1">1</ref>): 1, 0.5 and 0.2, and two context: Domain and User-Domain Impressions. In Table <ref type="table" coords="10,134.77,362.03,4.98,8.74" target="#tab_1">2</ref> and Table <ref type="table" coords="10,188.84,362.03,3.87,8.74" target="#tab_2">3</ref>, d stands for the context Domain. In Table <ref type="table" coords="10,385.75,362.03,3.87,8.74" target="#tab_2">3</ref>, di indicates the use of both contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">NewsREEL Live</head><p>The online evaluation of NewsREEL Live is from 24 April to 7 May 2017. The Open Recommendation Platform (ORP) is responsible for redirecting the traffic from the publishers and monitoring different recommender algorithms' performance. With ORP, participants are able to deploy their recommender services and receive recommendation requests. The low volume of data refers to the small number of recommendation requests, user clicks and user impressions, redirected to our recommender from plista. Comparing with the data stream in the Replay dataset, the data stream redirected in the Live task consists only a small portion of the whole plista data stream and is not enough to support training or updating of our contextual bandit algorithm. In the Live task, we deployed the best delegation recommender model trained from the NewsREEL Replay, referring to linucb 0.2 di b3 in Table <ref type="table" coords="10,258.74,560.48,3.87,8.74" target="#tab_2">3</ref>, to serve the incoming recommendation requests.</p><p>In addition, a portion of data from the Live task comes from a domain that is not included in the Replay dataset. This also gives rise to a challenge for us. Our solution is that for all the recommendation requests from that domain, we redirect them to the PRCate recommender. Table <ref type="table" coords="10,362.20,608.30,4.98,8.74" target="#tab_3">4</ref> shows our online evaluation results. There are two types of impressions created by ORP. The first type considers the impressions from the recommendation list, which are referred to as 'widget impressions', and the second type considers the impressions from individual items, which are referred to as 'item impressions'. ORP also creates a 'click' for each click on the recommended articles from users. The final metric for the recommender performance is measured by the CTR, which equals to the number of clicks divided by the number of impressions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">NewsREEL Replay</head><p>The NewsREEL Replay evaluation results are summarized in Table <ref type="table" coords="11,436.34,309.26,3.87,8.74" target="#tab_0">1</ref>, Table <ref type="table" coords="11,475.61,309.26,4.98,8.74" target="#tab_1">2</ref> and Table <ref type="table" coords="11,182.49,321.22,3.87,8.74" target="#tab_2">3</ref>. Table <ref type="table" coords="11,221.92,321.22,4.98,8.74" target="#tab_0">1</ref> shows the recommendation performance of the five basic recommenders from which the delegation model is able to choose an appropriate recommender. A random algorithm, which randomly selects a recommender for the incoming recommendation requests, is served as the baseline. Table <ref type="table" coords="11,447.18,357.09,4.98,8.74" target="#tab_1">2</ref> shows the evaluation results from the contextual bandit delegation model in which a MAB model is set up for each context. Table <ref type="table" coords="11,345.44,381.00,4.98,8.74" target="#tab_2">3</ref> shows the evaluation results from the contextual bandit delegation model in which the linear UCB model is implemented. The only context in Table <ref type="table" coords="11,326.67,404.91,4.98,8.74" target="#tab_1">2</ref> is Domain, while in Table <ref type="table" coords="11,453.54,404.91,3.87,8.74" target="#tab_2">3</ref>, two contexts Domain and User-Domain Impressions are considered. From both Table <ref type="table" coords="11,151.05,428.82,4.98,8.74" target="#tab_1">2</ref> and Table <ref type="table" coords="11,206.82,428.82,3.87,8.74" target="#tab_2">3</ref>, we can see the evaluation results from the delegation model outperform the random baseline. This indicates the delegation model is able to learn from the past and chooses appropriate recommender for the incoming recommendation requests in order to maximize the CTR.</p><p>To further explain the results, we first describe two facts with respect to the domain '35774': Firstly, as explained in the previous section, about 70% of the traffic is from this domain. Therefore, a CTR increase in domain '35774' leads to an increase of average CTR. Secondly, as shown in Table <ref type="table" coords="11,434.46,512.66,3.87,8.74" target="#tab_0">1</ref>, the recommender Recent performs much better than any other recommender in this domain. For the performance of different MAB algorithms, UCB1 works better than epsilon-greedy in domain '35774', but worse in domain '418' and domain '1677'. This result is a little bit unexpected since UCB1 explores under the guidance of a confidence bound <ref type="bibr" coords="11,253.47,572.43,14.61,8.74" target="#b9">[10]</ref>, while epsilon-greedy explores randomly without any guidance. The reason might be the parameter that is used to balance the exploration and exploitation is fixed in UCB1. In the future, we will try UCB with other value of the parameter. Thompson Sampling also works well in the evaluation, and in domain '1677' it shows the best performance. For domain '35774', further exploration does not benefit the CTR since the Recent recommender always performs best in the domain. The exploration leads to a CTR decrease in domain '35774' but CTR increases in domain '418' and domain '1677'. For epsilon-greedy, smaller value shows better results. From the side of epsilongreedy, exploring too much is also not a good idea. The fixed parameter is served to balance the exploration and exploitation. In Table <ref type="table" coords="12,407.31,142.90,3.87,8.74" target="#tab_2">3</ref>, in addition to the context Domain, another context User-domain Impressions, which measures the number of interactions the user has with the domain, is also taken into consideration. The results in Table <ref type="table" coords="12,269.60,178.77,4.98,8.74" target="#tab_2">3</ref> are in general better than the results from Table <ref type="table" coords="12,134.77,190.72,3.87,8.74" target="#tab_1">2</ref>. The contextual bandit delegation model based on linear UCB works better than the one in which there is a MAB model for each context. In addition, the context User-domain Impression is a useful context concerning CTR. Average CTR from the delegation model based on the linucb 0.2 di b3 algorithm even outperforms the Recent Recommender in Table <ref type="table" coords="12,348.05,238.55,3.87,8.74" target="#tab_0">1</ref>. One interesting observation is that CTR does not increase in domain '35774' and '1677' indicating that the exploration is less useful, but it does increase in domain '418', in which exploration is much more useful. This is due to some recommender algorithms always achieving the best performance in some domains (e.g., Recent recommender in domain '35774'), making exploration is unnecessary. The findings also indicate the performance of a single recommender algorithm appears to depend on the publishers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">NewsREEL Live</head><p>For NewsREEL Live we test our recommender for 14 days. There are two challenges in the Live task: Firstly, as discussed before, the low volume of data from the ORP to our account makes it hard for us to train the contextual bandit algorithm online. A delegation model trained from the Replay task is deployed to serve the incoming recommendation requests. Secondly, publishers in the Live task are different from the publishers in the Replay task. In NewsREEL Live, a portion of requests comes from domain '17614', which is not included in the Replay dataset. As the result, the corresponding requests from that domain are delegated to the PRCate recommender. The two challenges might lower our recommendation performance in the Live task. In total 19 teams which participate in NewsREEL Live, our delegation model ranked 10th.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Conclusion and Future Work</head><p>In conclusion, our results have verified our assumption the contextual bandit algorithm is able to select the appropriate recommender algorithm given the context. However, the balance between exploration and exploitation is important. If one particular recommender algorithm is performing significantly better, then exploitation does not necessarily help. For future work, firstly, we will add more recommender algorithms to our recommender algorithm pool, such as collaborative filtering since the performance of the contextual bandit algorithm is to some extent limited by the single recommender algorithm. Secondly, we will explore more contexts in order to further improve the recommendation CTR. Last but not least, we would like to evaluate the contextual bandit algorithm on a dataset with a more equally distributed traffic among different domains.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,140.99,522.50,339.60,8.77;4,151.70,534.49,62.32,8.74;4,214.02,532.91,3.97,6.12;4,221.81,534.49,49.07,8.74;4,140.99,546.02,339.60,8.77;4,151.70,558.01,140.39,8.74;4,140.99,569.55,339.60,8.77;4,151.70,581.53,328.89,8.74;4,151.70,593.49,328.89,8.74;4,151.70,605.44,86.92,8.74"><head>-</head><label></label><figDesc>Click : Similar to the algorithm Path, but the popularity algorithm considers only the clicks 4 of the user. -Imp: Similar to the algorithm Path, but the popularity algorithm considers only the impressions from users. -PRCate: Popularity and category based Recommender. Recommend the news article with most impressions and clicks within a certain category. The popularity scores only consider 100 most recently requested news articles within the category.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,192.04,229.33,231.28,7.89;6,134.77,115.83,345.84,98.72"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustration of updates and the end of each batch.</figDesc><graphic coords="6,134.77,115.83,345.84,98.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,250.91,166.81,229.68,8.74;7,134.77,178.77,345.82,8.74;7,134.77,190.72,345.82,8.74;7,134.77,202.68,345.82,8.74;7,134.77,214.64,345.83,8.74;7,134.77,226.59,345.83,8.74;7,134.77,238.55,23.25,8.74"><head></head><label></label><figDesc>context modeling, the categorical context features are encoded by one-hot coding. The context Domain is already a categorical feature by itself. For the context User-Domain Impressions, we implement some transformation. Specifically, we classifies the number of User-Domain Impressions into three groups: 0 ≤ number of User-Domain Impressions &lt; 5, 5 ≤ number of User-Domain Impressions &lt; 10 and 10 ≤ number of User-Domain Impressions &lt; 15.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,162.42,434.08,290.52,7.89;7,194.29,268.13,226.77,151.18"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Recommender Algorithms Performance w.r.t. Different Domains</figDesc><graphic coords="7,194.29,268.13,226.77,151.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="8,134.77,281.79,345.83,7.89;8,134.77,292.77,46.07,7.86;8,194.29,115.84,226.77,151.18"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Recommender Algorithms Performance w.r.t. User-Domain Impressions in Domain "418"</figDesc><graphic coords="8,194.29,115.84,226.77,151.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="8,134.77,513.61,345.83,147.36"><head>Table 1 .</head><label>1</label><figDesc>, NewsREEL Replay Evaluation Results: Single Recommender Algorithm Baselines</figDesc><table coords="8,152.83,584.67,308.96,76.31"><row><cell cols="5">Algorithm Average CTR Domain '418' Domain '1677' Domain '35774'</cell></row><row><cell>Random</cell><cell>0.645 (0%)</cell><cell>0.187 (0%)</cell><cell>0.401 (0%)</cell><cell>0.749 (0%)</cell></row><row><cell>Path</cell><cell cols="4">0.632 (-2.02%) 0.137 (-26.74%) 0.357 (-10.97%) 0.748 (-0.13%)</cell></row><row><cell>Recent</cell><cell cols="4">1.213 (88.06%) 0.224 (19.79%) 0.478 (19.20%) 1.487 (98.53%)</cell></row><row><cell>Click</cell><cell cols="4">0.256 (-60.31%) 0.264 (41.18%) 0.419 (4.49%) 0.220 (-70.63%)</cell></row><row><cell>Imp</cell><cell cols="4">0.618 (-4.19%) 0.114 (-39.04%) 0.330 (-17.71%) 0.738 (-1.74%)</cell></row><row><cell>PRCate</cell><cell cols="4">0.064 (-90.08%) 0.159 (-14.97%) 0.294 (-26.68%) 0.03 (-99.60%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,145.52,211.27,325.70,193.99"><head>Table 2 .</head><label>2</label><figDesc>NewsREEL Replay Evaluation Results: Context Pre-filtering (48.53%) 0.232 (24.06%) 0.449 (11.97%) 1.151 (53.67%) epsilon 0.3 b1 1.060 (64.34%) 0.249 (33.16%) 0.458 (14.21%) 1.283 (71.30%) epsilon 0.1 b1 1.160 (79.84%) 0.266 (42.25%) 0.456 (13.72%) 1.415 (88.92%)</figDesc><table coords="9,145.52,235.80,322.91,121.94"><row><cell>Algorithm</cell><cell>Average CTR</cell><cell>CTR '418'</cell><cell>CTR '1677'</cell><cell>CTR '35774'</cell></row><row><cell>random</cell><cell>0.645 (0%)</cell><cell>0.187 (0%)</cell><cell>0.401 (0%)</cell><cell>0.749 (0%)</cell></row><row><cell cols="3">epsilon 0.5 b3 0.954 (47.91%) 0.239 (27.81%)</cell><cell>0.437 (8.98%)</cell><cell>1.148 (53.27%)</cell></row><row><cell cols="5">epsilon 0.3 b3 1.070 (65.89%) 0.252 (34.75%) 0.468 (16.71%) 1.294 (72.76%)</cell></row><row><cell cols="5">epsilon 0.1 b3 1.163 (80.31%) 0.235 (25.67%) 0.456 (13.72%) 1.423 (89.99%)</cell></row><row><cell>ucb1 b3</cell><cell>1.197 (85.58%)</cell><cell>0.200 (6.95%)</cell><cell>0.420 (4.74%)</cell><cell>1.474 (96.80%)</cell></row><row><cell>ts b3</cell><cell cols="4">1.213 (88.06%) 0.224 (19.79%) 0.480 (19.70%) 1.486 (98.40%)</cell></row><row><cell cols="2">epsilon 0.5 b1 0.958 ucb1 b1 1.195 (85.27%)</cell><cell>0.199 (6.42%)</cell><cell>0.405 (1.00%)</cell><cell>1.475 (96.93%)</cell></row></table><note coords="9,151.50,362.75,3.65,5.24;9,157.95,364.52,313.27,7.86;9,157.95,375.48,313.28,7.86;9,157.95,386.44,313.28,7.86;9,157.95,397.40,45.10,7.86"><p><p>1 </p>Algorithm labels: epsilon 0.5 b3: epsilon greedy with = 0.5 with context Domain and batch size 300000, ucb1 b3: UCB1 with context Domain and batch size 300000, ts b3: Thompson Sampling with context Domain and batch size 300000</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,143.82,117.36,329.12,205.85"><head>Table 3 .</head><label>3</label><figDesc>NewsREEL Replay Evaluation Results: Context-Modeling .206 (86.98%) 0.279 (49.20%) 0.415 (3.49%) 1.485 (98.26%) linucb 0.2 di b3 1.214 (88.22%) 0.268 (43.32%) 0.467 (16.46%) 1.485 (98.26%) linucb 1 d b1 0.992 (53.80%) 0.244 (30.48%) 0.452 (12.72%) 1.180 (57.54%) linucb 0.5 d b1 1.205 (86.82%) 0.231 (23.53%) 0.457 (13.97%) 1.478 (97.33%) linucb 0.2 d b1 1.196 (85.43%) 0.263 (40.64%) 0.393 (-2.00%) 1.478 (97.33%) linucb 1 di b1 1.196 (85.43%) 0.253 (25.29%) 0.395 (-1.50%) 1.478 (97.33%) linucb 0.5 di b1 1.196 (85.43%) 0.207 (10.70%) 0.426 (6.23%) 1.477 (97.20%) linucb 0.2 di b1 1.197 (85.58%) 0.150 (-19.79%) 0.456 (13.72%) 1.479 (97.46%)</figDesc><table coords="10,143.82,141.89,326.33,64.90"><row><cell>Algorithm</cell><cell>Average CTR</cell><cell>CTR '418'</cell><cell>CTR '1677'</cell><cell>CTR '35774'</cell></row><row><cell>linucb 1 d b3</cell><cell cols="4">1.202 (86.36%) 0.220 (17.65%) 0.403 (0.50%) 1.483 (98.00%)</cell></row><row><cell cols="5">linucb 0.5 d b3 1.207 (87.13%) 0.246 (31.55%) 0.423 (5.49%) 1.483 (98.00%)</cell></row><row><cell cols="5">linucb 0.2 d b3 1.204 (86.67%) 0.257 (37.43%) 0.414 (3.24%) 1.484 (98.13%)</cell></row><row><cell>linucb 1 di b3</cell><cell cols="4">1.211 (87.75%) 0.259 (38.50%) 0.451 (12.47%) 1.485 (98.26%)</cell></row><row><cell cols="2">linucb 0.5 di b3 1</cell><cell></cell><cell></cell><cell></cell></row></table><note coords="10,149.79,291.66,3.65,5.24;10,156.24,293.42,316.69,7.86;10,156.24,304.38,316.69,7.86;10,156.24,315.34,196.78,7.86"><p>1 Algorithm annotation: linucb 1 d b3: LinUCB with β = 1 with context Domain and batch size 300000, linucb 1 di b3: LinUCB with β = 1 with context Domain, User-Domain Impressions and batch size 300000</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="11,134.77,116.41,345.83,62.83"><head>Table 4 .</head><label>4</label><figDesc>NewsREEL Live Evaluation Results from 24 April to 7 May 2017 (delegation model: linucb 0.2 di b3 trained from offline)</figDesc><table coords="11,205.01,148.67,205.34,30.58"><row><cell>Metric</cell><cell cols="3">Click Num Impression Num CTR</cell></row><row><cell>Widget</cell><cell>747</cell><cell>60814</cell><cell>0.012</cell></row><row><cell>Individual item</cell><cell>747</cell><cell>192207</cell><cell>0.0039</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="4,144.73,623.92,335.86,7.86"><p>The popularity is computed from the weighted combination of impressions and clicks.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="4,144.73,634.88,335.86,7.86;4,144.73,645.84,335.86,7.86;4,144.73,656.80,118.68,7.86"><p>A click is different from an impression: a click means the user clicks on the recommendation, while an impression means the user clicks on articles that were not necessarily recommended<ref type="bibr" coords="4,249.07,656.80,14.34,7.86" target="#b14">[15]</ref> </p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="13,142.96,142.15,337.64,7.86;13,151.52,153.11,329.08,7.86;13,151.52,164.07,224.41,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,229.69,153.11,250.90,7.86;13,151.52,164.07,31.13,7.86">Benchmarking news recommendations: The CLEF NewsREEL use case</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Brodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Seiler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kille</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lommatzsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Turrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Serény</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,204.61,164.07,77.69,7.86">ACM SIGIR Forum</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,174.94,337.64,7.86;13,152.80,183.63,327.79,10.13;13,151.52,196.86,329.07,7.86;13,151.52,207.82,49.66,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,213.65,185.90,266.94,7.86;13,151.52,196.86,131.93,7.86">CLEF 2017 NewsREEL overview: A stream-based recommender task for evaluation and education</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lommatzsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kille</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Brodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Seiler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ö</forename><surname>Özgöbek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,304.80,196.86,105.10,7.86">Proceedings of CLEF 2017</title>
		<meeting>CLEF 2017<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,218.69,337.64,7.86;13,151.52,229.65,329.07,7.86;13,151.52,240.60,329.07,7.86;13,151.52,251.56,329.07,7.86;13,151.52,262.52,145.62,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,369.61,229.65,110.98,7.86;13,151.52,240.60,310.10,7.86">Overview of NewsREEL&apos;16: Multi-dimensional evaluation of real-time stream-recommendation algorithms</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kille</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lommatzsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">G</forename><surname>Gebremeskel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Seiler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Malagoli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Serény</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Brodt</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Vries</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,151.52,251.56,329.07,7.86;13,151.52,262.52,40.25,7.86">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="311" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,273.39,337.63,7.86;13,151.52,284.35,329.07,7.86;13,151.52,295.31,329.07,7.86;13,151.52,306.27,32.25,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,151.52,284.35,209.08,7.86">Benchmarking news recommendations in a living lab</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kille</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lommatzsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Plumbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Brodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Heintz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,381.38,284.35,99.21,7.86;13,151.52,295.31,260.40,7.86">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="250" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,317.14,337.64,7.86;13,151.52,328.10,329.07,7.86;13,151.52,339.06,329.07,7.86;13,151.52,350.02,201.60,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,220.75,328.10,259.85,7.86;13,151.52,339.06,33.97,7.86">Stream-based recommendations: Online and offline evaluation as a service</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kille</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lommatzsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Turrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Serény</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Brodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Seiler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hopfgartner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,209.20,339.06,271.39,7.86;13,151.52,350.02,96.22,7.86">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="497" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,360.89,337.64,7.86;13,151.52,371.85,329.07,7.86;13,151.52,382.81,70.14,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,278.34,360.89,198.08,7.86">Real-time recommendations for user-item streams</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lommatzsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Albayrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,164.68,371.85,287.24,7.86">Proceedings of the 30th Annual ACM Symposium on Applied Computing</title>
		<meeting>the 30th Annual ACM Symposium on Applied Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1039" to="1046" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,393.68,295.02,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,195.93,393.68,172.04,7.86">Bandit algorithms for website optimization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,376.15,393.68,33.15,7.86">O&apos;Reilly</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,404.55,337.63,7.86;13,151.52,415.51,329.07,7.86;13,151.52,426.47,316.46,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,341.90,404.55,138.69,7.86;13,151.52,415.51,73.28,7.86">Automatic ad format selection via contextual bandits</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Rosales</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Agarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,246.90,415.51,233.69,7.86;13,151.52,426.47,213.55,7.86">Proceedings of the 22nd ACM international conference on Conference on information &amp; knowledge management</title>
		<meeting>the 22nd ACM international conference on Conference on information &amp; knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1587" to="1594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,437.34,337.63,7.86;13,151.52,448.30,329.07,7.86;13,151.52,459.26,329.07,7.86;13,151.52,470.22,76.53,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,366.10,437.34,114.49,7.86;13,151.52,448.30,212.96,7.86">Exploitation and exploration in a performance based contextual advertising system</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,386.11,448.30,94.48,7.86;13,151.52,459.26,324.76,7.86">Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 16th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="27" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,481.09,337.98,7.86;13,151.52,492.05,329.07,7.86;13,151.52,503.00,218.92,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,332.24,481.09,148.35,7.86;13,151.52,492.05,155.19,7.86">A contextual-bandit approach to personalized news article recommendation</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,330.05,492.05,150.54,7.86;13,151.52,503.00,124.97,7.86">Proceedings of the 19th international conference on World Wide Web</title>
		<meeting>the 19th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="661" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,513.88,337.98,7.86;13,151.52,524.83,302.77,7.86" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Burtini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Loeppky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Lawrence</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.00757</idno>
		<title level="m" coord="13,311.65,513.88,168.95,7.86;13,151.52,524.83,135.55,7.86">A survey of online experiment design with the stochastic multi-armed bandit</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="13,142.61,535.71,337.98,7.86;13,151.52,546.64,235.02,7.89" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,321.10,535.71,159.49,7.86;13,151.52,546.66,60.11,7.86">Finite-time analysis of the multiarmed bandit problem</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,220.14,546.66,69.14,7.86">Machine learning</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="235" to="256" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,557.54,337.97,7.86;13,151.52,568.49,240.19,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,234.27,557.54,187.22,7.86">An empirical evaluation of Thompson sampling</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,442.65,557.54,37.94,7.86;13,151.52,568.49,162.77,7.86">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page" from="2249" to="2257" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,579.37,337.97,7.86;13,151.52,590.32,131.71,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,245.17,579.37,235.42,7.86;13,151.52,590.32,30.93,7.86">Analysis of Thompson sampling for the multi-armed bandit problem</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,205.03,590.32,28.03,7.86">COLT</title>
		<imprint>
			<biblScope unit="page" from="39" to="40" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,601.20,337.97,7.86;13,151.52,612.16,329.07,7.86;13,151.52,623.11,329.07,7.86;13,152.35,631.81,328.24,10.13;13,151.52,645.03,147.77,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="13,298.66,601.20,181.93,7.86;13,151.52,612.16,75.22,7.86">Clicks pattern analysis for online news recommendation systems</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lommatzsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kille</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="13,151.52,623.11,324.67,7.86">Working Notes of CLEF 2016 -Conference and Labs of the Evaluation forum</title>
		<title level="s" coord="13,372.69,634.07,107.91,7.86;13,151.52,645.03,14.03,7.86">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<meeting><address><addrLine>Évora, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-09-08">5-8 September, 2016. 2016</date>
			<biblScope unit="volume">1609</biblScope>
			<biblScope unit="page" from="679" to="690" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
