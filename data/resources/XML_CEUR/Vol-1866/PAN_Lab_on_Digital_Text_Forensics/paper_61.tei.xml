<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,258.33,133.83,167.97,12.90;1,223.43,153.68,168.50,10.75">&apos;17: Author Profiling task Notebook for PAN at CLEF 2017</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,198.12,190.08,68.76,8.64"><forename type="first">Guillaume</forename><surname>Kheng</surname></persName>
							<email>guillaume.kheng@gmail.com</email>
						</author>
						<author>
							<persName coords="1,274.21,190.08,46.71,8.64"><forename type="first">Léa</forename><surname>Laporte</surname></persName>
							<email>lea.laporte@insa-lyon.fr</email>
						</author>
						<author>
							<persName coords="1,344.48,190.08,72.76,8.64"><forename type="first">Michael</forename><surname>Granitzer</surname></persName>
							<email>michael.granitzer@uni-passau.de</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">CLEF</orgName>
								<orgName type="institution">INSA LYON and UNI PASSAU&apos;s participation at PAN</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Institut National des Sciences Appliquées Lyon</orgName>
								<orgName type="institution">Universität Passau</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,258.33,133.83,167.97,12.90;1,223.43,153.68,168.50,10.75">&apos;17: Author Profiling task Notebook for PAN at CLEF 2017</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">70C22A981745049540FBB79E7D9AAE67</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of INSA Lyon and UNI Passau at the PAN 2017 Author Profiling task. Given the language and tweets from an author, the goal is to predict his/her gender and language variety. We consider two strategies : a "loose" classification that learns one predictive model for the gender and another one for the variety, and a "successive" classification that first predict the gender then learn a predictive model for variety, given the gender. We consider all the languages. We experiment various features representations and machine learning algorithms used in previous PAN Author Profiling editions in order to learn the models. We adapt the features and machine learning algorithm used for each language and each classification task by selecting the configuration that provides the best results in terms of prediction performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Thanks to the expansion of social networks and the progress of Internet and the related technologies, social media are now part of our daily life. A large amount of content, especially textual content, is thus produced and read every day, but without any certitude about the real identity of the author. Indeed, on the internet, people can easily hide their identity, even lie about it or usurp someone else's. One may want to know who authored a given content, or simply profile the content author in order to know to know more about him/her. Author Profiling (AP) is a text forensics field which try to tackle this latest issue. AP studies aim at retrieving some characteristics of an author (e.g. his/her age, gender, personality, etc) by analyzing only the texts he/she writes. Multiple applications of Author Profiling exist in various fields <ref type="bibr" coords="1,394.81,536.89,10.58,8.64" target="#b8">[9]</ref>. Indeed AP could help investigators profile criminals and use written content as evidence (forensics) or prevent malicious behavior on social network by profiling criminals (security). On the other hand, profiling the users of a product for a company could improve its consumer segmentation and yield a more accurate advertising campaign (marketing).</p><p>The CLEF PAN track have been offering an Author Profiling task for the last 5 years <ref type="bibr" coords="1,134.77,620.57,10.58,8.64" target="#b5">[6]</ref>. The task settings differ each year in terms of text genres, languages and author's characteristics. A summary of the previous AP editions' settings is provided in Table <ref type="table" coords="1,473.11,632.53,3.74,8.64" target="#tab_0">1</ref>. As shown in this table, the aim of the 2017 PAN Author Profiling task is to retrieve the gender of the author and his/her language variety i.e. the "specific variation of his/her language", due to the geographical location he/she comes from. Gender and language variety predictions can be considered as two subtasks of the PAN 2017 Author Profiling Task. Participants are given the choice to participate to the both subtasks or only one of them. Furthermore, they can consider all languages or only a subset. In our approach, we choose to participate to the both subtasks, for all the languages. One core aspect of our approach was to analyse the impact of different combinations of feature representation techniques and classification algorithms in terms of classification accuracy. We implemented various features extraction techniques such as n-grams, TF-IDF and LSA, and various machine learning algorithms, including Support Vector Machines, Naïves bayes and Random Forests. We also wanted to study the dependency between gender and variety. To do so we performed a "gender then variety" successive classification and compare it to a loose classification. Successive classification starts by predicting the gender only, then uses the results of this classification to predict the language variety. On the other hand, loose classification predicts the gender and variety labels independently. This paper is structured as follows. In section 2, we present our proposed approach. In section 3, we detail the experimental protocol and settings. Section 4 present the the results. In section 5, we discusses the perspectives and conclude this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Overview of our proposed approach</head><p>Our approach consists in 3 main steps: preprocessing, feature extraction and learning using a machine learning algorithm. In a first part, we present the preprocessing step. Then we introduce the different features we consider in order to achieve the best classification possible. Finally, we detail the learning step, including the machine learning algorithm we used in the context of the task and the successive learning strategy that we tried.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preprocessing</head><p>Several approaches have been proposed in the literature in order to process tweets for further information extraction <ref type="bibr" coords="3,255.50,192.46,10.58,8.64" target="#b6">[7]</ref>. Based on an analysis of previous PAN Author profiling editions, we choose to consider the following preprocesses:</p><p>Removal of short tweets: we remove all tweets with letter count below 10 characters (special characters included) Removal of the @user: On Twitter, '@' are used to adress twitter users. When a user start a discussion with another '@user', this specific Twitter id will appear multiple times, which might cause over-fitting, so we remove it. Removal of URLs: URLs might be too user-specific (causing over-fitting) and they might enrich the vocabulary too much for a poor gain in information as they are likely to occur only once. Lowercase of #hashtags' body: People might use the same hash-tag with different repartition of the upper/lowercase letters. For instance, without this technique, #Au-thorProfilingRocks and #authorProfilingROCKS supposedly mean the same but will end up as different "words". Removal of stop words: we made optional the removal of stop words as tweets are really short messages and some of the stop words might carry more meaning than in a longer text.</p><p>The corpus we obtain after the preprocessing step is described in table <ref type="table" coords="3,436.88,410.70,3.74,8.64" target="#tab_1">2</ref>. One can also notice that the number of tweets removed never amounts to more than 2% of each language sub-corpus. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Features Extraction</head><p>Once the corpus has been preprocessed, we extract features from the corpus and use them to represent the tweets. Most of the representations we considered have been used by the winners of the previous PAN AP tasks editions <ref type="bibr" coords="3,351.10,620.57,10.89,8.64" target="#b7">[8,</ref><ref type="bibr" coords="3,362.00,620.57,7.26,8.64" target="#b6">7,</ref><ref type="bibr" coords="3,369.26,620.57,7.26,8.64" target="#b8">9]</ref>. We consider there representation of tweets based on n-grams, TD-IDF and LSA. We also planned to consider stylometric features, but we finally do not implement them for technical reasons.</p><p>N-grams models. These models consists in establishing a vocabulary for the documents based on sequences of n items (characters, words, associations of words (for n &gt; 1), POS tags) extracted from text. Then, the features are the frequencies of the n-grams in the vocabulary. N-gram-based features have proven to be highly useful indicators of various linguistic differences between authors <ref type="bibr" coords="4,319.92,167.13,15.27,8.64" target="#b12">[13]</ref>. We implemented features with unigrams, bigrams and trigrams at the word level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TF-IDF. Text Frequency-Inverse Document Frequency (TF-IDF) is a well-established technique in Information</head><p>Retrieval. TF-IDF computes the apparition scores of each word by highlighting those appearing a lot in few documents which helps the learning algorithm selecting words with high discriminative power between labels. This approach have been widely used for the Author Profiling task.</p><p>Latent Semantic Analysis (LSA). LSA allows to capture semantic relations between groups of words as described in <ref type="bibr" coords="4,291.52,286.69,10.58,8.64" target="#b4">[5]</ref>. It produces a set of concepts linking words to documents and by extensions to profiles. LSA also proceeds into a dimensionality reduction which in our specific case is quite useful given the potential huge size of the vocabulary. The features provided by this technique allow us to train classifiers with deeper understanding of the tweets content. In 2015, the PAN AP task winners <ref type="bibr" coords="4,468.97,334.51,11.62,8.64" target="#b6">[7]</ref> yielded the top results with this approach.</p><p>Stylometry. We planned to consider features related to the Natural Language Processing field, including Part-Of-Speech features and Stylometric features (average word count per sentence, average number of letters per word, etc), that have been shown to perform well for this task <ref type="bibr" coords="4,240.77,406.24,10.58,8.64" target="#b3">[4]</ref>. Those features can be taken alone or unified with other types of features in order to carry more information and potentially achieve a better classification. Unfortunately, given the time constraint and some technical issues, we haven't been able to implement them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Machine learning algorithms</head><p>Our goal was to reproduce the state of the art approaches from the previous editions of PAN, more precisely, the classification techniques they considered. According to the PAN overviews [PAN16,15,14], SVM, Naive Bayes classifier and Random Forest are the most common learning techniques used in the context of the PAN AP task. Fortunately, they are also the ones achieving the best results on the AP task. We chose to implement these 3 classifiers, ie. Support Vector Machines, Naive Bayes classifer and Random Forest, in order to compare their respective results and pick the best one. As they are well-known machine learning algorithms [12,10,2], we do not describe them in details in this paper. In the case of SVM and Naives Bayes Classifier, we only indicate which variants we used.</p><p>For the Naives Bayes classifier, as the official sklearn documentation suggest that the "Multinomial" Naive Bayes classifier (MNBC) works well with TF-IDF, we chose to implement this variant. This method is the fastest in terms of training and classifying on the provided data, so we used it in order to achieve a stable basis for our software at the early stage of development.</p><p>Regarding SVM, we tested the kernel and linear approaches. However, the linear mode kept yielding significantly better results than the kernel one during the evaluating and comparing phases. As a consequence, we only use binary linear SVM to predict the gender and multiclass SVM with "one-vs-rest" strategy to predict the language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Successive and loose classification</head><p>As mentioned in the introdcution, we wondered if Gender and Language variety were not linked in some way. Our assumption was that predicting one label and using the results of this classification in order to predict the second label may achieve good results. We chose to call this type of classification : "successive classification" as opposed to "loose classification" in which one classifies each label regardless of the others (thus predicting gender and variety are two independent subtasks). The protocol for each type of classification is as follows.</p><p>For loose classification, we consider the gender and variety prediction as two independent subtask and train the corresponding models separately. We thus train a classifier to predict gender (respectively variety) on the whole language corpus, then we use the learned model to predict gender (respectively variety) for each author within the test dataset.</p><p>For successive classification , in the context of the task, two strategies could be considered: first predict the gender, then predict the variety given the knowledge of the gender ("gender-then-variety" strategy); or, first predict the variety, then predict the gender given the variety ("variety-the-gender" strategy). In this work, we consider only the "gender-then-variety" strategy for successive classification. We did not consider the "variety then gender" successive classification because the number of tweets available for training would have been significantly reduced and would have likely induced overfitting resulting in poor classification rates. In order to achieve "gender then variety" successive classification for each language corpus we proceed as follow :</p><p>1. We train a classifier to predict gender on the whole language corpus. 2. We split each language corpus in 2 sub-corpus, based on the ground truth: one for the female authors and another for the male authors. 3. On each sub-corpus we train a classifier to predict variety. This provides us with a male-variety classifier and a female-variety classifier. 4. We classify each author contained within the test-dataset on gender first and sort predicted males predicted and females authors into 2 sub-test-dataset. 5. We classify each author contained within the sub-test-datasets with the associated variety classifier i.e. the female-variety classifier predicts the variety labels for the authors classified as female, idem for the males.</p><p>Figures <ref type="figure" coords="5,181.74,596.45,4.98,8.64">1</ref> and<ref type="figure" coords="5,205.39,596.45,4.98,8.64">2</ref> show the processing of the test dataset with the loose and successive classification procedures respectively.</p><p>To simplify the notations we will call "classification units" the classifiers used to predict gender or variety labels. On figures 1 and 2, one can notice that the number of classifying units for each type of classification is different. Indeed, the "gender then variety" successive classification needs 3 classification units per language (one for the gender, then two variety classifier depending on the gender), whereas the loose classification only needs 2 classification units (one per classification subtask). For each classification unit, we have implemented all the combinations of the sets of features described in section 2.2 and the learning algorithms selected in section 2.3. For each classification unit, we then select the best combination possible according to a given evaluation measure: the F-score which will be detailed in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Evaluation</head><p>In this section, we present the experimental evaluation and results we obtained in the context of the 2017 PAN Author Profiling task edition. First, we present briefly the software implementation. Second, we describe the experimental protocols we followed through the task in order to obtain reliable results. Then, we disclose the different classification units we selected for the loose and the successive classifications, along with the results obtained on the test set provided by the task chairs for each classification type. Finally, we present the results of our submitted final run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Software implementation</head><p>The software implementation relies on the Python 3 sklearn and NLTK modules.The classifiers and feature extraction tools we used were pre-implemented and documented in the sklearn module. NLTK offered some powerful tools regarding tweet-tokenisation and stop words removal. The source files are available on the following github repo : github.com/SunTasked/profiler</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Protocol</head><p>Regarding the training and evaluation of each classification unit, we respected a certain set of rules in order to achieve reliable results.</p><p>Training of classifiers. We tested and optimized all classifiers described in subsection 2.3 using different sets of features: unigrams and bigrams at word level, TF-IDF based on unigrams, bigrams and trigrams at word level, LSA, and a combination of LSA and TF-IDF on unigrams and bigrams at word level. By optimizing, we mean tuning the classifier and feature extractor parameters to achieve the best score possible given this configuration. In order to do so, we used the sklearn "gridsearch" tool which allow you to try different combinations of parameters in a multi-threaded context. In addition, We also tested some combinations of features with and without the stop words removal step. We wanted to detect if these textual element had an impact in the classification process. This represent roughly 24 models trained for each classification unit summing up to a total of 480 models trained, optimized and cross-validated using 10 folds of the training data.</p><p>Evaluation measures. We use the micro-averaged and macro-averaged f-measures as the evaluation measures, since we have a corpus with a balanced distribution over the different labels, as recommended by <ref type="bibr" coords="7,285.26,458.28,15.27,8.64" target="#b10">[11]</ref>. When comparing one approach to another, we consider the macro measure first and in case of conflicts, we then consider the micro measure. If two configurations lead to same performance in terms of evaluation measure, we use the features which consume less computation power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Selected best configurations for the classification units</head><p>Regarding the training of the classifiers, we based our approach on a "single tweet" classification. We trained each classifier on tweets as standalone documents i.e. disregarding the fact that each tweet belong to an author along with 99 other tweets. Then, when proceeding to labels predictions, we classified each of the 100 tweets available for each author separately. Consequently for each author, we obtained 100 labels predictions. In order to obtain the author labels, we summed up the labels predictions and chose the label with the highest score.</p><p>In this subsection, we start by presenting the selected models for the gender classification units, as those are the same for loose classification and successive classification. Then we present the selected models for the language variety classification units for the loose and the successive classification.</p><p>Gender classification. As shown in table <ref type="table" coords="8,306.92,119.31,3.74,8.64" target="#tab_2">3</ref>, in all languages the best models for gender classification have been obtained by combining TF-IDF features on unigrams and bigrams and a Naive Bayes Classifier (NBC). Surprisingly, the classification over Latin languages seemed to work better when the stop-words were not being removed. Variety classification. Table <ref type="table" coords="8,256.87,318.21,4.98,8.64" target="#tab_3">4</ref> describes the best approaches selected for loose variety classification while table 5 describes the best approaches for "gender then variety" successive classification. We observe that the loose classification units for variety prediction yield better overall accuracy scores than the corresponding successive classification units. The English and Spanish classifiers are particularly affected by the division of the Corpus. The halving of the corpus on gender implied a shrinking of the extracted features set. Consequently, classifying units might have less features to discriminate the tweets on and offer poor prediction performances. On the other hand, the Arabic and Portuguese classifying units seem to yield quite equivalent scores in both loose and successive classification contexts. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">PAN'17 Results</head><p>In the context of the PAN'17 AP task, we decided to submit the loose classification approach. Indeed, as we saw in the experimental results section, the loose classification approach yields the best overall results in terms of variety prediction accuracy. It is particularly noticeable when we consider English and Spanish variety prediction. Moreover one of the main issues regarding "gender then variety" successive classification is that one must achieve a high quality classification on gender. Unfortunately, the results  Although we don't have the results of the other participants yet, the results regarding gender classification are not as high as we expected when we consider the result achieved in the previous PAN editions <ref type="bibr" coords="9,288.72,525.96,10.79,8.64" target="#b7">[8,</ref><ref type="bibr" coords="9,299.51,525.96,7.19,8.64" target="#b6">7]</ref>. One could justify such gap by the fact that we are lacking some preprocessing steps (POS tags).</p><p>In the contrary the quality of the classifiers in terms of variety prediction in Portuguese and Spanish are quite high as they achieved respectively 97,5% and 91,68% of accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion and Perspectives</head><p>In this PAN edition we wanted to implement a Multi Layered Perceptron as learning algorithm and compare to the the other classification approaches. Indeed, the use of SVM as a learning algorithm in the PAN literature represents more than 50% of the approaches as opposed to Neural networks which are almost non-existent in that same context. However, according to <ref type="bibr" coords="10,260.04,131.27,10.58,8.64" target="#b2">[3]</ref>, using a MLP properly tuned can outperform a SVM in such task. Unfortunately, technical issues prevented us from realizing this comparison.</p><p>In addition, we would have liked to compare different types of aggregations for the tweets. In our approach, we used only a "single tweet" classification meaning each tweet was considered as a document. As a consequence, the classifier could never grasp the notion of an "author" as a collection of 100 tweets and might have missed some interesting features. One could try to concatenate one author tweets into a single chunk of text or to consider the whole tweet collections as a document.</p><p>As we saw in section 3 (Experimental Results), we observed poor results in terms of gender classification. In order to improve those results, one could make use of the doc2vec tool which would improve significantly our results according to <ref type="bibr" coords="10,430.85,263.60,10.58,8.64" target="#b0">[1]</ref>. Another way to better the prediction of gender would be to train convolutional neural networks to extract automatically features from the tweets as described in <ref type="bibr" coords="10,391.37,287.51,15.27,8.64" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper we have offered a description of our approach in the context of PAN Author Profiling task. Our main aim was to compare loose classification to successive classification. The first one predicts each author's feature independently whereas the latest makes uses of each label prediction to sample the dataset and predict the remaining author's features. We selected the best classification units by comparing the combination of multiple features extractors and multiple classifiers while following a strict experimental protocol. The predictions rates regarding gender constrained us to submit a software implementing the loose classification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,135.40,344.78,154.35,7.77;6,189.16,355.74,46.82,7.77;6,142.55,188.27,140.06,144.71"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Prediction work-flow of the loose classification</figDesc><graphic coords="6,142.55,188.27,140.06,144.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,201.63,199.72,222.95,63.36"><head>Table 1 :</head><label>1</label><figDesc>Evolution of PAN AP task settings 2013-2017</figDesc><table coords="2,201.63,222.04,222.95,41.05"><row><cell></cell><cell></cell><cell cols="3">2013 2014 2015 2016 2017</cell></row><row><cell></cell><cell>Blogs</cell><cell>X</cell><cell>X</cell><cell>X</cell></row><row><cell>Text Genre</cell><cell>Reviews Social Media</cell><cell></cell><cell>X X</cell><cell>X X</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,162.26,467.62,290.84,64.16"><head>Table 2 : Characteristics of the corpus before and after preprocessing</head><label>2</label><figDesc></figDesc><table coords="3,162.26,489.94,290.84,41.85"><row><cell>language</cell><cell cols="2">Arabic English Spanish Portuguese</cell></row><row><cell>number of tweets in the initial dataset</cell><cell cols="2">240,000 360,000 420,000 120,000</cell></row><row><cell cols="2">number of "empty" tweets (len &lt;10 chars) 4,219 1,555 1,910</cell><cell>1,895</cell></row><row><cell>number of tweets post processing</cell><cell cols="2">235,781 358,445 418,090 118,105</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,134.77,187.76,345.82,86.48"><head>Table 3 :</head><label>3</label><figDesc>Best configurations for Gender classification; for all languages. These configurations have been used for loose and successive classification.</figDesc><table coords="8,157.73,221.04,299.89,53.20"><row><cell cols="2">Language Preprocessing</cell><cell>Features</cell><cell>Classifier F macro F micro</cell></row><row><cell>Arabic</cell><cell cols="3">removal of stop words TF-IDF (1/2-grams) NBC</cell><cell>0.707 0.708</cell></row><row><cell>English</cell><cell cols="3">removal of stop words TF-IDF (1/2-grams) NBC</cell><cell>0.669 0.669</cell></row><row><cell>Spanish</cell><cell></cell><cell cols="2">TF-IDF (1/2-grams) NBC</cell><cell>0.659 0.661</cell></row><row><cell>Portuguese</cell><cell></cell><cell cols="2">TF-IDF (1/2-grams) NBC</cell><cell>0.659 0.663</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,150.70,456.33,313.95,75.52"><head>Table 4 :</head><label>4</label><figDesc>Best configurations for Variety loose classification unit, for all languages</figDesc><table coords="8,150.70,478.65,313.95,53.20"><row><cell cols="2">Language Preprocessing Features</cell><cell cols="2">Classifier F macro F micro</cell></row><row><cell>Arabic</cell><cell>TF-IDF (1/2-grams) &amp; LSA</cell><cell>SVM</cell><cell>0.684 0.684</cell></row><row><cell>English</cell><cell>rm stop words TF-IDF(1/2-grams)</cell><cell>SVM</cell><cell>0.669 0.669</cell></row><row><cell>Spanish</cell><cell>TF-IDF (1/2-grams) &amp; LSA</cell><cell>SVM</cell><cell>0.684 0.684</cell></row><row><cell>Portuguese</cell><cell cols="2">TF-IDF (uni-, bi-and tri-grams) SVM</cell><cell>0.879 0.879</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,134.77,117.67,345.82,167.59"><head>Table 5 :</head><label>5</label><figDesc>Best configurations for Variety successive classification units, for all language</figDesc><table coords="9,134.77,139.99,345.82,145.28"><row><cell cols="3">Gender Language Preprocessing Features</cell><cell cols="3">Classifier F macro F micro</cell></row><row><cell></cell><cell>Arabic</cell><cell cols="2">TF-IDF (1/2-grams) &amp; LSA SVM</cell><cell cols="2">0.673 0.674</cell></row><row><cell>Female</cell><cell>English Spanish</cell><cell cols="2">rm stop words TF-IDF (1/2-grams) TF-IDF (1/2-grams) &amp; LSA SVM SVM</cell><cell cols="2">0.466 0.467 0.518 0.52</cell></row><row><cell></cell><cell>Portuguese</cell><cell cols="2">TF-IDF (1/2-grams) &amp; LSA SVM</cell><cell>0.88</cell><cell>0.88</cell></row><row><cell></cell><cell>Arabic</cell><cell cols="2">TF-IDF (1/2-grams) &amp; LSA SVM</cell><cell cols="2">0.687 0.687</cell></row><row><cell>Male</cell><cell>English Spanish</cell><cell>rm stop words TF-IDF (1/2-grams) TF-IDF (1/2-grams)</cell><cell>NBB SVM</cell><cell cols="2">0.450 0.449 0.555 0.556</cell></row><row><cell></cell><cell>Portuguese</cell><cell>TF-IDF (1/2/3-grams)</cell><cell>SVM</cell><cell cols="2">0.859 0.859</cell></row><row><cell cols="6">we obtained on this particular label were not very promising. The official results we</cell></row><row><cell cols="3">obtained are exposed in table 6.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,198.11,310.31,219.14,163.19"><head>Table 6 :</head><label>6</label><figDesc>Official results for the PAN'17 Author Profiling task</figDesc><table coords="9,241.39,332.28,132.59,141.22"><row><cell cols="3">Language Feature Score obtained</cell></row><row><cell></cell><cell>Gender</cell><cell>0.6856</cell></row><row><cell>Arabic</cell><cell>Variety</cell><cell>0.7544</cell></row><row><cell></cell><cell>Joint</cell><cell>0.5475</cell></row><row><cell></cell><cell>Gender</cell><cell>0.7546</cell></row><row><cell>English</cell><cell>Variety</cell><cell>0.7588</cell></row><row><cell></cell><cell>Joint</cell><cell>0.5704</cell></row><row><cell></cell><cell>Gender</cell><cell>0.6968</cell></row><row><cell>Spanish</cell><cell>Variety</cell><cell>0.9168</cell></row><row><cell></cell><cell>Joint</cell><cell>0.6400</cell></row><row><cell></cell><cell>Gender</cell><cell>0.6638</cell></row><row><cell>Portuguese</cell><cell>Variety</cell><cell>0.9750</cell></row><row><cell></cell><cell>Joint</cell><cell>0.6475</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0" coords="2,274.64,266.27,25.18,7.77;2,349.01,266.27,69.84,7.77;2,279.76,277.63,14.94,7.77;2,327.89,277.63,69.84,7.77;2,274.03,288.59,26.39,7.77;2,327.89,288.59,90.96,7.77;2,255.48,299.55,63.49,7.77;2,412.37,299.55,6.47,7.77;2,190.78,294.07,61.51,7.77;2,264.81,310.51,44.83,7.77;2,370.13,310.51,6.47,7.77;2,275.03,321.87,24.40,7.77;2,412.37,321.87,6.47,7.77;2,276.27,332.83,21.91,7.77;2,370.13,332.83,27.59,7.77;2,273.52,343.78,27.40,7.77;2,327.89,343.78,90.96,7.77;2,275.77,354.74,22.91,7.77;2,370.13,354.74,6.47,7.77;2,267.30,365.70,39.85,7.77;2,412.37,365.70,6.47,7.77;2,202.12,349.26,38.84,7.77;2,273.03,376.66,28.40,7.77;2,327.89,376.66,90.96,7.77"><p>Tweets X X X X Age X X X X Gender X X X X X Language Variety X Authors Features Personnality X Arabic X Dutch X X English X X X X X Italian X Portuguese X Languages Spanish X X X X X</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.61,490.65,312.63,7.77;10,150.95,501.61,52.54,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,228.40,490.65,143.16,7.77">Gender classification with deep learning</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bartle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,377.31,490.65,77.93,7.77;10,150.95,501.61,26.40,7.77">Text-Interdisciplinary Journal</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,512.98,328.33,7.77;10,150.95,523.93,66.49,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,185.83,512.98,125.88,7.77">Analysis of a random forests model</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Biau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,318.06,512.98,139.44,7.77">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1063" to="1095" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,535.30,320.88,7.77;10,150.95,546.26,320.80,7.77;10,150.95,557.22,70.98,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,233.87,535.30,229.62,7.77;10,150.95,546.26,20.13,7.77">Using machine learning algorithms for author profiling in social media</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Dichiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Rancea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,189.55,546.26,278.17,7.77">Working Notes of CLEF 2016 -Conference and Labs of the Evaluation forum</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="858" to="863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,568.59,313.64,7.77;10,150.95,579.55,231.88,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,316.26,568.59,139.98,7.77;10,150.95,579.55,102.82,7.77">Author Profiling using Stylometric and Structural Feature Groupings</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Grivas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Giannakopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,272.23,579.55,84.45,7.77">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,590.92,308.69,7.77;10,150.95,601.88,163.60,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,295.40,590.92,152.45,7.77">An introduction to latent semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">W</forename><surname>Foltz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Laham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,150.95,601.88,72.46,7.77">Discourse processes</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="259" to="284" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,613.25,334.54,7.77;10,150.95,624.21,315.97,7.77;10,150.95,635.17,324.88,7.77;10,150.95,646.13,317.88,7.77;10,150.95,657.08,295.35,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,432.45,613.25,44.71,7.77;10,150.95,624.21,262.32,7.77">Overview of PAN&apos;17: Author Identification, Author Profiling, and Author Obfuscation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,150.95,646.13,317.88,7.77;10,150.95,657.08,162.70,7.77">Experimental IR Meets Multilinguality, Multimodality, and Interaction. 8th International Conference of the CLEF Initiative (CLEF 17)</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Lawless</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Kelly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Mandl</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<date>Sep.</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,119.96,333.99,7.77;11,150.95,130.92,318.07,7.77;11,150.95,141.88,284.53,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,404.50,119.96,72.10,7.77;11,150.95,130.92,115.01,7.77">Overview of the 3rd author profiling task at pan 2015</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Celli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,173.36,141.88,82.96,7.77">CLEF (Working Notes)</title>
		<title level="s" coord="11,262.30,141.88,107.26,7.77">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1391</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,152.84,337.98,7.77;11,150.95,163.80,298.77,7.77;11,150.95,174.76,270.81,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,150.95,163.80,217.50,7.77">others: Overview of the 2nd author profiling task at pan 2014</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Trenkmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daeleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="11,386.93,163.80,62.79,7.77;11,150.95,174.76,42.23,7.77;11,286.76,174.76,108.86,7.77">CEUR Workshop Proceedings</title>
		<imprint>
			<biblScope unit="volume">1180</biblScope>
			<biblScope unit="page" from="898" to="927" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct coords="11,142.61,185.71,328.85,7.77;11,150.95,196.67,290.11,7.77;11,150.95,207.63,322.06,7.77;11,150.95,218.59,108.15,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,426.76,185.71,44.71,7.77;11,150.95,196.67,235.25,7.77">Overview of the 4th author profiling task at PAN 2016: cross-genre evaluations</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,321.29,207.63,82.96,7.77">CLEF (Working Notes)</title>
		<title level="s" coord="11,410.23,207.63,62.79,7.77;11,150.95,218.59,42.23,7.77">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1609</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,229.55,317.83,7.77;11,150.95,240.51,303.19,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,181.84,229.55,169.91,7.77">An empirical study of the naive Bayes classifier</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Rish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,369.25,229.55,90.81,7.77;11,150.95,240.51,150.77,7.77">IJCAI 2001 workshop on empirical methods in artificial intelligence</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>IBM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="41" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,251.47,293.89,7.77;11,150.95,262.43,297.35,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,252.86,251.47,183.26,7.77;11,150.95,262.43,65.88,7.77">A systematic analysis of performance measures for classification tasks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sokolova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Lapalme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,222.43,262.43,142.20,7.77">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="427" to="437" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,273.39,322.72,7.77;11,150.95,284.34,104.33,7.77" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="11,259.20,273.39,89.26,7.77">Support Vector Machines</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Steinwart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Christmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer Publishing Company, Incorporated</publisher>
		</imprint>
	</monogr>
	<note>1st edn.</note>
</biblStruct>

<biblStruct coords="11,142.24,295.30,304.52,7.77;11,150.95,306.26,321.55,7.77;11,150.95,317.22,308.97,7.77;11,150.95,328.18,93.39,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,246.84,306.26,119.71,7.77">Gronup: Groningen user profiling</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">B O</forename><surname>Vollenbroek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Carlotto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kreutz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Medvedeva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Pool</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bjerva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Haagsma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Nissim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,384.31,306.26,88.19,7.77;11,150.95,317.22,187.74,7.77">Working Notes of CLEF 2016 -Conference and Labs of the Evaluation forum</title>
		<meeting><address><addrLine>Évora, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-09-08">5-8 September, 2016. 2016</date>
			<biblScope unit="page" from="846" to="857" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,339.14,298.36,7.77;11,150.95,350.10,295.14,7.77;11,150.95,361.06,293.11,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,271.57,339.14,169.03,7.77;11,150.95,350.10,45.79,7.77">Character-level convolutional networks for text classification</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,214.46,350.10,231.63,7.77;11,150.95,361.06,197.48,7.77">Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="649" to="657" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
