<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,160.10,148.88,286.55,15.96;1,211.37,169.36,172.60,12.00">UniNE at CLEF 2017: Author Clustering Notebook for PAN at CLEF 2017</title>
				<funder ref="#_QRARZp2">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,236.21,207.68,56.30,9.05"><forename type="first">Mirco</forename><surname>Kocher</surname></persName>
							<email>mirco.kocher@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Dept</orgName>
								<orgName type="institution">University of Neuchâtel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,311.98,207.68,58.58,9.05"><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
							<email>jacques.savoy@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Dept</orgName>
								<orgName type="institution">University of Neuchâtel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,160.10,148.88,286.55,15.96;1,211.37,169.36,172.60,12.00">UniNE at CLEF 2017: Author Clustering Notebook for PAN at CLEF 2017</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BD9F88B05CF05D36D4B58C990574B3D9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes and evaluates an effective unsupervised author clustering and authorship linking model called SPATIUM. The suggested strategy can be adapted without any difficulty to different languages (such as Dutch, English, and Greek) in different text genres (e.g., newspaper articles and reviews). As features, we suggest using the m most frequent terms (isolated words and punctuation symbols) or the m most frequent character n-grams of each text. Applying a simple distance measure, we determine whether there is enough indication that two texts were written by the same author. The evaluations are based on 60 training and 120 test problems (PAN AUTHOR CLUSTERING task at CLEF 2017). Using the most frequent terms results in a higher clustering precision, while using the most frequent character n-grams of letters gives a higher clustering recall. An analysis to assess the variability of the performance measures indicates that we have a system working stable independent of the underlying text collection and that our parameter choices did not over-fit to the training data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The authorship attribution problem is an interesting problem in computational linguistics but also in applied areas such as criminal investigation and historical studies where knowing the author of a document (such as a ransom note) may be able to save lives <ref type="bibr" coords="1,145.58,523.81,15.43,9.05" target="#b13">[14]</ref>. With the Web 2.0 technologies, the number of anonymous or pseudonymous texts is increasing and in many cases one person writes in different places about different topics (e.g., multiple blog posts written by the same author). Therefore, proposing an effective algorithm to the authorship problem presents a real interest. In this case, the system must regroup all texts by the same author (possibly written about different text topics) into the same group or cluster. A justification supporting the proposed answer and a probability that the given answer is correct can be given to improve the confidence attached to the response <ref type="bibr" coords="1,320.11,604.36,15.43,9.05" target="#b9">[10]</ref>.</p><p>This author clustering task is more demanding than the classical authorship attribution problem. Given a document collection the task is to group documents written by the same author such that each cluster corresponds to a different author. The number of distinct authors whose documents are included is not given. For example, based on a set of passages extracted from larger documents, we should first determine the number of authors k and then regroup the texts into k clusters according to their real author. This task can also be viewed as establishing authorship links between texts and is related to the PAN 2015 task of authorship verification.</p><p>This paper is organized as follows. The next section presents the test collections and the evaluation methodology used in the experiments. The third section explains our proposed algorithm called SPATIUM. Then, we evaluate the proposed scheme on 60 training problems and compare it to the best performing schemes using 120 different test problems. The last section explains our parameter choices and provides a sensibility assessment. A conclusion draws the main findings of this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Test Collections and Evaluation Methodology</head><p>The evaluation was performed using the TIRA platform, which is an automated tool for deployment and evaluation of the software <ref type="bibr" coords="2,299.57,307.19,10.69,9.05" target="#b2">[3]</ref>. The data access is restricted such that during a software run the system is encapsulated and thus ensuring that there is no data leakage back to the task participants <ref type="bibr" coords="2,275.09,330.23,10.69,9.05" target="#b8">[9]</ref>. This evaluation procedure also offers a fair evaluation of the time needed to produce an answer.</p><p>During the PAN CLEF 2017 evaluation campaign, six corpora (or test collections) were built each containing 30 problems (10 for training and 20 for testing). In each problem, all the texts matched the same language, are in the same text genre, and are single-authored, but they may differ in text-length and can be cross-topic <ref type="bibr" coords="2,429.19,387.73,15.46,9.05" target="#b13">[14]</ref>. The number of distinct authors is not given. In this context, the task is defined as:</p><p>Given a problem of up to 50 short documents, identify authorship links and groups of documents by the same author. The six corpora are a combination of one of three languages (English, Dutch, or Greek) and one of two genres (newspaper articles or reviews). An overview of these corpora is depicted in Table <ref type="table" coords="2,206.93,456.73,3.77,9.05" target="#tab_0">1</ref>. Considering the six benchmarks we have 120 problems to test and 60 problems to train (pre-evaluate) our system. The training set was used to evaluate our approach and the test set was used to compare our results with other participants of the PAN CLEF 2017 campaign. This year, everyone had access to the test data twice. This means we can train and test a basic approach, improve it or provide a different approach, and then test it again for the second and final run.  These metrics are not available for the test corpora because the datasets remain undisclosed thanks to the TIRA system. We only know that the same combinations of language and genre are present.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corpus</head><p>In Table <ref type="table" coords="3,173.18,230.39,4.98,9.05" target="#tab_0">1</ref> we see that the number of words is rather small. In Figure <ref type="figure" coords="3,426.31,230.39,4.98,9.05" target="#fig_1">1</ref> we show three texts extracted from a problem containing articles written in the English language. The represented texts are the full unmodified documents as available in problem001. Notice that document0014 and document0017 are a single sentence, and the latter is so short that it would fit in a single Twitter tweet (it contains less than 140 characters). When analyzing the texts, we should detect a shared authorship between document0017 and document0018, but not with document0014 as this was written by someone else. The limited length of those documents is the main difficulty of this year's author clustering task.</p><p>When inspecting the training corpora, the number of words available is rather small (overall in mean 82 terms for each text). Since there are some authors who only wrote a single text we should only cluster two texts if there are enough evidences for a single authorship.</p><p>During the PAN CLEF 2017 campaign, a system must return two outputs in a JSON structure for each problem. First, the detected groups should be written to a file indicating the author clustering. Each text must belong to exactly one cluster; thus, the clusters must be non-overlapping. Second, a list of text pairs with a probability of having the same author should be written to another file representing the authorship links.</p><p>As performance measure, two evaluation measures were used during the PAN CLEF campaign. The first performance measure is the BCubed F1 to evaluate the clustering output <ref type="bibr" coords="3,153.38,640.24,10.69,9.05" target="#b0">[1]</ref>. This value is the harmonic mean of the precision and recall associated to each document. The document precision represents how many documents in the same cluster are written by the same author and therefore measures the purity of its cluster. Symmetrically, the recall associated to one document represents how many documents from that author appear in its cluster and therefore measures the completeness of its cluster.</p><p>As another measure, the PAN CLEF campaign adopts the mean average precision (MAP) measure for the authorship links between document pairs <ref type="bibr" coords="4,388.99,184.40,10.69,9.05" target="#b7">[8]</ref>. This evaluation measure provides a single-figure measure of quality across recall levels. The MAP is roughly the average area under the precision-recall curve for a set of problems. Therefore, this measure gives more emphasis on the first positions and a misclassification with a lower probability is less penalized. MAP does not punish verbosity, i.e., every true link counts even when appearing near the end of the ranked list. Therefore, by providing all possible authorship links, one can attempt to maximize MAP <ref type="bibr" coords="4,148.94,264.83,15.43,9.05" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Simple Clustering Algorithm</head><p>We suggest an unsupervised approach based on a simple feature extraction and distance measure called SPATIUM (Latin word meaning distance). The selected stylistic features correspond to the top m most frequent terms (isolated words without stemming but with the punctuation symbols) in the first run as in the last year <ref type="bibr" coords="4,365.59,364.67,11.72,9.05" target="#b4">[5]</ref> and additionally the m most frequent character n-grams for the second run. The features are selected solely based on the frequency in the query text. For determining the value of m, previous studies have shown that a value between 200 and 300 tends to provide the best performance <ref type="bibr" coords="4,177.14,410.65,10.89,9.05" target="#b1">[2,</ref><ref type="bibr" coords="4,189.98,410.65,11.97,9.05" target="#b9">10]</ref>. The texts were only paragraphs so the effective number of features m was set to at most 200 but was in most cases well below. The length of the n-grams was set to n=6 characters to ease the analysis of the most pertinent features. Unlike in the previous year <ref type="bibr" coords="4,202.61,445.21,10.69,9.05" target="#b4">[5]</ref>, we did not remove the words appearing only once (hapax legomenon) in the text due to the limited size of each document (see Table <ref type="table" coords="4,439.03,456.73,3.60,9.05" target="#tab_0">1</ref>). For instance, in document0017 depicted in Figure <ref type="figure" coords="4,316.61,468.13,4.98,9.05" target="#fig_1">1</ref> every term would be deleted if the hapax legomenon would be ignored.</p><p>To measure the distance between a Test A and another Text B, SPATIUM uses a variant of the L 1 -norm called Canberra. This distance suggests that the absolute differences of the individual features are normalized based on the sum of them as indicated in Equation <ref type="formula" coords="4,212.81,525.73,3.77,9.05">1</ref>. Observing a small value for ∆ 𝐴𝐵 provides evidence that both documents are written by the same author. On the other hand, a large value suggests the opposite. The real problem consists in defining precisely what a "small distance value" is. To verify whether the resulting ∆ 𝐴𝐵 value is small or rather large, a comparison basis must be determined.</p><formula xml:id="formula_0" coords="4,218.33,538.77,243.23,19.71">∆(𝐴, 𝐵) = ∆ 𝐴𝐵 = ∑ |𝑃 𝐴 [𝑓 𝑖 ]-𝑃 𝐵 [𝑓 𝑖 ]| 𝑃 𝐴 [𝑓 𝑖 ]+𝑃 𝐵 [𝑓 𝑖 ] 𝑚 𝑖=1<label>(</label></formula><p>To achieve this with a specific problem, the distance from Text A to all other texts is computed (or ∆(𝐴, 𝑗)). From this distribution, the mean (denoted 𝑚(𝐴, . )) and standard deviation (𝑠𝑡𝑑(𝐴, . )) are estimated. Moreover, the distribution of distance values to Text B (or ∆(𝑗, 𝐵)) can be computed to provide the mean 𝑚(. , 𝐵) and the standard deviation 𝑠𝑡𝑑(. , 𝐵) of the intertextual distances to Text B.</p><p>As a first definition of a "small" distance, we can assume that a small distance value from Text A must respect Eq. 2. In this formulation, 𝛿 is a parameter to be fixed.</p><p>𝐻𝑖𝑛𝑡 1: ∆(𝐴, 𝑗) ≤ 𝜙(𝐴, . ) = 𝑚(𝐴, . ) -𝛿 * 𝑠𝑡𝑑(𝐴, . )</p><p>Similarly, a small distance to Text B can be defined as: 𝐻𝑖𝑛𝑡 2: ∆(𝑗, 𝐵) ≤ 𝜙(. , B) = 𝑚(. , B) -𝛿 * 𝑠𝑡𝑑(. , B)</p><p>With these two decision rules, one can verify if a distance ∆ 𝐴𝐵 is small in comparison with all distances from Text A (Eq. 2) or all distances to Text B (Eq. 3). In the same way, one can verify whether the resulting ∆ 𝐵𝐴 value is small or rather large. Therefore, we propose to create two additional decision rules with Eq. 4 (based on the distribution of distance values from Text B) and Eq. 5 (for distance to Text A) as follows: 𝐻𝑖𝑛𝑡 3: ∆(𝐵, 𝑗) ≤ 𝜙(𝐵, . ) = 𝑚(𝐵, . ) -𝛿 * 𝑠𝑡𝑑(𝐵, . )</p><p>𝐻𝑖𝑛𝑡 4: ∆(𝑗, 𝐴) ≤ 𝜙(. , A) = 𝑚(. , A) -𝛿 * 𝑠𝑡𝑑(. , A) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>Since our system is based on an unsupervised approach we could directly evaluate it using the training set. In Table <ref type="table" coords="5,256.13,550.36,7.98,9.05" target="#tab_1">2a</ref>, we have reported the same performance measure applied during the PAN CLEF campaign, namely the BCubed F1 (with the clustering precision and recall) and the AP using the most frequent terms from our first run and in Table <ref type="table" coords="5,150.14,584.80,10.02,9.05" target="#tab_2">2b</ref> with the most frequent character 6-grams as used in the second run. Each corpus consists of 10 problems and we report the average of them in the last row. The final score is the arithmetic mean between the BCubed F1 and the MAP. The algorithm returns similar results over all corpora and seems to work stable independent of the text genre and language. But we can see that from the first to the second approach (from Table <ref type="table" coords="5,244.73,642.40,9.46,9.05" target="#tab_1">2a</ref> to Table <ref type="table" coords="5,292.25,642.40,8.85,9.05" target="#tab_2">2b</ref>) that the precision drops significantly and the recall increases notably. Overall, the approach with 6-grams results in a slightly higher performance of the clustering output (BCubed F1), the authorship linking (MAP), and the Final score (+2.4% difference, +5.3% change). As we can see, the final scores with all corpora are as expected from the training set with both approaches. We see a very similar performance when comparing it with the training set. Therefore, the system seems to perform stable independent of the underlying text collection and is not over-fitted to the data.</p><p>To put those values in perspective we can see in Table <ref type="table" coords="7,363.19,172.88,4.98,9.05" target="#tab_5">4</ref> our result in comparison with the other participants using macro-averaging for the effectiveness measures and showing the total runtime sorted by the final score. Overall, we are ranked 2 nd out of 6 approaches. Generally, there are only small differences in the BCubed F1 between the participants. Conversely, the MAP shows substantial variations and impacts the final score the most. The runtime only shows the actual time spent to classify the test set. On TIRA 1 there was the possibility to first train the system using the training set which had no influence on the final runtime. Since we have an unsupervised system it did not need to train any parameters, but this possibility might have been used by other participants. Overall, we achieve excellent results using a rather simple and fast approach in comparison with the other solutions.</p><p>In text categorization studies, we are convinced that a deeper analysis of the evaluation results is important to obtain a better understanding of the advantages and drawbacks of a suggested scheme. By just focusing on overall performance measures, we only observe a general behavior or trend without being able to acquire a better explanation of the proposed assignment. To achieve this deeper understanding, we could analyze some problems extracted from the English corpus. The relative frequency (or probability) differences with very frequent tokens such as the, (comma), to, or and can explain the decision. The confirmation of an authorship link is in many cases based on topical words and names that two texts share, like labour, party, people, Cameron, or work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Parameter Choices</head><p>Our approach uses a few parameters to solve the clustering task. The main influences on the performance are the choice of the distance measure, the threshold value 𝛿, and the feature selection scheme. Taking a decision solely on the outcome in the training data could lead to over-fitting. A leaving-one-out or a fold cross-validation is not possible in this task. Instead the bootstrap approach can be used. In this perspective, for each problem, the system must generate S new random bootstrap samples. More precisely, for each text, we will create S = 200 new copies having the same text length.</p><p>1 http://www.tira.io/task/author-clustering/ For each copy the probability of choosing one given feature (word and punctuation symbol, or n-gram) depends on its relative frequency in the original text. This drawing is done with replacement; thus, the underlying probabilities are stable. Each resulting text must be viewed as a bag-of-words. As the syntax is not respected, each bootstrap text is not readable but still reflects the stylistic aspects as analyzed by the SPATIUM approach.</p><p>For each of the original 60 training problems (Table <ref type="table" coords="8,347.95,218.84,4.12,9.05" target="#tab_0">1</ref>) we now have 200 generated problems of bootstrap samples and can compare different parameter choices. In Table <ref type="table" coords="8,465.82,230.39,4.98,9.05" target="#tab_6">5</ref> we analyze several distance measures and report the mean of the Final score achieved with the 200*60 new problems together with the limit of ±2 standard deviations σ corresponding to a confidence interval of 95.4%. Furthermore, the last two columns show the mean of the BCubed F1 and MAP over the 200 bootstrap samples and 60 problems. In a previous study <ref type="bibr" coords="8,206.79,445.93,11.86,9.05" target="#b6">[7]</ref> we found that Canberra and Clark work better on average in author profiling tasks than Cosine and Euclidean. We can again see the same distinction for this clustering task. In Table <ref type="table" coords="8,299.09,468.97,4.98,9.05" target="#tab_6">5</ref> we can also see that there is no significant difference between Canberra, Clark, Matusita, and KLD. For instance, between Canberra and Clark we only observe a relative change of +1.4% in the mean final score with the bootstrap approach, which isn't a substantial improvement that justifies changing our model. The next parameter to optimize is the threshold value 𝛿 that indicates the willingness of having more or less strict assignments. A smaller value for 𝛿 generates more potential links between texts and thus increases the risk of observing incorrect assignments. For a Gaussian distribution, common choices are 𝛿 = 1.96 to take account of 95%, 𝛿 = 1.64 which contains 90%, 𝛿 = 1.28 to include 80%, and 𝛿 = 1.0 to take in 66.3%. If a corpus is composed of many authors with each cluster contains only a few items, the parameter 𝛿 should be fixed at a relatively higher level. In our system from 2016, we set 𝛿 = 2.0 because of the small average cluster size <ref type="bibr" coords="8,430.92,608.20,10.82,9.05" target="#b4">[5]</ref>. With the dataset from 2017 the number of authors with only a single text is lower and there are more grouped up documents. Therefore, we decreased the threshold parameter in the current system to 𝛿 = 1.64.</p><p>Figure <ref type="figure" coords="8,164.78,654.52,4.98,9.05" target="#fig_4">2</ref> shows the mean of the BCubed F1, the MAP, and the Final score for different 𝛿 values when using the bootstrap approach. We can see that there was a lot of potential to improve the clustering outcome (highest line on top, BCubed F1). This analysis was performed after the completion of the testing stage where we fixed 𝛿 = 1.64 (shown with red squares in Figure <ref type="figure" coords="9,283.85,161.72,3.63,9.05" target="#fig_4">2</ref>). Setting 𝛿 = 1.28 would have enhanced the clustering output by 10% and therefore increased the final performance by 5%. The benefit of having a higher threshold is to be more certain that a given authorship link is correct, leading to higher clustering precisions. On the other hand, using a less restrictive threshold gives higher a clustering recall. We propose to more cautious, mainly because proposing an incorrect assignment must be viewed as more problematic in many systems (especially if they are legal and law related) than missing a link between two documents written by the same author.</p><p>Interestingly, the authorship linking seems to produce a constant result (dashed line on the bottom, MAP) independent of the used threshold value 𝛿. Finally, we can evaluate the performance variation on the training data to determine the optimal length of the character n-grams for our second run. Figure <ref type="figure" coords="9,398.35,501.61,4.98,9.05" target="#fig_5">3</ref> shows the mean clustering precision, recall, and the BCubed F1 for different n-gram lengths from n=1 (unigrams) to n=12 based on the bootstrap approach. We can see a convergence from n=2 to n=9 between the recall (increasing) and the precision (decreasing) before they diverge again. In our second run, we used 6-grams (shown with red squares in Figure <ref type="figure" coords="9,153.38,559.12,3.63,9.05" target="#fig_5">3</ref>). The highest harmonic mean between precision and recall is achieved using 7-grams, which is only slightly better than the neighboring 6-grams and 8-grams (less than 0.5% change).</p><p>Overall, the analysis has shown that the chosen parameters are fine but could have been optimized. On the one hand, choosing Clark instead of Canberra as a distance measure or taking n-grams with length n=7 characters instead of n=6 characters would have unlikely improved the result noticeably. On the other hand, using a lower threshold value like 𝛿 = 1.28 instead of 𝛿 = 1.64 would have significantly enhanced the overall clustering performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper proposes a simple unsupervised technique to solve the author clustering problem. As features to discriminate between the proposed author and different candidates, we propose using the top m most frequent terms (words and punctuations) or character n-grams. This choice was found effective for other related tasks such as authorship attribution <ref type="bibr" coords="10,214.37,450.61,10.69,9.05" target="#b1">[2]</ref>. Moreover, compared to various feature selection strategies used in text categorization <ref type="bibr" coords="10,241.61,462.01,15.53,9.05" target="#b11">[12]</ref>, the most frequent terms tend to select the most discriminative features when applied to stylistic studies <ref type="bibr" coords="10,345.43,473.53,15.43,9.05" target="#b10">[11]</ref>. To take the author linking decision, we propose using a simple distance measure called SPATIUM based on a variant of the L 1 norm called Canberra.</p><p>The proposed approach tends to perform very well in three different languages (Dutch, English, and Greek) and in two text genres (newspaper articles and reviews). Such a classifier strategy can be described as having a high bias but a low variance <ref type="bibr" coords="10,456.58,531.01,10.69,9.05" target="#b3">[4]</ref>. Changing the training data does not drastically change the decision. However, the suggested approach ignores other significant information such as mean sentence length, POS (part of speech) distribution, or topical terms. Even if the proposed system cannot capture all possible stylistic features (bias), changing the available data does not modify significantly the overall performance (variance).</p><p>It is common to fix some parameters (such as time period, size, genre, or length of the data) to minimize the possible sources of variation in the corpus. However, our main goal was to present a simple and unsupervised approach without too many predefined parameters.</p><p>With SPATIUM the proposed clustering decision could be clearly explained because it is based on a reduced set of features on the one hand and, on the other, those features are words, punctuation symbols, or long n-grams. Thus, the interpretation for the final user is clearer than when working with a huge number of features, when dealing with short n-grams of letters, or when combing several similarity measures. The SPATIUM decision can be explained by large differences in relative frequencies of frequent words, corresponding to either functional terms or overused topical words.</p><p>To improve the current classifier, we will investigate the consequence of other cluster linking strategies. Changing the single linkage strategy to a complete, average, or centroid linkage strategy could improve the outcome, because one sole link could no longer merge two bigger clusters and consequently not lower the precision drastically.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,326.95,548.56,53.51,9.05;2,261.53,560.56,66.48,9.05;2,346.39,560.56,25.42,9.05;2,401.95,560.56,25.46,9.05;2,149.42,573.04,251.27,9.05;2,415.99,573.04,30.08,9.05;2,149.42,585.04,69.75,9.05;2,236.33,585.04,164.36,9.05;2,415.99,585.04,30.08,9.05;2,149.42,597.04,251.27,9.05;2,415.99,597.04,30.08,9.05;2,149.42,609.04,69.75,9.05;2,235.25,609.04,210.82,9.05;2,149.42,621.04,251.27,9.05;2,415.99,621.04,30.08,9.05;2,149.42,633.04,69.75,9.05;2,235.25,633.04,165.44,9.05;2,415.99,633.04,30.08,9.05;2,124.82,648.04,345.74,9.05;2,124.82,659.56,345.86,9.05;2,124.82,671.08,345.55,9.05;2,124.82,682.60,345.72,9.05;3,124.82,149.84,345.77,9.05;3,124.82,161.36,345.86,9.05;3,124.82,172.88,345.85,9.05;3,124.82,184.40,345.67,9.05"><head></head><label></label><figDesc>, we have 10 problems in the training dataset containing the average number of texts as given under the label "Texts". The number of distinct authors on average together with the range for each corpus is indicated in the column "Authors", and the average with the minimum and maximum number of authors with only a single document is presented under the label "Single". Finally, the average number of terms (isolated words and punctuation symbols) is given in the column "Terms". For example, with the English newspaper collection (training set), 20 texts are written, on average, by 5.6 authors and we can find 1.8 authors who wrote only one single article.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,221.09,485.71,152.96,8.18;3,155.52,421.56,273.00,51.60"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Sample texts from problem001.</figDesc><graphic coords="3,155.52,421.56,273.00,51.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,461.56,543.52,7.80,9.05;4,124.82,565.59,345.82,9.06;4,124.82,576.99,345.65,9.06;4,124.82,588.51,345.63,9.06;4,124.82,600.04,345.71,9.05;4,124.82,611.55,345.73,9.06;4,124.82,623.08,345.68,9.05;4,124.82,634.60,244.79,9.05"><head>1 )</head><label>1</label><figDesc>where m indicates the number of features (words and punctuation symbols, or character n-grams), and PA[fi] and PB[fi] represent the estimated occurrence probability of the feature fi in the first Text A and in the other Text B respectively. To estimate these probabilities, we divide the feature occurrence frequency (ffi) by the sum of all features of the corresponding text (n), Prob[fi] = ffi / n, without smoothing and therefore accepting a probability of 0.0 in Text B. This distance measure is not symmetric due to the choice of the features to be include in the computation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,124.82,404.05,345.57,9.05;5,124.82,415.57,345.81,9.05;5,124.82,427.09,345.78,9.05;5,124.82,438.61,345.49,9.05;5,124.82,450.12,345.56,9.06;5,124.82,460.80,345.98,9.96;5,124.82,472.20,345.77,10.32"><head>An</head><label></label><figDesc>authorship between Text A and Text B is expected if at least two of the four hints are satisfied. For the clustering output, we use the single linkage strategy. For the list of links, we must rank each pair of texts by the certainty that they have a shared authorship. To determine the probability of a correct author linking we include both the number of satisfied hints h and the absolute distance between two texts in the computation<ref type="bibr" coords="5,178.94,461.65,10.68,9.05" target="#b5">[6]</ref>. A link with h hints fulfilled gets a probability between ℎ/5 and (ℎ + 1)/5, where the final score depends on the other text pairs that also satisfy h hints.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="9,156.02,472.71,283.18,9.00;9,145.10,280.57,315.75,184.23"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Results for various 𝛿 values after applying the bootstrap estimation.</figDesc><graphic coords="9,145.10,280.57,315.75,184.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="10,144.14,340.12,307.13,8.19;10,145.10,147.40,315.75,184.23"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Results for various n-gram lengths after applying the bootstrap estimation.</figDesc><graphic coords="10,145.10,147.40,315.75,184.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,200.45,531.42,194.51,8.19"><head>Table 1 . PAN CLEF 2017 training corpora statistics.</head><label>1</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,140.42,149.53,314.57,111.75"><head>Table 2a . Evaluation for the training corpora using the most frequent terms (first run).</head><label>2a</label><figDesc></figDesc><table coords="6,182.06,166.76,231.31,94.52"><row><cell cols="2">Corpus Final</cell><cell>F1</cell><cell cols="2">Precision Recall MAP</cell></row><row><cell>EN</cell><cell cols="2">0.4432 0.4836</cell><cell>0.8351</cell><cell>0.3533 0.4029</cell></row><row><cell>ER</cell><cell cols="2">0.4604 0.5332</cell><cell>0.8599</cell><cell>0.4098 0.3876</cell></row><row><cell>DN</cell><cell cols="2">0.4635 0.4762</cell><cell>0.8905</cell><cell>0.3344 0.4508</cell></row><row><cell>DR</cell><cell cols="2">0.4649 0.5988</cell><cell>0.9247</cell><cell>0.4464 0.3310</cell></row><row><cell>GN</cell><cell cols="2">0.4362 0.5316</cell><cell>0.8630</cell><cell>0.3863 0.3409</cell></row><row><cell>GR</cell><cell cols="2">0.4193 0.4929</cell><cell>0.8725</cell><cell>0.3515 0.3458</cell></row><row><cell cols="3">Overall 0.4479 0.5194</cell><cell>0.8743</cell><cell>0.3803 0.3765</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,129.98,269.92,335.57,111.72"><head>Table 2b . Evaluation for the training corpora using the most frequent 6-grams (second run).</head><label>2b</label><figDesc></figDesc><table coords="6,182.06,287.03,231.31,94.61"><row><cell cols="2">Corpus Final</cell><cell>F1</cell><cell cols="2">Precision Recall MAP</cell></row><row><cell>EN</cell><cell cols="2">0.4700 0.5338</cell><cell>0.7328</cell><cell>0.4423 0.4063</cell></row><row><cell>ER</cell><cell cols="2">0.5171 0.5948</cell><cell>0.6649</cell><cell>0.6356 0.4394</cell></row><row><cell>DN</cell><cell cols="2">0.5321 0.5700</cell><cell>0.7844</cell><cell>0.4783 0.4943</cell></row><row><cell>DR</cell><cell cols="2">0.4299 0.5476</cell><cell>0.5802</cell><cell>0.5558 0.3122</cell></row><row><cell>GN</cell><cell cols="2">0.4551 0.5491</cell><cell>0.7430</cell><cell>0.4673 0.3611</cell></row><row><cell>GR</cell><cell cols="2">0.4265 0.5388</cell><cell>0.7241</cell><cell>0.4625 0.3142</cell></row><row><cell cols="3">Overall 0.4718 0.5557</cell><cell>0.7049</cell><cell>0.5070 0.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,124.82,372.59,345.98,153.91"><head>3879 The test set is then used to rank the performance of all 6 participants in this task. Based on the same evaluation methodology, we achieve the results depicted in Table 3a and Table 3b corresponding to the six test corpora. Table 3a. Evaluation for the test corpora using the most frequent terms (first run).</head><label></label><figDesc></figDesc><table coords="6,182.06,444.97,231.35,81.53"><row><cell cols="2">Corpus Final</cell><cell>F1</cell><cell cols="2">Precision Recall MAP</cell></row><row><cell>EN</cell><cell cols="2">0.4776 0.4923</cell><cell>0.8860</cell><cell>0.3498 0.4628</cell></row><row><cell>ER</cell><cell cols="2">0.4320 0.5315</cell><cell>0.8089</cell><cell>0.4052 0.3325</cell></row><row><cell>DN</cell><cell cols="2">0.4537 0.5023</cell><cell>0.8779</cell><cell>0.3590 0.4051</cell></row><row><cell>DR</cell><cell cols="2">0.4575 0.6012</cell><cell>0.8973</cell><cell>0.4606 0.3138</cell></row><row><cell>GN</cell><cell cols="2">0.4339 0.4551</cell><cell>0.8763</cell><cell>0.3190 0.4127</cell></row><row><cell>GR</cell><cell cols="2">0.4255 0.4930</cell><cell>0.8925</cell><cell>0.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,138.14,517.45,319.13,142.40"><head>3501 0.3581 Overall 0.4467 0.5126 0.8732 0.3740 0.3808 Table 3b. Evaluation for the test corpora using the most frequent 6-grams (second run).</head><label></label><figDesc></figDesc><table coords="6,182.06,565.36,231.35,94.49"><row><cell cols="2">Corpus Final</cell><cell>F1</cell><cell cols="2">Precision Recall MAP</cell></row><row><cell>EN</cell><cell cols="2">0.5384 0.6068</cell><cell>0.7539</cell><cell>0.5244 0.4700</cell></row><row><cell>ER</cell><cell cols="2">0.4777 0.5696</cell><cell>0.6609</cell><cell>0.5731 0.3859</cell></row><row><cell>DN</cell><cell cols="2">0.5130 0.5860</cell><cell>0.7381</cell><cell>0.5291 0.4399</cell></row><row><cell>DR</cell><cell cols="2">0.4209 0.5349</cell><cell>0.5428</cell><cell>0.5597 0.3068</cell></row><row><cell>GN</cell><cell cols="2">0.4779 0.5107</cell><cell>0.7520</cell><cell>0.4214 0.4451</cell></row><row><cell>GR</cell><cell cols="2">0.4123 0.5021</cell><cell>0.6162</cell><cell>0.4876 0.3225</cell></row><row><cell cols="3">Overall 0.4734 0.5517</cell><cell>0.6773</cell><cell>0.5159 0.3951</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,142.58,224.54,310.03,98.78"><head>Table 4 .</head><label>4</label><figDesc>Evaluation comparison.</figDesc><table coords="7,142.58,241.79,310.03,81.53"><row><cell cols="2">Rank Participants</cell><cell>Final</cell><cell>F1</cell><cell>MAP Runtime (h:m:s)</cell></row><row><cell>1</cell><cell>Gómez-Adorno et al.</cell><cell cols="3">0.5142 0.5732 0.4552</cell><cell>00:02:05</cell></row><row><cell>2</cell><cell>Kocher &amp; Savoy</cell><cell cols="3">0.4734 0.5517 0.3951</cell><cell>00:00:41</cell></row><row><cell>3</cell><cell>García et al.</cell><cell cols="3">0.4724 0.5647 0.3800</cell><cell>00:15:49</cell></row><row><cell>4</cell><cell>Halvani &amp; Graner</cell><cell cols="3">0.3441 0.5488 0.1394</cell><cell>00:12:25</cell></row><row><cell>5</cell><cell>Karas ́</cell><cell cols="3">0.2958 0.4663 0.1252</cell><cell>00:00:26</cell></row><row><cell>6</cell><cell>Alberts</cell><cell cols="3">0.2846 0.5276 0.0416</cell><cell>00:01:45</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,141.98,305.09,311.57,134.89"><head>Table 5 . Results of various distance measures after applying the bootstrap estimation.</head><label>5</label><figDesc></figDesc><table coords="8,170.54,322.35,254.37,117.63"><row><cell>Distance</cell><cell>𝑥̅</cell><cell>Final 𝑥̅ -2𝜎 𝑥̅ + 2𝜎</cell><cell cols="2">BCubed F1 MAP</cell></row><row><cell cols="3">Manhattan 0.3933 0.3105 0.4761</cell><cell>0.4848</cell><cell>0.3018</cell></row><row><cell cols="3">Euclidean 0.3766 0.3158 0.4374</cell><cell>0.4671</cell><cell>0.2862</cell></row><row><cell>Canberra</cell><cell cols="2">0.4142 0.3387 0.4898</cell><cell>0.4977</cell><cell>0.3308</cell></row><row><cell>Clark</cell><cell cols="2">0.4199 0.3421 0.4976</cell><cell>0.5074</cell><cell>0.3324</cell></row><row><cell>Matusita</cell><cell cols="2">0.4156 0.3284 0.5028</cell><cell>0.5021</cell><cell>0.3291</cell></row><row><cell>KLD</cell><cell cols="2">0.4145 0.3294 0.4997</cell><cell>0.5001</cell><cell>0.3289</cell></row><row><cell>Cosine</cell><cell cols="2">0.3881 0.3069 0.4694</cell><cell>0.4851</cell><cell>0.2911</cell></row><row><cell>Dice</cell><cell cols="2">0.3974 0.3080 0.4867</cell><cell>0.4904</cell><cell>0.3043</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. The author wants to thank the task coordinators for their valuable effort to promote test collections in author clustering. This research was supported, in part, by the <rs type="funder">NSF</rs> under Grant #<rs type="grantNumber">200021_149665/1</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_QRARZp2">
					<idno type="grant-number">200021_149665/1</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,131.95,347.03,338.36,9.05;11,146.18,358.43,324.23,9.05;11,146.18,369.94,154.53,9.06" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,399.01,347.03,71.29,9.05;11,146.18,358.43,320.23,9.05">A comparison of Extrinsic Clustering Evaluation Metrics based on Formal Constraints</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Artiles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,146.18,369.94,85.60,9.06">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="461" to="486" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,131.95,381.49,338.38,9.05;11,146.18,393.00,288.47,9.06" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,236.63,381.49,233.70,9.05;11,146.18,393.01,71.65,9.05">Delta: A Measure of Stylistic Difference and a Guide to Likely Authorship</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Burrows</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,227.33,393.00,137.72,9.06">Literary and Linguistic Computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="267" to="287" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,131.95,404.53,338.28,9.05;11,146.18,416.05,324.04,9.05;11,146.18,427.44,264.08,9.06;11,410.35,426.37,5.04,5.90;11,418.15,427.44,52.63,9.06;11,146.18,438.96,73.66,9.06" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,339.29,404.53,130.94,9.05;11,146.18,416.05,276.00,9.05">Ousting Ivory Tower Research: Towards a Web Framework for Providing Experiments as a Service</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Burrows</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,350.85,427.44,59.41,9.06;11,410.35,426.37,5.04,5.90;11,418.15,427.44,52.63,9.06;11,146.18,438.96,17.62,9.06">SIGIR. The 35 th International ACM</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Hersh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Callan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Maarek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1125" to="1126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,131.95,450.48,338.67,9.06;11,146.18,462.00,324.53,9.06;11,146.18,473.53,23.59,9.05" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<title level="m" coord="11,359.11,450.48,111.50,9.06;11,146.18,462.00,202.69,9.06">The Elements of Statistical Learning. Data Mining, Inference, and Prediction</title>
		<meeting><address><addrLine>New York (NY</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,131.95,484.93,338.57,9.05;11,146.18,496.45,324.43,9.05;11,146.18,507.96,324.34,9.06;11,146.18,519.48,152.83,9.06" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,294.29,484.93,176.22,9.05;11,146.18,496.45,140.90,9.05">UniNE at CLEF 2016 Author Clustering: Notebook for PAN at CLEF 2016</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kocher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,245.45,507.96,143.60,9.06">CLEF 2016 Labs Working Notes</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Capellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<meeting><address><addrLine>Évora, Portugal; Aachen</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2016-09-05">2016. September 5-8, 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,131.95,531.01,338.76,9.05;11,146.18,542.56,324.25,9.05;11,146.18,553.95,324.43,9.06;11,146.18,565.47,324.23,9.06;11,146.18,576.99,324.65,9.06;11,146.18,588.52,43.57,9.05" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,279.41,531.01,186.98,9.05">Author Clustering with an Adaptive Threshold</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kocher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,303.77,553.95,166.84,9.06;11,146.18,565.47,324.23,9.06;11,146.18,576.99,45.03,9.06">Experimental IR Meets Multilinguality, Multimodality, and Interaction, 8th International Conference of the CLEF Association</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Lawless</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Kelly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Thomas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>CLEF; Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09-11">2017. 2017. September 11-14, 2017</date>
		</imprint>
	</monogr>
	<note>Proceedings. (to appear</note>
</biblStruct>

<biblStruct coords="11,131.95,600.04,338.65,9.05;11,146.18,611.55,237.35,9.06" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,301.13,600.04,165.68,9.05">Distance Measures in Author Profiling</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kocher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,146.18,611.55,157.35,9.06">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1103" to="1119" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,131.95,622.95,338.69,9.06;11,146.18,634.47,159.28,9.06" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="11,359.95,622.95,110.68,9.06;11,146.18,634.47,35.18,9.06">Introduction to Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Raghaven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,131.95,646.00,338.84,9.05;11,146.18,657.52,324.43,9.05;11,146.18,669.04,324.50,9.05;12,146.18,149.83,324.62,9.06;12,146.18,161.35,233.22,9.06" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,146.18,657.52,324.43,9.05;11,146.18,669.04,172.27,9.05">Improving the Reproducibility of PAN&apos;s Shared Tasks: -Plagiarism Detection, Author Identification, and Author Profiling</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="12,409.26,149.83,61.53,9.06;12,146.18,161.35,106.97,9.06">CLEF. Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Lupu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hall</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Handbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Toms</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">8685</biblScope>
			<biblScope unit="page" from="268" to="299" />
			<date type="published" when="2014">2014</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,136.56,172.87,334.24,9.06;12,146.18,184.39,315.11,9.06" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,213.20,172.88,217.91,9.05">Estimating the Probability of an Authorship Attribution</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,439.63,172.87,31.17,9.06;12,146.18,184.39,235.65,9.06">Journal of American Society for Information Science &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1462" to="1472" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,136.56,195.80,333.83,9.05;12,146.18,207.31,319.34,9.06" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,224.54,195.80,245.85,9.05;12,146.18,207.32,90.33,9.05">Comparative Evaluation of Term Selection Functions for Authorship Attribution</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,245.57,207.31,150.37,9.06">Digital Scholarship in the Humanities</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="246" to="261" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,136.56,218.83,334.19,9.06;12,146.18,230.38,126.71,9.06" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,232.28,218.84,208.47,9.05">Machine Learning in Automatic Text Categorization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,449.74,218.83,21.01,9.06;12,146.18,230.38,72.54,9.06">ACM Computing Survey</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,136.56,241.91,333.74,9.05;12,146.18,253.43,324.35,9.05;12,146.18,264.82,324.51,9.06;12,146.18,276.34,161.25,9.06" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,286.25,253.43,184.28,9.05;12,146.18,264.83,43.14,9.05">Clustering by Authorship Within and Across Documents</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,216.78,264.83,218.64,9.05">Working Notes of the CLEF 2016 Evaluation Labs</title>
		<title level="s" coord="12,444.70,264.82,25.99,9.06;12,146.18,276.34,91.26,9.06">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,136.56,287.87,334.13,9.05;12,146.18,299.39,324.25,9.05;12,146.18,310.91,324.40,9.05;12,146.18,322.42,324.64,9.06;12,146.18,333.83,33.30,9.05" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,265.73,299.39,204.70,9.05;12,146.18,310.91,211.50,9.05">Overview of the Author Identification Task at PAN 2017: Style Breach Detection and Author Clustering</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,379.09,310.91,91.49,9.05;12,146.18,322.43,150.87,9.05">Working Notes Papers of the CLEF 2017 Evaluation Labs</title>
		<title level="s" coord="12,306.53,322.42,124.96,9.06">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
