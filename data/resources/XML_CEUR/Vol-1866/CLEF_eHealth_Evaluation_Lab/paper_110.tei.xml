<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,142.98,115.96,329.41,12.62;1,258.22,133.89,98.91,12.62;1,178.37,151.82,258.62,12.62">A Lexicon Based Approach to Classification of ICD10 Codes. IMS Unipd at CLEF eHealth Task 1</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,156.70,189.49,74.99,8.74"><forename type="first">Giorgio</forename><forename type="middle">Maria</forename><surname>Di</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Information Engineering</orgName>
								<orgName type="institution">University of Padua</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,276.28,189.49,72.53,8.74"><forename type="first">Federica</forename><surname>Beghini</surname></persName>
							<email>fede.beghini92@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Linguistic and Literary Studies</orgName>
								<orgName type="institution">University of Padua</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,359.37,189.49,72.67,8.74"><forename type="first">Federica</forename><surname>Vezzani</surname></persName>
							<email>federicavezzani92@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Linguistic and Literary Studies</orgName>
								<orgName type="institution">University of Padua</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,266.65,201.45,77.59,8.74"><forename type="first">Geneviève</forename><surname>Henrot</surname></persName>
							<email>genevieve.henrot@unipd.it</email>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Linguistic and Literary Studies</orgName>
								<orgName type="institution">University of Padua</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,142.98,115.96,329.41,12.62;1,258.22,133.89,98.91,12.62;1,178.37,151.82,258.62,12.62">A Lexicon Based Approach to Classification of ICD10 Codes. IMS Unipd at CLEF eHealth Task 1</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">681F2FD3662331660079F5B16DD2BDF1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe the participation of the Information Management Systems (IMS) group at CLEF eHealth 2017 Task 1. In this task, participants are required to extract causes of death from death reports (in French and in English) and label them with the correct International Classification Diseases (ICD10) code. We tackled this task by focusing on the replicability and reproducibility of the experiments and, in particular, on building a basic compact system that produces a clean dataset that can be used to implement more sophisticated approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we report the experimental results of the IMS group that participated for the first time to the CLEF eHealth Lab <ref type="bibr" coords="1,360.76,440.92,9.96,8.74" target="#b7">[8]</ref>, in particular to Task 1: "Multilingual Information Extraction -ICD10 coding" <ref type="bibr" coords="1,379.72,452.88,14.61,8.74" target="#b10">[11]</ref>. This task consists in labelling with International Classification Diseases (ICD10) codes death certificate texts written in English or in French. This work is usually performed by experts in medicine; however, when large volumes of data need to be organized and labelled, manual work is not only expensive but also time consuming and probably not feasible when hundreds of thousands of death certificates need to be classified according to a taxonomy of thousands of codes. For this reason, a possible solution is to approach this task either from a machine learning perspective and/or a natural language processing perspective by using syntactic and/or semantic decision rules <ref type="bibr" coords="1,237.63,560.48,9.96,8.74" target="#b1">[2]</ref>.</p><p>The main goal of our participation to this task was to build a reproducible set of experiments of a system that i) converts raw data into a cleaned dataset, ii) implements a set of manual rules to split sentences and translate medical acronyms, and iii) implement a lexicon based classification approach with the aim of building a sufficiently strong baseline (our initial objective was to achieve a classifier with precision and recall equal 0.5) . We intentionally did not make use of any machine learning approach to improve the accuracy of the classification of death certificates; in fact, the main objective was to build a modular system that can be easily enhanced in order to make use of the cleaned training data available. For this purpose, we devised a pipeline for processing each death certificate and producing a 'normalized' version of the text. Indeed, death certificates are standardized documents filled by physicians to report the death of a patient but the content of each document contains heterogeneous and noisy data that participants had to deal with <ref type="bibr" coords="2,310.48,178.77,9.96,8.74" target="#b8">[9]</ref>. For example, some certificates contain non-diacritized text, or a mix of cases and diacritized text, acronyms and/or abbreviations, and so on.</p><p>The main points of our contribution to this task can be summarized as follows:</p><p>-A reproducibility framework to explain each step of the pipeline from raw data to cleaned data; -A minimal expert system based on rules to split sentences and translate acronyms; -Experimenting different weighting approach to retrieve the items in the dictionary most similar to the portion of the certificate of death; -A simple classification approach to select the ICD code with the highest weight.</p><p>For this task, we submitted 2 official English runs plus 3 unofficial English runs and 8 unofficial French runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>In this section, we describe the main aspects of our contribution: the software used to build the reproducibility framework, the data cleaning pipeline, and the classification approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">R Markdown for Reproducible Research</head><p>The problem of reproducibility in Information Retrieval has been addressed by many researchers in the field in the last years <ref type="bibr" coords="2,340.50,516.84,10.52,8.74" target="#b5">[6,</ref><ref type="bibr" coords="2,352.68,516.84,7.75,8.74" target="#b3">4,</ref><ref type="bibr" coords="2,362.10,516.84,11.62,8.74" target="#b11">12]</ref>. The main concerns for reproducibility in IR are related to system runs; in fact, even if a researcher uses the same datasets and the same open source software, there are many hidden parameters that make the full reproducibility of the experiment very difficult. For this reason, there are important initiatives in the main IR conferences that support this kind of activity (see for example the open source information retrieval reproducibility challenge at SIGIR<ref type="foot" coords="2,283.70,587.00,3.97,6.12" target="#foot_0">3</ref> or the Reproducibility track at ECIR <ref type="bibr" coords="2,454.41,588.57,10.79,8.74" target="#b4">[5]</ref>) as well as in the Natural Language Processing community <ref type="bibr" coords="2,378.79,600.53,9.96,8.74" target="#b0">[1]</ref>.</p><p>During the same time span, the Data Science community has questioned the same issues 4 and has produced interesting solutions from a software point of Table <ref type="table" coords="3,164.27,115.91,4.13,7.89">1</ref>. Expressions or punctuation marks used to split a line of a death certificate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>English</head><p>French with avec due to sur that caused par sec to suite à un[e] on top of dans un contexte de also caused by après ",", ";", "/" ",", ";", "/"</p><p>view. The R Markdown framework<ref type="foot" coords="3,287.43,257.13,3.97,6.12" target="#foot_1">5</ref> is now considered one of the possible solutions to document the results of an experiment and, at the same time, reproduce each step of the experiment itself. Following the indications given by <ref type="bibr" coords="3,436.27,282.61,9.96,8.74" target="#b6">[7]</ref>, we developed the experimental framework in R and publish the source code on github to allow other participants to reproduce our results. <ref type="foot" coords="3,361.19,304.95,3.97,6.12" target="#foot_2">6</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Pipeline for Data Cleaning</head><p>In order to produce a clean dataset, we implemented the following pipeline for data ingestion and preparation for all the experiments:</p><p>read a line of a death certificate, split the line according to the expression listed in Table <ref type="table" coords="3,397.72,400.70,3.87,8.74">1</ref>; remove extra white space (leading, trailing, internal); transform letters to lower case; remove punctuation; expand acronyms (if any); correct common patterns (if any).</p><p>Acronym Expansion Acronym expansion is a crucial step to normalize data and make the death certificate clearer and more coherent with the ICD10 codes.</p><p>For the English experiments, we used a manual approach to build the list of expanded acronyms and an automatic approach that gathers acronym from the Web. For the French experiments, we automatically created a list of expanded medical acronyms available on Wikipedia and a manual cleaning of the same list. Indeed, the automatically creation of a list of acronyms gathered from the Web presents some problems:</p><p>sometimes acronyms have more than one expansion, some of which do not belong to the medical field;</p><p>some entries contain more than one language, for example English and/or French and/or the Latin expanded acronym; some others have some spelling mistakes.</p><p>In order to deal with these issues, we referred to the ICD10 dictionary code list which contained a list of diseases and causes of death, to other French dictionaries, 7,8 and to some reliable websites. <ref type="foot" coords="4,308.18,181.73,3.97,6.12" target="#foot_5">9</ref>Moreover, we removed the wrong definitions and the acronym expansions written in English and in Latin, and we corrected the spelling mistakes concerning some of the accents (especially on the grapheme ¡e¿) and some typos (e.g. "isoniazide" instead of "izoniazide"). Additionally, there were some variants that differed only in the hyphen, e.g. broncho-pulmonaire/bronchopulmonaire, antiagrégant plaquettaire/anti-agrégant plaquettaire. In these cases, we chose the definition present in the ICD10 dictionary and, if both variants were present, we entered the one that had more occurrences on the Web.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Classification</head><p>We used a simple unsupervised lexicon based approach to label each (segment of a) line of a death certificate <ref type="bibr" coords="4,269.68,335.21,9.96,8.74" target="#b2">[3]</ref>. The procedure to assign an ICD10 code that does not require any training is the following:</p><p>for each (segment of a) line compute the score of each entry of the dictionary; group the ICD10 codes that have the maximum score; assign the most frequent code within this group.</p><p>The score of each entry is the sum of the weights of each term either binary weighting (term present or absent) or a term frequency -inverse document frequency (Tf-Idf) approach <ref type="bibr" coords="4,251.60,427.27,14.61,8.74" target="#b9">[10]</ref>. In those cases where two or more classes have the same number of entries with the maximum score, the first class in the list is assigned by default.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>In our experiments, we implemented:</p><p>1. a minimal expert system based on rules to translate acronyms, together with 2. a binary weighting approach or a Tf-Idf approach to retrieve the items in the dictionary most similar to the portion of the certificate of death, and 3. a lexicon based classification approach that selects the most frequent class with the highest weight.</p><p>We submitted two official runs for the English raw dataset. Then, we submitted 3 unofficial English runs and 8 unofficial French runs (four for the raw dataset and four for the aligned dataset). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Official Runs</head><p>For the two official English runs, we pre-processed the raw dataset in the following way:</p><p>1. Read the first three fields of the American dictionary (DiagnosisText, Icd1, Icd2, Icd3) and skip lines from 69328 to 69332 since there were some problems with the data format as shown below ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>Index the dictionary using either binary weights or Tf-Idf weights; 3. Build a test run by reading (and cleaning) the causes brutes file and split the sentence according to the following set of patterns: "with", "due to", "also due to", "that caused", "sec to", "on top of", expand each acronym using a table of manually curated acronyms, 4. classify each line by assigning the ICD code with the highest score, if one, or the most frequent code if more than a code matches the line of the death certificate.</p><p>The expansion of the acronym was done by manually checking the acronyms in the training data and building a table of expanded acronyms by means of the Web page https://www.allacronyms.com/_medical.</p><p>The results of the two runs, Unipd-run1 for the binary weighting approach and Unipd-run2 for the Tf-Idf weighing approach are reported in Table <ref type="table" coords="5,457.32,560.48,3.87,8.74" target="#tab_0">2</ref>.</p><p>The results of the binary weighting run was very close to our expectations, that is to classify correctly almost half of the ICD10 codes (both in terms of Recall and Precision) by just cleaning and normalizing the data without the help of any expert of the field.</p><p>The poor result of the Tf-Idf weighting approach on the second run was unexpected. For this reason, we investigated this matter and, thanks to the reproducibility approach, we were able to immediately spot two bugs in the code: 1) we unintentionally selected the Tf weights instead of TfIdf during the indexing phase, 2) more importantly, we made a mistake in the classification code (step 4 in the above list) that prevented the algorithm to select the most frequent code (it just assigned the first ICD code in the initial list of results).</p><p>For this reason, we decided to correct the code and submit a second version of Tf-Idf as an unofficial run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Unofficial</head><p>We also submitted unofficial runs both for French and English with the same original goal but a slightly different approach for the collection of acronyms and the use of transliteration of French diacritics. In particular, we were interested in automatically gathering medical acronyms from a Wikipedia page and manually cleaning the table of expanded acronyms (for example, duplicated entries, both English and French version, wrong diacritics, and so on).</p><p>For the expansion of French acronyms, we used the Wikipedia page "Liste d'abréviations en médecine"<ref type="foot" coords="6,259.98,444.31,7.94,6.12" target="#foot_6">10</ref> that contains 1,059 acronyms. After a manual cleaning of the broken/missing/duplicated entries, we produced a table of 1,179 expanded acronyms.</p><p>The increase in the number of acronyms is due to the fact that for the same acronym there were several solutions relevant to the medical field. Indeed, we decided to place each variant in a different row with the aim of providing a more complete overview of medical terminology. Furthermore, we applied the same procedure when two acronyms corresponded to the same expansion by keeping both alternatives and positioning them in different rows. Finally, we decided to remove the acronym expansions that were not relevant to the medical field.</p><p>For the expansion of the English acronyms, we decided not to use the English Wikipedia list of medical abbreviation page since it is much less informative compared to the French version. Instead, we chose a public Web page that contains 445 common medical abbreviations. <ref type="foot" coords="6,316.73,600.52,7.94,6.12" target="#foot_7">11</ref> For the English unofficial runs, we did not perform any manual corrections of the table of expanded acronyms. ation of expanded acronyms, with transliteration of diacritics;</p><p>-Unipd-run8 (raw), Unipd-run16 (aligned): binary weights, manually curated expanded acronyms, without transliteration of diacritics; -Unipd-run9 (raw), Unipd-run17 (aligned): binary weights, manually curated expanded acronyms, with transliteration of diacritics; -Unipd-run10 (raw), Unipd-run18 (aligned): Tf-idf weights, automatic creation of expanded acronyms, without transliteration of diacritics; -Unipd-run11 (raw), Unipd-run19 (aligned): Tf-idf weights, automatic creation of expanded acronyms, with transliteration of diacritics; -Unipd-run12 (raw), Unipd-run20 (aligned): Tf-idf weights, manually curated expanded acronyms, without transliteration of diacritics; -Unipd-run13 (raw), Unipd-run21 (aligned): Tf-idf weights, manually curated expanded acronyms, with transliteration of diacritics.</p><p>The results for the unofficial French runs are reported in Table <ref type="table" coords="8,412.56,290.44,3.87,8.74">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Final remarks and Future Work</head><p>The aim of our participation was to implement a reproducible lexicon based classifier that can be used as a baseline for further experiments. The performance was sufficiently good and in some cases the classifier achieved a classification performance above 50% both for Recall and Precision which was our initial ideal threshold as a baseline. Moreover, the preliminary results of the experiments (official and unofficial) have shown interesting differences between the English and French dataset:</p><p>-Tf-Idf works better for English while binary weighting performs consistently better for the French dataset; -For the expansion of the acronym there seems to be a trade-off between manual curation of data and quantity of data gathered from the Web; a lot of noisy data is comparable to a small curated set (see for example Unipd-run3 and Unipd-run5). With lots of data, a round of manual curation allows for small (if not negligible) improvements in terms of accuracy of classification; for the French dataset, the normalization of diacritics was a key factor that led to improvements of 10 points percent over the non-normalized version.</p><p>Before turning to a more complex system (based on a machine learning approach), we will investigate other forms of data cleaning. In particular, we want to investigate better the problem with diacritics and include an automatic correction of wrong spellings of words (very frequent in the dataset) based, for example, on the Hamming distance among the words of the ICD10 codes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,147.23,115.91,320.90,72.90"><head>Table 2 .</head><label>2</label><figDesc>Results for the official English runs</figDesc><table coords="5,147.23,136.31,320.90,52.50"><row><cell cols="4">EN-ALL Precision Recall F-measure EN-EXT Precision Recall F-measure</cell></row><row><cell cols="4">Unipd-run1 0.4963 0.4417 0.4674 Unipd-run1 0.2791 0.0952 0.1420</cell></row><row><cell cols="4">Unipd-run2 0.3822 0.3405 0.3602 Unipd-run2 0.2917 0.1111 0.1609</cell></row><row><cell>average</cell><cell>0.6548 0.5586 0.6017</cell><cell>average</cell><cell>0.3986 0.2749 0.2549</cell></row><row><cell>median</cell><cell>0.6459 0.5267 0.5892</cell><cell>median</cell><cell>0.2791 0.2619 0.2740</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,145.54,115.91,324.28,106.17"><head>Table 3 .</head><label>3</label><figDesc>Results for the unofficial English runs</figDesc><table coords="6,145.54,136.31,324.28,85.77"><row><cell cols="8">EN-ALL Precision Recall F-measure EN-EXT Precision Recall F-measure</cell></row><row><cell cols="4">Unipd-run3 0.6104 0.5454 0.5761</cell><cell></cell><cell cols="3">0.2167 0.1032 0.1398</cell></row><row><cell cols="4">Unipd-run4 0.5015 0.4442 0.4711</cell><cell></cell><cell cols="3">0.2439 0.0794 0.1198</cell></row><row><cell cols="4">Unipd-run5 0.6128 0.5474 0.5783</cell><cell></cell><cell cols="3">0.1833 0.0873 0.1183</cell></row><row><cell cols="4">Unipd-run1 0.4963 0.4417 0.4674</cell><cell></cell><cell cols="3">0.2791 0.0952 0.1420</cell></row><row><cell cols="4">Unipd-run2 0.3822 0.3405 0.3602</cell><cell></cell><cell cols="3">0.2917 0.1111 0.1609</cell></row><row><cell>average</cell><cell>0.670</cell><cell>0.582</cell><cell>0.622</cell><cell>average</cell><cell>0.405</cell><cell>0.267</cell><cell>0.267</cell></row><row><cell>median</cell><cell>0.646</cell><cell>0.606</cell><cell>0.611</cell><cell>median</cell><cell>0.279</cell><cell>0.262</cell><cell>0.274</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="2,144.73,646.48,212.32,7.47"><p>https://github.com/lintool/IR-Reproducibility</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="3,144.73,646.48,131.81,7.47"><p>http://rmarkdown.rstudio.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="3,144.73,657.44,203.90,7.47"><p>https://github.com/gmdn/CLEF-eHealth-Task-1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3" coords="4,144.73,623.92,302.25,8.12"><p>Larousse http://www.larousse.fr/dictionnaires/francais-monolingue</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4" coords="4,144.73,634.88,326.93,8.12"><p>Le Trésor de la Langue Française Informatisé http://atilf.atilf.fr/tlfi.htm</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5" coords="4,144.73,646.48,297.56,7.47;4,144.73,657.44,136.51,7.47"><p>http://www.cnci.univ-paris5.fr/medecine/abreviations.html,http: //dictionnaire.doctissimo.fr/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_6" coords="6,144.73,635.53,325.80,7.47"><p>https://fr.wikipedia.org/wiki/Liste_d\%27abr\'eviations_en_m\'edecine</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_7" coords="6,144.73,646.48,325.30,7.47;6,144.73,657.44,32.95,7.47"><p>http://www.spinalcord.org/resource-center/askus/index.php?pg=kb.page&amp; id=1413</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>English Run Results A total of three unofficial English runs were submitted:</p><p>-Unipd-run3 a corrected version of the official Tf-Idf run; -Unipd-run4 binary weights with automatic acronym expansion; -Unipd-run5 Tf-Idf weights with automatic acronym expansion.</p><p>The results for the unofficial English runs are reported in Table <ref type="table" coords="7,431.61,470.75,3.87,8.74">3</ref>. The first half of the table shows the results of the unofficial runs, while the second half reports the official results for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>French Run Results</head><p>For the French dataset, we had to lightly change the code that read the aligned and the raw causes since some lines (less than 1% of the data) had some issues with the number of fields (more than expected) and/or contained a semicolon in the death certificate (being the semicolon the separating characters of the fields). See the files available for the reproducibility track for more details.</p><p>A total of sixteen unofficial French runs were submitted: eight for the raw dataset, eight for the aligned dataset. For each type of dataset we tried the following settings:</p><p>-Unipd-run6 (raw), Unipd-run14 (aligned): binary weights, automatic creation of expanded acronyms, without transliteration of diacritics;</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,645.84,337.64,7.86;8,151.52,656.80,329.08,7.86;9,151.52,119.67,329.07,7.86;9,151.52,130.63,329.07,7.86;9,151.52,141.59,290.34,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,453.31,645.84,27.29,7.86;8,151.52,656.80,329.08,7.86;9,151.52,119.67,65.95,7.86">Reproducibility in natural language processing: A case study of two r libraries for mining pubmed/medline</title>
		<author>
			<persName coords=""><forename type="first">Jingbo</forename><surname>Kevin B Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christophe</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lawrence</forename><surname>Roeder</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Hunter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,249.62,119.67,230.97,7.86;9,151.52,130.63,324.62,7.86">LREC 4REAL Workshop: Workshop on Research Results Reproducibility and Resources Citation in Science and Technology of Language</title>
		<imprint>
			<publisher>European Language Resources Association (ELRA</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="6" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,152.55,337.64,7.86;9,151.52,163.51,329.07,7.86;9,151.52,174.47,329.07,7.86;9,151.52,183.16,329.07,10.13;9,151.52,196.39,102.08,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,276.40,163.51,204.18,7.86;9,151.52,174.47,185.89,7.86">ECSTRA-INSERM @ CLEF ehealth2016-task 2: ICD10 code extraction from death certificates</title>
		<author>
			<persName coords=""><forename type="first">Mohamed</forename><surname>Dermouche</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rémi</forename><surname>Vincent Looten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sylvie</forename><surname>Flicoteaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Chevret</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Namik</forename><surname>Velcin</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Taright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,358.13,174.47,122.46,7.86;9,151.52,185.43,190.57,7.86">Working Notes of CLEF 2016 -Conference and Labs of the Evaluation forum</title>
		<meeting><address><addrLine>Évora, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-09-08">5-8 September, 2016. 2016</date>
			<biblScope unit="page" from="61" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,207.34,337.64,7.86;9,151.52,218.30,329.07,7.86;9,151.52,229.26,273.33,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,226.95,207.34,214.95,7.86">Unsupervised learning for lexicon-based classification</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,462.94,207.34,17.66,7.86;9,151.52,218.30,286.23,7.86">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">February 4-9, 2017. 2017</date>
			<biblScope unit="page" from="3188" to="3194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,240.22,337.63,7.86;9,151.52,251.18,236.24,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,211.65,240.22,250.29,7.86">Reproducibility challenges in information retrieval evaluation</title>
		<author>
			<persName coords=""><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,472.94,240.22,7.65,7.86;9,151.52,251.18,119.97,7.86">J. Data and Information Quality</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2017-01">January 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,262.14,337.64,7.86;9,151.52,273.10,329.07,7.86;9,151.52,284.06,329.07,7.86;9,151.52,295.02,329.07,7.86;9,151.52,305.98,175.84,7.86" xml:id="b4">
	<analytic>
		<author>
			<persName coords=""><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Josiane</forename><surname>Mothe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,151.52,284.06,329.07,7.86;9,151.52,295.02,43.36,7.86">Advances in Information Retrieval -38th European Conference on IR Research, ECIR 2016</title>
		<title level="s" coord="9,451.65,295.02,28.95,7.86;9,151.52,305.98,108.29,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Fabrizio</forename><surname>Silvestri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Giorgio</forename><surname>Maria</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Di</forename><surname>Nunzio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Claudia</forename><surname>Hauff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Gianmaria</forename><surname>Silvello</surname></persName>
		</editor>
		<meeting><address><addrLine>Padua, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">March 20-23, 2016. 2016</date>
			<biblScope unit="volume">9626</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,316.93,337.64,7.86;9,151.52,327.89,329.07,7.86;9,151.52,338.85,329.07,7.86;9,151.52,349.81,288.77,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,232.82,327.89,247.78,7.86;9,151.52,338.85,287.23,7.86">Increasing reproducibility in ir: Findings from the dagstuhl seminar on &quot;reproducibility of data-oriented experiments in e-science</title>
		<author>
			<persName coords=""><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Norbert</forename><surname>Fuhr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kalervo</forename><surname>Jarvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noriko</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthias</forename><surname>Lippold</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</author>
		<ptr target="http://sigir.org/files/forum/2016J/p068.pdf" />
	</analytic>
	<monogr>
		<title level="j" coord="9,454.49,338.85,26.11,7.86;9,151.52,349.81,24.10,7.86">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="68" to="82" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,360.77,337.63,7.86;9,151.52,371.73,145.58,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,244.13,360.77,172.30,7.86">Reproducible Research with R and R Studio</title>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Gandrud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,424.04,360.77,56.55,7.86;9,151.52,371.73,38.79,7.86">Chapman and Hall/CRC</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>second ed. edition</note>
</biblStruct>

<biblStruct coords="9,142.96,382.69,337.64,7.86;9,151.52,393.65,329.07,7.86;9,151.52,404.61,329.07,7.86;9,151.52,415.56,302.42,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,455.98,393.65,24.61,7.86;9,151.52,404.61,154.27,7.86">CLEF 2017 eHealth Evaluation Lab Overview</title>
		<author>
			<persName coords=""><forename type="first">Lorraine</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liadh</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hanna</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aurélie</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aude</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Evangelos</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rene</forename><surname>Spijker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">João</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,313.53,404.61,167.06,7.86;9,151.52,415.56,85.62,7.86">CLEF 2017 -8th Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="9,245.04,415.56,141.41,7.86">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,426.52,337.63,7.86;9,151.52,437.48,329.07,7.86;9,151.52,448.44,329.07,7.86;9,151.52,457.13,329.07,10.13;9,151.52,470.36,223.39,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,268.94,437.48,187.04,7.86">Overview of the CLEF ehealth evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">Liadh</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lorraine</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hanna</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aurélie</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>João</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guido</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,164.40,448.44,316.19,7.86;9,151.52,459.40,255.07,7.86;9,239.38,470.36,44.41,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction -7th International Conference of the CLEF Association, CLEF 2016</title>
		<meeting><address><addrLine>Évora, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-09-05">2016. September 5-8, 2016. 2016</date>
			<biblScope unit="page" from="255" to="266" />
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct coords="9,142.61,481.32,337.98,7.86;9,151.52,492.28,329.07,7.86;9,151.52,503.24,139.59,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,427.14,481.32,53.45,7.86;9,151.52,492.28,153.93,7.86">Scoring, term weighting, and the vector space model</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prabhakar</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hinrich</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,326.66,492.28,150.10,7.86">Introduction to Information Retrieval</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="100" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,514.19,337.97,7.86;9,151.52,525.15,329.07,7.86;9,151.52,536.11,329.07,7.86;9,151.52,547.07,329.07,7.86;9,151.52,558.03,329.07,7.86;9,151.52,568.99,20.99,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,151.52,536.11,329.07,7.86;9,151.52,547.07,170.46,7.86">Clef ehealth 2017 multilingual information extraction task overview: Icd10 coding of death certificates in english and french</title>
		<author>
			<persName coords=""><forename type="first">Aurélie</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><forename type="middle">N</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bretonnel Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cyril</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Lavergne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Grégoire</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aude</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Claire</forename><surname>Rondet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Zweigenbaum</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="9,345.10,547.07,135.49,7.86;9,151.52,558.03,133.90,7.86">CLEF 2017 Evaluation Labs and Workshop: Online Working Notes</title>
		<title level="s" coord="9,292.42,558.03,146.69,7.86">CEUR Workshop Proceedings. CEUR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,579.95,337.98,7.86;9,151.52,590.91,329.07,7.86;9,151.52,601.87,329.07,7.86;9,151.52,612.82,329.07,7.86;9,151.52,623.78,123.38,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,418.37,579.95,62.23,7.86;9,151.52,590.91,329.07,7.86;9,151.52,601.87,15.40,7.86">Replicability of research in biomedical natural language processing: a pilot evaluation for a coding task</title>
		<author>
			<persName coords=""><forename type="first">Aurelie</forename><surname>Neveol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cyril</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aude</forename><surname>Robert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,185.09,601.87,295.50,7.86;9,151.52,612.82,101.47,7.86">Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis</title>
		<meeting>the Seventh International Workshop on Health Text Mining and Information Analysis<address><addrLine>Auxtin, TX</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-11">November 2016</date>
			<biblScope unit="page" from="78" to="84" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
