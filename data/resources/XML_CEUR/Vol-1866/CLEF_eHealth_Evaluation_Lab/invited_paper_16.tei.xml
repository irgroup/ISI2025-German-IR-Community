<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,139.87,116.26,335.62,12.45;1,224.01,134.19,167.34,12.45;1,134.77,154.16,345.82,10.38">CLEF 2017 Task Overview: The IR Task at the eHealth Evaluation Lab Evaluating Retrieval Methods for Consumer Health Search</title>
				<funder ref="#_bEEpU5z">
					<orgName type="full">ESF</orgName>
				</funder>
				<funder ref="#_ss4tDcw">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,137.80,190.14,53.13,8.80"><forename type="first">Joao</forename><surname>Palotti</surname></persName>
							<email>[palotti@ifs.tuwien.ac.at</email>
							<affiliation key="aff0">
								<orgName type="institution">Vienna University of Technology</orgName>
								<address>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,201.49,190.14,60.95,8.80"><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
							<email>[g.zuccon@qut.edu.au</email>
							<affiliation key="aff1">
								<orgName type="institution">Queensland University of Technology</orgName>
								<address>
									<settlement>Brisbane</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,313.03,190.14,55.35,8.80"><forename type="first">Pavel</forename><surname>Pecina</surname></persName>
							<email>pecina@ufal.mff.cuni.cz</email>
							<affiliation key="aff1">
								<orgName type="institution">Queensland University of Technology</orgName>
								<address>
									<settlement>Brisbane</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Charles University</orgName>
								<address>
									<settlement>Prague</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,378.94,190.14,51.33,8.80"><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
							<email>lupu@ifs.tuwien.ac.at</email>
							<affiliation key="aff0">
								<orgName type="institution">Vienna University of Technology</orgName>
								<address>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,440.83,190.14,36.73,8.80;1,207.86,202.10,38.57,8.80"><forename type="first">Lorraine</forename><surname>Goeuriot</surname></persName>
							<email>lorraine.goeuriot@imag.fr</email>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Grenoble INP</orgName>
								<orgName type="institution" key="instit4">LIG</orgName>
								<address>
									<postCode>F-38000</postCode>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,256.98,202.10,51.33,8.80"><forename type="first">Liadh</forename><surname>Kelly</surname></persName>
							<email>liadh.kelly@dcu.ie</email>
							<affiliation key="aff4">
								<orgName type="department">ADAPT Centre</orgName>
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,338.25,202.10,64.78,8.80"><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
							<email>hanbury]@ifs.tuwien.ac.at</email>
							<affiliation key="aff0">
								<orgName type="institution">Vienna University of Technology</orgName>
								<address>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,139.87,116.26,335.62,12.45;1,224.01,134.19,167.34,12.45;1,134.77,154.16,345.82,10.38">CLEF 2017 Task Overview: The IR Task at the eHealth Evaluation Lab Evaluating Retrieval Methods for Consumer Health Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E1123382DD1DE7E4B15EB078C7B468B3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper provides an overview of the information retrieval (IR) Task of the CLEF 2017 eHealth Evaluation Lab. This task investigates the effectiveness of web search engines in providing access to medical information for common people that have no or little medical knowledge (health consumers). The task aims to foster advances in the development of search technologies for consumer health search by providing resources and evaluation methods to test and validate search systems. The problem considered in this year's task was to retrieve web pages to support the information needs of health consumers that are faced with a medical condition and that want to seek relevant health information online through a search engine. The task re-used the 2016 topics, to deepen the assessment pool and create a more comprehensive and reusable collection. The task had four sub-tasks: ad-hoc search, personalized search, query variations, and multilingual ad-hoc search. Seven teams participated in the task; relevance assessment is underway and assessments along with the participants results will be released at the CLEF 2017 conference. Resources for this task, including topics, assessments, evaluation scripts and participant runs are available at the task's GitHub repository:</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper details the collection, systems and evaluation methods used in the IR Task of the CLEF 2017 eHealth Evaluation Lab (Task 3). This task is a continuation of the previous CLEF eHealth information retrieval (IR) tasks that ran between 2013 and 2016 <ref type="bibr" coords="1,255.59,656.06,11.93,8.80" target="#b3">[4,</ref><ref type="bibr" coords="1,267.52,656.06,7.95,8.80" target="#b4">5,</ref><ref type="bibr" coords="1,275.47,656.06,11.93,8.80" target="#b17">18,</ref><ref type="bibr" coords="1,287.39,656.06,11.93,8.80" target="#b26">27]</ref> and embraces the TREC-style evaluation process, with a shared collection of documents and queries, the contribution of runs from participants and the subsequent formation of relevance assessments and evaluation of the participants submissions.</p><p>The task investigated the problem of retrieving web pages to support information needs of health consumers (including their next-of-kin) that are confronted with a health problem or medical condition and that use a search engine to seek better understanding about their health. This task has been developed within the CLEF 2017 eHealth Evaluation Lab, which aims to foster the development of approaches to support patients, their next-of-kin, and clinical staff in understanding, accessing and authoring health information <ref type="bibr" coords="2,394.88,228.75,9.96,8.80" target="#b5">[6]</ref>.</p><p>The use of the Web as source of health-related information is a wide-spread practice among health consumers <ref type="bibr" coords="2,282.46,254.88,15.50,8.80" target="#b12">[13]</ref> and search engines are commonly used as a means to access health information available online <ref type="bibr" coords="2,369.91,266.83,9.96,8.80" target="#b2">[3]</ref>.</p><p>Previous iterations of this task (i.e. the 2013 and 2014 CLEF eHealth Lab Task 3 <ref type="bibr" coords="2,167.44,292.96,11.07,8.80" target="#b3">[4,</ref><ref type="bibr" coords="2,178.51,292.96,7.38,8.80" target="#b4">5]</ref>) aimed at evaluating the effectiveness of search engines to support people when searching for information about their conditions, e.g., to answer queries like "thrombocytopenia treatment corticosteroids length". These two evaluation exercises have provided valuable resources and an evaluation framework for developing and testing new and existing techniques. The fundamental contribution of these tasks to the improvement of search engine technology aimed at answering this type of health information need is demonstrated by the improvements in retrieval effectiveness provided by the best 2014 system <ref type="bibr" coords="2,443.78,376.65,15.50,8.80" target="#b19">[20]</ref> over the best 2013 system <ref type="bibr" coords="2,229.58,388.61,15.50,8.80" target="#b22">[23]</ref> (using different, but comparable, topic sets).</p><p>In 2015 the task took a different focus, specifically focusing on supporting consumers searching for self-diagnosis information <ref type="bibr" coords="2,362.50,414.74,14.61,8.80" target="#b17">[18]</ref>, an important type of health information seeking activity <ref type="bibr" coords="2,292.43,426.69,9.96,8.80" target="#b2">[3]</ref>. Last year's task expanded on the 2015 task, by considering not only self-diagnosis information needs, but also needs related to treatment and management of health conditions <ref type="bibr" coords="2,383.33,450.60,14.61,8.80" target="#b26">[27]</ref>. Previous research has shown that exposing people with no or scarce medical knowledge to complex medical language may lead to erroneous self-diagnosis and self-treatment and that access to medical information on the Web can lead to the escalation of concerns about common symptoms (e.g., cyberchondria) <ref type="bibr" coords="2,395.01,498.42,11.15,8.80" target="#b0">[1,</ref><ref type="bibr" coords="2,406.15,498.42,11.15,8.80" target="#b21">22]</ref>. Research has also shown that current commercial search engines are still far from being effective in answering such unclear and underspecified queries <ref type="bibr" coords="2,389.24,522.33,14.61,8.80" target="#b25">[26]</ref>. This year's task continues the growth path identified in past years and focuses on conducting assessments on deeper pooled sets than was possible in previous years of the task. The subtasks within this year's IR challenge are similar to 2016's: ad hoc search, query variation, and multilingual search. A new subtask is also introduced, aimed at exploring methods to personalize health search.</p><p>This paper is structured as follows: Section 2 details the four sub-tasks we considered this year; Section 3 describes the data collection, while Section 4 described the query set and the methodology used to create it; Section 5 lists the participants and their submissions; Section 6 details the methods used to create the assessment pools and relevance criteria; Section 7 lists the evaluation metrics used for this Task; finally, Section 8 concludes this overview paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">IRTask1: Ad-hoc Search</head><p>This is a standard ad-hoc search task, aiming at retrieving information relevant to people seeking health advice on the web. In this year's task, we re-used the 2016 topics, with the aim of improving the relevance assessment pool and the collection reusability (increase the pool depth). Because we re-used last year's topics, we asked participants to explicitly exclude from their search results for each query documents that have been already assessed in 2016 (a list of these documents was provided to participants, along with a script for checking submissions). Participants were highly encouraged to devise methods that explicitly explore relevance feedback, i.e. using the already assessed documents to improve their submissions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">IRTask2: Personalized Search</head><p>This task develops on top of the IRTask1. Here, we aimed to personalize the retrieved list of search results so as to match user expertise, measured by how likely the person is to be satisfied with the content of a document with respect to the expertise level of the health information.</p><p>Each topic in the collection has 6 query variations: the first 3 have been issued by people with no medical knowledge, while the second 3 have been issued by medical experts. When evaluating results for a query variation, we use a parameter alpha to capture user expertise. The parameter determines the shape of the gain curve, so that documents at the right understandability level obtain the highest gains, with decaying gains being assigned to documents that do not suit the understandability level of the modelled user. We use α=0.0 for query variation 1, α=0.2 for query variation 2, α=0.4 for query variation 3, α=0.6 for query variation 4, α=0.8 for query variation 5 and, finally, α=1.0 for query variation 6. This models increasing levels of expertise across query variations for one topic. The intuition in such evaluation is that a person with no specific health knowledge (represented by query variant 1) would not understand complex and technical health material, while an expert (represented by query variant 6) would have little or no interest in reading introductory/basic material. For more details about this evaluation measure, we refer the reader to Section 7.</p><p>Note that the 2016 collection includes assessments for understandability (for the same documents for which relevance was assessed), thus they could be used by teams for training. These understandability assessments are contained in the qunder files (similar to qrels, but for understandability) available at https: //github.com/CLEFeHealth/CLEFeHealth2016Task3.</p><p>As for IRTask1, we asked participants to explicitly exclude from their search results for each query documents that have been already assessed in 2016.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">IRTask3: Query Variations</head><p>IRTask1 and 2 treated query variations for a topic independently. IRTask3 instead explicitly explores the dependencies among query variations for the same information need. The task aims to foster research into building search systems that are robust to query variations. Different query variations were generated for the same forum entry (i.e. topic/information need), thus capturing the variability intrinsic in how people formulate queries when searching to answer the same information need.</p><p>For IRTask3 we asked participants to submit a single set of results for each topic (each topic has 6 query variations). Participants were informed of which query variations relate to the same topic, and should have taken these variations into account when building their systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">IRTask4: Multilingual Search</head><p>The goal of this sub-task is to foster research in multilingual information retrieval, developing techniques to support users that can express their information need well in their native language and can read the results in English. This task, similar to the corresponding one in 2016, offers parallel queries in several languages (Czech, French, Hungarian, German, Polish, Spanish and Swedish).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset</head><p>The 2013, 2014 and 2015 IR tasks in the CLEF eHealth Lab used the Khresmoi collection <ref type="bibr" coords="4,178.45,407.43,11.37,8.80" target="#b7">[8,</ref><ref type="bibr" coords="4,189.81,407.43,7.58,8.80" target="#b6">7,</ref><ref type="bibr" coords="4,197.39,407.43,7.58,8.80" target="#b3">4,</ref><ref type="bibr" coords="4,204.97,407.43,7.58,8.80" target="#b4">5,</ref><ref type="bibr" coords="4,212.55,407.43,11.37,8.80" target="#b17">18]</ref>, a collection of about 1 million health web pages. Since last year we have set a new challenge to the participants by using the ClueWeb12-B13<ref type="foot" coords="4,151.78,429.79,3.97,6.16" target="#foot_0">6</ref> , a collection of more than 52 million web pages. As opposed to the Khresmoi collection, the crawl in ClueWeb12-B13 is not limited to certified Health On the Net websites and known health portals, but it is a higher-fidelity representation of a common Internet crawl, making the dataset more in line with the content current web search engines index and retrieve.</p><p>For participants who did not have access to the ClueWeb dataset, Carnegie Mellon University granted the organisers permission to make the dataset available through cloud computing instances <ref type="foot" coords="4,315.77,513.47,3.97,6.16" target="#foot_1">7</ref> provided by Microsoft Azure. The Azure instances that were made available to participants for the IR challenge included (1) the Clueweb12-B13 dataset, (2) standard indexes built with the Terrier 8 [12], Indri 9 [21] and Elasticsearch 10 toolkits, (3) additional resources such as a spam list <ref type="bibr" coords="5,199.37,118.93,9.96,8.80" target="#b1">[2]</ref>, Page Rank scores, anchor texts <ref type="bibr" coords="5,357.40,118.93,9.96,8.80" target="#b8">[9]</ref>, urls, etc. made available through the ClueWeb12 website.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Query Set</head><p>Although a considerable number of documents (25,000) were assessed in the 2016 task, we decided to further deepen the assessment pools this year. Thus, the same topics developed in 2016 were kept for the 2017 task. For crafting the topics, we considered real health information needs expressed by the general public through posts published in public health web forums. Forum posts were extracted from the AskDocs section of Reddit 11 . This section allows users to post a description of a medical case or ask a medical question seeking medical information such as diagnosis, or details regarding treatments. Users can also interact through comments. We selected posts that were descriptive, clear and understandable. Posts with information regarding the author or patient (in case the post author sought help for another person), such as demographics (age, gender), medical history and current medical condition, were preferred.</p><p>The posts were manually selected by a student, and a total of 50 posts were used for query creation. Each of the selected forum posts were presented to 6 query creators with different medical expertise: these included 3 medical experts (final year medical students undertaking rotations in hospitals) and 3 lay users with no prior medical knowledge.</p><p>A total of 300 queries were created. Queries were numbered using the following convention: the first 3 digits of a query id identify a post number (information need), while the last 3 digits of a query id identify each individual query creator. Expert query creators used the identifier 1, 2 and 3 and laypeople query creators used the identifiers 4, 5 and 6. Queries and the posts used to generate them can be accessed at https://github.com/CLEFeHealth/CLEFeHealth2017IRtask/ tree/master/queries.</p><p>For the query variations element of the task (sub-task 3), participants were told which queries were related to the same information need, to allow them to produce one set of results to be used as answer for all query variations of an information need.</p><p>For the multilingual element of the challenge (sub-task 4), Czech, French, Hungarian, German, Polish, Spanish and Swedish translations of the queries were provided. Queries were translated by medical experts hired through a professional translation company.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Participants Submission</head><p>Out of the 43 registered participating teams, 7 submitted runs. Table <ref type="table" coords="5,438.37,613.50,4.98,8.80">1</ref> lists the participating teams and the number of submitted runs for each one of the tasks. Teams were allowed to submit up to 7 runs and priority was sequentially given Table <ref type="table" coords="6,162.05,231.16,3.87,8.80">1</ref>: Participating teams and the number of submissions for each Sub-Task.</p><p>for assessment depending on the run number. Thus runs were sampled according to their priority: the priority of a run is expressed by the number that is assigned to the run by the participant, i.e., run 2 has a higher priority (and thus higher likelihood of inclusion in the assessment pool) than run 3. Run 1 (the baseline) has the highest priority; run 7 the lowest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Assessments</head><p>Assessments are currently in progress. Similar to the 2016 pool, this year the pool was created using the RBP-based Method A (Summing contributions) by Moffat et al. <ref type="bibr" coords="6,194.61,393.04,14.61,8.80" target="#b13">[14]</ref>, in which documents are weighted according to their overall contribution to the effectiveness evaluation as provided by the RBP formula (with p=0.8, following Park and Zhang <ref type="bibr" coords="6,309.27,416.95,14.76,8.80" target="#b18">[19]</ref>). This strategy was chosen because it was shown that it should be preferred over traditional fixed-depth or stratified pooling when deciding upon the pooling strategy to be used to evaluate systems under fixed assessment budget constraints <ref type="bibr" coords="6,321.40,452.82,14.61,8.80" target="#b10">[11]</ref>, as it is the case for this task.</p><p>Following the suggestions of Palotti et al. <ref type="bibr" coords="6,337.16,464.78,14.61,8.80" target="#b16">[17]</ref>, we adopted a two-stage approach to gather multi-dimensional relevance assessments. In the first stage of such a method, assessor time from highly-paid expert assessors is focused on assessing topical relevance and document trustworthiness (for relevant documents). In the second stage, understandability assessments are acquired employing less expert or less expensive assessors. The use of such a two-stage approach for collecting assessments has the potential of reducing the overall cost of evaluation, allowing assessment of more documents.</p><p>The relevance criteria created in 2016 were re-used this year. They were drafted considering the entirety of the forum posts used to create the queries, a link to the forum posts was also provided to the assessors. Relevance assessments were provided with respect to the grades Highly relevant, Somewhat relevant and Not Relevant. Readability/understandability and reliability/trustworthiness judgements were also collected for the documents in the assessment pool. These judgements were collected using a integer value between 0 and 100 (lower values meant harder to understand document / low reliability) provided by judges through a slider tool; these judgements were used to evaluate systems across different dimensions of relevance <ref type="bibr" coords="7,278.51,118.93,15.50,8.80" target="#b24">[25,</ref><ref type="bibr" coords="7,294.01,118.93,11.62,8.80" target="#b23">24]</ref>. All assessments were collected through a purposely customised version of the Relevation toolkit <ref type="bibr" coords="7,383.14,130.89,14.61,8.80" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Evaluation Metrics</head><p>System evaluation is conducted with both topical relevance centred metrics as well as understandability biased metrics in this task. Multiple evaluation metrics are used depending on the sub-task.</p><p>For IRTasks 1 and 4, evaluation is conducted with standard topical relevance centred metrics: Precision at 10 (P@10), Normalized Discounted Cumulative Gain at depth 10 (NDCG@10) and Rank Biased Precision with µ parameter set to 0.8 (RBP(0.8)), as done in previous years <ref type="bibr" coords="7,331.33,260.70,15.50,8.80" target="#b26">[27,</ref><ref type="bibr" coords="7,346.83,260.70,11.62,8.80" target="#b17">18,</ref><ref type="bibr" coords="7,358.45,260.70,7.75,8.80" target="#b4">5]</ref>.</p><p>Submissions to IRTask3 are evaluated using the same measures as for IR-Task1 but using the mean-variance evaluation framework (MVE) <ref type="bibr" coords="7,428.77,284.82,14.61,8.80" target="#b27">[28]</ref>. In this framework, evaluation results for each query variations for a topic are averaged and their variance also accounted for to compute a final system performance estimate. A script that implements the mean-variance evaluation framework is available at https://github.com/CLEFeHealth/CLEFeHealth2017IRtask.</p><p>Submissions to IRTask2 are evaluated by understandability biased metrics <ref type="bibr" coords="7,467.19,344.81,14.61,8.80" target="#b23">[24]</ref>. We consider the understandability-biased Rank Biased Precision, also with µ parameter set to 0.8 (uRBP(0.8)), and propose three new metrics for this subtask.</p><p>The first personalization-aware metric is a specialization of uRBP, α-uRBP, which uses an α parameter to model the kind of documents a user wants to read. We assume that α is a parameter that represents the understandability profile of an entity. A low α is assigned to items/documents/users that are experts, while a high α means the opposite. We assume that a user with a low α is interested in reading specialized documents as opposed to easy and introductory documents, while a high α represents users preferring the opposite, i.e. easy and introductory documents over specialized ones. We model in α-uRBP a penalty for the case in which a low α document is retrieved for a user that wants high α documents and vice versa. While we are still investigating which function is best to model this penalty, for now we assume penalty score drawn from a normal distribution. Figure <ref type="figure" coords="7,166.69,512.39,4.98,8.80" target="#fig_0">1</ref> shows an example in which a user is seeking to read documents with α=20 and other values for α would have a penalty associated to them according to a Gaussian curve centered at 20 and with standard deviation of 30. We use the standard deviation of 30 in this evaluation campaign -methods to better estimate these parameters are left for future work.</p><p>The second and third personalization-aware metrics are simple modifications of Precision at depth X. For the relevant documents found up to rank X, we inspect how far the understandability label of each document is to the expected value required by a user. We could penalize the absolute difference linearly (Lin-UndP@X) or using the same Gaussian curve as in α-uRBP (GaussianUndP@10). Note that lower values are better for LinUndP@10, meaning that the distance from the required understandability value is small, and higher values are better for GaussianUndP@10, as a value of 100 is the best value one could reach. Scripts that implement the α-uRBP, LinUndP@X and GaussianUndP@10 are also available at https://github.com/CLEFeHealth/CLEFeHealth2017IRtask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>This document describes the settings and evaluation methods used in the IR Task of CLEF 2017 eHealth Evaluation Lab. The task considers the problem of retrieving web pages for people seeking health information regarding medical conditions, treatments and suggestions. The task was divided into 4 sub-tasks: ad-hoc search, personalized search, query variations, and multilingual ad-hoc search. Seven teams participated in the task; relevance assessment is underway and assessments along with the participants results will be released at the CLEF 2017 conference (and will be available at the task's GitHub repository). Further development of the assessments made this year makes the collection stronger, providing to the research community a rich collection that goes beyond topical judgements. The understandability and trustworthiness assessments can be used to foster the development of retrieval methods for health information seeking on the web (e.g. <ref type="bibr" coords="8,242.75,559.91,15.50,8.80" target="#b15">[16,</ref><ref type="bibr" coords="8,258.24,559.91,11.62,8.80" target="#b14">15]</ref>).</p><p>Baseline runs, participant runs and results, assessments, topics and query variations are available online at the GitHub repository for this Task: https: //github.com/CLEFeHealth/CLEFeHealth2017IRtask/.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="8,134.77,274.51,345.83,8.80;8,134.77,286.47,345.83,8.80;8,134.77,298.42,334.26,8.80"><head>Fig. 1 :</head><label>1</label><figDesc>Fig.1:A Gaussian model for penalty. This example of a normal distribution has its peak (mean) at 20 and standard deviation of 30. A document with α=60 would be worth only 41% of the score of a document with the desired α=20.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_0" coords="4,144.73,569.87,160.05,7.37"><p>http://lemurproject.org/clueweb12/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_1" coords="4,144.73,580.03,335.87,7.92;4,144.73,590.99,335.86,7.92;4,144.73,601.95,335.86,7.92;4,144.73,612.91,335.86,7.92"><p>The organisers are thankful to Carnegie Mellon University, and in particular to Jamie Callan and Christina Melucci, for their support in obtaining the permission to redistribute ClueWeb 12. The organisers are also thankful to Microsoft Azure who provided the Azure cloud computing infrastructure that was made available to</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank <rs type="grantName">Microsoft Azure</rs> grant (<rs type="grantNumber">CRM</rs>:<rs type="grantNumber">0518649</rs>), <rs type="funder">ESF</rs> for the financial support for relevance assessments, and the many assessor for their hard work. This work is supported in part by a <rs type="grantName">Google Faculty Award</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ss4tDcw">
					<idno type="grant-number">CRM</idno>
					<orgName type="grant-name">Microsoft Azure</orgName>
				</org>
				<org type="funding" xml:id="_bEEpU5z">
					<idno type="grant-number">0518649</idno>
					<orgName type="grant-name">Google Faculty Award</orgName>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>https://github.com/CLEFeHealth/CLEFeHealth2017IRtask/</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,142.96,142.33,337.63,7.92;9,151.52,153.29,212.75,7.92" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,266.46,142.33,210.34,7.92">Shortcomings of health information on the internet</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Benigeri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pluye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,151.52,153.29,123.36,7.92">Health promotion international</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="381" to="386" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,164.21,337.64,7.92;9,151.52,175.17,329.07,7.92;9,151.52,186.13,40.45,7.92" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,367.64,164.21,112.95,7.92;9,151.52,175.17,186.53,7.92">Efficient and effective spam filtering and re-ranking for large web datasets</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,347.63,175.17,83.84,7.92">Information retrieval</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="441" to="465" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,197.04,337.63,7.92;9,151.52,208.00,181.45,7.92" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="9,186.83,197.04,289.90,7.92">Health topics: 80% of internet users look for health information online</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Pew Internet &amp; American Life Project</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,218.92,337.63,7.92;9,151.52,229.88,329.07,7.92;9,151.52,240.84,329.07,7.92;9,151.52,251.80,190.25,7.92" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,271.63,229.88,208.96,7.92;9,151.52,240.84,325.19,7.92">ShARe/CLEF eHealth Evaluation Lab 2013, Task 3: Information retrieval to address patients&apos; questions when reading clinical reports</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Leveling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Salantera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,151.52,251.80,137.93,7.92">CLEF 2013 Online Working Notes</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">8138</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,262.71,337.63,7.92;9,151.52,273.67,329.07,7.92;9,151.52,284.63,329.07,7.92;9,151.52,295.59,220.61,7.92" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,262.93,273.67,217.66,7.92;9,151.52,284.63,167.89,7.92">ShARe/CLEF eHealth Evaluation Lab 2014, Task 3: User-centred health information retrieval</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pecina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">M</forename><surname>Gareth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,343.72,284.63,136.88,7.92;9,151.52,295.59,133.21,7.92">CLEF 2014 Evaluation Labs and Workshop: Online Working Notes</title>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,306.51,337.63,7.92;9,151.52,317.47,329.07,7.92;9,151.52,328.43,329.07,7.92;9,151.52,339.39,229.85,7.92" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,256.02,317.47,161.32,7.92">Clef 2017 ehealth evaluation lab overview</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Spijker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,434.71,317.47,45.88,7.92;9,151.52,328.43,265.16,7.92">Proceedings of CLEF 2017 -8th Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="9,424.45,328.43,56.14,7.92;9,151.52,339.39,110.96,7.92">Lecture Notes in Computer Science (LNCS</title>
		<meeting>CLEF 2017 -8th Conference and Labs of the Evaluation Forum</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017-09">September 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,350.30,337.64,7.92;9,151.52,361.26,329.07,7.92;9,151.52,372.22,329.07,7.92;9,151.52,383.18,254.96,7.92" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,351.92,350.30,128.67,7.92;9,151.52,361.26,157.93,7.92">Building evaluation datasets for consumer-oriented information retrieval</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,327.68,361.26,152.91,7.92;9,151.52,372.22,265.23,7.92">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC 2016)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,394.10,337.64,7.92;9,151.52,405.06,218.60,7.92" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,205.36,394.10,271.31,7.92">Medical information retrieval: an instance of domain-specific search</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,163.04,405.06,106.49,7.92">Proceedings of SIGIR 2012</title>
		<meeting>SIGIR 2012</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1191" to="1192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,415.98,337.64,7.92;9,151.52,426.93,153.46,7.92" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="9,265.41,415.98,210.93,7.92">Mirex: Mapreduce information retrieval experiments</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hauff</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1004.4489</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,142.61,437.85,337.98,7.92;9,151.52,448.81,210.36,7.92" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="9,274.98,437.85,205.61,7.92;9,151.52,448.81,117.70,7.92">Relevation! an open source system for information retrieval relevance assessment</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,142.61,459.73,337.97,7.92;9,151.52,470.69,329.07,7.92;9,151.52,481.65,329.07,7.92;9,151.52,492.61,117.25,7.92" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,421.84,459.73,58.75,7.92;9,151.52,470.69,208.25,7.92">The impact of fixed-cost pooling strategies on test collection bias</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lipani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Mihai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,383.45,470.69,97.14,7.92;9,151.52,481.65,305.42,7.92">Proceedings of the 2016 International Conference on The Theory of Information Retrieval, ICTIR &apos;16</title>
		<meeting>the 2016 International Conference on The Theory of Information Retrieval, ICTIR &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,503.52,337.98,7.92;9,151.52,514.48,317.46,7.92" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,381.03,503.52,99.56,7.92;9,151.52,514.48,131.47,7.92">From puppy to maturity: Experiences in developing terrier</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,290.54,514.48,95.79,7.92">Proc. of OSIR at SIGIR</title>
		<meeting>of OSIR at SIGIR</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="60" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,525.40,337.98,7.92;9,151.52,536.36,319.69,7.92" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="9,259.53,525.40,221.07,7.92;9,151.52,536.36,219.19,7.92">Online health: Untangling the web. evidence from the bupa health pulse 2010 international healthcare survey</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mcdaid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Park</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="9,142.61,547.28,337.97,7.92;9,151.52,558.24,237.92,7.92" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,251.44,547.28,229.15,7.92;9,151.52,558.24,30.13,7.92">Rank-biased precision for measurement of retrieval effectiveness</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,189.51,558.24,89.42,7.92">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="2008-12">Dec. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,569.16,337.98,7.92;9,151.52,580.11,329.07,7.92;9,151.52,591.07,329.07,7.92;9,151.52,602.03,72.44,7.92" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,199.88,569.16,280.71,7.92;9,151.52,580.11,104.40,7.92">Beyond topical relevance: Studying understandability and reliability in consumer health search</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,276.67,580.11,203.92,7.92;9,151.52,591.07,272.12,7.92">Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 39th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1167" to="1167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,612.95,337.97,7.92;9,151.52,623.91,329.07,7.92;9,151.52,634.87,317.61,7.92" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,373.09,612.95,107.50,7.92;9,151.52,623.91,144.24,7.92">Ranking health web pages with relevance and understandability</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,312.87,623.91,167.72,7.92;9,151.52,634.87,290.00,7.92">Proceedings of the 39th international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 39th international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,645.79,337.97,7.92;9,151.52,656.74,329.07,7.92;10,151.52,119.62,329.07,7.92;10,151.52,130.58,329.07,7.92;10,151.52,141.54,213.03,7.92" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,414.52,645.79,66.07,7.92;9,151.52,656.74,329.07,7.92;10,151.52,119.62,87.48,7.92">Assessors Agreement: A Case Study across Assessor Type, Payment Levels, Query Variations and Relevance Dimensions</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bernhardt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,260.61,119.62,219.98,7.92;10,151.52,130.58,329.07,7.92;10,151.52,141.54,44.40,7.92">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 7th International Conference of the CLEF Association, CLEF&apos;16 Proceedings</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,152.50,337.97,7.92;10,151.52,163.46,329.07,7.92;10,151.52,174.42,329.07,7.92" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,210.93,163.46,121.47,7.92;10,358.00,163.46,122.58,7.92;10,151.52,174.42,99.16,7.92">Task 2: Retrieving Information about Medical Symptoms</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanburyn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pecina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,269.12,174.42,134.93,7.92">CLEF 2015 Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note>CLEF eHealth Evaluation Lab</note>
</biblStruct>

<biblStruct coords="10,142.62,185.37,337.98,7.92;10,151.52,196.33,329.07,7.92;10,151.52,207.29,74.80,7.92" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,254.42,185.37,226.17,7.92;10,151.52,196.33,34.17,7.92">On the distribution of user persistence for rank-biased precision</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,203.56,196.33,272.40,7.92">Proceedings of the 12th Australasian document computing symposium</title>
		<meeting>the 12th Australasian document computing symposium</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,218.25,337.97,7.92;10,151.52,229.21,329.07,7.92;10,151.52,240.17,329.07,7.92;10,151.52,251.13,20.99,7.92" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="10,352.09,218.25,128.50,7.92;10,151.52,229.21,329.07,7.92;10,151.52,240.17,100.80,7.92">An investigation of the effectiveness of concept-based approach in medical information retrieval GRIUM@ CLEF2014eHealthTask 3</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,275.67,240.17,200.73,7.92">Proceedings of the CLEF eHealth Evaluation Lab</title>
		<meeting>the CLEF eHealth Evaluation Lab</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,262.09,337.98,7.92;10,151.52,273.05,329.07,7.92;10,151.52,284.00,321.03,7.92" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="10,378.32,262.09,102.28,7.92;10,151.52,273.05,159.00,7.92">Indri: A language modelbased search engine for complex queries</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,329.83,273.05,150.76,7.92;10,151.52,284.00,120.57,7.92">Proceedings of the International Conference on Intelligent Analysis</title>
		<meeting>the International Conference on Intelligent Analysis<address><addrLine>Amherst, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,294.96,337.98,7.92;10,151.52,305.92,210.33,7.92" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="10,274.31,294.96,206.28,7.92;10,151.52,305.92,90.43,7.92">Cyberchondria: studies of the escalation of medical concerns in web search</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,249.96,305.92,44.44,7.92">ACM TOIS</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,316.88,337.98,7.92;10,151.52,327.84,329.07,7.92;10,151.52,338.80,163.25,7.92" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="10,416.63,316.88,63.97,7.92;10,151.52,327.84,250.35,7.92">Using discharge summaries to improve information retrieval in clinical domain</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">-I</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Masanz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,423.55,327.84,57.04,7.92;10,151.52,338.80,134.98,7.92">Proceedings of the CLEF eHealth Evaluation Lab</title>
		<meeting>the CLEF eHealth Evaluation Lab</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,349.76,337.98,7.92;10,151.52,360.72,60.54,7.92" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="10,198.82,349.76,242.53,7.92">Understandability biased evaluation for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,459.65,349.76,20.94,7.92;10,151.52,360.72,31.34,7.92">Proc. of ECIR</title>
		<meeting>of ECIR</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,371.68,337.97,7.92;10,151.52,382.63,329.07,7.92;10,151.52,393.59,111.20,7.92" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="10,277.03,371.68,203.55,7.92;10,151.52,382.63,127.85,7.92">Integrating understandability in the evaluation of consumer health search engines</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Koopman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,302.73,382.63,177.86,7.92;10,151.52,393.59,46.50,7.92">Medical Information Retrieval Workshop at SIGIR 2014</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,404.55,337.98,7.92;10,151.52,415.51,329.07,7.92;10,151.52,426.47,227.59,7.92" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="10,314.35,404.55,166.25,7.92;10,151.52,415.51,270.48,7.92">Diagnose this if you can: On the effectiveness of search engines in finding medical self-diagnosis information</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,443.64,415.51,36.95,7.92;10,151.52,426.47,97.20,7.92">Advances in Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="562" to="567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,437.43,337.97,7.92;10,151.52,448.39,329.07,7.92;10,151.52,459.35,329.07,7.92;10,151.52,470.31,275.11,7.92" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="10,271.70,448.39,208.89,7.92;10,151.52,459.35,194.18,7.92">The IR Task at the CLEF eHealth Evaluation Lab 2016: User-centred Health Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pecina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Budaher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Deacon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,365.87,459.35,114.73,7.92;10,151.52,470.31,151.31,7.92">CLEF 2016 Evaluation Labs and Workshop: Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2016-09">September 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,481.26,337.98,7.92;10,151.52,492.22,329.07,7.92;10,151.52,503.18,329.07,7.92;10,151.52,514.14,20.99,7.92" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="10,313.74,481.26,166.85,7.92;10,151.52,492.22,141.95,7.92">Query variations and their effect on comparing information retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,311.27,492.22,169.32,7.92;10,151.52,503.18,235.22,7.92">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="691" to="700" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
