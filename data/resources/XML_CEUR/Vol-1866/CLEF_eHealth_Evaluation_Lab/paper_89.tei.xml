<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,140.38,115.96,334.61,12.62;1,136.94,133.89,341.48,12.62;1,158.13,151.82,299.11,12.62">Combining Inter-Review Learning-to-Rank and Intra-Review Incremental Training for Title and Abstract Screening in Systematic Reviews</title>
				<funder>
					<orgName type="full">Atypon Systems Inc</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,147.51,189.49,91.73,8.74"><forename type="first">Antonios</forename><surname>Anagnostou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">Aristotle University of Thessaloniki</orgName>
								<address>
									<postCode>54124</postCode>
									<settlement>Thessaloniki</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,247.52,189.49,98.25,8.74"><forename type="first">Athanasios</forename><surname>Lagopoulos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">Aristotle University of Thessaloniki</orgName>
								<address>
									<postCode>54124</postCode>
									<settlement>Thessaloniki</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,353.81,189.49,89.53,8.74"><forename type="first">Grigorios</forename><surname>Tsoumakas</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">Aristotle University of Thessaloniki</orgName>
								<address>
									<postCode>54124</postCode>
									<settlement>Thessaloniki</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,270.82,201.45,73.72,8.74"><forename type="first">Ioannis</forename><surname>Vlahavas</surname></persName>
							<email>vlahavas@csd.auth.gr</email>
							<affiliation key="aff0">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">Aristotle University of Thessaloniki</orgName>
								<address>
									<postCode>54124</postCode>
									<settlement>Thessaloniki</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,140.38,115.96,334.61,12.62;1,136.94,133.89,341.48,12.62;1,158.13,151.82,299.11,12.62">Combining Inter-Review Learning-to-Rank and Intra-Review Incremental Training for Title and Abstract Screening in Systematic Reviews</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1353B7AD9AC966C77CF45DBE2B432BE8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe the approach we employed for Task II of CLEF eHealth 2017, concerning title and abstract screening in diagnostic test accuracy reviews. Our approach combines a learning-to-rank model trained across multiple reviews with a model focused on the given review, incrementally trained based on relevance feedback. Our learning-to-rank model is built using extreme gradient boosting on features computed by considering the similarity of different fields of the documents (title, abstract), with different fields of the topics (title, query). Our incrementally trained model is a support vector machine trained on a TF-IDF representation of title and abstract of the documents. The results of our approach are promising, reaching 0.658 normalized cumulative gain in the top 10 ranked documents in the simple evaluation setting and 0.846 in the cost-effective evaluation setting, the latter assuming feedback can be obtained from an intermediate user/oracle instead of the end-user.</p><p>Cosine similarity of TF-IDF representations T -D</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Evidence-Based Medicine (EBM) is an approach to medical practice that makes use of the current best clinical evidence in making decisions about the care and treatment of individual patients <ref type="bibr" coords="1,274.13,496.99,14.61,8.74" target="#b12">[13]</ref>. Researchers in the medical domain conduct systematic research to find the best available evidence and form review articles summarizing their discoveries on a certain topic. These systematic reviews usually include three stages:</p><p>1. Document retrieval. Experts build a Boolean query and submit it to a medical database, which returns a set of possibly relevant documents. Boolean queries typically have very complicated syntax and consist of multiple lines. Such a query can be found for reference in Listing 1.1. 2. Title and abstract screening. Experts go through the title and abstract of the set of documents retrieved by the previous stage and perform a first level of screening. 3. Document screening. Experts go through the full text of each document that passes the screening of the previous stage to decide whether it will be included in their systematic review.</p><p>Considering the rapid pace with which libraries of medical articles are expanding, Systematic Review can be a very difficult and time-consuming task.</p><p>Task II <ref type="bibr" coords="2,185.11,143.49,10.52,8.74" target="#b6">[7]</ref> [9] of CLEF eHealth 2017 lab concerns Technologically Assisted Reviews in Empirical Medicine, focusing on Diagnostic Test Accuracy (DTA), and aims to automate the second part of this process by ranking the set of documents retrieved in the first stage. Its goal is to produce an efficient ordering of the documents retrieved in the first stage, by reducing the amount of documents that experts have to go through for their reviews. This can be accomplished in two stages: by classifying documents (relevant or not) and by thresholding, ie. showing only a subset of the returned documents (the ones that are highest on the list). It is the first time this task take place and very little research is previously done on the topic. Previous approaches on this problem use an ensemble of Support Vector Machines (SVM), built over different feature spaces (documents' titles, text, etc.). <ref type="bibr" coords="2,212.76,620.25,15.50,8.74" target="#b14">[15]</ref> Other approaches use Active Learning techniques to improve results' relevance by utilizing domain experts' knowledge. <ref type="bibr" coords="2,427.75,632.21,15.50,8.74" target="#b13">[14]</ref> Finally, Learning to Rank (LTR) approaches have also been tested on biomedical data and have shown promising results. <ref type="bibr" coords="2,287.80,656.12,15.50,8.74" target="#b11">[12]</ref> Our approaches on the task are based on binary classification methods combined with existing Learning to Rank techniques. We experimented with different classifiers and we also introduce a hybrid classification mechanism which consists of two parts: an inter-topic classifier, based on features computed on the training set and an intra-topic classifier, which is trained upon the test set documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task overview</head><p>In CLEF eHealth 2017 Task II, participants were given a total of 20 topics with the corresponding document IDs. An example of such topic can be find in Listing 1.1. Summarizing the topics' structure, they all contain:</p><p>1. A distinct topic id, 2. A topic title, 3. An Ovid MEDLINE query and 4. a set of documents' PIDs that are returned from the query.</p><p>Similarly, documents contain the following fields:</p><formula xml:id="formula_0" coords="3,138.97,336.18,78.23,32.20">1. A distinct pid, 2. A title, 3.</formula><p>The abstract text and 4. Mesh headings, based on their taxonomy</p><p>The test set comprised of topics in similar structure, summing up to a total of 30 topics.</p><p>For both the training and the test set, participants were also provided with the corresponding document relevance sheet, in which relevance was provided in the format shown in Listing 1.2, where 0 denotes negative relevance and 1 denotes positive one. For participants' evaluation, the task defined the following metrics:</p><p>1. Area under the recall-precision curve, i.e. Average Precision (metric in task's evaluation script: ap)</p><p>2. Minimum number of documents returned to retrieve all R relevant documents (metric in task's evaluation script: last rel) a measure for optimistic thresholding 3. Work Saved over Sampling @ Recall (metric in task's evaluation script:</p><p>wss 100, and wss 95)</p><formula xml:id="formula_1" coords="4,244.67,189.50,141.76,22.31">W SS@Recall = T N + F N N -(1 -Recall)</formula><p>4. Area under the cumulative recall curve normalized by the optimal area (metric in task's evaluation script: norm area)</p><formula xml:id="formula_2" coords="4,259.14,259.98,112.31,23.89">optimal area = R * N - R 2<label>2</label></formula><p>5. Normalized cumulative gain @ 0% to 100% of documents shown (metric in task's evaluation script: NCG@0 to NCG@100) 6. Total cost uniform (metric in task's evaluation script:</p><formula xml:id="formula_3" coords="4,279.00,320.67,201.59,41.70">total cost uniform) m R * (N -n) * C p</formula><p>where:</p><p>-N is the total number of documents in the collection n is the number of documents shown to the user -(N -n) is the number of documents not shown to the user m is the number of missing relevant documents -C a is the cost paid for experts/users reviewing returned documents' abstracts to determine their relevance, and -C p = 2 * C a 7. Total cost weighted (metric in task's evaluation script: total cost weighted)</p><formula xml:id="formula_4" coords="4,138.97,498.78,218.11,52.76">m i=1 1 2 i (N -n) * C p 8.</formula><p>Reliability (metric in task's evaluation script: loss er) <ref type="bibr" coords="4,392.21,542.80,10.52,8.74" target="#b3">[4]</ref> Reliability = loss r + loss e where loss r = (1 -recall) 2 (metric in task's evaluation script: loss r) loss e = n R+100 * 100 N ) 2 (metric in task's evaluation script: loss e) recall = nr R (metric in task's evaluation script: r) and n r is the number of relevant document found and R the total number of relevant documents </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Approach</head><p>The architecture of our approach, which comprises two models, is depicted in Figures <ref type="figure" coords="5,169.61,357.75,23.30,8.74" target="#fig_5">1 to 3</ref>. The first model is a learning-to-rank binary classifier that considers a topic-document pair as input and whether the document is relevant for the topic or not as output (Figure <ref type="figure" coords="5,269.40,381.66,3.87,8.74" target="#fig_2">1</ref>). This inter-topic model is used at a first stage of our approach in order to obtain an initial ranking of all documents returned by the Boolean query of an unseen test topic. The second model is a standard binary classifier that considers a document of the given test topic as input and whether this document is relevant to the test topic as output. This intra-topic model is incrementally trained based on relevance feedback that it requests after returning one or more documents to the user. The first version of this model is trained based on feedback obtained from the top k ranked documents by the inter-topic model (Figure <ref type="figure" coords="5,250.13,477.30,3.87,8.74" target="#fig_3">2</ref>). The re-ranking of subsequent documents is from then on based solely on the intra-topic model (Figure <ref type="figure" coords="5,371.41,489.26,3.87,8.74" target="#fig_4">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Inter-topic model</head><p>For each topic, document pair, we extracted a number of features, following the paradigm of <ref type="bibr" coords="5,205.75,552.91,14.61,8.74" target="#b11">[12]</ref>. The majority of the features were computed by considering the similarity of different fields of the document (title, abstract), with different fields of the topic (title, query), using a variety of similarity metrics, such as the number of common terms between the topic and the document parts, Levenshtein distance, cosine similarity or OKAPI BM25 <ref type="bibr" coords="5,323.32,600.73,9.96,8.74" target="#b7">[8]</ref>. We also computed features based solely on the topic. In order to use the rich information available in the query field of the topics, we used Polyglot<ref type="foot" coords="5,206.57,635.21,3.97,6.12" target="#foot_0">1</ref> , a JavaScript tool that can parse and produce a full syntactical  tree of Ovid MEDLINE queries. In particular, we extracted those medical subject headings (MeSH) that should characterize the retrieved documents, avoiding the ones that are negated in the query syntax. As an example, according to Polyglot, the MeSH terms found in the Ovid MEDLINE query of Listing 1.1 are the following:</p><p>-Ovarian neoplasms -Fallopian Tube Neoplasms, -Laparoscopy, animals (negated), humans</p><p>We eventually settled to the 24 features that can be found in Table <ref type="table" coords="7,449.13,118.99,3.87,8.74">1</ref>, after extensive investigation of the performance of our model with additional variations of these features. Two of these features are only topic-dependent, denoted with T in the Category column of Table <ref type="table" coords="7,312.67,154.86,3.87,8.74">1</ref>, as opposed to the rest 22 of the features that dependent on both the topic and the document, denoted with T -D. The notation used in the Description column of Table <ref type="table" coords="7,373.73,178.77,4.98,8.74">1</ref> is explained here:</p><p>t represents the title of each topic, consisting of tokens t i .</p><p>m represent the MeSH terms extracted from the query of each topic.</p><p>d represents the title or abstract of a document, consisting of |d| tokens d j .</p><p>c(x, d) denotes the number of occurrences of title token or MeSH term x of the topic in document d.</p><p>We have experimented with a variety of different classifiers, including Support Vector Machines <ref type="bibr" coords="7,235.80,272.05,9.96,8.74" target="#b4">[5]</ref>, Gradient Boosting <ref type="bibr" coords="7,339.78,272.05,9.96,8.74" target="#b5">[6]</ref>, eXtreme Gradient Boosting (XGBoost) <ref type="bibr" coords="7,186.26,284.01,10.52,8.74" target="#b2">[3]</ref> and LamdaMART <ref type="bibr" coords="7,284.08,284.01,9.96,8.74" target="#b1">[2]</ref>. The best results were achieved with XG-Boost. We have also experimented with a variety of undersampling techniques, such as EasyEnsemble <ref type="bibr" coords="7,235.16,307.92,14.61,8.74" target="#b9">[10]</ref>, but this did not lead to accuracy improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Intra-topic model</head><p>The first version of the intra-topic model is trained based on the top k documents as ranked by the inter-topic model. We then iteratively re-rank the rest of the documents, expanding the training set of the intra-topic model with the topranked document, until the whole list has been added to the training set or a certain threshold is reached. This iterative feedback and reranking mechanism is described in detail in Algorithm 1. For the local classifier, a standard TF-IDF vectorization was used, enhanced with English stop words removal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation setups and results</head><p>Task II of CLEF eHealth 2017 supported two experimental setups: one for simple evaluation and one for cost effective.</p><p>In the simple evaluation, our aim was to utilize relevance feedback as much as possible without any cap or limitation, so as to experiment with different techniques for boosting ranking metrics. In the cost-effective evaluation, we have implemented thresholding by limiting the amount of documents (column Threshold in Table <ref type="table" coords="7,173.09,548.52,4.43,8.74" target="#tab_0">2</ref>) that we request feedback for and by not showing to users documents for which negative relevance was received.</p><p>In Table <ref type="table" coords="7,190.78,572.43,4.98,8.74" target="#tab_1">3</ref> you can find the official results for the simple evaluation setup. In Table <ref type="table" coords="7,177.25,584.39,4.98,8.74" target="#tab_2">4</ref> you can find the results for the cost effective evaluation, as they derive from the evaluation script provided by the task's organizers. Please note, that because of undergoing software enhancements in the script some metrics in the cost-effective evaluation might be inaccurate, e.g. the total cost metrics, as they have not be adjusted to different run outputs for that setup. Each of the runs have a parameterized version of HybridRankSVM and thresholding points, which are listed in Table <ref type="table" coords="7,245.54,656.12,3.87,8.74" target="#tab_0">2</ref>.  In conclusion, in this paper we introduced a hybrid classification approach for medical document ranking. Our approach constructs a global classification model based on LTR features of the training documents, produces an initial ranking for the test documents and then iteratively asks for feedback and rerank them based on the acquired relevance.</p><formula xml:id="formula_5" coords="9,149.71,259.73,294.45,23.14">f inalRanking k = R k ; while not length(f inalRanking) == n OR length(f inalRanking) == t f</formula><p>As future work, we believe that experimentation with more features, such as semantic representations (e.g. word2vec <ref type="bibr" coords="11,312.26,216.42,14.61,8.74" target="#b10">[11]</ref>, LDA <ref type="bibr" coords="11,359.23,216.42,9.96,8.74" target="#b0">[1]</ref>, etc.) or different undersampling setups could boost metrics even further. Moreover, it would be worthy to experiment with other classification approaches as well, such as neural networks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,221.51,261.49,172.34,7.89;2,135.55,277.79,83.11,7.47;2,135.55,299.71,343.16,7.47;2,135.60,310.67,207.36,7.47;2,135.55,332.59,32.64,7.47;2,135.47,343.54,123.10,7.47;2,135.61,354.50,139.90,7.47;2,135.39,365.46,286.99,7.47;2,135.39,376.42,247.29,7.47;2,135.66,387.38,292.38,7.47;2,135.39,398.34,281.34,7.47;2,135.24,409.30,162.87,7.47;2,135.24,420.26,89.44,7.47;2,135.47,431.22,89.21,7.47;2,135.62,442.17,100.35,7.47;2,135.61,453.13,94.71,7.47;2,135.64,464.09,117.28,7.47;2,135.63,475.05,111.63,7.47;2,135.24,486.01,123.17,7.47;2,135.24,496.97,44.10,7.47;2,135.47,507.93,151.34,7.47;2,135.39,518.89,49.58,7.47;2,135.52,540.80,27.02,7.47;2,180.79,551.76,43.51,7.47;2,180.66,562.72,15.54,7.47"><head>Listing 1 . 1 .</head><label>11</label><figDesc>Example of query in data set Topic : CD009786 Title : Laparoscopy for diagnosing resectability of disease in patients with advanced ovarian cancer Query : exp Ovarian Neoplasms / Fallopian Tube Neoplasms / (( ovar * or fallopian tube *) adj5 ( cancer * or tumor * or tumour * or adenocarcinoma * or carcino * or cystadenocarcinoma * or choriocarcinoma * or malignan * or neoplas * or metasta * or mass or masses )). tw , ot . ( thecoma * or luteoma *). tw , ot . 1 or 2 or 3 or 4 exp Laparoscopy / laparoscop *. tw , ot . celioscop *. tw , ot . peritoneoscop *. tw , ot . abdominoscop *. tw , ot .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,201.42,469.98,212.51,7.89;3,135.60,485.46,43.51,7.47;3,208.67,485.46,55.20,7.47;3,299.05,485.46,4.71,7.47;3,135.60,496.42,43.51,7.47;3,208.67,496.42,60.83,7.47;3,299.05,496.42,4.71,7.47;3,135.60,507.38,43.51,7.47;3,208.67,507.38,55.20,7.47;3,299.05,507.38,4.71,7.47;3,135.60,518.34,43.51,7.47;3,208.67,518.34,60.83,7.47;3,299.05,518.34,4.71,7.47;3,135.60,529.29,43.51,7.47;3,208.67,529.29,60.83,7.47;3,299.05,529.29,4.71,7.47;3,135.60,540.25,43.51,7.47;3,208.67,540.25,60.83,7.47;3,299.05,540.25,4.71,7.47;3,135.47,551.21,15.53,7.47;3,135.60,573.13,43.51,7.47;3,208.67,573.13,60.83,7.47;3,299.05,573.13,4.71,7.47;3,135.60,584.09,43.51,7.47;3,208.67,584.09,60.83,7.47;3,299.05,584.09,4.71,7.47;3,135.60,595.05,43.51,7.47;3,208.67,595.05,60.83,7.47;3,299.05,595.05,4.71,7.47;3,135.47,606.01,15.53,7.47"><head>Listing 1 . 2 .</head><label>12</label><figDesc>Example of query/document relevance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,224.59,286.83,166.17,7.89;5,186.64,115.84,242.10,156.23"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Training of the inter-topic model.</figDesc><graphic coords="5,186.64,115.84,242.10,156.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,137.61,304.13,340.14,7.89;6,186.64,323.80,242.11,158.48"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Ranking with the inter-topic model. Initial training of the intra-topic model.</figDesc><graphic coords="6,186.64,323.80,242.11,158.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="6,134.77,497.05,345.83,7.89;6,134.77,508.03,88.09,7.86"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Continuous re-ranking of subsequent documents and incremental re-training of the intra-topic model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="9,142.24,121.70,264.88,8.77;9,149.71,135.33,315.05,7.89;9,189.63,146.31,266.30,7.86;9,189.63,157.27,263.16,8.35;9,189.63,168.23,148.97,8.35;9,149.71,179.16,227.88,7.89;9,149.71,190.15,85.04,7.86;9,411.92,190.79,61.20,7.47;9,149.71,201.08,70.71,7.89;9,165.05,212.07,84.72,7.86;9,149.71,226.86,29.70,7.86;9,149.71,237.79,320.88,7.89;9,165.05,248.77,48.25,7.86"><head>Algorithm 1 :</head><label>1</label><figDesc>Reranking algorithm of the intra-topic model Input : The ranked documents R, of length n, as produced by the XGBoost classifier, initial training step k, initial local training step stepinit, secondary local training step step secondary , step change threshold tstep, final threshold t f inal (optional) Output: Final ranking of documents R -f inalRanking f inalRanking ← () ; // empty list for i = 1 to k do f inalRankingi ← Ri k ← k; while not f inalRanking contains both relevant and irrelevant documents do k ← k + 1;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="9,135.70,274.49,337.42,380.21"><head>Table 2 .</head><label>2</label><figDesc>Run details for CLEF eHealth Task II</figDesc><table coords="9,444.85,274.49,28.27,8.37"><row><cell>inal do</cell></row></table><note coords="9,135.70,330.66,9.03,6.14;9,165.05,329.29,155.12,7.89;9,135.70,341.62,9.03,6.14;9,180.39,340.27,61.18,7.86;9,135.70,352.57,9.03,6.14;9,165.05,351.21,16.87,7.89;9,135.70,363.53,9.03,6.14;9,180.39,362.19,82.56,8.35;9,135.70,378.32,9.03,6.14;9,165.05,376.96,104.33,7.89;9,135.70,389.28,9.03,6.14;9,180.39,387.94,148.10,8.68"><p>11 if length(f inalRanking) &lt; tstep then 12 step = stepinit; 13 else 14 step = step secondary ; 15 for i = k to k + step do 16 f inalRankingi ← localRanking i-k ;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="10,182.13,340.84,251.10,264.43"><head>Table 3 .</head><label>3</label><figDesc>Simple Evaluation results for CLEF eHealth Task II</figDesc><table coords="10,214.03,426.05,187.31,179.22"><row><cell>Run Id</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell></row><row><cell>Recall</cell><cell cols="4">0.928 0.928 0.928 0.928</cell></row><row><cell cols="5">Average Precision 0.77 0.796 0.795 0.796</cell></row><row><cell>wss 95</cell><cell cols="4">0.579 0.613 0.612 0.612</cell></row><row><cell>wss 100</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>last rel</cell><cell cols="4">2025 1784 1797 1775</cell></row><row><cell>NCG@10</cell><cell cols="4">0.773 0.846 0.844 0.846</cell></row><row><cell>NCG@20</cell><cell cols="4">0.901 0.932 0.931 0.932</cell></row><row><cell>NCG@100</cell><cell cols="4">0.984 0.984 0.984 0.984</cell></row><row><cell cols="5">Cost(weighted) 3918.7 3918.7 3918.7 3918.7</cell></row><row><cell cols="5">Cost(uniform) 3918.7 3918.7 3918.7 3918.7</cell></row><row><cell>norm area</cell><cell cols="4">0.91 0.918 0.918 0.918</cell></row><row><cell>loss er</cell><cell cols="4">0.561 0.561 0.561 0.561</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,167.57,619.24,280.21,7.89"><head>Table 4 .</head><label>4</label><figDesc>Cost-Effective Evaluation results for CLEF eHealth Task II</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,144.73,656.80,166.76,7.86"><p>https://github.com/CREBP/sra-polyglot</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work has been partially funded by <rs type="funder">Atypon Systems Inc</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ID Description</head><p>Category Topic field Document field </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="11,142.96,369.49,337.64,7.86;11,151.52,380.45,171.63,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,294.82,369.49,102.95,7.86">Latent dirichlet allocation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,404.31,369.49,76.29,7.86;11,151.52,380.45,71.16,7.86">Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-01">Jan. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,391.70,337.63,7.86;11,151.52,402.66,89.09,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,206.10,391.70,232.17,7.86">From ranknet to lambdarank to lambdamart: An overview</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,445.11,391.70,35.48,7.86">Learning</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">23-581</biblScope>
			<biblScope unit="page">81</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,413.92,337.63,7.86;11,151.52,424.88,329.07,7.86;11,151.52,435.84,161.14,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,247.50,413.92,164.04,7.86">Xgboost: A scalable tree boosting system</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,432.52,413.92,48.07,7.86;11,151.52,424.88,329.07,7.86;11,151.52,435.84,49.45,7.86">Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,447.09,337.64,7.86;11,151.52,458.05,329.07,7.86;11,151.52,469.01,329.07,7.86;11,151.52,479.97,329.07,8.11;11,151.52,491.57,32.95,7.47" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,286.48,447.09,194.11,7.86;11,151.52,458.05,59.53,7.86">Engineering quality and reliability in technologyassisted review</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Grossman</surname></persName>
		</author>
		<idno type="DOI">10.1145/2911451.2911510</idno>
		<ptr target="http://doi.acm.org/10.1145/2911451.2911510" />
	</analytic>
	<monogr>
		<title level="m" coord="11,234.68,458.05,245.91,7.86;11,151.52,469.01,248.82,7.86;11,454.80,469.01,25.79,7.86;11,151.52,479.97,10.75,7.86">Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="75" to="84" />
		</imprint>
	</monogr>
	<note>SIGIR &apos;16</note>
</biblStruct>

<biblStruct coords="11,142.96,502.18,337.63,7.86;11,151.52,513.14,224.23,8.12" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,244.85,502.18,96.62,7.86">Support-vector networks</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<idno type="DOI">10.1023/A:1022627411411</idno>
		<ptr target="http://dx.doi.org/10.1023/A:1022627411411" />
	</analytic>
	<monogr>
		<title level="j" coord="11,348.16,502.18,71.72,7.86">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,524.40,337.63,7.86;11,151.52,535.36,124.50,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,219.89,524.40,115.32,7.86">Stochastic gradient boosting</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,343.54,524.40,137.05,7.86;11,151.52,535.36,33.89,7.86">Computational Statistics &amp; Data Analysis</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="367" to="378" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,546.61,337.64,7.86;11,151.52,557.57,329.07,7.86;11,151.52,568.53,329.07,7.86;11,151.52,579.49,138.14,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,261.88,557.57,165.44,7.86">Clef 2017 ehealth evaluation lab overview</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Spijker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,434.48,557.57,46.12,7.86;11,151.52,568.53,209.38,7.86">CLEF 2017 -8th Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="11,369.09,568.53,111.50,7.86;11,151.52,579.49,58.60,7.86">Lecture Notes in Computer Science (LNCS</title>
		<imprint>
			<date type="published" when="2017-09">September 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,590.75,337.63,7.86;11,151.52,601.71,329.07,7.86;11,151.52,612.67,151.80,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,318.98,590.75,161.61,7.86;11,151.52,601.71,231.08,7.86">A probabilistic model of information retrieval: development and comparative experiments: Part 2</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,388.91,601.71,91.69,7.86;11,151.52,612.67,61.19,7.86">Information processing &amp; management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="809" to="840" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,623.92,337.64,7.86;11,151.52,634.88,329.07,7.86;11,151.52,645.84,329.07,7.86;11,151.52,656.80,115.01,8.12" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,346.68,623.92,133.91,7.86;11,151.52,634.88,156.42,7.86">Clef 2017 technologically assisted reviews in empirical medicine overview</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Spijker</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="11,329.98,634.88,150.61,7.86;11,151.52,645.84,291.82,7.86">Working Notes of CLEF 2017 -Conference and Labs of the Evaluation forum. CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,119.67,337.98,7.86;12,151.52,130.63,329.07,7.86;12,151.52,141.59,76.80,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,284.47,119.67,196.13,7.86;12,151.52,130.63,30.97,7.86">Exploratory under-sampling for class-imbalance learning</title>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,202.32,130.63,272.66,7.86">Proceedings -IEEE International Conference on Data Mining, ICDM</title>
		<meeting>-IEEE International Conference on Data Mining, ICDM</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="965" to="969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,152.55,337.98,7.86;12,151.52,163.51,263.42,7.86" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<title level="m" coord="12,341.33,152.55,139.26,7.86;12,151.52,163.51,101.88,7.86">Efficient estimation of word representations in vector space</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,142.62,174.47,337.98,7.86;12,151.52,185.43,329.07,7.86;12,151.52,196.39,25.60,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,294.44,174.47,186.15,7.86;12,151.52,185.43,174.84,7.86">LETOR: A benchmark collection for research on learning to rank for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,332.66,185.43,86.63,7.86">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="346" to="374" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,207.34,337.98,7.86;12,151.52,218.30,79.82,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,210.17,207.34,98.64,7.86">Evidence-based medicine</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">L</forename><surname>Sackett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,330.18,207.34,98.26,7.86">Seminars in perinatology</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="3" to="5" />
			<date type="published" when="1997">1997</date>
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,229.26,337.97,7.86;12,151.52,240.22,329.07,7.86;12,151.52,251.18,329.07,7.86;12,151.52,262.14,25.60,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,401.32,229.26,79.26,7.86;12,151.52,240.22,116.91,7.86">Active learning for biomedical citation screening</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Small</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Brodley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Trikalinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,291.02,240.22,189.57,7.86;12,151.52,251.18,245.86,7.86">Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 16th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,273.10,337.97,7.86;12,151.52,284.06,329.07,7.86;12,151.52,295.02,96.81,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,458.06,273.10,22.53,7.86;12,151.52,284.06,264.21,7.86">Semiautomated screening of biomedical citations for systematic reviews</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Trikalinos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Brodley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,422.32,284.06,58.27,7.86;12,151.52,295.02,26.16,7.86">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">55</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
