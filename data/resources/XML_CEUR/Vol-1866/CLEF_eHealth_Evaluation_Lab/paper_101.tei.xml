<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,150.42,115.96,314.51,12.62;1,158.19,133.89,298.97,12.62">LIMSI@CLEF eHealth 2017 Task 2: Logistic Regression for Automatic Article Ranking</title>
				<funder ref="#_3HcV84d">
					<orgName type="full">European Union</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,169.03,171.63,90.08,8.74"><forename type="first">Christopher</forename><surname>Norman</surname></persName>
						</author>
						<author role="corresp">
							<persName coords="1,274.13,171.63,73.84,8.74"><forename type="first">Mariska</forename><surname>Leeflang</surname></persName>
							<email>m.m.leeflang@uva.nl</email>
							<affiliation key="aff1">
								<orgName type="department">Academic Medical Center</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">the Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,377.91,171.63,63.95,8.74"><forename type="first">Aurélie</forename><surname>Névéol</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LIMSI</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">Université Paris Saclay</orgName>
								<address>
									<postCode>F-91405</postCode>
									<settlement>Orsay</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,150.42,115.96,314.51,12.62;1,158.19,133.89,298.97,12.62">LIMSI@CLEF eHealth 2017 Task 2: Logistic Regression for Automatic Article Ranking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2F82EAC64CB079BD1D71992F1AEA90DC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Evidence Based Medicine</term>
					<term>Information Storage and Retrieval</term>
					<term>Review Literature as Topic</term>
					<term>Supervised Machine Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of the LIMSI-MIROR team at CLEF eHealth 2017, task 2. The task addresses the automatic ranking of articles in order to assist with the screening process of Diagnostic Test Accuracy (DTA) Systematic Reviews. We used a logistic regression classifier and handled class imbalance using a combination of class reweighting and undersampling. We also experimented with two strategies for relevance feedback. Our best run obtained an overall Average Precision of 0.179 and Work Saved over Sampling @95% Recall of 0.650. This run uses stochastic gradient descent for training but no feature selection or relevance feedback. We observe high performance variation within the queries in the test set. Nonetheless, our results suggest that automatic assistance is promising for ranking the DTA literature as it could reduce the screening workload for review writer by 65% on average.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Systematic reviews seek to gather all available published evidence for a given topic and provide an informed analysis of the results. This work constitutes some of the strongest forms of scientific evidence. Systematic reviews are an integral part of evidence based medicine in particular, and serve a key role in informing and guiding public and institutional decision-making. Systematic reviews for Diagnostic Test Accuracy (DTA) studies have been shown particularly challenging compared to other types of reviews because of the difficulty in defining search strategies offering adequate levels of sensitivity and specificity <ref type="bibr" coords="1,449.95,584.31,9.96,8.74" target="#b7">[8]</ref>. For this reason, there is a need to particularly investigate automation strategies to assist DTA systematic review writers in the time-consuming screening process.</p><p>Methods for automating the screening process in systematic reviews have been actively researched over the years <ref type="bibr" coords="1,303.42,632.21,9.96,8.74" target="#b5">[6]</ref>, with promising results obtained using a range of machine learning methods. However, previous work has not addressed DTA studies. This paper describes the work underlying our participation in the CLEF 2017 eHealth Task 2 <ref type="bibr" coords="2,226.66,130.95,15.50,8.74" target="#b9">[10,</ref><ref type="bibr" coords="2,245.39,130.95,7.01,8.74" target="#b3">4]</ref>. This work is part of an ongoing effort on providing automatic assistance for the screening process in systematic reviews addressing a variety of topics, including DTA studies.</p><p>The remainder of this paper is organized as follows; Section 2 presents the datasets used for system development. Section 3 provides an overview of our system and describes each component. Finally, section 4 reports our results and section 5 provides an analysis of our methods and participation in the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Datasets</head><p>The task relied on a corpus comprising 50 DTA systematic review topics associated with the full list of articles retrieved by an expert query and assessed for inclusion based on title and abstract or full text. The corpus was split into a development dataset comprising 20 topics and a test set comprising the remaining 30 topics. Our classifier was trained on the development dataset and evaluated on the test dataset. We have also used a dataset of systematic reviews on drug class efficacy due to Cohen et al. <ref type="bibr" coords="2,277.83,340.90,10.52,8.74" target="#b0">[1]</ref> to develop the methods applied in this task. Several groups have been using this dataset in the past <ref type="bibr" coords="2,381.03,352.86,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="2,395.12,352.86,7.01,8.74" target="#b4">5]</ref>, which gives us a way to compare our results with previous work, although we can of course only do by using the same evaluation metrics and training modes as previous work.</p><p>For both the CLEF and Cohen datasets we know the inclusion decisions based on the abstracts, as well as the inclusion decisions based on the full text. We thus have two definitions of positive examples, depending on whether we use the abstract decisions or full text decisions as the gold standard.</p><p>We use a tripartite labeling to reflect this:</p><p>-No (N) is the set of articles that were excluded based on the abstract -Maybe (M) is the set of articles that were preliminarily included based on the abstract, but later excluded based on the full text -Yes (Y) is the set of articles that were included based on both the abstract and the full text, and later used in the meta-analysis Table <ref type="table" coords="2,176.79,540.84,4.98,8.74" target="#tab_0">1</ref> shows a breakdown of the distribution of examples for each class the CLEF and Cohen datasets used in our work.</p><p>Following the work of Cohen et al. <ref type="bibr" coords="2,296.96,565.73,10.20,8.74" target="#b1">[2]</ref>, we also distinguish between two modes of training:</p><p>-Intertopic training uses articles from a different topic (systematic review)</p><p>for training -Intratopic training uses articles from the current topic (systematic review)</p><p>for training </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>We first give an overview of our system, which relies on logistic regression, in section 3.1. Further details about the system are given in sections 3.2-3.5, including features, strategies to handle class imbalance and implement relevance feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>We have tried the following two classifiers:</p><p>-Classifier 1 uses logistic regression trained using stochastic gradient descent on all features -Classifier 2 uses standard logistic regression trained using standard methods on a subset of the features, and with additional preprocessing to improve the throughput</p><p>We have tried three approaches to relevance feedback:</p><p>-no relevance feedback -abrupt uses intertopic ranking until a sufficient number of relevant and nonrelevant articles have been identified, and then switches to using intratopic ranking based on the identified articles -gradual initially uses intertopic ranking, and gradually improves the model using both Y and M identified through relevance feedback</p><p>In total, we have submitted the following four runs to the CLEF evaluation:</p><p>-no AF full uses classifier 1 with no relevance feedback -no AF uses classifier 2 with no relevance feedback -abrupt uses classifier 2 with abrupt relevance feedback -gradual uses classifier 2 with gradual relevance feedback</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Classification approach</head><p>We are currently using two classification systems. Both use logistic regression but differ in how the model is optimized and the amounts and types of pre-and postprocessing that is performed. Both methods use implementations provided by sklearn <ref type="bibr" coords="4,182.73,560.48,9.96,8.74" target="#b6">[7]</ref>. Our first method, which is used in no AF full tends to work well for intertopic classification on previous datasets (see table <ref type="table" coords="4,368.26,584.39,3.87,8.74" target="#tab_2">3</ref>), presumably because it generalizes better. This system uses logistic regression trained using stochastic gradient descent. The only preprocessing done is the normalization of numerals.</p><p>Our second method, which is used in no AF, abrupt, and gradual uses standard methods for training (liblinear). This version tends to work well on intratopic classification on previous datasets (see table <ref type="table" coords="4,371.70,644.16,3.87,8.74" target="#tab_2">3</ref>), but does not scale as well with data volume. We therefore need to do additional preprocessing to reduce the number of features and keep running times down. We thus remove features with variance less than a predefined threshold, we only consider n-grams with high mutual information with the target class in the training set, we normalize numerals, and we extract the principal components from the resulting data.</p><p>Principal component analysis tends to reduce overfitting in our experiments, and it also drastically reduces the time it takes to train and apply the classifier, which is mostly important when we use relevance feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Features</head><p>For all classifiers we extract n-grams (n ≤ 5) from the titles and abstracts. We also extract publication type, journal names, author assigned keywords, MeSH terms, and backward references, where these are available. The backward references are only available for references pointing to articles available in Pubmed Central, and this feature set is therefore fairly sparse.</p><p>Not all feature sets are useful for identifying DTA studies, but the current model has been constructed such that irrelevant features should not adversely effect the performance. All the feature sets have been shown to be useful on some domain. For instance MeSH terms might not be useful for DTA studies, but we have previously found them to be useful in identifying topics related to drug efficacy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Class imbalance</head><p>Class imbalance can be handled using undersampling, or by class reweighting. We are currently using a combination of both these approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class weights</head><p>We set the weight for the positive class to 80 for the initial intertopic classifier. We have determined this to be a reasonable weight experimentally using the Cohen dataset.</p><p>For the gradual relevance feedback we also attached higher weights to the intratopic training examples identified through relevance feedback.</p><p>Undersampling In order to reduce the effects of the class imbalance we undersample the training set to include an equal number of Y, M, and N. However, by doing so we end up with only around 1500 training samples. PCA yields at most the same number of principal components as we have input samples, and 1500 is generally too few principal components to build an accurate classifier. For the second model we therefore perform undersampling in two steps; We first select a maximum of 500 Y, 1000 M, and 1500 N that we feed into the feature extraction pipeline, which thus determines the number of features in our model. We then select a smaller undersample to use for training.</p><p>We take a new undersample in each iteration of relevance feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Relevance Feedback</head><p>We use two schemes for relevance feedback. For both schemes we retrain the classifier each time we retrieve relevance feedback.</p><p>abrupt trains an initial intertopic classifier on the training dataset and ranks the test dataset in descending order of confidence. The system then iteratively asks for feedback for the top ranked results. When enough positive and negative examples have been identified, the system switches to using a classifier trained on the examples identified from relevance feedback. Additional examples are added to the intratopic classifier as they are discovered.</p><p>The idea behind this system is that on some topics in Cohen we can train highly performing intratopic classifiers using very small amounts of data, and we have observed that even trained on small amounts of data these sometimes outperform intertopic classifiers by a large margin. In these cases it might make sense to switch to intratopic classification as soon as we can.</p><p>We set the minimum number of positive examples to 4, and the minimum number of negative examples to 10.</p><p>gradual trains an initial intertopic classifier using the training set and ranks the test set in descending order of confidence. The system then iteratively asks for feedback for the top ranked result. Articles queried for relevance feedback are then added to the model as they are queried, but with higher weights than the intertopic examples. The model thus starts out as an intertopic classifier, but gradually turns into an intratopic classifier as more targeted data is added to the model. Since the intratopic examples identified through relevance feedback are given higher weights, these will eventually drown out the original classifier, provided enough examples exist to be discovered.</p><p>Besides using Y and N, we also use intratopic M as positive examples, with lower weights than intratopic Y, but higher than intertopic Y. The reasoning behind this is that we often encounter M earlier than Y, and in greater numbers, in particular on topics with very few Y. We have observed on other datasets that we can sometimes improve performance by using both Y and M as positive examples, when the number of Y is very low.</p><p>After the number of Y found is larger than 40, we stop using M as positive examples.</p><p>Reasonable parameter settings were identified experimentally on the Cohen dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Use of the CLEF development dataset</head><p>We do not split the training data into separate training and validation splits, since we do not have the necessary number of Y to do this without hurting the performance of the classifier. We do however use a small set of samples that overlaps with the training set for validation. The performance we observe on this validation suffers from severe overfitting, but we can observe when the model fails to build a classifier on the current undersample. In such cases we can observe an AUROC &lt; 0.5 even on the training set. In these cases we simply discard the classifier and try again with a new undersample. We observe that this improves performance dramatically when we have a very small amount of training data (approximately four or less positive examples).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>We present a comparison with previous work on the Cohen dataset for WSS@95 in table 2 and for AUC in table <ref type="table" coords="7,282.25,270.08,3.87,8.74" target="#tab_2">3</ref>. Results from previous literature are taken from Khabsa et al. <ref type="bibr" coords="7,222.82,282.04,9.96,8.74" target="#b4">[5]</ref>, and Cohen et al. <ref type="bibr" coords="7,319.03,282.04,9.96,8.74" target="#b1">[2]</ref>. Exact intertopic AUC scores are not explicitly reported by Cohen et al. and have instead been extracted from Figure <ref type="figure" coords="7,166.16,305.95,4.98,8.74">1</ref> in their paper The majority of these results, with the exception of one result by Cohenet al. <ref type="bibr" coords="7,229.49,317.90,10.52,8.74" target="#b1">[2]</ref> use intratopic classification.</p><p>We present our results on the CLEF dataset for average precision in table 4, normalized average precision in table 5, WSS@95 in table 6, and in aggregate in table <ref type="bibr" coords="7,171.84,353.77,3.87,8.74" target="#b6">7</ref>. The results in these tables correspond to those submitted as official runs. For comparison, we also calculate a baseline by evaluating each metric on the data ordered randomly. This has been repeated 1000 times and we report the average and standard deviation.</p><p>We also report the mean, standard deviation, minimum and maximum WSS@95 and AUC over ten runs for a selection of topics in the CLEF dataset in table 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>One of the topics in the CLEF dataset, CD010653, has no Y. While we can still calculate performance scores relative to M, this topic might arguably have been omitted from the test data. One of the topics, CD008803, similarly has no M. This also happens to be the topic with the largest number of Y.</p><p>As a general tendency, we can observe that the relative number of Y / M / N in the CLEF dataset varies dramatically across topics. At the one end we have one topic consisting of 14.06% Y (CD008760), and one topic consisting of 15.79% Y (CD010705). At the other end we have three topics with a mere 0.01% Y (CD011548, CD011549, and CD012019). Most topics in the CLEF dataset have a very small number of Y compared to Cohen, both in terms of relative and absolute numbers. Several topics have a large number of M however (CD007427, CD008054, CD009020, CD009323, CD009591, 011134, CD011548, CD0011975, CD011984, CD009925, CD10339, CD011145). Curiously, more topics in the training set have a large number of M than in the test set, despite this comprising a smaller number of topics. The number of N also varies wildly, from 52 up to 43287. Compared to the Cohen dataset we also have a smaller minimum number of N, as well as much larger maximum number.</p><p>If we compare the training and test sets, the training set contains almost double the absolute number of M, many more N, but fewer Y.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance</head><p>While relevance feedback sometimes gives an improvement in performance, relevance feedback often seems to only confuse the system (tables 4-7). This should be contrasted with our experiments on the Cohen dataset, where the same implementation reliably yields an improvement (table <ref type="table" coords="13,359.45,249.64,3.87,8.74" target="#tab_2">3</ref>), and generally yields performance intermediate between intertopic and intratopic classification, as one would expect. There are perhaps better approaches to relevance feedback than ours, which can reliably improve upon the baseline, but it might also be that there is simply little to gain from relevance feedback on several of the topics. Of particular note, we should not expect any improvements by using RF on topics such as CD010386, CD010633, CD010860, CD010896, and CD012019, that have a low absolute number of Y and M. It is also worth pointing out that our abrupt scheme requires at least 4 Y before switching to the intratopic model, and any differences between no AF and abrupt on these topics can thus only be due to chance.</p><p>We can see an improvement on the topic CD010705 when using relevance feedback (tables 4-7). This topics is also the topic with the highest percentage of Y at 15.79%. We do not see any improvement for CD008760, the other topic with a high percentage of Y (14.06%), but this may be due to the initial classifier having much higher performance.</p><p>We can observe that gradual outperforms abrupt on topic CD008760, despite this topic having only 3 M, which is probably too low a numbe for gradual to have an advantage. The simplest explanation for this is likely random chance.</p><p>It is however easy to see that relevance feedback does not appear to lead to an improvement for our system. For instance abrupt outperforms no AF 15 times out of 30, and gradual outperforms no AF only 10 times out of 30 (tables 4).</p><p>Of course, it seems unlikely for relevance feedback to be useful for those topics where the number of positives is extremely low, even in theory. In particular, if there is only one relevant article, as is the case for CD012019 and CD010386, then relevance feedback cannot really add any value to the classification. Any successful use of relevance feedback on such topics would necessarily have to use the negative examples.</p><p>We get better performance for no AF full than no AF. We have however generally observed that this difference is generally reversed for intratopic classification, which is what we should end up with when we after relevance feedback, but it is possible that we would get better performance if we were to use no AF full as a base for our relevance feedback experiments, since we would start with a much better initial classifier.</p><p>Ordinarily, screeners would be free to choose the order in which they screen each article, and may proceed for instance in alphabetical or chronological order. For the purposes of our baseline, we assume that any such order ordinarily available to screeners would be indistinguishable from random order on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Metrics</head><p>Average Precision has been selected as the main metric for this task as it was previously found particularly adapted to evaluate retrieval performance for highly imbalanced datasets <ref type="bibr" coords="14,225.63,226.16,10.52,8.74" target="#b8">[9,</ref><ref type="bibr" coords="14,239.33,226.16,7.01,8.74" target="#b2">3]</ref>. However, these studies rely on common assumptions that we value high precision at the top of the ranking, whereas for systematic review screening we value recall almost exclusively. Of particular note, average precision heavily penalizes rankings where the top few results are non-relevant, even if the ranking manages to place all relevant articles in the upper percentiles of the ranking.</p><p>Furthermore, average precision is strongly correlated with the number of positives in the topic, with most of the cases where we achieve ap &gt; 0.2 are for topics with high prevalence. While this is to be expected, it means that average precision makes it difficult to compare performance across topics, since we can see a strong correlation with the prevalence of relevant articles in the topic (tables 1, 4-7). Similarly, Mean Average Precision will likely be dominated by the results on the topics with many relevant articles and a small number of total candidates, i.e. arguably the topics which are the least representative systematic reviews of DTA studies, and where automated methods are likely the least useful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Reliability of the Experiments</head><p>Our classification method is stochastic, and thus does not produce deterministic results that are always the same every time we run on the same input data. To gauge the reliability of the experiment we repeat it ten times for a subset of the topics and calculate the standard deviations, as well as examine the minimum and maximum values (table <ref type="table" coords="14,259.08,500.70,3.87,8.74" target="#tab_7">8</ref>).</p><p>We can generally observe a fairly large variability for topics with a small total number of candidates, such as CD008760 and CD010705, and for topics with a comparably smaller proportion of Y, such as CD010339. When we consider topics with a large number of candidates we can observe a large variability for the CD012019, but small variability for CD010386. We might speculate that small topic size and a small relative number of Y is correlated with larger variability, but it is clear that the variability for some topics is quite large, regardless of the underlying causes and mechanisms. The standard deviation can be as large as .139, which is large enough that it casts doubts about the reliability of the results. Furthermore, the minimum and maximum values are much more skewed towards extreme values than we should expect from the standard deviations were the values normally distributed, suggesting that the distribution is heavy-tailed and skewed towards outliers.</p><p>Considering the above, we might suspect that the differences in performance in tables 4-7 are not significant. For instance abrupt outperforms gradual 17 times out of 30, but we do not know whether this means that abrupt is a better method, or if this is simply due to random chance. We might speculate that our gradual implementation works better for the cases where we have a sufficient number of M, but the experiment is ultimately too low-powered to draw conclusions. Future iterations of the campaign could consider whether performance should be computed as an average over multiple runs, in order to get more precise results for stochastic systems such as ours.</p><p>We can however see smaller variability in the mean performance across all topics, which might suggest that these are more reliable estimates. However, these give little indication as to how the performance depends on topic composition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">General Remarks on the Shared Task Model</head><p>The Shared Task Model is typically implemented in evaluation campaigns that seek to perform a community-wide technical evaluation of systems addressing a particular task. A Shared Task thus offers an evaluation paradigm that includes: 1/a specific definition of the task and evaluation metrics 2/an implementation through the dissemination of datasets and evaluation tools and 3/the execution of the evaluation in a controlled setting where participants have access to data at the same time and are evaluated blindly by an independent third party. As outlined below, this year the TAR task was not conducted according to the Shared Task Model.</p><p>In this iteration of the evaluation campaign, the final set of evaluation metrics was decided only shortly before participants were required to freeze their systems. One of the expected outcomes of evaluation campaigns such as this is indeed the discussion of the relative merits of the various metrics to be used. However, changing the target metric close to the submission deadline means that some participants may have optimized for different metrics than those ultimately used for evaluation.</p><p>The gold standard labeled test data was distributed directly to the participants at the begining of the test phase. This is explained by the lack of an assessor through which participants could receive relevance feedback as has been the case in e.g. TREC Total Recall. While common labeled test collections are routinely used for research, this procedure is unusual in a shared task setting where participants are typically asked to process a test dataset while being blind to the gold standard associated with the dataset. This could alternatively have been accomplished in part by requiring the submission of runs without relevance feedback before the distribution of the gold standard labels.</p><p>Another feature of the shared task model is the computation of performance metrics for all participants by a common, independent party which ensures that all participations are evaluated using the exact same conditions. This confers a stronger reliability in the comparability and reproducibility of results. At the time of writing, while a common evaluation tool has been released, the performance reported by participants has been self-computed without validation from the task organizers. In addition to result validation, it would also have been useful to receive an indication of the overall performance of the participants prior to the deadline for the submission of the working notes. This would have enabled a discussion about the relative performance of the system that is currently difficult to do without comparing with previous literature using external datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>Our best system is the one using logistic regression trained using stochastic gradient descent, using a minimum of preprocessing, and no relevance feedback. This system achieves a workload reduction of 64.0% on average, with a minimum workload reduction of 19.3%, and a maximum workload reduction of 92.0%. On average, we would have to screen 1678 articles per topic to retrieve all relevant articles. Overall there is a large variation in performance across topics however.</p><p>We do not generally see an improvement when using relevance feedback. For the topics where relevance feedback is hypothetically feasible we sometimes see an improvement, although the effect does not appear very reliable, and the low power of the experiment means that the results are unlikely to be significant.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,147.11,117.05,321.14,583.55"><head>Table 1 :</head><label>1</label><figDesc>The distribution of class labels in each dataset.</figDesc><table coords="3,147.11,117.05,321.14,565.22"><row><cell></cell><cell cols="3">Absolute number</cell><cell cols="2">Relative number</cell><cell></cell></row><row><cell>Dataset Topic</cell><cell>Y</cell><cell>M</cell><cell>N</cell><cell>Y</cell><cell>M</cell><cell>N</cell></row><row><cell cols="2">Cohen CalciumChannelBlockers 100</cell><cell>180</cell><cell>938</cell><cell cols="3">8.21% 14.78% 77.01%</cell></row><row><cell>ACEInhibitors</cell><cell>41</cell><cell>142</cell><cell>2361</cell><cell>1.61%</cell><cell cols="2">5.58% 92.81%</cell></row><row><cell>BetaBlockers</cell><cell>42</cell><cell>260</cell><cell>1770</cell><cell cols="3">2.03% 12.55% 85.42%</cell></row><row><cell>Opiods</cell><cell>15</cell><cell>33</cell><cell>1867</cell><cell>0.78%</cell><cell cols="2">1.72% 97.49%</cell></row><row><cell>OralHypoglycemics</cell><cell>136</cell><cell>3</cell><cell>364</cell><cell cols="3">27.04% 0.60% 72.37%</cell></row><row><cell>Statins</cell><cell>85</cell><cell>88</cell><cell>3292</cell><cell>2.45%</cell><cell cols="2">2.54% 95.01%</cell></row><row><cell>SkeletalMuscleRelaxants</cell><cell>9</cell><cell>25</cell><cell>1609</cell><cell>0.55%</cell><cell cols="2">1.52% 97.93%</cell></row><row><cell>Antihistamines</cell><cell>16</cell><cell>76</cell><cell>218</cell><cell cols="3">5.16% 24.52% 70.32%</cell></row><row><cell>ProtonPumpInhibitors</cell><cell>51</cell><cell>187</cell><cell>1095</cell><cell cols="3">3.83% 14.03% 82.15%</cell></row><row><cell>Triptans</cell><cell>24</cell><cell>194</cell><cell>453</cell><cell cols="3">3.58% 28.91% 67.51%</cell></row><row><cell>NSAIDS</cell><cell>41</cell><cell>47</cell><cell>305</cell><cell cols="3">10.43% 11.96% 77.61%</cell></row><row><cell>ADHD</cell><cell>20</cell><cell>64</cell><cell>767</cell><cell>2.35%</cell><cell cols="2">7.52% 90.13%</cell></row><row><cell>AtypicalAntipsychotics</cell><cell>146</cell><cell>218</cell><cell>756</cell><cell cols="3">13.04% 19.46% 67.50%</cell></row><row><cell>UrinaryIncontinence</cell><cell>40</cell><cell>38</cell><cell>249</cell><cell cols="3">12.23% 11.63% 77.61%</cell></row><row><cell>Estrogens</cell><cell>80</cell><cell>0</cell><cell>288</cell><cell cols="3">21.74% 0.00% 78.26%</cell></row><row><cell>Total</cell><cell cols="3">846 1555 16333</cell><cell>4.52%</cell><cell cols="2">8.30% 87.18%</cell></row><row><cell>CLEF (train) CD007394</cell><cell>47</cell><cell>48</cell><cell>2450</cell><cell>1.85%</cell><cell cols="2">1.89% 96.27%</cell></row><row><cell>CD007427</cell><cell>17</cell><cell>106</cell><cell>1398</cell><cell>1.12%</cell><cell cols="2">6.97% 91.91%</cell></row><row><cell>CD008054</cell><cell>41</cell><cell>233</cell><cell>2940</cell><cell>1.28%</cell><cell cols="2">7.25% 91.47%</cell></row><row><cell>CD008643</cell><cell>7</cell><cell>4</cell><cell>15065</cell><cell>0.05%</cell><cell cols="2">0.03% 99.93%</cell></row><row><cell>CD008686</cell><cell>5</cell><cell>2</cell><cell>3946</cell><cell>0.13%</cell><cell cols="2">0.05% 99.82%</cell></row><row><cell>CD008691</cell><cell>20</cell><cell>53</cell><cell>1243</cell><cell>1.52%</cell><cell cols="2">4.03% 94.45%</cell></row><row><cell>CD009020</cell><cell>12</cell><cell>150</cell><cell>1422</cell><cell>0.76%</cell><cell cols="2">9.47% 89.77%</cell></row><row><cell>CD009323</cell><cell>9</cell><cell>113</cell><cell>3757</cell><cell>0.23%</cell><cell cols="2">2.91% 96.85%</cell></row><row><cell>CD009591</cell><cell>41</cell><cell>103</cell><cell>7847</cell><cell>0.51%</cell><cell cols="2">1.29% 98.20%</cell></row><row><cell>CD009593</cell><cell>24</cell><cell>54</cell><cell>14844</cell><cell>0.16%</cell><cell cols="2">0.36% 99.48%</cell></row><row><cell>CD009944</cell><cell>64</cell><cell>53</cell><cell>1064</cell><cell>5.42%</cell><cell cols="2">4.49% 90.09%</cell></row><row><cell>CD010409</cell><cell>41</cell><cell>35</cell><cell>43287</cell><cell>0.09%</cell><cell cols="2">0.08% 99.82%</cell></row><row><cell>CD010438</cell><cell>3</cell><cell>36</cell><cell>3211</cell><cell>0.09%</cell><cell cols="2">1.11% 98.80%</cell></row><row><cell>CD010632</cell><cell>14</cell><cell>18</cell><cell>1472</cell><cell>0.93%</cell><cell cols="2">1.20% 97.87%</cell></row><row><cell>CD010771</cell><cell>1</cell><cell>47</cell><cell>274</cell><cell cols="3">0.31% 14.60% 85.09%</cell></row><row><cell>CD011134</cell><cell>49</cell><cell>166</cell><cell>1738</cell><cell>2.51%</cell><cell cols="2">8.50% 88.99%</cell></row><row><cell>CD011548</cell><cell>1</cell><cell>108</cell><cell>12591</cell><cell>0.01%</cell><cell cols="2">0.85% 99.14%</cell></row><row><cell>CD011549</cell><cell>1</cell><cell>1</cell><cell>12699</cell><cell>0.01%</cell><cell cols="2">0.01% 99.98%</cell></row><row><cell>CD011975</cell><cell>60</cell><cell>559</cell><cell>7582</cell><cell>0.73%</cell><cell cols="2">6.82% 92.45%</cell></row><row><cell>CD011984</cell><cell>28</cell><cell>426</cell><cell>7738</cell><cell>0.34%</cell><cell cols="2">5.20% 94.46%</cell></row><row><cell>Total</cell><cell cols="4">485 2315 146568 0.32%</cell><cell cols="2">1.55% 98.13%</cell></row><row><cell>CLEF (test) CD007431</cell><cell>47</cell><cell>9</cell><cell>2050</cell><cell>2.23%</cell><cell cols="2">0.43% 97.34%</cell></row><row><cell>CD008081</cell><cell>10</cell><cell>16</cell><cell>944</cell><cell>1.03%</cell><cell cols="2">1.65% 97.32%</cell></row><row><cell>CD008760</cell><cell>9</cell><cell>3</cell><cell>52</cell><cell cols="3">14.06% 4.69% 81.25%</cell></row><row><cell>CD008782</cell><cell>34</cell><cell>11</cell><cell>10460</cell><cell>0.32%</cell><cell cols="2">0.10% 99.57%</cell></row><row><cell>CD008803</cell><cell>99</cell><cell>0</cell><cell>5121</cell><cell>1.90%</cell><cell cols="2">0.00% 98.10%</cell></row><row><cell>CD009135</cell><cell>19</cell><cell>58</cell><cell>714</cell><cell>2.40%</cell><cell cols="2">7.33% 90.27%</cell></row><row><cell>CD009185</cell><cell>23</cell><cell>69</cell><cell>1523</cell><cell>1.42%</cell><cell cols="2">4.27% 94.30%</cell></row><row><cell>CD009372</cell><cell>10</cell><cell>15</cell><cell>2223</cell><cell>0.44%</cell><cell cols="2">0.67% 98.89%</cell></row><row><cell>CD009519</cell><cell>46</cell><cell>58</cell><cell>5867</cell><cell>0.77%</cell><cell cols="2">0.97% 98.26%</cell></row><row><cell>CD009551</cell><cell>16</cell><cell>30</cell><cell>1865</cell><cell>0.84%</cell><cell cols="2">1.57% 97.59%</cell></row><row><cell>CD009579</cell><cell>79</cell><cell>59</cell><cell>6317</cell><cell>1.22%</cell><cell cols="2">0.91% 97.86%</cell></row><row><cell>CD009647</cell><cell>17</cell><cell>39</cell><cell>2729</cell><cell>0.61%</cell><cell cols="2">1.40% 97.99%</cell></row><row><cell>CD009786</cell><cell>6</cell><cell>4</cell><cell>2055</cell><cell>0.29%</cell><cell cols="2">0.19% 99.52%</cell></row><row><cell>CD009925</cell><cell>55</cell><cell>405</cell><cell>6071</cell><cell>0.84%</cell><cell cols="2">6.20% 92.96%</cell></row><row><cell>CD010023</cell><cell>14</cell><cell>38</cell><cell>929</cell><cell>1.43%</cell><cell cols="2">3.87% 84.70%</cell></row><row><cell>CD010173</cell><cell>10</cell><cell>13</cell><cell>5472</cell><cell>0.18%</cell><cell cols="2">0.24% 99.58%</cell></row><row><cell>CD010276</cell><cell>24</cell><cell>30</cell><cell>5441</cell><cell>0.44%</cell><cell cols="2">0.55% 99.02%</cell></row><row><cell>CD010339</cell><cell>9</cell><cell>105</cell><cell>12689</cell><cell>0.07%</cell><cell cols="2">0.82% 99.11%</cell></row><row><cell>CD010386</cell><cell>1</cell><cell>1</cell><cell>623</cell><cell>0.16%</cell><cell cols="2">0.16% 99.68%</cell></row><row><cell>CD010542</cell><cell>8</cell><cell>12</cell><cell>328</cell><cell>2.30%</cell><cell cols="2">3.45% 94.25%</cell></row><row><cell>CD010633</cell><cell>3</cell><cell>1</cell><cell>1569</cell><cell>0.19%</cell><cell cols="2">0.06% 99.75%</cell></row><row><cell>CD010653</cell><cell>0</cell><cell>45</cell><cell>7957</cell><cell>0.00%</cell><cell cols="2">0.56% 99.44%</cell></row><row><cell>CD010705</cell><cell>18</cell><cell>5</cell><cell>91</cell><cell cols="3">15.79% 4.39% 79.82%</cell></row><row><cell>CD010772</cell><cell>11</cell><cell>36</cell><cell>269</cell><cell cols="3">3.48% 11.39% 85.13%</cell></row><row><cell>CD010775</cell><cell>4</cell><cell>7</cell><cell>230</cell><cell>1.66%</cell><cell cols="2">2.90% 95.44%</cell></row><row><cell>CD010783</cell><cell>11</cell><cell>19</cell><cell>10875</cell><cell>0.10%</cell><cell cols="2">0.17% 99.72%</cell></row><row><cell>CD010860</cell><cell>4</cell><cell>3</cell><cell>87</cell><cell>4.26%</cell><cell cols="2">3.19% 92.55%</cell></row><row><cell>CD010896</cell><cell>3</cell><cell>3</cell><cell>163</cell><cell>1.78%</cell><cell cols="2">1.78% 96.45%</cell></row><row><cell>CD011145</cell><cell>48</cell><cell>154</cell><cell>10670</cell><cell>0.44%</cell><cell cols="2">1.42% 98.14%</cell></row><row><cell>CD012019</cell><cell>1</cell><cell>2</cell><cell>10314</cell><cell>0.01%</cell><cell cols="2">0.02% 99.97%</cell></row><row><cell>Total</cell><cell cols="4">639 1250 115698 0.54%</cell><cell cols="2">1.06% 98.39%</cell></row><row><cell>Total (train + test)</cell><cell cols="4">1124 3565 262266 0.42%</cell><cell cols="2">1.34% 98.24%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,100.90,132.41,413.57,450.18"><head>Table 2 :</head><label>2</label><figDesc>Comparison in terms of WSS@95% with previous literature using Voting Perceptrons, Complement Naive Bayes, and Random Forests, as reported by Khabsa et al.<ref type="bibr" coords="8,158.32,340.43,9.22,7.86" target="#b4">[5]</ref>. We here only have state of the art metrics for the intratopic case.</figDesc><table coords="8,100.90,132.41,413.57,450.18"><row><cell></cell><cell></cell><cell cols="3">Topic no AF full no AF</cell><cell cols="2">VP CNB RF</cell><cell></cell><cell></cell></row><row><cell cols="3">CalciumChannelBlockers</cell><cell>.398</cell><cell cols="3">.408 &lt;.100 .234 .287</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">ACEInhibitors</cell><cell>.629</cell><cell>.517</cell><cell cols="2">.318 .523 .447</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">BetaBlockers</cell><cell>.511</cell><cell>.427</cell><cell cols="2">.284 .367 .361</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Opiods</cell><cell>.590</cell><cell cols="3">.641 &lt;.190 .554 .455</cell><cell></cell><cell></cell></row><row><cell cols="3">OralHypoglycemics</cell><cell>.111</cell><cell cols="3">.153 &lt;.050 .080 .074</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Statins</cell><cell>.436</cell><cell>.573</cell><cell cols="2">.242 .315 .400</cell><cell></cell><cell></cell></row><row><cell cols="3">SkeletalMuscleRelaxants</cell><cell>.429</cell><cell>.179</cell><cell cols="2">-.050 .265 .371</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Antihistamines</cell><cell>.149</cell><cell>.157</cell><cell cols="2">.080 .148 .030</cell><cell></cell><cell></cell></row><row><cell cols="3">ProtonPumpInhibitors</cell><cell>.307</cell><cell cols="3">.320 &lt;.180 .229 .288</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Triptans</cell><cell>.303</cell><cell>.312</cell><cell cols="2">.030 .279 .312</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">NSAIDS</cell><cell>.537</cell><cell>.600</cell><cell cols="2">.352 .528 .404</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>ADHD</cell><cell>.616</cell><cell>.530</cell><cell cols="2">.668 .622 .447</cell><cell></cell><cell></cell></row><row><cell cols="3">AtypicalAntipsychotics</cell><cell>.210</cell><cell>.234</cell><cell cols="2">.140 .206 .199</cell><cell></cell><cell></cell></row><row><cell cols="3">UrinaryIncontinence</cell><cell>.422</cell><cell>.365</cell><cell cols="2">.260 .290 .411</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Estrogens</cell><cell>.292</cell><cell>.475</cell><cell cols="2">.140 .375 .180</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Intertopic</cell><cell></cell><cell>RF</cell><cell></cell><cell cols="2">Intratopic</cell><cell></cell></row><row><cell cols="9">Topic no AF full no AF Cohen gradual no AF full no AF Cohen Khabsa</cell></row><row><cell>CalciumChannelBlockers</cell><cell>.759</cell><cell>.773</cell><cell>.712</cell><cell>.862</cell><cell>.825</cell><cell>.868</cell><cell>.873</cell><cell>.870</cell></row><row><cell>ACEInhibitors</cell><cell>.817</cell><cell>.782</cell><cell>.806</cell><cell>.899</cell><cell>.917</cell><cell>.925</cell><cell>.946</cell><cell>.951</cell></row><row><cell>BetaBlockers</cell><cell>.837</cell><cell>.832</cell><cell>.801</cell><cell>.860</cell><cell>.863</cell><cell>.871</cell><cell>.891</cell><cell>.893</cell></row><row><cell>Opiods</cell><cell>.885</cell><cell>.902</cell><cell>.856</cell><cell>.936</cell><cell>.905</cell><cell>.893</cell><cell>.897</cell><cell>.913</cell></row><row><cell>OralHypoglycemics</cell><cell>.657</cell><cell>.581</cell><cell>.573</cell><cell>.753</cell><cell>.568</cell><cell>.768</cell><cell>.781</cell><cell>.734</cell></row><row><cell>Statins</cell><cell>.826</cell><cell>.798</cell><cell>.773</cell><cell>.797</cell><cell>.873</cell><cell>.922</cell><cell>.900</cell><cell>.915</cell></row><row><cell>SkeletalMuscleRelaxants</cell><cell>.826</cell><cell>.823</cell><cell>.836</cell><cell>.812</cell><cell>.740</cell><cell>.527</cell><cell>.738</cell><cell>.794</cell></row><row><cell>Antihistamines</cell><cell>.652</cell><cell>.600</cell><cell>.620</cell><cell>.752</cell><cell>.650</cell><cell>.655</cell><cell>.722</cell><cell>.701</cell></row><row><cell>ProtonPumpInhibitors</cell><cell>.823</cell><cell>.790</cell><cell>.793</cell><cell>.886</cell><cell>.826</cell><cell>.860</cell><cell>.860</cell><cell>.880</cell></row><row><cell>Triptans</cell><cell>.819</cell><cell>.796</cell><cell>.823</cell><cell>.804</cell><cell>.792</cell><cell>.808</cell><cell>.909</cell><cell>.894</cell></row><row><cell>NSAIDS</cell><cell>.912</cell><cell>.828</cell><cell>.899</cell><cell>.922</cell><cell>.861</cell><cell>.935</cell><cell>.951</cell><cell>.933</cell></row><row><cell>ADHD</cell><cell>.591</cell><cell>.606</cell><cell>.469</cell><cell>.740</cell><cell>.908</cell><cell>.897</cell><cell>.924</cell><cell>.951</cell></row><row><cell>AtypicalAntipsychotics</cell><cell>.759</cell><cell>.645</cell><cell>.653</cell><cell>.855</cell><cell>.779</cell><cell>.803</cell><cell>.835</cell><cell>.818</cell></row><row><cell>UrinaryIncontinence</cell><cell>.887</cell><cell>.875</cell><cell>.851</cell><cell>.888</cell><cell>.784</cell><cell>.885</cell><cell>.890</cell><cell>.862</cell></row><row><cell>Estrogens</cell><cell>.693</cell><cell>.649</cell><cell>.588</cell><cell>.879</cell><cell>.689</cell><cell>.912</cell><cell>.887</cell><cell>.840</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,134.77,596.04,345.83,40.74"><head>Table 3 :</head><label>3</label><figDesc>Comparison in terms of AUC with previous literature using Support Vector Machines(Cohen)  and Random Forests (Khabsa), as reported by Khabsa et al.<ref type="bibr" coords="8,468.31,607.00,9.22,7.86" target="#b4">[5]</ref>, and Cohen et al.<ref type="bibr" coords="8,203.41,617.96,9.22,7.86" target="#b1">[2]</ref>. Exact intertopic AUC scores are not explicitly reported by Cohen et al. and have instead been extracted from Figure1in their paper.</figDesc><table coords="9,64.18,188.98,487.00,369.91"><row><cell></cell><cell></cell><cell></cell><cell>Y||MN</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>YM||N</cell><cell></cell></row><row><cell cols="5">w/o RF Topic no AF full no AF abrupt gradual w/ RF</cell><cell>baseline</cell><cell cols="4">w/o RF no AF full no AF abrupt gradual w/ RF</cell><cell>baseline</cell></row><row><cell>CD007431</cell><cell>0.047</cell><cell>0.016</cell><cell>0.026</cell><cell cols="2">0.013 0.010 ± 0.005</cell><cell>0.065</cell><cell>0.026</cell><cell>0.044</cell><cell cols="2">0.019 0.015 ± 0.005</cell></row><row><cell>CD008081</cell><cell>0.146</cell><cell>0.099</cell><cell>0.087</cell><cell cols="2">0.046 0.016 ± 0.010</cell><cell>0.114</cell><cell>0.097</cell><cell>0.060</cell><cell cols="2">0.041 0.032 ± 0.009</cell></row><row><cell>CD008760</cell><cell>0.790</cell><cell>0.516</cell><cell>0.569</cell><cell cols="2">0.835 0.169 ± 0.052</cell><cell>0.886</cell><cell>0.644</cell><cell>0.734</cell><cell cols="2">0.807 0.210 ± 0.050</cell></row><row><cell>CD008782</cell><cell>0.057</cell><cell>0.231</cell><cell>0.032</cell><cell cols="2">0.042 0.004 ± 0.002</cell><cell>0.060</cell><cell>0.242</cell><cell>0.040</cell><cell cols="2">0.050 0.005 ± 0.002</cell></row><row><cell>CD008803</cell><cell>0.181</cell><cell>0.131</cell><cell>0.147</cell><cell cols="2">0.120 0.020 ± 0.003</cell><cell>0.181</cell><cell>0.131</cell><cell>0.147</cell><cell cols="2">0.120 0.020 ± 0.002</cell></row><row><cell>CD009135</cell><cell>0.382</cell><cell>0.217</cell><cell>0.149</cell><cell cols="2">0.324 0.030 ± 0.009</cell><cell>0.485</cell><cell>0.349</cell><cell>0.266</cell><cell cols="2">0.493 0.102 ± 0.012</cell></row><row><cell>CD009185</cell><cell>0.041</cell><cell>0.049</cell><cell>0.080</cell><cell cols="2">0.027 0.018 ± 0.006</cell><cell>0.139</cell><cell>0.096</cell><cell>0.135</cell><cell cols="2">0.085 0.060 ± 0.007</cell></row><row><cell>CD009372</cell><cell>0.122</cell><cell>0.189</cell><cell>0.078</cell><cell cols="2">0.081 0.007 ± 0.006</cell><cell>0.080</cell><cell>0.107</cell><cell>0.056</cell><cell cols="2">0.060 0.014 ± 0.004</cell></row><row><cell>CD009519</cell><cell>0.031</cell><cell>0.022</cell><cell>0.034</cell><cell cols="2">0.020 0.009 ± 0.002</cell><cell>0.059</cell><cell>0.051</cell><cell>0.067</cell><cell cols="2">0.038 0.019 ± 0.002</cell></row><row><cell>CD009551</cell><cell>0.199</cell><cell>0.140</cell><cell>0.222</cell><cell cols="2">0.157 0.011 ± 0.006</cell><cell>0.287</cell><cell>0.259</cell><cell>0.259</cell><cell cols="2">0.284 0.027 ± 0.006</cell></row><row><cell>CD009579</cell><cell>0.172</cell><cell>0.105</cell><cell>0.257</cell><cell cols="2">0.286 0.013 ± 0.002</cell><cell>0.253</cell><cell>0.157</cell><cell>0.259</cell><cell cols="2">0.286 0.022 ± 0.002</cell></row><row><cell>CD009647</cell><cell>0.038</cell><cell>0.024</cell><cell>0.019</cell><cell cols="2">0.026 0.008 ± 0.004</cell><cell>0.052</cell><cell>0.040</cell><cell>0.034</cell><cell cols="2">0.068 0.022 ± 0.004</cell></row><row><cell>CD009786</cell><cell>0.028</cell><cell>0.024</cell><cell>0.012</cell><cell cols="2">0.008 0.006 ± 0.007</cell><cell>0.034</cell><cell>0.055</cell><cell>0.190</cell><cell cols="2">0.014 0.008 ± 0.007</cell></row><row><cell>CD009925</cell><cell>0.114</cell><cell>0.080</cell><cell>0.044</cell><cell cols="2">0.077 0.010 ± 0.002</cell><cell>0.334</cell><cell>0.168</cell><cell>0.151</cell><cell cols="2">0.285 0.071 ± 0.003</cell></row><row><cell>CD010023</cell><cell>0.089</cell><cell>0.058</cell><cell>0.051</cell><cell cols="2">0.085 0.020 ± 0.008</cell><cell>0.303</cell><cell>0.273</cell><cell>0.168</cell><cell cols="2">0.222 0.058 ± 0.009</cell></row><row><cell>CD010173</cell><cell>0.014</cell><cell>0.008</cell><cell>0.010</cell><cell cols="2">0.001 0.003 ± 0.004</cell><cell>0.025</cell><cell>0.014</cell><cell>0.015</cell><cell cols="2">0.003 0.006 ± 0.003</cell></row><row><cell>CD010276</cell><cell>0.072</cell><cell>0.055</cell><cell>0.032</cell><cell cols="2">0.003 0.006 ± 0.003</cell><cell>0.108</cell><cell>0.100</cell><cell>0.057</cell><cell cols="2">0.007 0.011 ± 0.003</cell></row><row><cell>CD010339</cell><cell>0.018</cell><cell>0.067</cell><cell>0.021</cell><cell cols="2">0.035 0.001 ± 0.002</cell><cell>0.043</cell><cell>0.046</cell><cell>0.020</cell><cell cols="2">0.040 0.010 ± 0.001</cell></row><row><cell>CD010386</cell><cell>0.053</cell><cell>0.083</cell><cell>0.091</cell><cell cols="2">0.167 0.009 ± 0.023</cell><cell>0.031</cell><cell>0.044</cell><cell>0.050</cell><cell cols="2">0.085 0.010 ± 0.017</cell></row><row><cell>CD010542</cell><cell>0.082</cell><cell>0.145</cell><cell>0.190</cell><cell cols="2">0.038 0.036 ± 0.021</cell><cell>0.131</cell><cell>0.158</cell><cell>0.188</cell><cell cols="2">0.110 0.068 ± 0.018</cell></row><row><cell>CD010633</cell><cell>0.015</cell><cell>0.010</cell><cell>0.010</cell><cell cols="2">0.002 0.006 ± 0.014</cell><cell>0.071</cell><cell>0.028</cell><cell>0.023</cell><cell cols="2">0.003 0.006 ± 0.010</cell></row><row><cell>CD010653</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.011</cell><cell>0.016</cell><cell>0.012</cell><cell cols="2">0.005 0.006 ± 0.002</cell></row><row><cell>CD010705</cell><cell>0.240</cell><cell>0.220</cell><cell>0.389</cell><cell cols="2">0.312 0.174 ± 0.037</cell><cell>0.250</cell><cell>0.247</cell><cell>0.444</cell><cell cols="2">0.380 0.214 ± 0.036</cell></row><row><cell>CD010772</cell><cell>0.117</cell><cell>0.035</cell><cell>0.069</cell><cell cols="2">0.086 0.048 ± 0.020</cell><cell>0.211</cell><cell>0.155</cell><cell>0.214</cell><cell cols="2">0.343 0.158 ± 0.021</cell></row><row><cell>CD010775</cell><cell>0.187</cell><cell>0.101</cell><cell>0.170</cell><cell cols="2">0.069 0.034 ± 0.031</cell><cell>0.623</cell><cell>0.462</cell><cell>0.433</cell><cell cols="2">0.258 0.062 ± 0.023</cell></row><row><cell>CD010783</cell><cell>0.071</cell><cell>0.037</cell><cell>0.020</cell><cell cols="2">0.009 0.002 ± 0.003</cell><cell>0.044</cell><cell>0.103</cell><cell>0.051</cell><cell cols="2">0.026 0.004 ± 0.002</cell></row><row><cell>CD010860</cell><cell>0.188</cell><cell>0.139</cell><cell>0.135</cell><cell cols="2">0.032 0.070 ± 0.042</cell><cell>0.168</cell><cell>0.126</cell><cell>0.134</cell><cell cols="2">0.047 0.104 ± 0.042</cell></row><row><cell>CD010896</cell><cell>0.347</cell><cell>0.093</cell><cell>0.248</cell><cell cols="2">0.239 0.037 ± 0.033</cell><cell>0.213</cell><cell>0.100</cell><cell>0.154</cell><cell cols="2">0.163 0.054 ± 0.028</cell></row><row><cell>CD011145</cell><cell>0.027</cell><cell>0.009</cell><cell>0.023</cell><cell cols="2">0.011 0.005 ± 0.001</cell><cell>0.108</cell><cell>0.044</cell><cell>0.058</cell><cell cols="2">0.038 0.019 ± 0.002</cell></row><row><cell>CD012019</cell><cell>0.003</cell><cell>0.002</cell><cell>0.003</cell><cell cols="2">0.002 0.001 ± 0.008</cell><cell>0.003</cell><cell>0.002</cell><cell>0.002</cell><cell cols="2">0.001 0.001 ± 0.001</cell></row><row><cell>Average</cell><cell>0.179</cell><cell>0.145</cell><cell>0.143</cell><cell cols="2">0.146 0.027 ± 0.003</cell><cell>0.133</cell><cell>0.100</cell><cell>0.111</cell><cell cols="2">0.109 0.047 ± 0.003</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,171.41,572.35,272.55,7.86"><head>Table 4 :</head><label>4</label><figDesc>Average precision score for all topics in the CLEF dataset.</figDesc><table coords="10,64.18,188.98,487.00,369.91"><row><cell></cell><cell></cell><cell></cell><cell>Y||MN</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>YM||N</cell><cell></cell></row><row><cell cols="5">w/o RF Topic no AF full no AF abrupt gradual w/ RF</cell><cell>baseline</cell><cell cols="4">w/o RF no AF full no AF abrupt gradual w/ RF</cell><cell>baseline</cell></row><row><cell>CD007431</cell><cell>0.825</cell><cell>0.673</cell><cell>0.762</cell><cell cols="2">0.704 0.503 ± 0.074</cell><cell>0.773</cell><cell>0.684</cell><cell>0.769</cell><cell cols="2">0.700 0.501 ± 0.060</cell></row><row><cell>CD008081</cell><cell>0.907</cell><cell>0.872</cell><cell>0.801</cell><cell cols="2">0.695 0.504 ± 0.091</cell><cell>0.801</cell><cell>0.751</cell><cell>0.653</cell><cell cols="2">0.603 0.506 ± 0.057</cell></row><row><cell>CD008760</cell><cell>0.963</cell><cell>0.895</cell><cell>0.933</cell><cell cols="2">0.955 0.518 ± 0.098</cell><cell>0.976</cell><cell>0.917</cell><cell>0.927</cell><cell cols="2">0.920 0.536 ± 0.082</cell></row><row><cell>CD008782</cell><cell>0.942</cell><cell>0.983</cell><cell>0.351</cell><cell cols="2">0.876 0.501 ± 0.050</cell><cell>0.939</cell><cell>0.977</cell><cell>0.360</cell><cell cols="2">0.888 0.500 ± 0.044</cell></row><row><cell>CD008803</cell><cell>0.944</cell><cell>0.889</cell><cell>0.898</cell><cell cols="2">0.915 0.505 ± 0.029</cell><cell>0.944</cell><cell>0.889</cell><cell>0.898</cell><cell cols="2">0.915 0.504 ± 0.028</cell></row><row><cell>CD009135</cell><cell>0.962</cell><cell>0.875</cell><cell>0.856</cell><cell cols="2">0.959 0.503 ± 0.068</cell><cell>0.875</cell><cell>0.841</cell><cell>0.744</cell><cell cols="2">0.897 0.524 ± 0.033</cell></row><row><cell>CD009185</cell><cell>0.790</cell><cell>0.676</cell><cell>0.677</cell><cell cols="2">0.744 0.500 ± 0.060</cell><cell>0.779</cell><cell>0.603</cell><cell>0.618</cell><cell cols="2">0.687 0.514 ± 0.031</cell></row><row><cell>CD009372</cell><cell>0.947</cell><cell>0.970</cell><cell>0.817</cell><cell cols="2">0.853 0.500 ± 0.092</cell><cell>0.815</cell><cell>0.839</cell><cell>0.714</cell><cell cols="2">0.749 0.501 ± 0.059</cell></row><row><cell>CD009519</cell><cell>0.865</cell><cell>0.802</cell><cell>0.862</cell><cell cols="2">0.807 0.498 ± 0.041</cell><cell>0.851</cell><cell>0.792</cell><cell>0.838</cell><cell cols="2">0.766 0.503 ± 0.028</cell></row><row><cell>CD009551</cell><cell>0.960</cell><cell>0.961</cell><cell>0.892</cell><cell cols="2">0.946 0.503 ± 0.072</cell><cell>0.945</cell><cell>0.953</cell><cell>0.862</cell><cell cols="2">0.930 0.506 ± 0.043</cell></row><row><cell>CD009579</cell><cell>0.902</cell><cell>0.784</cell><cell>0.871</cell><cell cols="2">0.913 0.505 ± 0.032</cell><cell>0.902</cell><cell>0.827</cell><cell>0.821</cell><cell cols="2">0.875 0.505 ± 0.025</cell></row><row><cell>CD009647</cell><cell>0.747</cell><cell>0.774</cell><cell>0.674</cell><cell cols="2">0.830 0.500 ± 0.071</cell><cell>0.720</cell><cell>0.706</cell><cell>0.628</cell><cell cols="2">0.835 0.504 ± 0.038</cell></row><row><cell>CD009786</cell><cell>0.918</cell><cell>0.854</cell><cell>0.756</cell><cell cols="2">0.736 0.503 ± 0.118</cell><cell>0.895</cell><cell>0.858</cell><cell>0.743</cell><cell cols="2">0.762 0.501 ± 0.093</cell></row><row><cell>CD009925</cell><cell>0.947</cell><cell>0.822</cell><cell>0.695</cell><cell cols="2">0.839 0.502 ± 0.038</cell><cell>0.883</cell><cell>0.674</cell><cell>0.616</cell><cell cols="2">0.753 0.518 ± 0.013</cell></row><row><cell>CD010023</cell><cell>0.890</cell><cell>0.806</cell><cell>0.780</cell><cell cols="2">0.879 0.504 ± 0.077</cell><cell>0.872</cell><cell>0.864</cell><cell>0.780</cell><cell cols="2">0.889 0.513 ± 0.039</cell></row><row><cell>CD010173</cell><cell>0.929</cell><cell>0.805</cell><cell>0.882</cell><cell cols="2">0.379 0.495 ± 0.091</cell><cell>0.901</cell><cell>0.770</cell><cell>0.766</cell><cell cols="2">0.383 0.502 ± 0.062</cell></row><row><cell>CD010276</cell><cell>0.956</cell><cell>0.938</cell><cell>0.882</cell><cell cols="2">0.279 0.503 ± 0.057</cell><cell>0.940</cell><cell>0.904</cell><cell>0.801</cell><cell cols="2">0.345 0.503 ± 0.038</cell></row><row><cell>CD010339</cell><cell>0.887</cell><cell>0.860</cell><cell>0.777</cell><cell cols="2">0.873 0.506 ± 0.094</cell><cell>0.816</cell><cell>0.760</cell><cell>0.580</cell><cell cols="2">0.764 0.504 ± 0.028</cell></row><row><cell>CD010386</cell><cell>0.971</cell><cell>0.982</cell><cell>0.984</cell><cell cols="2">0.992 0.512 ± 0.290</cell><cell>0.820</cell><cell>0.686</cell><cell>0.804</cell><cell cols="2">0.531 0.510 ± 0.202</cell></row><row><cell>CD010542</cell><cell>0.794</cell><cell>0.748</cell><cell>0.793</cell><cell cols="2">0.650 0.503 ± 0.099</cell><cell>0.692</cell><cell>0.606</cell><cell>0.696</cell><cell cols="2">0.676 0.512 ± 0.066</cell></row><row><cell>CD010633</cell><cell>0.846</cell><cell>0.873</cell><cell>0.830</cell><cell cols="2">0.315 0.503 ± 0.171</cell><cell>0.884</cell><cell>0.903</cell><cell>0.869</cell><cell cols="2">0.414 0.500 ± 0.145</cell></row><row><cell>CD010653</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.688</cell><cell>0.753</cell><cell>0.721</cell><cell cols="2">0.497 0.500 ± 0.043</cell></row><row><cell>CD010705</cell><cell>0.713</cell><cell>0.621</cell><cell>0.867</cell><cell cols="2">0.802 0.531 ± 0.068</cell><cell>0.655</cell><cell>0.611</cell><cell>0.868</cell><cell cols="2">0.817 0.544 ± 0.059</cell></row><row><cell>CD010772</cell><cell>0.805</cell><cell>0.455</cell><cell>0.581</cell><cell cols="2">0.679 0.504 ± 0.089</cell><cell>0.661</cell><cell>0.485</cell><cell>0.551</cell><cell cols="2">0.719 0.537 ± 0.041</cell></row><row><cell>CD010775</cell><cell>0.956</cell><cell>0.893</cell><cell>0.601</cell><cell cols="2">0.847 0.496 ± 0.146</cell><cell>0.982</cell><cell>0.947</cell><cell>0.762</cell><cell cols="2">0.914 0.508 ± 0.084</cell></row><row><cell>CD010783</cell><cell>0.935</cell><cell>0.935</cell><cell>0.926</cell><cell cols="2">0.916 0.501 ± 0.089</cell><cell>0.918</cell><cell>0.941</cell><cell>0.848</cell><cell cols="2">0.870 0.502 ± 0.052</cell></row><row><cell>CD010860</cell><cell>0.832</cell><cell>0.840</cell><cell>0.837</cell><cell cols="2">0.217 0.498 ± 0.141</cell><cell>0.697</cell><cell>0.656</cell><cell>0.667</cell><cell cols="2">0.152 0.514 ± 0.111</cell></row><row><cell>CD010896</cell><cell>0.855</cell><cell>0.648</cell><cell>0.721</cell><cell cols="2">0.904 0.501 ± 0.168</cell><cell>0.756</cell><cell>0.691</cell><cell>0.605</cell><cell cols="2">0.733 0.503 ± 0.115</cell></row><row><cell>CD011145</cell><cell>0.860</cell><cell>0.736</cell><cell>0.792</cell><cell cols="2">0.750 0.500 ± 0.042</cell><cell>0.868</cell><cell>0.751</cell><cell>0.724</cell><cell cols="2">0.723 0.504 ± 0.020</cell></row><row><cell>CD012019</cell><cell>0.964</cell><cell>0.960</cell><cell>0.962</cell><cell cols="2">0.946 0.505 ± 0.286</cell><cell>0.917</cell><cell>0.767</cell><cell>0.806</cell><cell cols="2">0.542 0.497 ± 0.160</cell></row><row><cell>Average</cell><cell>0.890</cell><cell>0.825</cell><cell>0.795</cell><cell cols="2">0.766 0.504 ± 0.022</cell><cell>0.839</cell><cell>0.780</cell><cell>0.735</cell><cell cols="2">0.708 0.509 ± 0.014</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,148.23,572.35,318.91,7.86"><head>Table 5 :</head><label>5</label><figDesc>Normalized average precision score for all topics in the CLEF dataset.</figDesc><table coords="11,64.18,188.98,487.00,369.91"><row><cell></cell><cell></cell><cell></cell><cell>Y||MN</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>YM||N</cell><cell></cell></row><row><cell cols="5">w/o RF Topic no AF full no AF abrupt gradual w/ RF</cell><cell>baseline</cell><cell cols="4">w/o RF no AF full no AF abrupt gradual w/ RF</cell><cell>baseline</cell></row><row><cell>CD007431</cell><cell>0.621</cell><cell>0.298</cell><cell>0.356</cell><cell cols="2">0.415 0.071 ± 0.078</cell><cell>0.297</cell><cell>0.079</cell><cell>0.356</cell><cell cols="2">0.323 0.030 ± 0.052</cell></row><row><cell>CD008081</cell><cell>0.452</cell><cell>0.260</cell><cell>0.056</cell><cell cols="2">0.391 0.042 ± 0.082</cell><cell>0.430</cell><cell>0.138</cell><cell>0.283</cell><cell cols="2">0.365 0.023 ± 0.048</cell></row><row><cell>CD008760</cell><cell>0.731</cell><cell>0.512</cell><cell>0.591</cell><cell cols="2">0.575 0.023 ± 0.075</cell><cell>0.731</cell><cell>0.575</cell><cell>0.591</cell><cell cols="2">0.575 0.075 ± 0.087</cell></row><row><cell>CD008782</cell><cell>0.767</cell><cell cols="2">0.873 -0.037</cell><cell cols="2">0.476 0.036 ± 0.046</cell><cell>0.706</cell><cell cols="2">0.857 -0.039</cell><cell cols="2">0.476 0.013 ± 0.035</cell></row><row><cell>CD008803</cell><cell>0.787</cell><cell>0.584</cell><cell>0.528</cell><cell cols="2">0.612 0.009 ± 0.023</cell><cell>0.787</cell><cell>0.584</cell><cell>0.528</cell><cell cols="2">0.312 0.009 ± 0.023</cell></row><row><cell>CD009135</cell><cell>0.759</cell><cell>0.457</cell><cell>0.739</cell><cell cols="2">0.783 0.048 ± 0.067</cell><cell>0.439</cell><cell>0.403</cell><cell>0.035</cell><cell cols="2">0.580 0.012 ± 0.026</cell></row><row><cell>CD009185</cell><cell>0.377</cell><cell>0.073</cell><cell>0.096</cell><cell cols="2">0.500 0.031 ± 0.057</cell><cell>0.377</cell><cell>0.026</cell><cell>0.024</cell><cell cols="2">0.114 0.013 ± 0.025</cell></row><row><cell>CD009372</cell><cell>0.654</cell><cell>0.844</cell><cell>0.051</cell><cell cols="2">0.170 0.040 ± 0.083</cell><cell>0.353</cell><cell>0.461</cell><cell>0.139</cell><cell cols="2">0.170 0.025 ± 0.050</cell></row><row><cell>CD009519</cell><cell>0.597</cell><cell>0.294</cell><cell>0.442</cell><cell cols="2">0.624 0.011 ± 0.034</cell><cell>0.483</cell><cell>0.219</cell><cell>0.336</cell><cell cols="2">0.291 0.006 ± 0.022</cell></row><row><cell>CD009551</cell><cell>0.856</cell><cell>0.866</cell><cell>0.584</cell><cell cols="2">0.834 0.070 ± 0.075</cell><cell>0.757</cell><cell>0.838</cell><cell>0.368</cell><cell cols="2">0.667 0.014 ± 0.037</cell></row><row><cell>CD009579</cell><cell>0.531</cell><cell>0.153</cell><cell>0.327</cell><cell cols="2">0.522 0.012 ± 0.027</cell><cell>0.580</cell><cell>0.275</cell><cell>0.203</cell><cell cols="2">0.351 0.008 ± 0.021</cell></row><row><cell>CD009647</cell><cell>0.321</cell><cell>0.469</cell><cell>0.124</cell><cell cols="2">0.577 0.058 ± 0.073</cell><cell>0.240</cell><cell>0.243</cell><cell>0.028</cell><cell cols="2">0.499 0.018 ± 0.033</cell></row><row><cell>CD009786</cell><cell>0.799</cell><cell>0.656</cell><cell>0.134</cell><cell cols="2">0.248 0.098 ± 0.124</cell><cell>0.621</cell><cell>0.656</cell><cell>0.234</cell><cell cols="2">0.248 0.041 ± 0.085</cell></row><row><cell>CD009925</cell><cell>0.810</cell><cell>0.346</cell><cell>0.050</cell><cell cols="2">0.277 0.022 ± 0.033</cell><cell>0.469</cell><cell>0.0</cell><cell cols="3">-0.040 -0.037 0.002 ± 0.010</cell></row><row><cell>CD010023</cell><cell>0.714</cell><cell>0.649</cell><cell>0.572</cell><cell cols="2">0.693 0.085 ± 0.085</cell><cell>0.492</cell><cell>0.474</cell><cell>0.515</cell><cell cols="2">0.662 0.024 ± 0.034</cell></row><row><cell>CD010173</cell><cell>0.777</cell><cell>0.476</cell><cell>0.555</cell><cell cols="2">0.078 0.039 ± 0.083</cell><cell>0.671</cell><cell>0.271</cell><cell>0.174</cell><cell cols="2">0.078 0.034 ± 0.057</cell></row><row><cell>CD010276</cell><cell>0.811</cell><cell>0.803</cell><cell>0.486</cell><cell cols="2">-0.031 0.031 ± 0.050</cell><cell>0.719</cell><cell>0.511</cell><cell>0.217</cell><cell cols="2">-0.031 0.024 ± 0.034</cell></row><row><cell>CD010339</cell><cell>0.193</cell><cell>0.114</cell><cell>0.077</cell><cell cols="2">0.330 0.052 ± 0.095</cell><cell>0.346</cell><cell>0.192</cell><cell>0.026</cell><cell cols="2">0.219 0.011 ± 0.023</cell></row><row><cell>CD010386</cell><cell>0.920</cell><cell>0.931</cell><cell>0.932</cell><cell cols="2">0.940 0.461 ± 0.289</cell><cell>0.616</cell><cell>0.337</cell><cell>0.571</cell><cell cols="2">0.019 0.286 ± 0.237</cell></row><row><cell>CD010542</cell><cell>0.464</cell><cell>0.171</cell><cell>0.099</cell><cell cols="2">0.191 0.056 ± 0.097</cell><cell>0.232</cell><cell>0.065</cell><cell>0.099</cell><cell cols="2">0.191 0.041 ± 0.061</cell></row><row><cell>CD010633</cell><cell>0.637</cell><cell>0.741</cell><cell>0.584</cell><cell cols="2">0.050 0.203 ± 0.197</cell><cell>0.637</cell><cell>0.741</cell><cell>0.584</cell><cell cols="2">0.050 0.143 ± 0.164</cell></row><row><cell>CD010653</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.218</cell><cell>0.272</cell><cell>0.227</cell><cell cols="2">0.050 0.014 ± 0.035</cell></row><row><cell>CD010705</cell><cell>0.213</cell><cell>0.187</cell><cell>0.625</cell><cell cols="2">0.503 0.040 ± 0.064</cell><cell>0.064</cell><cell>0.161</cell><cell>0.564</cell><cell cols="2">0.494 0.014 ± 0.048</cell></row><row><cell>CD010772</cell><cell>0.532</cell><cell>0.070</cell><cell>0.247</cell><cell cols="2">0.153 0.108 ± 0.101</cell><cell>0.077</cell><cell cols="4">0.001 -0.041 -0.009 0.006 ± 0.031</cell></row><row><cell>CD010775</cell><cell>0.867</cell><cell>0.726</cell><cell>0.170</cell><cell cols="2">0.701 0.140 ± 0.163</cell><cell>0.867</cell><cell>0.813</cell><cell>0.174</cell><cell cols="2">0.718 0.109 ± 0.098</cell></row><row><cell>CD010783</cell><cell>0.856</cell><cell>0.906</cell><cell>0.819</cell><cell cols="2">0.842 0.124 ± 0.106</cell><cell>0.701</cell><cell>0.381</cell><cell>0.340</cell><cell cols="2">0.072 0.015 ± 0.043</cell></row><row><cell>CD010860</cell><cell>0.578</cell><cell>0.695</cell><cell>0.716</cell><cell cols="2">0.046 0.134 ± 0.155</cell><cell>0.237</cell><cell cols="4">0.067 -0.050 -0.039 0.065 ± 0.106</cell></row><row><cell>CD010896</cell><cell>0.517</cell><cell>0.098</cell><cell>0.151</cell><cell cols="2">0.684 0.192 ± 0.196</cell><cell>0.518</cell><cell>0.098</cell><cell>0.151</cell><cell cols="2">0.051 0.086 ± 0.121</cell></row><row><cell>CD011145</cell><cell>0.497</cell><cell>0.342</cell><cell>0.228</cell><cell cols="2">0.175 0.011 ± 0.034</cell><cell>0.446</cell><cell>0.327</cell><cell>0.108</cell><cell cols="2">0.103 0.004 ± 0.015</cell></row><row><cell>CD012019</cell><cell>0.914</cell><cell>0.909</cell><cell>0.912</cell><cell cols="2">0.896 0.455 ± 0.286</cell><cell>0.797</cell><cell>0.369</cell><cell>0.534</cell><cell cols="2">0.276 0.195 ± 0.190</cell></row><row><cell>Average</cell><cell>0.640</cell><cell>0.500</cell><cell>0.390</cell><cell cols="2">0.457 0.093 ± 0.023</cell><cell>0.497</cell><cell>0.348</cell><cell>0.241</cell><cell cols="2">0.271 0.015 ± 0.016</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="11,137.87,572.35,339.61,7.86"><head>Table 6 :</head><label>6</label><figDesc>Work saved over sampling at 95% recall for all topics in the CLEF dataset.</figDesc><table coords="12,61.65,165.79,492.05,194.56"><row><cell></cell><cell></cell><cell></cell><cell>Y||MN</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>YM||N</cell><cell></cell><cell></cell></row><row><cell cols="5">w/o RF Topic no AF full no AF abrupt gradual w/ RF</cell><cell>baseline</cell><cell cols="4">w/o RF no AF full no AF abrupt gradual w/ RF</cell><cell>baseline</cell></row><row><cell>WSS@95</cell><cell>0.640</cell><cell>0.500</cell><cell>0.390</cell><cell>0.457</cell><cell>0.093 ± 0.023</cell><cell>0.497</cell><cell>0.348</cell><cell>0.241</cell><cell cols="2">0.271 0.045 ± 0.016</cell></row><row><cell>WSS@100</cell><cell>0.591</cell><cell>0.420</cell><cell>0.350</cell><cell>0.407</cell><cell>0.112 ± 0.022</cell><cell>0.412</cell><cell>0.261</cell><cell>0.173</cell><cell cols="2">0.195 0.056 ± 0.015</cell></row><row><cell>last rel</cell><cell>1678</cell><cell>2263</cell><cell>2619</cell><cell>2384</cell><cell>3393.7 ± 118.1</cell><cell>2250</cell><cell>2993</cell><cell>3414</cell><cell>3406</cell><cell>3749.7 ± 68.8</cell></row><row><cell>NCG@10</cell><cell>0.517</cell><cell>0.407</cell><cell>0.357</cell><cell>0.346</cell><cell>0.081 ± 0.010</cell><cell>0.475</cell><cell>0.367</cell><cell>0.316</cell><cell cols="2">0.350 0.092 ± 0.006</cell></row><row><cell>NCG@20</cell><cell>0.802</cell><cell>0.639</cell><cell>0.644</cell><cell>0.685</cell><cell>0.180 ± 0.015</cell><cell>0.717</cell><cell>0.554</cell><cell>0.518</cell><cell cols="2">0.601 0.192 ± 0.008</cell></row><row><cell>NCG@30</cell><cell>0.908</cell><cell>0.783</cell><cell>0.753</cell><cell>0.789</cell><cell>0.280 ± 0.018</cell><cell>0.825</cell><cell>0.674</cell><cell>0.609</cell><cell cols="2">0.698 0.291 ± 0.010</cell></row><row><cell>NCG@40</cell><cell>0.946</cell><cell>0.843</cell><cell>0.814</cell><cell>0.832</cell><cell>0.379 ± 0.020</cell><cell>0.887</cell><cell>0.746</cell><cell>0.678</cell><cell cols="2">0.763 0.391 ± 0.011</cell></row><row><cell>NCG@50</cell><cell>0.972</cell><cell>0.890</cell><cell>0.842</cell><cell>0.881</cell><cell>0.479 ± 0.020</cell><cell>0.929</cell><cell>0.800</cell><cell>0.727</cell><cell cols="2">0.816 0.491 ± 0.011</cell></row><row><cell>NCG@60</cell><cell>0.984</cell><cell>0.921</cell><cell>0.886</cell><cell>0.911</cell><cell>0.579 ± 0.020</cell><cell>0.955</cell><cell>0.851</cell><cell>0.789</cell><cell cols="2">0.853 0.591 ± 0.011</cell></row><row><cell>NCG@70</cell><cell>0.990</cell><cell>0.942</cell><cell>0.911</cell><cell>0.937</cell><cell>0.679 ± 0.018</cell><cell>0.976</cell><cell>0.903</cell><cell>0.834</cell><cell cols="2">0.889 0.691 ± 0.011</cell></row><row><cell>NCG@80</cell><cell>0.997</cell><cell>0.960</cell><cell>0.939</cell><cell>0.959</cell><cell>0.778 ± 0.016</cell><cell>0.987</cell><cell>0.930</cell><cell>0.878</cell><cell cols="2">0.918 0.791 ± 0.007</cell></row><row><cell>NCG@90</cell><cell>0.998</cell><cell>0.987</cell><cell>0.965</cell><cell>0.980</cell><cell>0.878 ± 0.013</cell><cell>0.996</cell><cell>0.964</cell><cell>0.920</cell><cell cols="2">0.943 0.890 ± 0.007</cell></row><row><cell>NCG@100</cell><cell>1.000</cell><cell>0.998</cell><cell>1.000</cell><cell>1.000</cell><cell>0.977 ± 0.006</cell><cell>1.000</cell><cell>0.999</cell><cell>0.998</cell><cell cols="2">0.997 0.990 ± 0.002</cell></row><row><cell>norm area</cell><cell>0.890</cell><cell>0.825</cell><cell>0.795</cell><cell>0.766</cell><cell>0.504 ± 0.022</cell><cell>0.839</cell><cell>0.780</cell><cell>0.735</cell><cell cols="2">0.708 0.509 ± 0.014</cell></row><row><cell>ap</cell><cell>0.133</cell><cell>0.100</cell><cell>0.111</cell><cell>0.109</cell><cell>0.027 ± 0.003</cell><cell>0.179</cell><cell>0.145</cell><cell>0.143</cell><cell cols="2">0.146 0.047 ± 0.003</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="12,100.17,373.81,415.40,186.87"><head>Table 7 :</head><label>7</label><figDesc>Aggregate performance for each ranking metric.</figDesc><table coords="12,100.17,498.37,415.40,62.31"><row><cell></cell><cell></cell><cell></cell><cell cols="2">WSS@95</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>AUC</cell></row><row><cell></cell><cell></cell><cell cols="2">no AF full</cell><cell></cell><cell cols="2">no AF</cell><cell></cell><cell cols="2">no AF full</cell><cell>no AF</cell></row><row><cell cols="3">Topic mean std</cell><cell cols="3">min max mean std</cell><cell cols="3">min max mean std</cell><cell>min max mean std</cell><cell>min max</cell></row><row><cell>CD008760</cell><cell>.723</cell><cell cols="2">.034 .653 .762</cell><cell>.666</cell><cell cols="2">.080 .481 .764</cell><cell>.949</cell><cell cols="2">.012 .933 .971</cell><cell>.937</cell><cell>.020 .899 .962</cell></row><row><cell>CD010386</cell><cell>.899</cell><cell cols="2">.012 .883 .921</cell><cell>.932</cell><cell cols="2">.006 .923 .942</cell><cell>.949</cell><cell cols="2">.012 .933 .971</cell><cell>.982</cell><cell>.006 .973 .992</cell></row><row><cell>CD010705</cell><cell>.085</cell><cell cols="2">.036 .025 .143</cell><cell>.047</cell><cell cols="2">.027 .011 .099</cell><cell>.696</cell><cell cols="2">.013 .683 .705</cell><cell>.595</cell><cell>.028 .572 .632</cell></row><row><cell>CD012019</cell><cell>.920</cell><cell cols="2">.006 .907 .929</cell><cell>.923</cell><cell cols="2">.007 .903 .927</cell><cell>.962</cell><cell cols="2">.010 .949 .982</cell><cell>.973</cell><cell>.007 .899 .979</cell></row><row><cell>CD010339</cell><cell>.250</cell><cell cols="2">.085 .084 .415</cell><cell>.438</cell><cell cols="2">.139 .265 .607</cell><cell>.884</cell><cell cols="2">.013 .029 .864</cell><cell>.903</cell><cell>.039 .798 .923</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="12,134.77,573.63,345.83,30.03"><head>Table 8 :</head><label>8</label><figDesc>The average, standard deviation, mininum, and maximum WSS@95 and AUC over ten iterations on a subset of the topic in CLEF for our systems no AF and no AF full.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This project has received funding from the <rs type="funder">European Union</rs>'s <rs type="programName">Horizon 2020 research and innovation programme</rs> under the <rs type="grantName">Marie Sklodowska-Curie</rs> grant agreement No <rs type="grantNumber">676207</rs>.</p></div>
<div><head>Bibliography</head></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_3HcV84d">
					<idno type="grant-number">676207</idno>
					<orgName type="grant-name">Marie Sklodowska-Curie</orgName>
					<orgName type="program" subtype="full">Horizon 2020 research and innovation programme</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="17,155.24,170.80,325.35,8.74;17,155.24,182.75,325.35,8.74;17,155.24,194.71,83.03,8.74" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="17,381.74,170.80,98.84,8.74;17,155.24,182.75,325.35,8.74">Reducing Workload in Systematic Review Preparation Using Automated Citation Classification</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="206" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,155.24,206.67,325.35,8.74;17,155.24,218.62,325.34,8.74;17,155.24,230.58,35.97,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="17,217.76,206.67,262.84,8.74;17,155.24,218.62,110.47,8.74">Optimizing feature representation for automated systematic review work prioritization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,272.49,218.62,168.75,8.74">AMIA Annual Symposium proceedings</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="121" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,155.24,242.53,325.35,8.74;17,155.24,254.49,325.35,8.74;17,155.24,266.44,153.62,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="17,264.59,242.53,216.00,8.74;17,155.24,254.49,25.69,8.74">The relationship between precision-recall and roc curves</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Goadrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,206.54,254.49,274.05,8.74;17,155.24,266.44,33.48,8.74">Proceedings of the 23rd international conference on Machine learning</title>
		<meeting>the 23rd international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,155.24,278.40,325.35,8.74;17,155.24,290.35,232.46,8.74" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="17,377.34,278.40,103.25,8.74;17,155.24,290.35,232.46,8.74">Overview of the CLEF technologically assisted reviews in empirical medicine</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Spijker</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="17,155.24,302.31,325.35,8.74;17,155.24,314.26,325.35,8.74;17,155.24,326.22,276.41,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="17,442.23,302.31,38.36,8.74;17,155.24,314.26,325.35,8.74;17,155.24,326.22,87.48,8.74">Learning to identify relevant studies for systematic reviews using random forest and external information</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Khabsa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Elmagarmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hammady</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ouzzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,250.50,326.22,78.20,8.74">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="465" to="482" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,155.24,338.17,325.35,8.74;17,155.24,350.13,325.35,8.74;17,155.24,362.08,280.37,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="17,465.87,338.17,14.72,8.74;17,155.24,350.13,325.35,8.74;17,155.24,362.08,123.40,8.74">Using text mining for study identification in systematic reviews: a systematic review of current approaches</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>O'mara-Eves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mcnaught</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ananiadou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,286.59,362.08,82.60,8.74">Systematic reviews</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,155.24,374.04,325.35,8.74;17,155.24,385.99,325.35,8.74;17,155.24,397.95,199.37,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="17,204.46,385.99,179.66,8.74">Scikit-learn: Machine learning in python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,393.65,385.99,86.94,8.74;17,155.24,397.95,80.37,8.74">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011-10">Oct. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,155.24,409.90,325.35,8.74;17,155.24,421.86,325.35,8.74;17,155.24,433.81,319.30,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="17,346.18,409.90,134.41,8.74;17,155.24,421.86,325.35,8.74;17,155.24,433.81,125.59,8.74">Increased workload for systematic review literature searches of diagnostic tests compared with treatments: Challenges and opportunities</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Loy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,288.50,433.81,113.54,8.74">JMIR medical informatics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,155.24,445.77,325.34,8.74;17,155.24,457.72,325.35,8.74;17,155.24,469.68,140.72,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="17,281.38,445.77,199.20,8.74;17,155.24,457.72,321.09,8.74">The precision-recall plot is more informative than the roc plot when evaluating binary classifiers on imbalanced datasets</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rehmsmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,155.24,469.68,38.33,8.74">PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">118432</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,155.24,481.63,325.35,8.74;17,155.24,493.59,325.35,8.74;17,155.24,505.54,325.35,8.74;17,155.24,517.50,325.34,8.74;17,155.24,529.45,325.34,8.74;17,155.24,541.41,163.91,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="17,297.87,493.59,182.72,8.74;17,155.24,505.54,13.28,8.74">Overview of the CLEF ehealth evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Spijker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R M</forename><surname>Palotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,216.13,505.54,264.46,8.74;17,155.24,517.50,325.34,8.74;17,155.24,529.45,18.15,8.74">Experimental IR Meets Multilinguality, Multimodality, and Interaction -8th International Conference of the CLEF Association, CLEF 2017</title>
		<title level="s" coord="17,360.92,529.45,119.67,8.74;17,155.24,541.41,88.73,8.74">Proceedings. Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017-09-11">2017. September 11-14, 2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
