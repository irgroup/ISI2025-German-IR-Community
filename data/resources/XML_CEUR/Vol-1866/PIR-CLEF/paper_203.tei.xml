<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,142.15,115.90,331.06,12.68;1,147.12,133.83,321.12,12.68">EvalUMAP: Towards comparative evaluation in user modeling, adaptation and personalization</title>
				<funder ref="#_CvqEuUs">
					<orgName type="full">European Regional Development Fund</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,137.16,171.50,58.93,8.80"><forename type="first">Owen</forename><surname>Conlan</surname></persName>
							<email>owen.conlan@scss.tcd.ie</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ADAPT Centre</orgName>
								<orgName type="department" key="dep2">School of Computer Science</orgName>
								<orgName type="institution">Statistics Trinity College Dublin</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,206.65,171.50,51.33,8.80"><forename type="first">Liadh</forename><surname>Kelly</surname></persName>
							<email>liadh.kelly@dcu.ie</email>
							<affiliation key="aff1">
								<orgName type="department">ADAPT Centre</orgName>
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,268.53,171.50,52.57,8.80"><forename type="first">Kevin</forename><surname>Koidl</surname></persName>
							<email>kevin.koidl@scss.tcd.ie</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ADAPT Centre</orgName>
								<orgName type="department" key="dep2">School of Computer Science</orgName>
								<orgName type="institution">Statistics Trinity College Dublin</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,331.65,171.50,68.92,8.80"><forename type="first">Séamus</forename><surname>Lawless</surname></persName>
							<email>seamus.lawless@scss.tcd.ie</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ADAPT Centre</orgName>
								<orgName type="department" key="dep2">School of Computer Science</orgName>
								<orgName type="institution">Statistics Trinity College Dublin</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,430.50,171.50,47.70,8.80;1,277.89,183.45,55.11,8.80"><forename type="first">Athanasios</forename><surname>Staikopoulos</surname></persName>
							<email>athanasios.staikopoulos@scss.tcd.ie</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ADAPT Centre</orgName>
								<orgName type="department" key="dep2">School of Computer Science</orgName>
								<orgName type="institution">Statistics Trinity College Dublin</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,142.15,115.90,331.06,12.68;1,147.12,133.83,321.12,12.68">EvalUMAP: Towards comparative evaluation in user modeling, adaptation and personalization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E041BC82DD33A74C41BA91BE25B277F3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>There is currently no established or standardized means for the comparative evaluation of algorithms and systems developed by researchers in the User Modeling, Adaptation and Personalization (UMAP) space. The design and establishment of such methodologies has proven to be extremely difficult, but would be highly rewarding, as demonstrated by initiatives such as CLEF, TREC and NTCIR in the Information Retrieval domain. Privacy concerns, the challenges of working with interactive scenarios, and individual differences in behaviour between users must all be addressed in order to facilitate repeatable and comparable evaluation, and to advance research in this domain. In this paper we present EvalUMAP, a new concerted drive towards the establishment of shared challenges for comparative evaluation within the UMAP community.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Research in the areas of User Modelling, Adaptation and Personalization (UMAP) faces a number of significant scientific challenges. One of the most significant of these challenges is the issue of comparative evaluation. It has always been difficult to rigorously compare different approaches to personalization, as the function of the resulting systems is, by their nature, heavily influenced by the behaviour of the users involved in trialling the systems. To-date this topic has received relatively little attention when compared with other areas of Computer Science research, such as Information Retrieval (IR). Developing comparative evaluations in this space would be a huge advancement as it would enable shared comparison across research, which to-date has been very limited.</p><p>One of the significant challenges in establishing such an initiative, is that the UMAP community encompasses a broad range of research areas and technologies. An array of approaches to User Modeling exist, with no standardised approach to data capture, analysis or representation. Personalised and adaptive systems that utilise user models are also hugely varied in nature, from personalised IR systems which tailor the selection and ranking of content to an individual, to more complex personalised learning systems, which tailor interaction and learning offerings to an individual based upon their competency or performance in learning tasks.</p><p>Taking inspiration from communities such as IR and Machine Translation (MT), the EvalUMAP Workshop series <ref type="foot" coords="2,304.83,165.20,3.97,6.16" target="#foot_0">3</ref> was established in 2016 with the ambitious goal of moving towards comparative evaluation in the UMAP community. A specific first goal was set, to propose and design one or more shared tasks to support the comparative evaluation of approaches to User Modelling, Adaptation and Personalization. The long term vision is the establishment of an annual shared challenge series, similar to TREC<ref type="foot" coords="2,319.33,224.97,3.97,6.16" target="#foot_1">4</ref> and CLEF <ref type="foot" coords="2,376.06,224.97,3.97,6.16" target="#foot_2">5</ref> in the IR space. The establishment of such shared tasks requires that appropriate models, content, metadata, user behaviours, etc. be available, in order to comprehensively compare how different approaches and systems perform. In addition, a number of metrics and observations would need to be outlined, that participants would be expected to perform in order to facilitate comparison. This is significant. To move towards this goal we, as a community need to greatly advance our understanding of, and methodology associated with UMAP evaluation. Including not only the technical challenges associated with design and implementation, but also privacy, ethics, legal and security issues, evaluation methodologies and metrics.</p><p>When compared with shared tasks in IR, EvalUMAP aims to develop tasks and test collections which are focused on variations in the user (represented by variations in the underlying user model) and the personalised decisions taken by the systems, rather than variations in the queries and/or relevance judgments provided. The ultimate goal is to have the users who are being modeled involved in judging the performance of the personalised systems, and thereby contributing to the iterative enhancement of the test collections used.</p><p>In the next section we provide background for the EvalUMAP initiative and then move on to provide an overview of progress to-date towards this goal. We conclude with a discussion of future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Despite research interest and progress being made in UMAP research, it is well understood within the community that progression has been limited by a lack of cross comparable evaluation methods <ref type="bibr" coords="2,311.45,544.13,33.36,8.80">[10] [13]</ref>. This problem was highlighted during the panel session at the UMAP 2015 conference. An outcome of which was the need for community exerted effort in developing cross comparable evaluation approaches in UMAP evaluation. The subsequent EvalUMAP 2016 workshop <ref type="bibr" coords="2,470.08,580.00,10.51,8.80" target="#b6">[7]</ref> began concrete discussion on this topic.</p><p>Currently, there are no established or standardized baselines or evaluation metrics, and no commonly available test collections. Privacy concerns, the chal-lenges of working with interactive scenarios, and the individual differences in behaviour between users all must be addressed in order to facilitate repeatable and comparable evaluation and to advance research in this domain. While overcoming these problems is a big challenge, there have been some notable efforts in the past from which to build on.</p><p>Park et. al <ref type="bibr" coords="3,203.67,179.77,15.49,8.80" target="#b15">[16]</ref> for example, propose a two phase evaluation model consisting of a qualitative pre-screening phase followed by quantitative user-based assessments (using objective measures) to compare various content alternatives. Weibelzahl <ref type="bibr" coords="3,186.07,215.63,15.49,8.80" target="#b20">[21]</ref> and Chin et. al <ref type="bibr" coords="3,277.42,215.63,10.51,8.80" target="#b4">[5]</ref> on the other hand focus more on the need for system-wide empirical evaluations determining which users were helped or hindered by user-adapted interactions. Van Velsen et. al <ref type="bibr" coords="3,391.46,239.54,15.49,8.80" target="#b19">[20]</ref> also attempt to produce a model summarising the variables being assessed at each stage of the process along with relevant methods to assess them.</p><p>As more methods evaluating the usefulness and accuracy of adaptive systems appeared, the need to evaluate these evaluation methods became evident. Klaassen et. al <ref type="bibr" coords="3,201.38,300.38,15.49,8.80" target="#b18">[19]</ref> for example evaluated three of the most common test methods used to detect usability problems in personalised systems. More recently, Paramythis et. al. <ref type="bibr" coords="3,217.33,324.29,15.49,8.80" target="#b14">[15]</ref> proposed to unify previous approaches presented in the literature by introducing the Layered Evaluation framework. This approach seeks to tackle the difficulties involved with evaluating adaptivity by decomposing such systems into independent layers of adaptivity (such as User Model, Content Model and Adaptive Decisions Logic). They also propose methods related to the various development lifecycle stages of interactive systems. However, this layered approach advocates evaluations that require a separation of concerns within the design process that is not always possible. The main advantage however is that it enables a clear identification of issues within elements of the design.</p><p>As can be seen, adaptive system evaluation has been a recurrent topic within the community over the years. Nevertheless, a solution capable of delivering repeatable and comparable results that would become the standard method to evaluate UMAP research has yet to emerge. Improved solutions for UMAP evaluation that have lower cost, are more repeatable, and more realistic are required.</p><p>Lessons can be learned here from progress in other domains in shared challenge generation. The nearest to our UMAP challenge being arguably that of the Information Retrieval (IR) community. This community has a long history in shared challenge generation, with multiple established shared challenge evaluation series running across the globe, namely TREC<ref type="foot" coords="3,361.37,540.04,3.97,6.16" target="#foot_3">6</ref> , NTCIR<ref type="foot" coords="3,404.51,540.04,3.97,6.16" target="#foot_4">7</ref> , FIRE<ref type="foot" coords="3,439.07,540.04,3.97,6.16" target="#foot_5">8</ref> , CLEF <ref type="foot" coords="3,476.12,540.04,3.97,6.16" target="#foot_6">9</ref>and most recently MediaEval <ref type="foot" coords="3,262.94,552.00,7.94,6.16" target="#foot_7">10</ref> . The evaluation methodology adopted by these shared challenges primarily involves the sharing of resources with participating teams to perform a task, for example data retrieval or annotation. Each participating team then uses their developed technique to perform the ad hoc task using the provided data collection. Performance in the task is marked against an organizer provided gold standard.</p><p>These challenges traditionally considered the once off requirements of a typical or standard user of a system. In recent years the community has started to look more closely at bringing the user into the loop, exploring the creation of shared challenges that consider iterative search sessions (for example in initiatives such as <ref type="bibr" coords="4,190.20,191.25,10.29,8.80" target="#b8">[9]</ref>), providing profiles of individual users to aid search (for example, the new PIR-CLEF task <ref type="foot" coords="4,243.33,201.65,7.94,6.16" target="#foot_8">11</ref> ) and providing access to real users conducting real search tasks <ref type="bibr" coords="4,190.50,215.16,10.20,8.80" target="#b1">[2]</ref> <ref type="bibr" coords="4,200.70,215.16,10.20,8.80" target="#b7">[8]</ref>. Most recently, the Personalized Information Retrieval (PIR) task at CLEF 2017 introduces user profiles to personalize the retrieval process <ref type="foot" coords="4,134.77,237.51,7.94,6.16" target="#foot_9">12</ref> .</p><p>In working towards the possibility of shared challenges in the UMAP community we can learn from such initiatives. However, the types of algorithms and systems which the UMAP community seek to evaluate are of a distinct nature, and as such will require their own unique solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Outcomes of EvalUMAP 2016</head><p>The 1st International EvalUMAP 2016 Workshop brought together researchers from across the User Modelling, Adaptation and Personalization community to explore potential new ideas and approaches to support comparative evaluations. This area of research is identified as inherently complex, not only because of its focus on the user, but also because of the different and diverse domains involved. To date this has presented significant barriers to how research outcomes can be compared. In particular, the 1st EvalUMAP workshop investigated how the UMAP research community can facilitate the shared development of evaluation tasks and competitions. In the EvalUMAP 2016 workshop, 10 position and discussion papers were accepted, covering different evaluation aspects from potential frameworks and platforms to requirements and reference models as well as specific evaluation areas and metrics.</p><p>More specifically, the contributions of the papers were as follows: Koidl et. al. <ref type="bibr" coords="4,134.77,505.09,15.49,8.80" target="#b11">[12]</ref> alleged that researchers conducting evaluations in the fields of User Modelling and Personalisation face the challenge of missing continuing evaluation feedback and collaboration with the overall research community. As a result, the authors proposed a community-driven portal introduced as ECP (Evaluation Community Portal) specifically focused on evaluations within the UMAP community. ECP is inspired by work from the Cross-Language Evaluation Forum (CLEF) <ref type="foot" coords="4,191.20,575.26,7.94,6.16" target="#foot_10">13</ref> , and is based on the simplicity of Calls for Papers (CFP). As a starting point, the authors proposed the following key features: a) ability to post calls for participation in evaluations, b) ability to discuss approaches and findings in a forum manner, c) ability to upload and present data that can be shared and used in other evaluations. Furthermore, an initial task force (community champions) leading these efforts needs to be identified, that will bootstrap the Portal and provide the initial community momentum.</p><p>Vahid et. al. <ref type="bibr" coords="5,205.65,158.50,15.49,8.80" target="#b17">[18]</ref> presented how related tasks were designed -involving gathering users profiles and objects of their interest, in well-known IR evaluation communities. The paper reviews and compares existing user tasks and describes task resource collection, methods and metrics. In particular, the paper describes two tasks a) the Contextual Suggestion Task of TREC (Text REtrieval Conference) and b) the Social Book Search Task of CLEF. The goal of the contextual suggestion task is to evaluate the search techniques for complex information needs of users with respect to context and their point of interest. This task investigates the development of systems that are able to make suggestions of sites with the goal to explore an unknown city based upon the user's personal interests in the user's home city. A set of user preferences, example suggestions and a set of contexts are given to participants as inputs. As evaluation metrics, Precision at Rank 5 (P@5), Mean Reciprocal Rank (MRR) and a modified version of Time-Biased Gain (TBG) are used to rank participants runs. The Social Book Search task investigates evaluation methodologies for a book search task using a combination of various aspects of retrieval and recommendation dealing with professional and user-generated meta-data. A set of book requests and a set of user profiles have been assumed as inputs of the task and a submitted ranked list of recommended books has been evaluated as the result of participant's systems. The official evaluation measure for this task is nDCG@10. It takes graded relevance values into account and is designed for evaluation based on the top retrieved results. In addition, P@10, MAP and MRR scores will also be reported, with the evaluation results.</p><p>Next, Pandit et. al. <ref type="bibr" coords="5,237.91,437.17,15.49,8.80" target="#b13">[14]</ref> emphasised the need to support the reproducibility of results in a systematic way. Reproducibility of results is a key element for the verification of scientific experiments and an important indicator of the quality of a published experiment. Therefore, it is vital to precisely and transparently share both the method and the data associated with an experiment. In particular, in their paper the authors explore how emerging linked data standards such as the P-PLAN, CSVW and DCAT ontologies can be applied to the description of the steps and data associated with a published adaptive or personalised experiment in a manner that can be easily located, linked, accessed and reused to repeat an experiment. L. Kelly <ref type="bibr" coords="5,187.43,560.42,15.49,8.80" target="#b10">[11]</ref> proposed using the Living Labs methodology, an emerging evaluation paradigm in IR and recommender systems that provides a platform for supporting shared evaluation tasks. In this case, Living Labs will be adapted to allow for shared evaluation tasks in the UMAP community and, specifically, to support the individual requirements and differences, privacy concerns and the interactive nature of the space. In general, Living labs hold great promise for conducting realistic evaluations, with real users in natural task environments, and more importantly allowing for cross comparability (e.g. by providing a benchmarking platform, perform rankings) across research centres.</p><p>Adaji and Vassileva <ref type="bibr" coords="6,236.96,118.93,10.51,8.80" target="#b0">[1]</ref> introduced the Persuasive Systems Design (PSD) as a framework for developing and evaluating persuasive systems. Despite its extensive use as a guide for developing persuasive systems, its use as an evaluation tool for persuasive systems is yet to be exploited. The PSD framework is comprised of persuasive principles that could be used to develop and implement strategies that encourage personalisation and adaptation to user preferences. Using Netflix as a case study, the authors identified the implementation of the persuasive principles and the design of system features. This study can act as a guide for the development of evaluation metrics for persuasive related shared tasks.</p><p>Bogina and Kuflik <ref type="bibr" coords="6,231.52,234.21,10.51,8.80" target="#b2">[3]</ref> pointed out that User Adaptive Systems (UAS) do not intersect with software evaluations as commonly defined in Software Engineering domain. As a result, the authors suggested adopting the common software engineering practices and changing the community's practice and methods by integrating software testing as an integral part of the shared task evaluation process. This would result in more easily reproducible/reusable tasks and data for other members of the community.</p><p>Next, P.D. Bra <ref type="bibr" coords="6,217.29,325.58,10.51,8.80" target="#b3">[4]</ref> indicates that there is a strong focus on comparative evaluation in the research field of User Modeling, Adaptation and Personalization. In particular, the author discusses and argues when it is reasonable (makes sense) to perform such evaluation on adaptive systems and applications. For adaptive systems, the author argues that these types of comparisons have not gained much acceptance as being "evaluation" by the UMAP community. For applications, the author argues that it is difficult to perform a meaningful evaluation because it is hard to find something to compare the (use of the) application with. In both cases, having a common reference model and applying layered approaches among others may help the community get started and allow different systems and applications to be compared. <ref type="bibr" coords="6,264.69,464.78,15.49,8.80" target="#b16">[17]</ref> focused on evaluating user-adaptive systems and pointed out that it is still a challenging research issue and a difficult task. This is because of the lack of widely accepted evaluation methods, data and the difficulty on generalizing the application areas (e.g. learning, information systems, business). In order to move towards comparative evaluations of useradaptive systems and to ensure a scientific process the authors indicated some vital requirements. More specifically, the authors proposed developing a flexible common reference model and related metrics upon which user-adaptive systems and approaches could be evaluated and compared against each other both comprehensively (as a whole) as well as upon specific adaptation layers and aspects. The layers should encompass different aspects of a user-adaptive system such as a) inferring User/Group properties, b) identifying the user environment and context (e.g. location, affect), c) evaluating personalised content retrieval, d) evaluating the underlying decision making mechanisms, strategies and algorithms, e) evaluating the adaptation of content, navigation, presentation or user feedback and support, f) the user interaction and experience (e.g. evaluate usability, satisfaction) as well as, g) the system efficiency (e.g. scalability, responsiveness).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Staikopoulos and Conlan</head><p>In addition, Yousuf and Conlan <ref type="bibr" coords="7,290.75,118.93,15.49,8.80" target="#b21">[22]</ref> proposed evaluating the usage of visual narratives as a way to indicate positive behavioural change in student engagement levels. In particular, their paper describes the VisEN framework, to provide visual narratives to students and motivate them with their level of engagement with their course.</p><p>Finally, based on the proven existing relationship between the language usage and the author's personality, Chin and Wright <ref type="bibr" coords="7,364.58,190.97,10.51,8.80" target="#b5">[6]</ref> proposed using specific evaluation metrics and statistic tests for inferring (predicting user features) and benchmarking user's personality from text. Such guidelines and metrics can then be used to design and evaluate related evaluation tasks. To do so, the authors reported the need for having an established corpora with detailed reporting requirements that will allow researchers to easily compare their algorithms for inferring personality from text. However, there will always be a need to extend the corpora to increase the coverage of different types of writing, time periods, and localities. As a result, the authors recommended having a series of corpora, with, perhaps, one added every few years to keep providing new data to the community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>Developing means to conduct shared evaluation in the user modelling, adaptation and personalization (UMAP) space is inherently difficult. Not least because of privacy concerns, individual differences in behaviours between the users of systems and challenges associated with working in interactive scenarios. A further challenge is the underlying value of such datasets. Datasets which detail the actions or interests of authentic users are viewed as valuable, and in many cases, proprietry. This compounds the challenge of accessing this data. However, without this access the only resort that remains for reseachers to obtain up-todate user data is via systems that were created within a research environment leading to potentially low numbers and data that is not up-to-date.</p><p>Overcoming these challenges will require greatly advancing our understanding of, and the methodology associated with UMAP evaluation. Challenges include:</p><p>-Defining tasks and scenarios for evaluation purposes -Identification of potential corpora for shared tasks -Interesting target tasks and explanations of their importance -Combining existing evaluation metrics and methods -Improving on previously suggested metrics and methods -Proposing new evaluation metrics and methods -Investiagting anonymization or decentralisation of user data to ensure proprietry value is not compromised -Exploring potential partnerships with companies which hold user data to discuss how research can be conducted without the risk of privacy or value loss</p><p>The papers at the 1st EvalUMAP workshop (2016) covered both challenges and potential solutions associated with this area. It is envisaged that future workshops will build on these outcomes, creating a forum to present innovative datasets and shared challenges using these datasets to evaluate systems. The aim of this year's EvalUMAP workshop (2017) is to start scoping and designing a shared task(s). The resulting shared task(s) are to be accompanied by appropriate models, content, metadata, user behaviours, etc., and can be used to comprehensively compare how different approaches and systems perform. In addition, a number of metrics and observations will be outlined, that participants will be expected to perform to facilitate comparison.</p><p>To create a community around shared tasks for user modelling it is envisaged that the following aspects have to be addressed: (1) A clear understanding of the challenges and requirements related to the design of a shared task approach in the UMAP space; (2) the identification of suitable, publicly accessible datasets; and (3) an initial description for shared task evaluations using these identified and suitable datasets.</p><p>Establishing shared tasks that cover the many facets of a full personalisation system is challenging. With that in mind, the plan is to escalate the tasks year-on-year, starting with a user modelling challenge, then layering in some indicative personalisation decision making processes based on changes in user models, before identifying a mechanism to incorporate real users into the shared task. This escalation is necessary as the user is a complex element of the personalisation process; their actions heavily influence changes to the user model and subsequent personalisation decisions. In order to effectively compare different systems and approaches it is necessary to incorporate users in a meaningful and replicable manner. This of course presents an overhead in running shared tasks. All that being said, our plan is to run the first shared task in 2017-2018 as a static user modelling challenge based on historic social media data from the users and explicitly captured information about their expertise. The ADAPT Centre has committed to support these shared tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>The EvalUMAP workshop series considers the strengths and limitations of existing work in UMAP evaluation, while moving towards its ambitious goal of designing and establishing a forum for comparative evaluation in the UMAP space. The long term vision of EvalUMAP is the establishment of an annual shared challenge series. The workshop this year will focus on identifying candidate datasets that meet specific requirements (e.g. ownership, accessibility) and that could form the basis for designing shared task challenges and evaluations for the academic year 2017-18, which will be presented at an EvalUMAP 2018 forum. It is not intended that this is the only form of scholarly advancement, but through the shared tasks published and managed by the EvalUMAP Workshop a common baseline for comparison may be established.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="2,144.73,634.83,130.81,7.92"><p>http://evalumap.adaptcentre.ie/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="2,144.73,645.79,82.74,7.92"><p>http://trec.nist.gov/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="2,144.73,656.74,132.33,7.92"><p>http://clef2017.clef-initiative.eu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="3,144.73,612.91,82.74,7.92"><p>http://trec.nist.gov/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="3,144.73,623.87,179.27,7.92"><p>http://research.nii.ac.jp/ntcir/index-en.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5" coords="3,144.73,634.83,102.82,7.92"><p>http://fire.irsi.res.in/fire/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6" coords="3,144.73,645.79,132.33,7.92"><p>http://clef2017.clef-initiative.eu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_7" coords="3,144.73,656.74,132.34,7.92"><p>http://www.multimediaeval.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_8" coords="4,144.73,634.83,172.08,7.92"><p>http://www.ir.disco.unimib.it/pirclef2017/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_9" coords="4,144.73,645.79,172.08,7.92"><p>http://www.ir.disco.unimib.it/pirclef2017/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_10" coords="4,144.73,656.74,120.29,7.92"><p>http://www.clef-initiative.eu/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The <rs type="projectName">ADAPT Centre for Digital Content Technology</rs> is funded under the <rs type="programName">SFI Research Centres Programme</rs> (Grant <rs type="grantNumber">13/RC/2106</rs>) and is co-funded under the <rs type="funder">European Regional Development Fund</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_CvqEuUs">
					<idno type="grant-number">13/RC/2106</idno>
					<orgName type="project" subtype="full">ADAPT Centre for Digital Content Technology</orgName>
					<orgName type="program" subtype="full">SFI Research Centres Programme</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,142.95,220.57,337.64,7.92;9,151.52,231.53,256.89,7.92" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,248.92,220.57,227.19,7.92">Evaluating persuasive systems using the psd framework</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Adaji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vassileva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,215.75,231.53,142.50,7.92">UMAP 2016 Extended Proceedings</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">1618</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.95,242.36,337.64,7.92;9,151.52,253.32,25.59,7.92" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="9,279.51,242.36,201.08,7.92">Head first: Living labs for ad-hoc search evaluation</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Schuth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.95,264.15,337.64,7.92;9,151.52,275.11,329.08,7.92;9,151.52,286.07,25.59,7.92" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,248.31,264.15,232.28,7.92;9,151.52,275.11,97.54,7.92">Building a bridge between user-adaptive systems evaluation and software testing</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bogina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kuflik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,318.59,275.11,141.00,7.92">UMAP 2016 Extended Proceedings</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">1618</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.95,296.90,337.64,7.92;9,151.52,307.86,239.11,7.92" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,195.92,296.90,256.14,7.92">Evaluating adaptive systems and applications is often nonsense</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">D</forename><surname>Bra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,459.74,296.90,20.86,7.92;9,151.52,307.86,188.94,7.92">Eval-UMAP 16, UMAP 2016 Extended Proceedings</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">1618</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.95,318.69,337.63,7.92;9,151.52,329.64,272.99,7.92" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,230.16,318.69,246.22,7.92">Empirical evaluation of user models and user-adapted systems</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,151.52,329.64,182.39,7.92">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="327" to="337" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.95,340.48,337.64,7.92;9,151.52,351.43,256.89,7.92" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,262.18,340.48,214.68,7.92">Evaluation metrics for inferring personality from text</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">N</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,215.75,351.43,142.50,7.92">UMAP 2016 Extended Proceedings</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">1618</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.95,362.27,337.63,7.92;9,151.52,373.22,329.08,7.92;9,151.52,384.18,155.03,7.92" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Conlan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Koidl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lawless</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Levacher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Staikopoulos</surname></persName>
		</author>
		<title level="m" coord="9,459.73,362.27,20.86,7.92;9,151.52,373.22,329.08,7.92;9,151.52,384.18,126.37,7.92">Evalumap2016: Towards comparative evaluation in the user modelling, adaptation and personalization space workshop</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.95,395.01,337.64,7.92;9,151.52,405.97,241.36,7.92" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="9,151.52,405.97,212.69,7.92">Benchmarking news recommendations in a living lab</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kille</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lommatzsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Plumbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Brodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Heintz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.95,416.80,317.35,7.92" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hui Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<title level="m" coord="9,261.13,416.80,170.52,7.92">Trec 2016 dynamic domain track overview</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,427.63,337.98,7.92;9,151.52,438.59,155.68,7.92" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,194.15,427.63,235.65,7.92">Steps to take before intelligent user interfaces become real</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Höök</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,436.55,427.63,44.04,7.92;9,151.52,438.59,65.08,7.92">Interacting with Computers</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="409" to="426" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,449.42,337.97,7.92;9,151.52,460.38,98.22,7.92" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,191.46,449.42,126.78,7.92">Living labs for umap evaluation</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,389.34,449.42,91.25,7.92;9,151.52,460.38,48.07,7.92">UMAP 2016 Extended Proceedings</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">1618</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,471.21,337.98,7.92;9,151.52,482.17,329.07,7.92;9,151.52,493.13,102.72,7.92" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="9,350.08,471.21,130.51,7.92;9,151.52,482.17,329.07,7.92;9,151.52,493.13,31.25,7.92">Ecp: Evaluation community portal a portal for evaluation and collaboration in user modelling and personalisation research</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Koidl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Levacher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Conlan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Steichen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1618</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,503.96,337.98,7.92;9,151.52,514.92,270.83,7.92" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,307.55,503.96,173.04,7.92;9,151.52,514.92,34.82,7.92">Evaluation of recommender systems: A new approach</title>
		<author>
			<persName coords=""><forename type="first">Hernández</forename><surname>Del Olmo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Gaudioso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,193.77,514.92,137.99,7.92">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="790" to="804" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,525.75,337.98,7.92;9,151.52,536.71,329.07,7.92;9,151.52,547.67,192.66,7.92" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,349.79,525.75,130.81,7.92;9,151.52,536.71,257.65,7.92">The use of open data to improve the repeatability of adaptivity and personalisation experiment</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Pandit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">G</forename><surname>Hamed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lawless</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,151.52,547.67,142.50,7.92">UMAP 2016 Extended Proceedings</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">1618</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,558.50,337.98,7.92;9,151.52,569.46,329.07,7.92;9,151.52,580.42,172.00,7.92" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,344.20,558.50,136.39,7.92;9,151.52,569.46,216.10,7.92">Layered evaluation of interactive adaptive systems: framework and formative methods</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Paramythis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Weibelzahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Masthoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,376.35,569.46,104.24,7.92;9,151.52,580.42,81.40,7.92">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="383" to="453" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,591.25,337.98,7.92;9,151.52,602.21,329.07,7.92;9,151.52,613.17,197.84,7.92" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,257.91,591.25,222.68,7.92;9,151.52,602.21,235.71,7.92">A structured methodology for comparative evaluation of user interface designs using usability criteria and measures</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hwan Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,394.80,602.21,85.79,7.92;9,151.52,613.17,99.57,7.92">International Journal of Industrial Ergonomics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="379" to="389" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,624.00,337.97,7.92;9,151.52,634.96,329.08,7.92" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,276.17,624.00,204.42,7.92;9,151.52,634.96,65.55,7.92">Towards comparative evaluations of user-adaptive software systems</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Staikopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Conlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,288.33,634.96,142.26,7.92">UMAP 2016 Extended Proceedings</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">1618</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,645.79,337.98,7.92;9,151.52,656.74,282.84,7.92" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,300.98,645.79,179.61,7.92;9,151.52,656.74,19.07,7.92">A review of user-centred information retrieval tasks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">H</forename><surname>Vahid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">G</forename><surname>Hamed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Koidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,241.70,656.74,142.50,7.92">UMAP 2016 Extended Proceedings</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">1618</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,119.62,337.98,7.92;10,151.52,130.58,329.07,7.92;10,151.52,141.54,301.69,7.92" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,356.83,119.62,123.77,7.92;10,151.52,130.58,309.86,7.92">Identifying usability issues for personalization during formative evaluations: A comparison of three methods</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Van Velsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Van Der Geest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Klaassen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,469.07,130.58,11.51,7.92;10,151.52,141.54,211.09,7.92">International Journal of Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="670" to="698" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,152.50,337.98,7.92;10,151.52,163.46,329.07,7.92;10,151.52,174.42,170.48,7.92" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="10,425.72,152.50,54.87,7.92;10,151.52,163.46,259.75,7.92">User-centered evaluation of adaptive and adaptable systems: a literature review</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Van Velsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Van Der Geest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Klaassen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Steehouder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,418.14,163.46,62.45,7.92;10,151.52,174.42,79.88,7.92">The Knowledge Engineering Review</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="261" to="281" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,185.37,337.98,7.92;10,151.52,196.33,307.76,7.92" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="10,259.48,185.37,221.11,7.92;10,151.52,196.33,148.15,7.92">Advantages, opportunities, and limits of empirical evaluations: Evaluating adaptive systems</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Weibelzahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,306.94,196.33,87.33,7.92">Künstliche Intelligenz</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="17" to="20" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,207.29,337.98,7.92;10,151.52,218.25,302.55,7.92" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="10,248.32,207.29,232.27,7.92;10,151.52,218.25,38.70,7.92">Motivating behavioral change through personalized visual narratives</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Yousuf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Conlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,261.40,218.25,142.50,7.92">UMAP 2016 Extended Proceedings</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">1618</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
