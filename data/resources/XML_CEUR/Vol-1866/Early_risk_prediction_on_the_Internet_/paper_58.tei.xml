<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,145.46,115.96,326.68,12.62;1,169.41,133.89,277.14,12.62;1,232.36,151.82,150.63,12.62">UArizona at the CLEF eRisk 2017 Pilot Task: Linear and Recurrent Models for Early Depression Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,198.55,189.52,59.29,8.74"><forename type="first">Farig</forename><surname>Sadeque</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">University of Arizona</orgName>
								<address>
									<addrLine>1103 E 2nd St</addrLine>
									<postCode>85721</postCode>
									<settlement>Tucson</settlement>
									<region>AZ</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,265.96,189.52,55.49,8.74"><forename type="first">Dongfang</forename><surname>Xu</surname></persName>
							<email>dongfangxu9@email.arizona.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">University of Arizona</orgName>
								<address>
									<addrLine>1103 E 2nd St</addrLine>
									<postCode>85721</postCode>
									<settlement>Tucson</settlement>
									<region>AZ</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,349.40,189.52,67.42,8.74"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
							<email>bethard@email.arizona.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">University of Arizona</orgName>
								<address>
									<addrLine>1103 E 2nd St</addrLine>
									<postCode>85721</postCode>
									<settlement>Tucson</settlement>
									<region>AZ</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,145.46,115.96,326.68,12.62;1,169.41,133.89,277.14,12.62;1,232.36,151.82,150.63,12.62">UArizona at the CLEF eRisk 2017 Pilot Task: Linear and Recurrent Models for Early Depression Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7B0B6CE5F0F755E7BD1B03023850FDD1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The 2017 CLEF eRisk pilot task focuses on automatically detecting depression as early as possible from a users' posts to Reddit. In this paper we present the techniques employed for the University of Arizona team's participation in this early risk detection shared task. We leveraged external information beyond the small training set, including a preexisting depression lexicon and concepts from the Unified Medical Language System as features. For prediction, we used both sequential (recurrent neural network) and non-sequential (support vector machine) models. Our models perform decently on the test data, and the recurrent neural models perform better than the non-sequential support vector machines while using the same feature sets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Depression is responsible for almost 12% of all Years Lived with Disabilities (YLDs), with nearly 350 million people suffering from it worldwide <ref type="bibr" coords="1,415.44,452.85,14.32,8.74" target="#b19">[20]</ref>. As of 2000, depression also comes with an annual economic burden of 83 billion US dollars <ref type="bibr" coords="1,468.96,464.81,9.76,8.74" target="#b7">[8]</ref>; and a 1990 study by Goodwin and Jamison <ref type="bibr" coords="1,326.50,476.76,10.42,8.74" target="#b6">[7]</ref> suggested that depression is also the leading cause of suicide, as 15-20% of all major depressive disorder patients take their lives. Early detection of depression can help mitigate these threats, but most studies on early detection rely on diagnoses from patients' self reported surveys and experiences <ref type="bibr" coords="1,233.27,524.58,12.28,8.74" target="#b8">[9]</ref>, which are extremely costly in terms of both time and money, and a major portion of countries with primary health care service do not have the support for these diagnoses. Fortunately, social media may provide us with a solution to this problem, as many studies have successfully leveraged the contents of social media to analyze and predict users' mental well-being <ref type="bibr" coords="1,456.60,572.41,10.73,8.74" target="#b5">[6,</ref><ref type="bibr" coords="1,468.99,572.41,12.98,8.74" target="#b12">13,</ref><ref type="bibr" coords="1,134.27,584.36,12.56,8.74" target="#b14">15,</ref><ref type="bibr" coords="1,148.49,584.36,12.56,8.74" target="#b15">16,</ref><ref type="bibr" coords="1,162.72,584.36,11.47,8.74" target="#b18">19]</ref>. Unfortunately, none of these studies focuses on the importance of the temporal aspect of these detection tasks; hence the introduction of the pilot task on early risk detection of depression in the CLEF eRisk 2017 workshop on Early risk prediction on the Internet: experimental foundations <ref type="bibr" coords="1,386.54,620.23,14.61,8.74" target="#b10">[11]</ref>.</p><p>In this paper we present the five early risk detection models we submitted for the pilot task. We tried to leverage external knowledge sources beyond the provided training data. We incorporated the depression lexicon created by <ref type="bibr" coords="1,451.69,656.12,10.31,8.74" target="#b5">[6]</ref> and used Metamap <ref type="bibr" coords="2,200.17,118.99,10.31,8.74" target="#b0">[1]</ref> to obtain Unified Medical Language System (UMLS)-identified concept unique identifiers related to mental and behavioral dysfunction from user texts. We used these features with both sequential and non-sequential learning models: we used support vector machines as the non-sequential linear model and recurrent neural networks with multiple layers of gated recurrent units as the sequential models. Our results demonstrate the superiority of sequential over non-sequential models on this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Description</head><p>The pilot task on early risk detection of depression focused on sequential processing of contents posted by users in Reddit<ref type="foot" coords="2,329.27,257.89,3.97,6.12" target="#foot_0">1</ref>  <ref type="bibr" coords="2,337.06,259.46,14.50,8.74" target="#b9">[10]</ref>. The data was a collection of writings posted by users, divided into two cohorts: depressed and non-depressed. The text collection for each user is sorted in a chronological order and then divided into 10 chunks, where the first 10% of a user's writings is in chunk 1, the second 10% is in chunk 2 and so on. Details of this data are in section 3.</p><p>The task was divided into two stages: training stage and testing stage. The training stage started on November 30, 2016, when the entire text collection of 486 users was released, with their user-level annotations of depression. Participants then had a little over two months to develop their systems. The testing stage started on February 6, 2017 when the first 10% of texts written by 401 previously unobserved users were released. For the next 9 weeks, new chunks were released, with each chunk including the next 10% of each user's text. After each release, and before the next release, systems had to make a three-way decision for each user: tag the user as depressed, tag the user as non-depressed, or wait to see the next chunk of data. If a user was tagged as either depressed or non-depressed, this decision was final and could not be changed for future chunks of data. After the release of the 10th (and last) chunk of the data, the decision was two-way: tag the user as depressed, or tag the user as non-depressed. The prediction model was then evaluated based on its correctness and how early in the series of chunks was able to make its predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head><p>A number of social media websites were considered as potential data sources for this shared task. Twitter<ref type="foot" coords="2,242.11,553.88,3.97,6.12" target="#foot_1">2</ref> was discarded because it provided little to no context about the user, is highly dynamic and did not allow them to collect more than 3200 tweets per user, which, in 140-character microblogs, represents only a small amount of text. MTV's A Thin Red Line (ATL) <ref type="foot" coords="2,336.22,589.74,3.97,6.12" target="#foot_2">3</ref> , a platform designed to empower distressed teens to respond to issues ranging from sexting to cyberbullying, was also considered, but discarded as there were concerns about redistribution and problems regarding obtaining user history. Eventually, Reddit, a social media and news aggregation website, was selected because of its organization of contents among specific subreddits, and the ease of collecting data using the API provided by Reddit itself.</p><p>For each user, the organizers collected the maximum number of submissions they could find and were allowed to download through the API (maximum 2000 posts and comments per user). Users with less than 10 submissions were discarded. Original redditor IDs were replaced with pseudo user IDs for anonymization, and published along with the title, time and text of the posts.</p><p>After the data collection, the users were divided into two cohorts: an experimental depressed group and a control (non-depressed) group. For the depressed group, the organizers searched for phrases associated with self-declaration of depression, such as diagnosed with depression, and then manually examined the posts to filter down to just those redditors who explicitly said they were diagnosed with depression by a physician. These self declaration posts were omitted from the dataset to avoid making the detection trivial. For the non-depressed group, organizers collected redditors who had participated in depression forums but had no declaration of depression, as well as redditors from other random subreddits. Their final collection contained 531,453 submissions from 892 unique users, of which 486 users were used as training data, and 401 were used as test data. Statistics for that dataset are shown in Table <ref type="table" coords="3,335.67,358.29,3.87,8.74" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Features</head><p>We considered two types of features that could serve as inputs to our classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Depression Lexicon</head><p>This is a set of unigrams that has high probability of appearing in depressionrelated posts. The list was collected from <ref type="bibr" coords="3,312.08,620.25,9.76,8.74" target="#b5">[6]</ref>, where the authors compiled a list of words that are most associated with the stem "depress" in the Yahoo! Answers Mental Health forum using pointwise mutual information and log-likelihood ratio and kept the top words based on their TF-IDF in Wikipedia articles. We used the top 110 words that were presented in the paper. For each post, we generated 110 features: the counts of how many times each word occurred in the post.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Metamap Features</head><p>We used Metamap <ref type="bibr" coords="4,219.92,178.46,10.12,8.74" target="#b0">[1]</ref>, which is a highly configurable tool to discover concepts from the Unified Medical Language System (UMLS) Metathesaurus<ref type="foot" coords="4,441.31,188.84,3.97,6.12" target="#foot_3">4</ref> . In our preliminary experiments we found out that Metamap produced a lot of incorrect concept matches in social media texts (as it was mainly built to run on clinical texts), but with some tuning, it was possible to use this effectively on social media. We restricted Metamap to only one source (SNOMEDCT-US) and to only two semantic types (Mental or Behavioral Dysfunction, Clinical Drugs). We passed each post through the restricted Metamap and collected all the predicted concept unique identifiers (CUIs). We ended up with a set of 404 CUIs. We generated 404 features for each post: the counts of how many times each CUI occurred in the post.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Classifiers</head><p>We considered both sequential and non-sequential learning models for the prediction task. For the non-sequential model, we used a support vector machine that observes the user's entire post history at once. For the sequential model, we used a recurrent neural network model that observes each of a user's posts, one at a time. We also used an ensemble model to combine both the sequential and non-sequential models.</p><p>As per the shared task definition, classifiers were given the user's history in chunks (the first 10% of the user history, then the first 20%, etc.) and after each chunk, the classifiers were asked to make a prediction of "depressed", "not depressed", or "wait". All our classifiers were trained to make two-way predictions, "depressed" vs. "wait", and if a classifier predicted a user as depressed after seeing the first n% of the history, that prediction was considered final and the remaining 100 -n% of the history was ignored. On the final (10th) chunk, all users who had only ever been predicted as "wait" were classified as "not depressed". Note that our models never made post-by-post decisions; they always observed the entirety of the n% of the history they were given and then made a single prediction for the entire n%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Support Vector Machine</head><p>A support vector machine <ref type="bibr" coords="4,246.92,590.30,10.31,8.74" target="#b4">[5]</ref> or SVM is a machine learning technique that is used for binary classification tasks. In this technique, input vectors are non-linearly mapped to a high dimensional feature space, where a linear decision surface is constructed to classify the inputs. It is one of the most popular non-sequential machine learning techniques because of its high generalization ability.</p><p>For the support vector machine (SVM) models we used, the feature vectors needed to summarize the entire history of the user. We converted the post-level raw count features to user-level proportion features (e.g., converting the number of times depression was used in each post to the proportion of all words in a all of a user's posts that were depression).</p><p>We used two out-of-the-box implementations of support vector machines:</p><p>-Weka's implementation of the sequential minimal optimization algorithm <ref type="bibr" coords="5,465.40,198.60,15.19,8.74" target="#b13">[14]</ref> for training support vector machine classifiers <ref type="bibr" coords="5,360.94,210.55,14.90,8.74" target="#b20">[21]</ref>. The model was set to output probability estimates and it normalizes all attributes by default. Other parameters were set to their defaults. We used a degree-1 polynomial kernel and a cache size of 250007 as it performed better in preliminary experiments on the training data. -LibSVM's implementation of support vector machines <ref type="bibr" coords="5,395.24,270.31,10.73,8.74" target="#b2">[3]</ref> using C-support vector classification <ref type="bibr" coords="5,237.30,282.27,9.76,8.74" target="#b1">[2]</ref>. Apart from tuning the model for probability estimate outputs, we used the default parameter settings. We used the radial basis function kernel for this one as it performed better in preliminary experiments on the training data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Recurrent Neural Network</head><p>Due to the sequential property of the data, we opted for machine learning techniques that take advantage of this. We used Recurrent Neural Networks (RNN) which have been successful in other natural language modeling problems <ref type="bibr" coords="5,134.77,608.30,14.90,8.74" target="#b11">[12]</ref>. Recurrent neural networks are a form of artificial neural network where neurons are connected to form a directed cycle, allowing the network to exhibit temporal behavior, and thus be used as a sequential learning model.</p><p>We trained recurrent neural networks that take a sequence of feature vectors, each representing a single post, and predict whether the user is depressed or not.</p><p>Figure <ref type="figure" coords="6,165.96,118.99,4.94,8.74" target="#fig_0">1</ref> shows the general architecture of the model. We used Gated Recurrent Units (GRU) <ref type="bibr" coords="6,197.93,130.95,10.73,8.74" target="#b3">[4]</ref> to build recurrent layers. Feature vectors representing each post are first concatenated, and then fed as input to the first recurrent layer. A second GRU layer is stacked on top of the first one for more expressive power, and its output is fed through a sigmoid to produce binary output. To make the experiments with different input features comparable, we fixed the size of the GRU units to 32 for all experiments. To avoid overfitting, we used dropout <ref type="bibr" coords="6,465.11,190.72,15.48,8.74" target="#b16">[17]</ref> with probability 0.2 on the first input-to-hidden layer. Models were trained with RMSProp optimization <ref type="bibr" coords="6,236.61,214.64,15.19,8.74" target="#b17">[18]</ref> on mini-batches of size 200, with all hyperparameters set to default except the learning rate, which was set to 0.001. Each model is trained for at most 800 epochs. The training time for each experiment was around two hours using two Graphics Processing Units (GPUs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Ensemble</head><p>An ensemble learning model takes the outputs of a set of other machine learning algorithms and uses them as inputs for classification. They are typically used to improve the performance of individual machine learning techniques by leveraging the different strengths of multiple approaches. For this task, We implemented an ensemble learning technique using the probability outputs of the nine individual models (3 from Weka, 3 from LibSVM and 3 from RNN: models used as features either the depression lexicon, Metamap outputs, or both). We used 5-fold cross validation for each model to calculate the probability of each user being depressed and then fed these probabilities to a Naive Bayes classifier, which served as the ensemble classifier. We used Weka's naive Bayes implementation with the default parameter settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation and Analysis</head><p>We submitted five different models for the task:</p><p>-UArizonaA: An SVM model trained using LibSVM with the depression lexicon and Metamap outputs as features. -UArizonaB: An SVM model trained using Weka with the depression lexicon as features. -UArizonaC: An RNN model with both the depression lexicon and Metamap outputs as features.</p><p>-UArizonaD: The ensemble model.</p><p>-UArizonaE: An RNN model with the same structure as UArizonaC, but that always predicts "wait" until 60% of the test data is released.</p><p>All of these models were selected for their individual properties. UArizonaA was our most restrictive model, as it vigorously tried to not tag someone depressed, whereas UArizonaC was the most open as it tagged more users as depressed than any other models. The other 3 sat in between these 2. To make UArizonaA a little more open towards depression tagging, we combined its 10th chunk output with UArizonaE's 10th chunk output.</p><p>The performance of our models are given in table <ref type="table" coords="7,355.88,284.09,3.80,8.74" target="#tab_1">2</ref>, along with the performance of the model that achieved the highest F 1 in the shared task, FHDO-BCSGA. The models were evaluated based on 5 performance measures: precision, recall and F 1 , and 2 Early Risk Detection Error (ERDE) <ref type="bibr" coords="7,369.93,319.96,15.81,8.74" target="#b9">[10]</ref> variants, with cutoff parameter o set to 5 and 50 posts. ERDE penalizes systems that take many posts to predict depression. For precision, recall, and F 1 , a high score is good, while for ERDE, a low score is good.</p><p>Our models were competitive with others in the shared task. UArizonaC ranked 1 st out of 30 for recall, UArizonaD ranked 3 rd for ERDE 50 , and UArizonaB ranked 4 th for ERDE 5 . For precision and F 1 , our models were less impressive; both UArizonaD and UArizonaE ranked 11 th for F 1 and UArizonaE ranked 14 th for precision. Overall, UArizonaD is the best of our models: it has the highest F 1 , the lowest ERDE 50 , and the second-best recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Limitations</head><p>Our models fell short of the best system in the task for two main reasons. First, we attempted to predict depressed users from the beginning, even though the number of posts varies dramatically from user to user (from only 1 post per chunk to over 200 per chunk). A better strategy would have been to start making predictions after observing some threshold n posts, allowing us to predict early for users with many posts, while waiting until we have more information for users with few posts. Second, we did not sufficiently explore the broad range of possible features. For example, we could have built a domain-specific depression lexicon and used it instead of a previously collected lexicon, or we could have used more sophisticated techniques to represent posts as post-level feature vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion and Future Works</head><p>In this paper, we described the techniques for the University of Arizona submissions to the 2017 CLEF eRisk early risk detection of depression pilot task. We used features based on a depression lexicon and on the Unified Medical Language System (UMLS). We implemented sequential and non-sequential models and used ensemble methods to leverage the best of each model. We found that the ensemble model works better than the individual models, and waiting for more data before making a decision improves the traditional performance measures like precision, recall and F 1 . Whether it is acceptable to wait a decent amount of time to have better performance is still an open question -and we would like to work on that. We would like to establish a timeframe that can be deemed acceptable before making a decision so that the tradeoff between correctness and speed of the decision is minimized.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,134.77,490.02,345.83,7.89;5,134.77,501.01,113.00,7.86"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Architecture of the model for reading the sequence of a user's posts and predicting the user's depression status.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,147.67,389.91,320.01,84.93"><head>Table 1 .</head><label>1</label><figDesc>Summary of the task data</figDesc><table coords="3,317.45,389.91,150.23,18.82"><row><cell>Train</cell><cell>Test</cell></row><row><cell cols="2">Depressed Control Depressed Control</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,134.39,117.78,346.54,107.24"><head>Table 2 .</head><label>2</label><figDesc>Performance of the models. E5 and E50 are the shared-task-defined Early Risk Detection Error (ERDE) percentages, P is precision, R is recall, and F1 is the harmonic mean of precision and recall.</figDesc><table coords="7,138.12,117.78,339.11,74.41"><row><cell>Model</cell><cell>Brief description</cell><cell>E5 E50 F1 P R</cell></row><row><cell cols="3">FHDO-BCSGA Ranked #1 for F1, #2 for E5, #2 for E50 12.82 9.69 0.64 0.61 0.67</cell></row><row><cell>UArizonaA</cell><cell>LibSVM + lexicon + UMLS</cell><cell>14.62 12.68 0.40 0.31 0.58</cell></row><row><cell>UArizonaB</cell><cell>WekaSVM + lexicon</cell><cell>13.07 11.63 0.30 0.33 0.27</cell></row><row><cell>UArizonaC</cell><cell>RNN + lexicon + UMLS</cell><cell>17.93 12.74 0.34 0.21 0.92</cell></row><row><cell>UArizonaD</cell><cell>Ensemble</cell><cell>14.73 10.23 0.45 0.32 0.79</cell></row><row><cell>UArizonaE</cell><cell>RNN + lexicon + UMLS + 60%-wait</cell><cell>14.93 12.01 0.45 0.34 0.63</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,635.53,98.85,7.47"><p>http://www.reddit.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,646.48,103.56,7.47"><p>http://www.twitter.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,144.73,657.44,112.98,7.47"><p>http://www.athinline.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,144.73,657.44,329.51,7.47"><p>https://www.nlm.nih.gov/research/umls/knowledge_sources/metathesaurus/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to express our gratitude to the organizers of the pilot task for their effort towards building the first annotated user-level depression dataset.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,349.90,337.64,7.86;8,151.52,360.86,330.86,7.86;8,151.52,371.82,76.80,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,267.83,349.90,212.76,7.86;8,151.52,360.86,59.86,7.86">An overview of metamap: historical perspective and recent advances</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,231.80,360.86,224.76,7.86">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="229" to="236" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,382.78,337.64,7.86;8,151.52,393.74,329.07,7.86;8,151.52,404.70,134.93,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,317.17,382.78,163.43,7.86;8,151.52,393.74,36.18,7.86">A training algorithm for optimal margin classifiers</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">E</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">M</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,207.94,393.74,272.64,7.86;8,151.52,404.70,23.72,7.86">Proceedings of the fifth annual workshop on Computational learning theory</title>
		<meeting>the fifth annual workshop on Computational learning theory</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="144" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,415.67,337.64,7.86;8,151.19,426.62,307.67,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,254.35,415.67,195.49,7.86">Libsvm: A library for support vector machines</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,458.40,415.67,22.20,7.86;8,151.19,426.62,241.63,7.86">ACM Transactions on Intelligent Systems and Technology (TIST)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,437.59,337.63,7.86;8,151.52,448.55,329.07,7.86;8,151.52,459.51,304.58,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,395.27,437.59,85.32,7.86;8,151.52,448.55,225.14,7.86">On the properties of neural machine translation: Encoder-decoder approaches</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,397.95,448.55,82.64,7.86;8,151.52,459.51,275.92,7.86">Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation (SSST-8)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,470.47,338.10,7.86;8,150.44,481.43,25.60,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,246.78,470.47,96.67,7.86">Support-vector networks</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,350.73,470.47,68.73,7.86">Machine learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,492.39,337.64,7.86;8,151.52,503.35,151.85,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,379.95,492.39,100.65,7.86;8,151.52,503.35,47.58,7.86">Predicting depression via social media</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Choudhury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Counts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,220.69,503.35,29.65,7.86">ICWSM</title>
		<imprint>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,514.31,337.64,7.86;8,151.52,525.27,281.10,7.86" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">K</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">R</forename><surname>Jamison</surname></persName>
		</author>
		<title level="m" coord="8,285.51,514.31,195.09,7.86;8,151.52,525.27,84.55,7.86">Manic-Depressive Illness: Bipolar Disorder and Recurring Depression</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press Inc</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,536.24,339.17,7.86;8,151.52,547.20,329.07,7.86;8,151.52,558.15,305.98,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,188.24,547.20,292.36,7.86;8,151.52,558.15,97.80,7.86">The economic burden of depression in the united states: how did it change between 1990 and 2000?</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kessler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Birnbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Corey-Lisle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,266.47,558.15,70.73,7.86">J Clin Psychiatry</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1465" to="1475" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,569.12,337.63,7.86;8,151.18,580.08,331.76,8.12;8,151.05,591.68,174.17,7.47" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,200.80,569.12,254.49,7.86">Depression: the benefits of early and appropriate treatment</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Halfin</surname></persName>
		</author>
		<ptr target="http://europepmc.org/abstract/MED/18041868" />
	</analytic>
	<monogr>
		<title level="j" coord="8,464.40,569.12,16.19,7.86;8,151.18,580.08,146.14,7.86">The American journal of managed care</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">927</biblScope>
			<date type="published" when="2007-11">November 2007</date>
		</imprint>
	</monogr>
	<note>Suppl</note>
</biblStruct>

<biblStruct coords="8,142.62,602.00,337.98,7.86;8,151.52,612.96,329.26,7.86;8,151.52,623.92,297.77,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,259.27,602.00,221.32,7.86;8,151.52,612.96,11.79,7.86">A test collection for research on depression and language use</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,186.44,612.96,294.34,7.86;8,151.52,623.92,82.13,7.86">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="28" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,634.88,338.21,7.86;8,151.52,645.84,329.07,7.86;8,151.52,656.80,285.13,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,319.69,634.88,161.14,7.86;8,151.52,645.84,212.86,7.86">eRISK 2017: CLEF Lab on Early Risk Prediction on the Internet: Experimental foundations</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,385.58,645.84,95.00,7.86;8,151.52,656.80,187.61,7.86">Proceedings Conference and Labs of the Evaluation Forum CLEF 2017</title>
		<meeting>Conference and Labs of the Evaluation Forum CLEF 2017<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,119.67,338.23,7.86;9,151.52,130.63,294.31,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,440.19,119.67,40.66,7.86;9,151.52,130.63,149.73,7.86">Recurrent neural network based language model</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cernockỳ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,322.89,130.63,44.19,7.86">Interspeech</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,141.59,339.26,7.86;9,151.19,152.55,329.40,7.86;9,151.52,163.51,283.71,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,166.00,152.55,314.60,7.86;9,151.52,163.51,60.53,7.86">Feeling bad on facebook: depression disclosures by college students on a social networking site</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jelenchick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Egan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Gannon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Becker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,232.48,163.51,96.26,7.86">Depression and Anxiety</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="447" to="455" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,174.47,339.52,7.86;9,151.52,185.43,329.07,7.86;9,150.30,196.39,331.24,8.12;9,150.11,207.99,80.03,9.21" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,188.18,174.47,293.95,7.86;9,151.52,185.43,14.63,7.86">Fast training of support vector machines using sequential minimal optimization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
		<ptr target="http://research.microsoft.com/\~jplatt/smo.html" />
	</analytic>
	<monogr>
		<title level="m" coord="9,365.12,185.43,115.47,7.86;9,150.30,196.39,105.27,7.86">Advances in Kernel Methods -Support Vector Learning</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Schoelkopf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Smola</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,218.30,339.26,7.86;9,151.52,229.26,330.35,7.86;9,151.52,240.22,330.86,7.86;9,151.52,251.18,67.58,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,165.80,229.26,296.65,7.86">Why do they leave: Modeling participation in online depression forums</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sadeque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Solorio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Shrestha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Rey-Villamizar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,151.52,240.22,326.39,7.86">Proceedings of the 4th Workshop on Natural Language Processing and Social Media</title>
		<meeting>the 4th Workshop on Natural Language Processing and Social Media</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="14" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,262.14,339.26,7.86;9,151.52,273.10,330.61,7.86;9,151.52,284.06,329.07,7.86;9,151.52,295.02,174.50,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,378.14,273.10,103.99,7.86;9,151.52,284.06,168.60,7.86">Predicting individual wellbeing through the language of social media</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kapelner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dziurzynski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Stillwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,341.27,284.06,139.32,7.86;9,151.52,295.02,89.72,7.86">Biocomputing 2016: Proceedings of the Pacific Symposium</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="516" to="527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,305.98,339.25,7.86;9,151.52,316.93,329.07,7.86;9,151.52,327.89,211.03,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,151.52,316.93,279.21,7.86">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,438.26,316.93,42.33,7.86;9,151.52,327.89,111.20,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,338.85,337.98,7.86;9,151.52,349.81,329.07,7.86;9,151.20,360.77,45.05,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,258.78,338.85,221.81,7.86;9,151.52,349.81,119.69,7.86">Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,278.10,349.81,202.49,7.86">COURSERA: Neural networks for machine learning</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,371.73,339.25,7.86;9,151.52,382.69,330.35,7.86;9,151.52,393.65,330.86,7.86;9,151.52,404.61,288.40,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="9,151.52,382.69,311.06,7.86">Understanding and discovering deliberate self-harm content in social media</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Mellina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>O'hare</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,151.52,393.65,277.35,7.86">Proceedings of the 26th International Conference on World Wide Web</title>
		<meeting>the 26th International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>International World Wide Web Conferences Steering Committee</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="93" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,415.56,338.30,7.86;9,151.52,426.52,330.61,8.11;9,151.52,437.48,73.32,7.86" xml:id="b19">
	<monogr>
		<ptr target="http://www.who.int/whr/2001/en/whr01_en.pdf?ua=1" />
		<title level="m" coord="9,151.52,415.56,329.40,7.86;9,151.52,426.52,17.75,7.86">WHO: The world health report 2001-mental health: New understanding, new hope</title>
		<imprint>
			<date type="published" when="2001">2001. 2016-04-02</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,448.44,337.98,7.86;9,151.19,459.40,135.22,7.86" xml:id="b20">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<title level="m" coord="9,244.34,448.44,236.26,7.86;9,151.19,459.40,106.55,7.86">Data mining: practical machine learning tools and techniques with java implementations</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
