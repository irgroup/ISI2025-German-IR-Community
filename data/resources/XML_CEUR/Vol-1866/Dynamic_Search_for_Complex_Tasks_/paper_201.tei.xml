<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,134.93,116.26,345.50,12.45;1,260.84,134.19,93.68,12.45;1,235.35,155.34,182.74,10.38">Leveraging Wikipedia&apos;s article structure to build search agents</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,197.28,155.34,33.58,10.38"><surname>Tuw</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Vienna University of Technology (TUW</orgName>
								<address>
									<addrLine>Favoritenstrasse 9-11/188</addrLine>
									<postCode>1040</postCode>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,281.11,192.49,53.13,8.80"><forename type="first">Joao</forename><surname>Palotti</surname></persName>
							<email>palotti@ifs.tuwien.ac.at</email>
							<affiliation key="aff0">
								<orgName type="institution">Vienna University of Technology (TUW</orgName>
								<address>
									<addrLine>Favoritenstrasse 9-11/188</addrLine>
									<postCode>1040</postCode>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,134.93,116.26,345.50,12.45;1,260.84,134.19,93.68,12.45;1,235.35,155.34,182.74,10.38">Leveraging Wikipedia&apos;s article structure to build search agents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">004271BB89816BA644A43F67C0E9BACC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Often, single query search sessions are not enough to solve complex problems or to gather sufficient information to take an informed decision. Such complex search tasks include many ordinary tasks such as planning a vacation trip, studying for a school or college exam or gathering information on a symptom or condition. Nevertheless, complex search tasks can be broken into multiple smaller specific subtasks. In order to assist users in dealing with complex searches, a search agent could be employed to automatically break a complex search task into smaller tasks, to issue multiple queries for those subtasks, and to report the results back to the user in a meaningful way.</p><p>A key problem that the Information Retrieval community aims to solve in order to create such agents is the understanding of complex search tasks, which includes the identification of smaller subtasks. To foster research in such interesting problem a number of challenges have been recently proposed (e.g., <ref type="bibr" coords="1,450.70,474.09,11.21,8.80" target="#b4">[5,</ref><ref type="bibr" coords="1,461.91,474.09,7.47,8.80" target="#b3">4,</ref><ref type="bibr" coords="1,469.38,474.09,7.47,8.80" target="#b1">2]</ref>) and this paper describes the efforts of Vienna University of Technology (TUW) in one of such challenges, the first CLEF Dynamic Search <ref type="bibr" coords="1,389.87,498.00,9.96,8.80" target="#b1">[2]</ref>.</p><p>We propose the creation of a search agent that specifically leverage the structure of Wikipedia articles to understand search tasks. Our assumption is that human editors carefully choose meaningful section titles to cover the various aspects of an article. Our proposed search agent explores this fact, being responsible for two tasks: (1) identifying the key Wikipedia articles related to a complex search task, and (2) selecting section titles from those articles.</p><p>For instance, consider a user seeking information on how to quit smoking. Some of the relevant subtasks, in this case, are the description of different ways to quit smoking, the benefits of quitting smoking and second effects of quitting smoking. A possible query that expresses this information need is simply "quit smoking". The Wikipedia article Smoking Cessation 1 is the top hit for such query Fig. <ref type="figure" coords="2,153.45,253.35,3.87,8.80">1</ref>: Five runs were submitted at CLEF Dynamic Search: one simple baseline made up using only the initial query and four runs made appending section names extracted from Wikipedia to the initial query. using the Wikipedia Search API<ref type="foot" coords="2,275.66,312.89,3.97,6.16" target="#foot_1">2</ref> , and many of the crucial aspects of this topic are presented in the various sections of this article, e.g. methods, side effects and health benefits. Our proposed agent benefits from the effort made by the human editors on Wikipedia to easily gather information on all these aspects. One feature of our method is its accountability as it is easy to explicitly justify to users which are the subtasks being considered.</p><p>In the next section, we describe the details of our approach, including the methods devised to rank section titles from Wikipedia articles. In Section 4 we discuss our results and future work directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Experiments</head><p>Our proposed search agent starts by redirecting an initial user query to the Wikipedia API, which retrieves the top N Wikipedia articles for that query. We download the full-text of all top N Wikipedia articles retrieved by the Wikipedia API (which was accessed in March 2017), and we evaluate different approaches to select up to 5 section titles from the downloaded articles. Each section title is considered a subtask relevant for one aspect of the original user information need. We then append the selected section titles to the initial user query and issue multiple queries to an ElasticSearch index of ClueWeb 12 Category B, provided by the organizers. We do not prioritize any subtask and merge the results from the different subtasks using a round-robin approach. Other ways to present the results will be explored in future work. In this work, we set N = 3 and access the Wikipedia API using the Python package Wikipedia version 1.4.0 <ref type="foot" coords="2,439.32,601.13,3.97,6.16" target="#foot_2">3</ref> .</p><p>In total, we submitted five runs: one baseline run (TUW 0) and four regular runs (TUW 1-4) as following described:</p><p>-TUW0 -Baseline Run: This is an ElasticSearch BM25 run simply retrieving 50 documents using the query field for each information need. This run aims to assess how the usage of a search agent improves or hurts the search results; -TUW1 -Human Run: A human judge is used to select up to 5 section titles from the top Wikipedia articles returned by the Wikipedia API. This run aims to provide a comparison between automatic and manual methods to choose section titles; -TUW2 -First Five Run: This run implements a simple heuristic in which the first five section titles are selected. The assumption made here is that the Wikipedia Search API is highly precise, thus the top articles are more relevant than the others. Also, we assume that the most important aspects of a topic are addressed early in a Wikipedia page. -TUW3 -Word2VecMean Run: In this run, we take advantage of a background text to automatically rank Wikipedia section titles based on the content of each section. As background text, we used the description of the information need provided by the Workshop organizers and compare it to the text used in each individual section. We make use of the cosine similarity between the vector representation of each word in the both texts. The vector representations are extracted using Word2Vec trained on GoogleNews <ref type="bibr" coords="3,459.90,373.78,9.96,8.80" target="#b2">[3]</ref>.</p><p>Given the operator # that returns the number of elements of a set, we score each section S comparing the Word2Vec representation (W2VR) of each word WS in the section with each word WD in the information need description D. Formally:</p><formula xml:id="formula_0" coords="3,170.50,437.85,290.10,23.03">Score(S) = SW ∈S DW ∈D Cosine(W 2V R(SW ), W 2V R(DW )) #S × #D</formula><p>-TUW4 -W2V Plus NB Run: This run adds a step to TUW3. After selecting the top section titles and before applying the round-robin algorithm to merge the result of each query, an automatic text classifier predicts the relevance of each retrieved document. We used a Naive Bayes classifier trained on a set of documents that were judged with respect to their relevance to the topic. The reason to choose a Naive Bayes classifier is that it is a standard approach for text classification. Other text classifiers will be evaluated in future work.</p><p>An overview of our method and runs representing different strategies to select the top 5 section titles from the top Wikipedia articles is depicted in Figure <ref type="figure" coords="3,469.79,581.85,3.87,8.80">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>In Figure <ref type="figure" coords="3,178.81,632.15,3.87,8.80" target="#fig_1">2</ref>, we show different standard evaluation metrics and their results for each run. Figure <ref type="figure" coords="3,211.59,644.10,4.98,8.80" target="#fig_2">3</ref> shows the distribution of Precision at depth 5 and 10 over topics.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion and Conclusion</head><p>Overall, our baseline run, TUW0, obtained the best results, although the difference between TUW0 and TUW1-3 is not statistically significant for any metric shown in Figure <ref type="figure" coords="5,208.37,330.61,3.87,8.80" target="#fig_1">2</ref>. In some cases, as for P@5 and Reciprocal Rank, the human selection of titles from Wikipedia article was on average better than the baseline.</p><p>Interestingly, Figure <ref type="figure" coords="5,242.87,355.03,4.98,8.80" target="#fig_2">3</ref> shows that Topic 4 (quit smoking) had no relevant documents for any of our runs. An analysis of the QRels and retrieved pages might be necessary, as, for example, we did not remove any spam webpages and this topic is potentially vulnerable to spam. Considering P@5, the results using any search agent outperformed the baseline in 6 topics (7, 8, 19, 24, 27 and 31), while the baseline was exclusively better than any search agent in 7 topics <ref type="bibr" coords="5,468.96,414.81,11.62,8.80;5,134.77,426.76,109.31,8.80">(5, 21, 25, 29, 36, 42 and 48)</ref>.</p><p>Intent aware metrics, such as α-NDCG or ERR-IA, were not used in this evaluation, however they could reveal the potential benefits of using our proposed search agent. Experiments with this kind of metrics is left as future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,134.77,553.72,345.83,8.80;4,134.77,565.67,345.83,8.80;4,134.77,577.63,345.83,8.80;4,134.77,589.58,345.82,8.80;4,134.77,601.54,145.35,8.80"><head>Fig. 2 :</head><label>2</label><figDesc>Fig.2: Mean Average Precision (MAP), Binary Preference (BPref), Precision at depth 5 (P@5), Precision at depth 10 (P@10), Reciprocal Rank and the average number of relevant documents returned are plotted for each run. Runs are sorted by their average results over all topics and the error bar represents a confidence interval of 0.95 around the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,134.77,231.05,345.83,8.80;5,134.77,243.00,183.67,8.80"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Distribution of Precision at depth 5 (left) and Precision at depth 10 (right) over all the topics for each submitted run.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,657.54,221.25,7.37"><p>https://en.wikipedia.org/wiki/Smoking_cessation</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,623.87,114.02,7.92;2,144.73,635.62,324.81,7.37;2,144.73,646.58,94.15,7.37"><p>Accessed on 25th May 2017: https://en.wikipedia.org/w/api.php?action=query&amp;list=search&amp;srsearch= quit%20smoking&amp;utf8=</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,144.73,657.54,183.59,7.37"><p>https://pypi.python.org/pypi/wikipedia/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,138.35,523.71,342.24,7.92;5,146.91,534.67,333.68,7.92;5,146.91,545.63,297.30,7.92" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,309.88,523.71,170.72,7.92;5,146.91,534.67,65.20,7.92">The university of stavanger at the TREC 2016 tasks track</title>
		<author>
			<persName coords=""><forename type="first">Darío</forename><surname>Garigliotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,233.73,534.67,246.87,7.92;5,146.91,545.63,46.73,7.92">Proceedings of The Twenty-Fifth Text REtrieval Conference, TREC 2016</title>
		<meeting>The Twenty-Fifth Text REtrieval Conference, TREC 2016<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">November 15-18, 2016, 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,557.10,342.24,7.92;5,146.91,568.06,333.68,7.92;5,146.91,579.01,243.59,7.92" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,311.03,557.10,169.56,7.92;5,146.91,568.06,35.67,7.92">Overview of the clef dynamic search evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">Evangelos</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Leif</forename><surname>Azzopardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,221.66,568.06,254.11,7.92">CLEF 2017 -8th Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="5,146.91,579.01,170.30,7.92">Lecture Notes in Computer Science (LNCS</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,590.48,342.25,7.92;5,146.91,601.44,333.67,7.92;5,146.91,612.40,292.11,7.92" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,464.29,590.48,16.31,7.92;5,146.91,601.44,297.00,7.92">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,466.22,601.44,14.36,7.92;5,146.91,612.40,191.66,7.92">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,623.87,342.24,7.92;5,146.91,634.83,333.67,7.92;5,146.91,645.79,333.68,7.92;5,146.91,656.74,242.95,7.92" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,335.69,634.83,144.90,7.92;5,146.91,645.79,16.79,7.92">Overview of the TREC tasks track 2016</title>
		<author>
			<persName coords=""><forename type="first">Manisha</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Emine</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rishabh</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Evangelos</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,183.21,645.79,293.06,7.92">Proceedings of The Twenty-Fifth Text REtrieval Conference, TREC 2016</title>
		<meeting>The Twenty-Fifth Text REtrieval Conference, TREC 2016<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">November 15-18, 2016, 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,119.62,342.24,7.92;6,146.91,130.58,333.68,7.92;6,146.91,141.54,333.68,7.92;6,146.91,152.50,89.84,7.92" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,277.32,130.58,163.97,7.92">Overview of the TREC 2015 tasks track</title>
		<author>
			<persName coords=""><forename type="first">Emine</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manisha</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rishabh</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Evangelos</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,462.94,130.58,17.66,7.92;6,146.91,141.54,238.16,7.92">Proceedings of The Twenty-Fourth Text REtrieval Conference</title>
		<meeting>The Twenty-Fourth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
