<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,154.56,115.96,306.23,12.62;1,147.84,133.89,319.68,12.62;1,278.07,151.82,59.22,12.62">Replicating an Experiment in Cross-lingual Information Retrieval with Explicit Semantic Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,172.21,189.65,75.19,8.74"><forename type="first">Marco</forename><surname>Jungwirth</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Systems Engineering</orgName>
								<orgName type="institution">TU Wien</orgName>
								<address>
									<addrLine>Favoritenstraße 9-11/194</addrLine>
									<postCode>1040</postCode>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,291.13,189.65,64.78,8.74"><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
							<email>allan.hanbury@tuwien.ac.at</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Systems Engineering</orgName>
								<orgName type="institution">TU Wien</orgName>
								<address>
									<addrLine>Favoritenstraße 9-11/194</addrLine>
									<postCode>1040</postCode>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,154.56,115.96,306.23,12.62;1,147.84,133.89,319.68,12.62;1,278.07,151.82,59.22,12.62">Replicating an Experiment in Cross-lingual Information Retrieval with Explicit Semantic Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8F9C0903FDB209357EA7A773E31DF378</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>replicability</term>
					<term>Explicit Semantic Analysis</term>
					<term>cross-lingual</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We have participated in the Replicability Track of the CEN-TRE@CLEF 2018 conference <ref type="bibr" coords="1,283.10,286.13,7.17,7.86" target="#b0">[1]</ref><ref type="bibr" coords="1,290.27,286.13,3.58,7.86" target="#b1">[2]</ref><ref type="bibr" coords="1,290.27,286.13,3.58,7.86" target="#b2">[3]</ref><ref type="bibr" coords="1,293.85,286.13,7.17,7.86" target="#b3">[4]</ref>. This paper reintroduces Explicit Semantic Analysis (ESA) and its extension for cross-lingual document retrieval tasks, called Cross-lingual Explicit Semantic Analysis (CL-ESA), for the first time introduced by Sorg and Cimiano in 2008. The goal is to replicate an experiment from Sorg and Cimiano, who participated in the CLEF conference in 2008 and report on the results as well as to point out mistakes and problems along the way. This work should be read in conjunction with the original work done by Sorg and Cimiano [7].</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of this paper is to replicate an experiment and its results as reported in the paper Cross-lingual Information Retrieval with Explicit Semantic Analysis by Philipp Sorg and Philipp Cimiano. This paper is structured as follows: in Section 2, we concisely introduce Explicit Semantic Analysis <ref type="bibr" coords="1,422.20,479.23,9.96,8.74" target="#b4">[5]</ref>. Section 3 describes the extension of this approach for cross-lingual document retrieval using cross language links from Wikipedia. In Section 4 the experimental setup and the differences to the original experiment are described in detail. Finally, in Section 5 we present the results of the replicated experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Explicit Semantic Analysis</head><p>Explicit Semantic Analysis (ESA) uses chosen external categories to represent a given text t. We will introduce the main ideas of a Wikipedia based approach, so the reader is able to understand the notions in the implementation section. A more detailed description can be found either in the paper by Sorg and Cimiano <ref type="bibr" coords="1,197.20,632.21,10.52,8.74" target="#b7">[7]</ref> or by Markovitch and Gabrilovich <ref type="bibr" coords="1,372.19,632.21,9.96,8.74" target="#b4">[5]</ref>, who introduced this Wikipedia-based approach and the more general theory behind it. The main idea in Wikipedia-based Explicit Semantic Analysis is to map a text t into a high-dimensional real-valued vector space. Given a set of Wikipedia articles W k = {a 1 , . . . , a n } in language L k , each article a i is an external category and corresponds to a dimension in the vector space. The following function describes this mapping:</p><formula xml:id="formula_0" coords="2,257.66,177.17,95.66,43.41">Φ k : T → R |W k | Φ k (t) := v 1 , . . . , v |W k |</formula><p>where |W k | is the number of articles in W k . Each v i is computed by summing up the results of a function as, which defines the strength of association between a Wikipedia article a i and a word w j , for each word in a given text t = w 1 , . . . , w l . In this regard Φ k (t) is called ESA-vector and expresses the strength of association of a given text t with each article a i in W k .</p><formula xml:id="formula_1" coords="2,264.81,300.44,85.75,19.61">v i := wj ∈t as(w j , a i )</formula><p>There are many different ways to define the as function, e.g. here we use a tf.idf function, based on a Bag-of-Words model of the Wikipedia articles. In this sense, Explicit Semantic Analysis is very flexible, as it can be adapted to different tasks and contexts, simply by choosing a different as function.</p><p>as(w j , a i ) = tf.idf ai (w j )</p><p>The function we used for the experiment is described in Section 4. Computing the ESA-vector, means we compute the strength of association for each Wikipedia article a i , hence after sorting the ESA-vector by value, it corresponds to a ranking of Wikipedia articles according to relevance for a given text t. Essentially, Explicit Semantic Analysis transforms a given text t into a vector representation according to external categories. This means one can simply assess the similarity between two arbitrary texts t 1 and t 2 by computing their ESA-vectors and for example using the standard cosine similarity to compare the vectors. This is another reason for which Explicit Semantic Analysis is very flexible, as it can be used on arbitrary texts -we can simply adapt it to different tasks, among other things a retrieval task (query and document) or a clustering task (two documents).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Cross Lingual Explicit Semantic Analysis</head><p>Cross Lingual Explicit Semantic Analysis (CL-ESA) is an extension to ESA, which can handle multi-lingual retrieval tasks. This approach uses the fact that Wikipedia articles are linked across different languages. Therefore one can assume that there exists a mapping function m i→j , which maps an article a i from Wikipedia W i to its corresponding article in Wikipedia W j . Suppose there are n languages L 1 , . . . , L n . Transforming a given text t from language L i to language L j is as simple as transforming Φ i (t) to Φ j (t) using a map, which is defined over the cross language links in Wikipedia W i . Since we consider n languages, we define an n<ref type="foot" coords="3,183.36,141.33,3.97,6.12" target="#foot_1">2</ref> mapping function of the type:</p><formula xml:id="formula_2" coords="3,261.89,164.74,91.07,11.72">Ψ i→j : R |Wi| → R |Wj |</formula><p>This mapping is computed as follows:</p><formula xml:id="formula_3" coords="3,134.77,206.27,245.89,76.49">Ψ i→j v 1 , . . . , v |Wi| = v 1 , . . . , v |Wj | where v p = q∈{q * |mi→mj (aq * )=ap} v q with 1 ≤ p ≤ |W i |, 1 ≤ q ≤ |W j |.</formula><p>Given a text t in language L i , obtaining an ESA-vector from Wikipedia W j , is as simple as computing Ψ i→j (Φ i (t)). Using the above setting we can now define the cosine between a query q i in language L i and a document d j in language L j in a straightforward manner as follows:</p><formula xml:id="formula_4" coords="3,224.44,332.88,166.48,9.65">cos(q i , d j ) := cos(Φ i (q i ), Ψ j→i (Φ j (d j )))</formula><p>Now we obtained a uniform approach across multiple languages. Nevertheless, it is important to note that CL-ESA works under the assumption that the language of the document is known.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Implementation</head><p>In this section we will describe the implementation details used for the experiment. Unfortunately the overall setup differs from the original experiment, because we were not able to obtain database dumps from 2008. Instead we downloaded static HTML dumps<ref type="foot" coords="3,254.34,456.04,3.97,6.12" target="#foot_0">1</ref> in English, German and French from the year 2008 and extracted them on the disk <ref type="bibr" coords="3,275.43,469.57,7.75,8.74" target="#b0">[1]</ref><ref type="bibr" coords="3,283.18,469.57,3.87,8.74" target="#b1">[2]</ref><ref type="bibr" coords="3,283.18,469.57,3.87,8.74" target="#b2">[3]</ref><ref type="bibr" coords="3,287.06,469.57,7.75,8.74" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Preprocessing of the documents</head><p>For the actual indexing step we used the same methods as Sorg and Cimiano, namely a standard white space tokenizer, standard stop word lists for English, German and French and a Snowball 2 Stemmer for English, German and French respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">ESA Implementation</head><p>In this section we will give a detailed description of our implementation and preprocessing of the documents and Wikipedia articles. Moreover we will compare our implementation with the implementation described in the original paper by Sorg and Cimiano.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Wikipedia Article Preprocessing</head><p>After the extraction we realized quickly, that the static HTML dump has much more pages than just the article pages we wanted to index. Hence the first step for us was to write a python script which ignored Wikipedia specific pages. Fortunately these pages were easy to locate as their purpose was encoded in the filename of the page, namely pages which started with Category, Image, Portal, Help, Template, User or Wikipedia<ref type="foot" coords="4,476.12,177.20,3.97,6.12" target="#foot_2">3</ref> were ignored and the corresponding discussion pages <ref type="foot" coords="4,363.04,189.15,3.97,6.12" target="#foot_3">4</ref> were ignored as well. The python script simply changed the file extension from .html to .ign, which stands for ignore. Moreover every page with a filesize of less than 1KB was ignored, due to the fact that those files were redirect pages. The HTML markup for an actual article would already exceed this limit, hence there was no room for erroneously ignoring an actual article. Now the indexer would only index pages whose file extension is not .ign.</p><p>The processing of the Wikipedia articles is vastly different to Sorg's approach, due to using a different source. First we needed to extract the relevant text from the HTML mark up, using a library called JSoup<ref type="foot" coords="4,352.38,300.15,3.97,6.12" target="#foot_4">5</ref> . This library empowered us to query the HTML markup using CSS-style queries. With this approach we selected the div-element with id equal to content. Then we removed the table of contents which is a table tag with id equal to toc. Moreover we removed any category links, which is a div-element with id equal to catlinks and we removed all edit sections, which were span tags with class equal to editsection. After these steps we simply selected the text between all remaining tags and used this as a document for the index. We randomly sampled about 30 articles and looked at the result of this process to convince ourselves that there are no more unnecessary texts which might skew the index <ref type="bibr" coords="4,347.86,409.32,7.75,8.74" target="#b0">[1]</ref><ref type="bibr" coords="4,355.61,409.32,3.87,8.74" target="#b1">[2]</ref><ref type="bibr" coords="4,355.61,409.32,3.87,8.74" target="#b2">[3]</ref><ref type="bibr" coords="4,359.49,409.32,7.75,8.74" target="#b3">[4]</ref>. Nevertheless there were cases where this approach threw exceptions and we printed each of them into a logfile. However, the number was less than 200, when compared to the number of documents in the corpus which are more than half a million documents, we decided that it was not worth it to investigate those articles further at this stage.</p><p>For indexing the documents using Lucene 6 , it was not necessary to use the WikipediaAnalyzer, because our text was just plain text without Wiki markup. Therefore we used the same methods as in the preprocessing of the documents. Sorg and Cimiano mention two kinds of restrictions on the article selection, "Then all articles with less than 100 words or less than 5 incoming pagelinks were discarded." We implemented them adapted to the static HTML dump. The length is checked before adding a document to the index by counting the tokens generated from Lucene. The incoming page links were more complex to obtain. We generated a page link map by parsing all Wikipedia articles and counting the number of a href tags in the div-element with id equal to content. The link 7 in these tags is a path to the corresponding article in the filesystem and we used them as keys for the aforementioned page link map and counted the occurrences. Then instead of parsing the whole Wikipedia directory with the indexer, we simply looped over all keys in the map and only parsed the articles with 5 or more page links. Unfortunately, there are no exact document counts from Sorg and Cimiano after applying these restrictions. Nevertheless, they reported document counts after restricting the documents to "at least a language link to one of the two other languages we consider [. . . ] we used 536.896 English, 390.027 German and 362.972 French articles for the ESA indexing" <ref type="bibr" coords="5,425.44,214.64,10.52,8.74" target="#b7">[7]</ref> We ended up with more documents for the ESA indexing than Sorg and Cimiano. The English Wikipedia index consists of 1.517.398 documents, the German Wikipedia index consists of 520.433 documents and the French Wikipedia index consists of 431.245 documents. Considering the additional restriction Sorg and Cimiano applied to obtain their counts, we think that the discrepancy between our numbers is reasonable <ref type="bibr" coords="5,213.68,286.37,7.75,8.74" target="#b0">[1]</ref><ref type="bibr" coords="5,221.43,286.37,3.87,8.74" target="#b1">[2]</ref><ref type="bibr" coords="5,221.43,286.37,3.87,8.74" target="#b2">[3]</ref><ref type="bibr" coords="5,225.30,286.37,7.75,8.74" target="#b3">[4]</ref>. The English Wikipedia is much larger than the German or French Wikipedia. Therefore there are a lot more pages which do not have a link to German or French. The smaller discrepancy in the French and German Wikipedia are probably pages unique to their cultural heritage and therefore are not likely to have an English equivalent. Nevertheless, we did not check any of the aforementioned reasons, because the additional restriction is unrelated to replicating the experiment at hand. That being said, having a vastly different preprocessing and wikipedia source is probably a solid reason, why we were not able to obtain results similar to Sorg and Cimiano.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ESA Vector Computation</head><p>The computation of the ESA vector uses an inverted index of the selected Wikipedia articles. Each document will be queried against this index and the retrieved articles will be used to build the ESA vector. Similar to Sorg and Cimiano, we used Lucene for indexing and the association strength was implemented using a customized Lucene similarity function. The function takes a text t = w 1 , . . . , w l and a Wikipedia article a i of Wikipedia corpus |W | and computes the following function:</p><formula xml:id="formula_5" coords="5,134.77,506.90,270.90,137.30">as R (t, a i ) = (C t ) |a i | -1 wj ∈t tf ai (w j )idf (w j ) with C t = 1 wj ∈t idf (w j ) tf ai (w i ) = #occurrences ofw i ina i idf (w j ) = 1 + log |W | + 1 #articles containingw j</formula><p>The following idf is described in the original paper by Sorg and Cimiano:</p><formula xml:id="formula_6" coords="6,218.43,139.18,176.39,22.31">idf (w j ) = 1 + log #articles containingw j |W | + 1</formula><p>First we need to point out an error in defining the idf function the way it was defined by Sorg and Cimiano <ref type="bibr" coords="6,290.40,185.62,7.75,8.74" target="#b0">[1]</ref><ref type="bibr" coords="6,298.15,185.62,3.87,8.74" target="#b1">[2]</ref><ref type="bibr" coords="6,298.15,185.62,3.87,8.74" target="#b2">[3]</ref><ref type="bibr" coords="6,302.03,185.62,7.75,8.74" target="#b3">[4]</ref>. The result of the idf function would be negative because the fraction is definitely less than 1 and taking the log of a value less than 1 yields a negative result. We realized, that this is probably an error because in the literature (e.g. <ref type="bibr" coords="6,313.98,221.49,10.30,8.74" target="#b6">[6]</ref>), variations of the idf are defined differently and result in a positive value greater than 1. Therefore we swapped the numerator with the denominator and used this variant for our experiment.</p><p>Multi-lingual Mapping Similar to Sorg and Cimiano some preprocessing was needed to obtain the multi-lingual mapping. Due to using the static HTML dump instead of a database dump, the cross language links were embedded in the HTML and pointed to the actual filename on the filesystem. The replicated experiment only involved English topic titles, hence we only computed the mapping from German to English and from French to English. A normalization of the page title was not needed, because we computed the mapping using the document ids from the index, which correspond to the index of the dimension in the ESA-vector. Nevertheless we needed to deal with redirect pages <ref type="bibr" coords="6,415.50,371.84,7.75,8.74" target="#b0">[1]</ref><ref type="bibr" coords="6,423.25,371.84,3.87,8.74" target="#b1">[2]</ref><ref type="bibr" coords="6,423.25,371.84,3.87,8.74" target="#b2">[3]</ref><ref type="bibr" coords="6,427.12,371.84,7.75,8.74" target="#b3">[4]</ref>, therefore we used the following steps to compute the mapping:</p><p>1. For each document in the German (resp. French) index 2. Find the file in the file system and check 8 if a link to English is available 3. If an English link is available find the file in the file system. 4. Recursively determine if the file is a redirect page until the actual document is reached. 5. Look up the document id in the English index and add it to the mapping. Similar to Sorg and Cimiano we summed up the scores, in case of multiple language links pointed to the same article in the English Wikipedia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Language Identification</head><p>The computation of the ESA vector is based on the assumption that we know the language in which the document is written. Unfortunately this is not always the case. Even in the TEL German dataset used for the replication, there are records without any knowledge about the language. Hence Sorg and Cimiano presented the following function to determine the language of a document t:</p><formula xml:id="formula_7" coords="6,219.22,622.38,175.72,23.23">lang(t) := max L k ∈{L1,...,Ln} minDim(Φ k (t)) maxDim(Φ k (t))</formula><p>where "minDim(Φ k (t)) returns the value of the lowest dimension in vector Φ k and maxDim(Φ k (t)) returns the highest correspondingly." <ref type="bibr" coords="7,401.34,130.95,10.52,8.74" target="#b7">[7]</ref> To us this description of lowest and highest dimension of a vector does not make sense. We thought of multiple possibilities to interpret it, e.g. index of the dimension with the lowest and highest value of the vector or the actual minimal and maximal values of the vector. However, none of this made sense. Fortunately, Sorg and Cimiano give an intuition about their heuristic as "The intuition behind this heuristic is that a small difference between the values of the lowest and highest dimension, which is computed by the share of these values, means that the document matches good to many Wikipedia articles and it can therefore be assumed that the document is of the same language as the used Wikipedia articles. Comparing a document to Wikipedia articles in another language, there will be some matches but the value of lowest dimension will most probably be very small." Following this intuition lead us to interpret it as follows:</p><formula xml:id="formula_8" coords="7,192.89,294.83,228.37,23.22">lang(t) := max L k ∈{L1,...,Ln} #non zero elements of Φ k (t) |W k |</formula><p>where |W k | is the number of articles used from Wikipedia in language k <ref type="bibr" coords="7,457.35,325.18,7.75,8.74" target="#b0">[1]</ref><ref type="bibr" coords="7,465.09,325.18,3.87,8.74" target="#b1">[2]</ref><ref type="bibr" coords="7,465.09,325.18,3.87,8.74" target="#b2">[3]</ref><ref type="bibr" coords="7,468.97,325.18,7.75,8.74" target="#b3">[4]</ref>. This way we get the percentage of Wikipedia articles a document t is matched to. Then the language, in which the document should be written in, is the language of the Wikipedia base with the highest percentual article match. We have implemented our interpretation of the language identification, however when trying to identify the language of records without language tag, the run would have taken too long and we would not have been able to submit our results in time.</p><p>Therefore we chose to try and match a document without language tag with the German Wikipedia by default.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Retrieval</head><p>The retrieval algorithm we used, presented in Algorithm 1, is generally the same as Sorg and Cimiano presented in their paper. The only change here is that our language identification solely relies on language tags in the records to identify the correct language of the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>In this section we present additional information about the dataset, its language distribution, additional settings of the experiment and the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dataset</head><p>The TEL German dataset has in total 869353 records in over 100 different languages. The data can be split in records with a language tag, which is about 90%, and without a language tag, which is the rest. German, English and French are the main languages of those records with language tag and make up about Algorithm 1: Retrieval-Algorithm 88%. In our experiment we only use the title information to build queries for the index and according to Sorg and Cimiano "The title of the record is the only content information that is available for all records". We cannot confirm this statement, because we have found that about 4,5% of the records in the dataset do not contain title information <ref type="bibr" coords="8,278.68,321.45,7.75,8.74" target="#b0">[1]</ref><ref type="bibr" coords="8,286.43,321.45,3.87,8.74" target="#b1">[2]</ref><ref type="bibr" coords="8,286.43,321.45,3.87,8.74" target="#b2">[3]</ref><ref type="bibr" coords="8,290.30,321.45,7.75,8.74" target="#b3">[4]</ref>. In our experiment we simply ignore the records that do not contain this information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">CLEF Replicability Experiment</head><p>The objective of this experiment is to query the 50 given topics in English on the multi-lingual TEL German dataset <ref type="bibr" coords="8,310.77,393.10,7.75,8.74" target="#b0">[1]</ref><ref type="bibr" coords="8,318.52,393.10,3.87,8.74" target="#b1">[2]</ref><ref type="bibr" coords="8,318.52,393.10,3.87,8.74" target="#b2">[3]</ref><ref type="bibr" coords="8,322.40,393.10,7.75,8.74" target="#b3">[4]</ref>. The topics consist of a title and a short description to build a query. Sorg and Cimiano do not mention what they used to build the query. We chose to use only the title as a query. As for the ESA-vector length k we ended up trying two different settings. Sorg and Cimiano used k = 10.000 for topics and k = 1.000 for the records. We ran one experiment with the same settings and additionaly we ran another experiment with values of a magnitude smaller, namely for the topics we used k = 1.000 and for the records we used k = 100. The result obtained by Sorg and Cimiano was a mean average precision (MAP) of 6,7% <ref type="bibr" coords="8,304.22,488.75,9.96,8.74" target="#b7">[7]</ref>. Unfortunately, they did not explicitly mention a requirement for a record to count as a relevant document for a certain topic. Therefore we assumed, that every score greater than zero is a relevant document. This means that as soon as there is one overlapping dimension in the ESA-vectors of a record and a topic it would yield a relevant document. This assumption lead us to the problem, that the full list of relevant documents, obtained from the experiment with the larger ESA-vector length, matched more than two thirds of all the records in the dataset to nearly every topic. Looking at the list we figured out, that the score of the higher ranking documents decreased at a faster pace and the relevant documents after rank 1000 decreased in a much slower pace and yielded only a small fraction of the score in comparison to the higher ranking documents. We concluded, that it would be meaningful to cut off the results at a certain rank and look at the MAP of the reduced lists, because the relevant documents with a very low score might just have been accidently connected by a single Wikipedia article, which does not necessarily convey a semantical connection between a record and a topic. We used the top 10, the top 100 and the top 1000 results for each topic, and we calculated the MAP using trec eval 9 . The results are shown in Table <ref type="table" coords="9,347.94,142.90,3.87,8.74" target="#tab_0">1</ref>. After comparing our results with the 6,7% obtained by Sorg and Cimiano, we conclude, that we were not able to reproduce the result. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we described the CL-ESA approach presented by Sorg and Cimiano and we attempted to replicate an experiment, submitted to the CLEF conference in the year 2008. In the end we were not able to reproduce the result. Most parts of the experimental setup were replicated accurately, but especially the index might be very different in comparison with the index of the original experiment, because we were not able to obtain a Wikipedia database dump from 2008 and therefore worked with a static HTML dump. Since the index is at the core of the experiment, it can lead to subsequent differences in every other part. Other than that, some missing details, e.g. the way the query is built from the topics and a detailed explanation about what fields from the records of the dataset were used, make it hard to replicate the experiment in a more detailed manner. Moreover we ran into some problems based on our own assumptions. We are refering to the fact that the full result list of the experiment with the bigger ESA-vector lengths matched two thirds of all the records in the dataset to almost every topic. We think, that the cause of this problem lies in the fact, that while there are Wikipedia articles, which might very accurately describe a semantical category, there are certainly some articles, which have the opposite effect. To give a short example, suppose an article of a famous actress will have a lot of different words with different semantical meanings on her page (e.g. overview of her career and life), while also having acted in some horror movies. This article would then match any kind of record of the dataset, which somehow was able to obtain a positive score through words which are not semantically connected to horror movies, to the topic horror movies, even though there is probably no semantic connection whatsoever. Therefore we think, that for Wikipedia-based CL-ESA to yield better results it is essential to have a good article selection or to introduce certain restrictions on what ends up being a relevant document for a certain topic, e.g. at least 10 dimensions need to overlap in the ESA-vectors.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="8,149.71,118.90,181.04,7.89;8,149.71,129.86,52.25,7.89;8,165.05,139.87,43.48,8.37;8,149.71,150.78,16.66,7.89;8,149.71,161.74,54.89,7.89;8,165.05,171.78,50.82,7.86;8,165.05,182.71,64.95,8.37;8,165.05,193.67,52.25,7.89;8,180.39,203.68,94.32,7.89;8,165.05,214.59,16.66,7.89;8,149.71,226.55,16.66,7.89"><head>Input:</head><label></label><figDesc>Topics T , Language k, Documents D for t ∈ T do t = Φ k (t ); end for d ∈ D do l := lang(d); d = Ψ l→k Φ l (d ); for t ∈ T do score [t, d] = cos(t, d ); end end</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="9,169.99,197.21,275.39,69.36"><head>Table 1 .</head><label>1</label><figDesc>Mean Average Precisions of the experiments (values in %)</figDesc><table coords="9,195.11,218.51,223.74,48.06"><row><cell cols="4">ESA length (Topic/Record) Top 10 Top 100 Top 1.000</cell></row><row><cell>1.000/100</cell><cell>0,65 *</cell><cell>0,1</cell><cell>0,01</cell></row><row><cell>10.000/1.000</cell><cell cols="2">0,63 * 0,09 *</cell><cell>0,01</cell></row><row><cell cols="3">* submitted as run to the replicability track</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.73,646.48,282.93,7.47"><p>https://dumps.wikimedia.org/other/static_html_dumps/2008-06/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,144.73,656.80,173.03,7.86"><p>Snowball Stemmers are included in Lucene</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,144.73,612.96,335.87,7.86;4,144.73,623.92,138.67,7.86"><p>The prefixes were in the same language as the corresponding Wikipedia, e.g. Benutzer for User in the German Wikipedia</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,144.73,634.88,277.33,7.86"><p>for each prefix there was a discussion page encoded as &lt;prefix&gt; talk</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,144.73,646.48,84.73,7.47"><p>https://jsoup.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="4,144.73,657.44,145.93,7.47"><p>https://lucene.apache.org/core/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,138.35,142.59,342.24,7.86;10,146.91,153.55,333.68,7.86;10,146.91,164.51,333.68,7.86;10,146.91,175.46,333.68,7.86;10,146.91,186.42,153.75,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,296.33,153.55,184.26,7.86;10,146.91,164.51,107.54,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Trabelsi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mothe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Murtagh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,261.57,164.51,219.02,7.86;10,146.91,175.46,145.42,7.86">Proceedings of the Nineth International Conference of the CLEF Association (CLEF 2018)</title>
		<title level="s" coord="10,299.67,175.46,171.16,7.86">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Nineth International Conference of the CLEF Association (CLEF 2018)<address><addrLine>Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,197.38,342.25,7.86;10,146.91,208.34,288.78,7.86" xml:id="b1">
	<monogr>
		<title level="m" coord="10,368.26,197.38,108.10,7.86;10,146.91,208.34,183.64,7.86">CEUR Workshop Proceedings (CEUR-WS.org</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>CLEF 2018 Working Notes</note>
</biblStruct>

<biblStruct coords="10,138.35,219.30,342.24,7.86;10,146.91,230.26,188.59,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="10,336.43,219.30,144.16,7.86;10,146.91,230.26,87.00,7.86">CENTRE@CLEF2018: Overview of the Replicability Task</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Maistro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<editor>Cappellato et al.</editor>
		<imprint>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,241.22,342.24,7.86;10,146.91,252.18,295.06,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="10,334.00,241.22,146.59,7.86;10,146.91,252.18,212.90,7.86">Overview of CENTRE@CLEF 2018: a First Tale in the Systematic Reproducibility Realm</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Maistro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<editor>Bellot et al.</editor>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,263.14,342.24,7.86;10,146.91,274.09,333.68,7.86;10,146.91,285.05,311.52,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,279.70,263.14,200.89,7.86;10,146.91,274.09,143.34,7.86">Computing semantic relatedness using wikipediabased explicit semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Markovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,322.28,274.09,158.31,7.86;10,146.91,285.05,236.36,7.86">Proceedings of The Twentieth International Joint Conference for Artificial Intelligence</title>
		<meeting>The Twentieth International Joint Conference for Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="page" from="1606" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,465.75,285.05,14.85,7.86;10,146.91,296.01,333.68,9.85;10,146.91,307.62,170.46,7.47" xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Hyderabad</surname></persName>
		</author>
		<ptr target="http://www.cs.technion.ac.il/~shaulm/papers/pdf/Gabrilovich-Markovitch-ijcai2007.pdf" />
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>India</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,317.93,342.24,7.86;10,146.91,328.89,230.75,7.86" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="10,325.25,317.93,151.46,7.86">Introduction to Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,339.85,342.24,7.86;10,146.91,350.81,264.83,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,239.78,339.85,240.81,7.86;10,146.91,350.81,32.40,7.86">Cross-lingual Information Retrieval with Explicit Semantic Analysis</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sorg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cimiano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,200.51,350.81,182.55,7.86">Working Notes for the CLEF 2008 Workshop</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
