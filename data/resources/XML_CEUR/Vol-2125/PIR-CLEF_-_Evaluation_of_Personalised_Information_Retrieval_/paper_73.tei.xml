<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,148.41,115.96,318.53,12.62">PIR based on Explicit and Implicit Feedback</title>
				<funder ref="#_kehn2NK">
					<orgName type="full">Spanish Government</orgName>
				</funder>
				<funder ref="#_nfQ4k9T">
					<orgName type="full">Ministry of Education, Culture and Sport</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,144.14,153.84,96.38,8.74"><forename type="first">Alberto</forename><surname>Andreu-Marín</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center in Information and Communication Technologies (CEATIC</orgName>
								<orgName type="laboratory">Intelligent System for Information Access (SINAI) Advanced Studies</orgName>
								<orgName type="institution">Universidad de Jaén</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,248.83,153.84,151.31,8.74"><forename type="first">Fernando</forename><surname>Javier Martinez-Santiago</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center in Information and Communication Technologies (CEATIC</orgName>
								<orgName type="laboratory">Intelligent System for Information Access (SINAI) Advanced Studies</orgName>
								<orgName type="institution">Universidad de Jaén</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,408.04,153.84,63.18,8.74;1,214.55,165.79,55.11,8.74"><forename type="first">Manuel</forename><surname>Carlos Díaz-Galiano</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center in Information and Communication Technologies (CEATIC</orgName>
								<orgName type="laboratory">Intelligent System for Information Access (SINAI) Advanced Studies</orgName>
								<orgName type="institution">Universidad de Jaén</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,296.95,165.79,103.86,8.74"><forename type="first">L</forename><surname>Alfonso Ureña-López</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center in Information and Communication Technologies (CEATIC</orgName>
								<orgName type="laboratory">Intelligent System for Information Access (SINAI) Advanced Studies</orgName>
								<orgName type="institution">Universidad de Jaén</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,148.41,115.96,318.53,12.62">PIR based on Explicit and Implicit Feedback</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0DCF89FC480B5F53BAD7197CF490810F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Personalised Information Retrieval (PIR)</term>
					<term>explicit feedback</term>
					<term>implicit feedback</term>
					<term>language models</term>
					<term>perplexity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our research aim is twofold: the first one is to get leverage from the relevance feedback that the user provides over the course of every search session. In this way, we explore PIR task as a text categorization problem in order to distinguish between relevant and not relevant documents for the given user. A number of supervised machine learning algorithms has been applied in order to accomplish this task. The second one is related to implicit feedback. More concisely, time spent reading documents and text complexity. From the point of view of text complexity, we propose the hypothesis that there are significant differences of perplexity between judged/non-judged documents by the user. We find some weak statistical evidence that points out that high perplexity and judged documents are correlated.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Information Retrieval (IR) is a discipline that involves the retrieval of certain information within a document collection based on specific information needs <ref type="bibr" coords="1,463.10,476.36,17.49,8.74" target="#b11">[12,</ref><ref type="bibr" coords="1,134.77,488.32,7.01,8.74" target="#b1">2]</ref>. The widespread use of IR Systems by a large part of the population, in addition to the huge amount of data generated daily, requires knowledge of the specific information requirements of users. The evaluation that a user makes of a proposed result is personal <ref type="bibr" coords="1,264.40,524.18,9.96,8.74" target="#b5">[6]</ref>, this can be expressed either explicitly (giving his/her opinion, the so-called relevance judgments) or implicitly (analyzing the behavior while interacting with the system). In addition, it is desirable to obtain a knowledge base about the preferences of each user in order to adapt the proposed results.</p><p>The subject of this paper concerns task 2 of the PIR-CLEF laboratory. The challenge in this work is to use the files provided by the organization (csv1 -csv5) to create user profiles that can be used to improve the quality of the results provided by an IR System. Both explicit and implicit data can be found in these files, although certain characteristics can be inferred from the former.</p><p>This entire process involves the development of a Personalized Information Retrieval system (PIR) based on a number of explicit and implicit feedbacks such as user document relevance assessments, search logs including timestamps of every action, and ranking of documents as a result of every search performed by the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Explicit and implicit feedback</head><p>Two different types of input data sources are usually identified in the scientific literature: implicit and explicit feedback <ref type="bibr" coords="2,336.00,209.03,9.96,8.74" target="#b6">[7]</ref>. Specifically, explicit feedback refers to a conscious assessment given by the user indicating the relevance of a document retrieved for a query. On the other hand, in the implicit feedback, the information must be inferred according to the data that could be collected about the user's behavior when interacting with the system (navigation logs, task description, eyes tracking, etc.).</p><p>When implicit feedback is used for the development of this type of system, there may be uncertainty when interpreting the results. To this end, an attempt will be made to find some kind of correlation between the implicitly inferred information and the explicit evaluation given by the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and results</head><p>In this section, we present the different actions that we have accomplished in our participation in CLEF PIR 2018 Task 2 Evaluation of Personalised Information Retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Feature extraction from retrieved web pages</head><p>Firstly, data acquisition has been accomplished to retrieve the Clueweb documents that each user evaluated as a result of the execution of each of them <ref type="bibr" coords="2,462.33,454.85,14.61,8.74" target="#b10">[11]</ref>. For this first step, the attribute "query text" belonging to the file csv2.csv provided by the organization is used. A query result is made of the first one hundred documents obtained using the API provided by the organisation and developed by the University of Dublin<ref type="foot" coords="2,257.71,501.10,3.97,6.12" target="#foot_0">1</ref> , each of which contains an attribute called "id", which is used to download the corresponding web page using page rendering of Clueweb12 data-set online services <ref type="foot" coords="2,285.51,525.01,3.97,6.12" target="#foot_1">2</ref> .</p><p>Secondly, once the corresponding web pages are downloaded we move on to the pre-processing phase:</p><p>-Only the text contained in the labels "title" and "p" (paragraph) has been considered. -The resulting text has been processed by eliminating stop words and by executing the Porter stemming algorithm.</p><p>-Every document is represented as a set of tokens made by unigrams, bigrams and trigrams. -TF.IDF has been calculated for each token belonging to each of the different user categories <ref type="bibr" coords="3,217.62,155.02,9.96,8.74" target="#b4">[5]</ref>. This determines how relevant this term is in the category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Explicit feedback as text categorization</head><p>Relevance Feedback is a well-known technique in the field of information retrieval. The idea behind relevance feedback is to take the results that are initially returned from a given query, to gather user feedback, and to use information about whether or not those results are relevant to perform a new query <ref type="bibr" coords="3,462.33,254.30,14.61,8.74" target="#b11">[12]</ref>.</p><p>On the other hand, methods based on supervised machine learning are the most frequent approach to accomplish the task of text Categorization <ref type="bibr" coords="3,420.40,278.21,10.52,8.74" target="#b7">[8,</ref><ref type="bibr" coords="3,432.58,278.21,11.62,8.74" target="#b12">13]</ref>. In this section, we face the PIR task as a text categorization task where the categories are the user relevance judgments for every query and a set of retrieved documents. Thus, we do not perform a new query as usual when relevance feedback is applied. Instead of that, we train a number of supervised machine learning algorithms by using features extracted from every document (Section 3.1). The main hypothesis that we want to explore is whether the subjective and non-expert relevance judgments provided for each user are valid to define document categories.</p><p>A second hypothesis is to validate the set of features extracted from the retrieved documents. A final hypothesis regards with the number of examples (judged documents) provided for each user and query: is this number high enough to train some of the most popular supervised machine learning algorithms? As a consequence, a number of supervised machine learning algorithms have been trained using the user relevance judgments, characterizing each of the documents based on sequences of n grams (Unigrams, Bigrams and Trigrams) extracted from the texts and using the bag of words method, which allows us to represent documents ignoring the order of the words that make it up.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Results</head><p>. In order to evaluate our approach, we have followed a k-fold cross-validation approach with k = 10 <ref type="bibr" coords="3,302.72,512.33,10.52,8.74" target="#b8">[9]</ref> where applicable. In addition we have implemented both a fine-grained and a coarse-grained text categorization task. For the first one, on one hand, we distinguish four categories in the same way the relevance of the document to the topic (1 off-topic, 2 not relevant, 3 somewhat relevant, 4 relevant). On the other hand, The coarse-grained text categorization task is a binary classifier with two categories only: relevant (categories 3 and 4) and non-relevant documents (categories 1 and 2).</p><p>The results obtained in Table <ref type="table" coords="3,283.03,596.18,4.98,8.74" target="#tab_0">1</ref> represent the success rates of the classifiers in the test phase. These data must be analyzed from the perspective of the problems presented by the classification algorithms used. In this case, not all users present sufficient or sufficiently good data to confirm the results presented.</p><p>For experiments with 4 categories (1-2-3 and 4), 10-fold cross-validation can only be accomplished for user 02, user 11, user 15 and user 07 in the Books topic only. This is because many of the samples provided by the organization are not representative enough to perform cross-validation up to 10 folds. In general, it can be said that, when it is possible to define 10-fold, explicit feedback gets systematically results whose performance improvement (47% on average) is statistically significant when considering random values as case base. For the rest of the users, the results presented have been obtained by applying a smaller number of folds because some of the samples are unbalanced.</p><p>In the case of coarse-grained experiments, with 2 categories, it has not been possible to balance the evaluation values in any of the cases, the reference values taken to check the result of the classifiers remain the same as in the case of 4 categories. It can be seen that all cases the success rates of the classifiers increase by around 15% with respect to fine-grained results.</p><p>The best result is obtained by user 17 and Books as topic. The reason is that this case is extremely unbalanced: 128 of a total of 133 documents are judged as off-topic or not relevant.</p><p>Regarding the best classifier, it is not possible to select the best one since this depends on the user and topic. This suggests that a voting strategy could be a good option as future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Implicit feedback</head><p>Consider our first approximation to Personal Information Retrieval, we have focused on two different issues regarding implicit feedback <ref type="bibr" coords="4,401.83,632.21,9.96,8.74" target="#b6">[7]</ref>, where various search logs are collected and analyzed to infer attitudes with the aim to assess the relevance of certain items indirectly through a users actions and behaviours.</p><p>More concisely we are focused in two main hypothesis based on timing and statistics language models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.3.1</head><p>The time spent on a page. Based on the information in the data set provided by the organization, it is intended to make use of the time spent by each user evaluating each document. This experiment aims to demonstrate the hypothesis that the time the user spends evaluating a result is related to the interest generated by the content of the website. This is a quite controversial issue finding evidence that supports this hypothesis <ref type="bibr" coords="5,362.94,228.56,10.52,8.74" target="#b2">[3]</ref> or not at all <ref type="bibr" coords="5,432.70,228.56,14.61,8.74" target="#b9">[10]</ref>.</p><p>Suddenly, there is no way to be sure about the time spent on a page just by using the search logs provided by the PIR-CLEF organization since there is no timestamps about close document events. Even though this drawback we have tried to accomplish a study to correlate timing and user assessments. Consequently, we interpreted the time spent on a page as the difference between two consecutive open document events, start session and open document event or open document and end session event. The next step we tested is whether this sequence of time periods follows a normal sequence. Thus, we apply a ShapiroWilk test for each user search log. In addition, we eliminated time periods that are out the two central percentiles 25, with the aim of removing anomalous time periods. We find that the most of time distributions are not normal even though filtering anomalous data. Finally, we applied a two tailed Student T-Test for those cases where normality is found. For the rest of cases, we applied Mann-Whitney-Wilcoxon.</p><p>In the end of this process we have to conclude that, in general and following the procedure described above, it is not possible to reject the null hypothesis: user document judgments and time spent on a page are correlated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.3.2</head><p>Investigating the relationship between language model perplexity and user relevance measures. The canonical measure of goodness of a statistical language model is normally reported in terms of perplexity: the exponential of the negative normalized predictive likelihood under the model, and gives an indication of the expected word error rate as in speech recognizers <ref type="bibr" coords="5,134.77,532.60,9.96,8.74" target="#b0">[1]</ref>. This finds some evidence that the perplexity of the language model has a systematic relationship with the achievable precision recall performance by using traditional Information Retrieval systems. Following this finding, we hypothesize that for a given probabilistic language model, there is significant differences between the perplexity of the set of documents that are evaluated by the user and those documents that are not evaluated.</p><p>We used trigram language models with interpolated Kneser-Kney discounting trained using the SRI language modeling toolkit <ref type="bibr" coords="5,356.89,617.88,14.61,8.74" target="#b13">[14]</ref>. We generated different models by varying the training corpus.</p><p>-Simple-wiki <ref type="bibr" coords="5,205.66,656.12,9.96,8.74" target="#b3">[4]</ref>: 137K sentence Simple English Wikipedia articles.</p><p>-Sphinx-70k: CMUSphinx US English generic acoustic model<ref type="foot" coords="6,422.52,117.42,3.97,6.12" target="#foot_3">3</ref> . this is the most general language model that we have considered. This is the best suited to represent the English language. -ClueWeb12 search: List of documents retrieved by using every set of queries related for each topic. ClueWeb12 search service provided by the organization was applied in order to retrieve the 100 first ranked documents. Note that we have a different language model for each topic proposed in the PIR-CLEF dataset.</p><p>The perplexity of three sets of documents per each user query was measured: the set of relevant documents (user relevance judgment is 3 or 4), non-relevant documents (user relevance judgment is 1 or 2) and unjudged documents (there is no user relevance judgment in spite of they are part of the ranked list of documents retrieved) Finally, an one-tailed Mann-Whitney-Wilcoxon (MWW) test was performed<ref type="foot" coords="6,474.63,282.42,3.97,6.12" target="#foot_4">4</ref> . When language models based on Simple-wiki and ClueWeb12 search datasets are applied we have no found any significative difference between the perplexity of the the three set of documents considered (relevant, non-relevant or unjudged) When Sphinkx-70k is used to train the language model, we find some evidence that the complexity of judged documents (relevant or not relevant) are greater than those that are unjudged (U-value=59, critical U-value at p&lt;0,05=51). This is quite surprising since it could be interpreted in the way that the user tends to evaluate the most complex texts. Once we revise some of the non-judged document we find that it is quite frequent that these documents do not have textual content at all, only lists of sections, menus and stylesheets but no or very little meaningful text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Future Work</head><p>In this work, an overview has been given of the use of explicit and implicit feedback for the generation of user profiles. In the case of explicit feedback, a classification system is trained based on the user's judgements of relevance provided for a given set of documents. In the case of implicit feedback, the intention is to seek a correlation between the information that can be inferred from the data and the relevance judgments provided by users, so that user profiles and system accuracy can be improved.</p><p>In future work it would be interesting to have information relevant to certain aspects. The file csv6.csv provided by the organization, shows the TF.IDF values of the tokenized terms, it would be interesting to be able to relate each of these terms with the document to which it belongs, in this way, they could be used for the realization of the training phase characterization of web pages.</p><p>On the other hand, in order to search for a correlation between the interest that an user has in a web page and the time he spends visiting it, it would be interesting to have the "CLOSE DOCUMENT" attribute of all the records. Currently there are only 5 records with this attribute in the csv2.csv file.</p><p>In order to further deepen this task, it would be helpful to have the traditional expert judgements of relevance. In this way, relationships could be sought in those cases in which the user did not agree with the expert and try to discern the most probable cause.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.77,115.91,345.83,209.23"><head>Table 1 .</head><label>1</label><figDesc>Classification Results. Naive Bayes, Support Vector Machine and K-nn classifiers were used.</figDesc><table coords="4,136.56,146.92,285.92,178.22"><row><cell>4 categories</cell><cell>2 categories</cell></row><row><cell cols="2">Users/topic NB MVC Knn NB MVC Knn</cell><cell>NB &amp; MVC</cell></row><row><cell cols="2">User 02/Music 0.50 0.42 0.40 0.63 0.66 0.47</cell><cell>10 fold</cell></row><row><cell cols="2">User 07/Books 0.43 0.44 0.31 0.53 0.58 0.62</cell><cell>9 fold</cell></row><row><cell cols="2">User 07/Travel 0.66 0.75 0.71 0.79 0.83 0.73 User 08/Books 0.79 0.73 0.75 0.91 0.87 0.71</cell><cell>8 fold</cell></row><row><cell cols="2">User 08/Travel 0.68 0.67 0.88 0.92 0.89 0.77</cell><cell>6 fold</cell></row><row><cell cols="2">User 11/Travel 0.46 0.47 0.34 0.58 0.63 0.71</cell><cell>5 fold</cell></row><row><cell cols="2">User 12/Sports 0.47 0.42 0.33 0.79 0.74 0.38 User 12/Travel 0.64 0.64 0.72 0.82 0.77 0.88</cell><cell>3 fold</cell></row><row><cell cols="2">User 13/Sports 0.68 0.68 0.85 0.81 0.86 0.70</cell><cell>1 fold</cell></row><row><cell cols="2">User 15/Travel 0.47 0.46 0.56 0.69 0.74 0.65</cell><cell>KNN</cell></row><row><cell cols="2">User 16/Travel 0.59 0.56 0.64 0.72 0.66 0.56</cell><cell>Optimal K</cell></row><row><cell cols="2">User 17/Books 0.75 0.66 0.55 0.96 0.97 0.86 User 18/Books 0.31 0.15 0.58 0.68 0.68 0.56</cell><cell>k=3</cell></row><row><cell cols="2">User 18/Travel 0.42 0.47 0.25 0.47 0.55 0.25</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,623.92,266.95,7.86;2,144.73,634.88,335.86,7.86;2,144.73,645.84,49.66,7.86"><p>http://clueweb.adaptcentre.ie/WebSearcher/search?query="query String"&amp;selection=[selection numbers separated by comma] (last visited: 30/05/2018)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,656.80,273.24,7.86"><p>https://www.lemurproject.org/clueweb12/services.php (last visited:</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2" coords="2,421.04,656.80,49.65,7.86"><p>30/05/2018)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3" coords="6,144.73,591.04,335.87,7.86;6,144.73,602.00,26.93,7.86"><p>https://sourceforge.net/projects/cmusphinx/files/Acoustic and Language Models/US</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4" coords="6,137.50,611.20,3.65,5.24;6,144.73,612.96,335.86,7.86;6,144.73,623.92,335.87,7.86;6,144.73,634.88,335.86,7.86;6,144.73,645.84,335.86,7.86;6,144.73,656.80,335.86,7.86"><p><ref type="bibr" coords="6,137.50,611.20,3.65,5.24" target="#b3">4</ref> When the dataset is small, the P-Value from t-Student is likely to be the most usual test but it requires a normal distribution of the dataset. For this reason, we applied Shapiro-Wilk test that is suited for small datasets and we found that it is not always possible to assert that the considered datasets follow a normal distribution. As a consequence we applied a non-parametric test, the Mann-Whitney-Wilcoxon U test</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5">Acknowledgments</head><p>Work supported by a grant from the <rs type="funder">Ministry of Education, Culture and Sport</rs> (<rs type="grantName">MECD-Scholarship</rs> <rs type="grantNumber">BES-2016-076609</rs>) and the <rs type="projectName">REDES</rs> project (<rs type="grantNumber">TIN2015-65136-C2-1-R</rs>) of the <rs type="funder">Spanish Government</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_nfQ4k9T">
					<idno type="grant-number">BES-2016-076609</idno>
					<orgName type="grant-name">MECD-Scholarship</orgName>
					<orgName type="project" subtype="full">REDES</orgName>
				</org>
				<org type="funding" xml:id="_kehn2NK">
					<idno type="grant-number">TIN2015-65136-C2-1-R</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,142.96,372.51,337.64,7.86;7,151.52,383.47,329.07,7.86;7,151.52,394.43,329.07,7.86;7,151.52,405.39,233.01,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,348.07,372.51,132.53,7.86;7,151.52,383.47,259.70,7.86">Investigating the relationship between language model perplexity and ir precision-recall measures</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Girolami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Van Risjbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,432.51,383.47,48.08,7.86;7,151.52,394.43,329.07,7.86;7,151.52,405.39,122.20,7.86">Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval</title>
		<meeting>the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="369" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,416.27,337.64,7.86;7,151.52,427.23,116.62,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,322.12,416.27,117.19,7.86">Modern information retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>ACM press</publisher>
			<biblScope unit="volume">463</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,438.12,337.63,7.86;7,151.52,449.08,329.07,7.86;7,151.52,460.04,50.43,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,335.57,438.12,106.19,7.86">Implicit interest indicators</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Claypool</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wased</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,463.04,438.12,17.56,7.86;7,151.52,449.08,282.78,7.86">Proceedings of the 6th international conference on Intelligent user interfaces</title>
		<meeting>the 6th international conference on Intelligent user interfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,470.92,337.64,7.86;7,151.52,481.88,329.07,7.86;7,151.52,492.84,329.07,7.86;7,151.52,503.80,198.73,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,255.89,470.92,220.85,7.86">Simple english wikipedia: a new text simplification task</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Coster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kauchak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,165.47,481.88,315.13,7.86;7,151.52,492.84,232.02,7.86">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="665" to="669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,514.69,337.63,7.86;7,151.52,525.65,276.72,7.86" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">D</forename><surname>Galarza Quishpe</surname></persName>
		</author>
		<title level="m" coord="7,249.55,514.69,231.04,7.86;7,151.52,525.65,27.42,7.86">Text Classification for literature search of research study designs</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
		<respStmt>
			<orgName>Australia/Universidad de Melbourne</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct coords="7,142.96,536.54,337.64,7.86;7,151.52,547.49,329.07,7.86;7,151.52,558.43,191.18,7.89" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,204.95,536.54,275.65,7.86;7,151.52,547.49,207.26,7.86">Other people&apos;s judgments: A comparison of users&apos; and others&apos; judgments of document relevance, topicality, and utility</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Janes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,365.37,547.49,115.23,7.86;7,151.52,558.45,114.53,7.86">Journal of the American Society for Information science</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">160</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,569.34,337.64,7.86;7,151.52,580.30,240.02,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,304.58,569.34,171.89,7.86">Recommending based on implicit feedback</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jannach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lerche</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zanker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,165.60,580.30,102.46,7.86">Social Information Access</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="510" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,591.19,337.63,7.86;7,151.52,602.15,329.07,7.86;7,151.52,613.10,81.96,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,210.86,591.19,269.73,7.86;7,151.52,602.15,92.27,7.86">Text categorization with support vector machines: Learning with many relevant features</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,266.75,602.15,170.59,7.86">European conference on machine learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="137" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,623.99,337.63,7.86;7,151.52,634.95,319.04,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,222.95,623.99,257.64,7.86;7,151.52,634.95,78.54,7.86">A study of cross-validation and bootstrap for accuracy estimation and model selection</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kohavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,250.91,634.95,19.97,7.86">Ijcai</title>
		<meeting><address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1137" to="1145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,645.84,337.98,7.86;7,151.52,656.80,276.54,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,252.98,645.84,227.61,7.86;7,151.52,656.80,98.93,7.86">Information filtering based on user behavior analysis and best match text retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Morita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Shinoda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,271.17,656.80,32.86,7.86">SIGIR94</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="272" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,119.67,337.97,7.86;8,151.52,130.63,329.07,7.86;8,151.52,141.59,115.03,7.86" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="8,437.21,119.67,43.38,7.86;8,151.52,130.63,329.07,7.86;8,151.52,141.59,115.03,7.86">Evaluation of personalised information retrieval at clef 2017 (pir-clef): towards a reproducible evaluation framework for pir</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Marrara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sanvitto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ganguly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sen</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,152.55,337.97,7.86;8,151.52,163.48,315.82,7.89" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,253.30,152.55,223.16,7.86">Improving retrieval performance by relevance feedback</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,151.52,163.51,223.80,7.86">Journal of the American society for information science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="288" to="297" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,174.47,337.98,7.86;8,151.52,185.40,158.82,7.89" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,212.35,174.47,203.16,7.86">Machine learning in automated text categorization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,422.50,174.47,58.09,7.86;8,151.52,185.43,80.63,7.86">ACM computing surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,196.39,337.97,7.86;8,151.52,207.34,222.67,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,202.72,196.39,187.92,7.86">Srilm-an extensible language modeling toolkit</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,413.49,196.39,67.10,7.86;8,151.52,207.34,194.00,7.86">Seventh international conference on spoken language processing</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
