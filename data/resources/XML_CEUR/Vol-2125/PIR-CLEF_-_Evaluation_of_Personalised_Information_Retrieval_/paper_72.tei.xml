<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,160.11,115.96,295.14,12.62;1,184.31,133.89,246.74,12.62">ECNU at CLEF PIR 2018 : Evaluation of Personalized Information Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,183.82,171.56,59.64,8.74"><forename type="first">Qingchun</forename><surname>Bai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Software Engineering</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,254.02,171.56,46.64,8.74"><forename type="first">Jiayi</forename><surname>Chen</surname></persName>
							<email>jychen@ica.stc.sh.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Software Engineering</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,311.20,171.56,48.99,8.74"><forename type="first">Qinmin</forename><surname>Hu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Ryerson University</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,387.35,171.56,39.72,8.74"><forename type="first">Liang</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Software Engineering</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,160.11,115.96,295.14,12.62;1,184.31,133.89,246.74,12.62">ECNU at CLEF PIR 2018 : Evaluation of Personalized Information Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DE9F68FACC79022C063870CC75BEDBC2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Personalized Information Retrieval</term>
					<term>Query Expansion</term>
					<term>Data Analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Personalized Information Retrieval (PIR) is an effective solution when purposes of queries are issued but users receive the same results. The PIR-CLEF 2018 task aims to explore the methods and evaluations of PIR. By analyzing the provided data we generate query level and session level baselines. We compare baselines and extended models we propose, and experiment results show that insufficient relevance information has a negative impact on the performance of models and evaluation process. Since personalization ranking based on typical users interests is not effective in reality, especially when the results of relevance feedback is not satisfactory, we consider that the PIR task should not only relate to context, but to the various search intentions. We propose several suggestions about data and evaluation process.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The PIR-CLEF 2018 task aims to explore the methods and evaluations of Personalized Information Retrieval (PIR). PIR has drawn great attention to help understand user's behaviors in the interaction with IR systems. Personalized search is an effective solution when queries purposes are issued but users received the same results.</p><p>Existing works <ref type="bibr" coords="1,217.56,536.57,11.15,8.74" target="#b2">[3,</ref><ref type="bibr" coords="1,228.71,536.57,7.43,8.74" target="#b4">5,</ref><ref type="bibr" coords="1,236.15,536.57,7.43,8.74" target="#b3">4]</ref> have proved that personalized ranking can be considered as a good solution for PIR task. The foundation and key of personalized ranking service is how to obtain persons attempt to frame user's interest model. Various penalization strategies are carried out, for example, In <ref type="bibr" coords="1,412.37,572.43,9.96,8.74" target="#b6">[7]</ref>, a method is discussed to identify user's interest automatically, which based on the assumption that a user's general preference may help the search engine disambiguate the true intention of a query. The approach described in <ref type="bibr" coords="1,384.77,608.30,10.52,8.74" target="#b7">[8]</ref> considered a user's prior interactions with a wide variety of content to personalize that user's current web search. More recently, in <ref type="bibr" coords="1,285.96,632.21,9.96,8.74" target="#b0">[1]</ref>, a dynamic personalized ranking model is proposed to recommend the most relevant information which combined different sources of information.</p><p>For another piece of research, the research focus on understanding the user's intent of search session information <ref type="bibr" coords="2,285.09,130.95,12.57,8.74" target="#b1">[2,</ref><ref type="bibr" coords="2,297.66,130.95,8.38,8.74" target="#b5">6,</ref><ref type="bibr" coords="2,306.04,130.95,8.38,8.74" target="#b8">9,</ref><ref type="bibr" coords="2,314.42,130.95,12.57,8.74" target="#b9">10]</ref>, results show that it is possible to understand the user's intent, since people all have intentions in the process of seeking information and also have reasons to believe these information seeking intentions.</p><p>These prior works on personalized information retrieval have focused on independent issues with independent data. A few of them also have focused on the analysis of required data and evaluation of personalized ranking. In fact, we consider that personalized ranking based on typical user's interests is not effective in reality, especially when the results of relevance feedback are not good, the re-ranking model cannot achieve the desired result.</p><p>Therefore, in this study, we aim to explore the potential of the task and understand both the data and evaluation of the personalized search and ask the following research questions:</p><p>-If the provided PIR data can satisfied the task? -How to achieve personalization, and what kind of data is needed to support this research? -How to evaluate it?</p><p>To achieve this aims, this paper is organized as follows. In section 2, we briefly review and analysis the current PIR data. In section 3, we describes our baselines method to the data in detail. In section 4, experiments and results are presented. Finally, we discuss the task and evaluation in section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Review and Analysis</head><p>We present the statistics about dataset in this section, the review of current dataset described in Section 2.1, and explores the potenital of the dataset. Then we analysis the query session given by the data in Section 2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistics about Dataset</head><p>In this section, we briefly review current dataset of PIR task and provide a comprehensive analysis on this task. In PIR-CLEF 2018, data are provided with six csv files including information below:</p><p>the search tasks (sessions) of ten users; the queries submitted by all users and all documents returned by ClueWeb API; relevance scores labeled by users and original ranks of documents; personal information like gender and job; remarks written by users; statistical information of terms in queries.</p><p>Statistics about Sessions A user can submit several queries in a query session. These queries are aiming at different objectives. To find the objective of the user, we gather all queries as one query to represent the objective. We need to submit this query to the API and evalutate the performance.</p><p>The users submit their queries to the ClueWeb API<ref type="foot" coords="3,376.66,141.15,3.97,6.12" target="#foot_0">3</ref> and annotate whether the returned documents are relevant. The users divide relevance into four grades: relevant, somewhat relevant, not relevant and off topic with scores ranging from four to one. According to the description above, we define that documents are relevant to the query only when those scores are four. Figure <ref type="figure" coords="3,399.69,190.54,4.98,8.74" target="#fig_0">1</ref> shows the framework of the personalized ranking part. Baselines We propose two baselines: query-level baseline and session-level baseline. In query-level baseline, we evaluate each query independently. While in session-level baseline, we collect all relevant documents of queries in the session and consider them as the relevant documents of the search task. We evaluate the performance of each query on its search task. We also assume that queries belonging to one session represent different aspects of user's need. So we sum up all queries in a session to one and submit it to the ClueWeb API. We evaluate and display the performance of each session baseline in Table <ref type="table" coords="3,405.47,515.22,3.87,8.74" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query Expansion</head><p>We first take user's feedback into account. After the user labels the documents with relevance score, we choose ten words with highest frequency in relevant documents as expansion words and add them to the original session-level query. We submit the new queries to the API and evaluate the performance of this method. Then we assume top-20 documents returned from API are relevant and select ten most frequent words in documents as expansion words. The first method is listed in Table <ref type="table" coords="3,321.96,616.66,4.98,8.74" target="#tab_1">2</ref> with suffix "RF" while the second one is named with suffix "PRF".</p><p>Topic-Sensitive User model We propose a language modeling approach to personalized search based on users' search behavior and preference. To capture the user's searching interesting and implicit purpose, we propose to use LDAbased approach for simulating users which does not merely focus on simulating the search behaviours but also considers search sessions of the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Performance of Each Query Session</head><p>Table <ref type="table" coords="4,177.19,259.95,4.98,8.74" target="#tab_0">1</ref> shows the performance results of each query session, there are total 14 automatic session IDs and we obtain a list as follows. "Sum Up" means the performance of the new query generated by all queries in a session and "Single Query" is mean performance of all queries in a session. From this table, we observe that different session have the wide variations performance. The best result is session 156, the category of the query is "Travel". The user gives a higher relevance score which denotes the relevance of the document to the topic (1 off-topic, 2 not relevant, 3 somewhat relevant, 4 relevant). the description of the users is "The relevant documents are documents that list as many historical and popular places in venice. I don't want to see other documents that talk about other related places. In addition to that I am not interested about accomodation during my search." </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance Comparison</head><p>We further make a comparison between baselines and our methods in Table <ref type="table" coords="5,472.85,136.67,3.87,8.74" target="#tab_1">2</ref>. In query-level evaluation, our methods are worse than baselines. In session-level evaluation, relevance feedback method performs better than baselines because we can obtain users' interests from relevant documents. However pseudo relevance feedback and LDA methods get worse performance than baseline. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>It is within our expectation that all query-level evaluations are worse than that of baseline. We think this phenomenon is caused by the lack of relevant documents. In the provided data, each user only labels about twenty documents whose original ranks range from 0 to 100 and few of them are relevant. Assuming the users get 100 documents returned per query, eighty percent of relevance information is lost. In this scenario, any document not occurring in this list is considered as irrelevant which means a relevant document can be annotated as irrelevant from the perspective of user. Insufficient relevance information even make us hard to evaluate on certain queries. In session 154, 176 and 204, all documents are irrelevant so that even though we find the potentially relevant documents, we cannot know whether they are relevant from the angle of users.</p><p>We also think the evaluation process should be upgraded. Unlike existing search task like TREC tracks, personalized information retrieval focuses more on individual differences. In PIR-CLEF 2018, some users receive the same task but the queries they submit are different. For example, user 8,11 and 12 receive the same task of traveling, but their queries are about Dublin, Tokyo and Barcelona. The individual differences are expressed by queries so we think this task is still an ad-hoc retrieval task. So if we want to focus on individual differences, we need more users to join in the data collection.</p><p>We suggest that the complete logs of users can be provided. By analyzing the relevant documents annotated by users, we get an improvement in session aspect as listed in Table <ref type="table" coords="5,208.64,620.25,3.87,8.74" target="#tab_1">2</ref>. However our method still can be improved. In this task we are provided with users' actions such as opening document and submitting a query. But we think these data is not sufficient enough because only part of actions are provided so that we cannot analyze users' preference by their actions.</p><p>In conclusion, we put up with three suggestions. The first one is that more complete relevance labels should be provided. Then we think more participants can join in the data collection to provide more personalized data. The last one is that we think detailed user actions can help improve the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We have proposed a view of PIR task that implies that personalization should be with respect not only to context, but to the various information that people have during the course of an information search session. We focus on taking user's feedback into account and propose two extend models : Query Expansion method and Topic-Sensitive user model. We first conduct experiments on each query session, results show that different session have the wide variations performance. Then we compared baselines with extended models. Noting that topic-sensitive strategy does not work very well, insufficient relevance information has a negative impact on the performance of models and evaluation process. We will extract more useful features and focus on the learning to rank approaches in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,218.64,398.33,178.09,8.74"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Personalized Ranking Framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,155.71,426.89,303.93,199.53"><head>Table 1 :</head><label>1</label><figDesc>Performance of Each Query Session</figDesc><table coords="4,155.71,442.42,303.93,184.00"><row><cell>Session ID</cell><cell>Sum Up</cell><cell>Single Query</cell><cell></cell></row><row><cell></cell><cell>MAP NDCG P@5 P@10 MAP</cell><cell>NDCG</cell><cell>P@5 P@10</cell></row><row><cell>107</cell><cell>0.1581 0.5546 0.2000 0.3000 0.1069</cell><cell>0.2241</cell><cell>0.4222 0.3666</cell></row><row><cell>154</cell><cell>0.0000 0.0000 0.0000 0.0000 0.0000</cell><cell>0.0000</cell><cell>0.0000 0.0000</cell></row><row><cell>156</cell><cell>0.7588 0.9294 1.0000 1.0000 0.3878</cell><cell>0.5295</cell><cell>0.5000 0.5000</cell></row><row><cell>161</cell><cell>0.1321 0.4625 0.2000 0.3000 0.0839</cell><cell>0.1985</cell><cell>0.2800 0.2600</cell></row><row><cell>162</cell><cell>0.1621 0.5695 0.2000 0.3000 0.0702</cell><cell>0.2152</cell><cell>0.3333 0.3667</cell></row><row><cell>172</cell><cell>1.0000 1.0000 0.2000 0.1000 0.2000</cell><cell>0.2000</cell><cell>0.0400 0.0200</cell></row><row><cell>173</cell><cell>0.0890 0.3940 0.4000 0.4000 0.0329</cell><cell>0.1035</cell><cell>0.2375 0.1625</cell></row><row><cell>175</cell><cell>0.0120 0.1947 0.0000 0.0000 0.0523</cell><cell>0.1751</cell><cell>0.1666 0.1666</cell></row><row><cell>176</cell><cell>0.0000 0.0000 0.0000 0.0000 0.0000</cell><cell>0.0000</cell><cell>0.0000 0.0000</cell></row><row><cell>201</cell><cell>0.0990 0.3851 0.2000 0.1000 0.0893</cell><cell>0.2334</cell><cell>0.2000 0.1400</cell></row><row><cell>202</cell><cell>0.3711 0.6418 0.2000 0.1000 0.3711</cell><cell>0.6418</cell><cell>0.2000 0.1000</cell></row><row><cell>203</cell><cell>0.4052 0.6232 0.6000 0.4000 0.4052</cell><cell>0.6232</cell><cell>0.6000 0.4000</cell></row><row><cell>204</cell><cell>0.0000 0.0000 0.0000 0.0000 0.0000</cell><cell>0.0000</cell><cell>0.0000 0.0000</cell></row><row><cell>205</cell><cell>0.0060 0.1706 0.0000 0.0000 0.1145</cell><cell>0.1448</cell><cell>0.0800 0.1000</cell></row><row><cell>mean</cell><cell>0.2281 0.4232 0.2285 0.2142 0.1367</cell><cell>0.2349</cell><cell>0.2185 0.1844</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,202.86,214.97,209.63,100.90"><head>Table 2 :</head><label>2</label><figDesc>Performance Comparison</figDesc><table coords="5,202.86,230.49,209.63,85.37"><row><cell>Methods</cell><cell>MAP NDCG P@5 P@10 P@20</cell></row><row><cell cols="2">Query-Baseline 0.2216 0.3239 0.1922 0.1688 0.0929</cell></row><row><cell>Query-RF</cell><cell>0.1084 0.1908 0.1013 0.0000 0.1908</cell></row><row><cell cols="2">Query-PRF 0.1460 0.2300 0.1169 0.0935 0.0623</cell></row><row><cell cols="2">Session-Baseline 0.2283 0.4232 0.2286 0.2143 0.1619</cell></row><row><cell cols="2">Session-RF 0.2743 0.4251 0.4000 0.2714 0.2190</cell></row><row><cell cols="2">Session-PRF 0.0695 0.1549 0.1286 0.1071 0.0929</cell></row><row><cell cols="2">Session-LDA 0.1549 0.3005 0.1714 0.1786 0.1357</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="3,144.73,645.84,286.94,7.86;3,144.73,656.80,81.69,7.86"><p>http://clueweb.adaptcentre.ie/WebSearcher/search?query=queryString &amp;page=pagenumber</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,142.96,350.10,337.64,7.86;6,151.52,361.06,329.07,7.86;6,151.52,372.02,248.01,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,181.55,350.10,246.90,7.86">Dynamic personalized ranking of facets for exploratory search</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,447.41,350.10,33.18,7.86;6,151.52,361.06,329.07,7.86;6,151.52,372.02,120.49,7.86">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1379" to="1379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,382.25,337.64,7.86;6,151.52,393.21,329.07,7.86;6,151.52,404.17,154.89,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,352.61,382.25,127.98,7.86;6,151.52,393.21,232.87,7.86">Investigating exploratory search activities based on the stratagem level in digital libraries</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Carevic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lusky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Van Hoek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mayr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,393.61,393.21,86.99,7.86;6,151.52,404.17,77.80,7.86">International Journal on Digital Libraries</title>
		<imprint>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,414.41,337.64,7.86;6,151.52,425.37,329.07,7.86;6,151.52,436.33,58.87,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,288.67,414.41,191.92,7.86;6,151.52,425.37,91.73,7.86">A large-scale evaluation and analysis of personalized search strategies</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,264.05,425.37,185.97,7.86">International Conference on World Wide Web</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="581" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,446.56,337.64,7.86;6,151.52,457.52,200.75,7.86" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<title level="m" coord="6,323.91,446.56,156.68,7.86;6,151.52,457.52,30.76,7.86">Multiple Attribute Aware Personalized Ranking</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,467.76,337.64,7.86;6,151.52,478.72,232.82,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,310.96,467.76,169.63,7.86;6,151.52,478.72,65.07,7.86">Personalized ranking with pairwise factorization machines</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,225.03,478.72,62.67,7.86">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">214</biblScope>
			<biblScope unit="issue">C</biblScope>
			<biblScope unit="page" from="191" to="200" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,488.95,337.64,7.86;6,151.52,499.91,329.07,7.86;6,151.52,510.87,329.07,7.86;6,151.52,521.83,95.48,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,354.21,488.95,126.39,7.86;6,151.52,499.91,130.90,7.86">Predicting information seeking intentions from search behaviors</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitsui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">J</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,304.61,499.91,175.98,7.86;6,151.52,510.87,299.89,7.86">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1121" to="1124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,532.07,337.64,7.86;6,151.52,543.03,329.07,7.86;6,151.52,553.98,86.26,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,227.75,532.07,248.92,7.86">Automatic identification of user interest for personalized search</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,164.10,543.03,285.23,7.86">Proceedings of the 15th international conference on World Wide Web</title>
		<meeting>the 15th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="727" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,564.22,337.64,7.86;6,151.52,575.18,329.07,7.86;6,151.52,586.14,63.22,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,334.42,564.22,146.18,7.86;6,151.52,575.18,135.94,7.86">Personalizing search via automated analysis of interests and activities</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Teevan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,307.53,575.18,78.67,7.86">ACM SIGIR Forum</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="10" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,596.38,337.64,7.86;6,151.52,607.33,329.07,7.86;6,151.52,618.29,205.82,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,271.45,596.38,209.14,7.86;6,151.52,607.33,113.62,7.86">Building user groups based on a structural representation of user search sessions</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Van Hoek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Carevic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,283.62,607.33,196.97,7.86;6,151.52,618.29,75.44,7.86">International Conference on Theory and Practice of Digital Libraries</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="459" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.62,628.53,337.98,7.86;6,151.52,639.49,329.07,7.86;6,151.52,650.45,20.99,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,334.29,628.53,146.30,7.86;6,151.52,639.49,141.89,7.86">Session search modeling by partially observable markov decision process</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,303.14,639.49,120.52,7.86">Information Retrieval Journal</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="56" to="80" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
