<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,142.29,172.74,71.01,8.64"><forename type="first">Mostafa</forename><surname>Rahgouy</surname></persName>
							<email>mostafarahgouy@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Mohaghegh Ardabili</orgName>
								<address>
									<settlement>Ardabil</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,222.76,172.74,89.10,8.64"><forename type="first">Hamed</forename><forename type="middle">Babaei</forename><surname>Giglou</surname></persName>
							<email>hamedbabaeigiglou@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Mohaghegh Ardabili</orgName>
								<address>
									<settlement>Ardabil</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,321.30,172.74,60.80,8.64"><forename type="first">Taher</forename><surname>Rahgooy</surname></persName>
							<email>trahgooy@tulane.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Tulane University</orgName>
								<address>
									<settlement>New Orleans</settlement>
									<region>LA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,391.55,172.74,57.67,8.64"><forename type="first">Hasan</forename><surname>Zeynali</surname></persName>
							<email>hasanzeynalimc@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Mohaghegh Ardabili</orgName>
								<address>
									<settlement>Ardabil</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,249.97,184.69,51.73,8.64"><forename type="first">Salar</forename><surname>Khayat</surname></persName>
							<email>salarkhayatrasooli@gmail.com</email>
						</author>
						<author>
							<persName coords="1,304.19,184.69,56.73,8.64"><forename type="first">Mirza</forename><surname>Rasouli</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Mohaghegh Ardabili</orgName>
								<address>
									<settlement>Ardabil</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1E1B082EEB5FB5C4345346E25DFEB7FE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Author verification algorithms mainly rely on learning statistical fingerprints of authors. In the other hand, most of the previous algorithms in author masking try to apply changes to the original texts blindly without considering those finger-prints. In this paper, we propose an approach that learns author's finger-prints and uses them to apply directed transformations and distortions to the original text. We represent author finger-prints with different statistics such as word choice distribution, sentence length preference, etc. obtained from author's known texts. Automatic and manual evaluations of the obfuscated texts are very promising and show the effectiveness of our approach.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The author masking task of PAN 2018 is to paraphrase a given document so that authorship verification algorithms fail to detect it's author . The problem consist of a set of documents written by a specific author and another document of the same author named "original". The challenge is to use the information in the provided set of documents in order to obfuscate the "original" document.</p><p>Statistical properties of words, phrases, and sentences in documents play a pivotal role in identifying the author's style and finger-prints. For example average sentence length, text entropy, and word usage frequency alongside many other statistics is used by <ref type="bibr" coords="1,147.94,536.59,11.38,8.64" target="#b7">[8,</ref><ref type="bibr" coords="1,159.32,536.59,7.59,8.64" target="#b0">1,</ref><ref type="bibr" coords="1,166.91,536.59,7.59,8.64" target="#b1">2]</ref> to learn the author finger-prints either directly or indirectly. However, they apply their changes to the original texts irrespective of the author's style. As a result, some of those changes enforces the finger-prints of the author rather than diminish them.</p><p>Therefore, inspired by <ref type="bibr" coords="1,242.41,584.71,16.60,8.64" target="#b9">[10]</ref> work, we propose an approach that learns the author's finger-prints statistics(e.g. sentence length, word usage, etc.) from author's known documents and tries to distort those statistics in the target document using word replacement, combining/splitting sentences, and contraction transformation. In the rest of this paper, we explain the proposed approach and it's steps in Section 2, automatic and manual evaluations are covered in Section 3, and finally we summarize the paper findings in Section 4.</p><p>First, we learn the author's finger-prints by calculating several global statistics from documents written by the author (same-author documents). Next, we obfuscate the original text sentence by sentence considering the global statistics in the whole document and author's finger-prints. After splitting the text to sentences, we try to distort the text using word/phrase transformations, splitting and combining sentences, and word/phrase replacements in such a way that the resulting document has different statistics compared to the statistics obtained from other documents of the same author.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preprocessing</head><p>The first step in the proposed algorithm is to prepare the examples for obfuscation. In this step we split the original text to sentences using NLTK 3.0 Toolkit <ref type="bibr" coords="2,412.64,286.75,10.58,8.64" target="#b2">[3]</ref>. Next, using a pre-defined lexicon we split each sentence to phrase chunks and tokens. In other words, if we encounter a phrase from the lexicon we consider it as a chunk otherwise we use the tokens obtained from the tokenizer. The phrase lexicon is manually crafted from important phrases used in the same-author documents in the train-set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Author word usage distribution</head><p>Word choice and usage is one of the important components of every author's fingerprints. In order to capture this important component we use a maximum likelihood estimate of the word lemma frequencies in the same-author documents excluding stop words and auxiliary verbs. We denote the probability of choosing word w by P (w).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Word/Phrase Replacement</head><p>In this section we explain the process we used to replace words in the original document. Let d orig , d obf , w, and used be the original document, obfuscated document, current word, and list of words that already used for replacement respectively. We initialize the obfuscated document by the original document. Next, we iteratively choose words from the obfuscated document and perform replacements using Algorithm 1. As illustrated in Algorithm 1, we only consider adjectives, adverbs and verbs(excluding auxiliary verbs) for replacement. The replacement candidates are obtained from either WordNet <ref type="bibr" coords="2,457.63,555.15,11.62,8.64" target="#b4">[5]</ref> or Word2Vec <ref type="bibr" coords="2,177.30,567.11,15.27,8.64" target="#b10">[11]</ref>. Next, we choose the best scoring replacement from those that are less likely to be chosen by the author(have smaller P ) and also not used before. We score the appropriateness of a candidate replacement by averaging over three sub-scores:</p><p>1. Similarity to the original word: this score helps us to find meaningful replacements. This score obtained from WordNet or Word2Vec depending on the model that we evaluate. 2. Inverse of author's word usage probability: we want to use replacement that are less likely to be selected by the author.</p><p>3. Word mover's distance(WMD) <ref type="bibr" coords="3,276.90,118.92,14.65,8.96" target="#b8">[9]</ref>: The WMD distance measures the dissimilarity between two text documents as the minimum amount of distance that the embedded words of one document need to "travel" to reach the embedded words of another document. In other words the most efficient way to "move" the distribution of a document to the distribution of another document. Using WMD we can progressively measure the distance between the obfuscated document and the original document and choose a replacement that increases this measure. The ReplaceAll method used in the algorithm replaces all occurrences of word w in document d by replacement word r. This method returns a document with replacements and doesn't change the input document.</p><p>Algorithm 1: ReplaceWord (d obf , d orig , w, used) </p><formula xml:id="formula_0" coords="3,141.24,282.20,82.36,7.01">1 RE P L A C EWO R D(</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Contraction Transformation</head><p>We follow the method used in <ref type="bibr" coords="3,257.31,608.62,11.62,8.64" target="#b3">[4]</ref> to transform contractions to expanded form and vise versa. In order to perform these transformations we use the average preference of the author for using contractions in the same-author documents. If author prefers contractions then we try to convert them to expanded form in the obfuscated document and vise versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Sentence Length Alteration</head><p>According to <ref type="bibr" coords="4,190.90,139.27,10.58,8.64" target="#b7">[8]</ref>, sentence length is a deciding factor in authorship verification. As a result we consider it as a component of author's style and change the average sentence length of the obfuscated text based on preference of the author for sentence length in the same-author documents. If the author prefers short sentences, we try to combine consecutive sentences using and connector to increase the average length in the obfuscated text. In contrary, when author prefers long sentences, we search for connectors (e.g. words with CC POS-tag) in each long sentence and split it to two sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Evaluation</head><p>Author obfuscation task is evaluated by three performance dimensions. Accordingly, we call an obfuscation software <ref type="bibr" coords="4,263.31,278.81,10.79,8.64" target="#b5">[6]</ref>:</p><p>1. safe: if its obfuscated texts cannot be attributed to their original authors anymore 2. sound: if its obfuscated texts are textually entailed by their originals 3. sensible: if its obfuscated texts are well-formed and inconspicuous From these criteria only safety criterion is evaluated automatically and the other two are evaluated by human judgments. As discussed in Section 2.3 we rely on either WordNet or Word2Vec to find best replacements for words. Thus, we submitted two version of our algorithm for the task, one with Word-Net and another with Word2Vec. At the time of writing this paper the test results were not published. Therefore, in the following, we provide some examples and performance statistics of our proposed approach on training data using Word2Vec. The proposed algorithm and automatic evaluation are implemented in Python 3.6 and they are published on GitHub * .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example Original text Obfuscated text 1. Word replacement</head><p>For some people this is very devastating.</p><p>For some people this is extremely devastating.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Contraction</head><p>Whenever he speaks it is to say things like "Give me this" or "Ben wants that".</p><p>Whenever he speaks it's to believe things like "Give me this" or "Ben deserves that" 3. Expansion Don't patronise them, sir-pray, don't patronise them.</p><p>Do not patronise them , sir-pray , do not patronise them. 4. Sentence split Actually, the difficulty to draw lies rather in learning how to observe or being able to switch over to a particular way of seeing... Actually, the difficulty to draw lies rather in learning how to observe. being able to switch over to a particular way of seeing... Table <ref type="table" coords="4,261.62,595.52,3.36,8.06">1</ref>. Manually evaluated examples * https://github.com/Rahgooy/author_masking</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Manually Evaluated Examples</head><p>In this section we provide some manually evaluated examples. In the first example in Table <ref type="table" coords="5,158.72,149.33,4.98,8.64">1</ref> the adverb very is replaced by a very good alternative, extremely. As you can see in this example is is unchanged because it is an auxiliary verb. Second example shows a successful replacement of an expanded form it is with it's contraction it's for an author that prefers expanded forms over contractions. In addition, we have replacements for verbs say and wants with believe and deserves respectively. Conversely, in the third example, a contracted form phrase don't is converted to its expanded form do not due to the author preference for contractions.</p><p>The original text in the example 4 contains a long sentence from an author that prefers long sentences. We split this sentence by replacing conjunction word or with punctuation. It is clear that the resulting sentences are not complete and meaningful in this example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Automatic Evaluation</head><p>To evaluate our approach automatically, we trained a long-short term memory network (LSTM) <ref type="bibr" coords="5,170.79,326.91,11.62,8.64" target="#b6">[7]</ref> on the same author documents. We separated the texts in the same-author documents of each problem to train and evaluation sets.  We tested the model using the original document for each problem. The average verification score obtained by this model for original texts was 75.61%. The average score dropped dramatically to 51.71% when we applied the same model on the obfuscated data. Table <ref type="table" coords="6,180.72,155.18,4.98,8.64" target="#tab_1">2</ref> shows the results for 20 examples from the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper we proposed an algorithm for author masking task in PAN 2018. The proposed algorithms learns the author's finger-prints from known documents of the author. Next, it uses those statistics to apply calculated changes to the text in order to deform author's finger-prints in the obfuscated text effectively. Manual and automatic evaluation shows that our approach is very capable of diminishing author's finger-prints. In future works we try to add more components to the author's finger-prints and find clever ways to distort them in the obfuscated texts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,134.77,632.53,345.82,8.64;5,134.77,644.48,345.82,8.64;5,134.77,656.44,331.48,8.64"><head></head><label></label><figDesc>sampled fixed-length text from the documents and labeled them as positive examples.For negative examples we chose a number of documents from other problems randomly and generated approximately the same number of examples as number of positives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,137.76,280.95,334.17,246.42"><head></head><label></label><figDesc>d obf , d orig , w, used)</figDesc><table /><note coords="3,141.24,294.90,3.49,6.27;3,165.05,292.83,169.12,8.96;3,141.24,306.85,3.49,6.27;3,180.39,304.86,181.01,8.96;3,141.24,318.81,3.49,6.27;3,180.39,316.81,91.01,9.65;3,141.24,330.76,3.49,6.27;3,180.39,328.70,104.54,8.96;3,141.24,342.72,3.49,6.27;3,195.73,340.65,183.79,8.96;3,141.24,354.67,3.49,6.27;3,211.06,352.61,36.53,8.96;3,195.73,368.45,258.24,9.01;3,211.86,380.40,106.76,8.35;3,461.16,381.53,10.76,7.88;3,141.24,393.67,3.49,6.27;3,195.73,391.68,170.24,9.65;3,141.24,406.67,3.49,6.27;3,195.73,404.68,96.23,8.74;3,316.56,402.79,3.97,6.12;3,295.37,410.35,46.36,6.12;3,345.13,404.68,98.04,9.65;3,137.76,421.41,6.97,6.27;3,195.73,419.34,71.78,9.72;3,137.76,433.36,6.97,6.27;3,211.06,431.37,44.11,9.65;3,137.76,445.32,6.97,6.27;3,211.06,443.33,49.80,8.74;3,137.76,464.93,6.97,6.27;3,180.39,462.87,72.09,9.72;3,195.73,474.88,235.87,8.35;3,137.76,488.14,6.97,6.27;3,195.73,486.15,139.62,9.65;3,137.76,500.10,6.97,6.27;3,195.73,498.11,81.70,8.74;3,137.76,519.71,6.97,6.27;3,165.05,517.65,46.34,9.72"><p>2 if POS(w) in {ADJ, ADV, V ERB} then 3 (syns, similarities) ←GE TSY N O N Y M S (w) 4 (r, r score ) ← (null, 0) 5 for i ← 1 to len(syns) do 6 if syns[i] in used or P (w)≤ P (syns[i]) then 7 continue / * replace all w with syns[i] and put it in dtemp without changing d obf * / 8 d temp ← RE P L A C EAL L(d obf , w, syns[i]) 9 s ← (similarities[i] + 1 1+P(syns[i]) + WMD(d temp , d orig ))/3 10 if s &gt; r score then 11 r score ← s 12 r ← syns[i] 13 if r score &gt; 0 then // apply the best scoring replacement to d obf 14 d obf ← RE P L A C EAL L(d obf , w, r) 15 used ← used ∪ {r} 16 return d obf</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,167.12,338.87,313.46,280.39"><head>Table 2 .</head><label>2</label><figDesc>For training we randomly Automatic evaluation. Scores above 0.5 are identified as same author.</figDesc><table coords="5,205.85,371.49,203.66,236.91"><row><cell>Example</cell><cell cols="2">Original score Obfuscated score</cell></row><row><cell>Problem203.txt</cell><cell>0.82</cell><cell>0.33</cell></row><row><cell>Problem164.txt</cell><cell>0.46</cell><cell>0.18</cell></row><row><cell>Problem044.txt</cell><cell>0.66</cell><cell>0.60</cell></row><row><cell>Problem079.txt</cell><cell>0.51</cell><cell>0.44</cell></row><row><cell>Problem148.txt</cell><cell>0.97</cell><cell>0.89</cell></row><row><cell>Problem185.txt</cell><cell>0.55</cell><cell>0.48</cell></row><row><cell>Problem024.txt</cell><cell>0.36</cell><cell>0.19</cell></row><row><cell>Problem152.txt</cell><cell>0.70</cell><cell>0.74</cell></row><row><cell>Problem175.txt</cell><cell>0.98</cell><cell>0.60</cell></row><row><cell>Problem095.txt</cell><cell>0.58</cell><cell>0.54</cell></row><row><cell>Problem150.txt</cell><cell>0.96</cell><cell>0.68</cell></row><row><cell>Problem080.txt</cell><cell>0.48</cell><cell>0.48</cell></row><row><cell>Problem160.txt</cell><cell>0.99</cell><cell>0.57</cell></row><row><cell>Problem132.txt</cell><cell>0.50</cell><cell>0.41</cell></row><row><cell>Problem015.txt</cell><cell>0.54</cell><cell>0.50</cell></row><row><cell>Problem040.txt</cell><cell>041</cell><cell>0.45</cell></row><row><cell>Problem195.txt</cell><cell>0.61</cell><cell>0.53</cell></row><row><cell>Problem133.txt</cell><cell>0.86</cell><cell>0.85</cell></row><row><cell>Problem069.txt</cell><cell>0.85</cell><cell>0.88</cell></row><row><cell>Problem183.txt</cell><cell>0.65</cell><cell>0.35</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,142.61,338.14,319.31,7.77;6,150.95,349.10,122.05,7.77" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="6,196.78,338.14,238.82,7.77">Author identification using multi-headed recurrent neural networks</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bagnall</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.04891</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,142.61,360.06,310.69,7.77;6,150.95,371.02,313.92,7.77;6,150.95,381.98,72.48,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,374.25,360.06,79.06,7.77;6,150.95,371.02,138.04,7.77">An author verification approach based on differential features</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bartoli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dagri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>De Lorenzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Medvet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Tarlao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="6,306.84,371.02,136.97,7.77">CEUR WORKSHOP PROCEEDINGS</title>
		<imprint>
			<biblScope unit="volume">1391</biblScope>
			<date type="published" when="2015">2015</date>
			<publisher>CEUR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,392.94,336.34,7.77;6,150.95,403.90,213.27,7.77" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="6,257.69,392.94,221.26,7.77;6,150.95,403.90,97.40,7.77">Natural language processing with Python: analyzing text with the natural language toolkit</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>O&apos;Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,414.85,337.98,7.77;6,150.95,425.81,320.99,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,309.60,414.85,155.29,7.77">Author masking by sentence transformation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Castro-Castro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">O</forename><surname>Bueno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Muñoz</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="6,150.95,425.81,82.96,7.77">CLEF (Working Notes)</title>
		<title level="s" coord="6,239.89,425.81,107.26,7.77">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1866</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,436.77,299.34,7.77" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="6,202.26,436.77,149.87,7.77">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Bradford Books</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,447.73,325.27,7.77;6,150.95,458.69,289.60,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,277.48,447.73,190.39,7.77;6,150.95,458.69,92.41,7.77">Overview of the author obfuscation task at pan 2017: safety evaluation revisited</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,248.89,458.69,127.40,7.77">Working Notes Papers of the CLEF</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="33" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,469.65,310.36,7.77;6,150.95,480.61,66.49,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,267.53,469.65,87.80,7.77">Long short-term memory</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,362.08,469.65,71.47,7.77">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,491.57,311.46,7.77;6,150.95,502.53,243.35,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,393.56,491.57,60.51,7.77;6,150.95,502.53,114.79,7.77">Glad: Groningen lightweight authorship detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hürlimann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Weck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Suster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Nissim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,283.70,502.53,84.45,7.77">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,513.49,317.10,7.77;6,150.95,524.44,293.84,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,327.30,513.49,132.41,7.77;6,150.95,524.44,31.60,7.77">From word embeddings to document distances</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kolkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,200.51,524.44,167.22,7.77">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="957" to="966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.24,535.40,332.38,7.77;6,150.95,546.36,216.05,7.77" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="6,383.47,535.40,91.15,7.77;6,150.95,546.36,195.88,7.77">Author obfuscation using wordnet and language models-notebook for pan at clef</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mansoorizadeh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rahgooy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Aminiyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Eskandari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.24,557.32,338.35,7.77;6,150.95,568.28,188.91,7.77" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<title level="m" coord="6,314.42,557.32,166.17,7.77;6,150.95,568.28,42.98,7.77">Efficient estimation of word representations in vector space</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
