<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,137.63,115.90,340.10,12.90;1,191.44,133.83,232.48,12.90">Overview of the Author Obfuscation Task at PAN 2018: A New Approach to Measuring Safety</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,165.50,171.88,60.36,8.64"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
							<email>martin.potthast@uni-leipzig.de</email>
						</author>
						<author>
							<persName coords="1,234.69,171.88,66.19,8.64"><forename type="first">Felix</forename><surname>Schremmer</surname></persName>
							<email>felix.schremmer@uni-bonn.de</email>
						</author>
						<author>
							<persName coords="1,310.67,171.88,61.10,8.64"><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
						</author>
						<author>
							<persName coords="1,400.87,171.88,48.99,8.64"><forename type="first">Benno</forename><surname>Stein</surname></persName>
							<email>benno.stein@uni-weimar.de</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Leipzig University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Bonn</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Martin-Luther-Universität Halle-Wittenberg</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Bauhaus-Universität Weimar</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,137.63,115.90,340.10,12.90;1,191.44,133.83,232.48,12.90">Overview of the Author Obfuscation Task at PAN 2018: A New Approach to Measuring Safety</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E86494FB6144C0A89CC252A53A251028</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we evaluate seven author obfuscation approaches which are supposed to automatically mask an author's writing style in a given text to render automatic author identification impossible. The approaches are evaluated with regard to their safety, soundness, and sensibleness in terms of beating 44 author identification approaches, retaining the original meaning of the obfuscated text, and producing inconspicuous, human-readable obfuscations, respectively. Regarding the measurement of safety in particular, we introduce a set of new performance measures which are designed to render the performance of obfuscation approaches comparable as the numbers of author identification approaches and evaluation datasets increases, incorporating their respective performance and quality. Based on the new measures, we establish a world ranking of obfuscators.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Author obfuscation is the adversary task to author identification. The goal of obfuscation is to render the identification of authors based on their writing style impossible or at least intractable. Consequently, an effective identification approach has to be robust against obfuscation, or else it cannot be trusted. The fundamental question underlying both tasks is whether writing style can be purposefully manipulated. We hypothesize that this is indeed the case, and that style manipulations sufficient to counter identification can be accomplished in a way indistinguishable from genuine writing. Our goal is to foster the development of new technology in this respect, and its evaluation.</p><p>We consider three performance dimensions according to which an author obfuscation approach must excel to be considered fit for practical use. Obviously, the obfuscation performance should depend on the capability of fooling forensic experts-be it a piece of software or a human. However, fulfilling this requirement in isolation will disregard writers and their target audience, whose primary goal is to communicate, albeit safe from deanonymization: the quality of an obfuscated text along with the fact that its semantics is preserved are equally important to fool authorship identification. We hence call an obfuscation software 1. safe, if its obfuscated texts cannot be attributed to their original authors anymore, 2. sound, if its obfuscated texts are paraphrases of their originals, and 3. sensible, if its obfuscated texts are well-formed and inconspicuous. These dimensions are orthogonal; an obfuscation software may meet each of them to a certain degree of perfection. Related work on operationalizing different measures for these dimensions has been included in our recent overview <ref type="bibr" coords="2,373.71,195.23,15.27,8.64" target="#b19">[20]</ref>. In particular, for lack of suitable alternatives, we developed our own evaluation measures for the safety dimension, which were employed to evaluate five author obfuscation approaches in the past. In this paper, we build on this experience and redesign our suite of safety measures from the ground up in an attempt to rectify issues with the existing ones. For example, the new measures incorporate the notion of "case difficulty" of author identification cases, the a priori quality of identification approaches, and they prevent some forms of cheating.</p><p>We directly employ the new performance measures to evaluate the safety of seven author obfuscation approaches against 44 author identification approaches. This includes two obfuscation approaches submitted to our this year's shared task on author obfuscation at PAN 2018, as well as five that have been submitted to the two corresponding shared tasks in the past two years <ref type="bibr" coords="2,313.61,338.69,15.77,8.64" target="#b9">[10,</ref><ref type="bibr" coords="2,332.45,338.69,11.83,8.64" target="#b19">20]</ref>. The 44 authorship identification approaches have been obtained from the shared tasks on authorship verification-a specific variant of author identification where a pair of texts is checked for common authorship-organized at PAN 2013-2015 <ref type="bibr" coords="2,309.86,374.56,15.77,8.64" target="#b13">[14,</ref><ref type="bibr" coords="2,328.88,374.56,12.45,8.64" target="#b22">23,</ref><ref type="bibr" coords="2,344.58,374.56,11.83,8.64" target="#b21">22]</ref>. As for the evaluation of sensibleness and soundness, we stick to manual inspection and grading of examples as before.</p><p>In what follows, Section 2 introduces the new safety performance measures for author obfuscation, Section 3 reviews the two obfuscation approaches submitted this year, and Section 4 evaluates their performance in comparison to the five previously submitted ones. More detailed analyses of the new performance measure is found in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Towards a World Ranking for Author Obfuscators</head><p>We propose a formal model to implement a kind of "obfuscator world ranking" in order to ease the comparison of new approaches to the state of the art in this growing field. The central building block regarding the safety dimension is a set of effective authorship verification algorithms, also called authorship verifiers for short. Authorship verification is about deciding whether or not a document has been written by a certain author, given one or multiple texts that are known to be written by this author (a one-class classification problem). Then, given a set of authorship verifiers and a corpus of verification problems, a to-be-evaluated obfuscator is run on the positive problems (those problems where the correct answer is "same author"), and it is checked whether for the obfuscated texts the verifier decisions' are "different authors".</p><p>Thanks to the organizers and participants of the PAN 13, PAN 14, and PAN 15 shared tasks in authorship verification, 44 working authorship verifiers are at our disposal for empirical analysis. For each combination of a positive verification problem Table <ref type="table" coords="3,158.97,115.83,3.36,8.06">1</ref>. Performance matrix for a single obfuscator o given a number of positive verification problems p1, p2, . . . and a number of authorship verifiers av1, av2, . . . A table entry at position (i, j) encodes the following information: "T → _" (F → _) indicates for authorship verifier avj a true positive (false negative) decision on the i-th positive verification problem pi. Likewise, _→ F indicates for the obfuscator in question that it could "force" the authorship verifier avj to return a wrong decision (= different authors) on pi.</p><p>Obfuscator o av1 av2 av3 . . .</p><formula xml:id="formula_0" coords="3,203.44,213.41,204.22,47.51">p1 T → T T → F F → F p2 F → T F → F T → F . . . p3 T → T F → F T → T . . . . . .</formula><p>and a verifier, we can check how a verifier decides before and after applying the tobe-evaluated obfuscator, obtaining a performance matrix as given in Table <ref type="table" coords="3,434.96,303.22,3.74,8.64">1</ref>. An entry of the form T → F indicates that the obfuscator o successfully fooled the authorship verifier associated to this column on the verification problem in the respective line. Each successful entry in the performance matrix should increase the overall safety score of the respective obfuscator, while entries of the form F → T should decrease the score. The exact influence on the final score depends on the set of verifiers used and the "difficulty" of the problem instance (e.g., how many verifiers can identify the authorship before obfuscation).</p><p>Actually, Table <ref type="table" coords="3,215.69,398.86,4.98,8.64">1</ref> shows a simplified view of the real situation since an authorship verifier typically returns confidence scores instead of a plain binary decision. A confidence score in [0, 0.5) indicates a (gradually) negative answer (= different authors) whereas a confidence score in (0.5, 1] indicates a (gradually) positive answer. In practice, however, a sensible interpretation of the confidence scores requires a verifierspecific approach-or the computation of standard normally-distributed confidence scores. Here we will choose an individual confidence threshold for each verifier, optimizing its accuracy on the original instances from the verification task. The same threshold will then be used for the decisions on the obfuscated instances.</p><p>As for safety evaluation, in previous years we assumed that the used verifiers are deterministic in the sense that they always report the same answer for the same problem, regardless of the history of other problems they have seen. Note that the particular design of the testing scenario used at PAN (all test cases are provided at once) allows a verifier to consider all test documents when classifying an individual problem. E.g., a verifier could exploit global assumptions such as information about the ratio of positive versus negative problems in a setup. In such cases the entries of the performance matrices (see Table <ref type="table" coords="3,213.58,590.15,4.15,8.64">1</ref>) may change every time the verifier is run on another sequence of problem instances.</p><p>It should be noted that the verifiers that participated in the PAN verification tasks are obfuscation-unaware, i.e., they assume that no obfuscation has been applied and thus take no measures to revert or reduce potential obfuscation effects. In the terminology of Potthast et al. <ref type="bibr" coords="3,202.35,649.92,15.27,8.64" target="#b19">[20]</ref>, the verifiers perform automated authorship identification, as op-posed to de-obfuscation attacks. Being obfuscation-unaware is not necessary for safety evaluation; however, in the long run, obfuscation technology should aim to defeat both automated authorship identification and de-obfuscation attempts.</p><p>In the following we present three axioms that should be fulfilled by a measure that quantifies the obfuscation safety of an obfuscation algorithm.</p><p>1. Fooling an effective verifier should be scored higher than fooling a less effective one, where effectiveness may be measured as the verifier's true positive rate.</p><p>2. Fooling a verifier on an unambiguous problem should be scored higher than fooling it on an ambiguous one. Here, a problem is unambiguous if it is decided correctly by many verifiers.</p><p>3. Fooling two dissimilar verifiers from a set of equally effective verifiers should be scored higher than fooling two similar verifiers from this set. Here, two verifiers are called similar if they often come to the same decision.</p><p>Axiom 1 relates to the verifier effectiveness, Axiom 2 relates to the problem unambiguity, and Axiom 3 relates to the verifier-problem coverage.</p><p>The first and third criterion together should help to prevent the creators of obfuscation algorithms from "boosting" their score by submitting many variations of a particular verifier which is especially vulnerable to their obfuscation approach (or, similarly, by submitting variants of approaches that would lower the scores of other obfuscators). The second criterion puts emphasis on those problems for which many of the state-ofthe-art verification approaches perform well-in a nutshell: unambiguous implies "easy for attribution, difficult for obfuscation".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Definition of the New Safety Measure</head><p>For a formal treatment of authorship verification and obfuscation, we adopt the terminology outlined in <ref type="bibr" coords="4,208.75,458.02,15.27,8.64" target="#b19">[20]</ref>. Generally, an authorship problem is a tuple d u , D A consisting of one document of unknown authorship d u and a set of documents D A such that each document has a known author in the set A of authors. If A consists of a single author a, we call it authorship verification problem. We denote by γ( d u , D A ) ∈ A ∪ {∅} the true author of d u , if he/she is in A, and otherwise ∅.</p><p>Let D be the set of all authorship problems. An authorship analysis approach v is a computable function v( d u , D A ) ∈ A ∪ {∅} which is an approximation for γ. v has been trained on a subset of D, the training set, on which γ is known. v is evaluated using a test set D test ⊂ D, which is disjoint from the training set. In the specific case of authorship verification, we let D + test ⊂ D test be the subset of verification problems d u , D a where γ( d u , D a ) = a.</p><p>An obfuscator o is a mapping o( d u , D a ) = d u , D a which obfuscates the text d u of the author a, possibly using the other available files for that author D a . The aim of the obfuscation is to change the result of verifiers to ∅.</p><p>With the basic terminology at hand, we turn to the construction of the new measure: Let V be the set of verifiers under consideration. For v ∈ V and d ∈ D test , let c(v, d) = 1 indicate that v outputs the correct answer to the problem d (whether it is "same author" or "different authors") and let c(v, d) = 0 indicate a wrong answer. The accuracy and effectiveness of a verifier v ∈ V on the problem set D test are defined as follows:</p><formula xml:id="formula_1" coords="5,183.69,157.95,247.97,48.17">accuracy(v, D test ) = d∈Dtest c(v, d) |D test | , effectiveness(v, D test ) = max(0, 2 • accuracy(v, D test ) -1).</formula><p>These definitions work best with a balanced problem set D test , where the set of positive problems D + test and that of negative problems D test \D + test have approximately the same size. In a balanced situation, a verifier with effectiveness 0 does no better than guessing, whereas a verifier with effectiveness 1 is always correct.</p><p>To measure the similarity between two verifiers v, w ∈ V , we do not directly compare their answers but focus on the errors they make and assume that two verifiers are similar if they tend to make the same errors. We compute the Pearson correlation coefficient between the corresponding error-vectors c(v, •) and c(w, •):</p><formula xml:id="formula_2" coords="5,176.48,316.03,257.94,29.48">ρ(v, w) = d∈Dtest (c(v, d) -v)(c(w, d) -w) d∈Dtest (c(v, d) -v) 2 d∈Dtest (c(w, d) -w) 2</formula><p>, where v = accuracy(v) and w = accuracy(w).</p><p>There are edge cases with vanishing denominators: In case that c(v, d) = 0 for all d ∈ D test or c(v, d) = 1 for all d ∈ D test (similarly for w), the above expression is undefined and we set ρ(v, w) := 0 if v = w and ρ(v, v) = 1. Note that such verifiers have not been observed in practice yet-it would imply the existence of a perfect verifier for that particular set of problems. But in cases where test is small, it could easily happen-however, such small scenarios are not our aim.</p><p>For each verifier v ∈ V , we define its coverage as a real number in (0, 1] with the following intuition: If the verifier is unique of its kind (correlation with other verifiers near zero), the coverage should be 1. If there are k &gt; 0 other verifiers which give answers almost equal to v, the coverage of v and its k related verifiers should be ≈ 1 k+1 , such that these "redundant" verifiers together via their coverage scores will contribute as much to an obfuscator's performance as one verifier which is unique of its kind will. This motivates the following definition, where τ ∈ [0, 1] is a fixed constant:</p><formula xml:id="formula_3" coords="5,134.77,528.01,253.32,67.22">coverage(v) =     w∈V : ρ(v,w)≥τ ρ(v, w)     -1 . Since ρ(v, v) = 1, the coverage is always in (0, 1].</formula><p>Choosing a larger value for τ diminishes the influence of many small correlations in contrast to a few bigger ones. We pick τ = 0.5 to capture all real similarities while reducing the noise of correlations which are rather coincidences on a finite set of test instances. For each verifier v ∈ V , we then define its importance as</p><formula xml:id="formula_4" coords="5,207.25,652.53,200.86,8.74">importance(v) = effectiveness(v) • coverage(v).</formula><p>We now quantify the unambiguity of a problem d ∈ D + test as a weighted average of the verifiers giving the correct answer to d:</p><formula xml:id="formula_5" coords="6,202.31,151.54,206.77,25.38">unambiguity(d) = v∈V c(v, d) • importance(v) v∈V importance(v)</formula><p>.</p><p>With the above definitions, we can now define our measure of obfuscator safety. Thinking in terms of the performance matrix from Table <ref type="table" coords="6,361.79,199.28,3.74,8.64">1</ref>, an entry of the form T → F (i.e., successful obfuscation), corresponding to a verifier v ∈ V and a problem d ∈ D test , gives points equal to</p><formula xml:id="formula_6" coords="6,237.93,244.79,139.50,8.74">importance(v) • unambiguity(d).</formula><p>For entries of the form F → T, the same amount describes the number of points subtracted for a counter-productive obfuscation attempt. The world ranking score of the obfuscator o is the sum of the points awarded or subtracted for each combination of verifier and verification problem.</p><p>To put it differently, recall that o(d) denotes the obfuscated problem for d ∈ D + test , where the texts of known authorship are unchanged but the text of unknown authorship is obfuscated. Denote by c(v, o(d)) the answer of the verifier v ∈ V to the obfuscated problem (i.e., 1 if v correctly reports "same author" and 0 if not). Then the world ranking score of the obfuscator o equals</p><formula xml:id="formula_7" coords="6,168.68,385.92,277.99,23.24">d∈D + test v∈V (c(v, d) -c(v, o(d))) • importance(d) • unambiguity(d).</formula><p>The measure is named world ranking score since it allows to incorporate all available verifiers and verification problem corpora to produce a single numerical value evaluating the obfuscator's safety with respect to the given verifiers and verification problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Theoretical Discussion of Fairness Properties</head><p>We give the following a-priori arguments why we hypothesize that the world ranking score satisfies the three fairness axioms.</p><p>To the first axiom: We decided to quantify effectiveness using accuracy. An ineffective verifier will only obtain a small effectiveness score, such that the influence of its decision changes on the final score are not as high as the influence of an effective verifier. Moreover, it is reasonable to assume that an effective and an ineffective verifier will have small correlation, such that adding ineffective verifiers will not change the importance scores of the effective verifiers nor the unambiguity scores of the problems. Therefore, an ineffective verifier has only little influence on the final world ranking score of an obfuscator.</p><p>An ambiguous problem should get a small unambiguity score, such that the overall influence of its obfuscated version on an obfuscator's world ranking score should be small. Adding ambiguous problems will, in general, reduce the effectiveness scores and increase the coverage scores, as most verifiers will effectively guess their answer.</p><p>However, this should uniformly affect all verifiers and all obfuscators, such that the world ranking scores with respect to a fixed corpus are comparable.</p><p>Adding a variant v of an existing verifier v ∈ V will not change the effectiveness score of any existing verifier and not change the coverage scores of verifiers w ∈ V which are not similar to v. This will likely leave both the problem unambiguity scores and the overall obfuscator world ranking scores mostly unchanged, or at least affect them in a way that preserves the general proportions (i.e., the most unambiguous problems should remain the most unambiguous ones, even though their actual ambiguity scores may change).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Criticism and Shortcomings of the Impact Measure</head><p>Recall the definitions of recall and accuracy of a verifier v ∈ V :</p><formula xml:id="formula_8" coords="7,183.49,280.32,244.42,62.43">acc(v, D test ) = |{d ∈ D test : v(d) = γ(d)}| |D test | , rec(v, D test ) = acc(v, D + test ) = |{d ∈ D + test : v(d) = γ(d)}| |D + test |</formula><p>.</p><p>The performance of an obfuscator can therefore be measured by the change of recall:</p><formula xml:id="formula_9" coords="7,134.77,370.72,298.03,82.96">∆ rec (o, v, D test ) = rec(v, o(D test )) -rec(v, D test ). The impact of o is ∆ rec normalized to [-1, 1]: imp(o, v, D test ) =    -∆rec(o,v,Dtest) rec(v,Dtest) if ∆ rec (o, v, D test ) &lt; 0, -∆rec(o,v,Dtest) 1-rec(v,Dtest)</formula><p>otherwise,</p><p>.</p><p>If V denotes the set of available verifiers, the average impact of an obfuscator o is</p><formula xml:id="formula_10" coords="7,208.71,486.19,197.93,26.80">avg imp(o, V, D test ) = 1 |V | v∈V imp(o, v, D test ).</formula><p>The average impact is the measure used for the obfuscation shared tasks in PAN 16 and PAN 17 to automatically evaluate an obfuscator's safety. This measure does not satisfy the earlier defined fairness criteria: We will later see that the performance of the verifiers used here differ enormously. For an obfuscator o and a verifier v such that obfuscation by o decreases the recall of v (which is usually the case), the impact is, by definition,</p><formula xml:id="formula_11" coords="7,157.13,600.18,299.90,63.06">imp(o, v, D test ) = rec(v, D test ) -rec(v, o(D test )) rec(v, D test ) = 1 - rec(v, o(D test )) rec(v, D test ) =1 - {d ∈ D + test | v(o(d)) = γ(d)} {d ∈ D + test | v(d) = γ(d)} .</formula><p>If, e.g., o flips half of the correct decisions of v and leaves the wrong decisions as they were, the impact factor is 1  2 . Achieving an impact factor of ≥ 1 2 is therefore easier for weak verifiers (change few decisions of an ineffective verifier) than for more effective ones (change many decisions of an effective verifier). This is counter-intuitive and directly contradicts our first fairness principle above (the verifier effectiveness axiom). Of course, one has to be careful when using only recall (and not precision) to describe "effective verifiers", but a high recall is not a good indicator for ineffective verifiers.</p><p>Moreover, there are examples of similar verifiers: Jankowska et al. submitted a verifier in 2013 <ref type="bibr" coords="8,188.65,214.95,15.27,8.64" target="#b11">[12]</ref>, and an improved variation of it in 2014 <ref type="bibr" coords="8,376.59,214.95,15.27,8.64" target="#b12">[13]</ref>. These are treated as independent verifiers, such that the influence of that single approach in the final impact score is inappropriately high. This is not so much of a problem for the set of verifiers available at the time of writing (there are few such examples), but opens the door for simple manipulation of certain obfuscators' scores by re-submitting a verifier multiple times, possibly in slight variations. However, submission of variations of already present verifiers need not be an attempt of score manipulation, it could simply be an improvement of previous work (e.g. incorporating more features, or a different machine learning algorithm). Therefore it is not fair to disallow submissions of such variants (since we want to reflect the state of the art), nor can it be fair to consider them as entirely independent of one or more related verifiers when averaging the scores. When using the average impact measure, however, one has to decide for one of these options.</p><p>Finally, we will present evidence that there are very ambiguous as well as very unambiguous problems in the test corpora, an important distinction not reflected by the average impact measure. The idea is that fooling a certain verifier in an unambiguous problem is supposed to be more difficult than fooling it in an ambiguous one, so that success in the more difficult task should get a better reward than success in the easier one. However, one could make the non-trivial, yet reasonable assumption that each obfuscator which successfully (against a particular verifier) obfuscates problems up to some degree of unambiguity will also successfully (against the same verifier) obfuscate more ambiguous problems. Under this assumption, it is not necessary unfair to simply count the number of flipped decisions independent of each problem's ambiguity (though it also would not be unfair to take the ambiguity into account). This assumption can, however, be questioned, e.g. by pointing out that there are random effects involved such that an obfuscator may by chance fail to fool a verifier in some ambiguous problems although the obfuscation is successful in some more unambiguous cases. It is therefore desirable to have a measure whose fairness can be justified without relying on this or a similar assumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Survey of Submitted Obfuscation Approaches</head><p>The two approaches submitted to this year's edition of our shared task are of a more rule-based flavor, but with different aggressiveness. The rather conservative rule-based replacements of Kocher and Savoy's approach <ref type="bibr" coords="8,319.70,617.44,16.60,8.64" target="#b15">[16]</ref> aim for sensible and sound obfuscations, while the more aggressive strategy of Rahgouy et al.'s approach <ref type="bibr" coords="8,412.12,629.40,16.60,8.64" target="#b20">[21]</ref>   Kocher and Savoy The approach of Kocher and Savoy <ref type="bibr" coords="9,351.92,233.83,16.60,8.64" target="#b15">[16]</ref> is based on a set of 20 rules.</p><p>The rules replace contractions (e.g., 'll → will) or shorten words to contracted forms, replace adjectives (e.g., very good→excellent), exchange conjunctive terms (e.g., in fact→ actually), or introduce spelling errors by repeating a repeated letter.</p><p>As for the resulting texts, the rather conservative strategy does not change a lot and aims to keep the original text quality. A rather problematic issue of the approach is that it seems as if the sentences in the obfuscated text were re-ordered (the whole second paragraph is often directly inserted after the first sentence while the second sentence comes rather late). It is unclear how reordering a text changes its style, so that this issue might be due to some implementation error, and is the main cause for the rather sub-optimal scores for soundness. A more detailed analysis of the text quality of this approach follows in the evaluation (cf. Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rahgouy et al.</head><p>The approach of Rahgouy et al. <ref type="bibr" coords="9,332.00,389.25,16.60,8.64" target="#b20">[21]</ref> mainly focuses on changing the signals of sentence length (splitting at conjunctive terms or combining sentences), usage of contractions (either contracting two words or extending contractions), and word usage in general (replacement candidates from WordNet or a word2vec model), where a potential replacement term is scored based on the similarity to the original word, the likelihood of seeing it in the author's documents, and the word mover distance of the sentence variant.</p><p>The resulting text will usually be changed more than with Kocher and Savoy's approach. Depending on the word similarities and the "correctness" of splitting / combining sentences, some obfuscated text passages read very well while others are changed to often even a contrary meaning. Again, the text quality of this approach is discussed in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>As in the past two years, we automatically evaluate the safety of the submitted obfuscation approaches against 44 authorship verifiers that participated in the previous three shared tasks on authorship identification at PAN 2013-2015. We employ the new scoring scheme to obtain the first "world ranking" for obfuscation and contrast it with the previous way of evaluating safety. Sensibleness and soundness of the obfuscated texts are assessed manually via human inspection in the same way as before. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Safety</head><p>The evaluation setup is based on the cloud-based evaluation platform TIRA <ref type="bibr" coords="10,446.74,302.67,10.79,8.64" target="#b8">[9,</ref><ref type="bibr" coords="10,460.83,302.67,11.83,8.64" target="#b18">19]</ref>, <ref type="foot" coords="10,476.61,301.01,3.49,6.05" target="#foot_0">1</ref>which is being developed as part of our long-term evaluation-as-a-service initiative <ref type="bibr" coords="10,461.50,314.63,15.27,8.64" target="#b10">[11]</ref>. By using TIRA, it is possible to run 44 of the 49 authorship verification approaches which have been submitted to the shared tasks at PAN 2013-2015 on the outputs of the 7 obfuscation approaches submitted to the shared tasks at PAN 2016-2018 using the authorship verification corpora PAN13, PAN14 EE, PAN14 EN, and PAN15 (cf. Table <ref type="table" coords="10,159.14,374.41,4.98,8.64" target="#tab_1">2</ref> for respective corpus characteristics). Table <ref type="table" coords="10,174.37,386.36,4.98,8.64" target="#tab_2">3</ref> contrasts our new "world ranking" scheme described in Section 2 with the "legacy" safety measure we employed in the previous two years. It can be seen that the ranking of the approaches does not change from one measure to the other with Castro et al.'s approach <ref type="bibr" coords="10,230.43,422.23,11.62,8.64" target="#b5">[6]</ref> being the safest on both measures. Although the ranking of the so far seven submitted approaches does not change, the new measure seems a lot fairer since an obfuscator cannot simply gain a lot of average impact by fooling a few rather bad verifiers to each change one of their maybe only two correct "same author" decisions (impact of 0.5). Moreover, the point difference between of the world ranking provides for an intuitive idea of "how far" one obfuscator is ahead of another. Thus we will further employ the new "point-based" world ranking for safety evaluation since it takes the strengths (and weaknesses) of the participating verifiers and corpora into account.</p><p>Interestingly, the two obfuscator approaches from this year's shared task (green entries in Table <ref type="table" coords="10,193.33,541.78,4.15,8.64" target="#tab_2">3</ref>) are not able to break into the top-3 safety ranks overall. But their characteristic is also a less aggressive obfuscation with sometimes no changes in a sentence, so that the resulting text quality is not changed too much from the original (cf. next section for the respective evaluation of sensibleness and soundness). It should also be noted that even the "safest" of the approaches submitted so far still leaves a lot of room for safety improvements alone. The perfect obfuscator (i.e., the one that would be able to change every correct "same author" decision of each of the 44 verifiers in the evaluation) would obtain a world ranking score of 1093.49-thus Castro et al.'s best approach so far has not even made "half the way" to perfect obfuscation. A more fine-grained analysis of the old and new safety scores per corpus can be found in Appendix B while Appendix A gives some more experimental details on the robustness of the new world ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sensibleness and Soundness</head><p>As in the previous two shared task, a human assessor conducted a manual assessment on problem instances 6, 135, and 430. Spot checks on other instances indicated that the overall characteristics of the output texts are similar on other instances. The human assessor started by reading the obfuscated texts without knowing which was the output of what approach. During this reading phase, the assessor marked up errors (typos, grammar) and assigned school grades (on a scale from 1 (excellent) to 5 (fail)) for the sensibleness of each of the sample problem instances. The sensibleness scores obtained in the previous years were a <ref type="bibr" coords="11,246.77,276.72,22.13,8.64">grade</ref>   <ref type="bibr" coords="11,414.01,300.63,15.27,8.64" target="#b14">[15]</ref>. Kocher and Savoy's approach <ref type="bibr" coords="11,206.52,312.59,16.60,8.64" target="#b15">[16]</ref> approach obtains a grade 1-2, since there are hardly any changes, though spurious uppercase letters occurred in the middle of a sentence (probably due to some suboptimal "stitching" of text passages). Rahgouy et al.'s approach <ref type="bibr" coords="11,446.32,336.50,16.60,8.64" target="#b20">[21]</ref> had a much wider range with one text rather left intact and obtaining grade 1, while for another a grade 4 was assigned due to a lot of punctuation problems; on average, with the additional grade 3 on the third text, grade 3 overall is assigned.</p><p>After grading the sensibleness of the obfuscated texts, the assessor read the original texts and judged the textual differences in various ways to evaluate the soundness of the obfuscated texts on a three-point scale as either "correct", "passable", or "incorrect". The obfuscated texts of Mihaylova et al.'s, Keswani et al.'s, Bakhteev's and Khazov's, and Castro et al.'s previous years' approaches were all judged "incorrect", while Mansoorizadeh et al.'s very conservative approach from 2016 achieved "correct" and "passable" scores. This year's approaches (Kocher and Savoy's and Rahgouy et al.'s) both got "passable" as their average judgments-but for different reasons: With regard to Kocher and Savoy's approach, almost everything was left as it was with the main problem that the ordering of the sentences was changed which in some passages caused a rather odd reading "flow" resulting in a "'passable" for all three checked texts. With regard to Rahgouy et al.'s approach, the judgments are again more wide-spread with one text being "incorrect" since almost all sentences were wrongly split into parts, one document being "passable" and one being "correct" since hardly anything was changed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Outlook</head><p>In the third year of evaluating author obfuscation approaches in terms of their safety against the state of the art in authorship verification, two new approaches were added to the five approaches from the previous years. The best-performing obfuscator today achieves about 43% of the score a "perfect" obfuscator can achieve on our testbed with 44 authorship verifiers on the PAN authorship verification corpora from 2013-2015. Such a perfect obfuscator would be able to flip any correct decision for "same author" by any verifier towards choosing "different author".</p><p>We have developed a new "world ranking of obfuscators" in terms of safety. The idea is that an obfuscator obtains points per flipped correct "same author" decision, dependent on how unambiguous a problem is (i.e., the more unambiguous the more verifiers solve it correctly before obfuscation) and on the effectiveness of a verifier on unobfuscated problems (more points if a more effective verifier is fooled). This new safety measure is fairer than the previous impact measure, where scores were computed independent of a problem's unambiguity and a verifier's effectiveness.</p><p>Still, even with the new scoring scheme, the actual safety ranking does not change but the relative differences between the verifiers are more pronounced in the sense that they now include information about the actual problem unambiguity. The safety-wise best-performing approach of Castro et al. from 2017 was not beaten by the two new obfuscators, whose main focus seems to rather be text quality (i.e., soundness and sensibleness). As in the previous years, text quality was measured by manual inspection. It became clear that sometimes even small changes can "destroy" a particular sentence or text passage (distorting its meaning or decreasing readability). Unsurprisingly, the least safe approach of Kocher and Savoy from this year's shared task obtains the best scores among all approaches with respect to soundness and sensibleness-it simply does not change a lot. While still being readable, the obfuscated texts of the safest approach <ref type="bibr" coords="12,134.77,358.42,54.51,8.64">(Castro et al.)</ref> are rather poor when it comes to soundness.</p><p>It is still an open problem to develop obfuscation technology that is safe (even the best one is not half the way to a perfect obfuscation safety) while not harming paraphrase soundness or readability too much. Paradigmatically, there are still more or less only two groups of obfuscation approaches: (1) the ones that are somewhat safe but that produce rather unreadable text or text that is neither sound nor sensible, and (2) the ones that produce sound and sensible texts but that are not really safe against authorship verification.</p><p>As hinted in the previous shared task editions, a significant improvement of current obfuscation technology might require a much better consideration and integration of the surrounding context when, for example, replacing, adding, or removing words, and better ways of reordering clauses in sentences. Ideas in that direction could be to apply constrained paraphrasing <ref type="bibr" coords="12,237.13,501.88,16.60,8.64" target="#b23">[24]</ref> or paraphrasing rules from the PPDB <ref type="bibr" coords="12,406.74,501.88,10.58,8.64" target="#b7">[8]</ref>.</p><p>The remaining challenge of evaluating author obfuscation approaches properly and at scale does not seem to be safety. The new "world ranking" provides for a fair and robust tool that incorporates future verifiers, obfuscators, and corpora. What is missing are new and improved technologies for recognizing paraphrases, textual entailment, grammaticality, and style deception-the existing technology is not mature enough to easily replace manual inspection for evaluating soundness and sensibleness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Robustness of the World Ranking</head><p>We empirically test whether the parameters underlying the new world ranking are distributed as expected and how robust the new world ranking is against the addition of "random" verifiers or verifiers that are very similar to already existing ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Variation of the Measures Underlying the World Ranking</head><p>First, to ensure that the considerations underlying our new safety evaluation approach make sense in the given setup, we confirm that the main verifier and problem characteristics of effectiveness, coverage, and unambiguity vary sufficiently among the considered verifiers and datasets. We confirmed our findings on all PAN verification datasets but only give plots and explanations on the basis of the PAN 15 data since the observations on the other datasets are similar.  Note that some verifiers perform so poorly on the test data that our "best threshold" method chooses a threshold of +∞ or -∞, forcing them to always respond "different authors" or "same author", respectively. This behavior is mainly due to employing verification models that were trained on a different PAN corpus that are now tested on PAN 15 data (we did not re-train models that were submitted in another year), leading to multiple verifiers giving identical answers, which in turn then have very low coverage scores (between 0.11 and 0.123, with accuracies between 0.5 and 0.55). The two implementations of Jankowska et al. <ref type="bibr" coords="15,282.93,435.92,15.77,8.64" target="#b11">[12,</ref><ref type="bibr" coords="15,301.34,435.92,13.28,8.64" target="#b12">13]</ref> also seem to be similar to each other and have a coverage score of 0.59.</p><p>Figure <ref type="figure" coords="15,178.03,459.83,4.98,8.64" target="#fig_0">1</ref> (right) exemplify the unambiguity scores for the PAN 15 test data. Following the definition of unambiguity, a clear problem (i.e., easy to identify the author) has a high unambiguity score whereas an obscure one has a low score. The observation that clear and obscure problems are rather evenly spread does not only hold for PAN 15 but also for the other datasets.</p><p>Our inspection of the different PAN authorship verification corpora shows that the effectiveness, similarity, and unambiguity scores vary in the expected scope such that the definitions reasonably capture differences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Influence of Random or Copied Verifiers on the World Ranking</head><p>Since the PAN shared tasks are intended to continue even after the respective conferences, everyone can submit new approaches for authorship verification at any time. The measures underlying the "world ranking" are directly able to incorporate any such new approaches and thus are able to always include the state of the art in authorship verification. Also creators of obfuscation approaches, of course, may submit new verifiers. This possibility could in principle also be exploited to submit verifiers with the intention of boosting a specific obfuscator's world ranking score:</p><p>-One could let the obfuscator leave a certain "watermark" in the text that a newly submitted verifier could then detect to turn all its decisions on such watermarked cases to "different authors". -Somewhat similarly, one could develop a verifier just focused on those aspects of the texts that the desired obfuscator will manipulate (e.g., counting the occurrences of "it's" vs. "it is"). Such a verifier might work with some success on unobfuscated texts but then not at all on the obfuscated texts of the specific obfuscator since the obfuscator probably will have removed most of the features used by the verifier. -One could also submit a slight variation of an existing verifier which is particularly vulnerable to the to-be-boosted obfuscation approach by altering the answers only in low-confidence cases. The verifier variant then should easily be fooled by the obfuscator while retaining reasonable performance on unobfuscated texts.</p><p>Such and similar deliberate attempts to boost an obfuscator's score should be considered "unfair play" and unscientific. In case of being detected-probably rather difficult to do automatically-, such verifiers should probably be removed entirely instead of just being ignored in the world ranking.</p><p>The second option could still yield a reasonable and well-performing approach in authorship verification, in which case it is a valid contribution. If the verifier, however, does not perform better than guessing, its effectiveness score should become too low to make any difference. If the verifier significantly resembles an existing one (as in the third option), the corresponding coverage scores would be lowered accordingly such that the overall score of all obfuscators ultimately should remain stable.</p><p>These assertions can be tested (effectiveness and coverage for some potentially adversarial submissions). We perform two experiments, in which we add 40 mock verifiers to the existing ones and look how the characteristics of the verifiers and the problems behave, and whether the overall scores for the different obfuscators and test corpora change. In the first experiment, the guessing attack, the mock verifiers just choose their confidence scores randomly in [0, 1] (uniformly distributed). We expect that those mock verifiers get poor effectiveness and high coverage scores, whereas the characteristics of the original verifiers and the problems remain stable, as well as the obfuscators' scores. In the second experiment, the variation attack, each mock verifier is obtained from an existing verifier, replacing 10% of its decisions (on the original and the obfuscated problems) by random confidence scores in [0, 1]. We expect that the effectiveness scores of the new verifiers are a bit lower than those of their originals, that these mock verifiers get low coverage scores in general, and that the coverage scores of the existing verifiers decrease overall, in particular for those which have been copied. Note that in both experiments, the effectiveness scores of the original verifiers remain stable by definition.</p><p>The left column of since also some of the mock verifiers also perform very badly. The other coverage scores remain mostly stable-as expected. The problem unambiguity scores move towards 0.5 since about half of the guessing verifiers guess the correct answer-if every verifier guessed its answers on an instance, half of them will guess correctly, resulting in a unambiguity score of exactly 0.5 for that instance.</p><p>The right column of Figure A.2 (Experiment 2: Variation Attack) shows the behavior of the three characteristics after attacking the ranking by copying (with a 10% random change) the 40 original verifiers. Similar to the first experiment, the observations are close to our expectations. The mock verifiers have roughly the same effectiveness as their originals, sometimes diminished due to the 10% random choices. Those verifiers which have not been copied mostly have the same coverage scores (except some few side effects), whereas those which have been copied have significantly reduced coverage scores. Except some few random outliers, these reduced coverage scores are also observed for the copies of the verifiers (often slightly higher which may be explained by the "unpredictable" 10% random choices). Similar to the first experiment, the random 10% choices explain the slight drift of the unambiguity scores towards 0.5.</p><p>The obfuscators' scores in the two experimental setups from above (random mock verifiers and verifier variants) are given in Table <ref type="table" coords="18,329.08,322.55,3.74,8.64" target="#tab_4">4</ref>. It can be seen that adding the mock verifiers does change the obfuscators' scores, though most changes are small compared to the actual differences between the obfuscators under consideration. In particular, the ordering of the obfuscators for each dataset remains stable, with the two exceptions that In both experiments, some scores are increased whereas some are reduced; however, a general trend towards higher scores is observable in both experiments. This trend may be explained statistically, noting that those random verifiers with an accuracy 0.5 on the original training data will still have an expected accuracy of 0.5 on the obfuscated data, thus changing probably some correct positive decisions to negative ones while having a moderate effectiveness score. Those random verifiers which perform poorly on the original data (i.e., that have an accuracy of ≈ 0.5), are more likely to correct wrong decisions by chance, but get a smaller effectiveness score such that their final influence is not as high.</p><p>Other than that, the changes in the obfuscators' scores are probably best explained as just random effects, since adding 40 random mock verifiers to ≈ 40 real verifiers will induce them. The remarkable thing here is that our proposed measure retains relatively stable output under such heavy modifications of the input data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Safety Evaluation According to the Legacy Evaluation Measures</head><p>Table <ref type="table" coords="18,160.56,593.53,4.98,8.64" target="#tab_5">5</ref> shows the results of our safety evaluation of the two obfuscators from this year compared to the five obfuscators from the last two years against 44 authorship verification approaches on the aforementioned four PAN evaluation datasets. Although we combined the rankings into an overall score to arrive a our ranking of obfuscation approaches, a per-dataset inspection allows for a more in-depth interpretation of the results of this year's participants in context. The best-performing approach this year was submitted by Rahgouy et al., which achieves 4th rank overall across the three years as per average impact; the average impact quantifies the averaged ratio of true positive decisions turned false negative. However, this result must be taken with a grain of salt since this approach basically removed large parts of the original text. The approach of Bakhteev and Khazov <ref type="bibr" coords="19,429.36,571.21,11.62,8.64" target="#b0">[1]</ref> performs second-best this year, and ranks fourth out of five overall. The ranking induced by average impact is inconsistent with those induced by AUC difference or C@1 difference on some datasets. The penultimate approach of Kocher and Savoy <ref type="bibr" coords="19,407.52,607.07,16.60,8.64" target="#b15">[16]</ref> achieves best performance for these measure on the PAN 13 and the PAN 14 EN datasets. We hypothesize that is is due to the ability of this approach to effectively lower confidence values without actually bringing them below the threshold. Nevertheless, the approach of <ref type="bibr" coords="19,145.55,654.89,83.72,8.64">Mihaylova et al. [18]</ref> still performs best in most situations. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="15,134.77,266.91,345.82,8.12;15,134.77,278.21,345.82,7.77;15,134.77,288.89,329.51,8.06"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Left: Distribution of accuracy and coverage for the 40 verifiers that we were able to run on the PAN 15 corpus. Right: Distribution of the unambiguity scores for the PAN 15 corpus (by definition, only of the positive problems). The x-axis gives the internal IDs of the problems.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="15,149.71,316.37,330.88,8.64;15,134.77,328.32,345.82,8.64;15,134.77,339.96,345.83,8.96;15,134.77,352.23,345.82,8.64;15,134.77,363.87,345.83,8.96;15,134.77,376.14,345.82,8.64;15,134.77,388.10,345.82,8.64;15,134.77,400.06,345.82,8.64;15,134.77,412.01,345.82,8.64;15,134.77,423.65,345.83,8.96;15,134.77,435.92,345.83,8.64;15,134.77,447.56,120.52,8.96;15,149.71,459.83,330.88,8.64;15,134.77,471.79,345.82,8.64;15,134.77,483.74,345.82,8.64;15,134.77,495.70,345.82,8.64;15,134.77,507.65,104.31,8.64;15,149.71,519.61,330.88,8.64;15,134.77,531.56,345.82,8.64;15,134.77,543.52,183.18,8.64"><head>Figure 1 (</head><label>1</label><figDesc>Figure 1 (left) shows the accuracy and coverage scores of the 40 verifiers that we were able to run on the original PAN 15 data. Many of the verifiers seem to follow rather unique approaches such that 19 of the 40 verifiers have a coverage score of 1.Note that some verifiers perform so poorly on the test data that our "best threshold" method chooses a threshold of +∞ or -∞, forcing them to always respond "different authors" or "same author", respectively. This behavior is mainly due to employing verification models that were trained on a different PAN corpus that are now tested on PAN 15 data (we did not re-train models that were submitted in another year), leading to multiple verifiers giving identical answers, which in turn then have very low coverage scores (between 0.11 and 0.123, with accuracies between 0.5 and 0.55). The two implementations of Jankowska et al.<ref type="bibr" coords="15,282.93,435.92,15.77,8.64" target="#b11">[12,</ref><ref type="bibr" coords="15,301.34,435.92,13.28,8.64" target="#b12">13]</ref> also seem to be similar to each other and have a coverage score of 0.59.Figure1(right) exemplify the unambiguity scores for the PAN 15 test data. Following the definition of unambiguity, a clear problem (i.e., easy to identify the author) has a high unambiguity score whereas an obscure one has a low score. The observation that clear and obscure problems are rather evenly spread does not only hold for PAN 15 but also for the other datasets.Our inspection of the different PAN authorship verification corpora shows that the effectiveness, similarity, and unambiguity scores vary in the expected scope such that the definitions reasonably capture differences.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="17,134.77,534.87,345.83,8.12;17,134.77,545.89,345.83,8.06;17,134.77,557.14,345.83,7.77;17,134.77,568.10,345.83,7.77;17,134.77,579.06,345.82,7.77;17,134.77,590.02,345.82,7.77;17,134.77,600.97,345.83,7.77;17,134.77,611.93,345.82,7.77;17,134.77,622.89,322.66,7.77"><head>Figure A. 2 (Figure 2 .</head><label>22</label><figDesc>Figure 2. Results of two robustness experiments with regard to effectiveness, coverage, and unambiguity. The x-axes of the plots show IDs of verifiers and problems, respectively. Circles (•) denote scores of the original verifiers or problems, crosses (+) denote scores of original verifiers or problems after adding 40 mock verifiers, and diamonds (♦) denote scores of the 40 mock verifiers. Since effectiveness is unaffected by adding verifiers and since no mock problems have been added, there are no crosses in the first row of plots, and no diamonds in the last one. Dependent on the experiments, the 40 mock verifiers guess at random (verifier IDs 40-79 in the left plots) or are variants of the original ones (IDs 0-39 in the right plots shared with their respective original verifiers). The problem IDs refer to the subset of positive problems of the PAN 15 dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="18,134.77,370.37,345.82,8.64;18,134.77,382.33,345.82,8.64;18,134.77,394.28,80.24,8.64"><head></head><label></label><figDesc>Keswani et al. and Castro et al. change their ranks for PAN13 and that Mansoorizadeh et al. and Castro et al. change their ranks for PAN14-EE for the setup with the 40 random mock verifiers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="8,134.77,629.40,345.82,20.59"><head></head><label></label><figDesc>was inspired by Mihaylova et al.'s approach [18].</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,134.77,115.83,345.82,94.52"><head>Table 2 .</head><label>2</label><figDesc>Characteristics of the used corpora and the number of verifiers we were able to run on a corpus.</figDesc><table coords="9,208.25,149.98,198.87,60.37"><row><cell>Corpus</cell><cell></cell><cell>Problem instances</cell><cell></cell><cell>Verifiers</cell></row><row><cell></cell><cell cols="3">Same author Different author Total</cell><cell></cell></row><row><cell>PAN13</cell><cell>14</cell><cell>16</cell><cell>30</cell><cell>41</cell></row><row><cell>PAN14 EE</cell><cell>100</cell><cell>100</cell><cell>200</cell><cell>38</cell></row><row><cell>PAN14 EN</cell><cell>100</cell><cell>100</cell><cell>200</cell><cell>39</cell></row><row><cell>PAN15</cell><cell>250</cell><cell>250</cell><cell>500</cell><cell>40</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,134.77,115.83,345.83,143.17"><head>Table 3 .</head><label>3</label><figDesc>World ranking of seven obfuscators, including those submitted to PAN 2016 and PAN 2017, against sets of 44 authorship verification approaches submitted to PAN 2013 through PAN 2015. In addition, we provide the scores achieved with our legacy measures.</figDesc><table coords="10,135.32,162.56,344.73,96.43"><row><cell>Obfuscator</cell><cell></cell><cell></cell><cell>Verifier</cell><cell>Dataset</cell><cell cols="3">Legacy Measures</cell><cell>World Ranking</cell></row><row><cell>Team</cell><cell cols="2">[Reference]</cell><cell>|Y |</cell><cell>D test |D + test |</cell><cell>∆ acc</cell><cell>∆ rec</cell><cell>avg imp</cell><cell>Score</cell></row><row><cell>Castro et al.</cell><cell></cell><cell>[6]</cell><cell>44</cell><cell>all corpora 464</cell><cell>-0.1281</cell><cell>-0.2387</cell><cell>0.4495</cell><cell>474.24</cell></row><row><cell cols="2">Mihaylova et al.</cell><cell>[18]</cell><cell>44</cell><cell>all corpora 464</cell><cell>-0.1104</cell><cell>-0.2099</cell><cell>0.3901</cell><cell>466.18</cell></row><row><cell cols="2">Keswani et al.</cell><cell>[15]</cell><cell>44</cell><cell>all corpora 464</cell><cell>-0.1071</cell><cell>-0.1990</cell><cell>0.3736</cell><cell>296.64</cell></row><row><cell cols="2">Rahgouy et al.</cell><cell>[21]</cell><cell>44</cell><cell>all corpora 464</cell><cell></cell><cell>-0.1771</cell><cell>0.3531</cell><cell>355.18</cell></row><row><cell cols="2">Bakhteev et al.</cell><cell>[1]</cell><cell>44</cell><cell>all corpora 464</cell><cell>-0.0726</cell><cell>-0.1322</cell><cell>0.2491</cell><cell>291.01</cell></row><row><cell cols="3">Mansoorizadeh et al. [17]</cell><cell>44</cell><cell>all corpora 464</cell><cell>-0.0378</cell><cell>-0.0738</cell><cell>0.1523</cell><cell>208.62</cell></row><row><cell cols="3">Kocher and Savoy [16]</cell><cell>44</cell><cell>all corpora 464</cell><cell>-0.0549</cell><cell>-0.1003</cell><cell>0.2180</cell><cell>107.85</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="11,134.77,276.72,345.82,32.55"><head></head><label></label><figDesc>2 for Mansoorizadeh et al.'s approach [17], grade 2-3 for Castro et al.'s approach [6], grade 4 for Mihaylova et al.'s [18] and Bakhteev's and Khazov's [1] obfuscators, and a grade 5 for Keswani et al.'s obfuscator</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="19,134.77,115.83,345.83,381.82"><head>Table 4 .</head><label>4</label><figDesc>World ranking of seven obfuscators, including those submitted to PAN 2016 and PAN 2017, against sets of 34-39 authorship verification approaches submitted to PAN 2013 through PAN 2015. We note the scores for the original data and for the two experiments, each with additional 40 mock verifiers.</figDesc><table coords="19,163.43,171.67,288.50,325.97"><row><cell>Obfuscator</cell><cell></cell><cell></cell><cell>Verifier</cell><cell>Dataset</cell><cell></cell><cell cols="2">Experiments</cell><cell>World Ranking</cell></row><row><cell>Team</cell><cell cols="2">[Reference]</cell><cell>|Y |</cell><cell cols="4">D test |D + test | Guessing Variation</cell><cell>Score</cell></row><row><cell>Castro et al.</cell><cell></cell><cell>[6]</cell><cell>36</cell><cell>PAN13</cell><cell>14</cell><cell>28.92</cell><cell>21.56</cell><cell>15.96</cell></row><row><cell cols="2">Mihaylova et al.</cell><cell>[18]</cell><cell>36</cell><cell>PAN13</cell><cell>14</cell><cell>28.66</cell><cell>22.58</cell><cell>15.70</cell></row><row><cell cols="2">Keswani et al.</cell><cell>[15]</cell><cell>36</cell><cell>PAN13</cell><cell>14</cell><cell>20.97</cell><cell>18.84</cell><cell>13.84</cell></row><row><cell cols="2">Rahgouy et al.</cell><cell>[21]</cell><cell>36</cell><cell>PAN13</cell><cell>14</cell><cell>22.25</cell><cell>15.71</cell><cell>9.63</cell></row><row><cell cols="2">Bakhteev et al.</cell><cell>[1]</cell><cell>36</cell><cell>PAN13</cell><cell>14</cell><cell>21.00</cell><cell>15.19</cell><cell>8.74</cell></row><row><cell cols="3">Kocher and Savoy [16]</cell><cell>36</cell><cell>PAN13</cell><cell>14</cell><cell>12.72</cell><cell>5.86</cell><cell>4.43</cell></row><row><cell cols="3">Mansoorizadeh et al. [17]</cell><cell>36</cell><cell>PAN13</cell><cell>14</cell><cell>13.92</cell><cell>9.10</cell><cell>3.83</cell></row><row><cell>Castro et al.</cell><cell></cell><cell>[6]</cell><cell>34</cell><cell cols="2">PAN14 EE 100</cell><cell>63.71</cell><cell>69.59</cell><cell>61.80</cell></row><row><cell cols="2">Mihaylova et al.</cell><cell>[18]</cell><cell>34</cell><cell cols="2">PAN14 EE 100</cell><cell>57.02</cell><cell>60.34</cell><cell>54.47</cell></row><row><cell cols="2">Keswani et al.</cell><cell>[15]</cell><cell>34</cell><cell cols="2">PAN14 EE 100</cell><cell>49.90</cell><cell>48.87</cell><cell>46.40</cell></row><row><cell cols="2">Rahgouy et al.</cell><cell>[21]</cell><cell>34</cell><cell cols="2">PAN14 EE 100</cell><cell>41.47</cell><cell>39.90</cell><cell>35.98</cell></row><row><cell cols="2">Bakhteev et al.</cell><cell>[1]</cell><cell>34</cell><cell cols="2">PAN14 EE 100</cell><cell>30.77</cell><cell>31.65</cell><cell>28.62</cell></row><row><cell cols="3">Mansoorizadeh et al. [17]</cell><cell>34</cell><cell cols="2">PAN14 EE 100</cell><cell>27.51</cell><cell>25.82</cell><cell>23.00</cell></row><row><cell cols="3">Kocher and Savoy [16]</cell><cell>34</cell><cell cols="2">PAN14 EE 100</cell><cell>22.20</cell><cell>18.44</cell><cell>17.44</cell></row><row><cell cols="2">Mihaylova et al.</cell><cell>[18]</cell><cell>37</cell><cell cols="2">PAN14 EN 100</cell><cell>99.83</cell><cell>119.93</cell><cell>102.29</cell></row><row><cell>Castro et al.</cell><cell></cell><cell>[6]</cell><cell>37</cell><cell cols="2">PAN14 EN 100</cell><cell>73.50</cell><cell>90.83</cell><cell>72.90</cell></row><row><cell cols="2">Keswani et al.</cell><cell>[15]</cell><cell>37</cell><cell cols="2">PAN14 EN 100</cell><cell>56.83</cell><cell>58.51</cell><cell>56.20</cell></row><row><cell cols="2">Rahgouy et al.</cell><cell>[21]</cell><cell>37</cell><cell cols="2">PAN14 EN 100</cell><cell>55.89</cell><cell>60.97</cell><cell>52.47</cell></row><row><cell cols="2">Bakhteev et al.</cell><cell>[1]</cell><cell>37</cell><cell cols="2">PAN14 EN 100</cell><cell>40.35</cell><cell>47.23</cell><cell>44.32</cell></row><row><cell cols="3">Mansoorizadeh et al. [17]</cell><cell>37</cell><cell cols="2">PAN14 EN 100</cell><cell>33.35</cell><cell>38.43</cell><cell>36.10</cell></row><row><cell cols="3">Kocher and Savoy [16]</cell><cell>37</cell><cell cols="2">PAN14 EN 100</cell><cell>25.67</cell><cell>19.31</cell><cell>17.41</cell></row><row><cell>Castro et al.</cell><cell></cell><cell>[6]</cell><cell>39</cell><cell>PAN15</cell><cell>250</cell><cell>318.07</cell><cell>335.58</cell><cell>323.58</cell></row><row><cell cols="2">Mihaylova et al.</cell><cell>[18]</cell><cell>39</cell><cell>PAN15</cell><cell>250</cell><cell>295.14</cell><cell>305.07</cell><cell>293.72</cell></row><row><cell cols="2">Rahgouy et al.</cell><cell>[21]</cell><cell>39</cell><cell>PAN15</cell><cell>250</cell><cell>253.17</cell><cell>271.10</cell><cell>257.09</cell></row><row><cell cols="2">Bakhteev et al.</cell><cell>[1]</cell><cell>39</cell><cell>PAN15</cell><cell>250</cell><cell>208.16</cell><cell>218.35</cell><cell>209.32</cell></row><row><cell cols="2">Keswani et al.</cell><cell>[15]</cell><cell>39</cell><cell>PAN15</cell><cell>250</cell><cell>177.68</cell><cell>194.26</cell><cell>180.04</cell></row><row><cell cols="3">Mansoorizadeh et al. [17]</cell><cell>39</cell><cell>PAN15</cell><cell>250</cell><cell>149.44</cell><cell>151.66</cell><cell>145.70</cell></row><row><cell cols="3">Kocher and Savoy [16]</cell><cell>39</cell><cell>PAN15</cell><cell>250</cell><cell>74.85</cell><cell>72.94</cell><cell>68.58</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="20,134.77,180.43,345.83,176.05"><head>Table 5 .</head><label>5</label><figDesc>Safety evaluation of seven obfuscators, including those submitted to PAN 2016 and PAN 2017, against sets of 26-36 authorship verification approaches submitted to PAN 2013 through PAN 2015. The column group "PAN measures" shows the average performance delta on the evaluation measures ROC AUC, C@1, and the final score AUC • C@1 applied at PAN. The four row groups belong to the four English PAN test datasets; the rows within the row groups are ordered by average impact (avg imp, see the last column). test |D + test | ∆ AUC ∆ C@1 ∆ final ∆ acc ∆ rec avg imp</figDesc><table coords="20,135.13,260.05,342.78,96.43"><row><cell>Obfuscator</cell><cell></cell><cell>Verifier</cell><cell>Dataset</cell><cell>PAN Measures</cell><cell>Legacy Measures</cell></row><row><cell cols="4">Team D Mihaylova et al. [Reference] |Y | [18] 36 PAN13</cell><cell cols="2">14 -0.1066 -0.0759 -0.1030 -0.1389 -0.2778 0.4690</cell></row><row><cell>Keswani et al.</cell><cell>[15]</cell><cell>36</cell><cell>PAN13</cell><cell cols="2">14 -0.0908 -0.0695 -0.0940 -0.1148 -0.2361 0.4245</cell></row><row><cell>Castro et al.</cell><cell>[6]</cell><cell>36</cell><cell>PAN13</cell><cell cols="2">14 -0.1106 -0.0545 -0.0920 -0.1248 -0.2449 0.4175</cell></row><row><cell>Rahgouy et al.</cell><cell>[21]</cell><cell>36</cell><cell>PAN13</cell><cell cols="2">14 -0.1116 -0.0640 -0.0800 -0.1088 -0.2248 0.3952</cell></row><row><cell>Bakhteev et al.</cell><cell>[1]</cell><cell>36</cell><cell>PAN13</cell><cell cols="2">14 -0.0518 -0.0547 -0.0631 -0.0796 -0.1667 0.2881</cell></row><row><cell cols="2">Kocher and Savoy [16]</cell><cell>36</cell><cell>PAN13</cell><cell cols="2">14 -0.1353 -0.1149 -0.0912 -0.0452 -0.1020 0.1910</cell></row><row><cell cols="2">Mansoorizadeh et al. [17]</cell><cell>36</cell><cell>PAN13</cell><cell cols="2">14 -0.0422 -0.0254 -0.0392 -0.0463 -0.0933 0.1442</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="10,144.73,657.05,42.25,7.77"><p>www.tira.io</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank the participating teams of the three editions of this shared task.</p></div>
<div><head>Bibliography</head></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="13,154.69,142.87,260.44,7.77;13,154.68,153.83,171.76,7.77" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="13,250.52,142.87,164.61,7.77;13,154.68,153.83,136.15,7.77">Author Masking using Sequence-to-Sequence Models-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Bakhteev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Khazov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,154.69,164.79,314.56,7.77;13,154.68,175.75,325.61,7.77;13,154.68,186.71,131.08,7.77;13,154.68,197.67,198.21,7.77" xml:id="b1">
	<analytic>
		<ptr target="http://www.clef-initiative.eu/publication/working-notes" />
	</analytic>
	<monogr>
		<title level="m" coord="13,366.61,164.79,102.64,7.77;13,154.68,175.75,157.56,7.77">CLEF 2016 Evaluation Labs and Workshop -Working Notes Papers, 5-8</title>
		<title level="s" coord="13,417.50,175.75,62.79,7.77;13,154.68,186.71,68.09,7.77">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<meeting><address><addrLine>Évora, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-09">September. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,154.69,208.63,321.11,7.77;13,154.68,219.59,318.11,7.77;13,154.68,230.55,131.08,7.77;13,154.68,241.50,198.21,7.77" xml:id="b2">
	<analytic>
		<ptr target="http://www.clef-initiative.eu/publication/working-notes" />
	</analytic>
	<monogr>
		<title level="m" coord="13,357.97,208.63,117.83,7.77;13,154.68,219.59,124.46,7.77">CLEF 2017 Evaluation Labs and Workshop -Working Notes Papers</title>
		<title level="s" coord="13,410.00,219.59,62.79,7.77;13,154.68,230.55,68.09,7.77">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Mandl</surname></persName>
		</editor>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09-14">11-14 September. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,154.69,252.46,318.59,7.77;13,154.68,263.42,312.91,7.77;13,154.68,274.38,131.08,7.77;13,154.68,285.34,198.21,7.77" xml:id="b3">
	<analytic>
		<ptr target="http://www.clef-initiative.eu/publication/working-notes" />
	</analytic>
	<monogr>
		<title level="m" coord="13,355.45,252.46,117.83,7.77;13,154.68,263.42,124.46,7.77">CLEF 2014 Evaluation Labs and Workshop -Working Notes Papers</title>
		<title level="s" coord="13,404.80,263.42,62.79,7.77;13,154.68,274.38,68.09,7.77">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Halvey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</editor>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-09">September. 2014</date>
			<biblScope unit="page" from="15" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,154.69,296.30,310.55,7.77;13,154.68,307.26,322.92,7.77;13,154.68,318.22,131.08,7.77;13,154.68,329.18,198.21,7.77" xml:id="b4">
	<analytic>
		<ptr target="http://www.clef-initiative.eu/publication/working-notes" />
	</analytic>
	<monogr>
		<title level="m" coord="13,347.41,296.30,117.83,7.77;13,154.68,307.26,124.46,7.77">CLEF 2017 Evaluation Labs and Workshop -Working Notes Papers</title>
		<title level="s" coord="13,414.82,307.26,62.79,7.77;13,154.68,318.22,68.09,7.77">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-09-14">11-14 September. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,154.69,340.14,230.18,7.77;13,154.68,351.09,200.33,7.77" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="13,280.02,340.14,104.84,7.77;13,154.68,351.09,164.72,7.77">Author Masking by Sentence Transformation-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Muñoz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,154.69,362.05,304.31,7.77;13,154.68,373.01,234.61,7.77;13,154.68,383.97,198.21,7.77" xml:id="b6">
	<monogr>
		<ptr target="http://www.clef-initiative.eu/publication/working-notes" />
		<title level="m" coord="13,295.57,362.05,163.43,7.77;13,154.68,373.01,78.86,7.77">CLEF 2013 Evaluation Labs and Workshop -Working Notes Papers</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Tufis</surname></persName>
		</editor>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-09">September. 2013</date>
			<biblScope unit="page" from="23" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,154.69,394.93,321.92,7.77;13,154.68,405.89,297.18,7.77;13,154.68,416.85,325.91,7.77;13,154.68,427.81,203.55,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,345.89,394.93,113.85,7.77">PPDB: The paraphrase database</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,154.68,405.89,297.18,7.77;13,154.68,416.85,196.25,7.77">Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings</title>
		<meeting><address><addrLine>Westin Peachtree Plaza Hotel, Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">June 9-14, 2013. 2013</date>
			<biblScope unit="page" from="758" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,154.69,438.77,293.08,7.77;13,154.68,449.72,319.88,7.77;13,154.68,460.68,318.27,7.77;13,154.68,471.64,256.21,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,278.33,438.77,169.44,7.77;13,154.68,449.72,182.43,7.77">Ousting Ivory Tower Research: Towards a Web Framework for Providing Experiments as a Service</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Burrows</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,249.57,460.68,223.39,7.77;13,154.68,471.64,128.24,7.77">International ACM Conference on Research and Development in Information Retrieval (SIGIR 12)</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Hersh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Callan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Maarek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-08">Aug 2012</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1125" to="1126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,154.69,482.60,325.90,7.77;13,154.68,493.56,315.90,7.77;13,154.68,504.52,323.70,7.77;13,154.68,515.48,280.09,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,280.39,482.60,200.20,7.77;13,154.68,493.56,98.32,7.77">Overview of the Author Obfuscation Task at PAN 2017: Safety Evaluation Revisited</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1866/" />
	</analytic>
	<monogr>
		<title level="m" coord="13,154.68,504.52,206.43,7.77">Working Notes Papers of the CLEF 2017 Evaluation Labs</title>
		<title level="s" coord="13,367.29,504.52,107.26,7.77;13,192.86,515.48,59.13,7.77">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Mandl</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2017-09">Sep 2017</date>
			<biblScope unit="volume">1866</biblScope>
		</imprint>
	</monogr>
	<note>CLEF and CEUR</note>
</biblStruct>

<biblStruct coords="13,154.69,526.44,289.92,7.77;13,154.68,537.40,325.09,7.77;13,154.68,548.35,290.28,7.77;13,154.68,559.31,112.61,7.77" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="13,169.63,548.35,170.76,7.77">Evaluation-as-a-Service: Overview and Outlook</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Brodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Eggel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1512.07454" />
		<imprint>
			<date type="published" when="2015-12">Dec 2015</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct coords="13,154.69,570.27,307.63,7.77;13,154.68,581.23,317.98,7.77;13,154.68,592.19,66.74,7.77" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="13,296.94,570.27,165.38,7.77;13,154.68,581.23,317.98,7.77;13,154.68,592.19,21.92,7.77">Proximity based One-class Classification with Common N-Gram Dissimilarity for Authorship Verification Task-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jankowska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kešelj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Milios</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,154.69,603.15,288.94,7.77;13,154.68,614.11,275.85,7.77" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="13,292.46,603.15,151.17,7.77;13,154.68,614.11,231.04,7.77">Ensembles of Proximity-Based One-Class Classifiers for Author Verification-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jankowska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kešelj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Milios</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,154.69,625.07,317.85,7.77" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="13,245.10,625.07,182.63,7.77">Overview of the Author Identification Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,154.69,636.03,270.70,7.77;13,154.68,646.98,185.39,7.77" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="13,336.22,636.03,89.16,7.77;13,154.68,646.98,149.78,7.77">Author Masking through Translation-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Keswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Majumder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,154.69,119.96,308.52,7.77;14,154.68,130.92,66.74,7.77" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="14,235.91,119.96,227.31,7.77;14,154.68,130.92,21.92,7.77">UniNE at CLEF 2018: Author Masking-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kocher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,154.69,141.81,325.65,7.77;14,154.68,152.77,274.37,7.77;14,154.68,163.73,101.86,7.77" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="14,387.20,141.81,93.14,7.77;14,154.68,152.77,223.83,7.77">Author Obfuscation using WordNet and Language Models-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mansoorizadeh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rahgooy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Aminiyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Eskandari</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1609/" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,154.69,174.63,277.78,7.77;14,154.68,185.59,293.75,7.77;14,154.68,196.55,101.86,7.77" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="14,154.68,185.59,243.20,7.77">SU@PAN&apos;2016: Author Obfuscation-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mihaylova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Karadjov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kiprov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Georgiev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Koychev</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1609/" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,154.69,207.44,309.83,7.77;14,154.68,218.40,318.49,7.77;14,154.68,229.36,295.88,7.77;14,154.68,240.32,297.56,7.77;14,154.68,251.28,307.09,7.77;14,154.68,262.23,272.70,7.77" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="14,413.60,207.44,50.92,7.77;14,154.68,218.40,318.49,7.77;14,154.68,229.36,57.91,7.77">Improving the Reproducibility of PAN&apos;s Shared Tasks: Plagiarism Detection, Author Identification, and Author Profiling</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,259.54,240.32,192.71,7.77;14,154.68,251.28,307.09,7.77;14,154.68,262.23,37.80,7.77">Information Access Evaluation meets Multilinguality, Multimodality, and Visualization. 5th International Conference of the CLEF Initiative (CLEF 14)</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Lupu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hall</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Toms</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014-09">Sep 2014</date>
			<biblScope unit="page" from="268" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,154.69,273.13,317.79,7.77;14,154.68,284.09,312.46,7.77;14,154.68,295.05,289.34,7.77;14,154.68,306.01,101.86,7.77" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="14,281.21,273.13,191.26,7.77;14,154.68,284.09,83.28,7.77">Author Obfuscation: Attacking the State of the Art in Authorship Verification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1609/" />
	</analytic>
	<monogr>
		<title level="m" coord="14,256.78,284.09,206.43,7.77">Working Notes Papers of the CLEF 2016 Evaluation Labs</title>
		<title level="s" coord="14,154.68,295.05,107.26,7.77;14,306.21,295.05,59.13,7.77">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2016-09">Sep 2016</date>
			<biblScope unit="volume">1609</biblScope>
		</imprint>
	</monogr>
	<note>CLEF and CEUR</note>
</biblStruct>

<biblStruct coords="14,154.69,316.90,306.26,7.77;14,154.68,327.86,284.08,7.77" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="14,435.55,316.90,25.40,7.77;14,154.68,327.86,239.26,7.77">Author Masking Directed by Author&apos;s Style-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rahgouy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Babaei Giglou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rahgooy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zeynali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mirza Rasouli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,154.69,338.76,324.31,7.77;14,154.68,349.71,323.83,7.77;14,154.68,360.67,325.91,7.77;14,154.68,371.63,323.15,7.77;14,154.68,382.59,39.60,7.77" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="14,167.64,349.71,201.01,7.77">Overview of the Author Identification Task at PAN 2015</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">D</forename><surname>Amd Ben Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>López-López</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="14,260.98,360.67,219.61,7.77;14,154.68,371.63,22.30,7.77">CLEF 2015 Evaluation Labs and Workshop -Working Notes Papers</title>
		<title level="s" coord="14,310.11,371.63,133.12,7.77">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>San Juan</surname></persName>
		</editor>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09">8-11 September. Sep 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,154.69,393.49,285.47,7.77;14,154.68,404.44,308.44,7.77;14,154.68,415.40,65.41,7.77" xml:id="b22">
	<monogr>
		<title level="m" type="main" coord="14,299.85,404.44,163.28,7.77;14,154.68,415.40,17.11,7.77">Overview of the Author Identification Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanchez-Perez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,154.69,426.30,321.81,7.77;14,154.68,437.26,306.30,7.77;14,154.68,448.22,308.59,7.77;14,154.68,459.18,41.59,7.77" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="14,288.14,426.30,188.37,7.77;14,154.68,437.26,22.83,7.77">Generating Acrostics via Paraphrasing and Heuristic Search</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bräutigam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,304.84,437.26,156.14,7.77;14,154.68,448.22,91.84,7.77">International Conference on Computational Linguistics (COLING 14)</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hajic</surname></persName>
		</editor>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-08">Aug 2014</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2018" to="2029" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,135.13,369.33,48.47,6.48;20,199.46,369.04,278.46,6.77;20,135.13,379.19,35.90,6.48;20,203.20,379.19,274.72,6.48;20,135.13,389.05,42.28,6.48;20,199.46,389.05,278.46,6.48;20,135.13,398.92,43.37,6.48;20,199.46,398.92,278.46,6.48;20,135.13,408.78,44.43,6.48;20,203.20,408.78,274.72,6.48;20,135.13,418.64,342.78,6.48;20,135.13,428.50,342.78,6.48;20,135.13,447.83,48.47,6.48;20,199.46,447.54,278.46,6.77;20,135.13,457.69,43.37,6.48;20,199.46,457.69,278.46,6.48;20,135.13,467.56,35.90,6.48;20,203.20,467.56,274.72,6.48;20,135.13,477.42,42.28,6.48;20,199.46,477.42,278.46,6.48;20,135.13,487.28,44.43,6.48;20,203.20,487.28,274.72,6.48;20,135.13,497.15,342.78,6.48;20,135.13,506.72,342.78,6.77;20,135.13,526.34,48.47,6.48;20,199.46,526.34,70.28,6.48;20,286.84,526.04,191.08,6.77;20,135.13,536.20,35.90,6.48;20,203.20,536.20,66.55,6.48;20,286.84,536.20,191.08,6.48;20,135.13,546.06,43.37,6.48;20,199.46,546.06,70.28,6.48;20,286.84,546.06,191.08,6.48;20,135.13,555.92,42.28,6.48;20,199.46,555.92,70.28,6.48;20,286.84,555.92,191.08,6.48;20,135.13,565.79,44.43,6.48;20,203.20,565.79,66.55,6.48;20,286.84,565.79,191.08,6.48;20,135.13,575.65,134.61,6.48;20,286.84,575.65,191.08,6.48;20,135.13,585.51,134.61,6.48;20,286.84,585.51,191.08,6.48" xml:id="b24">
	<analytic>
		<title/>
		<author>
			<persName coords=""><surname>Mihaylova</surname></persName>
		</author>
		<idno>35 PAN15 250</idno>
	</analytic>
	<monogr>
		<title level="j" coord="20,248.01,369.33,21.73,6.48">PAN</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
		</imprint>
	</monogr>
	<note>Castro et al. Castro et al</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
