<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,135.83,115.90,343.69,12.90;1,138.84,135.75,337.69,10.75">Overview of the Author Identification Task at PAN-2018 Cross-domain Authorship Attribution and Style Change Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,135.09,172.15,64.29,8.64"><forename type="first">Mike</forename><surname>Kestemont</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Antwerp</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,210.88,172.15,82.57,8.64"><forename type="first">Michael</forename><surname>Tschuggnall</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Innsbruck</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,304.72,172.15,84.36,8.64"><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of the Aegean</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,400.24,172.15,70.88,8.64"><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Antwerp</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,201.08,184.10,60.52,8.64"><forename type="first">Günther</forename><surname>Specht</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Innsbruck</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,272.78,184.10,47.65,8.64"><forename type="first">Benno</forename><surname>Stein</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Bauhaus-Universität Weimar</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,348.09,184.10,61.72,8.64"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Leipzig University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,135.83,115.90,343.69,12.90;1,138.84,135.75,337.69,10.75">Overview of the Author Identification Task at PAN-2018 Cross-domain Authorship Attribution and Style Change Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5816B01F953D286ECB5D7352746864CF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Author identification attempts to reveal the authors behind texts. It is an emerging area of research associated with applications in literary research, cyber-security, forensics, and social media analysis. In this edition of PAN, we study two task, the novel task of cross-domain authorship attribution, where the texts of known and unknown authorship belong to different domains, and style change detection, where single-author and multi-author texts are to be distinguished. For the former task, we make use of fanfiction texts, a large part of contemporary fiction written by non-professional authors who are inspired by specific well-known works, to enable us control the domain of texts for the first time. We describe a new corpus of fanfiction texts covering five languages (English, French, Italian, Polish, and Spanish). For the latter, a new data set of Q&amp;As covering multiple topics in English is introduced. We received 11 submissions for the cross-domain authorship attribution task and 5 submissions for the style change detection task. A survey of participant methods and analytical evaluation results are presented in this paper.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="24" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="25" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, the authenticity of (online) information has attracted much attention, especially in the context of the so-called 'fake news' debate in the wake of the US presidential elections. Much emphasis is currently put in various media on the provenance and authenticity of information. In the case of written documents, an important aspect of this sort of provenance criticism relates to authorship: assessing the authenticity of information crucially relates to identifying the original author(s) of these documents. Consequently, one can argue that the development of computational authorship identification systems, that can assist humans in various tasks in this domain (journalism, law enforcement, content moderation, etc.), carries great significance.</p><p>Quantitative approaches to tasks like authorship attribution <ref type="bibr" coords="1,390.98,629.43,15.27,8.64" target="#b42">[42]</ref>, verification <ref type="bibr" coords="1,461.50,629.43,15.27,8.64" target="#b26">[26]</ref>, profiling <ref type="bibr" coords="1,171.38,641.39,11.62,8.64" target="#b1">[2]</ref> or author clustering <ref type="bibr" coords="1,265.19,641.39,16.60,8.64" target="#b48">[48]</ref> rely on the basic assumption that the writing style of documents is somehow quantified, learned, and used to build prediction models. It is commonly stressed that a unifying goal of the field is to develop modeling strategies for texts that focus on style rather than content. Any successful author identification system, be it in a attribution setup or in a verification setup, must yield robust identifications across texts in different genres, treating different topics or having different target audiences in mind. Because of this requirement, features such as function words or common character-level n-grams are typically considered valuable characteristics, because they are less strongly tied to the specific content or genre of texts. Such features nevertheless require relatively long documents to be successful and they typically result in sparse, less useful representations for short documents. As such, one of the field's most important goals remains the development of systems that do not overfit on the specific content of training texts and scale well across different text varieties.</p><p>This year we focus on so-called fanfiction, where non-professional authors produce prose fiction that is inspired by a well-known author or work. Many fans produce fiction across multiple fandoms, raising interesting questions about the stylistic continuity of these authors across these fandoms. Cross-fandom authorship attribution, which is closely related to cross-topic and cross-genre attribution, is therefore the main focus of the cross-domain authorship attribution task.</p><p>Traditional models for authorship attribution are not applicable in the case where multiple authors are involved within a single document. Therefore, it is an important prerequisite to at first determine if a document is single-or multi-author. To this end, the style breach detection task at PAN 2017 aimed to find the exact border positions within a document where the authorship changes. Previous results have shown that the problem is quite hard <ref type="bibr" coords="2,222.46,382.33,15.27,8.64" target="#b50">[50]</ref>, i.e., to identify the exact borders in terms of character position. Therefore, we substantially relaxed the task for PAN 2018 and broke it down to the simple question: Given a document, are there any style changes or not? An alternative formulation would thus be to predict whether a document is written by a single author or by multiple collaborators. In this sense, it is irrelevant to the task to identify the exact border positions between authors.</p><p>To be able to evaluate the submitted approaches sufficiently, a data set is needed which contains single as well as multi-author documents. Thereby a key requirement is that multi-author documents contain the same topic, as otherwise the task would be simplified (e.g., an author discussing about the first world war might be easily distinguished from a second one writing about programming languages by applying simple vocabulary analyses). Therefore we created a novel data set by crawling a popular Q&amp;A network, containing millions of publicly available questions and answers regarding several topics. By applying multiple cleaning steps, we ensure that it represents a realistic and high-quality data set for the style change detection problem.</p><p>In what follows, after a brief review of previous work on these two task in the following section, Sections 3 and 4 discuss the two outlined tasks, respectively, including a discussion of its rationale, data set construction, performance measures, survey of submitted approaches, evaluation results, and their analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Previous Work</head><p>Closed-set authorship attribution is a task with rich relevant literature <ref type="bibr" coords="3,424.42,143.22,15.77,8.64" target="#b42">[42,</ref><ref type="bibr" coords="3,443.82,143.22,11.83,8.64" target="#b29">29]</ref>. Two previous editions of PAN included corresponding shared tasks <ref type="bibr" coords="3,389.76,155.18,10.79,8.64" target="#b0">[1,</ref><ref type="bibr" coords="3,403.65,155.18,11.83,8.64" target="#b18">19]</ref>. However, they only examined the case where both training and test documents belong to the same domain, as it is the case for the vast majority of published studies in this area. Crossdomain authorship attribution has been sporadically studied in the last decade <ref type="bibr" coords="3,454.16,191.04,10.79,8.64" target="#b2">[3,</ref><ref type="bibr" coords="3,468.13,191.04,12.45,8.64" target="#b31">31,</ref><ref type="bibr" coords="3,134.77,203.00,12.45,8.64" target="#b37">37,</ref><ref type="bibr" coords="3,149.38,203.00,12.45,8.64" target="#b38">38,</ref><ref type="bibr" coords="3,164.01,203.00,12.45,8.64" target="#b39">39,</ref><ref type="bibr" coords="3,178.62,203.00,12.45,8.64" target="#b45">45,</ref><ref type="bibr" coords="3,193.25,203.00,11.83,8.64" target="#b46">46]</ref>. In such cases, training and test texts belong to different domains that may refer to topic, genre, or language. In this section we focus our on the construction of building suitable resources for evaluating cross-domain attribution methods.</p><p>The most frequent scenario examined in previous cross-domain attribution studies considers cross-topic conditions. To control topic, usually general thematic categories are defined and all texts are pre-assigned to a topic. For example, Koppel et al. uses three thematic categories (ritual, business, and family) of religious Hebrew-Aramaic texts <ref type="bibr" coords="3,155.91,286.69,15.27,8.64" target="#b23">[24]</ref>. Newspaper articles are considered by Mikros and Argiri <ref type="bibr" coords="3,403.16,286.69,16.60,8.64" target="#b27">[27]</ref> (classified into two thematic areas: politics and culture) and Stamatatos (classified into four areas: politics, society, world, and UK) <ref type="bibr" coords="3,249.62,310.60,15.27,8.64" target="#b45">[45]</ref>. Another approach is to use a controlled corpus where some individuals are asked to write texts on a specific, well-defined topic <ref type="bibr" coords="3,421.68,322.55,15.27,8.64" target="#b47">[47]</ref>. The latter provides fine-grained control over topic. On the other hand, the size of such controlled corpora is relatively small.</p><p>Another important cross-domain perspective concerns cross-genre conditions. In general, it is hard to collect texts by several authors in different genres. Kestemont et al. make use of literary texts (theater plays and literary prose) <ref type="bibr" coords="3,376.15,382.33,16.60,8.64" target="#b20">[21]</ref> while Stamatatos explores differences between opinion articles and book reviews published in the same newspaper <ref type="bibr" coords="3,180.09,406.24,15.27,8.64" target="#b45">[45]</ref>. Another idea is to use social media texts based on the fact that many users are active in different social networks (e.g., Facebook and Twitter) <ref type="bibr" coords="3,428.58,418.19,15.27,8.64" target="#b31">[31]</ref>. Finally, a controlled corpus can be built, where each subject (author) is asked to write a text in a set of genres (e.g., email, blog, essay) <ref type="bibr" coords="3,299.55,442.10,15.27,8.64" target="#b47">[47]</ref>. The most extreme case concerns crosslanguage conditions where training and test texts are in different languages <ref type="bibr" coords="3,436.46,454.06,10.58,8.64" target="#b2">[3]</ref>. A convenient source of such cases is provided by novels that have been translated to other languages hoping that the translator's preferences do not significantly affect the style of the original author. To the best of our knowledge, so far there is no cross-domain authorship attribution study using fanfiction texts.</p><p>With respect to intrinsic analyses of texts, PAN included several shared tasks in the last years. Starting from intrinsic plagiarism detection <ref type="bibr" coords="3,354.91,525.79,15.27,8.64" target="#b33">[33]</ref>, the focus went from clustering authors within documents <ref type="bibr" coords="3,266.68,537.74,16.60,8.64" target="#b48">[48]</ref> to the detection of positions where the style, i.e., the authorship, changes <ref type="bibr" coords="3,232.15,549.70,15.27,8.64" target="#b50">[50]</ref>. In general, all those tasks imply an intrinsic, stylometric analysis of the texts, as no reference corpora are available. Thus, stylistic fingerprints are created that include lexical features like character n-grams (e.g., <ref type="bibr" coords="3,416.55,573.61,14.94,8.64" target="#b43">[43]</ref>), word frequencies (e.g., <ref type="bibr" coords="3,197.05,585.56,15.93,8.64" target="#b15">[16]</ref>) or average word/sentence lengths (e.g., <ref type="bibr" coords="3,384.01,585.56,14.94,8.64" target="#b51">[51]</ref>), syntactic features like part-of-speech (POS) tag frequencies/structures (e.g., <ref type="bibr" coords="3,372.76,597.52,15.93,8.64" target="#b49">[49]</ref>) or structural features such as indentation usages (e.g., <ref type="bibr" coords="3,273.10,609.47,14.94,8.64" target="#b51">[51]</ref>). Approaches specifically tackling the similar style breach detection task at PAN 2017 also utilize typical stylometric features such as bags of character n-grams, frequencies of function words, and other lexical metrics, processed by algorithms operating on top to detect borders <ref type="bibr" coords="3,370.79,645.34,10.79,8.64" target="#b6">[7,</ref><ref type="bibr" coords="3,384.07,645.34,13.28,8.64" target="#b21">22]</ref> or outliers <ref type="bibr" coords="3,443.01,645.34,15.27,8.64" target="#b35">[35]</ref>.</p><p>In general, related work targeting multi-author documents is rare. While there exist several approaches for the related text segmentation problem, where a text is divided into distinct portions of different topics, only few approaches target a segmentation by other criteria, especially not by authorship. One of the first approaches in the latter direction that employs stylometry to automatically detect boundaries of authors of collaboratively written texts has been proposed by Glover and Hirst <ref type="bibr" coords="4,404.42,179.09,15.27,8.64" target="#b9">[10]</ref>. Nevertheless, the goal of detecting boundaries is not to reveal multiple authors, but to provide hints such that collaboratively written documents can be homogenized in terms of the global style. Further approaches include Graham et al. <ref type="bibr" coords="4,327.12,214.95,15.27,8.64" target="#b11">[12]</ref>, who utilize neural networks with several stylometric features, and Gianella <ref type="bibr" coords="4,303.56,226.91,10.58,8.64" target="#b8">[9]</ref>, who proposes a stochastic model on the occurrences of words to split a document by authorship.</p><p>With respect to the proposed style change detection task at PAN 2018, i.e., to solely separate single-author documents from multi-authored ones, no prior studies exist to the best of our knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Cross-domain Authorship Attribution</head><p>For this edition of PAN, a challenging and novel source of texts has been targeted that seems well suited to advance the field with respect to the style-content dichotomy that is so central to it: fanfiction <ref type="bibr" coords="4,248.34,354.43,15.27,8.64" target="#b14">[15]</ref>. In this section, after a brief introduction into this literary genre of writing, we describe how we constructed a data set from a collection of fanfiction works for the task of cross-domain authorship attribution. After that, the participants' submissions are surveyed, followed by an in-depth evaluation of their attribution performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Fanfiction</head><p>Fanfiction refers to the large body of contemporary fiction that is nowadays created by non-professional authors ('fans'), who write in the tradition of a well-known source work, such as the Harry Potter series by J.K. Rowling, that is called the 'fandom'. These writings or 'fics' engage in a far-reaching form of 'intertextuality': they heavily and explicitly borrow characters, motives, settings, etc. from the source fandom. The authors are typically 'amateurs' who do not seek any commercial gains. (A famous exception to this rule is the successful Fifty Shades trilogy by E.L. James, that was originally a Twilight fanfic.) In many cases, the legal status of these fanfics has been the subject of controversy, although many fans have stressed the 'transformative' status of their fics. Overall, one could make the distinction between 'transformative' fanfiction and 'affirmative' fanfiction-the latter staying relatively closer to the original texts in the fandom with respect to tone, style or storylines. At the other side of the spectrum, we find intense reworkings of the fandom that, apart from perhaps the names of the protagonists, have little in common anymore with the original fandom. Many texts are for instance pornographic in nature; this is especially true of the so-called 'slash' fics that focus on the (typically same-sex) encounter of two fictional characters, e.g. "Kirk/Spock".</p><p>There are various reasons why fanfiction is an interesting benchmark case for computational authorship identification. Most of the fanfiction is nowadays produced on online platforms (such as fanfiction.net or archiveofourown.org) that are not strongly mediated or moderated, so that the fics in all likelihood accurately reflect the author's individual style. This is typically not the case with professionally published authors for which editorial interventions are a constant cause of worry. Many fans are moreover active across different fandoms. Because of the explicit intertextuality, it can be anticipated that the style of the original fandom texts-sometimes also called the 'canon'has a strong influence on the fan's writings, because these often aim to imitate the style of the canon's original authors. An interesting example is for instance the James Potter series by Georges N. Lippert, an American writer whose children were so disappointed that the original Potter series has come to an end, that he decided to write a multivolume continuation of the storyline, featuring Harry's son James as a protagonist. For instance, for Lippert, it is clear that he was maximally trying to faithfully reproduce Rowling's writing style. <ref type="foot" coords="5,230.55,261.11,3.49,6.05" target="#foot_0">1</ref>Fanfiction thus allows for exciting authorship research: do fanfiction authors succeed in imitating the author's stylome or does their individual fingerprint still show in the style of their fics? This question is especially relevant for fans that are active contributors across different fandoms: can we still identify texts by the same author, even when they are basing themselves on different canons? Naturally, such issues challenge the state of the art in computational authorship identification and can provide ideal benchmark data to test the robustness of state-of-art systems across different domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Task Definition</head><p>The task can be defined as closed-set cross-fandom attribution in fanfiction. Given a sample of reference documents from a restricted and finite set of candidate authors, the task is to determine the most likely author of a previously unseen document of unknown authorship. Documents of known and unknown authorship belong to different domains (fandoms). More specifically, all documents of unknown authorship are fics of the same fandom (target fandom) while the documents of known authorship by the candidate authors are fics of several fandoms (other than the target-fandom). The participants are asked to prepare a method that can handle multiple cross-fandom attribution problems.</p><p>In more detail, a cross-domain authorship attribution problem is a tuple (A, K, U ), where A is the set of candidate authors, K is the set of reference (known authorship) texts, and U is the set of unknown authorship texts. For each candidate author a ∈ A, we are given K a ⊂ K, a set of texts unquestionably written by a. Each text in U should be assigned to exactly one a ∈ A. From a text categorization point of view, K is the training corpus and U is the test corpus. Let D K be the set of fandoms of texts in K. Then, all texts in U belong to a single (target) fandom d U / ∈ D K .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Data Set Construction</head><p>For this shared task, we have harvested a collection of fanfics and their associated metadata from the authoritative community platform Archive of Our Own, a project of the Organization for Transformative Works. <ref type="foot" coords="6,295.55,296.65,3.49,6.05" target="#foot_1">2</ref> We limited the material to fanfics in English (en), French (fr), Italian (it), Polish (pl), and Spanish (sp) that counted at least 500 tokens, according to the platform's own internal word count. Across all data sets, the 'Harry Potter -J. K. Rowling' fandom was typically the most frequent one. We therefore selected fics in this fandom as the test material and fics from all other fandoms as the training material. We included only material for authors that contributed at least one fic to the 'target fandom' and at least one fic to another, 'training fandom'. As such, the task was operationalized as a standard, closed-set attribution task, where all fics in the test material (belonging to the target fandom) had to be attributed to exactly one fan author in the training material.</p><p>For each language we constructed two separate data sets: a development set that participants could use to calibrate their system and an evaluation set on the final evaluation of the competing systems was evaluated (see Table <ref type="table" coords="6,337.12,441.78,3.60,8.64" target="#tab_0">1</ref>). Importantly there was no overlap in authors between the development set and the evaluation set (to discourage systems from overfitting on the characteristics of specific authors in the development material). To maximize the comparability of the data sets across languages, we randomly sampled 20 authors for each language and exactly 7 training texts (from non-target fandoms) for each author. No sampling was carried out in the test material of each attribution problem. In other words, in each attribution problem K is equally distributed over the authors while U is imbalanced. No files shorter than 500 tokens were included and to normalize the length of longer fics, we only included the middle 1,000 tokens of the text. Tokenization was done using NLTK's 'WordPunctTokenizer'. All texts were encoded as UTF8 plain text. To enrich the number of attribution problems in each language, random subsets of candidate authors (5, 10, or 15) were selected. For the early-bird evaluation phase, only the attribution problems with a maximal (20) number of candidate authors were used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Evaluation Framework</head><p>There are several evaluation measures that can be used for this closed-set multi-class and single-label classification task. Given that, in each attribution problem, the texts of unknown authorship are not equally distributed over the candidate authors, we decided to use the macro-averaged F1 score. Given an authorship attribution problem, for each candidate author, recall and precision of the provided answers are calculated and a F1 score (i.e., their harmonic mean) is provided. Then, the average F1 score over all candidate authors is used to estimate the performance of submissions for that attribution problem. Finally, submissions are ranked according to their mean macro-averaged F1 score over all available attribution problems. In addition, we also examine macroaveraged precision, macro-averaged recall, and micro-averaged accuracy to provide a more detailed view of submissions' performance.</p><p>Following the practice of previous PAN labs, software submissions were required. All submissions are deployed and evaluated in the TIRA experimentation platform <ref type="bibr" coords="7,461.50,282.70,15.27,8.64" target="#b34">[34]</ref>. Participants can apply their software to the evaluation data sets themselves. However, only PAN organizers can view the actual evaluation results. Moreover, the submitted software has no access to the internet during its run to avoid data leaks and to ensure a blind evaluation. Beyond evaluation measures, the runtime of submitted software is recorded.</p><p>To estimate the difficulty of a cross-domain authorship attribution problem and to provide a challenging baseline for participants, we developed a simple but quite effective approach already used in previous work for similar purposes <ref type="bibr" coords="7,410.48,378.34,15.77,8.64" target="#b38">[38,</ref><ref type="bibr" coords="7,429.05,378.34,12.45,8.64" target="#b37">37,</ref><ref type="bibr" coords="7,444.30,378.34,11.83,8.64" target="#b46">46]</ref>. This method is based on character n-gram features and a support vector machine (SVM) classifier. First, all character n-grams that appear at least f t times in the training (known authorship) texts of an attribution problem are extracted and used as features to represent both training and test texts. Then, an SVM with linear kernel is trained based on the training texts and can be used to predict the most likely author of the test texts. As shown in previous work, this simple model can be very effective in cross-domain conditions given that the number of features is appropriately defined for each specific attribution problem <ref type="bibr" coords="7,215.15,473.98,15.27,8.64" target="#b45">[45]</ref>. However, in this shared task, we use a simple version where the cutoff frequency threshold (i.e., practically, this defines the number of features) is the same for any attribution problem. More specifically, we use n = 3 (i.e., character trigrams) and f t = 5. This approach is called PAN18-BASELINE in the rest of this paper. A Python implementation of this approach<ref type="foot" coords="7,347.57,520.13,3.49,6.05" target="#foot_2">3</ref> has been released to enable participants experiment with its possible variations. This implementation makes use of the scikit-learn library <ref type="bibr" coords="7,210.44,545.71,16.60,8.64" target="#b32">[32]</ref> and its SVM classifier based on one-vs-rest strategy and C = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Survey of Submissions</head><p>We received 11 submissions from research teams from several countries (Austria, Brazil, Germany, Iran (2), Israel (2), Mexico, the Netherlands, Spain, and Switzerland). In addition, 9 out of 11 submitted approaches are described in working notes papers. Table <ref type="table" coords="7,159.12,631.39,4.98,8.64" target="#tab_1">2</ref> provides an overview of the received submissions and the PAN18-BASELINE. As can be seen, n-grams are the most popular type of features to represent texts in this task. More specifically, character and word n-grams are used by the majority of the participants. Martín dCR et al. also explore typed character n-grams <ref type="bibr" coords="8,410.85,394.12,16.60,8.64" target="#b37">[37]</ref> and function word n-grams <ref type="bibr" coords="8,194.09,406.08,15.27,8.64" target="#b44">[44]</ref>. Custódio and Paraboni apply text distortion <ref type="bibr" coords="8,396.03,406.08,16.60,8.64" target="#b46">[46]</ref> and then extract character n-grams to highlight the use of punctuation marks, numbers, and characters with diacritics (e.g., ó, é, etc). Part-of-speech (POS) n-grams are used by Gagala, Miller et al., and Yigal et al., while López-Anguita et al. report that they experimented with this type of features, but did not manage to include in their final submission. Other types of explored features are complexity measures <ref type="bibr" coords="8,350.22,465.85,15.27,8.64" target="#b24">[25]</ref>, word and sentence length, and lexical richness functions <ref type="bibr" coords="8,260.81,477.81,15.27,8.64" target="#b12">[13]</ref>. It has to be noted that the approach of Halvani and Graner makes use of text compression methods and does not extract concrete text representation features.</p><p>Several weighting/normalization schemes are used by the submitted approaches. TF and TF-IDF are the most popular. Martín dCR et al. prefer log-entropy while López-Anguita et al. apply L2-normalization. Only one approach is based on word embeddings <ref type="bibr" coords="8,159.47,549.54,15.27,8.64" target="#b41">[41]</ref>. In addition, some approaches also apply principal components analysis to extract a less sparse representation of reduced dimensionality <ref type="bibr" coords="8,381.41,561.49,10.79,8.64" target="#b5">[6,</ref><ref type="bibr" coords="8,394.69,561.49,11.83,8.64" target="#b12">13]</ref>.</p><p>Only one approach <ref type="bibr" coords="8,232.12,573.45,16.60,8.64" target="#b13">[14]</ref> follows the profile-based paradigm, where all available samples of known authorship by a candidate author are treated cumulatively <ref type="bibr" coords="8,445.79,585.40,15.27,8.64" target="#b42">[42]</ref>. All the other submitted methods follow the instance-based paradigm, where any text of known authorship is represented separately. The relatively small size of candidate author set in the attribution problems as well as the balanced distribution of training texts over the candidate authors have positively affected this preference for instance-based methods.</p><p>With respect to the classification method, the majority of submissions used support vector machines (SVM), an algorithm that is both efficient for limited number of classes and able to handle sparse representations of large dimensionality. Gagala explored the use of neural networks while Schaetti focused on a more sophisticated approach based on echo-state network-based reservoir computing, a deep learning algorithm that is easier to be trained in comparison to recurrent neural networks <ref type="bibr" coords="9,379.21,179.09,15.27,8.64" target="#b41">[41]</ref>. Halvani and Graner exploit the compression-based cosine similarity measure to estimate the most likely author. Finally, Custódio and Paraboni construct an ensemble of three simple models, each one based on logistic regression.</p><p>Each method has its parameters to be tuned, relevant to the type and number of used features, the applied weighting or normalization scheme, or the classifier hyperparameters. There are three basic approaches to do that. Some submitted methods that tune their parameters globally, for all available attribution problems in all languages <ref type="bibr" coords="9,165.91,274.73,10.79,8.64" target="#b5">[6,</ref><ref type="bibr" coords="9,180.18,274.73,12.45,8.64" target="#b13">14,</ref><ref type="bibr" coords="9,196.11,274.73,11.83,8.64" target="#b12">13]</ref>. Another approach tunes the submitted method for each language separately <ref type="bibr" coords="9,178.32,286.69,15.77,8.64" target="#b24">[25,</ref><ref type="bibr" coords="9,197.26,286.69,7.19,8.64" target="#b3">4]</ref>. Finally, a more detailed approach tunes (at least some) parameters for each attribution problem separately <ref type="bibr" coords="9,290.33,298.64,15.77,8.64" target="#b28">[28,</ref><ref type="bibr" coords="9,308.25,298.64,11.83,8.64" target="#b41">41]</ref>. Certainly, global and language-specific approaches are applied to a larger size of texts and attribution problems and they can extract more reliable statistics. On the other hand, local methods focus on the specific properties of a given attribution problem and they are not confused by irrelevant information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Evaluation Results</head><p>The results of the 11 submitted approaches and the baseline on the evaluation corpus are presented in Table <ref type="table" coords="9,229.87,405.38,3.74,8.64" target="#tab_2">3</ref>. Beyond macro F1 that is used to rank participants, macro precision, macro recall, and micro accuracy results as well as the total runtime cost are given. As can be seen, the winning submission of Custódio and Paraboni achieves the best scores across all evaluation measures. The ranking of the other approaches according to macro F1 roughly remains the same when other evaluation measures are considered. A notable exception is the approach of Yigal et al. which achieves the 3rdbest micro accuracy score while it is ranked 5th according to macro F1. This indicates an increased potential of that method to recognize majority authors in the test set (i.e., the authors with most unknown texts). For all approaches, macro recall is higher than macro precision. This can be explained by the presence of several candidate authors with very few (or just one) unknown text(s) in most of the attribution problems.</p><p>The majority of submissions <ref type="bibr" coords="9,267.21,536.89,11.62,8.64" target="#b5">(6)</ref> were able to surpass the baseline and another one was very close to it, according to the macro F1 ranking. The remaining 4 submissions were clearly outperformed by the baseline. Remarkably, simple approaches based on character/word n-grams and well-known classification algorithms <ref type="bibr" coords="9,413.57,572.75,10.79,8.64" target="#b5">[6,</ref><ref type="bibr" coords="9,427.25,572.75,13.28,8.64" target="#b28">28]</ref> are much more effective in this task than more sophisticated methods based on deep learning and linguistic analysis of texts <ref type="bibr" coords="9,241.52,596.66,10.79,8.64" target="#b7">[8,</ref><ref type="bibr" coords="9,254.96,596.66,11.83,8.64" target="#b41">41]</ref>. With respect to the total runtime cost of the submitted approaches, in general, the top-performing methods are also relatively fast. On the contrary, most of the methods that perform significantly lower than the baseline are also the least efficient ones.</p><p>Table <ref type="table" coords="9,174.66,644.48,4.98,8.64" target="#tab_3">4</ref> focuses on the macro F1 scores for all participants and the baseline when the subset of problems in each of the five available languages is examined. The overall top-performing submission by Custódio and Paraboni was also the most effective one for French and especially Spanish (with a remarkable difference from the second-best approach). Moreover, the method of Halvani and Graner achieved quite remarkable results for Italian in comparison to the rest of submissions. The most difficult cases appear to be the Polish ones while the highest average results are obtained for English and Spanish. Table <ref type="table" coords="10,173.53,573.14,4.98,8.64" target="#tab_4">5</ref> shows the performance (macro-averaged F1 score) of the submitted methods for a varying candidate set size (from 20 authors to 5 authors). For instance, when 20 authors are considered, all 5 attribution problems with that candidate set size in all languages are examined. Apparently, the overall top-performing method of Custódio and Paraboni remains the most effective one for each of the examined candidate set sizes. In most cases, the ranking of participants is very similar to their overall ranking. It's also remarkable that the PAN18-BASELINE is especially effective when there are As in previous PAN shared tasks, we have applied statistical significance testing to the attributions provided by the submitted approaches to assess to which extent the differences between their outputs are statistically meaningful. In authorship attribution, the distribution of class labels is often heavily skewed, simply unknown, or hard to estimate. This is why we resort to a non-parametric test known as approximate randomization testing <ref type="bibr" coords="11,182.47,417.21,15.27,8.64" target="#b30">[30]</ref>, which does not make any far-reaching assumptions about any underlying distributions. In Table <ref type="table" coords="11,250.22,429.17,4.98,8.64" target="#tab_5">6</ref> we present pairwise tests for all submitted approaches, where the predictions for all problems have been analyzed in terms of their respective F1-scores. The probabilities returned by the test (for 1,000 bootstrapped iterations) can be interpreted as the conventional p-values of one-sided, statistical tests: they indicate the probability of failing to reject the null hypothesis (H 0 ) that the classifiers do not output significantly different scores. We use a symbolic notation corresponding to the following thresholds: '=' (not significantly different: p &gt; 0.5), '*' (significantly different: p &lt; 0.05), '**' (very significantly different: p &lt; 0.01), '***' (highly significantly different: p &lt; 0.001). As can be seen from the table, the difference between submissions of a neighboring rank are typically less statistically meaningful, although it catches the eye that this is not true for the winner and its immediate runner-up in this edition (p = 0.183). Note however that the winner does realize a significant statistical difference with respect to all other participants, which is reassuring. Especially, the differences between the submissions which performed above the baseline seem less meaningful, adding to the relativity of the final rankings of these systems. Participants scoring below the baseline generally reach higher significance scores in comparison to those scoring above the baseline threshold, which attests to the competitiveness of the baseline in this edition.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Additional Analyses</head><p>We have conducted some additional analyses about the cross-fandom nature of the authorship attribution task. All attribution problems involved an attribution task where the unseen texts belonged to a target fandom ('Harry Potter -J.K. Rowling') that was not represented in the training data, which only contained so-called non-target or training fandoms. How did the variety in training fandoms for a particular problem affect the ultimate attribution performance for that author? In Figure <ref type="figure" coords="12,369.34,435.53,4.98,8.64">1</ref> (left) we plot the F1-score for each author individually, as a function of the number of distinct training fandoms which were available in the training material for that author. (Note that the total number of training texts per author was always kept stable inside a single problem.) The scores were calculated across all participant submissions, including the baseline. The application of a simple Pearson test to these results allows us to observe a mild (r = 0.2), yet statistically significant (p = 0.001) positive correlation: if more distinct training fandoms were available for an author, an author's F1-score for the test material benefited from this. This results are firmly in line with those of Sapkota et al., who, in the context of cross-topic authorship attribution, also 'demonstrated that training on diverse topics is better than training on a single topic' <ref type="bibr" coords="12,293.60,555.09,15.27,8.64" target="#b38">[38]</ref>. Finally, we explored the effect of the target fandom, i.e. the Harry Potter novel series by J.K. Rowling. Assuming that some of the authors of the target fandom could have been actively imitating Rowling's writing style, we hypothesized that this might have had an effect on the attribution results: i.e., if an author stayed very close to the style of the canon's author, this might have made it more difficult to identify the fan. Interestingly, the results reported in Figure <ref type="figure" coords="12,280.55,626.82,4.98,8.64">1</ref> (right) suggest that this was, perhaps somewhat surprisingly, not the case at all. For this analysis, we extracted a list of all 7 original Harry Potter chapters in the canon (original UK version published by Bloomsbury). We converted these into an L1-normalized bag-of-words model, capturing the relative frequencies of all character trigrams that appeared in at least 5 chapters. We represent Rowling's style in this analysis as the centroid for the resulting bag-of-words model (column-wise mean). Next, we converted all test fanfics using the same vectorizer and calculated the cosine distance between each test fanfic and Rowling's centroid. Next, we correlated this distance with the number of correct predictions for a test fanfic (across all participants), using Pearson's r. Interestingly, and in spite of the diversity in distances, no trend whatsoever is evident from this analysis (r = 0.027; p = 0.7). Interestingly, whether or not a fanfic stayed close to Rowling in writing style, thus did not have a clear effect on difficulty of the attribution task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Style Change Detection</head><p>The simple, yet challenging question to answer for the style change detection task is as follows: Given a document, is it written by a single author or by multiple authors? To be able to provide an answer, the document has to be intrinsically analyzed, i.e., changes of authorship have to be determined by capturing changes of writing styles. As it is irrelevant at this point to identify the exact change positions, the problem can also be tackled by applying a binary classification over the whole document. Therefore it is also possible to quantify the style of a whole document and to learn feature combinations which separate single-author documents from multi-author texts.</p><p>In this section, we present an overview of the style change detection task at PAN 2018. First, we describe the construction of the task's evaluation data set in detail, followed by an overview of its evaluation framework. Then we survey the submitted approaches and report on their evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Set Construction</head><p>Three distinct data sets for training (50%), validation (25%) and testing (25%) have been constructed, where the ground truth for the first two was provided up front to participants. All data sets are based on user posts from 15 heterogeneous sites of the Q&amp;A network StackExchange. <ref type="foot" coords="14,258.34,173.43,3.49,6.05" target="#foot_3">4</ref>Crawling The basis for the data sets has been crawled from the network<ref type="foot" coords="14,425.30,203.32,3.49,6.05" target="#foot_4">5</ref> as follows:</p><p>1. Choosing a site (e.g., programming, politics, sports or religion). In the following a site is referred to as topic. 2. Retrieving of the 20 most popular tags of the site (e.g., for politics the tags law, economy or european union are among the most popular ones). In the following a tag is referred to as subtopic. 3. For each subtopic, retrieving of the 30 authors which posted the most questions, as well as the 30 authors who provided the most answers with respect to this specific subtopic. 4. For each author and each subtopic, retrieving of all questions and answers.</p><p>Preprocessing Before the final data sets were compiled, all texts have been preprocessed and filtered. The following filtering steps have been applied for both answers and questions:</p><p>removal of very short texts (e.g., only a few words or symbols) removal of texts that have been edited by users other than the original author <ref type="foot" coords="14,456.55,404.57,3.49,6.05" target="#foot_5">6</ref>removal of external URLs removal of embedded images removal of code snippets (which is especially needed for the StackOverflow site) removal of bullet lists removal of block quotes removal of texts containing Arabic characters (especially needed for the Islam site) After applying these steps, most texts contain sufficiently long and well-formed sentences about a specific subtopic, without any HTML tags or other undesired content. In case the cleaning process shortened a document to less than three sentences, it was removed before creating the actual data set.</p><p>Compilation Using the cleaned questions and answers of users belonging to the same topic and subtopic, the final documents have been assembled by varying the parameters listed in Table <ref type="table" coords="14,196.05,587.56,3.74,8.64">7</ref>. For single-author documents, one or more texts of the same author have been used to create problems containing 300 to 1000 tokens. The compilation of Table <ref type="table" coords="15,202.01,115.83,3.36,8.06">7</ref>. Parameters for constructing the style change detection data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter</head><p>Value/s number of style changes 0-3 number of collaborating authors 1-3 document length 300-1000 tokens change positions at the end of / within paragraphs, mixed segment length distribution equalized / randomly two-authors distributions (A1-A2), (A1-A2-A1), (A1-A2-A1-A2) three-authors distributions (A1-A2-A3), (A1-A2-A1-A3), (A1-A2-A3-A1) (A2-A1-A3-A1) multi-author documents has been conducted by combining texts of multiple authors, where the number of authors, changes, segment lengths and author distributions have been varied. This way, 2980 training problems, 1492 validation problems, and 1352 test problems have been created, where for each data set the amount of documents containing style changes is equal to the number of documents containing no changes. A detailed view of the data set's statistics with respect to the parameters is shown in Table <ref type="table" coords="15,450.78,314.67,3.74,8.64" target="#tab_6">8</ref>. Concerning the topics, the number of problems are depicted in Table <ref type="table" coords="15,396.14,326.62,3.74,8.64" target="#tab_7">9</ref>. For each topic and subtopic, single-and multi-author problems are also equally represented. A complete list of subtopics appearing in each topic is shown in Table <ref type="table" coords="15,367.54,350.53,9.96,8.64" target="#tab_1">12</ref> in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Framework</head><p>The participants designed and optimized their approaches with the given, publicly available training and validation data sets described above. Performance could either be measured locally using the provided evaluation script, or by deploying the respective software to TIRA <ref type="bibr" coords="15,208.81,434.65,15.77,8.64" target="#b10">[11,</ref><ref type="bibr" coords="15,227.53,434.65,13.28,8.64" target="#b34">34]</ref> and running it against the respective data set. The test data set was not publicly available, so that the latter option was necessary in this case, i.e., participants submitted their final software and ran it against the test data, without seeing performance results. This way, no information other than that provided by the data set itself was available to participants. Participants were allowed to submit an unlimited number of runs on the test data, but were asked to select one specific run that to be be used for the final ranking and for all results presented in Section 4.4. To evaluate the performances of the approaches, their accuracy was measured, i.e., the portion of correctly predicted style change detection problems compared to the total number of problems. Three baselines were used for comparison:</p><p>1. rnd1-BASELINE: A guessing baseline that achieves 50% by default due to the balanced distribution of style changing and non-changing documents in the data set. 2. rnd2-BASELINE: An enhanced guessing baseline that exploits the data set's statistics document length and number of style changes. 3. C99-BASELINE: This baseline employs a commonly used text segmentation algorithm, namely the C99 algorithm proposed by Choi et al. <ref type="bibr" coords="15,382.62,620.57,10.58,8.64" target="#b4">[5]</ref>, since it is one of the few text segmentation algorithms capable of predicting the number of segments. We utilized this feature by predicting a style change if the algorithm found more than one segment, and no change otherwise. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Survey of Submissions</head><p>This year, 6 teams registered for the style change detection task, five of whom submitted their software to TIRA <ref type="bibr" coords="16,228.86,479.64,15.77,8.64" target="#b10">[11,</ref><ref type="bibr" coords="16,247.29,479.64,11.83,8.64" target="#b34">34]</ref>. In what follows, a short summary of each approach is given:</p><p>-Hosseinia and Mukherjee <ref type="bibr" coords="16,259.99,513.51,15.49,8.64" target="#b17">[18]</ref>: The main idea of this approach is to solely rely on the grammatical structure used by authors in order to detect style changes, i.e., no other lexical features like character or word n-grams are used. To compute corresponding features, first, the parse tree of each sentence of a given document is computed, which is further traversed and linearized. By doing so, the whole document is represented as a consecutive order of parse tree features, which are then fed into a recurrent neural network (RNN) based on the author's previous work on authorship verification <ref type="bibr" coords="16,244.21,597.20,15.27,8.64" target="#b16">[17]</ref>. In parallel, a second RNN is constructed of which the input is the parse tree feature representation of the reversed order of sentences of the document. Finally, multiple similarity metrics are computed to estimate the difference between the original and reversed order network representations, where a final softmax layer yields the style change prediction. -Khan <ref type="bibr" coords="17,175.77,358.49,15.49,8.64" target="#b22">[23]</ref>: Here, an algorithmic approach is utilized that operates on the sentencelevel. First, the document is split into sentences, for which groups of predefined sizes are formed. By using sliding windows, two consecutive sentence windows are then compared to each other, where exactly one sentence in the middle is shared among both groups. The comparison is based on a similarity function which operates on cooccurrences of word features. More specifically, stop words, most/least frequent words or word pairs, and punctuation frequencies are utilized. -Safin and Ogaltsov <ref type="bibr" coords="17,233.45,442.18,15.49,8.64" target="#b36">[36]</ref>: This approach utilizes an ensemble of three individual classifiers, each operating on different kinds of features. First, a random forest classifier is trained using 19 statistical text features including number of sentences, text length, and frequencies of unique words, punctuations, or letters. Second, a classifier is built from a 3,000-dimensional vector containing frequencies of character n-grams. Finally, a logistic regression classifier is trained from the frequencies of all word {1-6}-grams, resulting in a high-dimensional vector with over 3 million dimensions. Using optimized coefficients, a weighted linear combination of the three classifiers is formed, where a predefined threshold determines the final result. -Schaetti <ref type="bibr" coords="17,187.82,549.77,15.49,8.64" target="#b40">[40]</ref>: In this approach, a character-based convolutional neural network (CNN) is designed. Each document is represented as a fixed-sized vector of 12,000 consecutive characters which are fed into the network, i.e., into an embedding layer that reduces the dimension to 50 and captures context similarities of occurring characters in a multi-dimensional space. Subsequently, the second layer is composed of three different convolutional layers with 25 filters each to capture the most expressive patterns of 2-4 consecutive character 2-grams. After utilizing a max-pooling layer for each of the convolutional layers, a binary linear layer is finally used to predict the existence of style changes.  <ref type="bibr" coords="18,304.87,366.36,15.93,8.64" target="#b19">[20]</ref>) form the input for a logistic regression meta-classifier, which produces the final output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation Results</head><p>The overall performance results are depicted in Table <ref type="table" coords="18,354.91,428.13,8.30,8.64" target="#tab_8">10</ref>. With an accuracy of nearly 90%, Zlatkova et al. achieved the best result over all documents across all topics and subtopics. All approaches outperformed all baselines. With respect to runtime, the two best-performing approaches also needed significantly more time (due to the ensemble technique and parse tree generation, respectively), compared to the other participants who produced predictions within minutes for the roughly 1,300 documents in the test data set. Detailed results with respect to various parameters of the test data set are illustrated in Figure <ref type="figure" coords="18,172.61,523.77,3.74,8.64" target="#fig_3">2</ref>. Each sub-figure only show the C99-BASELINE, as it is the best-performing baseline and also the only one which is able to produce differentiated results for the individual text characteristics. As can be seen in Figure <ref type="figure" coords="18,363.19,547.68,7.93,8.64" target="#fig_3">2a</ref>, the three best performing approaches are stable to the amount of tokens contained in the problems, and only two approaches are sensitive to it. Concerning single-author and multi-author documents, the results are quite heterogeneous as depicted in Figure <ref type="figure" coords="18,356.51,583.55,8.04,8.64" target="#fig_3">2b</ref>. Zlatkova et al. and Ogaltsov et al. achieve similar results for both problem classes, whereas the other approaches as well as the baseline favor either of the two.</p><p>Figure <ref type="figure" coords="18,178.74,619.41,9.40,8.64" target="#fig_3">2c</ref> shows results for multi-author problems according to the type of author distribution. Interestingly, the simplest compilation A1-A2, i.e., two authors with one style change in between, is the most challenging type. In general, the performance seems to be related to the number of authors involved, i.e., the more authors, the better  the results. All submitted approaches are insensitive to the style change position as can be seen from Figure <ref type="figure" coords="19,220.62,616.92,8.30,8.64" target="#fig_3">2d</ref>. Thus, it is irrelevant for the respective algorithms if authors switch only at the end of paragraphs or anywhere else. Compared to the results of the previous year's style breach detection task <ref type="bibr" coords="19,306.44,640.83,16.60,8.64" target="#b50">[50]</ref> this can be seen as an enhancement, as With respect to the average number of tokens per author segment in multi-author documents, Figure <ref type="figure" coords="20,213.82,493.98,9.96,8.64" target="#fig_3">2d</ref> shows a clear tendency towards longer segments. That is, the more each author contributes to a document on average, the better the results get. Finally, Figure <ref type="figure" coords="20,187.55,517.89,8.30,8.64" target="#fig_3">2f</ref> shows the average accuracy of all submitted approaches (excluding the baseline) for each topic of the test data set. The results are quite homogeneous, yielding the best performance on average for politics and the worst for poker.</p><formula xml:id="formula_0" coords="19,150.68,276.36,143.44,98.29">,0 A 1 -A 2 A 1 -A 2 -A 1 A 1 -A 2 -A 1 -A 2 A 1 -A 2 -A 1 -A 3 A 1 -A 2 -A 3 A 1 -A 2 -A 3 -A 1 A 2 -A 1 -A 3 -A<label>1</label></formula><p>As a final performance analysis, Table <ref type="table" coords="20,309.13,553.76,9.96,8.64" target="#tab_10">11</ref> shows the accuracies achieved with respect to specific topics and subtopics. Here, the individual results for the on average 10 best-performing subtopics (upper part) as well as the 10 most problematic subtopics (lower part) are shown, where only subtopics containing at least eight documents have been considered. It can be seen that subtopics from various topics are represented, and that approaches achieve perfect accuracy for multiple subtopics. Remarkably, Zlatkova et al. reached the best performance for eight of the top subtopics, predicting 100% of the problems correctly for five of those subtopics. Moreover, for most of the worstperforming subtopics, at least one of the approaches achieved a good accuracy. Cross-domain authorship attribution studies a challenging, yet realistic scenario where the training and test texts belong to distinct domains. Fanfiction provides excellent material for this task since it enables significant control over the topic of texts. The number of received submissions for this task indicates there is a relatively large research community working on this field. In general, submissions that do not require a deep linguistic analysis of texts were found to be both the most effective and the most efficient ones. Heterogeneous ensembles of simple classifiers and compression models outperformed more sophisticated approaches based on deep learning. Furthermore, the candidate set size is inversely correlated with the attribution accuracy especially when more than 10 authors are considered, while the number of training fandoms positively affects the recognition accuracy of a candidate author.</p><p>With the relaxation of the style change detection task, we attracted not only more participants than before, but also rendered the task more tractable for them, as indicated by the the better performance scores achieved. On a novel data set created from a popular Q&amp;A network containing more than 4,000 problems, all participants managed to outperform the three baselines. To predict style changes, a rich set of features has been employed and exploited using various techniques ranging from machine learning ensembles to deep learning. Accuracies of up to nearly 90% over the whole data set and several individual results of 100% for specific topics indicate that the problem can be solved with a high precision. Consequently, the results represent a good starting point to further pursue the style change detection task in future PAN editions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="12,462.13,167.75,7.77,39.12;12,134.77,216.48,340.58,7.77;12,165.78,227.44,50.54,7.77;12,244.01,227.44,8.97,7.77;12,268.22,227.44,33.18,7.77;12,316.64,227.44,158.71,7.77;12,145.84,238.40,70.48,7.77;12,268.22,238.40,5.06,7.77;12,292.43,238.40,5.06,7.77;12,316.64,238.40,5.06,7.77;12,340.85,238.40,5.06,7.77;12,365.06,238.40,5.06,7.77;12,389.27,238.40,86.08,7.77;12,185.85,249.36,30.48,7.77;12,292.43,249.36,5.06,7.77;12,316.64,249.36,5.06,7.77;12,340.85,249.36,5.06,7.77;12,365.06,249.36,5.06,7.77;12,389.27,249.36,86.08,7.77;12,177.27,260.32,39.06,7.77;12,316.64,260.32,5.06,7.77;12,340.85,260.32,5.06,7.77;12,365.06,260.32,5.06,7.77;12,389.27,260.32,86.08,7.77;12,153.56,271.27,62.76,7.77;12,340.85,271.27,5.06,7.77;12,365.06,271.27,5.06,7.77;12,389.27,271.27,86.08,7.77;12,174.24,282.23,42.09,7.77;12,365.06,282.23,5.06,7.77;12,389.27,282.23,86.08,7.77;12,144.24,293.19,72.08,7.77;12,389.27,293.19,86.08,7.77;12,187.43,304.15,28.89,7.77;12,413.48,304.15,61.87,7.77;12,190.97,315.11,25.35,7.77;12,437.68,315.11,37.66,7.77;12,142.37,326.07,73.95,7.77;12,461.89,326.07,13.45,7.77"><head>Tabealhoje</head><label></label><figDesc>Custódio and Paraboni = *** *** *** *** *** *** *** *** *** **** *** *** Martín dCR et al. = = *** *** *** *** Miller et al. = *** *** *** *** PAN18-BASELINE *** *** *** *** Schaetti *** *** *** Gagala *** *** López-Anguita et al. ***</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="13,134.77,297.09,345.82,8.12;13,134.77,308.40,345.83,7.77;13,134.77,319.36,345.82,7.77;13,134.77,330.32,238.71,7.77"><head>7 Figure 1 .</head><label>71</label><figDesc>Figure1. Left: Effect of the number of distinct training fandoms available for an author on the F1-score for that author in the test material. Right: Effect of the stylistic similarity between a test fanfic and the target fandom's original author, J.K. Rowling, and the proportion of correct attributions for this fanfic. Interestingly, no trend can be discerned.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="19,134.77,568.23,345.82,8.12;19,134.77,579.53,69.99,7.77"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Detailed evaluation results of the style change detection approaches with respect to various parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,162.30,115.83,291.01,160.50"><head>Table 1 .</head><label>1</label><figDesc>The cross-domain authorship attribution corpus.</figDesc><table coords="6,162.30,134.41,291.01,141.92"><row><cell></cell><cell cols="2">Language Problems</cell><cell>Authors</cell><cell cols="3">Texts per author Text length</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">(subsets size) training</cell><cell>test</cell><cell>(avg. words)</cell></row><row><cell>Development</cell><cell>English French Italian Polish Spanish</cell><cell>2 2 2 2 2</cell><cell>5,20 5,20 5,20 5,20 5,20</cell><cell>7 7 7 7 7</cell><cell>1-22 1-10 1-17 1-21 1-21</cell><cell>795 796 795 800 832</cell></row><row><cell>Evaluation</cell><cell>English French Italian Polish</cell><cell>4 4 4 4</cell><cell>5,10,15,20 5,10,15,20 5,10,15,20 5,10,15,20</cell><cell>7 7 7 7</cell><cell>1-17 1-20 1-29 1-42</cell><cell>820 782 802 802</cell></row><row><cell></cell><cell>Spanish</cell><cell>4</cell><cell>5,10,15,20</cell><cell>7</cell><cell>1-24</cell><cell>829</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,134.77,115.83,345.83,234.95"><head>Table 2 .</head><label>2</label><figDesc>A survey of submissions (ranked alphabetically) to the cross-domain authorship attribution task. The following terms are abbreviated: instance-based (i-b), profile-based (p-b), language-specific (l-s), neural network (NN), Echo State Network (ESN), Support Vector Machine (SVM).</figDesc><table coords="8,134.94,167.63,344.84,169.63"><row><cell>Submission</cell><cell></cell><cell>Features</cell><cell>Weighting /</cell><cell cols="3">Paradigm Classifier Parameter</cell></row><row><cell>Team</cell><cell cols="2">Reference</cell><cell>Normalization</cell><cell></cell><cell></cell><cell>settings</cell></row><row><cell cols="3">Custódio and Paraboni[6] char &amp;</cell><cell>TF-IDF</cell><cell>i-b</cell><cell>ensemble</cell><cell>global</cell></row><row><cell></cell><cell></cell><cell>word n-grams</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Gagala</cell><cell></cell><cell cols="2">[8] various n-grams none</cell><cell>i-b</cell><cell>NN</cell><cell>global</cell></row><row><cell cols="3">Halvani and Graner [14] compression</cell><cell>none</cell><cell>p-b</cell><cell>similarity</cell><cell>global</cell></row><row><cell cols="3">López-Anguita et al. [25] complexity</cell><cell>L2-norm.</cell><cell>i-b</cell><cell>SVM</cell><cell>l-s</cell></row><row><cell cols="2">Martín dCR et al.</cell><cell cols="2">[4] various n-grams log-entropy</cell><cell>i-b</cell><cell>SVM</cell><cell>l-s</cell></row><row><cell>Miller et al.</cell><cell></cell><cell cols="2">[13] various n-grams TF-IDF</cell><cell>i-b</cell><cell>SVM</cell><cell>global</cell></row><row><cell></cell><cell></cell><cell>&amp; stylistic</cell><cell>&amp; TF</cell><cell></cell><cell></cell></row><row><cell>Murauer et al.</cell><cell></cell><cell>[28] char n-grams</cell><cell>TF-IDF</cell><cell>i-b</cell><cell>SVM</cell><cell>local</cell></row><row><cell cols="2">PAN18-BASELINE</cell><cell>char n-grams</cell><cell>TF</cell><cell>i-b</cell><cell>SVM</cell><cell>global</cell></row><row><cell>Schaetti</cell><cell></cell><cell>[41] tokens</cell><cell>embeddings</cell><cell>i-b</cell><cell>ESN</cell><cell>local</cell></row><row><cell>Yigal et al.</cell><cell></cell><cell cols="2">[13] various n-grams TF-IDF</cell><cell>i-b</cell><cell>SVM</cell><cell>global</cell></row><row><cell></cell><cell></cell><cell>&amp; stylistic</cell><cell>&amp; TF</cell><cell></cell><cell></cell></row></table><note coords="8,134.94,344.73,220.46,6.05"><p>Submissions without a working notes paper: Saeed Mosavat; Hadi Tabealhojeh</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,134.77,115.83,345.83,184.61"><head>Table 3 .</head><label>3</label><figDesc>Performance of submissions in the cross-domain authorship attribution task using several evaluation measures (ranking is based on macro F1).</figDesc><table coords="10,135.66,145.36,344.04,155.07"><row><cell>Submission</cell><cell>Macro</cell><cell>Macro</cell><cell>Macro</cell><cell>Micro</cell><cell>Runtime</cell></row><row><cell></cell><cell>F1</cell><cell>Precision</cell><cell>Recall</cell><cell>Accuracy</cell><cell></cell></row><row><cell>Custódio and Paraboni</cell><cell>0.685</cell><cell>0.672</cell><cell>0.784</cell><cell>0.779</cell><cell>00:04:27</cell></row><row><cell>Murauer et al.</cell><cell>0.643</cell><cell>0.646</cell><cell>0.741</cell><cell>0.752</cell><cell>00:19:15</cell></row><row><cell>Halvani and Graner</cell><cell>0.629</cell><cell>0.649</cell><cell>0.729</cell><cell>0.715</cell><cell>00:42:50</cell></row><row><cell>Mosavat</cell><cell>0.613</cell><cell>0.615</cell><cell>0.725</cell><cell>0.721</cell><cell>00:03:34</cell></row><row><cell>Yigal et al.</cell><cell>0.598</cell><cell>0.605</cell><cell>0.701</cell><cell>0.732</cell><cell>00:24:09</cell></row><row><cell>Martín dCR et al.</cell><cell>0.588</cell><cell>0.580</cell><cell>0.706</cell><cell>0.707</cell><cell>00:11:01</cell></row><row><cell>PAN18-BASELINE</cell><cell>0.584</cell><cell>0.588</cell><cell>0.692</cell><cell>0.719</cell><cell>00:01:18</cell></row><row><cell>Miller et al.</cell><cell>0.582</cell><cell>0.590</cell><cell>0.690</cell><cell>0.711</cell><cell>00:30:58</cell></row><row><cell>Schaetti</cell><cell>0.387</cell><cell>0.426</cell><cell>0.473</cell><cell>0.502</cell><cell>01:17:57</cell></row><row><cell>Gagala</cell><cell>0.267</cell><cell>0.306</cell><cell>0.366</cell><cell>0.361</cell><cell>01:37:56</cell></row><row><cell>López-Anguita et al.</cell><cell>0.139</cell><cell>0.149</cell><cell>0.241</cell><cell>0.245</cell><cell>00:38:46</cell></row><row><cell>Tabealhoje</cell><cell>0.028</cell><cell>0.025</cell><cell>0.100</cell><cell>0.111</cell><cell>02:19:14</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="10,137.08,316.72,341.19,162.69"><head>Table 4 .</head><label>4</label><figDesc>Authorship attribution evaluation results (macro F1) per language.</figDesc><table coords="10,137.08,335.30,341.19,144.11"><row><cell>Submission</cell><cell>Overall</cell><cell>English</cell><cell>French</cell><cell>Italian</cell><cell>Polish</cell><cell>Spanish</cell></row><row><cell>Custódio and Paraboni</cell><cell>0.685</cell><cell>0.744</cell><cell>0.668</cell><cell>0.676</cell><cell>0.482</cell><cell>0.856</cell></row><row><cell>Murauer et al.</cell><cell>0.643</cell><cell>0.762</cell><cell>0.607</cell><cell>0.663</cell><cell>0.450</cell><cell>0.734</cell></row><row><cell>Halvani and Graner</cell><cell>0.629</cell><cell>0.679</cell><cell>0.536</cell><cell>0.752</cell><cell>0.426</cell><cell>0.751</cell></row><row><cell>Mosavat</cell><cell>0.613</cell><cell>0.685</cell><cell>0.615</cell><cell>0.601</cell><cell>0.435</cell><cell>0.731</cell></row><row><cell>Yigal et al.</cell><cell>0.598</cell><cell>0.672</cell><cell>0.609</cell><cell>0.642</cell><cell>0.431</cell><cell>0.636</cell></row><row><cell>Martín dCR et al.</cell><cell>0.588</cell><cell>0.601</cell><cell>0.510</cell><cell>0.571</cell><cell>0.556</cell><cell>0.705</cell></row><row><cell>PAN18-BASELINE</cell><cell>0.584</cell><cell>0.697</cell><cell>0.585</cell><cell>0.605</cell><cell>0.419</cell><cell>0.615</cell></row><row><cell>Miller et al.</cell><cell>0.582</cell><cell>0.573</cell><cell>0.611</cell><cell>0.670</cell><cell>0.421</cell><cell>0.637</cell></row><row><cell>Schaetti</cell><cell>0.387</cell><cell>0.538</cell><cell>0.332</cell><cell>0.337</cell><cell>0.388</cell><cell>0.343</cell></row><row><cell>Gagala</cell><cell>0.267</cell><cell>0.376</cell><cell>0.215</cell><cell>0.248</cell><cell>0.216</cell><cell>0.280</cell></row><row><cell>López-Anguita et al.</cell><cell>0.139</cell><cell>0.190</cell><cell>0.065</cell><cell>0.161</cell><cell>0.128</cell><cell>0.153</cell></row><row><cell>Tabealhoje</cell><cell>0.028</cell><cell>0.037</cell><cell>0.048</cell><cell>0.014</cell><cell>0.024</cell><cell>0.018</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="11,134.77,115.83,345.82,238.29"><head>Table 5 .</head><label>5</label><figDesc>Performance (macro F1) of the cross-domain authorship attribution submissions per candidate set size.</figDesc><table coords="11,135.04,143.51,345.27,144.11"><row><cell>Submission</cell><cell>20 Authors</cell><cell>15 Authors</cell><cell>10 Authors</cell><cell>5 Authors</cell></row><row><cell>Custódio and Paraboni</cell><cell>0.648</cell><cell>0.676</cell><cell>0.739</cell><cell>0.677</cell></row><row><cell>Murauer et al.</cell><cell>0.609</cell><cell>0.642</cell><cell>0.680</cell><cell>0.642</cell></row><row><cell>Halvani and Graner</cell><cell>0.609</cell><cell>0.605</cell><cell>0.665</cell><cell>0.636</cell></row><row><cell>Mosavat</cell><cell>0.569</cell><cell>0.575</cell><cell>0.653</cell><cell>0.656</cell></row><row><cell>Yigal et al.</cell><cell>0.570</cell><cell>0.566</cell><cell>0.649</cell><cell>0.607</cell></row><row><cell>Martín dCR et al.</cell><cell>0.556</cell><cell>0.556</cell><cell>0.660</cell><cell>0.582</cell></row><row><cell>PAN18-BASELINE</cell><cell>0.546</cell><cell>0.532</cell><cell>0.595</cell><cell>0.663</cell></row><row><cell>Miller et al.</cell><cell>0.556</cell><cell>0.550</cell><cell>0.671</cell><cell>0.552</cell></row><row><cell>Schaetti</cell><cell>0.282</cell><cell>0.352</cell><cell>0.378</cell><cell>0.538</cell></row><row><cell>Gagala</cell><cell>0.204</cell><cell>0.240</cell><cell>0.285</cell><cell>0.339</cell></row><row><cell>López-Anguita et al.</cell><cell>0.064</cell><cell>0.065</cell><cell>0.195</cell><cell>0.233</cell></row><row><cell>Tabealhoje</cell><cell>0.012</cell><cell>0.015</cell><cell>0.030</cell><cell>0.056</cell></row></table><note coords="11,134.77,309.62,345.82,8.64;11,134.77,321.57,345.82,8.64;11,134.77,333.53,345.82,8.64;11,134.77,345.48,44.27,8.64"><p>only a few (5) authors. In general, the performance of submissions improves when the candidate set becomes smaller. However, it seems that the best-performing approaches are less accurate in problems with 5 candidate authors in comparison to problems with 10 authors.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="12,134.77,115.83,345.83,91.05"><head>Table 6 .</head><label>6</label><figDesc>Significance of pairwise differences in output between submissions, across all problems.</figDesc><table coords="12,227.32,132.92,218.38,73.96"><row><cell>Murauer et al.</cell><cell>Halvani and Graner</cell><cell>Mosavat</cell><cell>Yigal et al.</cell><cell>Martín dCR et al.</cell><cell>Miller et al.</cell><cell>PAN18-BASELINE</cell><cell>Schaetti</cell><cell>Gagala</cell><cell>López-Anguita et al.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="16,135.04,115.83,345.28,309.94"><head>Table 8 .</head><label>8</label><figDesc>Key figures of the style change detection data set regarding its construction parameters.</figDesc><table coords="16,135.18,134.41,345.00,291.36"><row><cell>Key figures</cell><cell></cell><cell>Training</cell><cell>Validation</cell><cell>Test</cell></row><row><cell>Number of documents:</cell><cell></cell><cell>2980 (100%)</cell><cell>1492 (100%)</cell><cell>1352 (100%)</cell></row><row><cell></cell><cell>1</cell><cell>1490 (50%)</cell><cell>746 (50%)</cell><cell>676 (50%)</cell></row><row><cell>Number of authors</cell><cell>2</cell><cell>872 (29%)</cell><cell>452 (30%)</cell><cell>384 (28%)</cell></row><row><cell></cell><cell>3</cell><cell>618 (21%)</cell><cell>294 (20%)</cell><cell>292 (22%)</cell></row><row><cell></cell><cell>300-500</cell><cell>476 (16%)</cell><cell>233 (16%)</cell><cell>203 (15%)</cell></row><row><cell>Document length</cell><cell>500-750</cell><cell>1012 (34%)</cell><cell>528 (35%)</cell><cell>450 (33%)</cell></row><row><cell>(tokens)</cell><cell>750-1000</cell><cell>1126 (38%)</cell><cell>555 (37%)</cell><cell>531 (39%)</cell></row><row><cell></cell><cell>&gt;1000</cell><cell>366 (12%)</cell><cell>176 (12%)</cell><cell>168 (12%)</cell></row><row><cell cols="2">Multi-authored-documents</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>A1-A2</cell><cell>360 (24%)</cell><cell>208 (28%)</cell><cell>149 (22%)</cell></row><row><cell></cell><cell>A1-A2-A1</cell><cell>299 (20%)</cell><cell>155 (21%)</cell><cell>131 (19%)</cell></row><row><cell>Author distribution</cell><cell>A1-A2-A1-A2 A1-A2-A1-A3</cell><cell>213 (14%) 30 (2%)</cell><cell>89 (12%) 23 (3%)</cell><cell>104 (15%) 18 (3%)</cell></row><row><cell></cell><cell>A1-A2-A3</cell><cell>525 (35%)</cell><cell>244 (33%)</cell><cell>240 (36%)</cell></row><row><cell></cell><cell>A1-A2-A3-A1</cell><cell>31 (2%)</cell><cell>14 (2%)</cell><cell>22 (3%)</cell></row><row><cell></cell><cell>A2-A1-A3-A1</cell><cell>32 (2%)</cell><cell>13 (2%)</cell><cell>12 (2%)</cell></row><row><cell></cell><cell>&lt; 200</cell><cell>149 (10%)</cell><cell>66 (9%)</cell><cell>71 (11%)</cell></row><row><cell>Average segment</cell><cell>200-300</cell><cell>806 (54%)</cell><cell>410 (55%)</cell><cell>385 (57%)</cell></row><row><cell>length (tokens)</cell><cell>300-400</cell><cell>408 (27%)</cell><cell>199 (27%)</cell><cell>163 (24%)</cell></row><row><cell></cell><cell>&gt; 400</cell><cell>127 (9%)</cell><cell>71 (10%)</cell><cell>57 (8%)</cell></row><row><cell></cell><cell>end of paragraph</cell><cell>526 (35%)</cell><cell>258 (35%)</cell><cell>255 (38%)</cell></row><row><cell>Change positions</cell><cell>within paragraphs</cell><cell>494 (33%)</cell><cell>229 (31%)</cell><cell>212 (31%)</cell></row><row><cell></cell><cell>mixed</cell><cell>470 (32%)</cell><cell>259 (35%)</cell><cell>209 (31%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="17,135.37,115.83,344.62,220.94"><head>Table 9 .</head><label>9</label><figDesc>Overview of the style change detection data set with respect to topics.</figDesc><table coords="17,135.37,133.64,344.62,203.13"><row><cell>Site</cell><cell cols="2">Training</cell><cell></cell><cell></cell><cell cols="2">Validation</cell><cell></cell><cell></cell><cell>Test</cell></row><row><cell></cell><cell>Problems</cell><cell cols="2">Authors</cell><cell></cell><cell>Problems</cell><cell cols="2">Authors</cell><cell></cell><cell>Problems</cell><cell>Authors</cell></row><row><cell></cell><cell></cell><cell>1</cell><cell>2</cell><cell>3</cell><cell></cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell>bicycles</cell><cell>160</cell><cell cols="3">80 47 33</cell><cell cols="4">82 41 28 13</cell><cell>70 35 27</cell><cell>8</cell></row><row><cell>christianity</cell><cell cols="4">358 179 107 72</cell><cell cols="4">176 88 48 40</cell><cell>172 86 45 41</cell></row><row><cell>gaming</cell><cell>178</cell><cell cols="3">89 47 42</cell><cell cols="4">86 43 23 20</cell><cell>78 39 21 18</cell></row><row><cell>history</cell><cell cols="4">354 177 104 73</cell><cell cols="4">178 89 54 35</cell><cell>170 85 46 39</cell></row><row><cell>islam</cell><cell>166</cell><cell cols="3">83 49 34</cell><cell cols="4">86 43 31 12</cell><cell>72 36 20 16</cell></row><row><cell>linguistics</cell><cell>144</cell><cell cols="3">72 46 26</cell><cell cols="4">72 36 22 14</cell><cell>64 32 12 20</cell></row><row><cell>meta</cell><cell>196</cell><cell cols="3">98 56 42</cell><cell cols="4">94 47 30 17</cell><cell>90 45 30 15</cell></row><row><cell>parenting</cell><cell>178</cell><cell cols="3">89 54 35</cell><cell cols="4">92 46 32 14</cell><cell>78 39 27 12</cell></row><row><cell>philosophy</cell><cell cols="4">468 234 146 88</cell><cell cols="4">232 116 63 53</cell><cell>224 112 65 47</cell></row><row><cell>poker</cell><cell>100</cell><cell cols="3">50 35 15</cell><cell cols="4">48 24 14 10</cell><cell>42 21 13</cell><cell>8</cell></row><row><cell>politics</cell><cell cols="4">204 102 57 45</cell><cell cols="4">102 51 34 17</cell><cell>90 45 22 23</cell></row><row><cell>project man.</cell><cell>104</cell><cell cols="3">52 24 28</cell><cell cols="4">50 25 12 13</cell><cell>44 22 14</cell><cell>8</cell></row><row><cell>sports</cell><cell>102</cell><cell cols="3">51 34 17</cell><cell cols="3">54 27 20</cell><cell>7</cell><cell>40 20 12</cell><cell>8</cell></row><row><cell>stackoverflow</cell><cell>112</cell><cell cols="3">56 23 33</cell><cell cols="4">60 30 16 14</cell><cell>48 24 12 12</cell></row><row><cell>writers</cell><cell>156</cell><cell cols="3">78 43 35</cell><cell cols="4">80 40 25 15</cell><cell>70 35 18 17</cell></row><row><cell></cell><cell cols="4">2980 1490 872 618</cell><cell cols="4">1492 746 452 294</cell><cell>1352 676 384 292</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="18,195.26,115.83,224.83,109.32"><head>Table 10 .</head><label>10</label><figDesc>Evaluation results of the style change detection task.</figDesc><table coords="18,218.03,133.64,179.29,91.51"><row><cell>Submission</cell><cell cols="2">Accuracy Runtime</cell></row><row><cell>Zlatkova et al.</cell><cell>0.893</cell><cell>01:35:25</cell></row><row><cell>Hosseinia and Mukherjee</cell><cell>0.825</cell><cell>10:12:28</cell></row><row><cell>Safin and Ogaltsov</cell><cell>0.803</cell><cell>00:05:15</cell></row><row><cell>Khan</cell><cell>0.643</cell><cell>00:01:10</cell></row><row><cell>Schaetti</cell><cell>0.621</cell><cell>00:03:36</cell></row><row><cell>C99-BASELINE</cell><cell>0.589</cell><cell>00:00:16</cell></row><row><cell>rnd2-BASELINE</cell><cell>0.560</cell><cell>-</cell></row><row><cell>rnd1-BASELINE</cell><cell>0.500</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="18,141.74,246.42,338.86,128.58"><head>-</head><label></label><figDesc>Zlatkova et al.<ref type="bibr" coords="18,213.83,246.81,15.49,8.64" target="#b52">[52]</ref>: At a glance, the authors rely on a rather sophisticated, hierarchical ensemble architecture (stacking) to solve the style change detection problem. Prior to building the ensemble, the texts are preprocessed by replacing URL's, file paths and very long words with special tokens, and also by splitting long hyphenated words. Moreover, each document is segmented into three fragments of equal lengths, and also sliding windows are utilized to increase the quantity of the assessed features. Using several distinct feature groups including lexical, syntactical, and other features, four different classifiers (e.g., SVM and random forest) are trained for each group, where a weighted model is subsequently computed for each feature group. These weighted models, in combination with a TF-IDF-based gradient boosting model (using LightGBM</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="20,134.76,115.83,346.14,362.88"><head>Table 11 .</head><label>11</label><figDesc>Evaluation results regarding selected subtopics containing eight or more documents.</figDesc><table coords="20,134.76,132.92,346.14,345.79"><row><cell></cell><cell>Subtopic (topic)</cell><cell>Docs.</cell><cell>C99-BASELINE</cell><cell>Hosseinia et al.</cell><cell>Khan</cell><cell>Ogaltsov et al.</cell><cell>Schaetti</cell><cell>Zlatkova et al.</cell><cell>Avg.</cell></row><row><cell></cell><cell>starcraft-2 (gaming)</cell><cell cols="8">12 0.67 0.83 0.92 1.00 1.00 0.92 0.93</cell></row><row><cell>Best 10 subtopics</cell><cell>political-history (history) history (christianity) halal-haram (islam) war (history) economy (politics) exegesis (christianity) prophet-muhammad (islam)</cell><cell cols="8">14 0.43 0.93 0.86 0.93 0.93 0.93 0.91 10 0.80 0.90 0.80 1.00 0.80 0.90 0.88 10 0.80 1.00 0.70 1.00 0.70 1.00 0.88 8 0.38 0.75 1.00 0.88 0.75 1.00 0.88 8 0.25 1.00 0.75 0.88 0.75 1.00 0.88 22 0.73 0.91 0.82 0.91 0.73 0.95 0.86 8 0.63 1.00 0.88 0.88 0.50 1.00 0.85</cell></row><row><cell></cell><cell>syntax (linguistics)</cell><cell cols="8">14 0.79 0.86 0.79 0.86 0.71 1.00 0.84</cell></row><row><cell></cell><cell>election (politics) . . .</cell><cell cols="8">10 0.60 0.80 0.90 0.90 0.70 0.90 0.84 . . . . . . . . . . . . . . . . . . . . . . . .</cell></row><row><cell></cell><cell>feature-request (meta)</cell><cell cols="8">20 0.45 0.75 0.60 0.75 0.60 0.80 0.70</cell></row><row><cell>Worst 10 subtopics</cell><cell>discipline (parenting) scrum (pm) ancient-rome (history) lds (christianity) fiction (writers) nature-of-god (christianity) english (linguistics) world-war-two (history)</cell><cell cols="8">10 0.30 0.90 0.70 0.50 0.60 0.80 0.70 14 0.93 0.93 0.43 0.79 0.57 0.79 0.70 12 0.42 0.83 0.67 0.75 0.25 0.92 0.68 14 0.43 0.71 0.57 0.79 0.50 0.71 0.66 14 0.36 0.86 0.36 0.93 0.29 0.86 0.66 12 0.75 0.75 0.50 0.67 0.42 0.83 0.63 8 0.50 0.75 0.63 0.50 0.63 0.50 0.60 26 0.62 0.73 0.42 0.54 0.46 0.81 0.59</cell></row><row><cell></cell><cell>support (meta)</cell><cell cols="8">10 0.40 0.70 0.50 0.60 0.40 0.70 0.58</cell></row><row><cell cols="10">those approaches showed clearly better results when authors changed only at paragraph</cell></row><row><cell cols="2">ends.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,144.73,645.05,124.94,7.77"><p>http://www.jamespotterseries.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="6,144.73,614.77,153.31,7.77"><p>https://github.com/radiolarian/AO3Scraper</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="7,144.73,651.03,228.26,7.77"><p>https://pan.webis.de/clef18/pan18-code/pan18-cdaa-baseline.py</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="14,144.73,619.14,94.66,7.77"><p>https://stackexchange.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="14,144.73,630.29,286.42,7.77"><p>using the StackExchange API, https://api.stackexchange.com, visited June 2018</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="14,144.73,641.44,335.86,7.77;14,144.73,652.40,274.18,7.77"><p>StackExchange allows questions and answers to be edited easily by any registered member, who may, e.g., correct spelling errors or reformulate texts to be more precise</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="21,154.69,430.55,324.44,7.77;21,154.68,441.51,311.12,7.77;21,154.68,452.47,154.39,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="21,238.91,430.55,240.22,7.77;21,154.68,441.51,44.51,7.77">Overview of the international authorship identification competition at PAN-2011</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="21,218.11,441.51,180.22,7.77">CLEF 2011 Labs and Workshop, Notebook Papers</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09-22">19-22 September 2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,154.69,462.83,321.35,7.77;21,154.68,473.79,271.83,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="21,353.25,462.83,122.79,7.77;21,154.68,473.79,76.31,7.77">Automatically profiling the author of an anonymous text</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="21,236.35,473.79,106.49,7.77">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="119" to="123" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,154.69,484.15,317.97,7.77;21,154.68,495.11,323.51,7.77;21,154.68,506.06,66.49,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="21,267.13,484.15,134.26,7.77">Cross-language authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bogdanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lazaridou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="21,419.12,484.15,53.54,7.77;21,154.68,495.11,306.02,7.77">Proceedings of the 9th International Conference on Language Resources and Evaluation, LREC 2014</title>
		<meeting>the 9th International Conference on Language Resources and Evaluation, LREC 2014</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2015" to="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,154.69,516.42,324.77,7.77;21,154.68,527.38,323.92,7.77;21,154.68,538.34,318.20,7.77;21,154.68,549.30,261.49,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="21,446.59,516.42,32.87,7.77;21,154.68,527.38,180.38,7.77">CIC-GIL Approach to Cross-domain Authorship Attribution</title>
		<author>
			<persName coords=""><forename type="first">Martín</forename><surname>Del Campo-Rodríguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gómez-Adorno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Batyrshin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="21,217.08,538.34,255.80,7.77;21,154.68,549.30,21.68,7.77">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="21,182.95,549.30,172.47,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,154.69,559.66,318.25,7.77;21,154.68,570.62,300.59,7.77;21,154.68,581.57,262.98,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="21,195.41,559.66,215.30,7.77">Advances in Domain Independent Linear Text Segmentation</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="21,429.11,559.66,43.83,7.77;21,154.68,570.62,300.59,7.77;21,154.68,581.57,37.79,7.77">Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference</title>
		<meeting>the 1st North American chapter of the Association for Computational Linguistics conference</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="26" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,154.69,591.93,325.90,7.77;21,154.68,602.89,303.83,7.77;21,154.68,613.85,320.92,7.77;21,154.68,624.81,80.53,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="21,255.37,591.93,209.81,7.77">EACH-USP Ensemble cross-domain authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">E</forename><surname>Custódio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Paraboni</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="21,344.92,602.89,113.59,7.77;21,154.68,613.85,163.89,7.77">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="21,325.15,613.85,150.46,7.77;21,154.68,624.81,19.77,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,154.69,635.17,308.83,7.77;21,154.68,646.13,315.70,7.77;21,154.68,657.08,222.76,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="21,272.48,635.17,191.04,7.77;21,154.68,646.13,61.03,7.77">OPI-JSA at CLEF 2017: Author Clustering and Style Breach Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Daniel Karaś</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sobecki</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="21,233.87,646.13,206.43,7.77">Working Notes Papers of the CLEF 2017 Evaluation Labs</title>
		<title level="s" coord="21,446.47,646.13,23.91,7.77;21,154.68,657.08,146.32,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<imprint>
			<date type="published" when="2017-09">Sep 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,154.69,119.96,292.30,7.77;22,154.68,130.92,303.83,7.77;22,154.68,141.88,320.92,7.77;22,154.68,152.84,80.53,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="22,196.96,119.96,234.41,7.77">Authorship attribution with neural networks and multiple features</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gagala</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="22,344.92,130.92,113.59,7.77;22,154.68,141.88,163.89,7.77">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="22,325.15,141.88,150.46,7.77;22,154.68,152.84,19.77,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,154.69,163.80,317.01,7.77;22,154.68,174.76,255.48,7.77" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="22,206.98,163.80,264.72,7.77;22,154.68,174.76,33.43,7.77">An improved algorithm for unsupervised decomposition of a multi-author document</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Giannella</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014-02">February 2014</date>
			<publisher>The MITRE Corporation</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Papers</note>
</biblStruct>

<biblStruct coords="22,154.69,185.71,316.04,7.77;22,154.68,196.67,206.37,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="22,232.50,185.71,206.32,7.77">Detecting stylistic inconsistencies in collaborative writing</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Glover</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="22,456.78,185.71,13.94,7.77;22,154.68,196.67,93.73,7.77">The New Writing Environment</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="147" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,154.69,207.63,293.08,7.77;22,154.68,218.59,318.89,7.77;22,154.68,229.55,318.27,7.77;22,154.68,240.51,256.21,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="22,278.34,207.63,169.44,7.77;22,154.68,218.59,182.43,7.77">Ousting Ivory Tower Research: Towards a Web Framework for Providing Experiments as a Service</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Burrows</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="22,249.57,229.55,223.39,7.77;22,154.68,240.51,128.24,7.77">International ACM Conference on Research and Development in Information Retrieval (SIGIR 12)</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Hersh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Callan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Maarek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-08">Aug 2012</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1125" to="1126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,154.69,251.47,315.14,7.77;22,154.68,262.43,169.58,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="22,278.70,251.47,158.54,7.77">Segmenting documents by stylistic character</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hirst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Marthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="22,442.94,251.47,26.89,7.77;22,154.68,262.43,81.42,7.77">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">04</biblScope>
			<biblScope unit="page" from="397" to="415" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,154.69,273.39,298.89,7.77;22,154.68,284.34,309.79,7.77;22,154.68,295.30,325.91,7.77;22,154.68,306.26,306.97,7.77;22,154.68,317.22,119.88,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="22,360.68,273.39,92.90,7.77;22,154.68,284.34,309.79,7.77;22,154.68,295.30,30.25,7.77">Cross-domain Authorship Attribution: Author Identification using char sequences, word unigrams, and POS-tags features)</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Hacohen-Kerner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yigal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Shayovitz</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="22,392.53,295.30,88.07,7.77;22,154.68,306.26,189.29,7.77">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="22,350.56,306.26,111.10,7.77;22,154.68,317.22,59.13,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,154.69,328.18,309.04,7.77;22,154.68,339.14,322.02,7.77;22,154.68,350.10,306.97,7.77;22,154.68,361.06,119.88,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="22,241.99,328.18,221.74,7.77;22,154.68,339.14,24.98,7.77">Cross-Domain Authorship Attribution Based on Compression Models</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Halvani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Graner</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="22,388.51,339.14,88.19,7.77;22,154.68,350.10,189.29,7.77">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="22,350.56,350.10,111.10,7.77;22,154.68,361.06,59.13,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,154.69,372.02,321.58,7.77;22,154.68,382.97,23.90,7.77" xml:id="b14">
	<monogr>
		<title level="m" coord="22,270.48,372.02,111.44,7.77">The Fan Fiction Studies Reader</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Hellekson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Busse</surname></persName>
		</editor>
		<imprint>
			<publisher>University of Iowa Press</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,154.69,393.93,293.46,7.77;22,154.68,404.89,162.64,7.77" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="22,205.73,393.93,192.51,7.77">The evolution of stylometry in humanities scholarship</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">I</forename><surname>Holmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="22,404.08,393.93,44.07,7.77;22,154.68,404.89,78.97,7.77">Literary and Linguistic Computing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="111" to="117" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,154.69,415.85,324.22,7.77;22,154.68,426.81,229.77,7.77" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="22,266.00,415.85,212.91,7.77;22,154.68,426.81,79.74,7.77">Experiments with neural networks for small and large scale authorship verification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hosseinia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.06456</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="22,154.69,437.77,305.82,7.77;22,154.68,448.73,325.74,7.77;22,154.68,459.69,292.54,7.77;22,154.68,470.65,168.19,7.77" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="22,266.00,437.77,194.51,7.77;22,154.68,448.73,63.03,7.77">Parallel Attention Recurrent Neural Network for Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hosseinia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="22,426.11,448.73,54.32,7.77;22,154.68,459.69,223.17,7.77">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="22,384.43,459.69,62.79,7.77;22,154.68,470.65,107.44,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,154.69,481.60,309.90,7.77;22,154.68,492.56,312.29,7.77;22,154.68,503.52,44.08,7.77" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="22,189.06,481.60,215.34,7.77">An overview of the traditional authorship attribution subtask</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="22,422.49,481.60,42.10,7.77;22,154.68,492.56,196.20,7.77">CLEF 2012 Evaluation Labs and Workshop, Online Working Notes</title>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">September 17-20, 2012 (2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,154.69,514.48,324.61,7.77;22,154.68,525.44,299.63,7.77;22,154.68,536.40,155.41,7.77" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="22,428.24,514.48,51.06,7.77;22,154.68,525.44,165.99,7.77">LightGBM: A highly efficient gradient boosting decision tree</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Finley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="22,338.25,525.44,116.06,7.77;22,154.68,536.40,69.21,7.77">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3149" to="3157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,154.69,547.36,294.13,7.77;22,154.68,558.32,248.18,7.77" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="22,365.39,547.36,83.42,7.77;22,154.68,558.32,102.06,7.77">Cross-genre authorship verification using unmasking</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Luyckx</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Crombez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="22,263.14,558.32,56.05,7.77">English Studies</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="340" to="356" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,154.69,569.28,318.78,7.77;22,154.68,580.23,177.70,7.77" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="22,197.76,569.28,202.83,7.77">Style breach detection: An unsupervised detection model</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="22,419.15,569.28,54.32,7.77;22,154.68,580.23,151.56,7.77">Working Notes Papers of the CLEF 2017 Evaluation Labs</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,154.69,591.19,322.97,7.77;22,154.68,602.15,312.53,7.77;22,154.68,613.11,302.36,7.77" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="22,197.76,591.19,171.10,7.77">A Model for Style Breach Detection at a Glance</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="22,252.28,602.15,214.93,7.77;22,154.68,613.11,62.55,7.77">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="22,223.81,613.11,172.47,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,154.69,624.07,302.53,7.77;22,154.68,635.03,303.92,7.77" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="22,314.49,624.07,142.73,7.77;22,154.68,635.03,80.96,7.77">Measuring differentiability: Unmasking pseudonymous authors</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Bonchek-Dokow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="22,241.47,635.03,139.44,7.77">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1261" to="1276" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,154.69,645.99,309.40,7.77;22,154.68,656.95,319.06,7.77" xml:id="b24">
	<monogr>
		<title level="m" type="main" coord="22,371.08,645.99,93.01,7.77;22,154.68,656.95,296.64,7.77">Complexity measures and POS n-grams for author identification in several languages: SINAI at PAN@CLEF</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>López-Anguita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Montejo-Ráez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">C</forename><surname>Díaz-Galiano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,154.68,119.96,316.04,7.77;23,154.68,130.92,320.92,7.77;23,154.68,141.88,80.53,7.77" xml:id="b25">
	<analytic>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="23,357.13,119.96,113.59,7.77;23,154.68,130.92,163.89,7.77">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="23,325.15,130.92,150.46,7.77;23,154.68,141.88,19.77,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,154.69,152.84,325.90,7.77;23,154.68,163.80,304.57,7.77;23,154.68,174.76,309.92,7.77" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="23,258.67,152.84,221.92,7.77;23,154.68,163.80,41.40,7.77">Authorship attribution and verification with many authors and limited data</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Luyckx</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="23,213.96,163.80,245.29,7.77;23,154.68,174.76,43.13,7.77">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,154.69,185.71,317.69,7.77;23,154.68,196.67,298.36,7.77;23,154.68,207.63,276.91,7.77;23,154.68,218.59,192.60,7.77" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="23,236.96,185.71,196.81,7.77">Investigating Topic Influence in Authorship Attribution</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mikros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Argiri</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-276" />
	</analytic>
	<monogr>
		<title level="m" coord="23,288.86,196.67,164.18,7.77;23,154.68,207.63,273.36,7.77">SIGIR 07 Workshop Workshop on Plagiarism Analysis, Authorship Identification, and Near-Duplicate Detection (PAN 07)</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Stein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Koppel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2007-07">Jul 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,154.69,229.55,318.75,7.77;23,154.68,240.51,320.35,7.77;23,154.68,251.47,315.70,7.77;23,154.68,262.43,168.19,7.77" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="23,308.23,229.55,165.21,7.77;23,154.68,240.51,81.01,7.77">Dynamic Parameter Search for Cross-Domain Authorship Attribution</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Murauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="23,443.88,240.51,31.16,7.77;23,154.68,251.47,246.33,7.77">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="23,407.59,251.47,62.79,7.77;23,154.68,262.43,107.44,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,154.69,273.39,296.56,7.77;23,154.68,284.34,304.72,7.77;23,154.68,295.30,23.90,7.77" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="23,414.66,273.39,36.59,7.77;23,154.68,284.34,138.45,7.77">Surveying stylometry techniques and applications</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Sundararajan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fatima</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Woodard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="23,298.88,284.34,93.53,7.77">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">36</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,154.69,306.26,310.04,7.77;23,154.68,317.22,101.62,7.77" xml:id="b30">
	<monogr>
		<title level="m" type="main" coord="23,210.13,306.26,251.02,7.77">Computer-Intensive Methods for Testing Hypotheses: An Introduction</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">W</forename><surname>Noreen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>John Wiley and Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,154.69,328.18,310.91,7.77;23,154.68,339.14,322.86,7.77;23,154.68,350.10,23.90,7.77" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="23,260.88,328.18,204.72,7.77;23,154.68,339.14,76.24,7.77">Blogs, twitter feeds, and reddit comments: Cross-domain authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Overdorf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Greenstadt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="23,236.45,339.14,174.60,7.77">Proceedings on Privacy Enhancing Technologies</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="155" to="171" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,154.69,361.06,316.00,7.77;23,154.68,372.02,315.24,7.77;23,154.68,382.97,322.31,7.77;23,154.68,393.93,192.98,7.77" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="23,299.67,382.97,144.73,7.77">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="23,450.59,382.97,26.40,7.77;23,154.68,393.93,110.80,7.77">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,154.69,404.89,304.23,7.77;23,154.68,415.85,296.48,7.77;23,154.68,426.81,325.83,7.77;23,154.68,437.77,172.57,7.77" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="23,386.82,404.89,72.10,7.77;23,154.68,415.85,180.34,7.77">Overview of the 3rd International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Eiselt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="23,353.18,415.85,97.98,7.77;23,154.68,426.81,321.61,7.77">Notebook Papers of the 5th Evaluation Lab on Uncovering Plagiarism, Authorship and Social Software Misuse (PAN)</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09">September 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,154.69,448.73,309.83,7.77;23,154.68,459.69,318.49,7.77;23,154.68,470.65,294.90,7.77;23,154.68,481.60,297.56,7.77;23,154.68,492.56,307.09,7.77;23,154.68,503.52,272.70,7.77" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="23,413.60,448.73,50.92,7.77;23,154.68,459.69,318.49,7.77;23,154.68,470.65,57.91,7.77">Improving the Reproducibility of PAN&apos;s Shared Tasks: Plagiarism Detection, Author Identification, and Author Profiling</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="23,259.54,481.60,192.71,7.77;23,154.68,492.56,307.09,7.77;23,154.68,503.52,37.80,7.77">Information Access Evaluation meets Multilinguality, Multimodality, and Visualization. 5th International Conference of the CLEF Initiative (CLEF 14)</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Lupu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hall</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Toms</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014-09">Sep 2014</date>
			<biblScope unit="page" from="268" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,154.69,514.48,319.51,7.77;23,154.68,525.44,323.70,7.77;23,154.68,536.40,135.57,7.77" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="23,250.07,514.48,207.64,7.77">Style Breach Detection with Neural Sentence Embeddings</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Safin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kuznetsova</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="23,154.68,525.44,206.43,7.77">Working Notes Papers of the CLEF 2017 Evaluation Labs</title>
		<title level="s" coord="23,367.29,525.44,111.10,7.77;23,154.68,536.40,59.13,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<imprint>
			<date type="published" when="2017-09">Sep 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,154.69,547.36,323.61,7.77;23,154.68,558.32,325.91,7.77;23,154.68,569.28,325.26,7.77" xml:id="b36">
	<analytic>
		<title level="a" type="main" coord="23,240.34,547.36,167.20,7.77">Detecting a change of style using text statistics</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Safin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ogaltsov</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="23,289.00,558.32,191.59,7.77;23,154.68,569.28,85.46,7.77">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="23,246.72,569.28,172.47,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,154.69,580.23,312.51,7.77;23,154.68,591.19,311.12,7.77;23,154.68,602.15,298.11,7.77;23,154.68,613.11,156.26,7.77" xml:id="b37">
	<analytic>
		<title level="a" type="main" coord="23,334.50,580.23,132.69,7.77;23,154.68,591.19,140.00,7.77">Not all character n-grams are created equal: A study in authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Sapkota</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Solorio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="23,312.41,591.19,153.39,7.77;23,154.68,602.15,298.11,7.77;23,154.68,613.11,83.68,7.77">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="93" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,154.69,624.07,298.38,7.77;23,154.68,635.03,288.84,7.77;23,154.68,645.99,300.08,7.77" xml:id="b38">
	<analytic>
		<title level="a" type="main" coord="23,371.62,624.07,81.44,7.77;23,154.68,635.03,141.42,7.77">Cross-topic authorship attribution: Will out-of-topic data help?</title>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Sapkota</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Solorio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="23,310.55,635.03,132.98,7.77;23,154.68,645.99,214.18,7.77">Proceedings of the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>the 25th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1228" to="1237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,154.69,119.96,297.34,7.77;24,154.68,130.92,325.91,7.77;24,154.68,141.88,280.68,7.77" xml:id="b39">
	<analytic>
		<title level="a" type="main" coord="24,370.85,119.96,81.18,7.77;24,154.68,130.92,241.38,7.77">Domain adaptation for authorship attribution: Improved structural correspondence learning</title>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Sapkota</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Solorio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="24,413.94,130.92,66.66,7.77;24,154.68,141.88,254.54,7.77">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,154.69,152.84,313.96,7.77;24,154.68,163.80,323.26,7.77;24,154.68,174.76,315.70,7.77;24,154.68,185.71,168.19,7.77" xml:id="b40">
	<analytic>
		<title level="a" type="main" coord="24,201.50,152.84,267.15,7.77;24,154.68,163.80,83.70,7.77">UniNE at CLEF 2018: Character-based Convolutional Neural Network for Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Schaetti</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="24,446.78,163.80,31.16,7.77;24,154.68,174.76,246.33,7.77">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="24,407.59,174.76,62.79,7.77;24,154.68,185.71,107.44,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,154.69,196.67,317.75,7.77;24,154.68,207.63,317.10,7.77;24,154.68,218.59,306.47,7.77;24,154.68,229.55,233.22,7.77" xml:id="b41">
	<analytic>
		<title level="a" type="main" coord="24,201.50,196.67,270.94,7.77;24,154.68,207.63,133.57,7.77">UniNE at CLEF 2018: Echo State Network-based Reservoir Computing for Cross-domain Authorship Attribution</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Schaetti</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="24,177.09,218.59,279.73,7.77">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="24,154.68,229.55,172.47,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,154.69,240.51,302.39,7.77;24,154.68,251.47,285.25,7.77" xml:id="b42">
	<analytic>
		<title level="a" type="main" coord="24,210.97,240.51,190.36,7.77">A Survey of Modern Authorship Attribution Methods</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="24,407.77,240.51,49.31,7.77;24,154.68,251.47,212.03,7.77">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="538" to="556" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,154.69,262.43,296.85,7.77;24,154.68,273.39,311.17,7.77;24,154.68,284.34,287.45,7.77" xml:id="b43">
	<analytic>
		<title level="a" type="main" coord="24,210.97,262.43,225.07,7.77">Intrinsic Plagiarism Detection Using Character n-gram Profiles</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="24,154.68,273.39,311.17,7.77;24,154.68,284.34,108.42,7.77">Notebook Papers of the 5th Evaluation Lab on Uncovering Plagiarism, Authorship and Social Software Misuse (PAN)</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09">September 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,154.69,295.30,316.94,7.77;24,154.68,306.26,242.42,7.77" xml:id="b44">
	<analytic>
		<title level="a" type="main" coord="24,210.97,295.30,160.58,7.77">Plagiarism detection using stopword n-grams</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="24,377.75,295.30,93.89,7.77;24,154.68,306.26,145.29,7.77">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2512" to="2527" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,154.69,317.22,306.69,7.77;24,154.68,328.18,200.44,7.77" xml:id="b45">
	<analytic>
		<title level="a" type="main" coord="24,210.97,317.22,250.41,7.77;24,154.68,328.18,27.22,7.77">On the robustness of authorship attribution based on character n-gram features</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="24,187.55,328.18,94.36,7.77">Journal of Law and Policy</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="421" to="439" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,154.69,339.14,311.51,7.77;24,154.68,350.10,311.79,7.77;24,154.68,361.06,325.47,7.77" xml:id="b46">
	<analytic>
		<title level="a" type="main" coord="24,210.97,339.14,152.53,7.77">Authorship attribution using text distortion</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="24,381.28,339.14,84.92,7.77;24,154.68,350.10,308.26,7.77">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1138" to="1149" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="24,154.69,372.02,302.40,7.77;24,154.68,382.97,111.53,7.77" xml:id="b47">
	<analytic>
		<title level="a" type="main" coord="24,210.97,372.02,242.83,7.77">Masking topic-related information to enhance authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="24,154.68,382.97,27.86,7.77">JASIST</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="461" to="473" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,154.69,393.93,308.87,7.77;24,154.68,404.89,322.70,7.77;24,154.68,415.85,306.50,7.77;24,154.68,426.81,202.56,7.77" xml:id="b48">
	<analytic>
		<title level="a" type="main" coord="24,203.01,404.89,201.30,7.77">Clustering by Authorship Within and Across Documents</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1609/" />
	</analytic>
	<monogr>
		<title level="m" coord="24,423.07,404.89,54.32,7.77;24,154.68,415.85,149.87,7.77">Working Notes Papers of the CLEF 2016 Evaluation Labs</title>
		<title level="s" coord="24,310.73,415.85,150.46,7.77;24,154.68,426.81,19.77,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<imprint>
			<date type="published" when="2016-09">Sep 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,154.69,437.77,325.87,7.77;24,154.68,448.73,289.85,7.77;24,154.68,459.69,257.24,7.77" xml:id="b49">
	<analytic>
		<title level="a" type="main" coord="24,260.53,437.77,220.03,7.77;24,154.68,448.73,32.03,7.77">Countering Plagiarism by Exposing Irregularities in Authors&apos; Grammar</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="24,205.73,448.73,238.80,7.77;24,154.68,459.69,70.37,7.77">Proceedings of the European Intelligence and Security Informatics Conference (EISIC)</title>
		<meeting>the European Intelligence and Security Informatics Conference (EISIC)<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013-08">August 2013</date>
			<biblScope unit="page" from="15" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,154.69,470.65,308.87,7.77;24,154.68,481.60,302.68,7.77;24,154.68,492.56,310.14,7.77;24,154.68,503.52,297.80,7.77;24,154.68,514.48,224.30,7.77;24,154.68,525.44,101.86,7.77" xml:id="b50">
	<analytic>
		<title level="a" type="main" coord="24,203.01,481.60,254.35,7.77;24,154.68,492.56,115.94,7.77">Overview of the Author Identification Task at PAN-2017: Style Breach Detection and Author Clustering</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1866/" />
	</analytic>
	<monogr>
		<title level="m" coord="24,177.09,503.52,206.43,7.77">Working Notes Papers of the CLEF 2017 Evaluation Labs</title>
		<title level="s" coord="24,389.69,503.52,62.79,7.77;24,154.68,514.48,42.23,7.77;24,241.17,514.48,59.13,7.77">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Mandl</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2017-09">Sep 2017</date>
			<biblScope unit="volume">1866</biblScope>
		</imprint>
	</monogr>
	<note>CLEF and CEUR</note>
</biblStruct>

<biblStruct coords="24,154.69,536.40,324.67,7.77;24,154.68,547.36,313.27,7.77;24,154.68,558.32,258.11,7.77" xml:id="b51">
	<analytic>
		<title level="a" type="main" coord="24,294.90,536.40,184.47,7.77;24,154.68,547.36,220.43,7.77">A framework for authorship identification of online messages: Writing-style features and classification techniques</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="24,381.05,547.36,86.90,7.77;24,154.68,558.32,174.43,7.77">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="378" to="393" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,154.69,569.28,325.90,7.77;24,154.68,580.23,304.86,7.77;24,154.68,591.19,303.83,7.77;24,154.68,602.15,320.92,7.77;24,154.68,613.11,80.53,7.77" xml:id="b52">
	<analytic>
		<title level="a" type="main" coord="24,469.63,569.28,10.96,7.77;24,154.68,580.23,288.94,7.77">An Ensemble-Rich Multi-Aspect Approach Towards Robust Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zlatkova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kopev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mitov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Atanasov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hardalov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Koychev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="24,344.92,591.19,113.59,7.77;24,154.68,602.15,163.89,7.77">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="24,325.15,602.15,150.46,7.77;24,154.68,613.11,19.77,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
