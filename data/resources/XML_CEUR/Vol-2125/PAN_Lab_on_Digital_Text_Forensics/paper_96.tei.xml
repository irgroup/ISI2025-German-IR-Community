<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,180.45,115.90,254.46,12.90;1,246.58,133.83,122.20,12.90;1,223.43,153.68,168.50,10.75">A Straightforward Multimodal Approach for Author Profiling Notebook for PAN at CLEF 2018</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,204.98,190.08,77.46,8.64"><forename type="first">Mario</forename><forename type="middle">Ezra</forename><surname>Aragón</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Engineering</orgName>
								<orgName type="institution">Universidad Autónoma de Chihuahua</orgName>
								<address>
									<addrLine>Chihuahua, Chih</addrLine>
									<postCode>31100</postCode>
									<region>México</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,306.27,190.08,99.64,8.64"><forename type="first">A</forename><surname>Pastor López-Monroy</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Houston</orgName>
								<address>
									<postCode>77004</postCode>
									<settlement>Houston TX</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,180.45,115.90,254.46,12.90;1,246.58,133.83,122.20,12.90;1,223.43,153.68,168.50,10.75">A Straightforward Multimodal Approach for Author Profiling Notebook for PAN at CLEF 2018</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">45F2F6A9248AE7FC712D56113329EBB2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Author Profiling</term>
					<term>Bag of Words</term>
					<term>CNN</term>
					<term>Text Classification</term>
					<term>Text Mining</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we evaluate different strategies from the literature for text and image classification at PAN 2018. The main objective of this shared task is the identification of the gender of different users by using tweets and images posted. We evaluate four popular strategies for the text representation: 1) Bag of Terms (BoT), 2) Second Order Attributes (SOA) representation, 3) Convolutional Neural Network (CNN) models and 4) an Ensemble of n-grams at word and character level. For the image representation we used a Convolutional Neural Network (CNN) based on <ref type="bibr" coords="1,223.59,368.91,9.52,7.77" target="#b5">[6]</ref>. We observed that the n-grams Ensemble presented the highest performance. For our participation we chose the Ensemble and perform an early fusion with the image representation to create a multimodal representation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Author Profiling (AP) is a common and well know task in Natural Language Processing (NLP), that consists in extracting all the possible information from an author's document <ref type="bibr" coords="1,157.75,501.02,15.27,8.64" target="#b10">[11]</ref>. The AP could help in different problems such as the detection of a person of interest, security, prevention, political opinion, business intelligence, etc. The PAN 2018 shared task has the objective of tackling this problem using machine learning and NLP techniques. The main objective is to identify the gender's user with the novelty of considering posted tweets and images as new information. The shared task has three different languages: English, Spanish and Arabic. In this work we separately evaluate the AP in three modalities: Textual, Visual and Textual-Visual. For the textual modality, we mainly evaluate what should be the de facto baseline: a huge ensemble of n-gram histograms at word and character level. Then, we compare this approach with three strategies: Bag-of-Terms <ref type="bibr" coords="1,417.10,608.62,10.58,8.64" target="#b2">[3]</ref>, Second Order Attributes <ref type="bibr" coords="1,193.37,620.57,11.62,8.64" target="#b3">[4]</ref> and CNNs <ref type="bibr" coords="1,253.61,620.57,10.58,8.64" target="#b4">[5]</ref>. The core idea behind our evaluation is to determine which approach captures better the thematic content, which according to the literature has been the cornerstone to effectively profile users <ref type="bibr" coords="1,350.10,644.48,16.00,8.64" target="#b10">[11,</ref><ref type="bibr" coords="1,366.09,644.48,12.00,8.64" target="#b12">13,</ref><ref type="bibr" coords="1,378.09,644.48,12.00,8.64" target="#b13">14]</ref>. Regarding to the visual modality, we only evaluate one very simple, yet effective, CNN based method.</p><p>For this visual approach, we extracted the category layer from the VGG16 <ref type="bibr" coords="2,435.80,119.31,11.62,8.64" target="#b5">[6]</ref> and use it as features with a SVM on the top. Then, a set of images belonging to the same users are averaged. Intuitively this approach exploits the posting behavior of users <ref type="bibr" coords="2,461.50,143.22,15.27,8.64" target="#b11">[12]</ref>, where the idea is to capture the visual content that is being posted by users. The intuition is that such visual content is significantly different between males and females, thus highly discriminative. This is somewhat analogous to observe the thematic content when classifying documents. Finally for the Textual-Visual modality, we bring together the textual-visual thematic into a single approach. For this we performed an early fusion to combine our multiple histograms of n-grams and the features extracted from the VGG16; this is precisely our submitted approach to PAN18.</p><p>The remainder of this paper is at follows: Section 2 presents some of the AP related work. In Section 3 we described the different strategies that we evaluated for the text representation. Section 4 describes our approach for the image representation. In Section 5 is described the multimodal representation and how was created. Section 6 and 7 describes the Experimental Settings and a description of the Experimental Results. Finally Section 8 include our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In this section we present a review of AP related work that have been proposed to handle this task. There are different methods: from a simple representations like removing stopwords and creating a Bag of Terms <ref type="bibr" coords="2,302.05,381.47,16.60,8.64" target="#b16">[17]</ref> to a more complex representations using traditional word embeddings <ref type="bibr" coords="2,270.99,393.42,16.60,8.64" target="#b19">[20]</ref> or embeddings exploiting the morphology and semantics of the words <ref type="bibr" coords="2,230.10,405.38,15.27,8.64" target="#b20">[21]</ref>. In <ref type="bibr" coords="2,263.15,405.38,16.60,8.64" target="#b18">[19]</ref> the authors proposed a simple method of classification based on the similarity between the objects; they consider different terms used in the texts that corresponds to a user's tweets. Other approach is to extract groups of terms that are presented in the tweets <ref type="bibr" coords="2,287.10,441.24,15.77,8.64" target="#b12">[13,</ref><ref type="bibr" coords="2,302.87,441.24,11.83,8.64" target="#b21">22]</ref>, where the authors also used extra information like emojis, document sentiment, POS tags, etc. In these approaches the authors found that including the extra information like emojis or POS tags do not improve the performance. Another popular approach is to address the problem as a profile based problem <ref type="bibr" coords="2,454.03,489.06,15.18,8.64" target="#b17">[18,</ref><ref type="bibr" coords="2,469.20,489.06,7.59,8.64" target="#b3">4]</ref>, where they create targets of profiles and groups of subprofiles for each user's tweets. In <ref type="bibr" coords="2,146.40,512.97,16.60,8.64" target="#b15">[16]</ref> authors built a system where they used a combination of different classifiers, with the objective of identified the behavior of different users. There are also some approaches that handle this task using relative new approaches like deep learning. For instance in <ref type="bibr" coords="2,180.39,548.84,16.60,8.64" target="#b20">[21]</ref> the authors generate embeddings representations that are classified using deep averaging networks. This model receives as input the word embeddings and the first layer average those embeddings, the next hidden layers transform the computed average. In <ref type="bibr" coords="2,208.17,584.71,16.60,8.64" target="#b22">[23]</ref> the authors used a deep learning model based on CNNs using a matrix of 2-grams of letters with punctuation marks as features. These deep learning approaches got an accuracy above the average results for the task. When we talk about visual and multimodal for AP, these approaches have been less studied in comparison with text approaches. For the visual modality approach, the authors had focused their research on gender recognition task <ref type="bibr" coords="2,383.73,644.48,16.00,8.64" target="#b23">[24,</ref><ref type="bibr" coords="2,399.73,644.48,12.00,8.64" target="#b24">25,</ref><ref type="bibr" coords="2,411.73,644.48,12.00,8.64" target="#b25">26]</ref>, where some general statistics have been considered using the images as features. For the multimodal approach, is a type of strategy that has just recently been explored <ref type="bibr" coords="3,399.80,119.31,15.27,8.64" target="#b26">[27]</ref>. In <ref type="bibr" coords="3,432.17,119.31,16.60,8.64" target="#b27">[28]</ref> authors used a image and text weighted strategy for gender classification. Their idea consist using a CNN for determining a score related to a user's image, and they combined this information with textual features and average the score. In this work, inspired in the related work we attempt to evaluate different approaches (see Section 3) and select the best one for the test data presented for the task. We proposed to bring an early fusion from the textual and visual features for our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Textual Modality Strategies</head><p>In this section we described the different strategies that we select from the literature for the textual representation. All these representations have resolved and got remarkable performance in different NLP classification tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Bag of Terms (BoT)</head><p>The bag of terms is the most simple and well know strategy for text representation where the text is described by the occurrence of words within a documents, i)the first step is the creation of a vocabulary form training data and then ii) the presence of the words are measure by its frequency <ref type="bibr" coords="3,251.18,358.46,10.58,8.64" target="#b2">[3]</ref>. This representation is an histogram thus it ignores the structure of the words, accounting only the occurrence of the words in the document and not the position or order in it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Second Order Attributes (SOA)</head><p>In this representation the document vectors are build in a space of profiles. Where each value in the vector represents the relationship that exist between each document with each target profile and subprofiles <ref type="bibr" coords="3,272.08,457.11,10.58,8.64" target="#b3">[4]</ref>. This representation has the objective of dividing the profiles using a clustering algorithm to create several subprofiles. First is needed to capture the relation of each term with the profiles. Then compute the term vector in a profile's space, it creates a term vectors of the terms that are contained in the document. Lastly they are weighted by the relative frequency of the term contained in the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">CNN Models</head><p>For this strategy we used CNN models that are based on <ref type="bibr" coords="3,369.58,567.72,10.58,8.64" target="#b4">[5]</ref>, we used three different training techniques for the models:</p><p>-CNN-Rand: This model tested is where we randomly initialized all weights and then are modified during the training phase..</p><p>-CNN-Static: Where this model uses word embedding vectors to initialize the embedding layer. During the training the weights of the embedding are kept fixed so they are not modified.</p><p>-CNN-NonStatic: This model is similar as the previous one, but we allowed to change the embedding weights during training.</p><p>We used filter windows of size 3,4 and 5 with 100 feature maps for each one, a dropout rate of 0.5, and stochastic gradients descent for training over shuffled mini-batches. We used pre-trained word vectors with a dimensionality 300, word vectors were obtained using word2vec <ref type="bibr" coords="4,200.37,183.57,16.60,8.64" target="#b9">[10]</ref> for English and FastText <ref type="bibr" coords="4,319.74,183.57,11.62,8.64" target="#b8">[9]</ref> for Spanish and Arabic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">N-Grams Subspaces for Author Profiling</head><p>The first step for our approach is the creation of the representation from the text. We proposed a method that has two stages for the creation: i) extract n-grams of size one to four at word level and size two to five at character level, ii) then we select the best n-grams using chi 2 distribution applied to each group and then concatenate the best selected n-grams from each group, as shows in Figure <ref type="figure" coords="4,352.65,274.21,4.98,8.64" target="#fig_0">1</ref> we can see the overall process of extraction and creation of the n-grams. In the following lines we explain the main two stages.</p><p>Extract n-grams The first step for our approach is to create the group of n-grams <ref type="bibr" coords="4,458.61,324.52,11.62,8.64" target="#b1">[2]</ref> of size one to four for the word level and two to five for the character level. To extract the n-grams we have three steps i) first we represent the documents using the occurrences of the group of words in the document, ii) then each group of terms vectors are normalize and iii) smoothing the weights of each group by the inverse document frequency adding one to document frequencies, preventing zero divisions as if every terms was seen in other document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CHI2 distribution</head><p>The second stage of this approach is the selection of the best features of each group of n-grams, we used the chi 2 distribution X 2 k <ref type="bibr" coords="4,397.37,434.60,11.62,8.64" target="#b0">[1]</ref> for this selection. When using this function we select the features that are the most likely to be relevant for the detection of the gender. The second step of our approach is the feature extraction of the images. Each user has 10 images that they post in the social media. We use a well know state-of-the-art model in <ref type="bibr" coords="5,146.11,167.81,11.62,8.64" target="#b5">[6]</ref> with pre-trained weights on ImageNet. We used the last layer (the class layer with the 1000 classes) of the pre-trained model as the features of the feed image. Then create a mean vector formed from the features of the 10 images. These mean vectors are used for training the image model. The idea behind this approach is to capture a similar distribution of images that users post, and achieve a discrimination between them. As the model is designed for visual object recognition (this includes objects and scenes), we expect similar values for users that post similar images. The pre-trained model that we used was the VGG16 with 1000 classes, VGG16 is a CNN model and refers to the 16 weight layers of the model. Figure <ref type="figure" coords="5,291.00,263.46,4.98,8.64" target="#fig_1">2</ref> shows the extraction of the features from the images for training the image model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Early Fusion: Textual and Visual Representations</head><p>The last step for the shared task is the classification of the users using both text and images. Our approach consist of an early fusion of both Textual and Visual representations concatenating previous vectors and then we pass the new representation to the classifier, we used a Support Vector Machine (SVM) for the training and classification. Our hypothesis is that combining both features the results should improve by giving more information about the users, than only using one kind of feature. Figure <ref type="figure" coords="5,419.57,563.42,4.98,8.64" target="#fig_2">3</ref> describes this feature extraction from the text and the images for the concatenation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Settings</head><p>The objective for this task is to determinate the gender of a user using a set of different tweets and images that the user posted. We evaluate the task in a separated way: i) only using the text we extract the group of n-grams and trained the SVM classifier for the prediction, ii) only using the images we used the VGG16 to extract the features of the images and calculate the mean vector of it and then trained other SVM classifier, and iii) we used both the features of the text and the images then concatenate and trained a third SVM classifier. The shared task have 3 different languages to test the models, and we trained one model for each language with this we have 9 different predictions for the test dataset. In <ref type="bibr" coords="6,208.50,470.36,16.60,8.64" target="#b14">[15]</ref> it presents an overview that describe in detail the tasks, data and evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experimental Results</head><p>To test the models before the TIRA platform we first separated the training dataset in 70% for training and 30% for test and extract the text and images features. For this task we measure the Accuracy over the predictions. For the test dataset we trained our models and then predict the gender using all the users in the training dataset. Table <ref type="table" coords="6,448.49,572.75,4.98,8.64" target="#tab_0">1</ref> shows the detailed classification results obtained with the text, images and both strategies for the three languages. In these results we could appreciate that the n-gram Ensemble performs better than the others strategies for text representation. SOA and CNN did not perform better in these tasks than the n-grams Ensemble this could be due the base term (words) used in those representations. Therefore this presents an opportunity to integrate the same idea as the n-grams and look for a better performance. The image representation alone did not perform better than only using the text, but when we com-bine both representations it increases the results. In order to study the remarkable performance of the n-grams, we extract the best 10 n-grams for the words group from the English and Spanish training corpus that were obtained using the chi 2 distribution and then cherry pick the best 5, Table <ref type="table" coords="7,426.18,276.14,4.98,8.64" target="#tab_1">2</ref> shows these group of words. In this table we can appreciate the selection of words that people prefer to use when they tweet about something of their interest. To analyze the performance of the image model, we select some images and get the probabilities from our model of been post by male or female. Figure <ref type="figure" coords="7,432.45,457.43,4.98,8.64">4</ref> shows the probabilities from some pictures from the three languages. For the English users, we can appreciate that sport's images related are more common for males and landscapes or cats are more common for females. We also present images from the Spanish users where for male is more common to post about sports and video games and for the females their prefer pictures from artist and landscapes. Last part of the figure shows images from the Arabic user where we can appreciate that males have a high probability of posting something related to sports too (even greater than English and Spanish) and for females is common to post more colorful pictures. But in general there are a lot of neutral pictures about politics, social events or comic images that are harder to classify.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>In this notebook we presented an approach in order to determine the gender of a user using the tweets and images they post. For the text part we used four different strategies, where the n-gram Ensemble gets the best overall performance. We used a n-gram</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,225.71,633.86,163.94,8.12;4,187.21,488.09,240.94,131.04"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. N-gram Ensemble diagram creation</figDesc><graphic coords="4,187.21,488.09,240.94,131.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,230.27,424.19,154.83,8.12;5,180.12,307.00,255.13,102.45"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Image feature extraction diagram</figDesc><graphic coords="5,180.12,307.00,255.13,102.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,171.69,376.92,271.98,8.12;6,208.47,115.84,198.43,246.35"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Diagram of Early Fusion with Textual and Visual Representations</figDesc><graphic coords="6,208.47,115.84,198.43,246.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,135.66,160.36,344.04,61.66"><head>Table 1 .</head><label>1</label><figDesc>Detailed classification accuracy</figDesc><table coords="7,135.66,180.89,344.04,41.13"><row><cell>Language</cell><cell></cell><cell>Training Data</cell><cell></cell><cell></cell><cell></cell><cell>Test Data</cell><cell></cell></row><row><cell></cell><cell>Text</cell><cell></cell><cell></cell><cell cols="2">Image Text and Image</cell><cell cols="2">Text Image Text and Image</cell></row><row><cell cols="8">BoT SOA CNN-Rand CNN-Static CNN-NonStatic N-Gram Ensemble VGG16 N-Gram + VGG16 N-Gram VGG16 NG+VGG16</cell></row><row><cell>English 0.7778 0.7717 0.5727</cell><cell>0.6182</cell><cell>0.6010</cell><cell>0.8495</cell><cell>0.6848</cell><cell>0.8515</cell><cell>0.7963 0.6921</cell><cell>0.8016</cell></row><row><cell>Spanish 0.7667 0.7485 0.5768</cell><cell>0.5879</cell><cell>0.6414</cell><cell>0.8414</cell><cell>0.6879</cell><cell>0.8465</cell><cell>0.7686 0.6668</cell><cell>0.7723</cell></row><row><cell>Arabic 0.5798 0.5980 0.5354</cell><cell>0.5394</cell><cell>0.5354</cell><cell>0.8343</cell><cell>0.6949</cell><cell>0.8444</cell><cell>0.6480 0.6800</cell><cell>0.6670</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,135.77,341.09,343.82,74.05"><head>Table 2 .</head><label>2</label><figDesc>Best n-grams at word level for English and Spanish users</figDesc><table coords="7,135.77,361.78,343.82,53.36"><row><cell></cell><cell>English</cell><cell></cell><cell></cell><cell></cell><cell>Spanish</cell><cell></cell></row><row><cell>1 word 2 words</cell><cell>3 words</cell><cell>4 words</cell><cell>1 word</cell><cell>2 words</cell><cell>3 words</cell><cell>4 words</cell></row><row><cell>'cute' 'More for'</cell><cell>'have the best'</cell><cell>'have the best day'</cell><cell cols="2">'amiga' 'mi novio'</cell><cell cols="2">'el gol de' 'de Trump https co'</cell></row><row><cell>'girls' 'my bed'</cell><cell>'in the league'</cell><cell cols="5">'liked YouTube video from' 'equipo' 'te amo' 'en mi corazón' 'EE UU https co'</cell></row><row><cell>'league' 'my mum'</cell><cell>'so excited to'</cell><cell>'new photo to Facebook'</cell><cell>'gol'</cell><cell cols="3">'gol de' 'más grande de' 'en EE UU https'</cell></row><row><cell cols="7">'lovely' 'my wife' 'happy birthday mate' 'photo to Facebook https' 'jugador' 'un equipo' 'porque no me' 'la vida https co'</cell></row><row><cell cols="2">'mum' 'the league' 'have lovely day'</cell><cell>'posted new photo to'</cell><cell cols="4">'partido' 'mi corazón' 'que mi mamá' 'que si https co'</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spanish Arabic</head><p>representation and analyze it to see the different group of words that have most discriminative value to give weight to the classes, in this representation we could see that the model capture important words that the users post when they tweet about something. For the image part we used a VGG16 model to extract features from the images and capture the kind of image that people usually post. The images alone did not get the expected results, due the similarity of the image topics about politics or social events. Then for the final step we concatenate the features from the text and images to see if the model could gain extra information for the classification. With these experiments we obtained evidence that only text information gives better results than only using the images, but the features combined improves the results in the training and test sets proving our hypothesis.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,138.13,294.78,342.46,7.77;9,146.47,305.74,131.77,7.77" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="9,191.78,294.78,223.27,7.77">Hand-book on Statistical Distributions for experimentalists</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Walck</surname></persName>
		</author>
		<idno>SUF-PFY/96-01</idno>
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>Stockholm</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Internal Report</note>
</biblStruct>

<biblStruct coords="9,138.13,316.74,342.46,7.77;9,146.47,327.70,334.12,7.77;9,146.47,338.66,63.50,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,235.87,316.74,244.72,7.77;9,146.47,327.70,61.64,7.77">Speech and Language Processing. An Introduction to Natural Language Processing</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,214.71,327.70,187.95,7.77">Computational Linguistics, and Speech Recognition</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>Third Edition draft. Chapter 4</note>
</biblStruct>

<biblStruct coords="9,138.13,349.67,342.46,7.77;9,146.47,360.63,209.54,7.77" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="9,197.42,349.67,283.17,7.77;9,146.47,360.63,126.57,7.77">Neural Network Methods in Natural Language Processing (Synthesis Lectures on Human Language Technologies)</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<editor>Graeme Hirst</editor>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.13,371.63,342.46,7.77;9,146.47,382.59,334.12,7.77;9,146.47,393.55,228.39,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,181.35,382.59,187.10,7.77">Inaoe&apos;s participation at pan&apos;13: Author profiling task</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Lopez-Monroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">J</forename><surname>Escalante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villasenor-Pineda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Villatoro-Tello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,385.88,382.59,94.71,7.77;9,146.47,393.55,97.15,7.77">Notebook Papers of CLEF 2013 LABs and Workshops</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-09">September 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.13,404.56,342.46,7.77;9,146.47,415.52,307.79,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,178.48,404.56,207.30,7.77">Convolutional neural networks for sentence classification</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,391.89,404.56,88.70,7.77;9,146.47,415.52,276.82,7.77">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.13,426.52,342.46,7.77;9,146.47,437.48,99.13,7.77" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="9,261.30,426.52,219.29,7.77;9,146.47,437.48,42.24,7.77">Very Deep Convolutional Networks for Large-Scale Image Recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.13,448.49,342.46,7.77;9,146.47,459.45,131.74,7.77" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="9,297.00,448.49,183.59,7.77;9,146.47,459.45,74.95,7.77">Comparative Study of CNN and RNN for Natural Language Processing</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.13,470.45,284.02,7.77" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="9,256.29,470.45,108.01,7.77">Deep Learning applied to NLP</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Moreno-Lopez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalita</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.13,481.46,342.46,7.77;9,146.47,492.42,74.97,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,334.94,481.46,145.65,7.77;9,146.47,492.42,20.70,7.77">Bag of Tricks for Efficient Text Classification</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolovn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,172.87,492.42,22.43,7.77">CoRR</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,503.42,338.35,7.77;9,146.47,514.38,109.33,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,316.64,503.42,163.95,7.77;9,146.47,514.38,54.57,7.77">Efficient Estimation of Word Representations in Vector Space</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,207.23,514.38,22.43,7.77">CoRR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,525.39,338.35,7.77;9,146.47,536.35,251.40,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,228.81,525.39,248.11,7.77">Use of language and author profiling: Identification of gender and age</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,146.47,536.35,186.63,7.77">Natural Language Processing and Cognitive Science</title>
		<imprint>
			<biblScope unit="page">177</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,547.35,338.35,7.77;9,146.47,558.31,334.12,7.77;9,146.47,569.27,208.72,7.77" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Álvarez-Carmona</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Pellegrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sánchez-Vega</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">J</forename><surname>Escalante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>López-Monroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villaseñor-Pineda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Villatoro-Tello</surname></persName>
		</author>
		<title level="m" coord="9,399.97,558.31,80.63,7.77;9,146.47,569.27,141.29,7.77">A visual approach for age and gender identification on Twitter</title>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,580.28,338.35,7.77;9,146.47,591.24,256.26,7.77" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Medvedeva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rawee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Haagsma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Nissim</surname></persName>
		</author>
		<title level="m" coord="9,425.97,580.28,54.62,7.77;9,146.47,591.24,230.11,7.77">N-GrAM: New Groningen Author-profiling Model</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Notebook for PAN at CLEF</note>
</biblStruct>

<biblStruct coords="9,142.24,602.24,338.35,7.77;9,146.47,613.20,262.67,7.77" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<title level="m" coord="9,316.71,602.24,163.88,7.77;9,146.47,613.20,236.52,7.77">Overview of the 5th Author Profiling Task at PAN 2017: Gender and Language Variety Identification in Twitter</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,624.21,338.35,7.77;9,146.47,635.17,334.12,7.77;9,146.47,646.13,334.12,7.77;9,146.47,657.08,270.83,7.77" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,393.53,624.21,87.06,7.77;9,146.47,635.17,275.38,7.77">Overview of the 6th Author Profiling Task at PAN 2018: Multimodal Gender Identification in Twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="9,292.72,646.13,187.87,7.77;9,146.47,657.08,129.18,7.77">Working Notes Papers of the CLEF 2018 Evaluation Labs. CEUR Workshop Proceedings</title>
		<title level="s" coord="9,281.73,657.08,59.13,7.77">CLEF and CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018-09">Sep 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,119.96,338.35,7.77;10,146.47,130.92,146.61,7.77" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,253.21,119.96,223.97,7.77">Age and Gender Identification using Stacking for Classification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Goncalves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,146.47,130.92,100.29,7.77">Notebook for PAN at CLEF</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,141.88,338.35,7.77;10,146.47,152.84,174.00,7.77" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,319.32,141.88,161.27,7.77;10,146.47,152.84,21.56,7.77">Author Profiling Using Support Vector Machines</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bakkar-Deyab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Duarte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gonçalves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,173.86,152.84,100.29,7.77">Notebook for PAN at CLEF</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,163.80,338.35,7.77;10,146.47,174.76,269.71,7.77" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,265.73,163.80,214.86,7.77;10,146.47,174.76,117.23,7.77">Author Profiling using Complementary Second Order Attributes and Stylometric Features</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bougiatiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,269.57,174.76,100.29,7.77">Notebook for PAN at CLEF</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,185.71,338.35,7.77;10,146.47,196.67,293.06,7.77" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,416.79,185.71,63.80,7.77;10,146.47,196.67,140.80,7.77">Author Profiling, instance-based Similarity Classification</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Adame-Arcia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Castro-Castro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ortega-Bueno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Muñoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,292.92,196.67,100.29,7.77">Notebook for PAN at CLEF</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,207.63,338.35,7.77;10,146.47,218.59,237.63,7.77" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="10,299.88,207.63,180.71,7.77;10,146.47,218.59,84.96,7.77">Twitter Author Profiling Using Word Embeddings and Logistic Regression</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Akhtyamova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cardiff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ignatov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,237.49,218.59,100.29,7.77">Notebook for PAN at CLEF</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,229.55,338.35,7.77;10,146.47,240.51,332.56,7.77" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="10,373.03,229.55,107.56,7.77;10,146.47,240.51,179.52,7.77">Subword-based Deep Averaging Networks for Author Profiling in Social Media</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Plotnikova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Pawar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Benajiba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,332.43,240.51,100.29,7.77">Notebook for PAN at CLEF</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,251.47,338.35,7.77;10,146.47,262.43,253.69,7.77" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="10,327.73,251.47,152.86,7.77;10,146.47,262.43,101.28,7.77">PAN 2017: Author Profiling -Gender and Language Variety Prediction</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Martinc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Škrjanec</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Zupan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Pollak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,253.55,262.43,100.29,7.77">Notebook for PAN at CLEF</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,273.39,338.35,7.77;10,146.47,284.34,129.18,7.77" xml:id="b22">
	<monogr>
		<title level="m" type="main" coord="10,197.97,273.39,282.62,7.77;10,146.47,284.34,82.86,7.77">UniNE at CLEF 2017: TF-IDF and Deep-Learning for Author Profiling. Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Schaetti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,295.30,338.35,7.77;10,146.47,306.26,139.21,7.77" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="10,246.97,295.30,230.25,7.77">Gender prediction using individual perceptual image aesthetics</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Azam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gavrilova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,146.47,306.26,60.87,7.77">Journal of WSCG</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="53" to="62" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,317.22,338.35,7.77;10,146.47,328.18,334.12,7.77;10,146.47,339.14,145.69,7.77" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="10,274.96,317.22,205.63,7.77;10,146.47,328.18,61.52,7.77">Gender estimation for sns user profiling using automatic image annotation</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Tsuboshita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,225.44,328.18,255.16,7.77;10,146.47,339.14,56.87,7.77">2014 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)</title>
		<imprint>
			<date type="published" when="2014-07">July (2014</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,350.10,338.35,7.77;10,146.47,361.06,334.12,7.77;10,146.47,372.02,211.40,7.77" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="10,158.91,361.06,317.81,7.77">A picture is worth a thousand words: A content analysis of Facebook profile photographs</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">J</forename><surname>Hum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">E</forename><surname>Chamberlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">L</forename><surname>Hambright</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Portwood</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Schat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Bevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,146.47,372.02,110.18,7.77">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1828" to="1833" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,382.97,338.35,7.77;10,146.47,393.93,334.12,7.77;10,146.47,404.89,176.56,7.77" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="10,274.01,382.97,206.58,7.77;10,146.47,393.93,147.91,7.77">You are what you tweet...pic! gender prediction based on semantic analysis of social media images</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Merler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,311.06,393.93,169.54,7.77;10,146.47,404.89,86.77,7.77">2015 IEEE International Conference on Multimedia and Expo (ICME)</title>
		<imprint>
			<date type="published" when="2015-06">June (2015</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,415.85,338.35,7.77;10,146.47,426.81,334.12,7.77;10,146.47,437.77,121.55,7.77" xml:id="b27">
	<monogr>
		<title level="m" type="main" coord="10,399.82,415.85,80.77,7.77;10,146.47,426.81,221.38,7.77">A Weighted Combination of Text and Image Classifiers for User Gender Inference</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Taniguchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sakaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Shigenaka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Tsuboshita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ohkuma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="87" to="93" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
