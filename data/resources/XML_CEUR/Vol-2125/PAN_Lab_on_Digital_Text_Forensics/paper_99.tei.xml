<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,166.55,115.96,282.26,12.62;1,144.79,133.89,325.78,12.62;1,231.94,151.82,151.48,12.62;1,208.38,171.66,198.60,10.52">Custom Document Embeddings Via the Centroids Method: Gender classification in an Author Profiling task Notebook for PAN at CLEF 2018</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,171.23,207.69,106.30,8.74"><forename type="first">Roberto</forename><surname>López-Santillán</surname></persName>
						</author>
						<author>
							<persName coords="1,288.08,207.69,129.43,8.74"><forename type="first">Luis</forename><surname>Carlos González-Gurrola</surname></persName>
						</author>
						<author>
							<persName coords="1,251.18,219.65,108.53,8.74"><forename type="first">Graciela</forename><surname>Ramírez-Alonso</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Facultad de Ingeniería</orgName>
								<orgName type="institution">Universidad Autónoma de Chihuahua</orgName>
								<address>
									<addrLine>Circuito No. 1</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Nuevo</orgName>
								<address>
									<addrLine>Campus Universitario</addrLine>
									<postBox>Apdo. postal 1552</postBox>
									<postCode>31240</postCode>
									<settlement>Chihuahua</settlement>
									<region>Chih., México. C.P</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,166.55,115.96,282.26,12.62;1,144.79,133.89,325.78,12.62;1,231.94,151.82,151.48,12.62;1,208.38,171.66,198.60,10.52">Custom Document Embeddings Via the Centroids Method: Gender classification in an Author Profiling task Notebook for PAN at CLEF 2018</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3AEC8B5C8C808C27303578C8DCE7CAD0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Author Profiling</term>
					<term>Word Embeddings</term>
					<term>Document Embeddings</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>According to Smart Insights 1 , out of the 7.5 billion persons in total population of the world, there are 4 billion Internet users, and out of those an outstanding 3.19 billion are active social media users. In a report by the U.S. Internet Crime Complaint Center, only in 2016 Identity theft, Extortion and Harassment or violence threads stand out among the most frequently reported cyber-crime events 2 . The Author Profiling (AP) task might be useful to counteract this phenomena by profiling cyber-criminals. AP consists in detecting personal traits of authors within texts (i.e. gender, age, personality). In the current report we describe a method to address the AP problem, which is one of the three shared tasks evaluated, as an exercise in digital text forensics at PAN 2018 within the CLEF conference (Conference and Labs of the Evaluation Forum). Our approach blends Word Embeddings (WE) and the Centroids Method to produce Document Embeddings (DE), that deliver competitive results predicting the gender of authors, over a dataset comprised of text posts from Twitter R . Specifically, in the testing dataset our proposal achieve an accuracy of 0.78 for English language users, and on average (for English, Spanish and Arabic languages users) it reaches an Accuracy score of 0.77.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Author Profiling (AP) is the task of discovering features like gender, age and psychological traits in persons, by analyzing their language expressions. A methodology to obtain personal profiles of individuals with high accuracy would be useful in areas like customer service, attention of neurological disorders (e.g. autism) and cyber-crimes among others <ref type="bibr" coords="2,273.50,130.95,9.96,8.74" target="#b0">[1]</ref>. The proficiency to accurately profile the author(s) of plagiarism, identity theft, Internet sexual predatory activities or even terrorist attacks, has become a matter of critical importance. On the other hand, influential companies such as Amazon, Netflix, Google, Apple amidst other, use several Machine Learning (ML) algorithms to address and create new demand among their clients and to attract new ones, based on profiling their customers <ref type="bibr" coords="2,134.77,202.68,9.96,8.74" target="#b1">[2]</ref>.</p><p>A fair amount of works have attempted solving this problem, several shared task events are held each year to test accuracy of new algorithms. These works report competitive results when predicting the gender or age group of individuals <ref type="bibr" coords="2,155.38,251.06,9.96,8.74" target="#b1">[2]</ref>. In an attempt to standardize and set a context framework, world wide conferences in the field of Natural Language Processing (NLP) are organized frequently. Among those events, the PAN evaluation lab on digital text forensics, organized within the CLEF Initiative (Conference and Labs of the Evaluation Forum), is held each year. For the 2018 edition<ref type="foot" coords="2,347.14,297.31,3.97,6.12" target="#foot_2">3</ref> the conference posed shared tasks in mainly 3 different efforts: Author Identification, Author Obfuscation and Author Profiling <ref type="bibr" coords="2,240.89,322.79,9.96,8.74" target="#b2">[3]</ref>.</p><p>Machine learning (ML) is a computer science field that has re-gained strength in the last years with the advent of Deep Learning (DL), a subfield of ML that has obtained strong achievements in image and speech recognition, computer vision and as of lately NLP. NLP deals with the problem of how computers can understand Human natural language <ref type="bibr" coords="2,302.40,383.13,9.96,8.74" target="#b4">[4]</ref>. AP may be viewed as a sub-task of NLP, and it should be approached as such.</p><p>Departing from traditional NLP strategies, we propose a different approach. Word embeddings (WE) are a type of DL application that project natural language words (vectors) into a n-dimensional space. The distance between vectors represent a similitude value within a semantic context. A WE algorithm proposed by Mikolov et al. <ref type="bibr" coords="2,211.81,455.42,10.52,8.74" target="#b5">[5]</ref> called Word2Vec is currently used in multiple NLP tasks with amazing results. Word2Vec uses a Bag of Words approach, but it retains the order of the tokens within the original text. This method provides additional semantic information, richer in inner structure components, which might increase the accuracy of ML algorithms to predict personal traits in people.</p><p>Although WEs deliver state-of-art results in NLP tasks, such as text classification or language translation, more difficult assignments like Sentiment Analysis (SA) (which tries to identify positive from negative user opinions) or AP, are not benefited in the same way. WEs capture syntactic and semantic information, nonetheless the latter is caught with less sensitivity. To vectorize whole documents, literature suggests other techniques, such as the Centroids Method <ref type="bibr" coords="2,467.31,575.53,9.96,8.74" target="#b6">[6]</ref>. This approach considers a document as the sum of its words, hence the WE of each word in a sentence, a paragraph or even a whole document is composed by an aggregate function like maximum, minimum, or a weighted average, producing a single vector for the entire document, with a similar dimension shape as the WE of its words. This design delivers good results when training ML algorithms to learn the target of such documents, like topics or themes. To identify the gender, the age or the personality profile of the person behind such manuscript, the Centroids Method is more limited.</p><p>The fields of Computer Science (CS), Linguistics and Psychology must come together in a transversal strategy to tackle this problem. Some studies have merged the power of computation and linguistics to identify words or combinations of them, so several large lexicons have been developed, with tokens of statistical significance that can identify gender, age or personality of authors with high accuracy <ref type="bibr" coords="3,221.27,214.88,9.96,8.74" target="#b7">[7]</ref>. Such exercises give the certainty that words have a discerning power to differentiate men from women, youngsters from old persons or introverts from extroverts. Then it is hypothesize that WEs could lend their potential to an aggregate strategy that could produce document vectors as well. Taking this into account, our approach to the AP task blends WEs in an aggregate strategy, to produce distributed representations of whole texts (DEs), which we use to train our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Age and gender are often associated with the style of writing. This means that the style might change with age and is strongly associated with the gender of persons. The size of the texts available on a single author for training is known to affect the outcome of the classifiers. Even though larger texts are preferred, short samples like the ones found in social media platforms like Twitter R , might be useful in the AP task. Several studies show that the accuracy to predict gender and age in short texts declined little when compared to larger samples available <ref type="bibr" coords="3,175.23,428.49,9.96,8.74" target="#b1">[2]</ref>. Adorno et. al. proposed in <ref type="bibr" coords="3,306.85,428.49,10.52,8.74" target="#b8">[8]</ref> an approach that joined the Doc2Vec algorithm (a spin-off of Word2Vec focusing on sentences rather than words <ref type="bibr" coords="3,466.20,440.44,10.79,8.74" target="#b9">[9]</ref>) and the use of a Neural Network (NN). Their hypothesis relies on the idea that standardizing nonstandard language expressions used by several authors could render better accuracy performance on the AP task. Moreover the detection of emotions in posts from social media outlets, could result in better accuracy predicting features, as proposed by <ref type="bibr" coords="3,290.35,500.22,14.61,8.74" target="#b10">[10]</ref>, where the emotions detected in on-line posts might help to predict gender accurately.</p><p>The 2015 PAN AP shared task included personality as a feature to predict <ref type="bibr" coords="3,134.77,536.33,9.96,8.74" target="#b1">[2]</ref>. This endeavor is better addressed as a regression problem since the prediction is a rational value. At that year several strategies were chosen to addresses the problem. For instance the approach of Pervaz et. al. focused on the stylistic and thematic properties of the dataset <ref type="bibr" coords="3,305.92,572.19,14.61,8.74" target="#b11">[11]</ref>. On the other hand lvarez-Carmona et. al. <ref type="bibr" coords="3,162.85,584.15,15.50,8.74" target="#b12">[12]</ref> chose Second Order Attributes (SOA) and Latent Semantic Analysis (LSA) to enhance the discriminative skills of their algorithms. Most of the teams attained competitive results using state-of-the-art ML algorithms. The most frequent classifiers used were: Naive Bayes (NB), Support Vector Machine (SVM) and Random Forest (RF) <ref type="bibr" coords="3,249.14,631.97,9.96,8.74" target="#b1">[2]</ref>.</p><p>To properly approach the AP problem, it is essential to understand the fundamental blocks of language. The vast majority of currently spoken idioms around the world, are build around tokens known as words. Even though syntax, grammar and other language constructs may vary from one dialect to another, the single elements like "words" remain the same. Nonetheless, Western Latin idioms are based on similar character sets, it is possible to "tokenize" languages like Arabic in order to obtain single tokens equivalent to the former. All this is relevant because works like the one published by Schwartz et. al. <ref type="bibr" coords="4,443.28,178.77,9.96,8.74" target="#b7">[7]</ref>, have established a statistically significant set of words for the English language, that have the power to categorize authors that use frequently these terms, by gender, age group and personality traits. They propose a mixture of Linguistics and Computer Science algorithms to determine which words in the English idiom are statistically significant, to be used with discriminative enough capabilities. As it is implied in this study, the popularity of social media has produced huge amounts of available data from all kinds of persons around the globe. This enormous potential datasets allows to develop new ML algorithms which might reveal the intricateness within the written language.</p><p>In order to perform NLP tasks, words need to be treated like numeric entities, not only as identifiers, but they must represent through their values something meaningful, to the term and to the context they are being used on. There are several ways to represent words in ML/NLP tasks, for instance One Hot Encoding, Bag-Of-Words or Word Embeddings are 3 of the most used architectures to represent words in NLP efforts. Figure <ref type="figure" coords="4,318.40,363.86,4.98,8.74">1</ref> demonstrates the basic structure of these word-coding methods.</p><p>For text classification, textual similarities or even translation activities, WEs by themselves deliver extraordinary results. In tasks such as sentiment analysis or author profiling, it is required to generate vectors for phrases or whole documents. One of the most straightforward techniques for vectorization of whole documents is called the Centroids Method. As proposed by Kusner et. al. in <ref type="bibr" coords="4,467.31,441.35,9.96,8.74" target="#b6">[6]</ref>, in order to perform accurate document classifications, texts should be projected into a n-dimensional space where a distance between them can be computed. A document embedding or vector is generated by calculating a weighted average of its WEs, then vectorial distances (Euclidean, Canberra, etc) between them allows for proper document classification.</p><p>As of late, WEs are the preferred method to engage NLP tasks, since they deliver state-of-the-art results in tasks such as text classification, translation, text generation or sentiment analysis (SA). Seyed et. al. in <ref type="bibr" coords="4,391.84,542.76,15.50,8.74" target="#b13">[13]</ref> tried to enhance WEs in a SE task by adding useful information to the word vectors. Their idea consists in calculating vectors for Part of Speech (POS) elements within the text. A POS is the category of the word, for instance nouns, verbs, adjectives or pronouns. Moreover, a lexicon vector is also computed and concatenated as well; there are several lexicons, particularly in the English language with proven discriminative properties as demonstrated by <ref type="bibr" coords="4,334.63,614.49,9.96,8.74" target="#b7">[7]</ref>.</p><p>Our approach is partially based on the aforementioned studies. We differentiate our strategy by creating our own distributed representations for the vocabulary and the POS tags. Also, a preliminary experiment showed that lexicons did Fig. <ref type="figure" coords="5,152.04,452.42,3.58,7.86">1</ref>: Several ways to encode words from texts. In a), oov (out of vocabulary) is used when a token does not belong to the dictionary. not add accuracy when joined to the DEs, hence they were discarded. A more in depth explanation is presented in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>The goal for the AP shared task at PAN 2018 was to classify subjects by gender in three different languages: English, Spanish and Arabic. In our implementation only a SVM classifier was employed, due to delivering the best results in preliminary runs. The model was trained offline on the provided training dataset, then was uploaded into a Virtual Machine (TIRA), available at a server in Bauhaus University at Weimar Germany. This environment allows different models (heterogeneous programming languages) to run on a common platform, thus making the evaluation of the shared task easier to assess <ref type="bibr" coords="5,349.69,656.12,14.61,8.74" target="#b14">[14]</ref>.</p><p>The employed strategy is an assemble approach which fuses a) WEs, b) the Centroids Method to produce DEs and c) the tf-idf (term frequencyinverse document frequency) weighting scheme. tf-idf is a statistical value computed for each term in a document. It helps establish the importance of a term within a corpus. The more a word appears in a text, the more the tf-idf value increases. For terms with high frequency but few discriminative power (e.g. the, and ), an offset value is computed. The tf-idf value is vastly used in information retrieval tasks <ref type="bibr" coords="6,160.06,202.68,14.61,8.74" target="#b15">[15]</ref>. Equation <ref type="bibr" coords="6,224.68,202.68,12.73,8.74" target="#b0">(1)</ref> shows how to compute a tf-idf value within a corpus.</p><formula xml:id="formula_0" coords="6,238.94,227.74,241.65,23.22">tf-idf t,d = (1 + log tf t,d ) • log N df t<label>(1)</label></formula><p>A new vocabulary of WEs was crafted from the dataset using the Skip-gram algorithm, then a tf-idf value was calculated for each term within the context of each collection of posts of all individuals. For example the tf-idf value for the word "drink" will be different among persons in the dataset (people use words differently). Next the DEs were generated for each person in the dataset (one per person), by computing the weighted average (using the tf-idf value of each word) of all WEs in every set of documents, as shown in formula <ref type="bibr" coords="6,414.94,333.72,11.62,8.74" target="#b1">(2)</ref>. Finally the DEs were used to train the SVM classifier. A distribution of specimens in the training dataset is depicted in table <ref type="table" coords="6,293.75,357.63,4.98,8.74" target="#tab_0">1</ref> DEs A Tokenization process designed for Twitter R posts<ref type="foot" coords="7,381.43,117.42,3.97,6.12" target="#foot_3">4</ref> was used to produce the individual terms in the dataset. This procedure allows to retrieve each term in the dataset as a single entity. Using a specific tool to produce tokens in a social network environment, allowed us to attain context specific terms such as "bit.ly", ":-)" or "#TuesdayThoughts", which might be more discriminative than single words. Figure <ref type="figure" coords="7,198.20,178.77,4.98,8.74" target="#fig_0">2</ref> shows an analysis done on the most frequent Twitter R tokens used on the training dataset. Inspired by the work in <ref type="bibr" coords="7,262.56,434.37,14.61,8.74" target="#b13">[13]</ref>, we performed a POS tagging procedure on the dataset for the English language. For this process we used the NLTK POS tagger <ref type="foot" coords="7,161.91,456.70,3.97,6.12" target="#foot_4">5</ref> , which uses a Greedy Averaged Perceptron (GAP) algorithm to compute the POS tags of each word. Subsequently each word in the dataset was replaced by its POS tag and the same Skip-gram algorithm was applied to generate embeddings for the POS labels. WEs from the dataset were enhanced by concatenating their POS tags vectors. To produce the Document Embeddings (DE) for every individual on the dataset, a weighted average was also computed for the enhanced WEs in the collection of posts of each individual. This embeddings share the same dimensionality of the enhanced vectors from single words (300 + 20). Figure <ref type="figure" coords="7,219.39,553.92,4.98,8.74" target="#fig_1">3</ref> shows the proposed model. For the English language the POS vectors were attached to the original WEs before the weighted averaging. For the Spanish and Arabic languages, no POS vectors were attached (DEs of 300 dimensions), because multilingual POS tagger tools did not deliver useful labels for these idioms. A translation approach to apply the POS tags strategy in these languages did not deliver an advantageous trade off between accuracy and running time. Table <ref type="table" coords="8,176.47,336.30,4.98,8.74" target="#tab_1">2</ref> shows the parameters used to train the WEs of words and their POS. The criterion to choose the parameters was based on a randomized grid search.</p><formula xml:id="formula_1" coords="6,245.64,382.54,234.95,29.52">-WAvg = i n=1 (w n * tf idf [w n ]) i n=1 tf idf [w n ]<label>(2)</label></formula><p>For the classification stage, a Support Vector Machine (SVM) algorithm was chosen. Although not entirely new (introduced by Vapnik in the 90's of last century), SVMs are currently acknowledged as one of the most used and effective ML algorithms <ref type="bibr" coords="8,205.99,399.66,14.61,8.74" target="#b16">[16]</ref>. A preliminary set of runs to test the best classifier for the AP task, showed that SVM was the fittest option among other methods such as Random Forest and Extra Trees. SVMs are useful in problems with hard separability, by using the so called kernel trick, they approximate a higher dimensional projection by computing variants of the dot product, which is both accurate enough and computationally tractable <ref type="bibr" coords="8,349.40,459.44,14.61,8.74" target="#b16">[16]</ref>. A full Grid Search (GS) was performed to find the best parameters for the SVM, table <ref type="table" coords="8,408.66,471.39,4.98,8.74" target="#tab_2">3</ref> shows the best parameters found by the GS. In order to evaluate our method in the training phase, a 10-fold cross-validation strategy was selected. Table <ref type="table" coords="9,257.70,155.65,4.98,8.74" target="#tab_3">4</ref> shows the performance of the SVM classifiers over the training dataset. An average of the accuracy over the three languages was computed to produce an overall performance value. For the testing stage, we ran our model through the platform TIRA <ref type="foot" coords="9,452.36,350.66,3.97,6.12" target="#foot_5">6</ref> . The results attained on the testing data showed little decrease compared to the results in the training step, this suggests the method is robust. Table <ref type="table" coords="9,414.04,376.14,4.98,8.74" target="#tab_4">5</ref> demonstrates the results achieved on testing. In both stages (training and testing), English language was best classified, this might be due in part to the POS tagging information that was added only in this idiom. Furthermore the strategy for Spanish and Arabic classification did not use POS tags, which might suggest the Document Embeddings produced were not as rich in semantic information as those enhanced by POS tags vectors. Despite having more samples (3000 individuals, whilst Arabic has 1500), the Spanish task resulted in the lowest accuracy overall, whether it was on training or testing data. This suggests that the use of words and topics in the Spanish language might be more uniform than in the Arabic idiom.</p><p>A more comprehensive list (from all participant teams) of methodologies and results is explained by <ref type="bibr" coords="9,257.13,519.76,90.12,8.74">Rangel et. al. in [17]</ref>, thus our methodology might be assessed more properly within this context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>The Author Profiling task is very important for the current online way of life. The ongoing mission to produce faster and more accurate algorithms, takes us in new directions, to explore new options, to test new approaches. Even tough state-of-the-art results are good enough for some applications, there is still a lot of room for improvement. The method proposed in this report, shows that fusing "old" ways with novel ones, might be a good strategy for the upcoming future. Moreover, given the limited scope of the available datasets for this type of tasks, it might be a good idea to work parallel in devising new techniques to produce more comprehensive datasets in a faster way.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,156.32,398.59,302.71,7.86;7,134.77,222.61,345.82,164.47"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Words clouds for English and Spanish terms in the training dataset.</figDesc><graphic coords="7,134.77,222.61,345.82,164.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="8,213.99,293.89,187.38,7.86;8,134.77,115.84,345.82,166.54"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Architecture of the proposed technique.</figDesc><graphic coords="8,134.77,115.84,345.82,166.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="5,134.77,115.84,345.84,325.08"><head></head><label></label><figDesc></figDesc><graphic coords="5,134.77,115.84,345.84,325.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,134.77,447.52,155.62,184.42"><head>Table 1 :</head><label>1</label><figDesc>Distribution of samples in the PAN-2018 dataset.</figDesc><table coords="6,172.82,495.41,76.45,136.53"><row><cell></cell><cell>Samples</cell></row><row><cell>English</cell><cell>3000</cell></row><row><cell>Female</cell><cell>1500</cell></row><row><cell>Male</cell><cell>1500</cell></row><row><cell>Spanish</cell><cell>3000</cell></row><row><cell>Female</cell><cell>1500</cell></row><row><cell>Male</cell><cell>1500</cell></row><row><cell>Arabic</cell><cell>1500</cell></row><row><cell>Female</cell><cell>750</cell></row><row><cell>Male</cell><cell>750</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,324.97,447.52,155.62,200.38"><head>Table 2 :</head><label>2</label><figDesc>Parameters used to train the words and their POS tags embeddings, using the Skip-gram model.</figDesc><table coords="6,343.47,494.92,118.63,152.99"><row><cell>Word Embeddings</cell><cell></cell></row><row><cell>size</cell><cell>300</cell></row><row><cell>min count</cell><cell>15</cell></row><row><cell>window</cell><cell>15</cell></row><row><cell>sample</cell><cell>0.05</cell></row><row><cell>iter</cell><cell>5</cell></row><row><cell>negative</cell><cell>15</cell></row><row><cell>POS tag Embeddings</cell><cell></cell></row><row><cell>size</cell><cell>20</cell></row><row><cell>min count</cell><cell>1</cell></row><row><cell>window</cell><cell>5</cell></row><row><cell>sample</cell><cell>0.05</cell></row><row><cell>iter</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,165.72,523.48,283.92,109.12"><head>Table 3 :</head><label>3</label><figDesc>Parameters explored in the Grid search of the SVM classifier.</figDesc><table coords="8,169.77,548.95,275.82,83.65"><row><cell cols="2">Parameter Range</cell></row><row><cell>C</cell><cell>[ 0.001, 0.01, 0.1, 0.5, 0.9, 1, 10 ]</cell></row><row><cell>gamma</cell><cell>[ 0.001, 0.01, 0.1, 1 ]</cell></row><row><cell>kernel</cell><cell>linear', 'rbf', 'poly', 'sigmoid'</cell></row><row><cell>degree</cell><cell>[ 1, 2, 3 ]</cell></row><row><cell>coef0</cell><cell>[ 0.0 -10 ]</cell></row><row><cell>best set</cell><cell>(C=10, degree=2, gamma=1, kernel='poly', coef0=0.0)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,146.82,212.84,131.52,98.17"><head>Table 4 :</head><label>4</label><figDesc>Performance in training dataset.</figDesc><table coords="9,167.54,249.28,89.93,61.73"><row><cell cols="2">Language Accuracy</cell></row><row><cell cols="2">English 0.7990</cell></row><row><cell cols="2">Spanish 0.7713</cell></row><row><cell>Arabic</cell><cell>0.7953</cell></row><row><cell cols="2">Average 0.7885</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,339.31,212.84,126.95,98.17"><head>Table 5 :</head><label>5</label><figDesc>Performance in testing dataset.</figDesc><table coords="9,357.74,249.28,89.93,61.73"><row><cell cols="2">Language Accuracy</cell></row><row><cell cols="2">English 0.7847</cell></row><row><cell cols="2">Spanish 0.7677</cell></row><row><cell>Arabic</cell><cell>0.7760</cell></row><row><cell cols="2">Average 0.7761</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,623.92,282.45,7.86;1,144.73,634.88,173.03,7.86"><p>https://www.smartinsights.com/social-media-marketing/social-mediastrategy/new-global-social-media-research/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,137.50,644.07,3.65,5.24;1,144.73,645.84,322.21,7.86;1,144.73,656.80,26.65,7.86"><p>2 https://www.statista.com/statistics/184083/commonly-reported-types-of-cybercrime/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,144.73,656.80,247.18,7.86"><p>https://pan.webis.de/clef18/pan18-web/author-profiling.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="7,144.73,645.84,191.30,7.86"><p>https://github.com/dlatk/happierfuntokenizing</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="7,144.73,656.80,154.94,7.86"><p>https://www.nltk.org/book/ch05.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="9,144.73,656.80,80.14,7.86"><p>http://www.tira.io/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.96,208.98,337.63,7.86;10,151.52,219.94,329.07,7.86;10,151.52,230.90,103.46,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="10,413.32,208.98,67.28,7.86;10,151.52,219.94,191.95,7.86">Profiling the European Citizen: Cross-Disciplinary Perspectives</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hildebrandt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gutwirth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hildebrandt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gutwirth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer Publishing Company, Incorporated</publisher>
		</imprint>
	</monogr>
	<note>1 ed.</note>
</biblStruct>

<biblStruct coords="10,142.96,241.71,337.64,7.86;10,151.52,252.67,329.07,7.86;10,151.52,263.63,329.07,7.86;10,151.52,274.59,70.38,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,166.96,252.67,220.97,7.86">Overview of the 3rd author profiling task at pan 2015</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">C P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Daelemans</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="10,411.48,252.67,69.11,7.86;10,151.52,263.63,60.43,7.86">CLEF 2015 Labs and Workshops</title>
		<title level="s" coord="10,220.63,263.63,222.28,7.86">Notebook Papers. CEUR Workshop Proceedings, CEUR</title>
		<imprint>
			<date type="published" when="2015-09">Sep 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,285.40,337.63,7.86;10,151.52,296.35,329.07,7.86;10,151.52,307.31,329.07,7.86;10,151.52,318.27,329.07,7.86;10,151.52,329.23,3.88,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,209.44,296.35,271.15,7.86;10,151.52,307.31,80.43,7.86">Overview of PAN-2018: Author Identification, Author Profiling, and Author Obfuscation</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,257.05,307.31,223.54,7.86;10,151.52,318.27,329.07,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction. 9th International Conference of the CLEF Initiative (CLEF 18)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.40,329.23,325.19,7.86;10,151.52,340.19,329.07,7.86;10,151.52,351.15,20.99,7.86" xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Trabelsi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mothe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Murtagh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Soulier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename></persName>
		</author>
		<editor>Sanjuan, L. Cappellato, and N. Ferro</editor>
		<imprint>
			<date type="published" when="2018-09">Sept. 2018</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,361.96,337.63,7.86" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<title level="m" coord="10,328.52,361.96,56.24,7.86">Deep Learning</title>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,372.77,337.63,7.86;10,151.52,383.73,329.07,7.86;10,151.52,394.68,329.07,7.86;10,151.52,405.64,329.07,7.86;10,151.52,416.60,41.72,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,408.09,372.77,72.51,7.86;10,151.52,383.73,236.11,7.86">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,409.65,383.73,70.95,7.86;10,151.52,394.68,143.89,7.86">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,427.41,337.64,7.86;10,151.52,438.37,329.07,7.86;10,151.52,449.33,329.07,7.86;10,151.52,460.29,87.18,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,388.51,427.41,92.08,7.86;10,151.52,438.37,90.49,7.86">From word embeddings to document distances</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">I</forename><surname>Kolkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,264.80,438.37,215.79,7.86;10,151.52,449.33,198.64,7.86">Proceedings of the 32Nd International Conference on International Conference on Machine Learning</title>
		<meeting>the 32Nd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>JMLR.org</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="957" to="966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,471.10,337.64,7.86;10,151.52,482.06,329.07,7.86;10,151.52,493.01,329.07,7.86;10,151.52,503.97,248.16,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,186.43,493.01,294.16,7.86;10,151.52,503.97,82.16,7.86">Personality, gender, and age in the language of social media: The openvocabulary approach</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dziurzynski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Ramones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kosinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Stillwell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E P</forename><surname>Seligman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,245.51,503.97,44.57,7.86">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2013-09">09 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,514.78,337.63,7.86;10,151.52,525.74,329.07,7.86;10,151.52,536.70,329.07,7.86;10,151.52,547.66,172.02,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,301.02,525.74,179.58,7.86;10,151.52,536.70,218.77,7.86">Improving feature representation based on a neural network for author profiling in social media texts</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Gómez-Adorno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Posadas-Durán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Sanchez-Perez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Chanona-Hernández</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,380.15,536.70,96.27,7.86">Comp. Int. and Neurosc</title>
		<imprint>
			<biblScope unit="volume">2016</biblScope>
			<biblScope unit="page" from="1" to="1638936" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,558.47,337.64,7.86;10,151.52,569.43,165.87,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,269.69,558.47,210.90,7.86;10,151.52,569.43,22.16,7.86">Distributed representations of sentences and documents</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno>abs/1405.4053</idno>
	</analytic>
	<monogr>
		<title level="j" coord="10,185.62,569.43,21.82,7.86">CoRR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,580.24,337.98,7.86;10,151.52,591.19,329.07,7.86;10,151.52,602.15,329.07,7.86;10,151.52,613.11,329.07,7.86;10,151.52,624.07,329.07,7.86;10,151.52,635.03,259.34,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,260.63,580.24,219.96,7.86;10,151.52,591.19,233.07,7.86">On the identification of emotions and authors&apos; gender in facebook comments on the basis of their writing style</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,407.24,591.19,73.35,7.86;10,151.52,602.15,329.07,7.86;10,151.52,613.11,329.07,7.86;10,151.52,624.07,329.07,7.86;10,151.52,635.03,53.71,7.86">Proceedings of the First International Workshop on Emotion and Sentiment in Social and Expressive Media: approaches and perspectives from AI (ESSEM 2013) A workshop of the XIII International Conference of the Italian Association for Artificial Intelligence (AI*IA 2013)</title>
		<meeting>the First International Workshop on Emotion and Sentiment in Social and Expressive Media: approaches and perspectives from AI (ESSEM 2013) A workshop of the XIII International Conference of the Italian Association for Artificial Intelligence (AI*IA 2013)<address><addrLine>Turin, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-12-03">December 3, 2013. 2013</date>
			<biblScope unit="page" from="34" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,645.84,337.98,7.86;10,151.52,656.80,329.07,7.86;11,151.52,119.67,329.07,7.86;11,151.52,130.63,260.06,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,383.70,645.84,96.89,7.86;10,151.52,656.80,279.68,7.86">Identification of author personality traits using stylistic features: Notebook for pan at clef 2015</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Pervaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ameer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sittar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M A</forename><surname>Nawab</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="10,455.98,656.80,24.61,7.86;11,151.52,119.67,67.70,7.86">CLEF (Working Notes)</title>
		<title level="s" coord="11,200.93,130.63,145.11,7.86">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1391</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,139.33,337.97,10.13;11,151.52,152.55,329.07,7.86;11,151.52,163.51,329.07,7.86;11,151.52,174.47,148.60,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,221.56,152.55,212.56,7.86">Inaoe&apos;s participation at pan&apos;15: Author profiling task</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">Á Á</forename><surname>Carmona</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>López-Monroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">V</forename><surname>Pineda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">J</forename><surname>Escalante</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,455.28,152.55,25.31,7.86;11,151.52,163.51,283.54,7.86">Working Notes of CLEF 2015 -Conference and Labs of the Evaluation forum</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">September 8-11, 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,185.43,337.98,7.86;11,151.52,196.39,329.07,7.86;11,151.52,207.34,20.99,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,351.97,185.43,128.62,7.86;11,151.52,196.39,200.69,7.86">Improving the accuracy of pretrained word embeddings for sentiment analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Rezaeinia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ghodsi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Rahmani</surname></persName>
		</author>
		<idno>abs/1711.08609</idno>
	</analytic>
	<monogr>
		<title level="j" coord="11,364.78,196.39,21.82,7.86">CoRR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,218.30,337.98,7.86;11,151.52,229.26,329.07,7.86;11,151.52,240.22,329.07,7.86;11,151.52,251.18,329.07,7.86;11,151.52,262.14,329.07,7.86;11,151.52,273.10,329.07,7.86;11,151.52,284.06,103.46,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,466.58,218.30,14.01,7.86;11,151.52,229.26,329.07,7.86;11,151.52,240.22,140.70,7.86">Improving the Reproducibility of PAN&apos;s Shared Tasks: Plagiarism Detection, Author Identification, and Author Profiling</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,312.16,240.22,168.43,7.86;11,151.52,251.18,329.07,7.86;11,151.52,262.14,115.34,7.86">Information Access Evaluation meets Multilinguality, Multimodality, and Visualization. 5th International Conference of the CLEF Initiative (CLEF 14)</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Lupu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hall</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Toms</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014-09">Sept. 2014</date>
			<biblScope unit="page" from="268" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,295.02,310.97,7.86" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="11,199.41,295.02,246.37,7.86">Using tf-idf to determine word relevance in document queries</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ramos</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,305.98,337.98,7.86" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="11,210.29,305.98,196.08,7.86">Machine Learning: An Algorithmic Perspective</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Marsland</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Second Edition</note>
</biblStruct>

<biblStruct coords="11,151.52,316.93,155.26,7.86" xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">Hall</forename><surname>Chapman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,227.99,316.93,14.55,7.86">CRC</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct coords="11,142.62,327.89,337.98,7.86;11,151.52,338.85,329.07,7.86;11,151.52,349.81,329.07,7.86;11,151.52,360.77,329.07,7.86;11,151.52,371.73,155.53,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="11,443.02,327.89,37.57,7.86;11,151.52,338.85,329.07,7.86;11,151.52,349.81,39.83,7.86">Overview of the 6th Author Profiling Task at PAN 2018: Multimodal Gender Identification in Twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target=".org" />
	</analytic>
	<monogr>
		<title level="m" coord="11,212.77,349.81,231.14,7.86">Working Notes Papers of the CLEF 2018 Evaluation Labs</title>
		<title level="s" coord="11,356.26,360.77,124.33,7.86;11,151.52,371.73,81.99,7.86">CEUR Workshop Proceedings, CLEF and CEUR-WS</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018-09">Sept. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
