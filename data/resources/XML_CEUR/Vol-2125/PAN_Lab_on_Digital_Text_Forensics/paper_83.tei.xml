<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,139.95,116.10,335.47,12.64;1,230.95,134.03,153.46,12.64;1,223.43,154.40,168.50,10.53">Text and Image Synergy with Feature Cross Technique for Gender Identification Notebook for PAN at CLEF 2018</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,135.62,191.08,71.06,8.76"><forename type="first">Takumi</forename><surname>Takahashi</surname></persName>
							<email>takahashi.takumi@fujixerox.co.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Fuji Xerox Co., Ltd</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,213.43,191.08,52.87,8.76"><forename type="first">Takuji</forename><surname>Tahara</surname></persName>
							<email>tahara.takuji@fujixerox.co.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Fuji Xerox Co., Ltd</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,272.97,191.08,56.21,8.76"><forename type="first">Koki</forename><surname>Nagatani</surname></persName>
							<email>nagatani.koki@fujixerox.co.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Fuji Xerox Co., Ltd</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,335.94,191.08,61.49,8.76"><forename type="first">Yasuhide</forename><surname>Miura</surname></persName>
							<email>yasuhide.miura@fujixerox.co.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Fuji Xerox Co., Ltd</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,404.39,191.08,71.14,8.76"><forename type="first">Tomoki</forename><surname>Taniguchi</surname></persName>
							<email>taniguchi.tomoki@fujixerox.co.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Fuji Xerox Co., Ltd</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,281.28,203.03,69.67,8.76"><forename type="first">Tomoko</forename><surname>Ohkuma</surname></persName>
							<email>ohkuma.tomoko@fujixerox.co.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Fuji Xerox Co., Ltd</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,139.95,116.10,335.47,12.64;1,230.95,134.03,153.46,12.64;1,223.43,154.40,168.50,10.53">Text and Image Synergy with Feature Cross Technique for Gender Identification Notebook for PAN at CLEF 2018</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">95504B22599D57512F7ED5E3811DA94C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes a neural network model for the author profiling task of PAN@CLEF 2018. Traditional machine learning models have shown superior performances for the author profiling task in past PAN series. However, these models often require careful feature-engineering to improve their performance. On the other hand, neural network approaches have recently shown advanced performances in both natural language processing (NLP) and computer vision (CV) tasks. We tackle the author profiling task using neural networks for texts and images. In order to leverage the synergy of the texts and images, we propose Text Image Fusion Neural Network (TIFNN), which considers their interaction. In an in-house experiment, TIFNN achieved accuracies of 84-90% for different languages when used for gender identification.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Author profiling technologies that extract author profile traits from social media can be applied to some applications, e.g., advertisement, recommendation, and marketing. PAN 2018: Author Profiling Task <ref type="bibr" coords="1,270.90,487.29,16.60,8.76" target="#b12">[13]</ref> is identifying the user's gender from tweets that are contained texts and images in three languages (English, Spanish, and Arabic).</p><p>In PAN 2017 Author Profiling Task, various approaches based on a deep neural network (DNN) were presented <ref type="bibr" coords="1,269.80,523.71,11.56,8.76" target="#b5">[6,</ref><ref type="bibr" coords="1,281.36,523.71,7.71,8.76" target="#b6">7,</ref><ref type="bibr" coords="1,289.07,523.71,7.71,8.76" target="#b8">9,</ref><ref type="bibr" coords="1,296.78,523.71,11.56,8.76" target="#b15">16,</ref><ref type="bibr" coords="1,308.34,523.71,11.56,8.76" target="#b17">18]</ref>. However, such approaches could not outperform traditional machine learning models that were carefully modeled, such as support vector machine. In contrast, neural network approaches have shown superior performances on various NLP tasks, e.g., machine translation, summarization, and information retrieval. In addition, DNN approaches have shown advanced performances in various CV tasks.</p><p>Because PAN 2018 Author Profiling Task includes both texts and images, using both texts and images in a neural network will improve the performances. Therefore, we tackle this task using both texts and images in a DNN-based approach.</p><p>In order to leverage the synergy of the texts and images, we propose Text Image Fusion Neural Network (TIFNN), which considers their interaction. This paper makes the following contributions.</p><p>1. We propose an effective fusion strategy for a neural network to utilize texts and images for gender identification. 2. We show that TIFNN has drastically improved accuracies (3-8pt) compared with both a text-based neural network and an image-based neural network.</p><p>In the following section of this paper, we first explain the related work in Section 2. Our neural network model is described in Section 3. The details of the experiments used to confirm the model's performances are described in Section 4. Finally, we conclude the paper and outline future work in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>PAN Author Profiling Task was to identify both age and gender from social media text in the past PAN series before 2017 edition <ref type="bibr" coords="2,310.80,294.08,15.77,8.76" target="#b11">[12,</ref><ref type="bibr" coords="2,326.57,294.08,11.83,8.76" target="#b14">15]</ref>. In the last year, the task included language variety identification instead of age identification <ref type="bibr" coords="2,374.27,306.03,15.27,8.76" target="#b13">[14]</ref>. In PAN 2017 Author Profiling Task, various models that used not only traditional machine learning but also deep neural networks were presented.</p><p>Basile et al. <ref type="bibr" coords="2,200.35,342.80,11.62,8.76" target="#b0">[1]</ref> used linear support vector machine (SVM) with character 3-to 5grams and word 1-to 2-grams features and showed that it outperforms other approaches. Martinc et al. <ref type="bibr" coords="2,190.96,366.71,11.62,8.76" target="#b7">[8]</ref> explored many approaches (e.g. linear SVM, logistic regression, random forest, XGBoost, and voting classifier combining these models) with various parameters for this task. They finally tested logistic regression because it showed the best performance. Tellez et al. <ref type="bibr" coords="2,236.96,402.57,16.60,8.76" target="#b19">[20]</ref> used a generic framework for text classification, as called MicroTC. As shown in these researches, the approaches of traditional machine learning that were carefully designed showed the superior performances in this task.</p><p>On the other hand, the approaches based on deep neural networks were also presented <ref type="bibr" coords="2,163.66,451.29,11.56,8.76" target="#b5">[6,</ref><ref type="bibr" coords="2,175.22,451.29,7.71,8.76" target="#b6">7,</ref><ref type="bibr" coords="2,182.93,451.29,7.71,8.76" target="#b8">9,</ref><ref type="bibr" coords="2,190.63,451.29,11.56,8.76" target="#b15">16,</ref><ref type="bibr" coords="2,202.20,451.29,11.56,8.76" target="#b17">18]</ref>. Miura et al. <ref type="bibr" coords="2,272.61,451.29,11.62,8.76" target="#b8">[9]</ref> used both bi-directional GRU with an attention mechanism to capture the word representations and convolutional neural network (CNN) to capture the character representations. Sierra et al. <ref type="bibr" coords="2,350.23,475.20,16.60,8.76" target="#b17">[18]</ref> applied CNN that has a set of convolutional filters of different sizes to capture n-gram features. Although the approaches using deep neural networks are strong model for many NLP tasks, the above approaches could not outperform traditional machine learning approaches in this task.</p><p>In author profiling tasks outside of PAN, researches utilizing images or multimodality also exist. The research of <ref type="bibr" coords="2,257.55,535.88,16.60,8.76" target="#b16">[17]</ref> utilized images to identify the gender of users and the object of images with a multi-task bilinear model. In addition, the research of <ref type="bibr" coords="2,463.99,547.83,16.60,8.76" target="#b20">[21]</ref> presented a state-of-the-art model that utilized both texts and images to predict users' traits such as gender, age, political orientation, and location.</p><p>As overviewed in this section, the approaches using traditional machine learning showed the superior performances in past PAN series. Although the approaches based on deep neural networks utilizing only text could not outperform traditional machine learning approaches, the researches of <ref type="bibr" coords="2,286.27,620.46,16.60,8.76" target="#b16">[17,</ref><ref type="bibr" coords="2,302.87,620.46,12.45,8.76" target="#b20">21]</ref> indicated that utilizing images is effective in the prediction of author profile traits. Because using images is possible in PAN 2018 Author Profiling Task, utilizing both texts and images would be effective for gender identification. 3 Model</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Proposed Model</head><p>Figure <ref type="figure" coords="3,163.29,485.89,4.98,8.76" target="#fig_0">1</ref> illustrates the proposed model. The model is constructed of a text component, an image component, and a fusion component. The proposed model processes texts and images in their respective components. The fusion component computes the relationship between the texts and images using direct-product, column-wise pooling, and row-wise pooling. Finally, the combination feature of the texts and images is fed to two fully connected layers.</p><p>In the following, we first describe each component of the model in Section 3.2 and 3.3. The details of the fusion component are also described in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Text Component</head><p>This section describes the text component of the model, which is the "Text Component" division in Figure <ref type="figure" coords="3,208.52,632.42,3.74,8.76" target="#fig_0">1</ref>. The component is implemented based on the previous models <ref type="bibr" coords="3,463.43,632.42,12.87,8.76" target="#b8">[9]</ref>. layers. For the RNN, we used Gated Recurrent Unit (GRU) <ref type="bibr" coords="4,382.81,345.97,11.62,8.76" target="#b3">[4]</ref> with a bi-directional setting.</p><p>First, the input words are embedded to k w dimensional word embeddings with embedding matrix E w to obtain x with x t ∈ R kw . x are then fed to RNN W with the following transition functions: </p><formula xml:id="formula_0" coords="4,218.13,429.67,262.47,41.48">z t = σ (W z x t + U z h t-1 + b z ) (1) r t = σ (W r x t + U r h t-1 + b r ) (2) ht = tanh (W h x t + U h (r t ⊙ h t-1 ) + b h )<label>(3)</label></formula><formula xml:id="formula_1" coords="4,217.43,475.72,263.17,12.28">h t = (1 -z t ) ⊙ h t-1 + z t ⊙ ht<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Image Component</head><p>This section describes the image component of the model, which is the "Image Component" division in Figure <ref type="figure" coords="4,243.78,656.33,3.74,8.76" target="#fig_0">1</ref>. Figure <ref type="figure" coords="4,283.19,656.33,4.98,8.76">3</ref> provides an overview of the image component. CNN I in Figure <ref type="figure" coords="5,219.31,470.19,4.98,8.76" target="#fig_0">1</ref> represents the layers from Conv.Layers1 to FC7 in Figure <ref type="figure" coords="5,473.12,470.19,3.74,8.76">3</ref>. This architecture is implemented based on VGG16 <ref type="bibr" coords="5,339.51,482.14,15.27,8.76" target="#b18">[19]</ref>. CNN I utilizes the layers from Conv.Layers1 to FC7 to extract each image feature.</p><p>Pooling FI fuses the features extracted from images. The images posted by a single author on social media can be regarded as a kind of time series. However, we cannot know the ground truth of the images' order in time steps and the interval of time between posted images. Therefore, we simply use the average or max operation over image features as Pooling I .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Fusion Component</head><p>The fusion component is expected to complementarily capture the relationship between the texts and images. User representation r txt ∈ R M is obtained via the text component and r img ∈ R L is obtained via the image component. The relationship between the texts and images is represented as a matrix G ∈ R M ×L with the following equation:</p><formula xml:id="formula_2" coords="5,272.17,656.09,204.55,9.68">G = r txt ⊗ r img (<label>5</label></formula><formula xml:id="formula_3" coords="5,476.72,656.33,3.87,8.76">)</formula><p>where ⊗ is a direct-product operation. We apply column-wise and row-wise maxpoolings over G to generate g txt ∈ R M and g img ∈ R L , respectively. Formally, the j-th elements of the vector g txt and the j-th elements of the vector g img are computed in the following operation:</p><formula xml:id="formula_4" coords="6,260.60,177.90,219.99,14.66">[g txt ] j = max 1≤l≤L [G j,l ]<label>(6)</label></formula><formula xml:id="formula_5" coords="6,257.11,199.05,223.48,14.60">[g img ] j = max 1≤m≤M [G m,j ]<label>(7)</label></formula><p>We can interpret the j-th element of the vector g txt as an importance degree for the j-th text feature with regard to image features. Finally, the vectors g txt and g img are concatenated to obtain g comb as g comb = [g txt , g img ] and passed to FC1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>This section describes two datasets: PAN@CLEF 2018 Author Profiling Training Corpus and streaming tweets. PAN@CLEF 2018 Author Profiling Training Corpus was utilized to train the proposed model and comparison models. Streaming tweets were utilized to pre-train a word embedding matrix E w .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PAN@CLEF 2018 Author Profiling Training Corpus</head><p>The first dataset we used to train the proposed model was the official PAN@CLEF 2018 Author Profiling Training Corpus. This dataset is constructed of users' tweets in three languages: English, Spanish, and Arabic. There are 3, 000 English language users, 3, 000 Spanish language users, and 1, 500 Arabic language users, with a gender ratio of 1:1. We used random sampling to divide this dataset into train 8 , dev 1 , and test 1 , with a ratio of 8:1:1, while maintaining the gender ratio of 1:1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Streaming Tweets</head><p>The second dataset we used to pre-train the word embeddings was composed of tweets collected by Twitter Streaming APIs<ref type="foot" coords="6,359.63,518.23,3.49,6.13" target="#foot_0">1</ref> . We used the collected tweets to pre-train the word embedding matrix E w of the proposed model and the comparison models. Table <ref type="table" coords="6,193.99,543.78,4.98,8.76" target="#tab_1">1</ref> lists the number of resulting tweets. The process of collecting tweets was described in <ref type="bibr" coords="6,207.09,555.73,10.58,8.76" target="#b8">[9]</ref>. We will describe the process to pre-train the word embedding matrix in Section 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Model Initialization</head><p>We pre-trained each component for the proposed model. We used three steps to initialize the proposed model for training according to the following procedure. Initialization of text component We first pre-trained a word embedding matrix E w for the text component. The details of the pre-training of the word embeddings will be described in Section 4.3. The text component was trained using train 8 and dev 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Initialization of image component</head><p>The image component was trained by fine-tuning on train 8 and dev 1 . First, the layers from Conv.Layers1 to FC7 described in Figure <ref type="figure" coords="7,475.61,285.82,4.98,8.76">3</ref> (VGG16) were pre-trained on ImageNet <ref type="bibr" coords="7,297.23,297.77,10.58,8.76" target="#b4">[5]</ref>. We then initialized CNN I , as described in Figure <ref type="figure" coords="7,163.26,309.73,3.74,8.76" target="#fig_0">1</ref>, using the pre-trained VGG16. Finally, FC UI was then randomly initialized.</p><p>Initialization of TIFNN We described the pre-training procedure for each component using train 8 and dev 1 above. This was done because TIFNN could be successfully trained utilizing pre-trained text and image components. Thus, we used the pre-trained text and image components to train TIFNN. Therefore, all of TIFNN parameters except FC1 and FC2 were initialized with the parameters of the pre-trained components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Configurations</head><p>Text pre-processing We applied unicode normalization, user name normalization, URL normalization, and HTML normalization. We used twokenizer <ref type="bibr" coords="7,415.59,443.19,16.60,8.76" target="#b9">[10]</ref> for the English text. We used WordPunctTokenizer in NLTK <ref type="bibr" coords="7,340.11,455.15,11.62,8.76" target="#b1">[2]</ref> for the other languages for tokenization.</p><p>Image pre-processing We applied two resizing methods: direct resizing and resizingcropping.</p><p>-Direct resizing: We resized images to 224 pixels × 224 pixels.</p><p>-Resizing-cropping: We resized images to 256 pixels × 256 pixels and then cropped the center of each image to 224 pixels × 224 pixels.</p><p>Direct resizing was applied to an image-based neural network and resizing-cropping to TIFNN. After resizing, normalization was applied to all the images by subtracting the average values of the RGB channels for each language.</p><p>Initialization of word embeddings We used fastText <ref type="bibr" coords="7,351.27,620.46,11.62,8.76" target="#b2">[3]</ref> with the skip-gram algorithm to pre-train a word embedding matrix E w . The pre-training parameters were as follows: dimension = 100, learning rate = 0.025, window size = 5, negative sample = Parameters and pooling settings for proposed model Table <ref type="table" coords="8,386.86,273.83,4.98,8.76" target="#tab_2">2</ref> summarizes the number of parameters in the proposed model. In addition, Pooling W was applied as a max pooling layer for each language, Pooling I was applied as an average operation for each language, and Pooling T was applied as a max pooling layer for Arabic or an average pooling layer for the other languages.</p><p>Optimization strategies We used cross-entropy loss as an objective function for the models. The objective function of TIFNN was minimized over shuffled mini-batches with SGD. We also used Adam for the text component and SGD for an image component. The initial SGD learning rate for the image component was set at 1e -3 . In addition, we selected the best TIFNN learning rate for each language: 5e -3 for English and 1e -2 for the other languages.</p><p>Parameter selection The models had l 2 regularization parameter α. We selected the best parameter α of the text component from the following candidates. On the other hand, the parameter α of TIFNN was fixed at α = 1e -5 .</p><p>α ∈ {1e -3 , 5e -4 , 1e -4 , 5e -5 , 1e -5 }</p><p>We explored the best parameter α for each model using dev 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Comparison Models</head><p>We next describe the details of the comparison models used for the in-house experiment. Figure <ref type="figure" coords="8,163.26,573.75,4.98,8.76" target="#fig_5">4</ref> illustrates the following comparison models, except the baseline.</p><p>baseline The model was constructed of SVM using TF-IDF uni-gram features.</p><p>Text NN The text component in the figure is the same as that for Figure <ref type="figure" coords="8,448.64,608.38,4.98,8.76">2</ref> (from WordEmbedding to FC1 UT ). The parameter α is set to 1e -3 for English, 1e -4 for Spanish, and 5e -5 for Arabic. Image NN The image component in the figure is the same as that for Figure <ref type="figure" coords="8,449.90,644.37,4.98,8.76">3</ref>    The parameter of FC1 is different from that listed in Table <ref type="table" coords="9,387.35,460.72,3.88,8.76" target="#tab_2">2</ref>; we set it to 100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">In-house Experiment</head><p>We evaluated the proposed model and the comparison models using train 8 , dev 1 , and test 1 . With the exception of the baseline, the models were trained using Titan X GPUs. Table <ref type="table" coords="9,159.13,528.64,4.98,8.76" target="#tab_3">3</ref> summarizes the gender identification results. As listed in Table <ref type="table" coords="9,221.20,540.59,3.74,8.76" target="#tab_3">3</ref>, Text NN and Image NN achieved accuracies of 80.0-82.3% for each language. TIFNN drastically improved the accuracies (3-8pt) for each language compared with Text NN and Image NN in this task. Furthermore, TIFNN has also improved the accuracies for English and Spanish compared with Text NN + Image NN. This indicated that obtaining a fusion synergy via the fusion component was an effective approach for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Submission Run</head><p>We chose the best performing models, which were the Text NN, Image NN, and TIFNN, as described in a TIRA virtual machine <ref type="bibr" coords="10,233.58,360.28,16.60,8.76" target="#b10">[11]</ref> with CPUs. Table <ref type="table" coords="10,326.91,360.28,4.98,8.76" target="#tab_5">4</ref> summarizes the performances of the models in the submission run that are published as the official PAN results <ref type="foot" coords="10,433.94,370.60,3.49,6.13" target="#foot_1">2</ref> . Although the models have lower accuracies compared with the in-house experiment, it is observed that TIFNN has better accuracies for each language compared with Text NN and Image NN. They ranked 1st in English ranking, 2nd in Spanish ranking, 7th in Arabic ranking, and 1st in Global ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we proposed Text Image Fusion Neural Network (TIFNN) for gender identification. In order to leverage the synergy of texts and images, the model computes the relationship between them using the direct-product. In-house experimental results showed that Text NN and Image NN achieved accuracies of 80.0-82.3% for each language in gender identification. TIFNN had drastically improved accuracies (+3-8pt) compared with Text NN and Image NN. Furthermore, TIFNN also had improved accuracies for English and Spanish compared with Text NN + Image NN. In addition to the results of this in-house experiment, we confirmed that TIFNN could improve the accuracy compared with individual models in a submission run.</p><p>In future work, we would like to analyze how the proposed model interacts with texts and images. We believe that understanding this interaction will make it possible to improve TIFNN.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,134.77,395.81,345.82,8.37;3,134.77,406.96,89.13,7.88"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Overview of proposed model. FC denotes a fully connected layer and ⊗ presents the direct-product operation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,144.03,310.74,327.29,8.07"><head>Figure 2 Figure 2 .</head><label>22</label><figDesc>Figure 2. Overview of text component with detailed description of RNNW and PoolingW.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,233.23,339.26,148.89,8.01"><head>Figure 3 .step 1</head><label>31</label><figDesc>Figure 3. Overview of image component.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,457.90,644.37,22.68,8.76;8,151.70,656.12,276.77,9.65"><head></head><label></label><figDesc>(from Conv.Layers1 to FC UI ). The model does not apply l2 regularization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="9,134.77,346.89,345.83,8.01;9,134.77,357.97,253.80,7.88"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Overview of comparison models. The left model denotes Text NN, the center model denotes Image NN, and the right model denotes Text NN + Image NN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.77,500.67,345.83,97.74"><head></head><label></label><figDesc>] and are then fed to Pooling W . In Pooling W , g are processed to obtain i-th tweet feature m t i with max pooling or average pooling over time and are fed to Pooling T . m t i are processed to obtain the j-th user feature m u j , as well as Pooling W . Finally, m u of the user representations are fed to FC1 UT .</figDesc><table coords="4,134.77,534.01,221.26,17.51"><row><cell>-→ h and</cell><cell>← -h are concatenated to obtain g as g t = [</cell><cell>-→ h t ,</cell><cell>← -h t</cell></row></table><note coords="4,134.77,500.67,345.83,12.28;4,134.77,515.22,345.82,9.68;4,134.77,527.21,345.83,9.30"><p>where z t is an update gate, r t is a reset gate, ht is a candidate state, h t is a state, W z , W r , W h , U z , U r , U h are weight matrices, b z , b r , b h are bias vectors, σ is a logistic sigmoid function, and ⊙ is an element-wise multiplication operator. The output vectors</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,134.77,117.97,345.83,70.10"><head>Table 1 .</head><label>1</label><figDesc>Number of tweets collected for each language with Twitter Streaming APIs. M in the table represents the million unit.</figDesc><table coords="7,274.13,117.97,67.11,41.16"><row><cell>Language #tweet</cell></row><row><cell>English 10.72M</cell></row><row><cell>Spanish 3.17M</cell></row><row><cell>Arabic 2.46M</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,134.77,644.16,345.82,20.92"><head>Table 2 .</head><label>2</label><figDesc>Sizes of parameters in proposed model.</figDesc><table coords="7,455.16,644.16,25.42,8.97"><row><cell>5, and</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,196.76,656.33,283.82,8.76"><head>Table 3 ,</head><label>3</label><figDesc>for our submission run. The submission run was performed on</figDesc><table coords="10,207.10,117.97,198.93,63.87"><row><cell>Model</cell><cell>Arabic English Spanish Average</cell></row><row><cell>baseline</cell><cell>0.760 0.800 0.817 0.792</cell></row><row><cell>Text NN</cell><cell>0.813 0.817 0.803 0.811</cell></row><row><cell>Image NN</cell><cell>0.800 0.823 0.800 0.808</cell></row><row><cell cols="2">Text NN + Image NN 0.840 0.863 0.850 0.851</cell></row><row><cell>TIFNN</cell><cell>0.840 0.903 0.863 0.869</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,134.77,187.47,345.83,98.20"><head>Table 3 .</head><label>3</label><figDesc>Performances of proposed model and comparison models for each language on test1. The evaluation metric is accuracy.</figDesc><table coords="10,227.30,244.50,158.53,41.16"><row><cell cols="2">Model Arabic English Spanish Average</cell></row><row><cell>Text NN</cell><cell>0.771 0.797 0.786 0.785</cell></row><row><cell cols="2">Image NN 0.772 0.816 0.773 0.787</cell></row><row><cell>TIFNN</cell><cell>0.785 0.858 0.816 0.820</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,134.77,291.35,345.83,18.97"><head>Table 4 .</head><label>4</label><figDesc>Performances of our models in submission run. The evaluation metric is accuracy. These results are published in the official website of PAN.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="6,144.73,656.99,153.13,7.88"><p>https://dev.twitter.com/streaming/overview</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="10,144.73,656.99,216.75,7.88"><p>https://pan.webis.de/clef18/pan18-web/author-profiling.html</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="11,142.61,145.30,334.76,7.88;11,150.95,156.26,232.18,7.88" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="11,428.04,145.30,49.33,7.88;11,150.95,156.26,117.98,7.88">N-gram: New groningen author-profiling model</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Medvedeva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rawee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Haagsma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Nissim</surname></persName>
		</author>
		<idno>CoRR abs/1707.03764</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,167.72,327.51,7.88;11,150.95,178.68,39.83,7.88" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="11,257.69,167.72,149.71,7.88">Natural Language Processing with Python</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Klein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>O&apos;Reilly Media Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,190.15,325.56,7.88;11,150.95,201.11,191.30,7.88" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="11,333.00,190.15,135.17,7.88;11,150.95,201.11,40.87,7.88">Enriching word vectors with subword information</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.04606</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,142.61,212.57,318.77,7.88;11,150.95,223.53,305.20,7.88;11,150.95,234.49,309.29,7.88;11,150.95,245.45,228.60,7.88" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,193.63,223.53,262.53,7.88;11,150.95,234.49,69.37,7.88">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ç</forename><surname>Gülçehre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,238.11,234.49,222.13,7.88;11,150.95,245.45,141.59,7.88">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,256.91,313.81,7.88;11,150.95,267.87,179.27,7.88" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,364.45,256.91,91.97,7.88;11,150.95,267.87,102.40,7.88">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,271.70,267.87,32.39,7.88">CVPR09</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,279.33,305.67,7.88;11,150.95,290.29,262.33,7.88" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,373.42,279.33,74.86,7.88;11,150.95,290.29,195.79,7.88">Subword-based deep averaging networks for author profiling in social media</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Plotnikova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Pawar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Benajiba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,365.22,290.29,21.92,7.88">CLEF</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,301.76,335.06,7.88;11,150.95,312.72,171.35,7.88" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,353.38,301.76,124.28,7.88;11,150.95,312.72,105.30,7.88">Author profiling with bidirectional rnns using attention with grus</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kodiyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hardegger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Neuhaus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cieliebak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,274.23,312.72,21.92,7.88">CLEF</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,324.18,325.24,7.88;11,150.95,335.14,162.63,7.88" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,324.04,324.18,143.81,7.88;11,150.95,335.14,96.61,7.88">Pan 2017: Author profiling -gender and language variety prediction</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Martinc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Skrjanec</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Zupan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Pollak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,265.52,335.14,21.92,7.88">CLEF</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,346.60,335.63,7.88;11,150.95,357.56,152.31,7.88" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,343.03,346.60,135.21,7.88;11,150.95,357.56,85.86,7.88">Author profiling with word+character neural attention network</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Miura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Taniguchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Taniguchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ohkuma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,255.20,357.56,21.92,7.88">CLEF</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,369.03,326.07,7.88;11,150.95,379.98,326.49,7.88;11,150.95,390.94,324.72,7.88;11,150.95,401.90,291.24,7.88" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,433.70,369.03,34.60,7.88;11,150.95,379.98,255.22,7.88">Improved part-of-speech tagging for online conversational text with word clusters</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Owoputi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>O'connor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,423.91,379.98,53.54,7.88;11,150.95,390.94,324.72,7.88;11,150.95,401.90,213.66,7.88">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL HLT)</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL HLT)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="380" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,413.37,318.55,7.88;11,150.95,424.32,318.49,7.88;11,150.95,435.28,329.64,7.88;11,150.95,446.24,318.19,7.88;11,150.95,457.20,308.40,7.88;11,150.95,468.16,215.67,7.88" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,409.87,413.37,50.92,7.88;11,150.95,424.32,318.49,7.88;11,150.95,435.28,57.88,7.88">Improving the Reproducibility of PAN&apos;s Shared Tasks: Plagiarism Detection, Author Identification, and Author Profiling</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,220.70,446.24,248.44,7.88;11,150.95,457.20,291.40,7.88">Information Access Evaluation meets Multilinguality, Multimodality, and Visualization. 5th International Conference of the CLEF Initiative (CLEF 14)</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Lupu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hall</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Toms</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014-09">Sep 2014</date>
			<biblScope unit="page" from="268" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,479.62,316.18,7.88;11,150.95,490.58,320.92,7.88;11,150.95,501.54,211.80,7.88;11,150.95,512.50,224.36,7.88" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,386.32,479.62,72.10,7.88;11,150.95,490.58,115.00,7.88">Overview of the 3rd author profiling task at pan 2015</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">C P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<ptr target="http://www.clef-initiative.eu/publication/working-notes" />
	</analytic>
	<monogr>
		<title level="m" coord="11,284.44,490.58,117.34,7.88">CLEF 2015 Labs and Workshops</title>
		<title level="s" coord="11,408.24,490.58,63.63,7.88;11,150.95,501.54,133.12,7.88">Notebook Papers. CEUR Workshop Proceedings, CEUR</title>
		<imprint>
			<date type="published" when="2015-09">Sep 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,523.97,324.70,7.88;11,150.95,534.92,303.58,7.88;11,150.95,545.88,317.64,7.88;11,150.95,556.84,308.71,7.88;11,150.95,567.80,20.92,7.88" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,395.33,523.97,71.61,7.88;11,150.95,534.92,287.90,7.88">Overview of the 6th Author Profiling Task at PAN 2018: Multimodal Gender Identification in Twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="11,341.19,545.88,127.40,7.88;11,150.95,556.84,190.21,7.88">Working Notes Papers of the CLEF 2018 Evaluation Labs. CEUR Workshop Proceedings</title>
		<title level="s" coord="11,347.25,556.84,59.14,7.88">CLEF and CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018-09">Sep 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,579.26,325.95,7.88;11,150.95,590.22,319.43,7.88;11,150.95,601.18,61.26,7.88" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,312.90,579.26,155.29,7.88;11,150.95,590.22,224.00,7.88">Overview of the 5th author profiling task at pan 2017: Gender and language variety identification in twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,380.33,590.22,90.05,7.88;11,150.95,601.18,35.11,7.88">Working Notes Papers of the CLEF</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,612.65,329.23,7.88;11,150.95,623.61,305.40,7.88;11,150.95,634.56,291.05,7.88" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,426.76,612.65,44.71,7.88;11,150.95,623.61,233.09,7.88">Overview of the 4th author profiling task at pan 2016: Cross-genre evaluations</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,402.03,623.61,54.32,7.88;11,150.95,634.56,264.90,7.88">Working Notes Papers of the CLEF 2016 Evaluation Labs. CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,646.03,324.48,7.88;11,150.95,656.99,23.90,7.88" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,197.77,646.03,229.27,7.88">Unine at clef 2017: Tf-idf and deep-learning for author profiling</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Schaetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,444.80,646.03,21.92,7.88">CLEF</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,119.86,335.21,7.88;12,150.95,130.82,317.25,7.88;12,150.95,141.78,139.21,7.88" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,296.73,119.86,180.72,7.88;12,150.95,130.82,167.10,7.88">Content-aware multi-task neural networks for user gender inference based on social media images</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Shigenaka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Tsuboshita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,344.42,130.82,123.78,7.88;12,150.95,141.78,65.99,7.88">IEEE International Symposium on Multimedia (ISM)</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="169" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,152.74,332.20,7.88;12,150.95,163.70,165.37,7.88" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="12,351.29,152.74,123.14,7.88;12,150.95,163.70,80.44,7.88">Convolutional neural networks for author profiling in pan</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sierra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Solorio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">A</forename><surname>González</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,268.25,163.70,21.92,7.88">CLEF</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,174.66,316.80,7.88;12,150.95,185.62,307.91,7.88;12,150.95,196.58,112.05,7.88" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="12,260.15,174.66,198.88,7.88;12,150.95,185.62,152.97,7.88">VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,323.66,185.62,135.20,7.88;12,150.95,196.58,85.91,7.88">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,207.53,335.83,7.88;12,150.95,218.49,159.89,7.88" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="12,374.21,207.53,103.86,7.88;12,150.95,218.49,93.67,7.88">Gender and language-variety identification with microtc</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">S</forename><surname>Tellez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Miranda-Jiménez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Moctezuma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,262.77,218.49,21.92,7.88">CLEF</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,229.45,326.49,7.88;12,150.95,240.41,299.84,7.88;12,150.95,251.37,304.48,7.88;12,150.95,262.33,147.89,7.88" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="12,304.09,229.45,164.64,7.88;12,150.95,240.41,113.29,7.88">Twitter demographic classification using deep multi-modal multi-task learning</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Vijayaraghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,282.20,240.41,168.59,7.88;12,150.95,251.37,193.11,7.88">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-08-04">July 30 -August 4. 2017</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
