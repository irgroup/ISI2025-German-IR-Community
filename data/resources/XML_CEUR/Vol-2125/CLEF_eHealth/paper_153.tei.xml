<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,156.15,115.96,303.06,12.62;1,136.64,133.89,342.08,12.62;1,134.77,151.82,345.83,12.62">Toronto CL at CLEF 2018 eHealth Task 1: Multi-lingual ICD-10 Coding using an Ensemble of Recurrent and Convolutional Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,137.42,190.23,58.83,8.74"><forename type="first">Serena</forename><surname>Jeblee</surname></persName>
							<email>sjeblee@cs.toronto.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,206.81,190.23,72.73,8.74"><forename type="first">Akshay</forename><surname>Budhkar</surname></persName>
							<email>abudhkar@cs.toronto.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,290.10,190.23,44.62,8.74"><forename type="first">Saša</forename><surname>Milić</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,345.26,190.23,42.35,8.74"><forename type="first">Jeff</forename><surname>Pinto</surname></persName>
							<email>jeffpinto@cs.toronto.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,398.16,190.23,72.54,8.74"><forename type="first">Chloé</forename><surname>Pou-Prom</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,158.21,202.19,118.05,8.74"><forename type="first">Krishnapriya</forename><surname>Vishnubhotla</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,286.82,202.19,59.13,8.74"><forename type="first">Graeme</forename><surname>Hirst</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,375.89,202.19,63.11,8.74"><forename type="first">Frank</forename><surname>Rudzicz</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Toronto Rehabilitation Institute</orgName>
								<orgName type="institution" key="instit2">UHN</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">The Vector Institute</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,156.15,115.96,303.06,12.62;1,136.64,133.89,342.08,12.62;1,134.77,151.82,345.83,12.62">Toronto CL at CLEF 2018 eHealth Task 1: Multi-lingual ICD-10 Coding using an Ensemble of Recurrent and Convolutional Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C2609BFE98276A184F90D3B82B26A48E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>GRU</term>
					<term>CNN</term>
					<term>ensemble</term>
					<term>word embeddings</term>
					<term>medical coding</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We assign ICD-10 codes to cause-of-death phrases in multiple languages by creating rich and relevant word embedding models. We train 100-dimensional word embeddings on the training data provided, combined with language-specific Wikipedia corpora. We then use n-gram matching of the raw text to the provided ICD dictionary followed by an ensemble model which includes predictions from a CNN classifier and a GRU encoder-decoder model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The International Classification of Diseases (ICD), established by the World Health Organization, provides a standardized and universal way to encode medical diagnoses. Used for the purposes of determining health trends and reporting statistics, the ICD assigns each medical concept, disease, or disorder to a hierarchical letter-digits combination (e.g., A08 denotes "viral and other specified intestinal infections") <ref type="bibr" coords="1,229.76,526.24,14.61,8.74" target="#b22">[23]</ref>. Medical coding is important for public health research and for making clinical and financial decisions. However, the coding process is often expensive and time-consuming, and can be error-prone due to its complex pipeline <ref type="bibr" coords="1,171.65,562.11,14.61,8.74" target="#b10">[11]</ref>. Automated medical coding could offer a potential solution to these problems.</p><p>Here we present our methodology and results for the task 1 of the CLEF 2018 eHealth challenge: "Multilingual information extraction -ICD10 coding" <ref type="bibr" coords="1,134.77,610.67,15.50,8.74" target="#b11">[12,</ref><ref type="bibr" coords="1,151.93,610.67,11.62,8.74" target="#b19">20]</ref>. This task consists of assigning ICD-10 codes <ref type="bibr" coords="1,368.86,610.67,15.50,8.74" target="#b22">[23]</ref> (the tenth revision of ICD) <ref type="foot" coords="1,157.04,621.05,3.97,6.12" target="#foot_0">4</ref> to the text of death certificates. Datasets are provided for three languages: French, Italian, and Hungarian, and we submit results for all three.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>The recent popularity of neural network-based methods has spread to the healthcare domain, especially convolutional neural networks (CNNs) and recurrent neural networks (RNNs), both of which we use in this paper. A variety of models have been successfully applied to health-related automated tasks, such as predicting hospital readmissions and suicide risk <ref type="bibr" coords="2,347.10,188.50,15.50,8.74" target="#b18">[19,</ref><ref type="bibr" coords="2,364.25,188.50,12.73,8.74" target="#b12">13]</ref> and automated diagnosis and information extraction using deep convolutional belief networks <ref type="bibr" coords="2,448.34,200.45,9.96,8.74" target="#b8">[9]</ref>.</p><p>For this task, we can treat ICD coding as a sequence-to-sequence problem of words to ICD codes. Indeed, the best submission from the CLEF eHealth 2017 challenge achieved an F 1 score of 85.01% on the test data using an encoderdecoder model <ref type="bibr" coords="2,203.42,248.27,14.61,8.74" target="#b20">[21]</ref>. Other approaches from the 2017 challenge included rulebased systems (IMSUNIPD <ref type="bibr" coords="2,260.24,260.23,14.61,8.74" target="#b14">[15]</ref>, LITL <ref type="bibr" coords="2,309.98,260.23,10.30,8.74" target="#b3">[4]</ref>), SVM classifiers (LIMSI <ref type="bibr" coords="2,438.29,260.23,14.76,8.74" target="#b23">[24]</ref>), and query-based algorithms (SIBM <ref type="bibr" coords="2,272.06,272.18,9.96,8.74" target="#b0">[1]</ref>, WBI <ref type="bibr" coords="2,312.88,272.18,14.61,8.74" target="#b21">[22]</ref>, LITL).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data and pre-processing</head><p>The provided training data consists of cause-of-death texts, ICD-10 codes, and demographic information in the French, Hungarian, and Italian languages. The data is given in either raw or aligned format. Raw data consists of the following three files:</p><p>-A CausesBrutes file containing values for DocID (the death certificate ID), YearCoded (the year the death certificate was processed), LineID (the line number within the death certificate), RawText (the raw text entered by the physician in the death certificate), IntType (the type of time interval the patient had been suffering from coded cause), and IntValue (the time interval of IntType). -A CausesCalculees file containing the ICD-10 codes. Similar to Causes-Brutes, this file contains the DocID, YearCoded, and LineID fields. Additionally, this file includes values for CauseRank (the rank of the ICD-10 code assigned by the coder), StandardText (the dictionary entry or excerpt of RawText that supports the assigned code), and ICD10 (the gold standard ICD-10 code). -A Ident file containing demographic information. This file contains the DocID, YearCoded, and LineID fields, as well as the following fields: Gender (the gender of the deceased), PrimCauseCode (the code of the primary cause of death), Age (age at the time of death, rounded to the nearest five-year age group), and LocationOfDeath.</p><p>Files are provided in the raw format for the French, Hungarian, and Italian datasets. Additionally, the French data is also provided in an aligned format, consisting of one file in which the information from the CausesBrutes, Caus-esCalculees, and Ident files is already combined.</p><p>For each language, ICD-10 dictionaries are supplied. From these dictionaries, we retain the DiagnosisText (the text description of the given code) and Icd1 (the ICD-10 code) fields.</p><p>For this task we discover that, with the exception of n-gram matching, model performance improves in proportion to the volume and quality of reference data. To this end, we pre-process both training and supplementary reference data to maximize the model's coverage of terms in the text by standardizing the corpora and reducing noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training Data</head><p>We combine the raw format files with the demographic data to create an alignedlike file for each language, since preliminary experiments reveal that using the demographic information greatly improves classification results. We create a concatenated input stream by appending each row of RawText with the YearCoded, Gender, Age, IntType, IntValue, and LocationOfDeath that match the row's DocID and LineID. If a document has multiple rows, each row has identical appended data.</p><p>After initial experiments, we determine that commas (,) in the RawText field often indicate multiple ICD-10 codes. Our results improve by splitting each unaligned training row by commas prior to processing for the n-gram and the CNN models, thus assigning n + 1 codes given a row with n commas. Removing accents from the text does not improve performance on the training data, so we keep all accents for all languages. We lowercase and strip the text from the RawText field of all punctuation symbols for all of our models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Supplementary data</head><p>For our word embedding models, we use publicly available monolingual Wikipedia data from Linguatools <ref type="bibr" coords="3,237.04,438.99,9.96,8.74" target="#b6">[7]</ref>. The supplementary data is pre-processed to reduce the content to only alphabetical characters (including accented characters), since the input RawText does not contain significant numeric data. In addition to removing web URLs and extra whitespace, we remove any characters not in the language-specific lists in Table <ref type="table" coords="3,271.93,486.81,3.87,8.74">1</ref>, and convert all text to lower case. After preprocessing, we have over 9M lines of Hungarian (120M tokens), 21M lines of Italian (370M tokens), and 32M lines of French (540M tokens) supplemental data. Table <ref type="table" coords="3,164.73,552.73,4.13,7.89">1</ref>. Allowed characters in supplementary data. We pre-process the Wikipedia data by removing web URLs, whitespace, and any characters not in these lists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language Allowed characters</head><formula xml:id="formula_0" coords="3,221.85,594.40,171.66,33.69">French a-zA-Z À-ÖØ-öø-ÿ Hungarian a-záéúőóüöíA-Z ÁÉ Ú Ő Ó Ü ÖÍ Italian a-zA-Zàèéìíîòóùú ÀÈÉÌÍÎ Ò Ó Ù Ú Table 2.</formula><p>Vocabulary coverage of our word embedding models on the test data, compared to models from Facebook MUSE. We report the dimensions of each word embedding, and the vocabulary coverage as quantified by the percentage of types and of tokens of the test data that can be found in the corresponding word embedding model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language Embeddings Dimensions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Word embeddings</head><p>We experiment with pre-trained French, Hungarian, and Italian word embedding models from the Facebook MUSE dataset <ref type="bibr" coords="4,319.17,329.68,9.96,8.74" target="#b1">[2]</ref>, but discover that they have fairly low vocabulary coverage on the training data. In order to get better coverage, we train our own word embeddings using Wikipedia data (Section 3.2), which we augment with the RawText field from the training data and the dictionaries. The training and dictionary texts are repeated N = 4 times, (N is chosen empirically to increase the overall accuracy). We use the word2vec <ref type="bibr" coords="4,381.61,389.45,15.50,8.74" target="#b9">[10]</ref> implementation in Gensim <ref type="bibr" coords="4,171.16,401.41,14.61,8.74" target="#b17">[18]</ref>, with a context window size of 2 and a minimum word occurrence frequency set to 4. We set the dimensions of our word embeddings to 100, chosen for the ease of potentially aligning these vectors to other publicly available vectors trained on medical datasets. Because we train the word embedding models on text from the provided training data, we get 100% vocabulary coverage of the training data, and very high coverage of the testing data. See Table <ref type="table" coords="4,336.33,474.92,4.98,8.74">2</ref> for coverage on the test set of our word embeddings models compared to pre-trained models from Facebook MUSE. We report vocabulary coverage as the percentage of types (i.e., distinct words) and the percentage of tokens (i.e., all words) from the RawText field that can be found in the given word vector model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Models</head><p>We use n-gram text matching followed by a variety of neural network models. We implement the neural network models in PyTorch <ref type="bibr" coords="4,369.74,608.30,15.50,8.74" target="#b15">[16]</ref> with CUDA <ref type="bibr" coords="4,443.23,608.30,14.61,8.74" target="#b13">[14]</ref>, and train them on the sequence of word embeddings representing the text of each line. We conduct 10-fold cross-validation on the training data in order to choose the final models and parameters, using scikit-learn's GroupKFold function <ref type="bibr" coords="4,134.77,656.12,14.61,8.74" target="#b16">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">N -gram matching</head><p>The "first pass" of our pipeline checks whether the text string has an exact match in the dictionary. If so, we use the corresponding ICD code as our target. We experiment with spelling correction on the input text before matching it to dictionary text, since we notice that there are spelling errors in the training data. For spelling correction we use the pyenchant package <ref type="bibr" coords="5,416.66,185.53,9.96,8.74" target="#b4">[5]</ref>. pyenchant computes edit distance between a given string and vocabulary; the vocabulary we supply in this case is the words in the dictionary entries. Because spellcheck improves precision only on the French dataset, our French classifier is the only one which performs spellcheck before the exact match procedure. Interestingly, the French, Italian, and Hungarian datasets have notably different F 1 scores when this simple procedure is applied. This perhaps suggests a different model or approach for each language might be necessary for classification rather than one language-agnostic approach. Occasionally, the exact same text might map to more than one ICD code. If this happens, the most frequent ICD code is taken -frequency is computed across all training data in all languages (we assume that the distribution of ICD codes is the same across year and region).</p><p>N -gram matching on the Hungarian dataset We note that the Hungarian dataset performs well with pattern matching, thus for one of our test runs, we submit results obtained with a purely rule-based, pattern-matching classifier. Specifically, for the Hungarian data set, a "second pass" is performed in which bigrams of the input text are matched to bigrams of dictionary text. Since there is a many-to-many mapping between bigrams in the training text and bigrams in the dictionary text, our chosen target ICD code is the one that matches the largest number of bigrams from the input text. Again, ties are broken by choosing the most frequent ICD code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Encoder-decoder</head><p>Similar to work done by <ref type="bibr" coords="5,244.24,488.75,14.61,8.74" target="#b20">[21]</ref>, we build an encoder-decoder model that takes as input a sequence of words and outputs a sequence of ICD codes. We experiment with one-hot vectors and various word embeddings as described in Section 4, and obtain our best results using our own word embeddings trained on the Wikipedia corpora augmented with training data and dictionary data.</p><p>The encoder and decoder architectures consist of gated recurrent units (GRUs) of hidden size 256, to which we apply a dropout of 0.1. The encoder-decoder model is trained on pairs of sequences of tokens of RawText, ICD10 for each line of each death certificate (i.e., for each LineID, DocID). The sequence of ICD10 codes is ordered from left-to-right by increasing rank. The pre-processed sequence of tokens from the RawText field is converted to a sequence of 100dimensional word vectors, and the corresponding ICD-10 codes are converted to one-hot word vectors. We also make use of the demographic information (i.e., the Gender, Age, LocationOfDeath, IntType, IntValue fields) and pass it as input to the decoder as a zero-padded 100-dimensional vector. We train our model for 10 epochs, using the AdaGrad algorithm <ref type="bibr" coords="6,356.42,118.99,10.52,8.74" target="#b2">[3]</ref> and a learning rate of 0.1, where each epoch iterates through the whole training set. The encoder-decoder model training time depends on the size of the input dataset -it takes about 4 hours for the Italian dataset (the smallest one), and up to 12 hours for the Hungarian dataset. Since we order the ICD-10 codes by rank during training, our output sequence of ICD-10 codes is also ordered by rank. For example, for an output of "T293 S299", we assign Rank 1 to "T293" and Rank 2 to "S299".</p><p>We note that unlike the n-gram matching and CNN approaches, we do not split the RawText on commas during training, and give as input the entire text to the encoder-decoder. Since this model treats ICD-10 prediction as a sequenceto-sequence model, it is able to "learn" the correct number of ICD-10 codes for each line of text given, as well as the correct rank order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Convolutional neural network</head><p>We also use a convolutional neural network (CNN). Although CNNs are typically used for image processing, they have also achieved good results on text problems, including tasks in the medical domain <ref type="bibr" coords="6,303.97,343.13,14.61,8.74" target="#b18">[19]</ref>.</p><p>For French and Hungarian data, we apply spelling correction to the text before passing it to the CNN. On the training data, spelling correction does not improve CNN results for Italian, so we do not correct the Italian text. All text is then pre-processed as described in Section 3.</p><p>The CNN model consists of filters of size 1 through 4 by the word embedding size (100), a max pooling layer, and a softmax prediction layer. We use Adam <ref type="bibr" coords="6,470.08,418.30,10.52,8.74" target="#b5">[6]</ref> as the optimizer, with a learning rate of 0.001, and train for 20 epochs. Compared to the encoder-decoder model, the CNN is very fast to train: 5-20 minutes versus 4-12 hours for the encoder-decoder.</p><p>One limitation of the CNN model is that it outputs exactly one ICD code per input line. In order to overcome this limitation, we use the softmax output probabilities from the last layer of the network as the input to the ensemble model, which allows us to choose multiple codes per line for the final output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Ensemble model</head><p>We combine the outputs from the models discussed in the previous sections using a rule-based ensemble model. This model takes as inputs the CNN softmax probabilities for all the ICD codes, the codes predicted by the encoder-decoder model (including their ranks), and the codes predicted by n-gram matching.</p><p>We empirically choose thresholds to optimize the accuracy on the first crossvalidation fold of every language. For each ICD code, the ensemble model determines whether they are assigned to the given RawText based on the following rules:</p><p>(ICD ∈ ende output and ICD ende rank &lt; t ende rank ) or (ICD cnn prob &gt; p cnn ) or (ICD ∈ ngram output and ICD cnn prob &gt; p ngram ) For every ICD code, we first check whether it is in the list of ICD-10 codes producible by the encoder-decoder ende output, and then check whether its rank ICD ende rank falls below the threshold t ende rank . Next, the ensemble model checks whether the ICD code CNN probability ICD cnn prob is greater than the threshold p cnn . Then, the model checks whether the ICD code is in the list of n-gram matched codes ngram output and verifies whether the corresponding CNN probability ICD cnn prob is greater than the threshold p ngram . Here, the CNN probabilities have two thresholds -one for the probabilities of all the ICD codes, and one only for the n-gram matched codes. Any codes that pass one of the checks described above are included in our prediction. The n-gram matched codes are only used for French.</p><p>The ensemble optimizes the rank threshold t ende rank , and the probability thresholds p cnn and p ngram . See Table <ref type="table" coords="7,308.26,337.49,4.98,8.74">3</ref> for the threshold values for the three languages.</p><p>Table <ref type="table" coords="7,163.97,384.58,4.13,7.89">3</ref>. Ensemble thresholds. For each language, the ensemble model optimizes the encoder-decoder rank threshold (t ende rank ), and CNN probability thresholds used to determine inclusion of codes from the CNN (pcnn) and from the n-gram model (pngram). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language Encoder-decoder CNN N -gram</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>Table <ref type="table" coords="7,162.21,570.61,4.98,8.74" target="#tab_1">4</ref> shows the results of the final n-gram models and of the neural network models on the training set (trained and evaluated on the same data). The precision, recall, and F 1 measures are computed from the provided evaluation script on the training data. Table <ref type="table" coords="7,178.44,620.25,4.98,8.74" target="#tab_2">5</ref> shows the results of the final models on the official test set. For French and Italian, we submit runs using our encoder-decoder and ensemble models. For Hungarian, we submit one run using n-gram matching only, and another run using the ensemble model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>In our final submission, we use the n-gram and ensemble models for the Hungarian dataset, and the encoder-decoder and ensemble models for both the Italian and French datasets.</p><p>For Hungarian, we achieve fairly good results using a simple n-gram matching scheme. This suggests that the Hungarian ICD dictionary has better coverage of the words in the death certificate text than the dictionaries of the other two languages. The lines in the Hungarian test data have an average length of 2.9 words (2.0 standard deviation), compared to 2.1 (1.5) for Italian and 3.3 (2.5) for French.</p><p>For the encoder-decoder, CNN, and ensemble model, we use the same framework for all three languages. With training data, this model could easily be extended to new languages.</p><p>Our test results show low recall values for French, especially for the raw data. We suspect that the test data includes ICD codes that our models had not seen during training. A potential way to ensure that our model sees all possible ICD codes would be to include the ICD dictionaries during training. However, in our experiments, combining dictionary data with training data when training the encoder-decoder model actually produced lower results in cross-validation experiments. Augmenting data with the dictionary text skews the distribution of ICD-10 codes, which in turn, affects classification.</p><p>Our best model achieves an F 1 measure of 0.91 on the Hungarian language test data using the ensemble model. An ANOVA on the F 1 measures of our test data reveals no significant effect from either language (F = 3.712, p = 0.212), model (F = 1.033, p = 0.492), or between the effect of the two covariates (F = 0.001, p = 0.982).</p><p>We note that the amount of supplementary material is not proportional to a language's vocabulary coverage. The French Wikipedia corpus has over three times the quantity of tokens and sentences of the Hungarian, yet includes 20% fewer terms (see Table <ref type="table" coords="9,234.56,310.67,3.87,8.74">2</ref>). This implies that the source of supplemental material has varied efficacy depending on the language. Note that spelling is not corrected in the supplemental data, which may reduce the term coverage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We have shown that using in-domain data in addition to a large corpus of general language-specific data for word embeddings, along with neural network models, can achieve fairly high performance on ICD coding in multiple languages. This kind of model does not require any expert knowledge or feature engineering, and therefore can be implemented for any language for which we have training data.</p><p>The performance of this model could be improved in several ways. Our word embedding models are trained on a large corpus of language-specific Wikipedia data, but we would expect a better representation if the embedding models were trained on large corpora of text in the respective languages from the medical domain, such as clinical notes or medical textbooks.</p><p>A multilingual ICD classification model could also benefit from cross-lingual representations such as word embeddings aligned in the same vector space <ref type="bibr" coords="9,467.31,524.22,9.96,8.74" target="#b7">[8]</ref>. We were unable to get a good alignment for this task, but such an alignment would allow us to train models on multiple languages, and apply them to any language for which we have aligned word embeddings.</p><p>This model could also potentially benefit from character-based embeddings and RNN models, especially for agglutinative languages such as Hungarian, which have complex morphology. For such languages, more pre-processing such as morphological analysis could also help.</p><p>This challenge exposes several aspects of disease prediction that must be overcome if machine learning is to be applied globally to the electronic medical record. Not least of these aspects includes differences that occur between languages -both in terms of their own structure and semantics but also in terms of the availability of data resources from which models are to be trained. Although we have made progress in terms of overall precision and recall, more work remains.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,134.77,115.91,345.83,192.50"><head>Table 4 .</head><label>4</label><figDesc>Results of the final models on the training data. We report the precision, recall, and F1 scores as given by the evaluation script. Models for which we submit test results are in bold.</figDesc><table coords="8,152.72,156.86,309.92,151.55"><row><cell cols="2">Language Model</cell><cell cols="2">Precision Recall F1</cell></row><row><cell>French</cell><cell>Exact match</cell><cell>0.879</cell><cell>0.464 0.608</cell></row><row><cell></cell><cell>N -gram match</cell><cell>0.754</cell><cell>0.585 0.659</cell></row><row><cell></cell><cell cols="2">Exact match + encoder-decoder 0.8666</cell><cell>0.6508 0.7433</cell></row><row><cell></cell><cell>Exact match + ensemble</cell><cell>0.8461</cell><cell>0.7857 0.8148</cell></row><row><cell cols="2">Hungarian Exact match</cell><cell>0.977</cell><cell>0.650 0.780</cell></row><row><cell></cell><cell>N -gram match</cell><cell>0.875</cell><cell>0.865 0.870</cell></row><row><cell></cell><cell>Exact match + encoder-decoder</cell><cell>0.9329</cell><cell>0.9022 0.9173</cell></row><row><cell></cell><cell>Exact match + ensemble</cell><cell>0.9304</cell><cell>0.9043 0.9172</cell></row><row><cell>Italian</cell><cell>Exact match</cell><cell>0.988</cell><cell>0.291 0.450</cell></row><row><cell></cell><cell>Exact match + spellcheck</cell><cell>0.937</cell><cell>0.559 0.700</cell></row><row><cell></cell><cell cols="2">Longest n-gram match + spellcheck 0.708</cell><cell>0.613 0.657</cell></row><row><cell></cell><cell cols="2">Exact match + encoder-decoder 0.9475</cell><cell>0.8719 0.9081</cell></row><row><cell></cell><cell>Exact match + ensemble</cell><cell>0.9375</cell><cell>0.8740 0.9046</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,134.77,334.97,345.82,118.42"><head>Table 5 .</head><label>5</label><figDesc>Results on the test data (official evaluation). Bold indicates the better score.</figDesc><table coords="8,154.00,356.24,307.36,97.15"><row><cell>Language</cell><cell>Model</cell><cell cols="2">Precision Recall F1</cell></row><row><cell cols="3">French (aligned ) Exact match + encoder-decoder 0.8152</cell><cell>0.7118 0.7600</cell></row><row><cell></cell><cell>Exact match + ensemble</cell><cell>0.8103</cell><cell>0.7195 0.7622</cell></row><row><cell>French (raw )</cell><cell cols="2">Exact match + encoder-decoder 0.8466</cell><cell>0.5151 0.6405</cell></row><row><cell></cell><cell>Exact match + ensemble</cell><cell>0.8418</cell><cell>0.5215 0.6440</cell></row><row><cell>Hungarian</cell><cell>N -gram match</cell><cell>0.9013</cell><cell>0.8869 0.8940</cell></row><row><cell></cell><cell>Exact match + ensemble</cell><cell>0.9221</cell><cell>0.8972 0.9095</cell></row><row><cell>Italian</cell><cell cols="2">Exact match + encoder-decoder 0.9077</cell><cell>0.8239 0.8638</cell></row><row><cell></cell><cell>Exact match + ensemble</cell><cell>0.8995</cell><cell>0.8294 0.8630</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="1,144.73,656.80,233.49,7.86"><p>http://apps.who.int/classifications/icd10/browse/2016/en</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.96,197.58,337.63,7.86;10,151.52,208.54,329.07,7.86;10,151.52,219.50,273.20,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,321.00,197.58,159.59,7.86;10,151.52,208.54,227.13,7.86">SIBM at CLEF eHealth Evaluation Lab 2017: Multilingual information extraction with CIM-IND</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cabot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">F</forename><surname>Soualmia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">J</forename><surname>Darmoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,400.85,208.54,79.74,7.86;10,151.52,219.50,192.94,7.86">CLEF 2017 Evaluation Labs and Workshop: Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,230.37,337.64,7.86;10,151.52,241.33,249.69,7.86" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.04087</idno>
		<title level="m" coord="10,411.77,230.37,68.82,7.86;10,151.52,241.33,83.48,7.86">Word translation without parallel data</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,142.96,252.20,337.63,7.86;10,151.52,263.13,329.07,7.89;10,151.52,274.12,47.10,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,282.42,252.20,198.17,7.86;10,151.52,263.16,108.60,7.86">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,266.74,263.16,152.99,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011-07">Jul. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,284.99,337.63,7.86;10,151.52,295.95,329.07,7.86;10,151.52,306.91,329.07,7.86;10,151.52,317.87,329.07,7.86;10,151.52,328.83,25.60,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,168.06,306.91,293.13,7.86">LITL at CLEF eHealth2017: Automatic classification of death reports</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">M</forename><surname>Ho-Dac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fabre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Birski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Boudraa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bourriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cassier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Delvenne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Garcia-Gonzalez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Piccinini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Rohrbacher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Séguier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,151.52,317.87,276.62,7.86">CLEF 2017 Evaluation Labs and Workshop: Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,339.70,337.64,7.86;10,151.52,350.66,257.11,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="10,211.48,339.70,228.45,7.86">Python bindings for the enchant spellchecker</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kelly</surname></persName>
		</author>
		<ptr target="https://github.com/rfk/pyenchant" />
		<imprint>
			<date type="published" when="2017">2017. 2018-05-24</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,361.53,337.63,7.86;10,151.52,372.48,207.80,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,231.62,361.53,176.58,7.86">Adam: A method for stochastic optimization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,428.35,361.53,52.24,7.86;10,151.52,372.48,162.74,7.86">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2014-12">dec 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,383.36,30.58,7.86;10,189.84,383.36,10.62,7.86;10,216.77,383.36,49.58,7.86;10,282.65,383.36,41.22,7.86;10,340.17,383.36,49.15,7.86;10,405.62,383.36,30.51,7.86;10,452.43,383.36,28.16,7.86;10,151.52,394.31,283.07,7.86;10,463.00,394.31,17.59,7.86;10,151.52,405.27,92.26,7.86" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kolb</surname></persName>
		</author>
		<ptr target="http://linguatools.org/tools/corpora/wikipedia-monolingual-corpora/" />
		<title level="m" coord="10,216.77,383.36,49.58,7.86;10,282.65,383.36,41.22,7.86;10,340.17,383.36,49.15,7.86;10,405.62,383.36,30.51,7.86">Linguatools; Wikipedia monolingual corpora</title>
		<imprint>
			<date type="published" when="2018-05-24">2018. 2018-05-24</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,416.14,337.64,7.86;10,151.52,427.10,266.86,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="10,316.58,416.14,164.01,7.86;10,151.52,427.10,100.95,7.86">Unsupervised machine translation using monolingual corpora only</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.00043</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,142.96,437.97,337.64,7.86;10,151.52,448.93,329.07,7.86;10,151.52,459.89,329.07,7.86;10,151.52,470.85,22.14,7.86;10,192.14,470.85,44.05,7.86;10,254.69,470.85,24.58,7.86;10,297.75,470.85,182.84,7.86;10,151.52,481.81,186.94,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,367.85,437.97,112.75,7.86;10,151.52,448.93,154.40,7.86">Deep learning for healthcare decision making with EMRs</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Hu</surname></persName>
		</author>
		<idno type="DOI">10.1109/BIBM.2014.6999219</idno>
		<ptr target="http://ieeexplore.ieee.org/document/6999219/" />
	</analytic>
	<monogr>
		<title level="m" coord="10,368.42,448.93,112.17,7.86;10,151.52,459.89,251.72,7.86">IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014-11">2014. November 2014</date>
			<biblScope unit="page" from="556" to="559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,492.68,337.98,7.86;10,151.52,503.64,329.07,7.86;10,151.52,514.60,232.82,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,395.40,492.68,85.19,7.86;10,151.52,503.64,226.83,7.86">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,400.72,503.64,79.87,7.86;10,151.52,514.60,128.88,7.86">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,525.47,337.98,7.86;10,151.52,536.43,329.07,7.86;10,151.52,547.39,329.07,7.86;10,151.52,558.34,329.07,7.86;10,151.52,569.30,101.42,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,329.65,536.43,150.94,7.86;10,151.52,547.39,329.07,7.86;10,151.52,558.34,64.35,7.86">CLEF eHealth 2017 Multilingual Information Extraction task Overview: ICD10 Coding of Death Certificates in English and French</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">N</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lavergne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Rondet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,236.77,558.34,243.82,7.86;10,151.52,569.30,21.16,7.86">CLEF 2017 Evaluation Labs and Workshop: Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,580.17,337.97,7.86;10,151.52,591.13,329.07,7.86;10,151.52,602.09,329.07,7.86;10,151.52,613.05,329.07,7.86;10,151.52,624.01,72.95,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,277.75,591.13,202.84,7.86;10,151.52,602.09,329.07,7.86;10,151.52,613.05,42.42,7.86">CLEF eHealth 2018 Multilingual Information Extraction task Overview: ICD10 coding of death certificates in French, Hungarian and Italian</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Grippo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Morgand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Orsi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Pelikán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ramadier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,213.09,613.05,263.27,7.86">CLEF 2018 Evaluation Labs and Workshop: Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,634.88,337.98,7.86;10,151.52,645.81,329.07,7.89;10,151.52,656.80,72.06,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,387.58,634.88,93.01,7.86;10,151.52,645.84,89.20,7.86">Deepr: A convolutional net for medical records</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Wickramasinghe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,247.06,645.84,206.17,7.86">IEEE Journal of Biomedical and Health Informatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="30" />
			<date type="published" when="2017-07">July 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,119.67,337.97,7.86;11,151.52,130.61,329.07,7.89;11,151.52,141.59,182.03,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,356.03,119.67,124.56,7.86;11,151.52,130.63,44.38,7.86">Scalable parallel programming with CUDA</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nickolls</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Garland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Skadron</surname></persName>
		</author>
		<idno type="DOI">10.1145/1365490.1365500</idno>
		<ptr target="http://doi.acm.org/10.1145/1365490.1365500" />
	</analytic>
	<monogr>
		<title level="j" coord="11,204.46,130.63,25.61,7.86">Queue</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="40" to="53" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,152.55,337.98,7.86;11,151.52,163.51,329.07,7.86;11,151.52,174.47,322.22,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,375.77,152.55,104.82,7.86;11,151.52,163.51,126.59,7.86">A lexicon based approach to classification of ICD10 codes</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">M D</forename><surname>Nunzio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Beghini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Vezzani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Henrot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,285.58,163.51,148.89,7.86;11,455.89,163.51,24.70,7.86;11,151.52,174.47,241.96,7.86">CLEF 2017 Evaluation Labs and Workshop: Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>IMS Unipd at CLEF eHealth Task 1</note>
</biblStruct>

<biblStruct coords="11,142.62,185.43,337.98,7.86;11,151.52,196.39,329.07,7.86;11,151.52,207.34,329.07,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,312.03,196.39,148.99,7.86">Automatic differentiation in pytorch</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,151.52,207.34,300.74,7.86">Autodiff Workshop at Neural Information Processing Systems (NIPS) 2017</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,218.30,337.98,7.86;11,151.52,229.26,329.07,7.86;11,151.52,240.22,329.07,7.86;11,151.52,248.91,329.07,10.13;11,151.52,262.14,178.49,7.86" xml:id="b16">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">É</forename><surname>Duchesnay</surname></persName>
		</author>
		<ptr target="https://dl.acm.org/citation.cfm?id=2078195" />
	</analytic>
	<monogr>
		<title level="j" coord="11,190.35,251.18,163.76,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2001">2001</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,270.83,337.97,10.13;11,151.52,284.06,329.07,7.86;11,151.52,295.02,329.07,7.86;11,151.52,305.98,164.39,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="11,259.39,273.10,221.20,7.86;11,151.52,284.06,28.93,7.86">Software framework for topic modelling with large corpora</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Řehůřek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<ptr target="http://is.muni.cz/publication/884893/en" />
	</analytic>
	<monogr>
		<title level="m" coord="11,212.22,284.06,268.38,7.86;11,151.52,295.02,116.40,7.86">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</title>
		<meeting>the LREC 2010 Workshop on New Challenges for NLP Frameworks<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<publisher>ELRA</publisher>
			<date type="published" when="2010-05">May 2010</date>
			<biblScope unit="page" from="45" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,316.93,337.98,7.86;11,151.52,327.89,329.07,7.86;11,151.52,338.85,230.33,7.86" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="11,352.35,316.93,128.24,7.86;11,151.52,327.89,329.07,7.86">Deep EHR: A survey of recent advances in deep learning techniques for electronic health record (EHR) analysis</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Shickel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tighe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bihorac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rashidi</surname></persName>
		</author>
		<idno type="DOI">10.1109/JBHI.2017.2767063</idno>
		<ptr target="https://doi.org/10.1109/JBHI.2017.2767063" />
		<imprint>
			<date type="published" when="2017-06">June 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,349.81,337.97,7.86;11,151.52,360.77,329.07,7.86;11,151.52,371.73,329.07,7.86;11,151.52,382.69,329.07,7.86;11,151.52,393.65,99.75,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="11,151.52,371.73,193.52,7.86">Overview of the CLEF eHealth Evaluation Lab</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Spijker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ramadier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Jimmy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,387.57,371.73,93.02,7.86;11,151.52,382.69,173.64,7.86">CLEF 2018 -8th Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="11,333.98,382.69,146.61,7.86;11,151.52,393.65,24.41,7.86">Lecture Notes in Computer Science (LNCS</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,404.61,337.98,7.86;11,151.52,415.56,329.07,7.86;11,151.52,426.52,329.07,7.86;11,151.52,437.48,131.41,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="11,311.92,404.61,168.67,7.86;11,151.52,415.56,141.64,7.86">An Encoder-Decoder Model for ICD-10 Coding of Death Certificates</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Tutubalina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Miftahutdinov</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1712.01213" />
	</analytic>
	<monogr>
		<title level="m" coord="11,321.43,415.56,159.16,7.86;11,151.52,426.52,273.37,7.86">Machine Learning for Health Workshop at Neural Information Processing Systems (NIPS) 2017</title>
		<imprint>
			<date type="published" when="2017-12">dec 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,446.17,337.98,10.13;11,151.52,459.40,329.07,7.86;11,151.52,470.36,329.07,7.86;11,151.52,481.32,25.60,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="11,332.00,448.44,148.59,7.86;11,151.52,459.40,304.45,7.86">Multi-lingual ICD-10 coding using a hybrid rule-based and supervised classification approach at CLEF eHealth</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ševa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kittner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Leser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,164.97,470.36,264.67,7.86">CLEF 2017 Evaluation Labs and Workshop: Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,492.28,337.98,7.86;11,151.52,503.24,329.07,7.86;11,151.52,514.19,75.79,7.86" xml:id="b22">
	<monogr>
		<title level="m" coord="11,151.52,492.28,329.08,7.86;11,151.52,503.24,138.79,7.86">World Health Organization: International statistical classifications of diseases and related health problems. 10th rev</title>
		<meeting><address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>World Health Organization</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,525.15,337.98,7.86;11,151.52,536.11,329.07,7.86;11,151.52,547.07,282.93,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="11,279.99,525.15,200.61,7.86;11,151.52,536.11,240.93,7.86">Multiple methods for multi-class, multi-label ICD-10 coding of multi-granularity, multilingual death certificates</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lavergne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,411.78,536.11,68.81,7.86;11,151.52,547.07,202.67,7.86">CLEF 2017 Evaluation Labs and Workshop: Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
