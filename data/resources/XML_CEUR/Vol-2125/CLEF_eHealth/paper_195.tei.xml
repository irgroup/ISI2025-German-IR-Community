<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,134.77,135.07,345.83,12.39;1,199.86,154.92,215.63,10.52">Improving Personalized Consumer Health Search: Notebook for eHealth at CLEF 2018</title>
				<funder ref="#_qXbuXFA">
					<orgName type="full">EACEA</orgName>
				</funder>
				<funder ref="#_nt7TK4W">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,229.37,191.14,43.45,8.74"><forename type="first">Hua</forename><surname>Yang</surname></persName>
							<email>huayangchn@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Évora</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">ZhongYuan University of Technology</orgName>
								<address>
									<settlement>Zhengzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,306.31,191.14,75.20,8.74"><forename type="first">Teresa</forename><surname>Gonçalves</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Évora</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,134.77,135.07,345.83,12.39;1,199.86,154.92,215.63,10.52">Improving Personalized Consumer Health Search: Notebook for eHealth at CLEF 2018</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">45FCD8B8F860053BD403945C05E4FDED</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>health information search</term>
					<term>learning to rank</term>
					<term>query expansion</term>
					<term>UMLS</term>
					<term>word vectors</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>CLEF 2018 eHealth Consumer Health Search task aims to investigate the effectiveness of the information retrieval systems in providing health information to common health consumers. Compared to previous years, this year's task includes five subtasks and adopts new data corpus and set of queries. This paper presents the work of University of Evora participating in two subtasks: IRtask-1 and IRtask-2. It explores the use of learning to rank techniques as well as query expansion approaches. A number of field based features are used for training a learning to rank model and a medical concept model proposed in previous work is re-employed for this year's new task. Word vectors and UMLS are used as query expansion sources. Four runs were submitted to each task accordingly.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>CLEF 2018 eHealth Consumer Health Search (CHS) task is a continuation of the previous CLEF eHealth information retrieval (IR) tasks that started on 2013 <ref type="bibr" coords="1,159.55,513.27,10.52,8.74" target="#b7">[8,</ref><ref type="bibr" coords="1,174.94,513.27,7.01,8.74" target="#b2">3]</ref>. Search engines are commonly used by health consumers seeking better understanding about health problems or medical conditions. This task aims to research on the problem of retrieving web pages to a health consumer for his information needs. The 2018 CHS task includes 5 subtasks and uses a new web corpus and a new set of queries <ref type="bibr" coords="1,315.69,561.09,9.96,8.74" target="#b2">[3]</ref>.</p><p>This paper describes the University of Évora (UEvora) approach to CLEF 2018 eHealth CHS subtasks IRTask-1 and IRtask-2. While IRTask-1 is a standard ad-hoc search that aims at retrieving relevant information to people seeking health advice on the web, IRTask-2 is a personalized search task. This task develops on top of the IRTask-1 and aims to personalize the retrieved list of search results to match user expertise.</p><p>The following questions were investigated by conducting experiments on CLEF 2018 eHealth CHS Task:</p><p>1. How does a model learned from data based on 2016 and 2017 CLEF eHealth IR task <ref type="bibr" coords="2,189.20,131.95,10.52,8.74" target="#b5">[6,</ref><ref type="bibr" coords="2,203.99,131.95,12.73,8.74" target="#b11">12]</ref> perform on this year's new data collection and new set of queries (learning to rank features exploring)? 2. When applying query expansion techniques, as an expansion source, will domain specific word embeddings (built from a medical related training corpus) outperform a domain specific thesaurus? 3. How does the medical concepts model proposed in previous work <ref type="bibr" coords="2,432.96,192.79,10.52,8.74" target="#b8">[9]</ref> perform on a new task?</p><p>2 Methods</p><p>To answer the questions proposed in the previous section, different approaches were employed in this work. To answer the first question, learning to rank techniques were used: a number of features were explored and assessments results from 2016 and 2017 CLEF eHealth IR task were used for training a model. For the second question, a pre-trained word vectors model was used as a source of query expansion and the result is compared to the one retrieved with query expansion using the domain specific United Medical Language System (UMLS) thesaurus. Finally, to tackle the third question, the model proposed in previous work <ref type="bibr" coords="2,158.97,361.51,10.52,8.74" target="#b8">[9]</ref> was re-employed and tested with this year's new task (composed of a a new data corpus and new set of queries).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Pre-processing</head><p>All queries were pre-processed with characters lower-casing, stop words removing and Porter Stemmer stemming. The default stop words list available in the IR platform Terrier 4.2<ref type="foot" coords="2,221.22,450.94,3.97,6.12" target="#foot_0">1</ref> was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Learning to rank</head><p>The assessment results from 2016 and 2017 CLEF eHealth IR task were employed and used to train a learning to rank model where a number of fields based features were explored in this work.</p><p>Features extracted. In this work, a simple group of features on different fields were extracted for training a learning to rank model. Three information fields were considered: title, H1 and else. One kind of the features were using a normal weighting model on a single field. BM25 and PL2 were used as the weighting model, with each weighting model for every field. Query independent features and field length were also taken into account. DL weighting model implementing a simple document length was used <ref type="bibr" coords="2,292.39,635.85,10.52,8.74" target="#b4">[5,</ref><ref type="bibr" coords="2,306.24,635.85,7.01,8.74" target="#b3">4]</ref>.</p><p>Training a model. Different learning to rank algorithms were previously explored (logistic regression, random forests, LambdaMART, AdaRank and List-Net) and among all, LabmdaMART algorithm presented the best performance <ref type="bibr" coords="3,470.08,143.90,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="3,134.77,155.86,7.01,8.74" target="#b6">7]</ref>. As such, this algorithm was employed in this work.</p><p>The assessment results from 2016 and 2017 CLEF eHealth IRtask <ref type="bibr" coords="3,432.59,167.81,15.50,8.74" target="#b11">[12,</ref><ref type="bibr" coords="3,450.63,167.81,7.75,8.74" target="#b5">6]</ref> were used as the training data. For IRtask-1, the topical relevance results were used; the result documents were scored with 0, 1 or 2 representing not relevant, relevant or highly relevant, respectively. For IRtask-2, the understandability scores were used; the scores ranged from -1 to 100, with a higher score representing higher understandability. These results were used directly for training and no extra or further processing was performed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Query expansion with a medical concepts model</head><p>A medical concepts model employed <ref type="bibr" coords="3,297.74,287.13,10.52,8.74" target="#b8">[9]</ref> as a source for query expansion. First, cTAKES<ref type="foot" coords="3,173.09,297.51,3.97,6.12" target="#foot_1">2</ref> , a Natural Language Processing tool, was used to identify the medical concepts present in a query. Next, the following techniques were applied: medical phrase concepts processing, medical term concepts processing and query expansion. Finally, the new terms were added building the new expanded query.</p><p>Two different expansion sources were used: UMLS and word vectors model. For UMLS based expansion, selected terms were added to the original query and the approach employed our previous work <ref type="bibr" coords="3,314.89,370.81,9.96,8.74" target="#b8">[9]</ref>. The word vector model was trained using 2011 and 2012 TREC Medical Records Track collection and Word2vec with a skipgram architecture was used as the training tool <ref type="bibr" coords="3,366.86,394.72,14.61,8.74" target="#b10">[11]</ref>. The vector dimension was set to 1000 and a total of 25,469 vectors were included in the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Pseudo Relevance Feedback</head><p>Besides the query expansion techniques, the pseudo relevance feedback was also tested for automatic expansion during retrieval process. The number of words was set to 10 and the number of top-ranked documents from which those words were extracted was set to 3 in Terrier 4.2 platform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>This section first briefly presents the IR platform employed in this work, the dataset and queries for the task, as well as the evaluation measures used for the assessments. Next is the description of the techniques employed in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">IR model</head><p>Terrier platform version 4.2 was chosen as IR model of the system. The Okapi BM25 weighting model was used with all the parameters set to default values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dataset</head><p>The dataset used in CLEF 2018 CHS task consisted of web pages acquired from the CommonCrawl. By submitting the task queries to the Microsoft Bing APIs repeatedly over a period of time, an initial list of websites used for acquisition was returned. Some URLs domains were excluded and a number of know reliable health websites were added <ref type="foot" coords="4,254.62,186.21,3.97,6.12" target="#foot_2">3</ref> . Totally, a number of 1,903 sites were included in the list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Queries</head><p>The basic query set used for CLEF 2018 CHS task consisted of 50 queries written in English and were issued by the general public to the search service <ref type="bibr" coords="4,441.09,261.61,9.96,8.74" target="#b1">[2]</ref>.</p><p>For IRtask-1, this basic set of 50 queries was used as the input to participating systems. An example of a query is shown in Figure <ref type="figure" coords="4,360.51,285.53,3.87,8.74" target="#fig_0">1</ref>. IRtask-2 was based on IRtask-1 with 7 variations for each query. The first 4 variations were issued by people with no medical backgrounds while the remaining were issued by medical experts. An example for IRtask-2 is shown in Figure <ref type="figure" coords="4,166.20,455.28,3.87,8.74">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Evaluation Measures</head><p>Different evaluation measures were used for IRtask-1 and IRtask-2. For IRtask-1 they were: Normalized Discounted Cumulative Gain at depth 10 (NDCG@10), binary preference-based measure (Bpref) and Rank Biased Precision (RBP) <ref type="bibr" coords="4,462.32,529.10,14.61,8.74" target="#b9">[10]</ref>.</p><p>For IRtask-2, uRBPgr with alpha was be used for the assessment. Based on RBP, uRBPgr is calculated as</p><formula xml:id="formula_0" coords="4,233.90,573.74,246.69,30.55">uRBP = (1 -ρ) K k=1 ρ k-1 r(k)u(k)<label>(1)</label></formula><p>where the u(k) function is a graded gain function for the understandability dimension. The parameter ρ attempts to model user behaviour and was set to In IRTask 2, each topic has 7 query variations. A parameter alpha capturing user expertise is used when evaluating results for query variations. Setting alpha to increasing values, an increasing level of medical expertise across the query variations is modeled <ref type="bibr" coords="5,284.91,466.68,10.52,8.74" target="#b5">[6,</ref><ref type="bibr" coords="5,300.73,466.68,11.62,8.74" target="#b9">10]</ref>. For this task the value was set to {0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0} to query variations 1 to 7, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Experiments</head><p>Four experiments were conducted for each sub-task. Next paragraphs discuss the techniques used.</p><p>Runs for IRTask-1. UEvoraIRTask1Run1 is based on the Medical Concepts Model presented in previous work <ref type="bibr" coords="5,291.65,597.34,9.96,8.74" target="#b8">[9]</ref>. First, cTAKES is used to identify the medical concepts in a pre-processed query. Next, the identified concepts are expanded with UMLS; an extra weight of 2.0 and 1.5 were set for words expanded from a phrase concept or from a term concept, respectively. Then, a phrase is reconstructed into a loose phrase with the maximum interval words set to 2; the loose phrase is regarded as a must check item during the retrieval process.</p><p>Finally, these processed phrases and terms with extra weights are added to the query.</p><p>For UEvoraIRTask1Run2 the same techniques are used but the expansion is performed with the pre-trained word vectors model.</p><p>UEvoraIRTask1Run3 uses a ranking model trained with the topical assessments from 2016 and 2017 CLEF eHealth IR task (see sub-section 2.2).</p><p>UEvoraIRTask1Run4 uses the similar techniques to UEvoraIRTask1Run3, yet using five folders cross validation to obtain a learning to rank model.</p><p>Runs for IRTask-2. Similar techniques and parameters were used for IRTask-2. UEvoraIRTask2Run1 uses the same approach employed UEvoraIRTask1Run1; the queries and their variations were processed and issued to the retrieval system. UEvoraIRTask2Run2 uses a similar approach to UEvoraIRTask2Run1 with queries expanded using a pre-trained word vectors model and for UEvoraIR-Task2Run3 the understandability assessments from 2016 and 2017 CLEF eHealth IR task were used for training a learning to rank model. Finally and for UEvo-raIRTask2Run4, the same techniques of UEvoraTask2run3 were employed and a five cross validation was done when training the learning to rank model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Results</head><p>The assessments for the CLEF eHealth 2018 IR tasks are still being conducted, so they are not available at this time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and future work</head><p>This working note reports the U Évora team participation in two different tasks of CLEF 2018 eHealth CHS. A number of field based features were explored while applying learning to rank techniques. Based on previous work, both UMLS and a word vector model were applied for performing query expansion.</p><p>As the future work, the methods proposed in this paper will be further analyzed: different learning to rank features will be explored and an ensemble algorithm will be investigated.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,229.62,385.60,156.11,7.89;4,223.27,316.97,168.82,53.86"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. An example query for IRtask-1</figDesc><graphic coords="4,223.27,316.97,168.82,53.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,229.62,372.55,156.11,7.89;5,215.84,116.83,183.68,240.95"><head>Fig. 2 . 2 0. 8 .</head><label>228</label><figDesc>Fig. 2. An example query for IRtask-2</figDesc><graphic coords="5,215.84,116.83,183.68,240.95" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,658.44,89.44,7.47"><p>http://terrier.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,144.73,658.44,164.76,7.47"><p>http://ctakes.apache.org/index.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,144.73,647.48,226.95,7.47;4,144.73,658.44,143.21,7.47"><p>https://sites.google.com/view/clef-ehealth-2018/ task-3-consumer-health-search/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This work was supported by <rs type="funder">EACEA</rs> under the <rs type="programName">Erasmus Mundus Action 2</rs>, <rs type="programName">Strand 1 project</rs> <rs type="projectName">LEADER -Links in Europe and Asia for engineering, eDucation</rs>, Enterprise and Research exchanges.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_qXbuXFA">
					<orgName type="program" subtype="full">Erasmus Mundus Action 2</orgName>
				</org>
				<org type="funded-project" xml:id="_nt7TK4W">
					<orgName type="project" subtype="full">LEADER -Links in Europe and Asia for engineering, eDucation</orgName>
					<orgName type="program" subtype="full">Strand 1 project</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,160.23,645.16,330.55,8.74;6,160.23,657.11,290.00,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,301.16,645.16,180.54,8.74">Yahoo! learning to rank challenge overview</title>
		<author>
			<persName coords=""><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,175.45,657.11,201.09,8.74">Proceedings of the Learning to Rank Challenge</title>
		<meeting>the Learning to Rank Challenge</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,160.23,119.99,320.36,8.74;7,160.23,131.95,320.37,8.74;7,160.23,143.90,59.34,8.74" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,277.87,119.99,202.72,8.74;7,160.23,131.95,142.77,8.74">Meta-analysis of the second phase of empirical and user-centered evaluations</title>
		<author>
			<persName coords=""><forename type="first">Lorraine</forename><surname>Goeuriot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">Khresmoi Project</note>
</biblStruct>

<biblStruct coords="7,160.23,155.86,320.36,8.74;7,160.23,167.81,320.37,8.74;7,160.23,179.77,123.97,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,221.29,155.86,249.87,8.74">Overview of the CLEF 2018 Consumer Health Search Task</title>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,176.41,167.81,299.60,8.74">CLEF 2018 Evaluation Labs and Workshop: Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2018-09">September, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,160.23,191.72,320.37,8.74;7,160.23,203.68,320.37,8.74;7,160.23,215.63,88.56,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,414.13,191.72,66.46,8.74;7,160.23,203.68,174.63,8.74">The whens and hows of learning to rank for web search</title>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rodrygo Lt</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,363.14,203.68,94.85,8.74">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="584" to="628" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,160.23,227.59,320.37,8.74;7,160.23,239.54,320.36,8.74;7,160.23,251.50,79.15,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,271.92,227.59,208.67,8.74;7,160.23,239.54,71.08,8.74">About learning models with multiple query dependent features</title>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,256.99,239.54,223.60,8.74">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,160.23,263.45,320.36,8.74;7,160.23,275.41,320.37,8.74;7,160.23,287.36,230.80,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,243.23,263.45,237.36,8.74;7,160.23,275.41,43.68,8.74">Clef 2017 task overview: The ir task at the ehealth evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">Joao</forename><surname>Palotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,231.01,275.41,249.58,8.74;7,160.23,287.36,64.67,8.74">Working Notes of Conference and Labs of the Evaluation (CLEF) Forum</title>
		<title level="s" coord="7,233.72,287.36,126.92,8.74">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,160.23,299.32,320.36,8.74;7,160.23,311.27,320.37,8.74;7,160.23,323.23,168.28,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,318.13,299.32,162.46,8.74;7,160.23,311.27,124.42,8.74">Learning to rank for consumer health search: a semantic approach</title>
		<author>
			<persName coords=""><forename type="first">Luca</forename><surname>Soldaini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nazli</forename><surname>Goharian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,315.28,311.27,165.31,8.74;7,160.23,323.23,37.33,8.74">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="640" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,160.23,335.18,320.37,8.74;7,160.23,347.14,320.37,8.74;7,160.23,359.09,311.61,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,270.85,335.18,209.74,8.74;7,160.23,347.14,18.45,8.74">Overview of the CLEF eHealth Evaluation Lab 2018</title>
		<author>
			<persName coords=""><forename type="first">Hanna</forename><surname>Suominen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,205.02,347.14,270.32,8.74">CLEF 2018 -8th Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="7,160.23,359.09,184.09,8.74">Lecture Notes in Computer Science (LNCS</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018-09">September, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,160.23,371.05,320.37,8.74;7,160.23,383.00,320.36,8.74;7,160.23,394.96,192.45,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,317.47,371.05,163.12,8.74;7,160.23,383.00,4.24,8.74">UEvora at CLEF eHealth 2017 Task 3</title>
		<author>
			<persName coords=""><forename type="first">Hua</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Teresa</forename><surname>Gonçalves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,191.83,383.00,288.76,8.74;7,160.23,394.96,26.32,8.74">Working Notes of Conference and Labs of the Evaluation (CLEF) Forum</title>
		<title level="s" coord="7,195.37,394.96,126.92,8.74">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,160.23,406.91,320.37,8.74;7,160.23,418.87,320.68,8.74;7,160.23,430.82,54.79,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,234.00,406.91,246.59,8.74;7,160.23,418.87,27.35,8.74">Understandability biased evaluation for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,211.74,418.87,198.52,8.74">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="280" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,160.23,442.78,320.36,8.74;7,160.23,454.74,320.36,8.74;7,160.23,466.69,181.28,8.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,250.06,442.78,230.53,8.74;7,160.23,454.74,89.82,8.74">Integrating and evaluating neural word embeddings in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,276.96,454.74,203.63,8.74;7,160.23,466.69,92.98,8.74">Proceedings of the 20th Australasian document computing symposium</title>
		<meeting>the 20th Australasian document computing symposium</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,160.23,478.65,320.37,8.74;7,160.23,490.60,323.26,8.74;7,160.23,502.56,272.65,8.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,258.74,478.65,221.86,8.74;7,160.23,490.60,197.91,8.74">The IR Task at the CLEF eHealth evaluation lab 2016: user-centred health information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,382.38,490.60,101.11,8.74;7,160.23,502.56,146.78,8.74">CLEF 2016-Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1609</biblScope>
			<biblScope unit="page" from="15" to="27" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
