<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,145.44,115.96,324.47,12.62;1,140.19,133.89,334.98,12.62;1,256.72,151.82,101.93,12.62">Location-based species recommendation using co-occurrences and environment-GeoLifeCLEF 2018 challenge</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,144.60,189.49,72.50,8.74"><forename type="first">Benjamin</forename><surname>Deneu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,227.66,189.49,94.13,8.74"><forename type="first">Maximilien</forename><surname>Servajean</surname></persName>
							<email>maximilien.servajean@lirmm.fr</email>
							<affiliation key="aff1">
								<orgName type="laboratory">AMIS</orgName>
								<orgName type="institution">Université Paul Valéry Montpellier</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">LIRMM UMR 5506</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">University of Montpellier</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,332.34,189.49,81.87,8.74"><forename type="first">Christophe</forename><surname>Botella</surname></persName>
							<email>christophe.botella@inria.fr</email>
							<affiliation key="aff3">
								<orgName type="laboratory">AMAP</orgName>
								<orgName type="institution" key="instit1">INRA</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,444.14,189.49,26.62,8.74;1,296.38,201.45,18.13,8.74"><forename type="first">Alexis</forename><surname>Joly</surname></persName>
							<email>alexis.joly@inria.frbenjamin.deneu@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,145.44,115.96,324.47,12.62;1,140.19,133.89,334.98,12.62;1,256.72,151.82,101.93,12.62">Location-based species recommendation using co-occurrences and environment-GeoLifeCLEF 2018 challenge</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">54570AA118611370A2E59206CA9D0C48</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents several approaches for plant predictions given their location in the context of the GeoLifeCLEF 2018 challenge. We have developed three kinds of prediction models, one convolutional neural network on environmental data (CNN), one neural network on co-occurrences data and two other models only based on the spatial occurrences of species (a closest-location classifier and a random forest fitted on the spatial coordinates). We also evaluated the combination of these models through two different late fusion methods (one based on predictive probabilities and the other one based on predictive ranks). Results show the effectiveness of the CNN which obtained the best prediction score of the whole GeoLifeCLEF challenge. The fusion of this model with the spatial ones only provides slight improvements suggesting that the CNN already captured most of the spatial information in addition to the environmental preferences of the plants.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatically predicting the list of species that are the most likely to be observed at a given location is useful for many scenarios in biodiversity informatics. First of all, it could improve species identification processes and tools by reducing the list of candidate species that are observable at a given location (be they automated, semi-automated or based on classical field guides or flora). More generally, it could facilitate biodiversity inventories through the development of location-based recommendation services (typically on mobile phones) as well as the involvement of non-expert nature observers. Last but not least, it might serve educational purposes thanks to biodiversity discovery applications providing innovative features such as contextualized educational pathways. This challenge is highly related to the problem known as Species Distribution Modeling (SDM) in ecology. SDM have become increasingly important in the last few decades for the study of biodiversity, macro ecology, community ecology and the ecology of conservation. An accurate knowledge of the spatial distribution of species is actually of crucial importance for many concrete scenarios including landscape management, preservation of rare and/or endangered species, surveillance of alien invasive species, measurement of human impact or climate change on species, etc. Concretely, the goal of SDM is to infer the spatial distribution of a given species, and they are often based on a set of geo-localized occurrences of that species (collected by naturalists, field ecologists, nature observers, citizen sciences project, etc.). However, it is usually not reliable to learn that distribution directly from the spatial positions of the input occurrences. The two major problems are the limited number of occurrences and the bias of the sampling effort compared to the real underlying distribution. In a real-world dataset, the raw spatial distribution of the occurrences is actually highly influenced by the accessibility of the sites, the preferences and habits of the observers. Another difficulty is that an occurrence means a punctual presence of the species, while no occurrences doesn't mean the species is absent, which makes us very uncertain about regions without observed specimens. For all these reasons, SDM is usually achieved through environmental niche modeling approaches, i.e. by predicting the distribution in the geographic space on the basis of a representation in the environmental space. This environmental space is in most cases represented by climate data (such as temperature, and precipitation), but also by other variables such as soil type, land cover, distance to water, etc. Then, the objective is to learn a function that takes the environmental feature vector of a given location as input and outputs an estimate of the abundance of the species. The main underlying hypothesis is that the abundance function is related to the fundamental ecological niche of the species. That means that in theory, a given species is likely to live in a single privileged ecological niche, characterized by an unimodal distribution in the environmental space. However, in reality, the abundance function is expected to be more complex. Many phenomena can actually affect the distribution of the species relative to its so called abiotic preferences. For instance, environment perturbations, or geographical constraints, or interactions with other living organisms (including humans) might have encourage specimens of that species to live in a different environment. As a consequence, the realized ecological niche of a species can be much more diverse and complex than its hypothetical fundamental niche. Very recently, SDM based on deep neural networks have started to appear <ref type="bibr" coords="2,467.31,537.42,9.96,8.74" target="#b1">[2]</ref>. These first experiments showed that they can have a good predictive power, potentially better than the models used conventionally in ecology. Actually, deep neural networks are able to learn complex nonlinear transformations in a wide variety of domains. In addition, they make it possible to learn an area of environmental representation common to a large number of species, which stabilizes predictions from one species to another and improves them globally. Finally, spatial patterns in environmental variables often contain useful information for species distribution but are generally not considered in conventional models. Conversely, convolutional neural networks effectively use this information and improve prediction performance. In this paper, we report an evaluation study of three main kinds of SDM in the context of the GeoLifeCLEF challenge <ref type="bibr" coords="3,305.30,142.90,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="3,317.49,142.90,7.01,8.74" target="#b3">4]</ref>:</p><p>1. A convolutional neural network aimed at learning the ecological preferences of species thanks to environmental image patches provided as inputs (temperature, soil type, etc.). 2. A purely spatial model based on a random forest fitted on the spatial coordinates of the occurrences of each species. 3. A species co-occurrence model aiming at predicting the likelihood of presence of a given species thanks to the knowledge of the presence of other species.</p><p>Section 2 gives an overview of the data and evaluation methodology of the GeoLifeCLEF challenge. Section 3 provides the detailed description of the evaluated models. Section 4 presents the results of the experiments and their analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data and evaluation methodology</head><p>A detailed description of the protocol used to build the GeoLifeCLEF 2018 dataset is provided in <ref type="bibr" coords="3,234.13,345.28,9.96,8.74" target="#b0">[1]</ref>. In a nutshell, the dataset was built from occurrence data of the Global Biodiversity Information Facility (GBIF), the world's largest open data infrastructure in this domain, funded by governments. It is composed of 291,392 occurrences of N = 3, 336 plant species observed on the French territory between 1835 and 2017. Each occurrence is characterized by 33 local environmental images of 64x64 pixels. These environmental images are windows cropped from wider environmental rasters and centered on the occurrence spatial location. They were constructed from various open datasets including Chelsea Climate, ESDB soil pedology data, Corine Land Cover 2012 soil occupation data, CGIAR-CSI evapotranspiration data, USGS Elevation data (Data available from the U.S. Geological Survey.) and BD Carthage hydrologic data. This dataset was split in 3/4 for training and 1/4 for testing with the constraints that: (i) for each species in the test set, there is at least one observation of it in the train set. and (ii), an observation of a species in the test set is distant of more than 100 meters from all observations of this species in the train set. In the following, we usually denote as x ∈ X a particular occurrence, each x being associated to a spatial position p(x) in the spatial domain D, a species label y(x) and an environmental tensor g(x) of size 64x64x33. We denote as P the set of all spatial positions p covered by X. It is important to note that a given spatial position p 0 ∈ P usually corresponds to several occurrences x j ∈ X, p(x j ) = p 0 observed at that location (18 000 spatial locations over a total of 60 000, because of quantized GPS coordinates or Names-to-GPS transforms). In the training set, up to several hundreds of occurrences can be located at the same place (be they of the same species or not). The occurrences in the test set might also occur at identical locations but, by construction, the occurrence of a given species does never occur at a location closer than 100 meters from the occurrences of the same species in the training set.</p><p>The used evaluation metric is the Mean Reciprocal Rank (MRR). The MRR is a statistic measure for evaluating any process that produces a list of possible responses to a sample of queries ordered by probability of correctness. The reciprocal rank of a query response is the multiplicative inverse of the rank of the first correct answer. The MRR is the average of the reciprocal ranks for the whole test set:</p><formula xml:id="formula_0" coords="4,260.03,187.57,93.35,30.67">M RR = 1 Q Q q=1 1 rank q</formula><p>where Q is the total number of query occurrences x q in the test set and rank q is the rank of the correct species y(x q ) in the ranked list of species predicted by the evaluated method for x q .</p><p>3 Evaluated SDM models</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Convolutional neural network</head><p>It has been previously shown in <ref type="bibr" coords="4,275.70,337.48,10.52,8.74" target="#b1">[2]</ref> that Convolutional Neural Networks (CNN) may reach better predictive performance than classical models used in ecology. Our approach builds upon this idea but differs from the one of Botella et al in several important points:</p><p>-Softmax loss: whereas the CNN of Botella et al. <ref type="bibr" coords="4,365.33,393.13,10.52,8.74" target="#b1">[2]</ref> was aimed at predicting species abundances thanks to a Poisson regression on the learned environmental features, our model rather attempts to predict the most likely species to be observed according to the learned environmental features. In practice, this is simply done by using a softmax layer and a categorical loss instead of the Poisson loss layer used in <ref type="bibr" coords="4,293.56,452.91,9.96,8.74" target="#b1">[2]</ref>. -Unstacking categorical input variables: The environmental data provided within GeoLifeCLEF 2018 is composed of tensors of 64x64X33 pixels. Each tensor encodes the environment observed around a given location and is the result of the concatenation of 33 different environmental variables. Most of them are continuous variables such as the average temperature, the altitude or the distance to water. Thus, the corresponding 64x64 pixel matrices can be processed as classical image channels provided as input of the CNN. Some of the variables are rather of ordinal type (such as ESDB v2). But still, they can be considered as additional channels of the CNN in the sense that the order of the pixel values remains meaningful. This is not true, however, for categorical variables such as the Corine Land Cover soil type variable provided within GeoLifeCLEF. This variable can take up to 48 different categorical values but the order of these values does not have any meaning. Consequently, we preferred unstacking the corresponding channel into 48 different binary channels. Furthermore, to avoid that these new channels become predominant over the other ones, we processed them as a separate input tensor of the CNN (as illustrated in Figure <ref type="figure" coords="4,372.60,656.12,3.87,8.74" target="#fig_0">1</ref>). In the end, our CNN has two different types of input tensors that are merged through a joint fully connected layer on top of a sequence of convolutional layers specific to each input. We validated experimentally that this separation does improve the performance of the model (through cross-validation tests). -Convolution layers architecture: we also used a slightly different architecture of the convolutional layers compared to the one of Botella et al.. The detailed parameters of our new architecture (number of layers, window sizes, etc.) are provided in Figure <ref type="figure" coords="5,275.07,202.73,3.87,8.74" target="#fig_0">1</ref>.</p><p>Learning set up and parameters: All our experiments were conducted using PyTorh deep learning framework <ref type="foot" coords="5,281.95,233.20,3.97,6.12" target="#foot_0">4</ref> and were run on a single computing node equipped with 4 Nvidia GTX 1080 ti GPU. We used the Stochastic Gradient Descent optimization algorithm with a learning rate of 0.001 (decreased every 10 epoch by 10), a momentum of 0.9 and a mini-batch size of 16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Spatial models</head><p>For this category of models, we rely solely on the spatial positions p(x) to model the species distribution (i.e. we do not use the environmental information at all). We did evaluate two different classifiers based on such spatial data:</p><p>1. Closest-location classifier: For any occurrence x q in the test set and its associated spatial position p(x q ), we return the labels of the species observed at the closest location p N N in P train (except p(x q ) itself if p(x q ) ∈ P train ).</p><p>The species are then ranked by their frequency of appearance at location p N N . Note that p(x q ) is excluded from the set of potential closest locations because of the construction protocol of the test. Indeed, as mentioned earlier, it was enforced that the occurrence of a given species in the test set does never occur at a location closer than 100 meters from the occurrences of the same species in the training set. As a consequence, if we took p N N = p(x q ), the right species would never belong to the predicted set of species.</p><p>One of the problem of the above method is that it returns only a subset of species for a given query occurrence x q (i.e. the ones located at p N N .</p><p>Returning a ranked list of all species in the training set would be more profitable with regard to the used evaluation metric (Mean Reciprocal Rank). Thus, to improve the overall performance, we extended the list of the closest species by the list of the most frequent species in the training set (up to reaching the authorized number of 100 predictions for each test item). 2. Random forest classifier: Random forests are known to provide good performance on a large variety of tasks and are likely to outperform the naive closest-location based classifier described above. In particular we used the random forest algorithm implemented within the scikit-learn framework  We used only the spatial positions p(x) as input variables and the species labels y(x) as targets. For any occurrence x q in the test set, the random forest classifier predicts a ranked list of the most likely species according to p(x q ). Concerning the hyper-parametrization of the method, we conducted a few validation tests on the training data and finally used 50 trees of depth 8 for the final runs submitted to the GeoLifeCLEF challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Co-occurrence model</head><p>Species co-occurrence is an important information in that it may capture interdependencies between species that are not explained by the observed environment. For instance, some species live in community because they share preferences for a kind of environment that we don't observe (communities of weeds are often specialized to fine scale agronomic practices that are not reported in our environmental data), they use the available resources in a complementary way, or they favor one another by affecting the local environment (leguminous and graminaceous plants in permanent grasslands). On the opposite, some species are not likely to be observed jointly because they live in different environments, they compete for ressources or negatively affect the environment for others (allelopathy, etc.). To capture this co-occurrence information, it is required to train a model aimed at predicting the likelihood of presence of a given species thanks to the knowledge of the presence of other species (without using the environmental information or the explicit spatial positions). Therefore, we did train a feed-forward neural network taking species abundance vectors as input data and species labels as targets. The abundance vectors were built in a similar way than the closest-location classifier described in section 3.2. For any spatial position q ∈ D, we first aggregate all the occurrences located at the closest location p N N in P train (except q itself). Then, we count the number of occurrences of each species in the aggregated set. More formally, we define the abundance vector z(q) ∈ R N of any spatial position q ∈ D as:</p><formula xml:id="formula_1" coords="7,232.40,495.86,248.19,21.14">∀i, ∀x, z i (q) = p(x)=p N N 1(y(x) = i)<label>(1)</label></formula><p>where 1() is an indicator function equals to one if the condition in parenthesis is true and z i (q) is the component of z(q) corresponding to the abundance of the i-th species. The neural network we used to predict the most likely species based on a given abundance vector is a simple Multi-Layered Perceptron (MLP) with one hidden layer of 256 fully connected neurons. We used ReLU activation functions <ref type="bibr" coords="7,451.10,590.24,10.52,8.74" target="#b4">[5]</ref> and Batch Normalization <ref type="bibr" coords="7,231.06,602.19,10.52,8.74" target="#b2">[3]</ref> for the hidden layer, and a softmax loss function as output of the network. This model was implemented and trained within Pytorch deep learning framework<ref type="foot" coords="7,241.73,624.53,3.97,6.12" target="#foot_2">6</ref> using Adam optimizer with an initial learning rate of 0.0001.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Validation experiments</head><p>We conducted a set of preliminary experiments on the training set before training the final models to be evaluated within the GeoLifeCLEF challenge. Therefore, we extracted a part of the training set (10% occurrences selected at random) and used it as a validation set. We choose two cross-validation protocol :</p><p>-For the two models based on neural network we choose to fix the split between training set and test set (Holdout cross-validation). As, the neural networks took around a day to be learned completely, it was not workable to repeat split and learning many times. Thus, we worked with a single validation set to calibrate all our neural networks models. If we don't fix the train-test split we can't compare the two networks learn once, because the difference of performance can be due to this split. By fixing the train-test split we assume to introduce a bias, but this bias is then constant between the experiments which allows us to compare the performance obtained on a single learning. -For the two spatial models, that require a lower computation time, we choose to not fix the train-test split but to learn the model on twenty random train-test split (Monte Carlo cross-validation). The performance of a model is defined by the average performance of the model on the twenty different train-test split. Like this we don't introduce a bias as for the neural networks but we keep the possibility to compare two models. Note that for the random forest classifier of scikit-learn we need to have at least one occurrence of each species in the training set and one occurrence of each species in the test set. However, some species are present only once in the data, so we had to remove them for validation experiments of this model. For the validation experiments, in addition to the MRR (see section 2), we also measured the top1 accuracy, i.e. the percentage of well predicted occurrence species by the model at the first prediction rank. The validation performance of each model is given in tables 1 and 2. The best model is the CNN. It achieves a pretty good MRR of 0.10 knowing that the ideal MRR cannot exceed 0.409 (due to the fact that several outputs exist for the same entry). On average, it returns the correct species in the position with a success rate close to 1/20 (knowing that there is 3336 species in the training set). Nevertheless, the other models achieve good results too, all are over 0.06 of MRR and the random forest reaches almost 0.08. They return the good species label between 1 time out of 40 and 1 time out of 30. These results show that some fairly simple models can capture a strong information. It would be interesting to study the complementarity between these methods and the CNN to produce a highly predictive model.  Submissions We submitted 10 run files to be evaluated within the LifeCLEF 2018 challenge, each run file containing the prediction of a particular method on the whole test set. It is important to note that this evaluation was conducted entirely in blind, i.e. we never had access to the labels of the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">GeoLifeCLEF challenge: submitted runs and results</head><p>The four first run files we submitted contained the predictions of our four main models, i.e.: The other six run files we submitted corresponded to different fusion schemes of the four base models. Indeed, the base models being trained on different kinds of input data, we expect that their fusion may benefit from their complementarity. We used two different kinds of fusion methods: Late fusion based on probabilities: For each test item we simply average the prediction probabilities of the fused models and then we re-sort the predictions. Note that we could'nt do this late fusion with the closest-location classifier as it doesn't output probabilities, but only species ranks. For the three other models, we evaluated the fusion of all possible pairs and the fusion of the three models: FLO 5: late fusion of the probabilities given by the CNN and the co-occurrences models. FLO 6: late fusion of the probabilities given by the CNN and the spatial random forest models. FLO 7: late fusion of the probabilities given by the co-occurrences and the spatial random forest models. FLO 8: late fusion of the probabilities given by the CNN, the co-occurrences and the spatial random forest models.</p><p>Late fusion based on Borda count: Borda count is a voting system allowing to merge ranked list of candidates. In our case, it simply consists in summing the rank of a test item in the different run files to be fused. Two new run files were generated using this method: FLO 9: Borda count of the predictions given by the CNN, the co-occurrences and the spatial random forest models FLO 10: Borda count of the predictions given by the CNN, the spatial random forest and the closest-location classifier</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The results we obtained within the GeoLifeCLEF challenge are presented in table 3 (along with other participant's runs). Figure <ref type="figure" coords="11,411.61,620.25,4.98,8.74" target="#fig_1">2</ref> illustrates the MRR values obtained by our runs solely. The conclusions we can draw from the results are the following:</p><p>-Supremacy of the CNN model:The results show that our run FLO 6</p><p>is the best performing model among all the evaluated systems in the challenge. It corresponds to the fusion of the environmental CNN model and the spatial random forest classifier. Nevertheless, the CNN model alone obtains a very close performance (FLO 3) so that the contribution of the random forest predictions to the fused model seems to be very limited. As another evidence of the supremacy of the CNN model, all our other runs including its predictions (FLO 8, FLO 5,FLO 9,FLO 10) are above all the other runs submitted to the challenge. However, their performance is degraded compared to the CNN model alone.</p><p>The second best model within our four base models seems to be the spatial classifier based on random forest (FLO 4). Indeed, it obtains a very fair performance considering that it only uses the spatial positions of the occurrences (which makes it very easy to implement in a real-world system).</p><p>The co-occurrence model (FLO 2) obtains significantly lower performance, while the closest-location classifier, which uses only the nearest point species data, is the worst model (FLO 1).</p><p>-Late fusion methods comparison: We can notice that the probabilities late fusion (FLO 8) worked better than Borda's (FLO 9). However, our late fusions, that give the same weights to fused models predictions, never significantly outperformed the best of the fused models, especially for fusions based on the environmental CNN. Though, we can wonder if learning an unbalanced weighting, or a local weighting would increase the performance.</p><p>-Final results vs. cross-validation results: Overall, the MRR values achieved by our models on the blind test set of GeoLifeCLEF are much lower than the ones obtained within our cross-validation experiments (see Tables <ref type="table" coords="12,183.04,473.09,4.98,8.74" target="#tab_1">1</ref> and<ref type="table" coords="12,210.72,473.09,3.87,8.74" target="#tab_2">2</ref>). We believe that this performance loss is mainly due to the construction of the blind test set, i.e. to the fact that the occurrence of a given species in the test set does never occur at a location closer than 100 meters from the occurrences of the same species in the training set. This rule was not taken into account during our cross-validation experiments on the training set.</p><p>-Species community: The co-occurrence model FLO 2 seems to generalize better than the closest-location classifier (FLO 1), though both methods used almost the same input information which is the species of the neighborhood. It is likely that the neural network detect the signature of a community from its input co-occurrences. For example, the network is able to predict a common mediterranean species when it gets a rare mediterranean species as entry. Indeed, the probability of observing this same rare species near its known observation is very small, but the closest location classifier would do the error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Conclusion and perspectives</head><p>This paper reported our participation to the GeoLifeCLEF challenge aimed at evaluating location-based species prediction models. We compared three main types of models: (i) a convolutional neural network trained on environmental variables extracted around the location of interest, (ii) a purely spatial model trained with a random forest and (iii), a co-occurrence based model aimed at predicting the likelihood of presence of a given species thanks to the knowledge of the presence of other species. The main conclusion of our study is that the convolutional neural network model is the best performing model. Indeed, it achieved the best performance of the whole GeoLifeCLEF challenge. Interestingly, the combination of the CNN model with the other models did not allow any significant improvement of the results. This is surprising in the sense that the CNN model was trained on environmental data solely whereas the other models focused on complementary information, i.e. the spatial location and the species co-occurrences. This suggests that the CNN model already captured all this information, maybe because the environmental tensor associated to each location is sufficient to recognize this particular location. In future work, we will attempt to better understand what information the CNN does capture from that environmental tensors and how it could be improved according to this.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,225.29,608.88,164.78,7.89"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Environmental CNN architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,134.77,631.51,345.82,7.89;9,134.77,317.07,338.91,299.67"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. MRR achieved by the 10 runs we submitted to the GeoLifeCLEF 2018 challenge</figDesc><graphic coords="9,134.77,317.07,338.91,299.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="11,134.77,203.38,277.25,8.77;11,134.77,215.34,230.02,8.77;11,134.77,227.29,228.60,8.77;11,134.77,239.25,274.27,8.77"><head>FLO 1 : 2 : 3 : 4 :</head><label>1234</label><figDesc>The predictions of the closest-location classifier model. FLO The predictions of the co-occurrence model. FLO The predictions of the environmental CNN. FLO The predictions of the spatial random forest classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,473.35,624.80,7.24,10.31"><head></head><label></label><figDesc>5 .</figDesc><table coords="6,138.50,164.61,407.47,426.92"><row><cell>conv_1_32.weight</cell><cell>conv_1_32.bias</cell><cell cols="2">conv_1_48.weight</cell><cell cols="2">conv_1_48.bias</cell></row><row><cell>(256, 32, 7, 7)</cell><cell>(256)</cell><cell cols="2">(256, 48, 7, 7)</cell><cell>(256)</cell><cell></cell></row><row><cell>ConvNd</cell><cell>conv_1_32_bn.weight (256)</cell><cell>conv_1_32_bn.bias (256)</cell><cell cols="2">ConvNd</cell><cell>conv_1_48_bn.weight (256)</cell><cell>conv_1_48_bn.bias (256)</cell></row><row><cell></cell><cell>BatchNorm</cell><cell></cell><cell></cell><cell></cell><cell>BatchNorm</cell></row><row><cell></cell><cell>Threshold</cell><cell>conv_2_32.weight (256, 256, 3, 3)</cell><cell>conv_2_32.bias (256)</cell><cell></cell><cell>Threshold</cell><cell>conv_2_48.weight (256, 256, 3, 3)</cell><cell>conv_2_48.bias (256)</cell></row><row><cell></cell><cell></cell><cell>ConvNd</cell><cell cols="2">conv_2_32_bn.weight (256)</cell><cell>conv_2_32_bn.bias (256)</cell><cell>ConvNd</cell><cell>conv_2_48_bn.weight (256)</cell><cell>conv_2_48_bn.bias (256)</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">BatchNorm</cell><cell></cell><cell>BatchNorm</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Threshold</cell><cell>conv_3_32.weight (256, 256, 3, 3)</cell><cell>conv_3_32.bias (256)</cell><cell>Threshold</cell><cell>conv_3_48.weight (256, 256, 3, 3)</cell><cell>conv_3_48.bias (256)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ConvNd</cell><cell>conv_3_32_bn.weight (256)</cell><cell>conv_3_32_bn.bias (256)</cell><cell>ConvNd</cell><cell>conv_3_48_bn.weight (256)</cell><cell>conv_3_48_bn.bias (256)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BatchNorm</cell><cell>BatchNorm</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Threshold</cell><cell>Threshold</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>fc_1_32.bias (256)</cell><cell>AvgPool2D</cell><cell>fc_1_32.weight (256, 12544)</cell><cell>fc_1_48.bias (256)</cell><cell>AvgPool2D</cell><cell>fc_1_48.weight (256, 12544)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Expand</cell><cell>View</cell><cell>T</cell><cell>Expand</cell><cell>View</cell><cell>T</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Addmm</cell><cell>Addmm</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>fc_2.bias (256)</cell><cell>Threshold</cell><cell>Threshold</cell><cell>fc_2.weight (256, 512)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Expand</cell><cell>Cat</cell><cell>T</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>fc_3.bias (256)</cell><cell>Addmm</cell><cell>fc_3.weight (256, 256)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Expand</cell><cell>Threshold</cell><cell>T</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Expand</cell><cell>Addmm</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Threshold</cell><cell>T</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>fc_5.bias (3336)</cell><cell>Addmm</cell><cell>fc_5.weight (3336, 256)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Expand</cell><cell>Threshold</cell><cell>T</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Addmm</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Mean1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,134.77,479.60,345.83,107.09"><head>Table 1 .</head><label>1</label><figDesc>Performance of the two spatial models in validation experiments (Monte Carlo cross-validation on twenty random train-test splits).</figDesc><table coords="8,163.84,479.60,287.67,107.09"><row><cell>model</cell><cell cols="2">validation MRR mean ± standard deviation</cell><cell>validation Top1 mean ± standard deviation</cell></row><row><cell>closest-location</cell><cell cols="2">0.0640 ± 0.0011</cell><cell>0.0314 ± 0.0010</cell></row><row><cell>random forest</cell><cell cols="2">0.0781 ± 0.0008</cell><cell>0.0304 ± 0.0008</cell></row><row><cell></cell><cell>model</cell><cell cols="2">validation MRR validation Top1</cell></row><row><cell cols="2">co-occurrences</cell><cell>0.0669</cell><cell>0.0260</cell></row><row><cell></cell><cell>CNN</cell><cell>0.1040</cell><cell>0.0480</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,134.77,589.71,345.83,18.85"><head>Table 2 .</head><label>2</label><figDesc>Performance of the two neural networks models in validation experiments (Holdout cross-validation).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="10,151.59,195.83,312.17,380.82"><head>Table 3 .</head><label>3</label><figDesc>Overview of the results of all runs submitted to GeoLifeCLEF2018.</figDesc><table coords="10,206.94,195.83,201.47,369.91"><row><cell cols="3">rank test MRR runname</cell><cell>participant name</cell></row><row><cell>1</cell><cell>0.0435</cell><cell>FLO 6</cell><cell>Floris'Tic</cell></row><row><cell>2</cell><cell>0.0430</cell><cell>FLO 3</cell><cell>Floris'Tic</cell></row><row><cell>3</cell><cell>0.0423</cell><cell>FLO 8</cell><cell>Floris'Tic</cell></row><row><cell>4</cell><cell>0.0422</cell><cell>FLO 5</cell><cell>Floris'Tic</cell></row><row><cell>5</cell><cell>0.0388</cell><cell>FLO 9</cell><cell>Floris'Tic</cell></row><row><cell>6</cell><cell>0.0365</cell><cell>FLO 10</cell><cell>Floris'Tic</cell></row><row><cell>7</cell><cell>0.0358</cell><cell>ST 16</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell>8</cell><cell>0.0352</cell><cell>ST 13</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell>9</cell><cell>0.0348</cell><cell>ST 10</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">10 0.0344</cell><cell>ST 9</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">11 0.0343</cell><cell>ST 12</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">12 0.0338</cell><cell>ST 6</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">13 0.0329</cell><cell>FLO 4</cell><cell>Floris'Tic</cell></row><row><cell cols="2">14 0.0327</cell><cell>FLO 7</cell><cell>Floris'Tic</cell></row><row><cell cols="2">15 0.0326</cell><cell>ST 17</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">16 0.0274</cell><cell>FLO 2</cell><cell>Floris'Tic</cell></row><row><cell cols="2">17 0.0271</cell><cell>ST 5</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">18 0.0220</cell><cell>ST 8</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">19 0.0199</cell><cell>FLO 1</cell><cell>Floris'Tic</cell></row><row><cell cols="2">20 0.0153</cell><cell>ST 3</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">21 0.0153</cell><cell>ST 1</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">22 0.0144</cell><cell>ST 14</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">23 0.0134</cell><cell>ST 7</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">24 0.0103</cell><cell>ST 15</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">25 0.0099</cell><cell>ST 19</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">26 0.0096</cell><cell>ST 11</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">27 0.0096</cell><cell>ST 18</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">28 0.0085</cell><cell>ST 4</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">29 0.0030</cell><cell>SSN 3</cell><cell>SSN CS 19</cell></row><row><cell cols="2">30 0.0016</cell><cell>SSN 4</cell><cell>SSN CS 19</cell></row><row><cell cols="2">31 0.0016</cell><cell>ST 2</cell><cell>TUC MI Stefan Taubert</cell></row><row><cell cols="2">32 0.0013</cell><cell>SSN 2</cell><cell>SSN CS 19</cell></row><row><cell cols="2">33 0.0004</cell><cell>SSN 1</cell><cell>SSN CS 19</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="5,144.73,645.84,83.03,7.86"><p>https://pytorch.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="5,144.73,656.80,121.49,7.86"><p>http://scikit-learn.org/stable/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="7,144.73,656.80,83.03,7.86"><p>https://pytorch.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="13,138.35,397.63,342.24,7.86;13,146.91,408.59,220.11,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,277.80,397.63,202.79,7.86;13,146.91,408.59,64.54,7.86">Overview of geolifeclef 2018: location-based species recommendation</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,233.21,408.59,105.15,7.86">CLEF working notes 2018</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,138.35,419.55,342.24,7.86;13,146.91,430.51,333.68,7.86;13,146.91,441.47,125.70,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="13,373.99,419.55,106.61,7.86;13,146.91,430.51,133.37,7.86">A deep learning approach to species distribution modelling</title>
		<author>
			<persName coords=""><forename type="first">Christophe</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">B P M</forename><surname>Munoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Multimedia Technologies for Environmental &amp; Biodiversity Informatics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,138.35,452.43,342.24,7.86;13,146.91,463.38,333.68,7.86;13,146.91,474.34,76.80,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,236.48,452.43,244.11,7.86;13,146.91,463.38,125.78,7.86">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,292.21,463.38,184.16,7.86">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,138.35,485.30,342.25,7.86;13,146.91,496.26,333.68,7.86;13,146.91,507.22,333.68,7.86;13,146.91,518.18,319.39,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,146.91,507.22,333.68,7.86;13,146.91,518.18,162.48,7.86">Overview of lifeclef 2018: a large-scale evaluation of species identification and recommendation algorithms in the era of ai</title>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christophe</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Hervé</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Planqué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Willem-Pier And</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Henning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,329.79,518.18,107.84,7.86">Proceedings of CLEF 2018</title>
		<meeting>CLEF 2018</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,138.35,529.14,342.24,7.86;13,146.91,540.10,333.68,7.86;13,146.91,551.06,126.06,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,248.12,529.14,232.47,7.86;13,146.91,540.10,23.08,7.86">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,193.10,540.10,287.49,7.86;13,146.91,551.06,41.58,7.86">Proceedings of the 27th international conference on machine learning (ICML-10)</title>
		<meeting>the 27th international conference on machine learning (ICML-10)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
