<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,136.18,115.96,342.99,12.62;1,148.99,133.89,317.39,12.62">Convolutional Long Short-Term Memory Neural Networks for Hierarchical Species Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,141.54,171.79,98.99,8.74"><forename type="first">Nithish</forename><forename type="middle">B</forename><surname>Moudhgalya</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">VIT University</orgName>
								<address>
									<settlement>Vellore</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,251.08,171.79,64.81,8.74"><forename type="first">Sharan</forename><surname>Sundar</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">VIT University</orgName>
								<address>
									<settlement>Vellore</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,335.31,171.79,64.92,8.74"><forename type="first">Siddharth</forename><surname>Divi</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">VIT University</orgName>
								<address>
									<settlement>Vellore</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,410.79,171.79,55.79,8.74"><forename type="first">P</forename><surname>Mirunalini</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">VIT University</orgName>
								<address>
									<settlement>Vellore</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,214.22,183.75,105.82,8.74"><forename type="first">Chandrabose</forename><surname>Aravindan</surname></persName>
							<email>aravindanc@ssn.edu.in</email>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">VIT University</orgName>
								<address>
									<settlement>Vellore</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,330.60,183.75,66.06,8.74"><forename type="first">S</forename><forename type="middle">M</forename><surname>Jaisakthi</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">SSN College of Engineering</orgName>
								<address>
									<settlement>Kalavakkam, Chennai</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,136.18,115.96,342.99,12.62;1,148.99,133.89,317.39,12.62">Convolutional Long Short-Term Memory Neural Networks for Hierarchical Species Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">ABD5FA5F00188C71E10E9AABFF509693</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Niche modeling</term>
					<term>Hierarchical embedding</term>
					<term>Taxonomic prediction</term>
					<term>CLNN</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Building accurate knowledge of the identity, the geographic distribution and the evolution of organisms is essential for biodiversity conservation. Automatic prediction of list of species is useful for many scenarios in biodiversity informatics. In this work, we propose a hybrid model to predict the species that are most probable to be observed at a given location, using environmental features and taxonomy of the organism. These environmental features are represented as k-dimensional image patches, where each dimension represents the value of an environmental variable, in the neighborhood of the occurrence of the species. The hybrid model Convolutional Long Short-Term Memory Neural Networks henceforth called as CLNN, is a combination of Convolutional Neural Networks(CNNs) and Long Short-Term Memory Networks(LSTMs), where the CNN forms the spatial feature generator while the LSTM focuses on finding the taxonomy. Using the dataset provided by Geo LifeCLEF 2018, the proposed method helped achieve a Mean Reciprocal Rank (MRR) score of 0.003 during the test phase.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Environmental niche models have been used by biologists and environmentalists to understand the species distribution in geographic space. These models help reduce resources expended in data collection and analysis, thus giving space for research in analyzing impacts of global phenomenon like climate change, habitat loss, species invasion and evolutionary trends that could help in translocation of species.</p><p>Considering the overwhelming uses of species prediction modeling, CLEF organizers posed the Geo LifeCLEF 2018 challenge <ref type="bibr" coords="1,348.51,644.16,9.96,8.74" target="#b4">[5]</ref>. The aim of the challenge is to develop a location-based species recommendation system using image-based representation of environmental features of the immediate surroundings. The main focus was to substitute environmental feature vectors at a given location with image-based representation of the features containing details of the neighborhood. The inclusion of features of the neighborhood better portrays the distribution of species in a region as compared to other niche modeling techniques.</p><p>Modeling image-based environmental features involves complex convolutions over multiple filters/channels. Moreover, the impact caused by each feature in determining the likelihood of a particular species can't be analyzed by visualizing the spatial rasters provided. The high number of target classes may lead to vanishing probabilities, an issue where the model's predicted probabilities are low and uniformly distributed across the target classes, thus making the learning process error-prone.</p><p>To overcome these challenges, we propose the use of Convolutional Long Short-Term Memory Neural Networks (CLNN) architecture shown in Fig. <ref type="figure" coords="2,431.48,298.32,3.87,8.74" target="#fig_2">4</ref>, to model the species distribution given their spatial environmental features along with the species taxonomy. The introduction of taxonomy addresses the vanishing probabilities by reducing the target classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>The proposed CLNN model is a hybrid pipeline of CNN and LSTM layers. Both CNN's and LSTM's are brainchildren of Deep Learning Techniques. Deep Learning (DL) is a broader type of machine learning algorithms, drawing inspirations from the biological nervous system. In DL, a cascade of multiple layers of non-linear processing is used for feature extraction and transformation. Convolutional Neural Networks(CNNs) <ref type="bibr" coords="2,280.16,476.79,10.52,8.74" target="#b1">[2]</ref> are a class of deep neural networks that are used for Computer Vision or analyzing visual imagery. CNN makes use of a set of learnable filters, which are used to detect the presence of specific features or patterns present in the original image. Different filters which detect different features are convolved and a set of activation maps are produced. These maps are then flattened i.e. reduced to a n-dimensional vector, and fed into the LSTM. Long Short-Term Memory Networks(LSTMs) <ref type="bibr" coords="2,341.29,548.52,10.52,8.74" target="#b3">[4]</ref> are a class of deep learning techniques that are constructed based on recurrent concepts in neural networks. The LSTM cells have 3 gates namely input, output and forget that helps it to arbitrarily remember some input thus giving it memory. They are usually used for modeling sequences and to predict the change in patterns with respect to some fixed variable. The LSTM layers used here, get the flattened features from CNN and find the taxonomy of the species as a sequence. The taxonomy of organisms was used to capture the intra rank similarities and also reduce the search space for species prediction. Embeddings were added to represent the labels in k-dimensional space and to maintain their taxonomic context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Use of taxonomic nomenclature</head><p>Taxonomy of organisms was introduced in Biology, to group species based on their common ancestral characteristics. According to Darwins Common Descent theory <ref type="bibr" coords="3,167.69,167.43,9.96,8.74" target="#b0">[1]</ref>, the process of speciation occurs due to the adaptation of organisms/species to environmental changes. This results in different species with a common ancestor, that share common characteristics and requirements. This fact has been exploited in our species prediction model by making use of taxonomic hierarchy. The Fig. <ref type="figure" coords="3,249.44,215.25,4.98,8.74" target="#fig_0">1</ref> shows the radial tree of taxonomic hierarchy, where the center of the diagram is the root node "NULL" and the leaf nodes represent the species ids. The diagram shows that many labels get eliminated as we traverse radially outward, thus narrowing our search space greatly in reaching the right species id. In Fig. <ref type="figure" coords="3,254.33,263.07,3.87,8.74">2</ref>, the bar plot shows that the number of class labels at the final layer during classification, dropped from 3336 to about 72 with the introduction of a hierarchy of 5 levels. The taxonomic ranks were contained in the below mentioned data columns -Kingdom, Phylum, Class, Order, Family, Genus and Species glc id. As the first 2 ranks were same for all the given instances, only the last 5 levels were used in the tree structure shown in Fig. <ref type="figure" coords="3,464.17,322.85,3.87,8.74" target="#fig_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Embedding</head><p>Embeddings were introduced in Machine learning especially in Natural Language Processing (NLP) WordtoVec algorithms, by Tomas Mikolov <ref type="bibr" coords="4,438.44,632.21,9.96,8.74" target="#b5">[6]</ref>. Many embedding algorithms have since been developed, but most of them use euclidean distance as the measure of similarity. However, since hierarchical vectors form a tree structure which resembles a hyperbolic curve as seen in Fig. <ref type="figure" coords="5,447.14,118.99,3.87,8.74" target="#fig_0">1</ref>, using hyperbolic distance as the measure of similarity embeds species vectors aptly. Póincare embeddings <ref type="bibr" coords="5,230.75,142.90,10.52,8.74" target="#b6">[7]</ref> can be used represent hierarchical vectors. The Fig. <ref type="figure" coords="5,475.61,142.90,4.98,8.74">3</ref> shows a t-SNE plot <ref type="bibr" coords="5,221.87,154.86,10.52,8.74" target="#b8">[9]</ref> of the Póincare embeddings created in experiments. The named dots are the class names and the other indistinct dull spots belong to each unique label in other lower level taxonomic ranks. The axes shown in the plot are used to visualize the n-dimensional vectors in a 3D space but are not correlated to any coordinate system. From the plot, it can be inferred that the class labels are embedded far apart and the corresponding lower ranks are clustered along, thus preserving hierarchy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">CLNN architecture</head><p>The CNN used is the state-of-art ResNext model architecture <ref type="bibr" coords="5,416.99,280.90,15.49,8.74" target="#b9">[10]</ref> that combines Inception <ref type="bibr" coords="5,207.21,292.85,11.94,8.74" target="#b7">[8]</ref>(parallelized convolutions) and Resnet <ref type="bibr" coords="5,393.48,292.85,12.35,8.74" target="#b2">[3]</ref>(sequential layers with residues) together. The first + symbol in the Fig. <ref type="figure" coords="5,381.79,304.81,4.98,8.74" target="#fig_2">4</ref> shows the global average pooling of 256 parallel convolutions, while the second + represents the concatenation of input residue to the output from that block. CNNs are used to extract meaningful spatial features from the given tiff images. These features are repeated over 5 time steps and passed on to the LSTM layer to predict the taxonomic ranks. At each time step, the LSTM predicts the taxonomic ranks namely class, order, family, genus and species as shown in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>The GeoLifeCLEF 2018 dataset, consists of 2,18,000 tiff images, with each tiff image containing 33 raster layers of environmental features. The batch size for all experimental purposes was fixed at 32. The CLNN model proposed contains 23M trainable parameters and 32,000 non-trainable parameters. The learning rate of the model was set to the default value of 0.001. The codes were written in Keras API with back-end as tensorflow. Python packages like numpy, scikit-io, tifffile, PIL and pandas were used for data preprocessing. The resource configurations include 4GB dedicated graphics by Nvidia GEFORCE 840M processor and 12GB CPU memory. Different combinations of main concepts mentioned earlier were used to make the following runs.</p><p>SSN 1 The CLNN model used the given 33 layers of spatial feature maps to predict the taxonomic ranks of species. Every layer of each tiff image was first center-cropped to a size of 32x32 and then fed to the model which ran for 5 time steps classifying the image into taxonomic ranks. However the model was not trained to classify each rank .i.e. the back-propagation algorithm ran only for species classification and not for the other ranks. Adam optimizer was used to find the minima of the sparse categorical cross-entropy loss function.</p><p>SSN 2 The concept of embeddings was introduced and an independent model was used to create the embeddings of 10 dimensions between each pair of taxonomic ranks .i.e. class labels were embedded to find order, order labels embedded to find family and so on. The embedded vectors were used as identifiers of the unique labels in the CLNN model. So the architecture was modified to predict a 5 time-stepped sequence of 10 dimensional vector, where each vector corresponds to its unique taxonomic rank labels. However, these embeddings did not capture the context of hierarchy, which was not used for creating them.</p><p>The back-propagation algorithm runs only for the last time step .i.e. the species predictions. Adam optimizer was used to find the minima of a MSE loss function.</p><p>SSN 3 The concept of Póincare embeddings was used and binarization was used to convert each ordinal feature layer into n-1 layers, where n stands for the number of categories it can assume. All images were fed into the model with the original dimensions of 64x64. The CLNN model was made to learn each level in the taxonomic hierarchy, by adding a time distributed wrapper around the layers following the LSTM. The model predicts the Póincare embedded vector of 5 dimensions, at each time step for a particular image which is then decoded to find the corresponding labels. The ranks of species were calculated based on the distance between the learned embeddings and the model predicted embeddings of the species. Since Póincare embeddings was used, the logcosh loss function was used with Adam optimizer by the model for a batch size of 32 tiff images.</p><p>SSN 4 All images were fed into the model with the original dimensions of 64x64. A time distributed wrapper was added to the layers following the LSTM segment of the CLNN to ensure the back propagation algorithm applied to every time step, thus enabling the model to learn the entire taxonomic hierarchy. Again, the concept behind binarization was applied to ordinal feature layers. The Adam optimizer was used to find minima of sparse categorical cross-entropy loss function, as the final outputs were one-hot encoded.</p><p>The metric used to measure model efficiency is Mean Reciprocal Rank(MRR) which is calculated as,</p><formula xml:id="formula_0" coords="7,257.81,391.02,98.05,31.18">M RR = 1 |Q| |Q| i=1 1 rank i</formula><p>The results are calculated for both training and testing datasets and shown in Table <ref type="table" coords="7,173.78,444.67,3.87,8.74" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Future Work</head><p>The hybrid CLNN model with the power of taxonomy resulted in low accuracies initially but showed promising surge in the later stages(0.004 to 0.0030). The use of Póincare embeddings along with learning taxonomy at each time step, showed best results so far. However, these relatively low values can be attributed to some or all the following reasons. The LSTMs need a large number of epochs to learn the sequences but due to the processing and resource bottlenecks, the LSTM was trained only for a few epochs. The mathematical complexity involved in incorporating Póincare Embeddings for the taxonomic prediction is still debatable. Thus fine tuning the hyper parameters of the CLNN model to maximize the use of taxonomy and embeddings can be incorporated in future. The use of embeddings at output levels are hard to model as they are n-dimensional float values for each label and cannot be easily predicted by model within a few epochs thus displaying huge errors at starting stages. To find the top n ranks of species, the distance between model predictions and learned embeddings were compared. As the embeddings were calculated using different functions and CLNN trained on different loss function, the distances calculated need not belong to either coordinate system thus giving curious results in some cases. Also the shuffle among patch ids and species ids predicted by model may be attributed to bottlenecks in CPU and GPU computations owing to the use of Sequence generator. CLNN can be modularized in the future, by training the CNN and LSTM separately, to avoid misleading gradient problem, wherein the errors made by LSTM need not be reflected into CNNs feature generations. The model would thus function like image-captioning with CNN features being fixed and LSTM training to understand sequences from these fixed features. Yet another family of thoughts could give rise to Branch-CNN <ref type="bibr" coords="8,329.36,358.10,15.50,8.74" target="#b10">[11]</ref> in which the coarse layers are used to predict lower level hierarchy and finer layers to predict higher level hierarchy. Each branch trains specifically for the corresponding taxonomic rank thus compartmentalizing the CNN's features generated.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,237.77,655.03,139.82,7.89;3,189.19,393.94,236.13,235.95"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Taxonomic Hierarchic Tree</figDesc><graphic coords="3,189.19,393.94,236.13,235.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,395.35,376.54,85.24,8.74;5,134.77,388.49,345.82,8.74;5,134.77,400.45,345.83,8.74;5,134.77,412.40,345.83,8.74;5,134.77,424.36,345.83,8.74;5,134.77,436.31,345.83,8.74;5,134.77,448.27,345.83,8.74;5,134.77,460.22,80.29,8.74"><head>Fig 5 .</head><label>5</label><figDesc>The 3 Dense layers containing[128,128,<ref type="bibr" coords="5,247.61,388.49,8.35,8.74" target="#b4">5]</ref> neurons respectively, follow the LSTM and are time distributed, which ensures that the logcosh loss is calculated and the errors in Póincare embedding predictions are back-propagated to both the LSTM and CNN layers with equal weights for each time step. This helps the CNN work with the LSTM, and provide features that help the LSTM improve its predictions. No pre-trained weights were used and hence the model trains entirely on the data provided.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,253.59,655.03,108.19,7.89;5,221.22,492.54,172.91,147.72"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. CLNN architecture</figDesc><graphic coords="5,221.22,492.54,172.91,147.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,134.77,115.84,345.83,164.13"><head></head><label></label><figDesc></figDesc><graphic coords="6,134.77,115.84,345.83,164.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,211.55,474.15,192.26,72.90"><head>Table 1 .</head><label>1</label><figDesc>Accuracy and MRR of each run</figDesc><table coords="7,211.55,494.94,192.26,52.10"><row><cell cols="3">Run Name Training set accuracy Test set MRR</cell></row><row><cell>SSN 1</cell><cell>0.15</cell><cell>0.0004</cell></row><row><cell>SSN 2</cell><cell>0.22</cell><cell>0.0013</cell></row><row><cell>SSN 3</cell><cell>0.38</cell><cell>0.0030</cell></row><row><cell>SSN 4</cell><cell>0.25</cell><cell>0.0016</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,448.92,235.25,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="8,201.59,448.92,88.29,7.86">The Origin Of Species</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Darwin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1859">1859</date>
			<publisher>John Murray</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,459.82,337.63,7.86;8,151.52,470.78,23.04,7.86;8,189.77,470.78,26.90,7.86;8,231.88,470.78,40.01,7.86;8,287.09,471.43,193.49,7.47;8,151.52,481.74,299.98,8.12" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,236.29,459.82,244.30,7.86;8,151.52,470.78,23.04,7.86;8,189.77,470.78,26.90,7.86;8,231.88,470.78,35.56,7.86">A Beginner&apos;s Guide To Understanding Convolutional Neural Networks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Deshpande</surname></persName>
		</author>
		<ptr target="https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,492.64,337.64,7.86;8,151.52,503.58,127.81,7.89" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="8,299.05,492.64,177.61,7.86">Deep residual learning for image recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno>CoRR abs/1512.03385</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,514.48,337.64,7.89;8,151.52,525.46,89.33,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,284.94,514.50,98.82,7.86">Long short-term memory</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,392.01,514.50,65.58,7.86">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997-11">Nov 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,536.36,337.63,7.86;8,151.52,547.32,329.07,7.86;8,151.52,558.28,329.07,7.86;8,151.52,569.24,25.60,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,223.02,547.32,257.57,7.86;8,151.52,558.28,225.26,7.86">Overview of lifeclef 2018: a large-scale evaluation of species identification and recommendation algorithms in the era of ai</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christophe</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">H</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Planqué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,395.71,558.28,84.88,7.86">Proceedings of CLEF</title>
		<meeting>CLEF</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,580.14,337.64,7.86;8,151.52,591.10,329.07,7.86;8,151.52,602.06,329.07,7.86;8,151.52,613.02,204.75,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,395.73,580.14,84.86,7.86;8,151.52,591.10,224.48,7.86">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="8,402.67,602.06,77.92,7.86;8,151.52,613.02,128.10,7.86">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,623.92,337.63,7.86;8,151.52,634.88,329.07,7.86;8,151.52,645.84,329.07,7.86;8,151.52,656.80,96.81,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,244.25,623.92,236.34,7.86;8,151.52,634.88,18.39,7.86">Poincaré embeddings for learning hierarchical representations</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,285.53,645.84,195.07,7.86;8,151.52,656.80,29.92,7.86">Advances in Neural Information Processing Systems 30</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="6338" to="6347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,119.67,337.64,7.86;9,151.52,130.63,329.07,7.86;9,151.52,141.57,94.60,7.89" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="9,320.25,130.63,127.83,7.86">Going deeper with convolutions</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno>CoRR abs/1409.4842</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,152.55,337.63,7.86" xml:id="b8">
	<analytic>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Vigas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,312.52,152.55,108.57,7.86">How to use t-sne effectively</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,163.51,337.98,7.86;9,151.52,174.47,264.13,7.86" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="9,334.97,163.51,145.62,7.86;9,151.52,174.47,97.76,7.86">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dollr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05431</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,142.62,185.43,337.97,7.86;9,151.52,196.36,184.23,7.89" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="9,231.01,185.43,249.58,7.86;9,151.52,196.39,49.79,7.86">B-CNN: branch convolutional neural network for hierarchical classification</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bain</surname></persName>
		</author>
		<idno>CoRR abs/1709.09890</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
