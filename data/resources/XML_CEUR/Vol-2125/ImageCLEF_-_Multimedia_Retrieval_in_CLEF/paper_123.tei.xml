<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,142.20,115.96,330.95,12.62;1,174.76,133.89,265.84,12.62;1,193.71,151.82,227.93,12.62">ImageCLEF 2018 Tuberculosis Task: Ensemble of 3D CNNs with Multiple Inputs for Tuberculosis Type Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,236.72,190.31,52.64,8.74"><forename type="first">Adam</forename><surname>Ishay</surname></persName>
							<email>aishay@fau.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">Florida Atlantic University</orgName>
								<address>
									<postCode>33431</postCode>
									<settlement>Boca Raton FL</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,316.52,190.31,57.65,8.74"><forename type="first">Oge</forename><surname>Marques</surname></persName>
							<email>omarques@fau.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">Florida Atlantic University</orgName>
								<address>
									<postCode>33431</postCode>
									<settlement>Boca Raton FL</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,142.20,115.96,330.95,12.62;1,174.76,133.89,265.84,12.62;1,193.71,151.82,227.93,12.62">ImageCLEF 2018 Tuberculosis Task: Ensemble of 3D CNNs with Multiple Inputs for Tuberculosis Type Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B3AF22D9386A6F252F35FE8172A03B75</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>3D-CNN</term>
					<term>Deep Learning</term>
					<term>Tuberculosis</term>
					<term>Image Classification</term>
					<term>Medical Imaging</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Convolutional neural networks have achieved state-of-theart results in general image classification tasks and have shown success in several applications within the medical imaging domain. In this paper, we apply a 3D convolutional neural network (CNN) to a dataset of tuberculosis-positive computed tomography (CT) scans to solve the task of automatically categorizing each tuberculosis (TB) case into one of five possible TB types in the context of the ImageCLEFtuberculosis 2018 challenge. The size of the volumetric scans poses unique constraints on the network and the training process. The CT volumes are segmented with the provided masks, which are further pre-processed prior to training our model. Our best run ranked 2 nd with an unweighted Cohen's Kappa of 0.1736 and an accuracy of 35.33%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>For the second year, ImageCLEF <ref type="bibr" coords="1,283.69,499.88,10.52,8.74" target="#b4">[5]</ref> has proposed the ImageCLEFtuberculosis 2018 task <ref type="bibr" coords="1,180.34,511.83,9.96,8.74" target="#b2">[3]</ref>, in efforts to reduce the time required and cost of medical image analysis. This year there are three subtasks: multi-drug resistance (MDR) detection, tuberculosis type classification, and severity scoring. The goal of the MDR task is to predict probabilities of a patient having a drug-resistant form of tuberculosis. The third task, severity scoring, aims at predicting a severity score from 1 (very bad) to 5 (very good). Finally, the task that this paper addresses is the tuberculosis type classification. We are tasked with classifying the type of tuberculosis, given a positive image. These types are: (1) Infiltrative, (2) Focal, (3) Tuberculoma, (4) Miliary, and (5) Fibro-cavernous.</p><p>Deep learning approaches have been shown to be successful on a large variety of computer vision and image analysis tasks <ref type="bibr" coords="1,337.76,632.21,9.96,8.74" target="#b6">[7]</ref>. Deep learning and CNNs in particular have now broadly been applied to medical imaging <ref type="bibr" coords="1,412.21,644.16,9.96,8.74" target="#b7">[8]</ref>. We apply a deep 3D CNN to the medical image dataset for classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Pre-processing</head><p>The training set provided by the ImageCLEF organizers consisted of patient chest CT scans of five different types of TB along with their labels. Often patients had multiple scans and all scans of the same patient were of the same type. There were 228, 210, 100, 79, and 60 patients belonging to Infiltrative, Focal, Tuberculoma, Miliary, and Fibro-cavernous types, respectively. The dataset totaled 677 patients with 1008 scans (Table <ref type="table" coords="2,331.91,203.56,3.87,8.74" target="#tab_0">1</ref>). Each scan consists of approximately 100 512×512 slices. The depth of each scan varies and was changed to a constant number of slices. The pre-processing stage consisted of 7 steps (Figure <ref type="figure" coords="2,374.76,380.97,3.87,8.74" target="#fig_0">1</ref>). The supplied masks <ref type="bibr" coords="2,474.83,380.97,10.52,8.74" target="#b3">[4]</ref> were applied to the original scans to segment the lungs. The distance between slices along with the resolution of each slice varied among scans. For easier training, the images were resampled to an isotropic resolution of 1×1×1 mm. After this step, the scans were roughly 300×300×300 in size. All scans were then cut to remove the excess zeros in the background from the mask. The voxel values were clipped between -1000 and 400, and normalized between 0 and 1. The values outside of this range are not useful. Then, the largest lungs were used to find the new width and height to which all images would be padded, with the common background voxel value in the scans. The scans were also padded in the depth dimension to the depth of the largest scan. Next, the mean pixel was calculated and subtracted from all scans to zero-center the data for better training. Finally, the resulting scans were resized to reduce the data to a more reasonable size for the network. Using this process, two datasets of different sized images were created (see Figure <ref type="figure" coords="2,208.69,548.35,3.87,8.74" target="#fig_1">2</ref>). The purpose of this was to combine two different networks to predict the label. The batch sizes used are a function of the size of the input and the architecture of the network. In the networks used, most of the memory consumption was due to the first few layers of the network, since in these layers the images were still large.</p><p>The two datasets each had a respective train/validation split of 80/20. Initially this split was done by scan and validation accuracy was relatively high. However, when submitting results on the test set the accuracy was much lower and close to random. This was thought to be at least partially due to the method for splitting. Because some patients had multiple scans, there were scans in the train and validation set from the same patient. Upon visual inspection, scans from the same patient were indeed similar (see Figure <ref type="figure" coords="3,373.18,208.66,3.87,8.74" target="#fig_2">3</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>The trained models were 3D convolutional neural networks using the software library Keras <ref type="bibr" coords="3,197.97,500.43,10.52,8.74" target="#b1">[2]</ref> with Tensorflow <ref type="bibr" coords="3,288.11,500.43,10.52,8.74" target="#b0">[1]</ref> backend. We opted for 3D convolutions because they naturally capture the 3D nature of the scans. We trained two networks, one for each dataset created in the pre-processing stage. The combination of the two networks achieved better results than either of them alone. To alleviate the class imbalance problem shown in Table <ref type="table" coords="3,341.71,548.25,3.87,8.74" target="#tab_0">1</ref>, oversampling was used during the training phase. Classes three, four, and five were oversampled to approximately match the test distribution. This meant that a full epoch of training was reached when roughly 900 patients (677 + ∼200) were processed by the network.</p><p>Each network (Figure <ref type="figure" coords="3,246.44,596.34,4.43,8.74" target="#fig_3">4</ref>) had five convolution layers with rectified linear unit (ReLU) activations, each with a following batch normalization and max pooling with dropout layer. These led to two fully connected layers, each with batch normalization and dropout. Finally, these activations went through a softmax layer, which output a tensor of size five, for each category. Categorical crossentropy was used as the loss function, and Adam <ref type="bibr" coords="3,352.04,656.12,10.52,8.74" target="#b5">[6]</ref> was used for optimization.  One of the restrictive parts of training this model was the batch size. Such small batches make it harder to converge.</p><p>Our most successful model was the combination of the two best models, which had inputs of different size image volumes. The outcome of this ensemble were 5 probabilities, one for each class. The probabilities were summed across the two models, and then this vector was iteratively scaled by a weight vector which was calculated from the class distribution. This resulted in output labels which more closely matched the data distribution. This combination of networks shown in Figure <ref type="figure" coords="4,208.04,578.42,4.98,8.74" target="#fig_3">4</ref> was used for predicting the test labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Only runs for the tuberculosis type subtask 2 were submitted. Our initial submissions accuracies were barely better than random chance (≈28%). After combining models and weighting probabilities, the accuracy and kappa score did im-  prove. Our best run (indicated in bold in Table <ref type="table" coords="5,344.38,399.92,4.43,8.74" target="#tab_1">2</ref>) ranked second in unweighted kappa coefficient, but tenth in accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper applies a 3D CNN to pre-processed CT scans of the lungs. The question of whether a CNN can extract the information necessary for labeling types of TB remains open. Making predictions on image data alone has proved a challenging problem. The large size of the images and small size and class imbalance of the datasets are characteristic of medical imaging tasks. In this analysis, batch sizes were restricted to sizes of five and fourteen samples for the two networks used. A feasible way of effectively training with a much larger batch size is to accumulate the gradients of each batch and only update the weights of the network after storing a sufficient number of batches gradients. The average of the gradients for each batch can be used to update the weights. This allows for effectively training on larger batch sizes, circumventing memory problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,162.61,162.43,287.06,7.89"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The 7 steps that made up the pipeline for processing the scans.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,134.77,396.96,345.83,7.89;3,134.77,407.95,330.03,7.86;3,134.77,241.29,345.73,140.91"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The same scan processed into two different sizes which were used in the ensemble. The bigger scan is size (176×133×195) and the smaller one is (128×97×142).</figDesc><graphic coords="3,134.77,241.29,345.73,140.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,134.77,275.31,345.83,7.89;4,134.77,286.30,345.82,7.86;4,134.77,297.25,118.29,7.86;4,134.77,316.56,345.74,118.72"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Slices of scans of the same patient taken 7 years apart. It is easy to see the similarities visually, and this was reason to split the dataset by patient instead of scan to avoid potential overfitting.</figDesc><graphic coords="4,134.77,316.56,345.74,118.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,202.90,450.05,206.48,7.89"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Diagram of the 3D CNNs used for training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,159.13,250.44,297.09,7.89;5,134.77,115.82,345.74,119.85"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Diagram of the pipeline for predicting the labels of the test scans.</figDesc><graphic coords="5,134.77,115.82,345.74,119.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,136.16,257.38,276.21,93.47"><head>Table 1 .</head><label>1</label><figDesc>Train and test distribution of the dataset.</figDesc><table coords="2,136.16,276.43,261.30,74.41"><row><cell>Class</cell><cell cols="2">Train Patients (Scans) Test Patients (Scans)</cell></row><row><cell>Infiltrative (1)</cell><cell>228 (376)</cell><cell>89 (176)</cell></row><row><cell>Focal (2)</cell><cell>210 (273)</cell><cell>80 (115)</cell></row><row><cell>Tuberculoma (3)</cell><cell>100(154)</cell><cell>60 (86)</cell></row><row><cell>Miliary (4)</cell><cell>79(106)</cell><cell>50 (71)</cell></row><row><cell>Fibro-cavernous (5)</cell><cell>60 (99)</cell><cell>38 (57)</cell></row><row><cell>Total</cell><cell>677 (1008)</cell><cell>317 (505)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,134.77,269.95,352.47,104.03"><head>Table 2 .</head><label>2</label><figDesc>Top six rankings from the ImageCLEFtuberculosis [3] 2018 tuberculosis type task.</figDesc><table coords="5,136.16,299.96,351.07,74.02"><row><cell>Model (Group Name)</cell><cell cols="3">Kappa Score Accuracy ranking</cell></row><row><cell>run TBdescs2 zparts3 thrprob50 rf150 (UIIP BioMed)</cell><cell>0.2312</cell><cell>0.4227</cell><cell>1</cell></row><row><cell>m4 weighted (fau ml4cv)</cell><cell>0.1736</cell><cell>0.3533</cell><cell>2</cell></row><row><cell>AllFeats std euclidean TST (MedGIFT)</cell><cell>0.1706</cell><cell>0.3849</cell><cell>3</cell></row><row><cell>Riesz AllCols euclidean TST (MedGIFT)</cell><cell>0.1674</cell><cell>0.3849</cell><cell>4</cell></row><row><cell>Run-02-Mohan-RF-F20I1500S20-317 (VISTA@UEvora)</cell><cell>0.1664</cell><cell>0.3785</cell><cell>5</cell></row><row><cell>m3 weighted (fau ml4cv)</cell><cell>0.1655</cell><cell>0.3438</cell><cell>6</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,138.35,634.88,342.25,7.86;5,146.91,645.84,333.68,7.86;5,146.91,656.80,333.68,7.86;6,146.91,119.67,333.68,7.86;6,146.91,130.63,333.68,7.86;6,146.91,141.59,333.68,7.86;6,146.91,152.55,333.68,7.86;6,146.91,163.51,273.47,7.86" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mané</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/,softwareavailablefromtensorflow.org" />
		<title level="m" coord="6,163.58,152.55,284.22,7.86">TensorFlow: Large-scale machine learning on heterogeneous systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,174.47,203.95,7.86" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://keras.io" />
		<title level="m" coord="6,222.05,174.47,21.39,7.86">Keras</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,185.43,342.25,7.86;6,146.91,196.39,333.68,7.86;6,146.91,207.34,333.68,7.86;6,146.91,218.30,333.68,7.86;6,146.91,229.26,22.02,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,377.45,185.43,103.14,7.86;6,146.91,196.39,333.68,7.86;6,146.91,207.34,109.57,7.86">Overview of ImageCLEFtuberculosis 2018 -detecting multi-drug resistance, classifying tuberculosis type, and assessing severity score</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<ptr target="org&lt;http://ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="m" coord="6,277.64,207.34,104.73,7.86">CLEF2018 Working Notes</title>
		<title level="s" coord="6,389.78,207.34,90.81,7.86;6,146.91,218.30,81.94,7.86">CEUR Workshop Proceedings, CEUR-WS.</title>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">September 10-14 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,240.22,342.24,7.86;6,146.91,251.18,333.68,7.86;6,146.91,262.14,333.68,7.86;6,146.91,273.10,333.68,7.86;6,146.91,284.06,168.95,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,429.73,240.22,50.86,7.86;6,146.91,251.18,219.32,7.86">Efficient and fully automatic segmentation of the lungs in ct volumes</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">A</forename><surname>Jiménez Del Toro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Depeursinge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,382.87,262.14,97.72,7.86;6,146.91,273.10,230.71,7.86">Proceedings of the VIS-CERAL Anatomy Grand Challenge at the 2015 IEEE ISBI</title>
		<title level="s" coord="6,426.89,273.10,53.70,7.86;6,146.91,284.06,67.97,7.86">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">O</forename><surname>Goksel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Jiménez Del Toro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Foncubierta-Rodríguez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<meeting>the VIS-CERAL Anatomy Grand Challenge at the 2015 IEEE ISBI</meeting>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2015-05">May 2015</date>
			<biblScope unit="page" from="31" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,295.02,342.24,7.86;6,146.91,305.98,333.67,7.86;6,146.91,316.93,333.68,7.86;6,146.91,327.89,333.68,7.86;6,146.91,338.85,333.68,7.86;6,146.91,349.81,333.68,7.86;6,146.91,360.77,333.68,7.86;6,146.91,371.73,22.02,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,194.26,327.89,268.45,7.86">Overview of ImageCLEF 2018: Challenges, datasets and evaluation</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Andrearczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">D</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Farri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lungren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,146.91,338.85,333.68,7.86;6,146.91,349.81,280.03,7.86">Proceedings of the Ninth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="6,456.15,349.81,24.45,7.86;6,146.91,360.77,144.00,7.86">LNCS Lecture Notes in Computer Science</title>
		<meeting>the Ninth International Conference of the CLEF Association (CLEF<address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018-09-10">2018. September 10-14 2018</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="6,138.35,382.69,342.24,7.86;6,146.91,393.65,93.19,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="6,236.79,382.69,178.71,7.86">Adam: A method for stochastic optimization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,138.35,404.58,338.05,7.89" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,291.35,404.61,54.39,7.86">Deep learning</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,352.69,404.61,27.93,7.86">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page">436</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,415.56,342.25,7.86;6,146.91,426.52,333.68,7.86;6,146.91,437.46,261.44,7.89" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,363.34,426.52,117.25,7.86;6,146.91,437.48,90.77,7.86">A survey on deep learning in medical image analysis</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kooi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">E</forename><surname>Bejnordi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A A</forename><surname>Setio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ciompi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ghafoorian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Van Der Laak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">I</forename><surname>Sánchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,244.56,437.48,92.77,7.86">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="60" to="88" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
