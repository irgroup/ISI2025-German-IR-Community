<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,130.70,152.67,333.82,12.64">3D-CNN and SVM for Multi-Drug Resistance Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,132.26,191.70,60.15,8.96"><forename type="first">Imane</forename><surname>Allaouzi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Sciences and Techniques</orgName>
								<orgName type="institution">Essaâdi University</orgName>
								<address>
									<settlement>Tangier</settlement>
									<country key="MA">Morocco</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,199.04,191.70,61.13,8.96"><forename type="first">Badr</forename><surname>Benamrou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Sciences and Techniques</orgName>
								<orgName type="institution">Essaâdi University</orgName>
								<address>
									<settlement>Tangier</settlement>
									<country key="MA">Morocco</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,267.59,191.70,84.59,8.96"><forename type="first">Mohamed</forename><surname>Benamrou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Sciences and Techniques</orgName>
								<orgName type="institution">Essaâdi University</orgName>
								<address>
									<settlement>Tangier</settlement>
									<country key="MA">Morocco</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,371.65,191.70,59.04,8.96"><forename type="first">Mohamed</forename><surname>Ben</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Sciences and Techniques</orgName>
								<orgName type="institution">Essaâdi University</orgName>
								<address>
									<settlement>Tangier</settlement>
									<country key="MA">Morocco</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,433.28,191.70,29.31,8.96;1,240.65,213.47,43.95,8.10"><forename type="first">Ahmed</forename><surname>Abdelmalek</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Sciences and Techniques</orgName>
								<orgName type="institution">Essaâdi University</orgName>
								<address>
									<settlement>Tangier</settlement>
									<country key="MA">Morocco</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,130.70,152.67,333.82,12.64">3D-CNN and SVM for Multi-Drug Resistance Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F41438A27FC519193FADF4ED393E4BBB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>3D-CNN</term>
					<term>Deep Neural Networks</term>
					<term>SVM classifier</term>
					<term>3D CT medical imaging</term>
					<term>binary classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently, deep Convolutional neural networks (CNN) have obtained significant results in volumetric medical image classification task. However, a number of studies have claimed that replacing the trainable classifier (the conventional softmax function) of a CNN model with an SVM classifier can improve the classification performance. In this paper, we investigate the use of a hybrid approach which combines 3D CNN and a linear SVM to tackle the task of Multi-Drug Resistant detection.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Tuberculosis (TB) is a serious infectious disease usually caused by the Mycobacterium tuberculosis (MTB) <ref type="bibr" coords="1,228.95,443.75,10.06,8.96" target="#b0">[1]</ref>.It is one of the top 10 causes of morbidity and mortality worldwide, killing 1.7 million people in 2016. The greatest problem that can happen to a patient with tuberculosis (TB) is that the organisms become resistant to two or more of the standard drugs, which is a formidable obstacle to effective TB care and prevention globally. The motivation of ImageCLEFtuberculosis 2018 task <ref type="bibr" coords="1,355.01,503.75,11.54,8.96" target="#b1">[2,</ref><ref type="bibr" coords="1,366.55,503.75,7.69,8.96" target="#b2">3]</ref> is to explore the use of tuberculosis CT (Computed Tomography) scans in order to help in early detection of the drug resistance (DR) status which in turn has a great importance for effective treatment. In this paper, we describe our contribution to the task of Multi-Drug Resistant (MDR) detection, which aims to assess the probability of a TB patient having resistant form of tuberculosis.</p><p>Recently, deep Convolutional neural networks (CNNs) have obtained significant results in volumetric medical image classification task <ref type="bibr" coords="1,347.14,587.75,10.94,8.96" target="#b3">[4,</ref><ref type="bibr" coords="1,358.08,587.75,7.30,8.96" target="#b4">5,</ref><ref type="bibr" coords="1,365.38,587.75,7.30,8.96" target="#b5">6]</ref>. However, a number of studies have claimed that replacing the trainable classifier (the conventional softmax function) of a CNN model with the Support Vector Machine (SVM) classifier can improve the classification performance <ref type="bibr" coords="1,285.27,623.78,10.66,8.96" target="#b6">[7]</ref>. In this regard, we investigate the use of a hybrid approach that combines 3D CNN and a linear SVM classifier to tackle the task of MDR detection.</p><p>The remainder of this paper is organized as follows: the dataset is described in Section 2, the proposed methodology is described in Section 3, results are presented and discussed in Section 4, and finally Section 5 draws some conclusions and future work. This section elaborates on the details our proposed approach to address the MDR detection task from ImageCLEFtuberculosis 2018. As shown in the fig. <ref type="figure" coords="2,415.87,388.89,3.49,8.96" target="#fig_0">1</ref>, our system is designed to (1) automatically extract prominent features from 3D CT scans using a 3D CNN, and then (2) classify them into predefined categories with the Linear SVM classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig.1.</head><p>The architecture of our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head> Data pre-processing:</head><p>The input 3D CT scans are stored in Niftii file format, where the number of slices is around 50-400, and the image size per slice of 512x512 pixels. However, slices variations can be problematic for automatic analysis using CNN. For that we have standardized the size of input images to 100x100x50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head> 3D CNN as features Extractor:</head><p>Generally, CNN architecture consist of three main types of layers (convolutional layers, pooling layers and fully connected layers) that are stacked on top of each other to form a full CNN model.</p><p>1) Convolutional layer: the convolutional layer is always the first layer of CNN, it serves as features extractor, and it consists of several features maps. Each neuron in a feature map is connected to a small region, called the local receptive field, through a set of shared weights and a single shared bias. Two main advantages of using Convolutional layer instead of fully connected layer. The first one is parameters sharing; where sharing weights and bias are equal for all neurons in a feature map, which greatly reduces the number of parameters that in turn will result in faster training, and, ultimately, will help to build deep networks <ref type="bibr" coords="3,201.06,321.81,12.83,8.96" target="#b7">[8]</ref>.The second advantage is sparsity of connections since in each layer, each output value depends only on a small number of inputs.</p><p>2) Pooling layer: The pooling layer is usually applied after convolutional layer with the aim of reducing the spatial resolution of the feature maps, speeding the computation and extracting prominent features. The most used technique for pooling is Max-pooling, where each pooling unit is equal to the largest element in a receptive field.</p><p>3) Fully connected (FC) layer: The fully connected layer input must be a vector, so we must first flatten the output features from the convolutional and pooling layers. Then, we may pass them to the output layer, where we usually use a softmax classifier or sigmoid to predict the input class label. CNNs are mainly developed for 2D images, however in the medical domain most images are 3D tensors. The traditional way to solve this problem is to convert 3D image into 2D representation, but this method leads to a loss of information, which in turn limits the performance of the overall system <ref type="bibr" coords="3,324.51,648.02,10.71,8.96" target="#b3">[4]</ref>. For that, we propose a 3D CNN model with the following architecture. At the first fully connected layer and in each convolutional layer, we have chosen to use a Rectified Linear Unit (ReLU) <ref type="bibr" coords="4,279.44,389.85,14.33,8.96" target="#b8">[9]</ref> as an activation function since some recent work on image recognition, has found considerable benefit in using rectified linear units through much of the network. In addition, we have adopted dropout technique with a rate of 0.5 to the first fully connected layer; this prevents hidden units from complex co-adaptations that might ultimately lead to overfitting.</p><p>Our 3D CNN was trained on the training set, with "Categorical Cross-entropy" as loss function and Adam <ref type="bibr" coords="4,224.32,458.87,16.89,8.96" target="#b9">[10]</ref> as optimizer. We have used a mini-batch size of 5 samples, and a number of epochs up to 10, where the best model was selected based on the validation loss.</p><p>However, this trained model is used only as features extractor. Therefore, we have replaced the fully connected layers (FC1 and FC2) with the SVM classifier, which takes the flattened output from the rest layers as a new feature vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head> Support Vector Machine (SVM) classifier:</head><p>The SVM <ref type="bibr" coords="4,168.35,561.59,16.78,8.96" target="#b10">[11]</ref> is one of the most powerful and adopted algorithm for the classification task. Its main idea is to find the optimal hyper-plane that maximizes the margin between two classes in a given dataset.</p><p>To predict the probability of a TB patient having resistant form of tuberculosis, we have used the SVM classifier with a linear kernel. This classifier takes as input the extracted features from the pre-trained 3D CNN (with a size of 127050), and trained on the whole training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>:</head><p>In this section, we present the performance results of our model on the test set:</p><p> Multi-Drug Resistant (MDR) Detection:</p><p>MDR detection task consists on assigning the probability of each patient having MDR. For that, two metrics was used to evaluate model performance: Accuracy and Area Under the Curve (AUC) obtained from the ROC-curves produced with the submitted probabilities. The following table provides the results obtained by our model and the best run for the task of MDR detection. Our model gives good results on MDR detection task with an AUC of 0.5029 and an accuracy of 0.4576. However, the best model has achieved an accuracy of 0.6144 and AUC of 0.6178. For that we aim to improve the performance of our model by using the provided masks <ref type="bibr" coords="5,203.51,402.09,18.47,8.96" target="#b11">[12]</ref> to reduce the size of 3D volumes before resampling them.</p><p>With this we can focus on the lung tissue and we can reduce the noise from the rest of the body.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion:</head><p>In this paper, we investigate the use of a combination of 3D-CNN and SVM classifier to tackle the problem of MDR detection. Where, the 3D-CNN is used to extract relevant features from patients CT scans, while the SVM is used for the classification step. However, the test results of our submitted run are not satisfactory comparatively with the results obtained by the best model. Therefore, we aim to improve the performance of our model by adding more training data using the provided masks to reduce the size of 3D volumes before resampling them. With this we can focus on the lung tissue and we can reduce the noise from the rest of the body.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,230.57,592.96,145.32,8.10;3,157.45,469.90,291.60,111.00"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. An example of CNN architecture.</figDesc><graphic coords="3,157.45,469.90,291.60,111.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="2,136.10,444.25,346.05,149.15"><head></head><label></label><figDesc></figDesc><graphic coords="2,136.10,444.25,346.05,149.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,124.70,151.54,346.12,94.60"><head>2 Dataset: • MDR detection dataset:</head><label></label><figDesc></figDesc><table coords="2,124.70,201.18,346.12,44.96"><row><cell>MDR detection is a Binary classification task, where the goal is to predict the proba-</cell></row><row><cell>bility for each of the two classes: Drug Sensitive (DS) and Multi-Drug Resistant</cell></row><row><cell>(MDR). As shown in the table below a dataset of 3D CT images is used with 259 of</cell></row><row><cell>training examples, and 236 of test cases.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,124.70,270.38,279.07,92.87"><head>Table 1 .</head><label>1</label><figDesc>The distribution of MDR detection dataset.</figDesc><table coords="2,124.70,293.54,279.07,69.71"><row><cell></cell><cell>Dataset</cell><cell>Train</cell><cell>Test</cell></row><row><cell></cell><cell>DS</cell><cell>134</cell><cell>99</cell></row><row><cell></cell><cell>MDR</cell><cell>125</cell><cell>137</cell></row><row><cell>3</cell><cell>Methodology :</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,124.70,149.39,346.00,226.50"><head>Table 2 .</head><label>2</label><figDesc>Our 3D CNN architecture.As shown in the table above, our 3D CNN has about 130 million parameters. It consists of two convolutional layers with the same padding and 64 filters with a kernel size of 5x5x5; each Convolutional layer is followed by a max-pooling layer with overlapping 3 × 3 × 3 windows, and two fully connected layers with 1024, and 2 neurons respectively.</figDesc><table coords="4,124.70,172.55,344.81,123.09"><row><cell>Name</cell><cell>Type</cell><cell>Kernel</cell><cell>Activation</cell><cell>Output dims</cell></row><row><cell></cell><cell></cell><cell>dims</cell><cell></cell><cell></cell></row><row><cell>Data</cell><cell>Input</cell><cell>-</cell><cell>-</cell><cell>100x100x50</cell></row><row><cell>Conv3D_1</cell><cell>Convolution</cell><cell>5x5x5</cell><cell>ReLu</cell><cell>100x100x50x64</cell></row><row><cell>Max pool3D_1</cell><cell>Max pooling</cell><cell>3x3x3</cell><cell>-</cell><cell>33x33x50x21</cell></row><row><cell>Conv3D_2</cell><cell>Convolution</cell><cell>5x5x5</cell><cell>ReLu</cell><cell>33x33x50x64</cell></row><row><cell>Max Pool3D_1</cell><cell>Max pooling</cell><cell>3x3x3</cell><cell>-</cell><cell>11x11x50x21</cell></row><row><cell>FC1</cell><cell>Fully connected</cell><cell>-</cell><cell>ReLu</cell><cell>1024</cell></row><row><cell>FC2</cell><cell>Fully connected</cell><cell>-</cell><cell>Softmax</cell><cell>2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,147.50,289.10,311.38,63.54"><head>Table 3 .</head><label>3</label><figDesc>Test results obtained by our model, and best submissions for MDR detection.</figDesc><table coords="5,165.74,312.26,285.18,40.38"><row><cell>Metrics</cell><cell>LIST model</cell><cell>MDR Detection VISTA@UEvora model</cell></row><row><cell>Accuracy</cell><cell>0.4576</cell><cell>0.6144</cell></row><row><cell>AUC</cell><cell>0.5029</cell><cell>0.6178</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,132.67,619.03,337.93,8.10;5,141.74,630.07,154.30,8.10" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="5,141.74,619.03,112.03,8.10">Tuberculosis Fact sheet N°104</title>
		<imprint>
			<date type="published" when="2015-10-11">October 2015. 11 February 2016</date>
		</imprint>
		<respStmt>
			<orgName>WHO</orgName>
		</respStmt>
	</monogr>
	<note>Archived from the original on 23 August 2012</note>
</biblStruct>

<biblStruct coords="5,132.67,641.11,187.38,8.10;5,336.91,641.11,63.23,8.10;5,416.95,641.11,53.74,8.10;5,141.74,652.03,328.87,8.10;5,141.74,663.07,254.00,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,421.15,641.11,49.54,8.10;5,141.74,652.03,328.87,8.10;5,141.74,663.07,119.41,8.10">Overview of ImageCLEFtuberculosis 2018 -Detecting multi-drug resistance, classifying tuberculosis type, and assessing severity score</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,266.99,663.07,74.13,8.10">CLEF working notes</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,132.67,674.11,337.92,8.10;5,141.74,685.03,328.82,8.10;6,141.74,149.99,328.94,8.10;6,141.74,161.03,329.12,8.10;6,141.74,172.07,313.97,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,197.57,161.03,250.88,8.10">Overview of ImageCLEF 2018: Challenges, Datasets and Evaluation</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Andrearczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Farri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lungren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gurrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,454.85,161.03,16.00,8.10;6,141.74,172.07,261.17,8.10">Proceedings of the Ninth International Conference of the CLEF Association</title>
		<meeting>the Ninth International Conference of the CLEF Association<address><addrLine>CLEF</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.67,182.99,338.19,8.10;6,141.74,194.03,328.79,8.10;6,141.74,205.07,161.60,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,262.69,182.99,208.17,8.10;6,141.74,194.03,45.03,8.10">Lung nodule detection in CT using 3D convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vaidya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,215.54,194.03,254.99,8.10;6,141.74,205.07,19.45,8.10">IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)</title>
		<meeting><address><addrLine>VIC, Melbourne</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="379" to="383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.67,215.99,337.95,8.10;6,141.74,227.03,278.06,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,352.55,215.99,118.07,8.10;6,141.74,227.03,139.09,8.10">3D-CNN in Drug Resistance Detection and Tuberculosis Classification</title>
		<author>
			<persName coords=""><forename type="first">Figueira</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Miguel Silva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pinho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,291.17,227.03,74.13,8.10">CLEF working notes</title>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.67,238.07,338.07,8.10;6,141.74,248.90,328.90,8.19;6,141.74,260.03,172.36,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,281.77,238.07,188.97,8.10;6,141.74,248.90,96.78,8.19">Lung nodule detection in ct images using deep convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Golan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Denzinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,259.86,248.90,210.79,8.18;6,141.74,260.03,29.49,8.10">2016 International Joint Conference on Neural Networks (IJCNN)</title>
		<meeting><address><addrLine>Vancouver, BC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="243" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.67,271.10,337.80,8.10;6,141.74,282.02,87.52,8.10" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="6,222.62,271.10,188.67,8.10">Deep learning using linear support vector machines</title>
		<author>
			<persName coords=""><forename type="first">Yichuan</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1306.0239</idno>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,132.67,293.06,337.80,8.10;6,141.74,304.10,45.32,8.10" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="6,227.44,293.06,139.21,8.10">Neural Networks and Deep Learning</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Nielsen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Determination Press</publisher>
		</imprint>
	</monogr>
	<note>Chapter 6</note>
</biblStruct>

<biblStruct coords="6,132.67,315.02,337.77,8.10;6,141.74,325.97,60.79,8.18" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,234.82,315.02,221.33,8.10">Rectified linear units improve restricted Boltzmann machines</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,141.74,325.97,34.48,8.18">ICML&apos;10</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.40,337.10,337.89,8.10;6,141.74,348.02,24.09,8.10" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="6,221.70,337.10,164.72,8.10">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno>CoRR abs/1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.40,359.06,338.30,8.10;6,141.74,370.10,26.37,8.10" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,227.80,359.06,89.33,8.10">Support-vector Networks</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,323.67,359.06,64.81,8.10">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.40,381.02,338.34,8.10;6,141.74,392.06,328.60,8.10;6,141.74,403.10,328.88,8.10;6,141.74,414.02,105.87,8.10" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,155.89,392.06,254.30,8.10">Efficient and fully automatic segmentation of the lungs in CT volumes</title>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oscar</forename><forename type="middle">A</forename><surname>Jiménez-Del-Toro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrien</forename><surname>Depeursinge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,185.50,403.10,285.12,8.10;6,141.74,414.02,63.21,8.10">Proceedings of the VISCERAL Challenge at ISBI. No. 1390 in CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">O</forename><surname>Goksel</surname></persName>
		</editor>
		<meeting>the VISCERAL Challenge at ISBI. No. 1390 in CEUR Workshop Proceedings</meeting>
		<imprint>
			<date type="published" when="2015-04">Apr 2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
