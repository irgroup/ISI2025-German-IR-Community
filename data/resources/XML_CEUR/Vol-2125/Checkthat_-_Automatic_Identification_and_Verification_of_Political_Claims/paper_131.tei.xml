<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,172.64,115.96,270.07,12.62;1,139.30,133.89,336.76,12.62;1,274.35,151.82,66.66,12.62">UPV-INAOE-Autoritas -Check That: Preliminary Approach for Checking Worthiness of Claims</title>
				<funder ref="#_n3HNPeT">
					<orgName type="full">Qatar National Research Fund</orgName>
				</funder>
				<funder>
					<orgName type="full">Qatar Foundation</orgName>
				</funder>
				<funder ref="#_r2ZKrnZ">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,214.21,189.73,60.26,8.74"><forename type="first">Bilal</forename><surname>Ghanem</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">PRHLT Research Center</orgName>
								<orgName type="institution">Universitat Politècnica de València</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,285.02,189.73,108.88,8.74"><forename type="first">Manuel</forename><surname>Montes-Y-Gómez</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Óptica y Electrónica (INAOE)</orgName>
								<orgName type="institution">Instituto Nacional de Astrofìsica</orgName>
								<address>
									<settlement>Puebla</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,223.73,201.68,73.97,8.74"><forename type="first">Francisco</forename><surname>Rangel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">PRHLT Research Center</orgName>
								<orgName type="institution">Universitat Politècnica de València</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Autoritas Consulting</orgName>
								<address>
									<settlement>Valencia</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,334.47,201.68,52.69,8.74"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
							<email>prosso@dsic</email>
							<affiliation key="aff0">
								<orgName type="department">PRHLT Research Center</orgName>
								<orgName type="institution">Universitat Politècnica de València</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,172.64,115.96,270.07,12.62;1,139.30,133.89,336.76,12.62;1,274.35,151.82,66.66,12.62">UPV-INAOE-Autoritas -Check That: Preliminary Approach for Checking Worthiness of Claims</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FBE599C833B8249229F66E60882CE05A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Factual Claims</term>
					<term>English</term>
					<term>Arabic</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Journalists usually work for a long time to investigate presidential debates. Their main role is to extract the sentences in the debates that include information about facts or previous events. These sentences are called claims. The investigation process of these claims is important where it can reveal how credible is the speaker or the other candidates. Therefore, proposing systems for extracting these claims can certainly improve the press work. In this paper, we will present our approach for CLEF-2018 Check That lab for Task 1. We propose an approach that uses a text distortion technique to detect claims that are worthy for checking. Our approach has achieved an acceptable results taking into account the complexity of this task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the recent years, the political situation in many countries started to be more complex, which made the politicians started to exchange accusations in the public political debates, especially in the presidential debates. The prevailing situation in any debate is that each presidential candidate has a short period to respond to the claims of the other candidates. Each of them has the right to accuse the other with different claims, where the main objective is to convince the audience about his ability for that political position. During these long debates, the journalists' role is to investigate and validate the mutual accusations between those candidates to reveal the truth behind each claim. This task is complex to be done manually and in a short time, since the debates are very long, and each candidate declares many claims. Many of these claims are just opinions while the others contain previous facts that happened before. Starting from this issue, recent research topics are moving towards detecting check worthy claims in the presidential debates, where automatic approaches will save a lot of time to journalists for this process. In this paper, we present our approach for detecting claims that are worthy for checking, we tried to predict factual claims by highlighting specific cue words in a classification process. In <ref type="bibr" coords="2,411.09,142.90,10.52,8.74" target="#b0">[1]</ref> we presented our approach for task 2 (checking claims factuality). In the following section, we present the previous works in the literature, then in Section 3, we describe the task. In Section 4, we describe our approach. Section 5 presents the experimental results, and finally in Section 6 we draw some conclusions and discuss further work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The main orientation in the literature was focused more on another related issue on claims, about detecting their factuality. Some researchers have proposed multiple approaches using different types of features to handle this issue. In <ref type="bibr" coords="2,452.86,279.96,10.52,8.74" target="#b1">[2]</ref> the authors have used a tree kernel approach to detect claims in the argument mining domain. Their approach used consistency trees of sentences to detect claims by capturing the trees similarities. They employed a support vector machine (SVM). In a different direction, a set of textual features to detect worthy claims in the presidential debates was proposed in <ref type="bibr" coords="2,331.23,339.74,9.96,8.74" target="#b2">[3]</ref>. They used sentiment polarity, number of words in a sentence, Bag-of-Words (BOW) using the Tf-Idf weighting scheme, Part-of-Speech tags, and named entities types. Since they generated a large feature set, they used a feature selection technique to extract the top N important features. Finally, different classifiers were tested, where the Random Forest classifier shows better results. Another related approach was proposed in <ref type="bibr" coords="2,145.96,411.47,9.96,8.74" target="#b3">[4]</ref>, similarly, also for the presidential debates. The authors proposed different types of features, such as sentence-level features (sentiment, named entities, linguistic features etc.), contextual features (the position of a claim in the debate), and other mixed features such as text embedding, the discussed topic, and contradictions in the debate. For their approach, a SVM and a deep forward neural network (FNN) were used. In the results, the FNN showed better results comparing to the SVM. They created a corpus from the USA presidential debates of 2016, with a total of 5,415 sentences and they made it available to the research community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task Description</head><p>A set of presidential debates from the US presidential election are presented for the task, where each claim in the debate text has been tagged manually as worth to be check <ref type="bibr" coords="2,186.20,584.39,12.73,8.74" target="#b0">(1)</ref> or not (0). The text of the debates is used for the task as it is, to give the opportunity to the participants to exploit also contextual features in the debates. These debates are provided in two languages, English and Arabic, where the Arabic text is obtained translating from the English debates. The dataset that was provided is totally imbalanced, where the total number of claims is 4064: 90 claims are worth to be check and 3970 are not. The task goal is to detect the claims that are worthy for checking and to rank them, from the most worthy one for checking to the lowest one. The Average Precision was used as a performance measure. More details of the task are mentioned in <ref type="bibr" coords="3,417.34,130.95,9.96,8.74" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Proposed Approach</head><p>Previously, the authors in <ref type="bibr" coords="3,252.50,187.11,10.52,8.74" target="#b4">[5]</ref> have proposed a text distortion technique to enhance thematic text clustering by maintaining the words that have a low frequency in a document. Later on, a similar research in <ref type="bibr" coords="3,382.95,211.02,10.52,8.74" target="#b5">[6]</ref> has used the same text distortion technique for authorship attribution task, where the author has maintained the words that have the highest frequency in the documents, in an attempt to detect the author from his writing style.</p><p>We believe that this type of tasks is more thematic than stylistic, where the writing style is not important as the thematic words. In our approach, we used the same text distortion technique to detect worthy claims, where we concealed words that have high frequency in documents and maintaining (highlighting) other cue words that are used more in factual claims. Therefore, we followed <ref type="bibr" coords="3,470.07,306.70,10.52,8.74" target="#b4">[5]</ref> in their approach by concealing the most frequent words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Text Distortion with Linguistic Features</head><p>In our approach, we have maintained the thematic words (that have the lowest frequency) using a threshold (C). The higher value of C is, the more thematic words are maintained. Also, we maintained a set of linguistic cue words (LC) that were used previously in <ref type="bibr" coords="3,265.40,404.71,10.52,8.74" target="#b6">[7]</ref> to infer the credibility of news (see Table <ref type="table" coords="3,468.97,404.71,3.87,8.74" target="#tab_0">1</ref>). Additionally, we maintained also the named entities (NE) from being distorted, such as: Iraq, Trump, America. Through the manually checking of the claims, we found the checking worthy claims tended to list different types of named entities. In Table <ref type="table" coords="3,189.56,596.30,3.87,8.74">2</ref>, we show an example of the distortion process.</p><p>After applying the distortion process, the new version of the text was used by the char n-gram model using Tf-Idf weighting scheme. The new distorted text, become less biased by the high frequency words, such as stopwords. Finally, after preparing the distorted text, there is still one issue which is the value of C variable. The value of C is crucial, being a threshold between the amount Table <ref type="table" coords="4,177.17,115.91,4.13,7.89">2</ref>. An example of the text distortion process using different values of C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original claim</head><p>It was actually $1.7 billion in cash, obviously, I guess for the hostages. of thematic and the stylistic words. In Section 5, we show how we select the most appropriate value of C. For the Arabic language, we employed the same approach, where the only issue we had was the Arabic version of the linguistic lexicons. The manual translation of them is a time-consuming process, where they are quite large. Therefore, we used Google Translation API to translate these lexicons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Results</head><p>In this section, we present the tuning process of our approach. We carried out many experiments to test different machine learning classifiers. We found that the K-Nearest-Neighbor (KNN) has achieved the highest Average Precision value. We had have two parameters to select the best model: the value of Kneighbors (K) of the KNN classifier and the C value of the distortion ratio. The selection process of these two values is hard to be set manually, therefore, we used the Grid Search technique to select the most appropriate values of these two parameters. The best value of K is 1, where for C value is 1700. The low value of K is due to the highly imbalanced situation of the dataset; larger values tend to bias the classifier to the majority class. A similar process was applied to select the best parameters but using word n-gram rather than character. For the evaluation, the Average Precision @N was used. The results of both runs are showed in Table <ref type="table" coords="4,229.05,534.19,3.87,8.74">3</ref>. From these runs, we can see that char n-gram model outperformed clearly the one using word n-gram.</p><p>Table <ref type="table" coords="4,164.17,566.11,4.13,7.89">3</ref>. The results obtained during the tuning phase using word and char n-gram models. We chose @N in our experiments as the last record in the testing part.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approach</head><p>Classifier K C value n-gram AVG Precision @N Text Distortion + char n-gram <ref type="bibr" coords="4,284.58,609.23,20.99,7.86">KNN</ref>  Ranking Claims After the claims have been detected, it is important to rank them based on their worthiness for checking. For the ranking process, we used the KNN classifier. We ranked the claims based on the KNN confidence in the classification process. At the beginning, we extracted the distances to the nearest neighbor (since we used K-neighbor equal to 1) for all the predictions in the test file. Then we applied a normalization for the distances to range 0-1. For each predicted instance, we checked the class type of the nearest neighbor: if it was positive, we subtracted the distance value from 1 and we used it for the ranking. We subtracted the distance from 1 to take the inverse of it: the small distance value (near to zero) mean a high classification confidence. The highest value (near to 1) is the one that obtained a higher rank (more worthy for checking).</p><p>We the same process when the nearest neighbor is from the negative class, the rank value by -1, in order to discriminate the positive and the negative instances.</p><p>As we mentioned before, the used measure for this task is the Average Precision. In the official testing phase, multiple testing files were presented. For the final results the Mean Average Precision (MAP) was used. The official results of the task 1 are shown in Table <ref type="table" coords="5,269.75,310.48,3.87,8.74" target="#tab_2">4</ref>. In the English part of the task, our approach has achieved the third position among seven teams, where the results are close to each other. In the Arabic part, only two teams have submitted their results. Similar to English, the results are close and there is not big difference between them. We believe that the lower results of our approach in the Arabic part is because of the automatic translation of the lexicons. A manual translation would have been more reliable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>Detecting the claims that are worthy to be checked is important being a preliminary step for detecting their factuality. With these two steps, we can improve the journalists work of manual investigating for instance presidential debates. As a result of that, journalists can achieve their work quicker and in an easier manner. As we saw from the official results, performances are low, showing the difficulty of the task. Also, we can conclude that text distortion method worked better than using the full text in the classification process, where it has improved the results comparing to the baseline with the normal BOW method. As future work, we will try to test more features that could discriminate the claims that are worthy to be checked from those that are not.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,173.32,159.03,24.57,7.86;4,234.78,159.03,233.46,7.86;4,300.31,169.99,102.39,7.86;4,150.29,181.34,70.65,7.86;4,239.11,181.34,224.81,7.86;4,301.28,192.30,100.45,7.86;4,143.38,203.66,328.61,7.86;4,314.85,214.62,73.32,7.86;4,143.38,225.98,322.91,7.86;4,316.25,236.93,70.52,7.86"><head></head><label></label><figDesc>** ******** $ # . # ******* ** **** , ********* , * ***** *** *** ******** . C = 0 &amp; LC+NE ** *** actually $ # . # ******* ** **** , obviously , * guess *** *** ******** . C = 2000 &amp; LC+NE ** *** actually $ 1 . 7 ******* ** cash , obviously , * guess *** *** hostages . C = 3500 &amp; LC+NE It *** actually $ 1 . 7 billion in cash , obviously , I guess for *** hostages .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,189.68,470.21,235.99,108.16"><head>Table 1 .</head><label>1</label><figDesc>Samples from the linguistic lexicons.</figDesc><table coords="3,189.68,491.01,235.99,87.36"><row><cell>Linguistic lexicons</cell><cell>Examples</cell></row><row><cell>Assertives</cell><cell>appear, declare, guarantee, hypothesize</cell></row><row><cell>Factives</cell><cell>learn, realize, know, discover</cell></row><row><cell>Hedges</cell><cell>almost, guess, indicate, mostly</cell></row><row><cell>Implicatives</cell><cell>cause, manage, hesitate, neglect</cell></row><row><cell>Report</cell><cell>admit, answer, clarify, comment</cell></row><row><cell>Bias</cell><cell>adhere, act, agree, allow, addition</cell></row><row><cell>Subjectivity</cell><cell>afraid, champ, apologist, amusement</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,167.88,342.37,279.59,108.16"><head>Table 4 .</head><label>4</label><figDesc>Official results for the Task1, released using MAP measure.</figDesc><table coords="5,221.05,363.17,174.13,87.36"><row><cell>Team</cell><cell>English</cell><cell>Arabic</cell></row><row><cell>Prise de Fer</cell><cell>0.1332</cell><cell></cell></row><row><cell>Copenhagen</cell><cell>0.1152</cell><cell></cell></row><row><cell>UPV-INAOE</cell><cell>0.1130</cell><cell>0.0585</cell></row><row><cell>bigIR</cell><cell>0.1120</cell><cell>0.0899</cell></row><row><cell>Fragarach</cell><cell>0.0812</cell><cell></cell></row><row><cell>blue</cell><cell>0.0801</cell><cell></cell></row><row><cell>RNCC</cell><cell>0.0632</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7">Acknowledgements</head><p>The authors acknowledge the <rs type="grantNumber">SomEMBED TIN2015-71147-C2-1-P</rs> <rs type="projectName">MINECO</rs> research project. The work on the data in Arabic as well as this publication were made possible by NPRP grant #<rs type="grantNumber">9-175-1-033</rs> from the <rs type="funder">Qatar National Research Fund</rs> (a member of <rs type="funder">Qatar Foundation</rs>). The statements made herein are solely the responsibility of the last two authors.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_r2ZKrnZ">
					<idno type="grant-number">SomEMBED TIN2015-71147-C2-1-P</idno>
					<orgName type="project" subtype="full">MINECO</orgName>
				</org>
				<org type="funding" xml:id="_n3HNPeT">
					<idno type="grant-number">9-175-1-033</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,138.35,313.95,342.24,7.86;6,146.91,324.90,333.68,7.86;6,146.91,335.86,333.68,7.86;6,146.91,346.82,240.44,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,457.43,313.95,23.16,7.86;6,146.91,324.90,333.68,7.86;6,146.91,335.86,72.14,7.86">UPV-INAOE-Autoritas -Check That: An Approach based on External Sources to Detect Claims Credibility</title>
		<author>
			<persName coords=""><forename type="first">Bilal</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manuel</forename><surname>Montes-Y-Gòmez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,237.96,335.86,242.64,7.86;6,146.91,346.82,116.87,7.86">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum, CLEF &apos;18</title>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date>September</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,357.78,342.24,7.86;6,146.91,368.74,204.91,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,284.89,357.78,195.70,7.86;6,146.91,368.74,49.85,7.86">Context-Independent Claim Detection for Argument Mining</title>
		<author>
			<persName coords=""><forename type="first">Marco</forename><surname>Lippi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Torroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,215.77,368.74,22.93,7.86">IJCAI</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="185" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,379.70,342.24,7.86;6,146.91,390.66,333.68,7.86;6,146.91,401.62,333.68,7.86;6,146.91,412.58,20.99,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,361.38,379.70,119.21,7.86;6,146.91,390.66,140.65,7.86">Detecting Check-Worthy Factual Claims in Presidential Debates</title>
		<author>
			<persName coords=""><forename type="first">Naeemul</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengkai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Tremayne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,306.07,390.66,174.52,7.86;6,146.91,401.62,239.22,7.86">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1835" to="1838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,423.53,342.24,7.86;6,146.91,434.49,333.68,7.86;6,146.91,445.45,333.68,7.86;6,146.91,456.41,256.77,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,186.62,434.49,293.97,7.86;6,146.91,445.45,55.92,7.86">A Context-Aware Approach for Detecting Worth-Checking Claims in Political Debates</title>
		<author>
			<persName coords=""><forename type="first">Pepa</forename><surname>Gencheva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ivan</forename><surname>Koychev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,221.61,445.45,258.98,7.86;6,146.91,456.41,116.62,7.86">Proceedings of the International Conference Recent Advances in Natural Language Processing</title>
		<meeting>the International Conference Recent Advances in Natural Language Processing</meeting>
		<imprint>
			<publisher>RANLP</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="267" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,467.37,342.24,7.86;6,146.91,478.33,333.68,7.86;6,146.91,489.29,333.68,7.86;6,146.91,500.25,20.99,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,183.29,478.33,293.35,7.86">Reducing the Loss of Information Through Annealing Text Distortion</title>
		<author>
			<persName coords=""><forename type="first">Ana</forename><surname>Granados</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manuel</forename><surname>Cebrian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Camacho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Borja</forename><surname>Rodriguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,146.91,489.29,234.36,7.86">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1090" to="1102" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,511.21,342.24,7.86;6,146.91,522.16,333.68,7.86;6,146.91,533.12,303.13,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,244.18,511.21,182.68,7.86">Authorship Attribution using Text Distortion</title>
		<author>
			<persName coords=""><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,445.36,511.21,35.23,7.86;6,146.91,522.16,333.68,7.86;6,146.91,533.12,86.52,7.86">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<title level="s" coord="6,283.84,533.12,48.80,7.86">Long Papers</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1138" to="1149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,544.08,342.24,7.86;6,146.91,555.04,333.68,7.86;6,146.91,566.00,333.68,7.86;6,146.91,576.96,48.38,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,345.44,544.08,135.16,7.86;6,146.91,555.04,168.94,7.86">Leveraging Joint Interactions for Credibility Analysis in News Communities</title>
		<author>
			<persName coords=""><forename type="first">Subhabrata</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,334.97,555.04,145.63,7.86;6,146.91,566.00,275.88,7.86">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="353" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,587.92,342.25,7.86;6,146.91,598.88,333.67,7.86;6,146.91,609.84,333.68,7.86;6,146.91,620.79,333.68,7.86;6,146.91,631.75,333.68,7.86;6,146.91,642.71,240.44,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,332.29,609.84,148.30,7.86;6,146.91,620.79,333.68,7.86;6,146.91,631.75,70.47,7.86">Overview of the CLEF-2018 Check-That! Lab on Automatic Identification and Verification of Political Claims. Task 1: Check-Worthiness</title>
		<author>
			<persName coords=""><forename type="first">Pepa</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Tamer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Reem</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wajdi</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Spas</forename><surname>Kyuchukov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Giovanni</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,237.12,631.75,243.47,7.86;6,146.91,642.71,116.87,7.86">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum, CLEF &apos;18</title>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date>September</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
