<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,149.10,115.96,317.15,12.62">Check It Out : Politics and Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,139.54,153.97,70.75,8.74"><forename type="first">Yash</forename><forename type="middle">Kumar</forename><surname>Lal</surname></persName>
						</author>
						<author>
							<persName coords="1,217.81,153.97,64.12,8.74"><forename type="first">Dhruv</forename><surname>Khattar</surname></persName>
							<email>dhruv.khattar@research.iiit.ac.in</email>
						</author>
						<author>
							<persName coords="1,289.95,153.97,66.44,8.74"><forename type="first">Vaibhav</forename><surname>Kumar</surname></persName>
							<email>vaibhav.kumar@research.iiit.ac.in</email>
						</author>
						<author>
							<persName coords="1,365.25,153.97,86.48,8.74"><forename type="first">Abhimanshu</forename><surname>Mishra</surname></persName>
							<email>abhimanshu@gmail.com</email>
						</author>
						<author>
							<persName coords="1,271.25,165.92,72.86,8.74"><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Manipal</orgName>
								<orgName type="institution">Manipal Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">International Institute of Information Technology Hyderabad</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">International Institute of Information Technology Hyderabad</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Birla Institute of Technology</orgName>
								<address>
									<addrLine>Mesra</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">International Institute of Information Technology Hyderabad</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,149.10,115.96,317.15,12.62">Check It Out : Politics and Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">894A5E73E61C055075473410F5D62EF7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Fact Checking</term>
					<term>Bidirectional LSTM</term>
					<term>Attention Mechanism</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The task of fact-checking has been formalised as the assessment of the truthfulness of a claim. Be it a political proclamation or a technological development, verification of a new tidbit of information before its propagation to the general public is of utmost importance. Failing to do so leads to the spread of misinformation, which is a devious tool. Fact-checking is commonly performed by journalists, manually looking up information pertaining to the statement in question. This is a drawn out and tedious process with a chance of the concerned person not covering the domain exhaustively. Some of this effort is reduced by the use of knowledge bases created over a period of time. In this work under Task 2 (Factuality) of the CLEF 2018 CheckThat! Lab, we detail a neural network based methodology which models the textual data of a claim based on various representations of its words and characters. An affixed attention mechanism allows us to encapsulate linguistic features common in false claims. We achieve an accuracy of 39.57% on the task dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Fact-checking is the task of evaluating claims made in discourse by public figures like politicians, pundits etc. The process of creation and curation of an article often takes a journalist through the fact checking phase. This task is a part of the pipeline in the creation of knowledge bases for various domains. Apart from journalists, with the advent of the present political scenario, institutes and government organisations dedicated to fact-checking have risen to prominence. Lawyers, as part of the judicial process, are required to meticulously vet facts and statements before presenting it to the concerned authorities.</p><p>Even with the plethora of information available on the Internet, just a click away, it is a tedious and long drawn-out process. Generally, it involves first checking the validity of the claim from a curated list of trusted sources. Next, the consistency of the claim is verified by looking it up against various sources. For the preceding to happen, the fact-checker has to first fully dissect and understand the claim being made since there can be multiple interpretations of the same, or it can, in turn, be based on a combination of factors or pre-requisite claims. Websites providing this service generally provide in-depth analysis, encompassing the different possibilities, of a claim rather than a numeric score for its validity.</p><p>Fact-checking requires more research and a more advanced style of writing than ordinary journalism. The difficulty of fact-checking, exacerbated by a lack of resources for investigative journalism, leaves many harmful claims unchecked, particularly at the local level. Its effectiveness is negatively impacted by a gap in time and availability (defined as the necessity of a checker to have to look up a documented fact nevertheless).</p><p>The emergence of the field of computational journalism has promoted the conversation about the need and importance of automatic fact-checking systems. <ref type="bibr" coords="2,134.77,381.58,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="2,146.95,381.58,7.75,8.74" target="#b1">2]</ref> have pioneered the work being done to achieve the same. Bolstered by the advances being made in the domains of natural language processing, databases and information retrieval, the objective is to provide journalists with tools to effectively and accurately automate this element of their job. This automation is enabled by the increasing online availability of datasets, survey results, and reports in machine-readable formats by various institutions. Another layer of checks required is at the reader level.</p><p>With the advent and exponential rise of social media platforms, dissemination of news might wholly skip the traditional channel, thereby not being verified by journalists at all. Apart from this, an increase in citizen journalism <ref type="bibr" coords="2,438.85,497.00,10.52,8.74" target="#b4">[5]</ref> means that anyone is capable of creating and disseminating 'facts' without checks and consequences, leading to far-reaching misinformation.</p><p>Another problem with current fact-checking platforms is their outdated nature of publishing. Many of these rely on older content management systems built just for newspapers and blogs that are not designed for structured journalism. This limits how well they can be used in computational pipelines.</p><p>We propose a neural network based architecture for the task. We leverage the distributional semantics of the claim and model its temporal and sequential properties. The contribution of a word towards the validity of the claim is calculated in a differential manner since the output of the LSTM is passed into an attention layer <ref type="bibr" coords="2,201.65,644.16,9.96,8.74" target="#b2">[3]</ref>, following which it goes through a dense layer and assigns an output class.</p><p>Most of the work done towards accomplishment of this task requires manual effort. <ref type="bibr" coords="3,163.18,154.04,10.52,8.74" target="#b6">[7]</ref> formalised the definition of the task at hand and proposed an approach and format of constructing the required dataset. <ref type="bibr" coords="3,347.89,166.00,10.52,8.74" target="#b7">[8]</ref> theorise the construction of an ideal fact-checking system, having built ClaimBuster, a system to detect if a sentence has a claim in it and if the claim is worth validating. Such a tool could streamline the task for journalists, causing them to do research sparingly instead of looking at all sentences in discourse. Due to the prominence of fake news in the media nowadays, organisations such as FullFact have taken it upon themselves to weed out the problem, setting out a roadmap to do the same and inviting collaboration in the field. They have released a survey detailing the techniques being adopted now, possible ways of tackling this problem, and defining global standards to be followed for the creation of an effective, combined solution. <ref type="bibr" coords="3,174.99,285.55,10.52,8.74" target="#b5">[6]</ref> developed sentence representations from natural language inference data which can be used as part of a transfer learning approach to solve this problem. FullFact has hypothesised that these vectors can act as effective inputs to a bi-LSTM max-pooling network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model Architecture</head><p>We now describe our approach to developing a fact-checking system and the reasons behind devising such a model. We start with an explanation of the type of embeddings we have used and proceed to describe our proposed model, a bidirectional long short term memory network with an attention mechanism. An overview of the architecture can be seen in Figure <ref type="figure" coords="3,374.79,423.40,3.87,8.74">1</ref>. Finally, we cover how the parameters are learned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Distributed Word Embeddings</head><p>Considering the effectiveness of distributional semantics in modeling language data, we use a pre-trained 300 dimensional Word2Vec <ref type="bibr" coords="3,368.57,474.01,10.52,8.74" target="#b3">[4]</ref> model trained over 100 billion words in the Google News corpus using the Continuous Bag of Words architecture. These map the words in a language to a high dimensional realvalued vectors to capture hidden semantic and syntactic properties of words, and are typically learned from large, unannotated text corpora. For each word in the title, we obtain its equivalent Word2Vec embeddings using the model described above.</p><p>We now move on to describing the crux of our proposed approach.</p><p>Bidirectional LSTM with Attention Recurrent Neural Network (RNN) is a class of artificial neural networks which utilizes sequential information and maintains history through its intermediate layers. A standard RNN has an internal state whose output at every time-step which can be expressed in terms of that of previous time-steps. However, it has been seen that standard RNNs suffer from a problem of vanishing gradients <ref type="bibr" coords="3,467.31,632.21,9.96,8.74" target="#b8">[9]</ref>. This means it will not be able to efficiently model dependencies and interactions between words that are a few steps apart. LSTMs are able to tackle this issue Fig. <ref type="figure" coords="4,254.44,414.07,4.13,7.89">1</ref>. Overview of proposed model by their use of gating mechanisms. We convert the words of the claim into the previously mentioned types of embeddings to act as input to our bidirectional LSTMs.</p><p>(</p><formula xml:id="formula_0" coords="4,153.58,478.78,71.40,15.57">- → h 1 , - → h 2 , . . . , - → h R</formula><p>) represent forward states of the LSTM and its state updates satisfy the following equations:</p><formula xml:id="formula_1" coords="4,234.84,513.34,245.75,15.57">- → f t , - → i t , - → o t = σ -→ W - → h t-1 , - → r t + - → b<label>(1)</label></formula><formula xml:id="formula_2" coords="4,241.88,539.09,238.71,15.57">- → l t = tanh - → V - → h t-1 , - → r t + - → d<label>(2)</label></formula><formula xml:id="formula_3" coords="4,255.99,561.19,224.60,15.57">- → c t = - → f t • - → c t-1 + - → i t • - → l t<label>(3)</label></formula><formula xml:id="formula_4" coords="4,268.66,582.30,207.69,15.57">- → h t = - → o t • tanh( - → c t ) (<label>4</label></formula><formula xml:id="formula_5" coords="4,476.35,588.22,4.24,8.74">)</formula><p>here σ is the logistic sigmoid function, -→ W and -→ V are matrices which represent the weights associated with the connections.</p><formula xml:id="formula_6" coords="4,303.12,602.38,84.22,15.57">- → f t , - → i t , - → o t represent</formula><formula xml:id="formula_7" coords="5,149.71,113.07,75.27,15.57">( ← - h 1 , ← - h 2 , . . . , ← - h R</formula><p>) denote the backward states and its updates can be computed similarly.</p><p>The number of bidirectional LSTM units is set to a constant K, which is the maximum length of all title lengths of records used in training. The forward and backward states are then concatenated to obtain (h 1 , h 2 , . . . , h K ), where</p><formula xml:id="formula_8" coords="5,283.23,182.71,197.36,15.57">h i = - → h i ← - h i<label>(5)</label></formula><p>Finally, we are left with the task of figuring out the significance of each word in the sequence i.e. how much a word shapes towards a writing style characteristic of factual claims. The effectiveness of attention mechanisms have been proven for the task of neural machine translation <ref type="bibr" coords="5,321.54,245.21,10.52,8.74" target="#b2">[3]</ref> and it has the same effect in this case. The goal of attention mechanisms in such tasks is to derive context vectors which capture relevant source side information and help predict the current target word. The sequence of annotations generated by the encoder to come up with a context vector capturing how each word contributes to the record's factuality is of paramount importance to this model. In a typical RNN encoderdecoder framework <ref type="bibr" coords="5,219.51,316.94,9.96,8.74" target="#b2">[3]</ref>, a context vector is generated at each time-step to predict the target word. However, we only need it for calculation of context vector for a single time-step.</p><formula xml:id="formula_9" coords="5,263.49,351.59,217.11,30.32">c attention = K j=1 α j h j<label>(6)</label></formula><p>where, h 1 ,. . . ,h K represents the sequence of annotations to which the encoder maps the post title vector and each α j represents the respective weight corresponding to each annotation h j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learning the Parameters</head><p>We use binary cross-entropy as the loss optimization function for our model. The cross-entropy method <ref type="bibr" coords="5,250.48,451.80,15.50,8.74" target="#b11">[14]</ref> is an iterative procedure where each iteration can be divided into two stages:</p><p>(1) Generate a random data sample (vectors, trajectories etc.) according to a specified mechanism.</p><p>(2) Update the parameters of the random mechanism based on the data to produce a "better" sample in the next iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>[10] has provided a compilation of all the sentences from the first and second of the 2016 US Presidential election debates and the Vice-Presidential debate. The discourse in these moderated debates contains a plethora of claims made by each candidate as they attempted to make their case to hold the highest office in the United States.</p><p>The first distinction between the types of sentences is that some of them contain claims, and need to be processed by the model, while the others do not, and can be ignored. Further, each of the sentences that has been tagged as containing a claim is assigned a label pertaining to the validity of the claim. Each claim can be one of three types : TRUE, HALF-TRUE and FALSE.</p><p>Each record is associated with a line number (position in discourse of the debate), the speaker (which can be either candidate, or the moderator, or SYS-TEM in case of external noise), a tag establishing whether it is a claim or not, a chronological claim number, and a label for the validity of the claim. In case of the sentence not containing a claim, it is considered part of a separate 'N/A' class. Table <ref type="table" coords="6,188.13,215.29,4.98,8.74" target="#tab_1">1</ref> shows some basic statistics found on analysis of the training data files. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metric</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiment Settings</head><p>We combine the three files and then randomly split the 4064 sentences into training and validation set in a 4:1 ratio. This ensures that the two sets do not overlap. The model hyperparameters are tuned over the validation set. We initialise the fully connected network weights with the uniform distribution in the range -6/(f anin + f anout) and 6/(f anin + f anout) <ref type="bibr" coords="6,411.97,442.77,14.61,8.74">[12]</ref>. We used a batch size of 256 and adadelta <ref type="bibr" coords="6,274.85,454.72,15.50,8.74" target="#b10">[13]</ref> as a gradient based optimizer for learning the parameters of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>The model was evaluated over test set of 7 files which contained a combined total of 192 possible claims to be verified. The subsequent result files were submitted to the CLEF Fact Checking Lab <ref type="bibr" coords="6,275.56,546.99,15.50,8.74" target="#b9">[10]</ref> to be evaluated against a variety of metrics. We reach a comparable accuracy to various proposed approaches to the task. The use of separate knowledge bases and other information sources would have contributed to higher accuracy or better recall for other participants' models <ref type="bibr" coords="7,149.21,154.86,15.50,8.74">[11]</ref> in this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>We see that LSTMs are able to model claims and figure out possible dependencies between its constituents. Furthermore, the use of an attention layer allows our approach to capture features unique to fake claims and leverage them in the verification of others.</p><p>As part of improving this approach, would like to try the addition of a knowledge base for political claims, and augmenting the dataset with tweets from Politico's Twitter handle tagged with #PresidentialDebate. It is also possible to generate a similarity score between a claim to be verified and each fact stored in the knowledge base, and evaluate if they refer to the same core idea.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,144.73,656.80,172.60,7.86"><head>First</head><label></label><figDesc>four authors have equal contribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,149.80,259.97,315.77,52.07"><head>Table 1 .</head><label>1</label><figDesc>Basic statistics of training data files</figDesc><table coords="6,149.80,259.97,315.77,41.16"><row><cell></cell><cell cols="3">Prez Debate 1 Prez Debate 2 Vice Prez Debate</cell></row><row><cell>Number of sentences</cell><cell>1403</cell><cell>1303</cell><cell>1358</cell></row><row><cell>Words in longest claim</cell><cell>64</cell><cell>91</cell><cell>91</cell></row><row><cell>Chars in longest claim</cell><cell>372</cell><cell>506</cell><cell>511</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,134.77,558.95,277.12,84.84"><head>Table 2</head><label>2</label><figDesc>details the outcome of the evaluation.</figDesc><table coords="6,203.46,591.67,208.42,52.12"><row><cell>Model</cell><cell cols="2">Accuracy Macro Recall</cell></row><row><cell cols="2">BiLSTM with Attention 39.57%</cell><cell>0.33</cell></row><row><cell>Team BigIR</cell><cell>39.57%</cell><cell>0.33</cell></row><row><cell>Team FACTR</cell><cell>41.01%</cell><cell>0.36</cell></row><row><cell>Team UPV-INAOE</cell><cell>38.85%</cell><cell>0.34</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,251.79,646.81,111.77,7.89"><head>Table 2 .</head><label>2</label><figDesc>Model Evaluation</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,138.35,361.20,342.25,7.86;7,146.91,372.16,333.68,7.86;7,146.91,383.12,123.06,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,340.07,361.20,140.52,7.86;7,146.91,372.16,133.21,7.86">Computational Journalism: A Call to Arms to Database Researchers</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,301.34,372.16,179.25,7.86;7,146.91,383.12,94.39,7.86">Proceedings of the Conference on Innovative Data Systems Research</title>
		<meeting>the Conference on Innovative Data Systems Research</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,394.05,342.24,7.86;7,146.91,405.01,333.68,7.86;7,146.91,415.97,72.98,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,326.35,394.05,154.24,7.86;7,146.91,405.01,12.33,7.86">The promise of computational journalism</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Flew</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Spurgeon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,178.65,405.01,301.94,7.86;7,146.91,415.97,44.32,7.86">Proceedings of the Australian and New Zealand Communication Association Conference</title>
		<meeting>the Australian and New Zealand Communication Association Conference</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,426.89,342.24,7.86;7,146.91,437.85,153.69,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,326.94,426.89,153.66,7.86;7,146.91,437.85,121.22,7.86">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,448.78,342.24,7.86;7,146.91,459.74,186.41,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="7,388.29,448.78,92.30,7.86;7,146.91,459.74,153.47,7.86">Efficient Estimation of Word Representations in Vector Space</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,470.66,342.24,7.86;7,146.91,481.62,25.60,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="7,191.61,470.66,182.19,7.86">Social news, citizen journalism and democracy</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goode</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>New Media &amp; Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,492.55,342.24,7.86;7,146.91,503.51,333.67,7.86;7,146.91,514.46,333.68,7.86;7,146.91,525.42,112.76,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,467.28,492.55,13.31,7.86;7,146.91,503.51,333.67,7.86;7,146.91,514.46,56.93,7.86">Supervised Learning of Universal Sentence Representations from Natural Language Inference Data</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,224.60,514.46,255.99,7.86;7,146.91,525.42,84.09,7.86">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,536.35,342.25,7.86;7,146.91,547.31,333.67,7.86;7,146.91,558.27,84.74,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,256.77,536.35,219.81,7.86">Fact checking: Task definition and dataset construction</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Reidel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,160.00,547.31,320.59,7.86;7,146.91,558.27,56.07,7.86">Proceedings of the ACL Workshop on Language Technologies and Computational Social Science</title>
		<meeting>the ACL Workshop on Language Technologies and Computational Social Science</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,569.19,342.24,7.86;7,146.91,580.15,333.68,7.86;7,146.91,591.11,189.16,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,231.42,580.15,154.59,7.86">The Quest to Automate Fact-Checking</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Adair</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tremayne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,406.80,580.15,73.80,7.86;7,146.91,591.11,160.50,7.86">Proceedings of the Computation + Journalism Symposium</title>
		<meeting>the Computation + Journalism Symposium</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,602.04,342.24,7.86;7,146.91,613.00,52.73,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,296.31,602.04,98.95,7.86">Long short-term memory</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,418.02,602.04,62.57,7.86;7,146.91,613.00,24.06,7.86">Neural Computation</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,623.92,337.97,7.86;7,146.91,634.88,333.68,7.86;7,146.91,645.84,333.68,7.86;7,146.91,656.80,333.68,7.86;8,146.91,119.67,333.68,7.86;8,146.91,130.63,287.06,7.86;8,134.77,141.59,345.83,7.86;8,146.91,152.55,333.68,7.86;8,146.91,163.51,333.68,7.86;8,146.91,174.47,333.68,7.86;8,146.91,185.43,333.68,7.86;8,146.91,196.39,159.69,7.86;8,134.77,207.34,345.83,7.86;8,146.91,218.30,333.68,7.86;8,146.91,229.26,132.20,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,361.85,645.84,118.74,7.86;7,146.91,656.80,329.36,7.86;8,264.29,207.34,216.30,7.86;8,146.91,218.30,84.70,7.86">Overview of the CLEF-2018 CheckThat! Lab on Automatic Identification and Verification of Political Claims</title>
		<author>
			<persName coords=""><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Tamer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Reem</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wajdi</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pepa</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Spas</forename><surname>Kyuchukov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Giovanni</forename><forename type="middle">;</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Da San</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Giovanni</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,162.03,119.67,318.56,7.86;8,146.91,130.63,287.06,7.86;8,134.77,141.59,7.85,7.86;8,331.36,163.51,149.23,7.86;8,146.91,174.47,333.68,7.86;8,146.91,185.43,38.51,7.86;8,206.49,185.43,274.11,7.86;8,146.91,196.39,159.69,7.86;8,252.75,218.30,227.84,7.86;8,146.91,229.26,103.53,7.86">Proceedings of the Ninth International Conference of the CLEF Association: Experimental IR Meets Multilinguality, Multimodality, and Interaction 11</title>
		<meeting>the Ninth International Conference of the CLEF Association: Experimental IR Meets Multilinguality, Multimodality, and Interaction 11</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>Proceedings of the International Conference on Artificial Intelligence and Statistics</note>
</biblStruct>

<biblStruct coords="8,142.62,240.22,337.97,7.86;8,146.91,251.18,93.19,7.86" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="8,209.40,240.22,190.77,7.86">ADADELTA: an adaptive learning rate method</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1212.5701</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,142.62,262.14,337.98,7.86;8,146.91,273.10,281.16,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,427.56,262.14,53.03,7.86;8,146.91,273.10,105.78,7.86">A Tutorial on the Cross-Entropy Method</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>De Boer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">P</forename><surname>Kroese</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mannor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">Y</forename><surname>Rubinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,274.67,273.10,124.73,7.86">Annals of Operations Research</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
