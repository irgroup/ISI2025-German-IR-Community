<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,150.84,115.96,313.68,12.62;1,172.25,133.89,270.85,12.62;1,227.12,151.82,161.13,12.62">CLEF MC2 2018 Lab: Technical 0verview of Cross Language Microblog Search and Argumentative Mining</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,138.53,189.49,74.99,8.74"><forename type="first">Jean</forename><forename type="middle">Valre</forename><surname>Cossu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">My Local Influence</orgName>
								<address>
									<settlement>Aubagne</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,224.08,189.49,59.99,8.74"><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">UNED</orgName>
								<address>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,294.62,189.49,61.71,8.74"><forename type="first">Malek</forename><surname>Hajjem</surname></persName>
							<email>malek.hajjem@univ-avignon.fr</email>
							<affiliation key="aff2">
								<orgName type="laboratory">LIA</orgName>
								<orgName type="institution">Avignon University</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">LIPAH</orgName>
								<orgName type="institution">Tunis El Manar University</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,373.23,189.49,64.24,8.74"><forename type="first">Olivier</forename><surname>Hamon</surname></persName>
							<affiliation key="aff3">
								<orgName type="laboratory">LIPAH</orgName>
								<orgName type="institution">Tunis El Manar University</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,448.02,189.49,28.81,8.74;1,249.01,201.45,24.52,8.74"><forename type="first">Chiraz</forename><surname>Latiri</surname></persName>
							<affiliation key="aff3">
								<orgName type="laboratory">LIPAH</orgName>
								<orgName type="institution">Tunis El Manar University</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,303.46,201.45,58.42,8.74"><forename type="first">Eric</forename><surname>Sanjuan</surname></persName>
							<email>eric.sanjuan@univ-avignon.fr</email>
							<affiliation key="aff2">
								<orgName type="laboratory">LIA</orgName>
								<orgName type="institution">Avignon University</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<address>
									<settlement>Syllabs, Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="laboratory">LIPAH</orgName>
								<orgName type="institution">Tunis El Manar University</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,150.84,115.96,313.68,12.62;1,172.25,133.89,270.85,12.62;1,227.12,151.82,161.13,12.62">CLEF MC2 2018 Lab: Technical 0verview of Cross Language Microblog Search and Argumentative Mining</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B7D8986E92F6E557195146E091103DAE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Argumentation Mining</term>
					<term>Microblog Search</term>
					<term>Cross Language Information Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>MC2 lab mainly focuses on developing processing methods and resources to mine the social media (SM) spheres surrounding cultural events such as festivals, music, books, movies and museums. Two main tasks and one pilot ran in 2018. The first task was specific to movies. Topics were extracted from the French VodKaster website that allows readers to get personal short comments (microcritics) about movies. The challenge was to find related microblogs in four different languages in a large archive. The second task, argumentation mining, aimed to automatically identify reason-conclusion structures that can lead to model social web users positions about a cultural event expressed via Twitter microblogs. The idea was to perform a search process on a massive microblog collection that focuses on claims about a given festival. A pilot task was also launched on a new corpus, extending the 2017 language recognition task to handle also dialects.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Following previous editions, MC2 Lab 2018 was centered on multilingual culture mining and retrieval processes over the large corpus of cultural microblogs <ref type="bibr" coords="1,467.42,584.39,13.18,8.74" target="#b3">[4]</ref> considered in the two previous editions <ref type="bibr" coords="1,306.10,596.34,12.09,8.74" target="#b2">[3,</ref><ref type="bibr" coords="1,319.86,596.34,7.01,8.74" target="#b4">5]</ref>. Two main tasks were considered: cross-language cultural microblog search (Task 1) and Argumentation Mining (Task 2).</p><p>Topics for Task 1 (microblog search) were extracted from the VodKaster website, that allows French readers to get personal short comments (microcritics) about movies. You can get similar and/or complementary opinions on Twitter; however, they are less specific to movies and harder to find. The usual case is to display to the reader a concise summary of microblogs related to the microcritics he/she is reading, considering bilingual and trilingual users that would read microblogs in other languages than French. Summaries were exclusively made of extracts from microblog contents and should include authors' names if considered informative, and have to be readable. Codes like external URLs references to multimedia objects had to be removed as well. Summaries were intended to provide an idea of all relevant information included in the corpus, and diversity among top ranked microblogs was considered important.</p><p>Task 2 was about Argumentation Mining, a new problem in corpus-based text analysis that addresses the challenging task of automatically identifying the justifications provided by opinion holders for their judgment. Several approaches of argumentation mining have been proposed so far in areas such as legal documents, online debates, product reviews, newspaper articles and court cases, as well as in dialogical domains. With the popularization of social networks, argumentation mining is considered as an extension of the opinion mining issue from social network content. The aim is to automatically identify reason-conclusion structures that can lead to model social web users positions about a service or an event expressed through social network platforms like Twitter. Indeed, when we need to form an opinion on a new topic or make a decision, arguments is what we are looking for, rather than a mere aggregation of sentiment or stance. To make argumentation structures available, in the case of Twitter, robust automatic recognition is required. However, the ambiguity of natural language text produced in social media, the different writing styles, the lack of proper syntax, the large amount of implicit context and the heterogeneity of sources make argumentation mining on Twitter a very challenging problem.</p><p>Another possible way to identify the argumentation structures from a generic tweet corpus, is to use approaches based on information extraction. The idea is to perform a search process that focuses on claims about a given topic within a massive collection. This approach relates to the field of focused retrieval, that aims to provide users with direct access to relevant information in retrieved documents. In this task, relevant information is expressed in the form of arguments <ref type="bibr" coords="2,163.88,517.62,9.96,8.74" target="#b6">[7]</ref>.</p><p>As in previous MC2 editions, registered participants were given access to the microblog collection <ref type="bibr" coords="2,237.51,549.56,11.88,8.74" target="#b3">[4]</ref> provided by ANR project GAFES <ref type="foot" coords="2,401.35,547.99,3.97,6.12" target="#foot_0">7</ref> with their metainformation and expanded URLs on a MySQL server. Due to legal terms, the access to this database is restricted to registered participants under a privacy agreement.</p><p>These two tasks are fully described in the remainder of the paper.</p><p>2 Task 1: Cross-Language cultural microblog search Vodkaster<ref type="foot" coords="3,178.02,140.93,3.97,6.12" target="#foot_1">8</ref> is a French social network about movies where participants can share comments about movies under the form of microcritics no longer than a microblog. The main differences are the restricted cultural domains and the form. The objective of the task is for a given movie or microcritic language among French, English, Spanish, Portuguese and Arabic to provide a summary of the related microblogs.</p><p>Microblogs included in a summary should provide relevant information about at least one of the following aspects:</p><p>-The film mentioned in the microcritic includes a subject, genre, presence in festivals, reception, audience, critics or opinions, as well as actors and producers careers. -Events such as festivals mentioned in the microcritics if any, including opinions and narratives. -Comments and critics in Twitter similar to those in the microcritic if any.</p><p>Extended summaries can include microblogs about closely related films and events. -If promotional, automatic microblogs or retweets are not considered as relevant. However, retweets by movie aficionados or movie makers are considered relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Use Case</head><p>The task's use case is to display a concise summary of microblogs to a (native French) reader that are related to the microcritics he/she is reading, considering bilingual and trilingual users that could read microblogs in other languages than French. Summaries are exclusively made of extracts from microblog contents and may include authors' names if this additional piece of information is considered as relevant and informative. Automatically produced summaries should be readable and coded items like external URLs and references to multimedia objects should be removed. Three different summary lengths in words are considered: 50, 150 and up to 250. Summaries are intended to provide an idea of all relevant information included in the corpus. Diversity among top ranked microblogs is important. If the summary does not provide any microblog directly related to the topic, it is implicitly suggesting that there is no relevant information in the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Topics</head><p>Topics represent a selection from VodKaster microcritics in French mentioning the term festival. Each topic contains:</p><p>-A topic ID, -A title made of the movie name, -A narrative showing a microcritic about the movie, -A list of nuggets (i.e terms and expressions) manually extracted from microcritic.</p><p>To facilitate data exploration, an Indri index with a web interface has been provided to query the whole set of microblogs. Online Indri indexes are also available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Results</head><p>Runs are evaluated according to their informativeness following INEX Tweets Contextualisation <ref type="bibr" coords="4,215.55,265.36,10.52,8.74" target="#b1">[2]</ref> guidelines. Seven teams registered for this task, but only one team (A collaboration between Chedi Bechikh Ali from the Institut Suprieur de Gestion, Universit de Tunis, Tunisia, and Hatem Haddad from the Universit Libre de Bruxelles) managed to submit 3 complete runs. A Baseline was generated based on Indri index. Both the baseline and the index were shared with participants.</p><p>A multilingual reference of 2887 unique textual contents that could be considered of interest by Vodkaster's users according to community managers has been manually extracted from the corpus. All microblogs in this reference contain personal opinions about movies or related festivals. Among them, only 229 could be related to topics in the queries. We used a large textual reference characterizing interestingness and a reduced reference about relevant microblogs, and then applied INEX Tweet Contextualisation <ref type="bibr" coords="4,308.16,409.15,10.52,8.74" target="#b1">[2]</ref> methodology to compare participant runs with the provided baseline.</p><p>All three runs from the only participant outperformed the baseline. Three approaches were experimented. One (FR-FR) without translation, another with translation to English (FR-EN) and a third one using a French to English dictionary. In terms of interestingness, the monolingual approach (FR-FR) did better, which is coherent with the fact that the majority of Vodkaster users express themselves in French. However, the translation approach (FR-EN) outperformed all others on relevancy. This is again coherent with the fact that a majority of microblogs in the corpus are in English. Very specific relevant microblogs can be found but not in the query original language.</p><p>Table <ref type="table" coords="4,177.24,541.31,4.24,8.74">2</ref>.3 shows interestingness and informativeness results for baseline and participant runs using the context-eval.pl<ref type="foot" coords="4,313.09,551.69,3.97,6.12" target="#foot_2">9</ref> program.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task 2: Mining Opinion Argumentations</head><p>Topics for this task are a selection of festival names which are popular on Flickr in English (14) and French (4). Participants have to search for the most argumentative tweets in the same collection of microblogs used for Task 1. The identified microblogs must be ranked according to their probability of being argumentative. This use case was proposed to help festival organisers deal with online opinions about their festival finding out not only what people liked/disliked but, most importantly, why. For each language (English and French), a monolingual scenario is expected. Diversity in the rank is not required, because an argument that is frequently repeated is assumed to be of higher priority.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluation</head><p>The official evaluation measure has been NDCG. This ranking measure gives a score for each retrieved microblog with a discount function over the rank.</p><p>These are examples of opinions about the "Cannes" festival name:</p><p>-I've seen some people saying they're boycotting Cannes because of the high heels rule. I'm not sure they'll notice. -Not going to lie, one of my favorite things about the Cannes festival is all of these handsome men in tuxedos. -Cannes is relevant because movies get timed standing ovations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Baseline</head><p>To express argumentation, users tend to employ a specific list of argumentative keywords <ref type="bibr" coords="5,181.34,527.43,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="5,193.52,527.43,7.75,8.74" target="#b7">8,</ref><ref type="bibr" coords="5,202.92,527.43,7.01,8.74" target="#b5">6]</ref>. For example:</p><p>-More, less: to compare and contrast ideas -Pronouns like my, mine, myself,I are used to make their statement sound more objective. -Verbs like believe, think, agree, should, could play an important role to identify argument components and express what users were expecting. -Adverbs like also,often or really emphasize the importance of some premise.</p><p>We also observed that some expressions (such as because -â†’ coz) could be normalized to match a higher number of microblogs. These lexical features about opinion and argumentation were provided to participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>Argumentative mining received considerable interest, with 31 registered participants. However, only 5 teams submitted a total of 18 runs per language. Organizer baselines were added to this pool as well. The NDGC has been adopted as the main official measure; however, precision at 100 gives the same rankings.</p><p>Two reference sets of argumentative structures were represented as regular expressions and have been assigned to each query (festival name). The first reference of 97 distinct regular expressions has been extracted a priori from the manual interactive run provided as baseline. The second one contains 77 expressions and has been extracted from participant runs. To avoid duplicated content, only microblog textual content has been considered. All meta-data such as URLs, #hashtags and @replies were removed.</p><p>These steps were both applied to the English and French runs.  <ref type="table" coords="6,163.32,373.48,4.13,7.89">2</ref>. Sample of regular expressions used to match participants runs in French and English languages Table <ref type="table" coords="6,176.78,428.50,4.24,8.74" target="#tab_1">3</ref>.3 shows the five top runs based on NDGC results for English queries based on the organizers' reference. Table <ref type="table" coords="6,311.34,440.45,4.24,8.74" target="#tab_1">3</ref>.3 shows the same for the reference extracted by pooling from participant submissions. Results over French are similar but due to a smaller number of queries, differences are not statistically significant.</p><p>All participant systems relied on an initial step of the preliminary treatment to filter the original dataset by language and topic.</p><p>Participant runs can be grouped into two strategies: Runs based on the same lexical resource provided by organizers and runs which make use of external resources. ERTIM Team falls in the second category, and it is the group that found the highest number of argumentative microblogs using lexical data enrichment <ref type="bibr" coords="6,152.34,560.32,13.18,8.74" target="#b8">[9]</ref>. This resource associates a score to each lemma according to its affective nature.</p><p>Besides these lexicon-based measures, opinion was detected based on the proportion of adjectives with respect to all Part-of-Speech tags. In addition to this opinion scoring process, ERTIM tackled the argumentation detection in the same way by scoring opinion tweets based on the number of conjunctions. Conjunctions are discourse connectors commonly used to structure a text. This was a systematic approach applied to all microblogs in the corpus. Although they found a number of argumentative microblogs higher than other participants for almost all queries, there was no overlap with argumentative microblogs found in the baseline runs.</p><p>Teams relying on language models using queries mixing multiword terms with argumentative connectors found less argumentative microblogs, but a larger overlap with the reference extracted from the baseline run. This was the case of the LIA Team, which found the best overlap with the reference of organizers by using a convolutional neural network. As no labeled data was provided, participants from this team constructed their own training dataset. Concerning ECNUica team, they experimented various re-ranking strategies. Finally the ISAMM team experimented with a combination of Information Retrieval, Topic Modeling and Opinion Mining techniques.  <ref type="table" coords="7,163.49,481.40,4.13,7.89">4</ref>. Average NDGC ranks for the five best runs for English on pool (*) and (**) denote statistical significance (with p &lt; 0.05 and p &lt; 0.005, respectively) with respect to the 6 th run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>The initial challenge for 2018 was, given a short movie review on the French VodKaster 10 Social Media site, to find related microblogs in the MC2 corpus in four different target languages (French, English, Spanish and Portuguese). Browsing the VodKaster website, French readers got personal short comments about movies. Since similar posts can be found on Twitter, we decided to display to the reader a concise summary of microblogs related to the comment he/she is reading, considering bilingual and trilingual users that would read microblogs in other languages than French. In this scenario, personal and argumentative microblogs are expected to be more relevant than news or official announcements. Microblogs sharing similar arguments can be considered as highly relevant even though they are about different movies. In addition, a second task was created focusing on argument mining in a multilingual collection. It consisted in finding personal and argumentative microblogs in the corpus. Public posts about cultural events such as festivals are frequently promotional announcements by organizers or artists. Personal argumentative microblogs about specific festivals, in contrast, provide real insights into public reception but both their variety and sparsity make them difficult to locate and aggregate. Argumentative mining attracted most of the participants' efforts in this edition of the MC2 CLEF Lab. The cold start scenario of finding them without any specific learning resources motivated the use of IR approaches based on language models or specialized linguistic resources.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,134.77,117.78,345.81,95.88"><head>Table 1 .</head><label>1</label><figDesc>Evaluation of runs submitted by Chedi Bechikh Ali from the Institut Suprieur de Gestion, Universit de Tunis, Tunisia and Hatem Haddad from the Universit Libre de Bruxelles, based on INEX context-eval skip-gram informativeness measure.</figDesc><table coords="5,236.62,117.78,142.11,63.06"><row><cell>Run</cell><cell cols="2">Interestingness Relevance</cell></row><row><cell>Baseline</cell><cell>0.057</cell><cell>0.0062</cell></row><row><cell>Baseline</cell><cell>5.28</cell><cell>0.41</cell></row><row><cell>fr-en-dict</cell><cell>5.86</cell><cell>1.09</cell></row><row><cell>fr-fr</cell><cell>10.14</cell><cell>1.51</cell></row><row><cell>fr-en</cell><cell>6.89</cell><cell>2.02</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,271.53,345.84,109.84"><head>Table 3 .</head><label>3</label><figDesc>3 provides examples of extracted regular expressions.</figDesc><table coords="6,134.77,317.14,308.07,64.23"><row><cell>Regular Expression</cell><cell>Argument Matched</cell><cell>Type</cell></row><row><cell>.* c'est bien mais .*</cell><cell>contrasting clause</cell><cell>generic</cell></row><row><cell>.* super programmation</cell><cell>exact argument</cell><cell>specific</cell></row><row><cell>(.*,){3,}</cell><cell cols="2">enumeration of at least 3 elements generic</cell></row><row><cell>.*delicious food .*</cell><cell>Exact argument</cell><cell>specific</cell></row><row><cell>Table</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,134.77,272.00,345.81,217.29"><head>Table 3 .</head><label>3</label><figDesc>Average NDGC ranks for the five best runs for English on organizer's reference. (*) denotes statistical significance with p &lt; 0.05 with respect to the 6 th run.</figDesc><table coords="7,134.77,272.00,249.04,217.29"><row><cell>Run</cell><cell cols="2">Rank EN Rank FR</cell></row><row><cell>LIA-run1</cell><cell>1 (*)</cell><cell>1</cell></row><row><cell>LIA-run2</cell><cell>2 (*)</cell><cell>2</cell></row><row><cell>ECNUica-0.6</cell><cell>3</cell><cell>6</cell></row><row><cell>ECNUica-0.6-2</cell><cell>4</cell><cell>8</cell></row><row><cell>ECNUica-0.4</cell><cell>5</cell><cell>3</cell></row><row><cell>Run</cell><cell cols="2">Rank EN</cell></row><row><cell cols="2">Ertim-run2</cell><cell>1 (**)</cell></row><row><cell cols="2">Ertim-run3</cell><cell>2 (*)</cell></row><row><cell cols="2">Ertim-run1</cell><cell>3 (*)</cell></row><row><cell cols="2">ECNUica-0.0-3</cell><cell>4</cell></row><row><cell>Baseline</cell><cell></cell><cell>5</cell></row><row><cell>Table</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_0" coords="2,144.73,656.80,133.20,7.86"><p>http://anr-gafes.univ-avignon.fr/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_1" coords="3,144.73,656.80,113.47,7.86"><p>http://www.vodkaster.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_2" coords="4,144.73,656.80,70.91,7.86"><p>http://tc.talne.eu</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_3" coords="7,144.73,656.80,113.47,7.86"><p>http://www.vodkaster.com/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,138.35,347.23,342.23,7.86;8,146.91,358.19,333.66,7.86;8,146.91,369.15,333.67,7.86;8,146.91,380.11,243.27,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,457.80,347.23,22.78,7.86;8,146.91,358.19,314.93,7.86">What works and what does not: Classifier and feature analysis for argument mining</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Aker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sliwa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Lui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Borad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ziyaei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ghobadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,146.91,369.15,329.47,7.86">Proceedings of the 4th Workshop on Argument Mining, ArgMining@EMNLP 2017</title>
		<meeting>the 4th Workshop on Argument Mining, ArgMining@EMNLP 2017</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="91" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,390.34,342.23,7.86;8,146.91,401.27,333.68,7.89;8,146.91,412.25,60.92,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,392.80,390.34,87.77,7.86;8,146.91,401.30,211.29,7.86">INEX tweet contextualization task: Evaluation, results and lesson learned</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Moriceau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mothe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tannier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,365.38,401.30,87.05,7.86">Inf. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="801" to="819" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,422.48,342.23,7.86;8,146.91,433.44,333.67,7.86;8,146.91,444.40,333.66,7.86;8,146.91,455.36,333.67,7.86;8,146.91,466.32,192.55,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,415.19,422.48,65.39,7.86;8,146.91,433.44,241.93,7.86">Overview of the CLEF 2016 cultural micro-blog contextualization workshop</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mothe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Murtagh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,412.32,433.44,68.26,7.86;8,146.91,444.40,333.66,7.86;8,146.91,455.36,156.32,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction -7th International Conference of the CLEF Association, CLEF 2016</title>
		<title level="s" coord="8,311.67,455.36,168.91,7.86;8,146.91,466.32,27.78,7.86">Proceedings. Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9822</biblScope>
			<biblScope unit="page" from="371" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,476.55,342.22,7.86;8,146.91,487.51,333.66,7.86;8,146.91,498.47,333.66,7.86;8,146.91,509.43,153.55,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,363.63,476.55,116.94,7.86;8,146.91,487.51,122.81,7.86">Building evaluation datasets for cultural microblog retrieval</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mothe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,290.32,487.51,190.26,7.86;8,146.91,498.47,244.75,7.86">Proceedings of the Eleventh International Conference on Language Resources and Evaluation, LREC 2018</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation, LREC 2018</meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,519.65,342.23,7.86;8,146.91,530.61,333.67,7.86;8,146.91,541.57,221.49,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,306.66,519.65,173.92,7.86;8,146.91,530.61,33.25,7.86">CLEF 2017 MC2 search and time line tasks overview</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,200.37,530.61,280.21,7.86;8,146.91,541.57,24.01,7.86">Working Notes of CLEF 2017 -Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">September 11-14, 2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,551.80,342.23,7.86;8,146.91,562.76,333.66,7.86;8,146.91,573.72,269.55,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,214.56,551.80,170.85,7.86">Mining and summarizing customer reviews</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,406.36,551.80,74.22,7.86;8,146.91,562.76,333.66,7.86;8,146.91,573.72,26.55,7.86;8,234.71,573.72,35.06,7.86">Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
	<note>KDD &apos;04</note>
</biblStruct>

<biblStruct coords="8,138.35,583.95,342.23,7.86;8,146.91,594.88,243.92,7.89" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,237.38,583.95,239.24,7.86">Argumentation mining: State of the art and emerging trends</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lippi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Torroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,146.91,594.91,122.45,7.86">ACM Trans. Internet Technol</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2016-03">Mar 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,605.14,342.23,7.86;8,146.91,616.10,150.02,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,240.28,605.14,240.30,7.86;8,146.91,616.10,22.95,7.86">Identifying argumentative discourse structures in persuasive essays</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,190.84,616.10,35.45,7.86">EMNLP</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="46" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,626.33,342.22,7.86;8,146.91,637.26,333.67,7.89;8,146.91,648.24,43.91,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,335.42,626.33,145.15,7.86;8,146.91,637.28,135.00,7.86">Norms of valence, arousal, and dominance for 13,915 english lemmas</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Warriner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kuperman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brysbaert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,290.84,637.28,114.85,7.86">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1191" to="1207" />
			<date type="published" when="2013-12">Dec 2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
