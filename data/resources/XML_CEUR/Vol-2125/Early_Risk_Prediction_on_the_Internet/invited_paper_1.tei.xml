<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,233.11,115.90,149.13,12.90;1,193.75,133.83,227.86,12.90;1,234.98,151.77,145.40,12.90">Overview of eRisk 2018: Early Risk Prediction on the Internet (extended lab overview)</title>
				<funder>
					<orgName type="full">i)</orgName>
				</funder>
				<funder ref="#_anrnW5V">
					<orgName type="full">Swiss National Science Foundation</orgName>
					<orgName type="abbreviated">SNSF</orgName>
				</funder>
				<funder ref="#_azAtkn7">
					<orgName type="full">Xunta de Galicia</orgName>
				</funder>
				<funder ref="#_dJhqRbN #_33w6XSA">
					<orgName type="full">European Regional Development Fund</orgName>
					<orgName type="abbreviated">ERDF</orgName>
				</funder>
				<funder ref="#_8WeucFV">
					<orgName type="full">FEDER Funds</orgName>
				</funder>
				<funder>
					<orgName type="full">Xunta de Galicia -&quot;Consellería de Cultura, Educación e Ordenación Universitaria</orgName>
				</funder>
				<funder>
					<orgName type="full">Ministerio de Economía y Competitividad&quot; of the Government of Spain</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,197.02,189.94,66.48,8.64"><forename type="first">David</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
							<email>david.losada@usc.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS)</orgName>
								<orgName type="institution">Universidade de Santiago de Compostela</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,272.95,189.94,58.24,8.64"><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
							<email>fabio.crestani@usi.ch</email>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Informatics</orgName>
								<orgName type="institution">Universitá della Svizzera italiana (USI)</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,357.51,189.94,56.36,8.64"><forename type="first">Javier</forename><surname>Parapar</surname></persName>
							<email>javierparapar@udc.es</email>
							<affiliation key="aff2">
								<orgName type="laboratory">Information Retrieval Lab</orgName>
								<orgName type="institution">University of A Coruña</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,233.11,115.90,149.13,12.90;1,193.75,133.83,227.86,12.90;1,234.98,151.77,145.40,12.90">Overview of eRisk 2018: Early Risk Prediction on the Internet (extended lab overview)</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3B0DC173E95F6701713A7C24D17655AA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper provides an overview of eRisk 2018. This was the second year that this lab was organized at CLEF. The main purpose of eRisk was to explore issues of evaluation methodology, effectiveness metrics and other processes related to early risk detection. Early detection technologies can be employed in different areas, particularly those related to health and safety. The second edition of eRisk had two tasks: a task on early risk detection of depression and a task on early risk detection of anorexia.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The main purpose of this lab is to explore issues of evaluation methodologies, performance metrics and other aspects related to building test collections and defining challenges for early risk detection. Early detection technologies are potentially useful in different areas, particularly those related to safety and health. For example, early alerts could be sent when a person starts showing signs of a mental disorder, when a sexual predator starts interacting with a child, or when a potential offender starts publishing antisocial threats on the Internet. In 2017, our main goal was to pioneer a new interdisciplinary research area that would be potentially applicable to a wide variety of profiles, such as potential paedophiles, stalkers, individuals with a latent tendency to fall into the hands of criminal organisations, people with suicidal inclinations, or people susceptible to depression.</p><p>The 2017 lab had two possible ways to participate. One of them followed a classical workshop pattern. This workshop was open to the submission of papers describing test collections or data sets suitable for early risk prediction or early risk prediction challenges, tasks and evaluation metrics. This open submission format was discontinued in 2018. eRisk 2017 also included an exploratory task on early detection of depression. This pilot task was based on the evaluation methodology and test collection presented in a CLEF 2016 paper <ref type="bibr" coords="2,218.21,119.31,10.58,8.64" target="#b0">[1]</ref>. The interaction between depression and language use is interesting for early risk detection algorithms. We shared this collection with all participating teams and the 2017 participants approached the problem with multiple technologies and models (e.g. Natural Language Processing, Machine Learning, Information Retrieval, etc.). However, the effectiveness of all participating systems was relatively low <ref type="bibr" coords="2,450.37,167.13,10.58,8.64" target="#b1">[2]</ref>. For example, the highest F1 was 64%. This suggests that the 2017 task was challenging and there was still much room from improvement.</p><p>In 2018, the lab followed a standard campaign-style format. It was composed of two different tasks: early risk detection of depression and early risk detection of anorexia. The first task is a continuation of the eRisk 2017 pilot task. The teams had access to the eRisk 2017 data as training data, and new depression and non-depression test cases were extracted and provided to the participants during the test stage. The second task followed the same format as the depression task. The organizers of the task collected data on anorexia and language use, the data were divided into a training subset and a test subset, and the task followed the same iterative evaluation schedule implemented in 2017 (see below).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task 1: Early Detection of Signs of Depression</head><p>This is an exploratory task on early detection of signs of depression. The challenge consists of sequentially processing pieces of evidence -in the form of writings posted by depressed or non-depressed users-and learn to detect early signs of depression as soon as possible. The lab focuses on Text Mining solutions and, thus, it concentrates on Social Media submissions (posts or comments in a Social Media website). Texts should be processed by the participating systems in the order they were created. In this way, systems that effectively perform this task could be applied to sequentially track user interactions in blogs, social networks, or other types of online media.</p><p>The test collection for this task has the same format as the collection described in <ref type="bibr" coords="2,134.77,458.38,10.58,8.64" target="#b0">[1]</ref>. It is a collection of submissions or writings (posts or comments) done by Social Media users. There are two classes of users, depressed and non-depressed. For each user, the collection contains his sequence of submissions (in chronological order) and this sequence was split into 10 chunks. The first chunk has the oldest 10% of the submissions, the second chunk has the second oldest 10%, and so forth.</p><p>The task was organized into two different stages:</p><p>-Training stage. Initially, the teams that participated in this task had access to some training data. In this stage, the organizers of the task released the entire history of submissions done by a set of training users. All chunks of all training users were sent to the participants. Additionally, the actual class (depressed or non-depressed) of each training user was also provided (i.e. whether or not the user explicitly mentioned that they were diagnosed with depression  <ref type="table" coords="3,196.43,194.73,3.36,8.06">1</ref>. Task1 (depression). Main statistics of the train and test collections users), the second week we gave the 2nd chunk of data (second oldest submissions of all test users), and so forth. After each release, the teams had to process the data and, before the next week, each team had to choose between: a) emitting a decision on the user (i.e. depressed or non-depressed), or b) making no decision (i.e. waiting to see more chunks). This choice had to be made for each user in the test split. If the team emitted a decision then the decision was considered as final. The systems were evaluated based on the accuracy of the decisions and the number of chunks required to take the decisions (see below). The first release of test data was done on Feb 6th, 2018 and the last (10th) release of test data was done on April 10th, 2018.</p><p>Table <ref type="table" coords="3,173.85,356.02,4.98,8.64">1</ref> reports the main statistics of the train and test collections. The two splits are unbalanced (there are more non-depression cases than depression cases). In the training collection the percentage of depressed cases was about 15% and in the test collection this percentage was about 9%. The number of users is not large, but each user has a long history of submissions (on average, the collections have several hundred submissions per user). Additionally, the mean range of dates from the first submission to the last submission is wide (more than 500 days). Such wide history permits to analyze the evolution of the language from the oldest post or comment to the most recent one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Evaluation measures</head><p>The evaluation of the tasks considered standard classification measures, such as F1, Precision and Recall (computed with respect to the positive class -depression or anorexia, respectively-) and an early risk detection measure proposed in <ref type="bibr" coords="3,389.69,512.97,10.58,8.64" target="#b0">[1]</ref>. The standard classification measures can be employed to assess the teams' estimations with respect to golden truth judgments that inform us about users that are really positive cases. We include them in our evaluation report because these metrics are well-known and easily interpretable.</p><p>However, standard classification measures are time-unaware and do not penalize late decisions. Therefore, the evaluation of the tasks also considered a newer measure of performance that rewards early alerts. More specifically, we employed ERDE, an error measure for early risk detection <ref type="bibr" coords="3,284.46,608.62,11.62,8.64" target="#b0">[1]</ref> for which the fewer writings required to make the alert, the better. For each user the evaluation proceeds as follows. Given a chunk of data, if a team's system does not emit a decision then it has access to the next chunk of data (i.e. more submissions from the same user). However, the team's system gets a penalty for late emission. ERDE, which stands for early risk detection error, takes into account the correctness of the (binary) decision and the delay taken by the system to make the decision. The delay is measured by counting the number (k) of distinct submissions (posts or comments) seen before taking the decision. For instance, imagine a user u who posted a total number of 250 posts or comments (i.e. exactly 25 submissions per chunk to simplify the example). If a team's system emitted a decision for user u after the second chunk of data then the delay k would be 50 (because the system needed to see 50 pieces of evidence in order to make its decision).</p><p>Another important factor is that data are unbalanced (many more negative cases than positive cases) and, thus, the evaluation measure needs to weight different errors in a different way. Consider a binary decision d taken by a team's system with delay k. Given golden truth judgments, the prediction d can be a true positive (TP), true negative (TN), false positive (FP) or false negative (FN). Given these four cases, the ERDE measure is defined as:</p><formula xml:id="formula_0" coords="4,145.39,301.91,321.99,46.79">ERDE o (d, k) =        c f p if d=positive AND ground truth=negative (FP) c f n if d=negative AND ground truth=positive (FN) lc o (k) • c tp if d=positive AND ground truth=positive (TP) 0 if d=negative AND ground truth=negative (TN)</formula><p>How to set c f p and c f n depends on the application domain and the implications of FP and FN decisions. We will often deal with detection tasks where the number of negative cases is several orders of magnitude larger than the number of positive cases. Hence, if we want to avoid building trivial systems that always say no, we need to have c f n &gt;&gt; c f p . In evaluating the systems, we fixed c f n to 1 and c f p was set according to the proportion of positive cases in 2017's test data (e.g. we set c f p to 0.1296).</p><p>The factor lc o (k)(∈ [0, 1]) represents a cost associated to the delay in detecting true positives. We set c tp to c f n (i.e. c tp was set to 1) because late detection can have severe consequences (as a late detection is considered as equivalent to not detecting the case at all).</p><p>The function lc o (k) is a monotonically increasing function of k:</p><formula xml:id="formula_1" coords="4,260.23,506.27,220.36,22.31">lc o (k) = 1 - 1 1 + e k-o<label>(1)</label></formula><p>The function is parameterised by o, which controls the place in the X axis where the cost grows more quickly (Figure <ref type="figure" coords="4,267.06,548.84,4.98,8.64" target="#fig_0">1</ref> plots lc 5 (k) and lc 50 (k)).</p><p>The latency cost factor was only used for the true positives because we understand that late detection is not an issue for true negatives. True negatives are non-risk cases that, of course, would not demand early intervention (i.e. these cases just need to be effectively filtered out from the positive cases). The systems must therefore focus on early detecting risk cases and detecting non-risk cases (regardless of when these nonrisk cases are detected).</p><p>All cost weights are in [0, 1] and, thus, ERDE is in the range [0, 1]. Systems had to take one decision for each subject and the overall error is the mean of the p ERDE values. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Results</head><p>Each team could submit up to 5 runs or variants. We received 45 contributions from 11 different institutions. This is a substantial increase with respect to erisk 2017, which had 8 institutions and 30 contributed runs. Table <ref type="table" coords="5,316.24,415.40,4.98,8.64" target="#tab_2">3</ref> reports the institutions that contributed to eRisk 2018 and the labels associated to their runs. First, we briefly describe the main characteristics of the early detection systems implemented by these participants:</p><p>-FHDO, Germany. This is a joint effort performed by the several institutions in Germany (and led by the University of Applied Sciences and Arts Dortmund). This team submitted results for four machine learning models, together with an ensemble model that combined different base predictions. The models employ user-level linguistic metadata, bag of words, neural word embeddings, and convolutional neural networks.</p><p>-IRIT, France. This is a team composed of researchers from IRIT and LIMSI. Their experiments focused on investigating two types of textual representations: linguistic features vs vectorization. The team combined the representations in different ways and trained a number of machine learning models.</p><p>-LIRMM, France. This team, composed of researchers from different institutions in Montpellier, paid special attention to the temporal dimension. Their models try to capture temporal mood variation by sequentially analysing the available user submissions. The resulting mdoels have two learning stages and employ standard text vectorization methods.</p><p>-PEIMEX, Mexico &amp; USA. This team submitted several runs as a result of a joint collaboration between multiple Mexican institutions and Houston University. Their approach makes a sentence-level analysis to detect sentences where users refer to them-selves. The main intuition is that those sentences contain terms that better expose their interests and habits and, thus, they might reveal personality and psychological states. This extraction of sentences was followed by a novel feature selection process and a subsequent term weighting method.</p><p>-UDC, Spain. This team performed a standard machine learning treatment of the challenge. They formalized the task as a classification task and experimented with different features (text-based, semantic-based and writing-based). They implemented two independent models. The first was oriented to predict depression cases and the second was oriented to detect non-depression cases. To meet these aims, these researchers designed two variants, named as Duplex Model Chunk Dependent and Duplex Model Writing Dependent.</p><p>-UNSL, Argentina &amp; Mexico. This is a team composed of researchers from a couple of Argentinian institutions (UNSL and CONICET) and INAOE, from Mexico. This team implemented a variant based on a model of flexible temporal variation of terms and another variant based on sequential incremental classification. The first model follows a semantic representation of documents that explicitly considers that the information available at each chunk is partial. The second model is a novel text classification approach that incrementally estimates the association of each individual to each class based on the accumulated evidence.</p><p>-UPF, Spain. This team, from Univ. Pompeu Fabra in Barcelona, implemented several machine learning models that follow a dynamic and incremental representation of the user's submissions. The main focus of the experimentation was on testing different types of features, including linguistic features, domain-specific vocabularies and psychology-based features.</p><p>-UQAM, Canada. This team implemented a topic extraction approach and experimented with Latent Dirichlet Allocation and Neural Networks. The submitted runs represented the texts using unigrams, bigrams and trigrams and the team worked with 30 latent topics. The final estimations were supplied by a multilayer perceptron, together with a decision-based algorithm that classifies the users in a time-aware manner.</p><p>-TBS, Taiwan. This team is composed of researchers from two different institutions in Taiwan. Their models combine tf/idf evidence with convolutional neural networks (CNNs). The CNNs work with chunk-level evidence and are responsible of emitting the depression decisions. These decisions are based on classifying individual submissions made by each user.</p><p>-TUA1, Japan. The University of Tokushima in Japan sent results associated to a support vector machine classifier that works with tf/idf representations, a deep neural network and a simple keyword-based method. Now, let us analyze the behaviour of the systems in terms of how fast they emitted decisions. Figure <ref type="figure" coords="6,206.52,593.78,4.98,8.64">2</ref> shows a boxplot graph of the number of chunks required to make the decisions. The test collection has 820 users and, thus, each boxplot represents the statistics of 820 cases. Some systems (RKMVERIB, RKMVERIC, RKMVERID, RKMVERIE, TBSA, UPFC, UPFD) took all decisions after the last chunk (i.e. did not emit any earlier decision). These variants were extremely conservative: they waited to see the whole history of submissions for all users and, next, they emitted their decisions. Remember that all teams were forced to emit a decision for each user at the last chunk.</p><p>Many other runs also took most of the decisions after the last chunk. For example, FHDO-BCSGA assigned a decision at the last chunk in 725 out of 820 users. Only a few runs were really quick at emitting decisions. Notably, most UDC's runs and LIIRA had a median of 1 chunk needed to emit decisions.</p><p>Figure <ref type="figure" coords="7,179.29,200.26,4.98,8.64">3</ref> shows a boxplot of the number of submissions required by each run in order to emit decisions. Most of the time the teams waited to see hundreds of writings for each user. Only a few submissions (UDCA, UDCB, UDCD, UDCE, UNSLD, some LIIRx runs) had a median number of writings analyzed below 100. It appears that the teams have concentrated on accuracy (rather than delay) and, thus, they did not care much about penalties for late decisions. A similar behaviour was found in the runs submitted in 2017.</p><p>The number of user submissions has a high variance. Some users have only 10 submissions, while other users have more than a thousand submissions. It would be interesting to study the interaction between the number of user submissions and the effectiveness of the estimations done by the participating systems. This study could help to shed light on issues such as the usefulness of a large (vs short) history of submissions and the effect of off-topic submissions (e.g. submissions totally unrelated to depression).</p><p>Another intriguing issue relates to potential false positives. For instance, a doctor who is active on the depression community because he gives support to people suffering from depression, or a wife whose husband has been diagnosed with depression. These people would often write about depression and possibly use a style that might imply they are depressed, but obviously they are not. The collection contains this type of non-depressed users and these cases are challenging for automatic classification. Arguably, these non-depressed users are much different from other non-depressed users who do not engage in any depression-related conversation. In any case, this issue requires further investigation. For example, it will be interesting to do error analysis with the systems' decisions and check the characteristics of the false positives.</p><p>Figure <ref type="figure" coords="7,179.62,501.02,4.98,8.64">4</ref> helps to analyze another aspect of the decisions emitted by the teams. For each user class, it plots the percentage of correct decisions against the number of users. For example, the last two bars of the upper plot show that about 5 users were correctly identified by more than 90% of the runs. Similarly, the rightmost bar of the lower plot means that a few non-depressed users were correctly classified by all runs (100% correct decisions). The graphs show that the teams tend to be more effective with non-depressed users. This is as expected because most non-depressed cases do not engage in depression-related conversations and, therefore, they are easier to distinguish from depressed users. The distribution of correct decisions for non-depressed users has many cases where more than 80% of the systems are correct. The distribution of correct decisions for depressed users is flatter, and many depressed users are only identified by a low percentage of the runs. This suggests that the teams implemented a wide range of strategies that detect different portions of the depression class. Furthermore, there are not depressed users that are correctly identified by all systems. However, an interesting point is that no depressed user has 0% of correct decisions. This means that every depressed user was classified as such by at least one run.</p><p>Let us now analyze the effectiveness results (see Table <ref type="table" coords="8,372.52,263.22,3.60,8.64">4</ref>). The first conclusion we can draw is that the task is as difficult as in 2017. In terms of F1, performance is again low. The highest F1 is 0.64 and the highest precision is 0.67. This might be related to the effect of false positives discussed above. The lowest ERDE 50 was achieved by the FHDO-BCSG team, which also submitted the runs that performed the best in terms of F 1. The run with the lowest ERDE 5 was submitted by the UNSLA team and the run with the highest precision was submitted by RKMVERI. The UDC team submitted a high recall run (0.95) but its precision was extremely low.</p><p>In terms of ERDE 5 , the best performing run is UNSLA, which has poor F1, Precision and Recall. This run was not good at identifying many depressed users but, still, it has low ERDE 5 . This suggests that the true positives were emitted by this run at earlier chunks (quick emissions). ERDE 5 is extremely stringent with delays (after 5 writings, penalties grow quickly, see <ref type="bibr" coords="8,245.82,406.91,23.22,8.64">Fig 1)</ref>. This promotes runs that emit few but quick depression decisions. ERDE 50 , instead, gives smoother penalties to delays. This makes that the run with the lowest ERDE 50 , FHDO-BCSGB, has much higher F1 and Precision. Such difference between ERDE 5 and ERDE 50 is highly relevant in practice. For example, a mental health agency seeking an automatic tool for screening depression could set the penalty weights depending on the consequences of late detection of signs of depression.</p><p>3 Task 2: Early Detection of Signs of Anorexia Task 2 was an exploratory task on early detection of signs of anorexia. The format of the task, data extraction methods and evaluation methodology (training stage followed by a test stage with on sequential releases of user data) was the same used for Task 1. This task was introduced in 2018 and, therefore, all users (training+test) were collected just for this new task.</p><p>Table <ref type="table" coords="8,174.92,596.66,4.98,8.64" target="#tab_1">2</ref> reports the main statistics of the train and test collections of Task 2. The collection shares the main characteristics of Task 1's collections: the two splits are unbalanced (of course, there are more non-anorexia cases than anorexia cases). Contrary to the depression case, the number of users is not large (and, again, each user has a long history of submissions). The mean range of dates from the first submission to the last submission is also wide (more than 500 days).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Results</head><p>Each team could submit up to 5 runs or variants. We received 35 contributions from 9 different institutions. All institutions participating in Task 2 had also sent results for Task 1. Table <ref type="table" coords="9,189.07,164.57,4.98,8.64" target="#tab_3">5</ref> reports the institutions that contributed to this second task of eRisk 2018 and the labels associated to their runs.</p><p>Most of the teams implemented the same type of models and use them for both tasks (with minor modifications, such as the inclusion of anorexia-related lexica). We refer to section 2.2, where the reader can see a brief description of each group's variants. The interested reader is also referred to the working note papers to see a full description of the experiments performed by each team.</p><p>The behaviour of the systems in terms of how fast they emitted decisions is shown in Figure <ref type="figure" coords="9,163.33,260.78,3.74,8.64">5</ref>, which includes boxplot graphs of the number of chunks required to make the decisions. The test collection of Task 2 has 320 users and, thus, each boxplot represents the statistics of 320 cases. The trends are similar to those found in Task 1. Mosf of the systems emitted decisions at a late stage with only a few exceptions (notably, LIIRA and LIIRB). LIIRA and LIIRB had a median number of chunks analyzed of 3 and 6, respectively. The rest of the systems had a median number of chunks analized equal to or near 10.</p><p>Figure <ref type="figure" coords="9,179.29,344.75,4.98,8.64">6</ref> shows a boxplot of the number of submissions required by each run in order to emit decisions. Again, most of the variants analyzed hundred of submissions before emitting decisions. Only the two LIIR runs discussed above and LIRMMD opted for emitting decisions after a fewer number of user submissions. In Task 2, again, most of the teams have ignored the penalties for late decisions and they have mostly focused on classification accuracy.</p><p>Figure <ref type="figure" coords="9,178.38,416.77,4.98,8.64">7</ref> plots the percentage of correct decisions against the number of users. The plot shows again a clear distinction between the positive class (anorexia) and the negative class (non-anorexia). Most of the non-anorexia users are correctly identified by most of the systems (nearly all non-anorexia users fall in the range 80%-100%, meaning that at least 80% of the systems labeled them as non-anorexic). In contrast, the distribution of anorexia users is flatter and, in many cases, they are only identified by less than half of the systems. An interesting result is that all anorexia users were identified by at least 10% of the systems.</p><p>Table <ref type="table" coords="9,174.07,512.69,4.98,8.64">6</ref> reports the effectiveness of the systems. In general, performance is remarkably higher than that achieved by the systems for Task 1. There could be a number of reasons for such an outcome. First, the proportion of potential false positives (e.g. people engaging in anorexia-related conversations) might be lower in Task 2's test collection. This hypothesis would need to be investigated through a careful analysis of the data. Second, the submissions of anorexia users might be extremely focused on eating habits, losing weights, etc. If they do not often engage in general (anorexia unrelated) conversations then it would be easier for the systems to distinguish them from other users. In any case, these are only speculations and this issue requires further research.</p><p>The highest F1 is 0.85 and the highest precision is 0.91. The lowest ERDE 50 was achieved by FHDO-BCSGD, which also has the highest recall (0.88). The run with the lowest ERDE 5 was submitted by the UNSL team (UNSLB), which shows again that this team paid more attention to emitting early decisions (at least for the true positives).</p><p>Overall, the results obtained by the teams are promising. The high performance achieved suggest that it is feasible to design automatic text analysis tools that make early alerts of signs of eating disorders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>This paper provided an overview of eRisk 2018. This was the second year that this lab was organized at CLEF and the lab's activities concentrated on two tasks (early detection of signs of depression and early detection of signs of anorexia). Overall, the tasks received 80 variants or runs and the teams focused on tuning different classification solutions. The tradeoff between early detection and accuracy was ignored by most participants.</p><p>The effectiveness of the solutions implemented to early detect signs of depression is similar to that achieved for eRisk 2017. This performance is still modest, suggesting that it is challenging to tell depressed and non-depressed users apart. In contrast, the effectiveness of the systems that detect signs of anorexia was much higher. This promising result encourages us to further explore the creation of benchmarks for text-based screening of eating disorders. In the future, we also want to instigate more research on the tradeoff between accuracy and delay.    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,216.47,334.27,182.42,8.12"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Latency Cost Functions: lc5(k) and lc50(k)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="12,150.45,621.46,312.22,8.12"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. Number of chunks required by each contributing run in order to emit a decision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="17,150.45,661.61,312.22,8.12"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. Number of chunks required by each contributing run in order to emit a decision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,158.44,118.07,298.48,84.79"><head>Table 2 .</head><label>2</label><figDesc>Task2 (anorexia). Main statistics of the train and test collections</figDesc><table coords="8,327.19,118.07,128.91,18.53"><row><cell>Train</cell><cell>Test</cell></row><row><cell cols="2">Anorexia Control Anorexia Control</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="11,146.16,127.23,325.28,516.55"><head>Table 3 .</head><label>3</label><figDesc>Task 1 (depression). Participating institutions and submitted results</figDesc><table coords="11,414.16,127.23,54.06,7.77"><row><cell>Submitted files</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="14,134.77,484.45,345.83,18.73"><head>Table 5 .</head><label>5</label><figDesc>Number of depressed and non-depressed subjects that had a given percentage of correct decisions. Task 2 (anorexia). Participating institutions and submitted results</figDesc><table coords="15,213.58,129.13,188.19,512.47"><row><cell></cell><cell cols="3">ERDE5 ERDE50 F1 P R</cell></row><row><cell cols="2">FHDO-BCSGA 9.21%</cell><cell cols="2">6.68% 0.61 0.56 0.67</cell></row><row><cell cols="2">FHDO-BCSGB 9.50%</cell><cell cols="2">6.44% 0.64 0.64 0.65</cell></row><row><cell cols="2">FHDO-BCSGC 9.58%</cell><cell cols="2">6.96% 0.51 0.42 0.66</cell></row><row><cell cols="2">FHDO-BCSGD 9.46%</cell><cell cols="2">7.08% 0.54 0.64 0.47</cell></row><row><cell cols="2">FHDO-BCSGE 9.52%</cell><cell cols="2">6.49% 0.53 0.42 0.72</cell></row><row><cell>LIIRA</cell><cell>9.46%</cell><cell cols="2">7.56% 0.50 0.61 0.42</cell></row><row><cell>LIIRB</cell><cell cols="3">10.03% 7.09% 0.48 0.38 0.67</cell></row><row><cell>LIIRC</cell><cell cols="3">10.51% 7.71% 0.42 0.31 0.66</cell></row><row><cell>LIIRD</cell><cell cols="3">10.52% 7.84% 0.42 0.31 0.66</cell></row><row><cell>LIIRE</cell><cell>9.78%</cell><cell cols="2">7.91% 0.55 0.66 0.47</cell></row><row><cell>LIRMMA</cell><cell cols="3">10.66% 9.16% 0.49 0.38 0.68</cell></row><row><cell>LIRMMB</cell><cell cols="3">11.81% 9.20% 0.36 0.24 0.73</cell></row><row><cell>LIRMMC</cell><cell cols="3">11.78% 9.02% 0.35 0.23 0.71</cell></row><row><cell>LIRMMD</cell><cell cols="3">11.32% 8.08% 0.32 0.22 0.57</cell></row><row><cell>LIRMME</cell><cell cols="3">10.71% 8.38% 0.37 0.29 0.52</cell></row><row><cell>PEIMEXA</cell><cell cols="3">10.30% 7.22% 0.38 0.28 0.62</cell></row><row><cell>PEIMEXB</cell><cell cols="3">10.30% 7.61% 0.45 0.37 0.57</cell></row><row><cell>PEIMEXC</cell><cell cols="3">10.07% 7.35% 0.37 0.29 0.51</cell></row><row><cell>PEIMEXD</cell><cell cols="3">10.11% 7.70% 0.39 0.35 0.44</cell></row><row><cell>PEIMEXE</cell><cell cols="3">10.77% 7.32% 0.35 0.25 0.57</cell></row><row><cell>RKMVERIA</cell><cell cols="3">10.14% 8.68% 0.52 0.49 0.54</cell></row><row><cell>RKMVERIB</cell><cell cols="3">10.66% 9.07% 0.47 0.37 0.65</cell></row><row><cell>RKMVERIC</cell><cell>9.81%</cell><cell cols="2">9.08% 0.48 0.67 0.38</cell></row><row><cell>RKMVERID</cell><cell>9.97%</cell><cell cols="2">8.63% 0.58 0.60 0.56</cell></row><row><cell>RKMVERIE</cell><cell>9.89%</cell><cell cols="2">9.28% 0.21 0.35 0.15</cell></row><row><cell>UDCA</cell><cell cols="3">10.93% 8.27% 0.26 0.17 0.53</cell></row><row><cell>UDCB</cell><cell cols="3">15.79% 11.95% 0.18 0.10 0.95</cell></row><row><cell>UDCC</cell><cell>9.47%</cell><cell cols="2">8.65% 0.18 0.13 0.29</cell></row><row><cell>UDCD</cell><cell cols="3">12.38% 8.54% 0.18 0.11 0.61</cell></row><row><cell>UDCE</cell><cell>9.51%</cell><cell cols="2">8.70% 0.18 0.13 0.29</cell></row><row><cell>UNSLA</cell><cell>8.78%</cell><cell cols="2">7.39% 0.38 0.48 0.32</cell></row><row><cell>UNSLB</cell><cell>8.94%</cell><cell cols="2">7.24% 0.40 0.35 0.46</cell></row><row><cell>UNSLC</cell><cell>8.82%</cell><cell cols="2">6.95% 0.43 0.38 0.49</cell></row><row><cell>UNSLD</cell><cell cols="3">10.68% 7.84% 0.45 0.31 0.85</cell></row><row><cell>UNSLE</cell><cell>9.86%</cell><cell cols="2">7.60% 0.60 0.53 0.70</cell></row><row><cell>UPFA</cell><cell cols="3">10.01% 8.28% 0.55 0.56 0.54</cell></row><row><cell>UPFB</cell><cell cols="3">10.71% 8.60% 0.48 0.37 0.70</cell></row><row><cell>UPFC</cell><cell cols="3">10.26% 9.16% 0.53 0.48 0.61</cell></row><row><cell>UPFD</cell><cell cols="3">10.16% 9.79% 0.42 0.42 0.42</cell></row><row><cell>UQAMA</cell><cell cols="3">10.04% 7.85% 0.42 0.32 0.62</cell></row><row><cell>TBSA</cell><cell cols="3">10.81% 9.22% 0.37 0.29 0.52</cell></row><row><cell>TUA1A</cell><cell cols="3">10.19% 9.70% 0.29 0.31 0.27</cell></row><row><cell>TUA1B</cell><cell cols="3">10.40% 9.54% 0.27 0.25 0.28</cell></row><row><cell>TUA1C</cell><cell cols="3">10.86% 9.51% 0.47 0.35 0.71</cell></row><row><cell>TUA1D</cell><cell>-</cell><cell>-</cell><cell>0.00 0.00 0.00</cell></row><row><cell cols="4">Table 4. Task 1 (depression). Results</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank the support obtained from the <rs type="funder">Swiss National Science Foundation (SNSF)</rs> under the project "<rs type="projectName">Early risk prediction on the Internet: an evaluation corpus</rs>", 2015.</p><p>We also thank the financial support obtained from the <rs type="funder">i)</rs> "<rs type="funder">Ministerio de Economía y Competitividad" of the Government of Spain</rs> and <rs type="funder">FEDER Funds</rs> under the research project <rs type="grantNumber">TIN2015-64282-R</rs>, ii) <rs type="funder">Xunta de Galicia</rs> (project <rs type="grantNumber">GPC 2016/035</rs>), and iii) <rs type="funder">Xunta de Galicia -"Consellería de Cultura, Educación e Ordenación Universitaria</rs>" and the <rs type="funder">European Regional Development Fund (ERDF)</rs> through the following 2016-2019 accreditations: <rs type="grantNumber">ED431G/01</rs> ("<rs type="projectName">Centro singular de investigacion de Galicia</rs>") and <rs type="grantNumber">ED431G/08</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_anrnW5V">
					<orgName type="project" subtype="full">Early risk prediction on the Internet: an evaluation corpus</orgName>
				</org>
				<org type="funding" xml:id="_8WeucFV">
					<idno type="grant-number">TIN2015-64282-R</idno>
				</org>
				<org type="funding" xml:id="_azAtkn7">
					<idno type="grant-number">GPC 2016/035</idno>
				</org>
				<org type="funded-project" xml:id="_dJhqRbN">
					<idno type="grant-number">ED431G/01</idno>
					<orgName type="project" subtype="full">Centro singular de investigacion de Galicia</orgName>
				</org>
				<org type="funding" xml:id="_33w6XSA">
					<idno type="grant-number">ED431G/08</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="10,138.13,537.40,342.46,7.77;10,146.47,548.20,334.12,7.93;10,146.47,559.31,55.00,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,287.80,537.40,192.79,7.77;10,146.47,548.35,34.17,7.77">A test collection for research on depression and language use</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,196.75,548.20,254.21,7.72">Proceedings Conference and Labs of the Evaluation Forum CLEF 2016</title>
		<meeting>Conference and Labs of the Evaluation Forum CLEF 2016<address><addrLine>Evora, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.13,570.27,342.46,7.77;10,146.47,581.08,334.12,7.93;10,146.47,592.04,207.46,7.93" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,340.49,570.27,140.10,7.77;10,146.47,581.23,186.59,7.77">eRISK 2017: CLEF Lab on Early Risk Prediction on the Internet: Experimental foundations</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Javier</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,349.11,581.08,131.48,7.72;10,146.47,592.04,121.74,7.72">Proceedings Conference and Labs of the Evaluation Forum CLEF 2017</title>
		<meeting>Conference and Labs of the Evaluation Forum CLEF 2017<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
