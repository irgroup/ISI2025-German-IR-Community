<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,162.02,115.96,291.31,12.62;1,147.19,133.89,320.99,12.62;1,199.07,151.82,217.21,12.62">Early Detection of Signs of Anorexia and Depression Over Social Media using Effective Machine Learning Frameworks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,176.55,190.61,55.68,8.74"><forename type="first">Sayanta</forename><surname>Paul</surname></persName>
							<email>sayanta95@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Ramakrishna Mission Vivekananda Educational and Research Institute Belur Math</orgName>
								<address>
									<settlement>Howrah</settlement>
									<region>West Bengal</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,240.06,190.61,102.84,8.74"><forename type="first">Jandhyala</forename><forename type="middle">Sree</forename><surname>Kalyani</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ramakrishna Mission Vivekananda Educational and Research Institute Belur Math</orgName>
								<address>
									<settlement>Howrah</settlement>
									<region>West Bengal</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,370.17,190.61,59.98,8.74"><forename type="first">Tanmay</forename><surname>Basu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ramakrishna Mission Vivekananda Educational and Research Institute Belur Math</orgName>
								<address>
									<settlement>Howrah</settlement>
									<region>West Bengal</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,162.02,115.96,291.31,12.62;1,147.19,133.89,320.99,12.62;1,199.07,151.82,217.21,12.62">Early Detection of Signs of Anorexia and Depression Over Social Media using Effective Machine Learning Frameworks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A06CFE7EE708457751E11CBD6C6C26E3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>identification of depression</term>
					<term>anorexia detection</term>
					<term>text classification</term>
					<term>information extraction</term>
					<term>machine learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The CLEF eRisk 2018 challenge focuses on early detection of signs of depression or anorexia using posts or comments over social media. The eRisk lab has organized two tasks this year and released two different corpora for the individual tasks. The corpora are developed using the posts and comments over Reddit, a popular social media. The machine learning group at Ramakrishna Mission Vivekananda Educational and Research Institute (RKMVERI), India has participated in this challenge and individually submitted five results to accomplish the objectives of these two tasks. The paper presents different machine learning techniques and analyze their performance for early risk prediction of anorexia or depression. The techniques involve various classifiers and feature engineering schemes. The simple bag of words model has been used to perform ada boost, random forest, logistic regression and support vector machine classifiers to identify documents related to anorexia or depression in the individual corpora. We have also extracted the terms related to anorexia or depression using metamap, a tool to extract biomedical concepts. Theerefore, the classifiers have been implemented using bag of words features and metamap features individually and subsequently combining these features. The performance of the recurrent neural network is also reported using GloVe and Fasttext word embeddings. Glove and Fasttext are pre-trained word vectors developed using specific corpora e.g., Wikipedia. The experimental analysis on the training set shows that the ada boost classifier using bag of words model outperforms the other methods for task1 and it achieves best score on the test set in terms of precision over all the runs in the challenge. Support vector machine classifier using bag of words model outperforms the other methods in terms of fmeasure for task2. The results on the test set submitted to the challenge suggest that these framework achieve reasonably good performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Early risk prediction is a new research area potentially applicable to a wide variety of situations such as identifying people with mental illness over social media. Online social platforms allow people to share and express their thoughts and feelings freely and publicly with other people <ref type="bibr" coords="2,331.95,181.26,9.96,8.74" target="#b0">[1]</ref>. The information available over social media is a rich source for sentiment analysis or inferring mental health issues <ref type="bibr" coords="2,163.20,205.17,9.96,8.74" target="#b1">[2]</ref>. The CLEF eRisk 2018 challenge focuses on early prediction of risks related to mental disorder using the social media. The main goal of eRisk 2018 is to instigate discussion on the creation of reusable benchmarks for evaluating early risk detection algorithms by exploring issues of evaluation methodology, effectiveness metrics and other processes related to the creation of test collections for early detection of depression <ref type="bibr" coords="2,305.05,264.94,9.96,8.74" target="#b2">[3]</ref>. It has organized two tasks this year and released two different corpora for the individual tasks and these corpora are developed using the posts and comments over Reddit, a popular social media <ref type="bibr" coords="2,467.31,288.85,9.96,8.74" target="#b2">[3]</ref>. The first task is early risk prediction of depression using the posts and comments on Reddit. The other task is a pilot task and the aim of the task is to identify the signs of anorexia using the given corpus of comments and posts over Reddit.</p><p>Depression is a common illness that negatively affects feelings, thoughts and behaviors and can harm regular activities like sleeping. It is a leading cause of disability and many other diseases <ref type="bibr" coords="2,290.85,372.54,9.96,8.74" target="#b0">[1]</ref>. According to WHO (World Health Organization) <ref type="foot" coords="2,183.47,382.92,3.97,6.12" target="#foot_0">1</ref> statistics, more than 300 million people over the world are affected in depression and in each country at least 10% are provided treatment. Poor recognition and treatment of depression may aggravate heart failure symptoms, precipitate functional decline, disrupt social and occupational functioning, and lead to an increased risk of mortality <ref type="bibr" coords="2,302.69,432.32,9.96,8.74" target="#b3">[4]</ref>. Early detection of depression is thus necessary. Unfortunately the rates of detecting and treating depression among those with medical illness are quite low <ref type="bibr" coords="2,315.16,456.23,9.96,8.74" target="#b4">[5]</ref>. To be diagnosed with depression, there must be proper resources to detect depression. Many research works have been done in the last few years to examine the potential of social media as a tool for early detection of depression or mental illness <ref type="bibr" coords="2,373.98,492.09,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="2,386.15,492.09,7.75,8.74" target="#b5">6,</ref><ref type="bibr" coords="2,395.56,492.09,7.01,8.74" target="#b6">7]</ref>. The first task of this challenge is mainly concerned about evaluating the performance of different machine learning frameworks for potential information extraction from the given corpus of Reddit posts regarding the symptoms of depression <ref type="bibr" coords="2,404.13,527.96,9.96,8.74" target="#b2">[3]</ref>. A set of posts over Reditt of a particular person is considered as a single document. The corpus is divided into training and test set. The training set is further divided into two categories i.e., depression and control group i.e., non-depression. Therefore 10 chunks of the test set were released over ten weeks with each chunk per week. Each test chunk contains the posts of a particular person. The task is to identify whether the posts of a particular person in a chunk belong to depression category.</p><p>Anorexia is a serious psychiatric disorder distinguished by a refusal to maintain a minimally normal body weight, intense fear of weight gain, and disturbances in the perception of body shape and weight <ref type="bibr" coords="3,335.50,118.99,9.96,8.74" target="#b7">[8]</ref>. Anorexia has severe physical side effects and may be associated with disturbances in multiple organ systems <ref type="bibr" coords="3,134.77,142.90,9.96,8.74" target="#b7">[8]</ref>. According to National Eating Disorder Association, USA, 70 million people of all ages suffer from anorexia<ref type="foot" coords="3,273.01,153.28,3.97,6.12" target="#foot_1">2</ref> . A survey of WHO considers severe anorexia as one of the most burdensome diseases in the world <ref type="bibr" coords="3,378.35,166.81,9.96,8.74" target="#b8">[9]</ref>. Moreover, anorexia can adversely affect chronic health conditions, such as cardiovascular disease, cancer, diabetes and obesity. An individual suffering from anorexia may reveal one or several signs such as rapidly losing weight or being significantly thin, depressed or lethargic and so on <ref type="bibr" coords="3,265.45,214.64,9.96,8.74" target="#b7">[8]</ref>. The motivation behind the second task is that if anorexic symptoms are properly identified on time, then, professionals could intervene before anorexia progresses. The objective of the second task is to develop effective machine learning frameworks to detect the signs of anorexia using the given corpus. The corpus is divided into training and test set. The training set is divided into two categories -anorexia, and non-anorexia i.e., control group <ref type="bibr" coords="3,134.77,286.37,9.96,8.74" target="#b2">[3]</ref>. The task consists of identifying whether the posts of a particular person in the test set belong to the anorexia category.</p><p>In this paper, different machine learning frameworks have been proposed to accomplish the given tasks. The aim is to train a machine learning classifier using the training set to identify anorexia or depression of the individual documents of the test sets of these tasks. The performance of a text classification technique is highly dependent on the potential features of a corpus. Therefore the performance of different classifiers have been tested using both text features and biomedical features extracted from the given corpus. In general, each unique term of a corpus is considered as a feature and therefore the frequency of the individual terms are considered to form the document vectors <ref type="bibr" coords="3,439.27,417.87,14.61,8.74" target="#b9">[10]</ref>. This is known as bag of words (BOW) model. However, the term document matrix of a corpus becomes sparse and high dimensional following the BOW model. The same may deviate the performance of the classifiers. Hence we have used MetaMap<ref type="foot" coords="3,176.83,464.12,3.97,6.12" target="#foot_2">3</ref> , a tool to extract UMLS concepts in free text <ref type="bibr" coords="3,384.64,465.69,14.60,8.74" target="#b10">[11]</ref>. UMLS stands for Unified Medical Language System and it can identify semantic types of a term in free text that belong to different pre-defined biomedical categories <ref type="bibr" coords="3,438.75,489.60,14.61,8.74" target="#b11">[12]</ref>. Here we have considered only those terms that belong to the semantic categories related to depression or anorexia depending upon the tasks. We have implemented Metamap for individual corpora of the given tasks and extracted the UMLS features. Subsequently, ada boost <ref type="bibr" coords="3,272.74,537.42,14.61,8.74" target="#b12">[13]</ref>, logistic regression <ref type="bibr" coords="3,375.48,537.42,14.61,8.74" target="#b13">[14]</ref>, random forest <ref type="bibr" coords="3,462.33,537.42,14.61,8.74" target="#b14">[15]</ref>, support vector machine <ref type="bibr" coords="3,240.33,549.38,15.50,8.74" target="#b15">[16]</ref> classifiers have been implemented using only BOW features, only UMLS features and combining BOW and UMLS features to categorize the documents of the test set of individual tasks. Moreover, for the first task recurrent neural network is implemented using fasttext, a pretrained word vectors developed over crawling the web <ref type="bibr" coords="3,311.87,597.20,15.50,8.74" target="#b16">[17,</ref><ref type="bibr" coords="3,329.03,597.20,11.62,8.74" target="#b17">18]</ref>. For the second task, the recurrent neural network is implemented using GloVe <ref type="bibr" coords="3,347.90,609.16,14.61,8.74" target="#b18">[19]</ref>, a pretrained word vectors developed using a Wikipedia and a Twitter corpus.</p><p>The empirical results for the first task demonstrate that the ada boost, random forest and support vector machine classifiers using BOW features outperform the other frameworks using UMLS features and combining BOW and UMLS features. Furthermore, ada boost classifier using BOW features outperforms the other methods and it achieves best score on the test set in terms of precision over all the submissions in the eRisk 2018 challenge. For the second task, the experimental results show that the support vector machine classifier using BOW features outperforms the other frameworks using both UMLS features and combining BOW and UMLS features. The results on the test set submitted to the challenge suggest that these frameworks for task2 achieve reasonably good performance. However, there are some submissions for this pilot task, which beat the performance of this framework.</p><p>The paper is organized as follows. The proposed machine learning frameworks are explained in section 2. Section 3 describes the experimental evaluation. The conclusion is presented in section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed Methodologies</head><p>Various machine learning techniques have been proposed here to identify the documents related to anorexia from the given corpus, which is released in XML format. Each XML document contains the posts or comments of a Reddit user over a period of time with the corresponding dates and titles. We have extracted the posts or comments from the XML documents and ignored the other entries. Therefore the corpus used for experiments in this article contain only the free texts related to different posts over Reddit for individual users. Different types of features are considered to build the proposed frameworks to identify anorexia or depression of the individual documents using state of the art classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Feature Engineering Techniques</head><p>Different feature engineering techniques exist in the literature of text mining. We have considered both raw text features and semantic features in the proposed methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Bag Of Words (BOW) Features</head><p>The text documents are generally represented by the bag of words (BOW) model <ref type="bibr" coords="4,134.77,596.24,30.01,8.74">[20][10]</ref>. In this model, each document in a corpus is generally represented by a vector, whose length is equal to the number of unique terms, also known as vocabulary <ref type="bibr" coords="4,185.71,620.15,14.61,8.74" target="#b20">[21]</ref>.</p><p>Let us denote the number of documents of the corpus and the number of terms of the vocabulary by N and n respectively. The number of times the i th term t i occurs in the j th document is denoted by tf ij , i = 1, 2, ..., n; j = 1, 2, ..., N . Document frequency df i is the number of documents in which a particular term appears. Inverse document frequency determines how frequently a term occurs in a corpus and it is defined as idf i = log( N dfi ). The weight of the i th term in the j th document, denoted by w ij , is determined by combining the term frequency with the inverse document frequency as follows:</p><formula xml:id="formula_0" coords="5,151.31,185.26,306.07,23.22">w ij = tf ij × idf i = tf ij × log( N df i ), ∀ i = 1, 2, ..., n and ∀ j = 1, 2, ..., N</formula><p>This weighting scheme is known as tf-idf weighting scheme. The documents can be efficiently represented using the vector space model in most of the text mining algorithms <ref type="bibr" coords="5,185.10,239.02,14.61,8.74" target="#b21">[22]</ref>. In this model each document d j is considered to be a vector d j , where the i th component of the vector is w ij , i.e., d j = (w 1j , w 2j , ..., w nj ).</p><p>The document vectors are often sparse as most of the terms do not occur in a particular document and the vectors are also high dimensional. However, this tf-idf weighting scheme is used to represent document vectors throughout this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">UMLS Features</head><p>We have also considered the UMLS concepts extracted from the text as features.</p><p>The UMLS stands for Unified Medical Language System and it is a comprehensive list of biomedical terms for developing automated systems capable of understanding the specialized vocabulary used in biomedicine and health care <ref type="bibr" coords="5,462.32,376.94,14.61,8.74" target="#b22">[23]</ref>.</p><p>In UMLS there are 133<ref type="foot" coords="5,235.99,387.32,3.97,6.12" target="#foot_3">4</ref> semantic categories related to biomedicine and health.</p><p>The semantic category of a term can be identified using MetaMap<ref type="foot" coords="5,430.57,399.28,3.97,6.12" target="#foot_4">5</ref> , a tool to recognize UMLS concepts in free-text <ref type="bibr" coords="5,304.01,412.81,14.61,8.74" target="#b23">[24]</ref>. MetaMap first breaks the text into phrases and then for each phrase it returns different semantic categories of a term and ranked these categories according to a confidence score. It generates a Concept Unique Identifier (CUI) for each term belong to a particular semantic category <ref type="bibr" coords="5,190.03,460.63,14.61,8.74" target="#b10">[11]</ref>. These CUIs are considered as features and they are called as UMLS features in this article.</p><p>For the first task we have retained only those terms related to some manually selected semantic categories related to depression, namely, mental health and behavioral dysfunctions, abnormalities, diagnostic procedures, signs and symptoms, and findings. For the second task, the terms belonging to the UMLS concepts, namely, Protein, Activity, Disease, Food, Individual Behavior, Social Behavior, and Vitamin are considered in the experiments as the other semantic categories in UMLS are not related to eating habits or eating disorders.</p><p>MetaMap also normalizes the identified concepts of a term and provides a concept unique identifier (CUI) for each of the concepts <ref type="bibr" coords="5,374.22,604.09,14.61,8.74" target="#b10">[11]</ref>. We have generated features corresponding to the CUIs and these features are called as UMLS features throughout this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Text Classification Techniques</head><p>Different text classification methods have been implemented to identify depression or anorexia in the given corpus using the BOW features and UMLS features individually and by combining them. The proposed frameworks are developed using ada boost, logistic regression (LR), Random Forest (RF), Support Vector Machine (SVM) and recurrent neural network (RNN) classifiers.</p><p>SVM is widely used for text categorization <ref type="bibr" coords="6,334.76,209.51,14.61,8.74" target="#b15">[16]</ref>. The linear kernel is recommended for text categorization as the linear kernel performs nicely when there is a lot of features <ref type="bibr" coords="6,216.82,233.42,14.61,8.74" target="#b24">[25]</ref>. Hence linear SVM is used in the experiments.</p><p>Random Forest is an ensemble of decision tree classifiers, which is trained with the bagging method. The general idea of the bagging method is that a combination of learning models increases the overall result. It has shown good results for two class text classification problems <ref type="bibr" coords="6,297.17,293.20,14.61,8.74" target="#b14">[15]</ref>. We have used random forest classifier using Gini index as the measure of the quality of a split.</p><p>Logistic regression performs well for binary class classification problem <ref type="bibr" coords="6,445.34,329.06,14.61,8.74" target="#b13">[14]</ref>. We have implemented logistic regression using liblinear, a library for large scale linear classification <ref type="bibr" coords="6,209.63,352.97,14.61,8.74" target="#b24">[25]</ref>.</p><p>The Ada boost algorithm is an ensemble technique, which can combine many weak classifiers into one strong classifier <ref type="bibr" coords="6,313.26,388.84,14.61,8.74" target="#b12">[13]</ref>. This has been widely used for binary class classification problems <ref type="bibr" coords="6,282.04,400.79,14.61,8.74" target="#b25">[26]</ref>.</p><p>RNN is an useful classifier for sequential data because each neuron or unit can use its internal memory to maintain information about the previous input. This allows the network to gain a deeper understanding of the statement. In principle, RNN can handle context from the beginning of the sentence which will allow more accurate predictions of a word at the end of a sentence <ref type="bibr" coords="6,427.40,472.52,14.61,8.74" target="#b16">[17]</ref>. For the first task, RNN is implemented using Fasttext embeddings, a pre-trained word vector on 600 billion tokens, 2 million vocabulary and 300 dimensional vectors generated from a corpus of Wikipedia <ref type="bibr" coords="6,310.17,508.39,14.61,8.74" target="#b26">[27]</ref>. For task 2, RNN is implemented using GloVe embeddings, a pre-trained word embeddings on 840 billion tokens, 2.2 million vocabulary and 300 dimensional vectors generated from a corpus of Wikipedia and Twitter <ref type="bibr" coords="6,238.57,544.26,14.61,8.74" target="#b18">[19]</ref>.</p><p>3 Experimental Evaluation The corpus released as part of the first task is a collection of posts or comments from a set of users over Reddit <ref type="bibr" coords="6,275.33,644.16,9.96,8.74" target="#b2">[3]</ref>. The corpus is divided into two categoriesthe posts of the users who are suffering from depression, and the posts of the other users belong to the control group or non-depression category i.e., the users who are not diagnosed with depression <ref type="bibr" coords="7,304.87,130.95,9.96,8.74" target="#b2">[3]</ref>. For each user, the collection contains a sequence of writings in chronological order. For each user, the collection of writings has been divided into 10 chunks. The first chunk contains the oldest 10% of the posts, the second chunk contains the second oldest 10% posts, and so forth <ref type="bibr" coords="7,172.43,178.77,9.96,8.74" target="#b2">[3]</ref>. The overview of the corpus is presented in Table <ref type="table" coords="7,408.18,178.77,3.87,8.74" target="#tab_0">1</ref>. As the corpus consists of posts and comments over Reddit, we cannot rule out the possibility of having some individuals who are suffering from depression in the control group (non-depression), and vice-versa. The fundamental issue is how to determine a set of posts that indicates depression. Hence it is necessary to have adequate knowledge about the corpus. The corpus contains 1,076,582 posts or comments from 1027 unique users, of which the posts of 486 users are considered as training set, and rest 820 are used as test set. The most important factor is that the data is unbalanced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Task2</head><p>The corpus released as part of task2 is also a collection of posts or comments from a set of users over Reddit <ref type="bibr" coords="7,271.93,512.66,9.96,8.74" target="#b2">[3]</ref>. The data is different from the data of task1, however, both of the corpora are generated from Reddit posts. This corpus is also divided into two categories -the posts of the users who are suffering from anorexia, and the posts of the other users belong to the control group or nonanorexia category i.e., the users who are not diagnosed with anorexia <ref type="bibr" coords="7,446.29,560.48,9.96,8.74" target="#b2">[3]</ref>. The corpus contains a series of posts in sequential manner for each user and it is divided into 10 chunks for each user. The first chunk contains the oldest 10% of the posts, the second chunk contains the second oldest 10% posts and so on <ref type="bibr" coords="7,467.31,596.34,9.96,8.74" target="#b2">[3]</ref>. The overview of the corpus is presented in Table <ref type="table" coords="7,345.11,608.30,3.87,8.74" target="#tab_1">2</ref>. The corpus contains 2,53,752 posts or comments from 472 unique users, of which the posts of 152 users are considered as training set, and rest 320 are used as test set. This indicates that the corpus is unbalanced. The objective is to identify the posts in the test set that belong to anorexia category. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Setup</head><p>The term-document matrices are generally sparse and high dimensional. The same may have adverse affect on the quality of the classifiers. Hence the significant terms related to different categories of a corpus is to be determined. Many term selection techniques are available in the literature. The term selection methods rank the terms in the vocabulary according to different criterion function and then a fixed number of top terms forms the resultant set of features.</p><p>A widely used term selection technique is χ 2 -statistic <ref type="bibr" coords="8,367.20,341.32,15.50,8.74" target="#b9">[10]</ref> and this is used in the experiments. We have considered different number of top terms generated by χ 2 -statistic and evaluated the performance of different classifiers using these set of terms from the training set. Eventually we have considered the best feature subset for individual classifiers.</p><p>Ada boost, LR, RF and SVM classifiers are implemented in Scikit-learn <ref type="foot" coords="8,463.53,411.47,3.97,6.12" target="#foot_5">6</ref> , a machine learning tool in Python <ref type="bibr" coords="8,283.25,425.00,14.61,8.74" target="#b27">[28]</ref>. RNN is implemented in Keras<ref type="foot" coords="8,440.15,423.43,3.97,6.12" target="#foot_6">7</ref> , a deep learning tool in Python. The other experimental settings for the individual tasks are mentioned below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Task1</head><p>The data of the same challenge in 2017 has been released as the training set for this task. The corpus of the 2017 challenge was divided into training set and test set. The ground truths were available for both training and test set. We have used this training set to train different classifiers of the proposed frameworks in this article. The parameters of different classifiers are tuned using 10-fold cross validation technique on this training set of 2017 challenge. The test data of 2017 challenge is used as the validation set to evaluate the performance of the classifiers of the proposed frameworks using the ground truths. The classifiers using a particular type of features that perform the best on the validation set are chosen for implementation on the test set of this year. Subsequently, the results of the proposed frameworks on this test set have been submitted to the eRisk 2018 challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Task2</head><p>The given training set of second task is further divided into two parts namely, training set and validation set. The new training set is build by randomly choosing 80% documents individually from anorexia and non-anorexia categories. Similarly the rest 20% of these categories form the validation set. The parameters of different classifiers are tuned using 10-fold cross validation technique on the newly formed training set and therefore the performance of these classifiers are tested on the validation set. The classifiers using a particular type of features that had shown better results than other such frameworks are submitted to the challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Evaluation Measures</head><p>The performance of the proposed method and the state of the art classifiers are evaluated by using the standard precision, recall and fmeasure and ERDE. The precision and recall for two classification problem can be computed as follows:</p><p>Precision = TP TP+FP Recall = TP TP+FN Here TP stands for true positive and it counts the number of data points correctly predicted to the positive class. FP stands for false positive and it counts the number of data points that actually belong to the negative class, but predicted as positive (i.e., falsely predicted as positive). FN stands for false negative and it counts the number of data points that actually belong to the positive class, but predicted as negative (i.e., falsely predicted as negative). TN stands for true negative and it counts the number of data points correctly predicted to the negative class. The fmeasure combines recall and precision with an equal weight in the following form:</p><formula xml:id="formula_1" coords="9,230.61,526.91,147.37,22.31">Fmeasure = 2 × recall × precision recall + precision</formula><p>The closer the values of precision and recall, the higher is the fmeasure. Fmeasure becomes 1 when the values of precision and recall are 1 and it becomes 0 when precision is 0, or recall is 0, or both are 0. Thus fmeasure lies between 0 and 1 <ref type="bibr" coords="9,162.44,596.34,14.61,8.74" target="#b28">[29]</ref>. A high fmeasure value is desirable for good classification <ref type="bibr" coords="9,434.01,596.34,14.61,8.74" target="#b28">[29]</ref>.</p><p>The organizers of this challenge introduced early risk detection error (ERDE), which checks the correctness of the decision made and the delay to make such decision <ref type="bibr" coords="9,173.12,644.16,14.61,8.74" target="#b29">[30]</ref>. The delay was measured by counting the number (k) of distinct textual items seen before giving the answer. The threshold of ERDE was set to 5</p><p>to 50 posts which was represented by ERDE 5 and ERDE 50 . The correctness of each emitting decision and the delay taken by the system to make the decision has to be calculated. The delay is measured here by counting the number (k) of individual documents seen before giving the answer. Another fundamental issue is that, the corpus used in this task is unbalanced. Consider a binary decision d taken by a system with delay k. The prediction d can be either of TP, TN, FP or FN. Given these four cases ERDE <ref type="bibr" coords="10,299.03,190.72,15.50,8.74" target="#b29">[30]</ref> can be defined as . A low value of ERDE is desirable as this is a measure to find error in the system <ref type="bibr" coords="10,462.33,327.28,14.61,8.74" target="#b29">[30]</ref>.</p><formula xml:id="formula_2" coords="10,134.77,212.38,155.53,51.21">ERDE o (d, k) =          c f p , if d =</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Analysis of Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Task1</head><p>We have reported the performance of Ada Boost, LR, RF and SVM classifiers on the validation set using BOW features, UMLS features and the combination of BOW and UMLS features respectively in Table <ref type="table" coords="10,355.57,417.01,3.87,8.74" target="#tab_2">3</ref>, Table <ref type="table" coords="10,393.93,417.01,4.98,8.74" target="#tab_3">4</ref> and Table <ref type="table" coords="10,448.82,417.01,3.87,8.74" target="#tab_4">5</ref>. Note that the validation set is the test set of the same challenge in 2017. The performance of these classifiers are measured in terms of fmeasure in these tables.</p><p>These results are useful to analyze the performance of different proposed frameworks. Eventually, the best frameworks have been implemented on the given test set of eRisk 2018 challenge and subsequently the results are communicated.</p><p>Table <ref type="table" coords="10,162.10,500.70,4.98,8.74" target="#tab_2">3</ref> shows that the performance of Ada Boost is better than the other classifiers in terms of precision, recall and fmeasure. It can be seen from Table <ref type="table" coords="10,475.61,512.66,4.98,8.74" target="#tab_3">4</ref> that the performance of Ada Boost is best among all other classifiers in terms of recall and fmeasure. It is observed from Table <ref type="table" coords="10,346.00,536.57,4.98,8.74" target="#tab_4">5</ref> that LR, RF outperforms the other classifiers in terms of precision, recall and fmeasure respectively.</p><p>It may be noted from Table <ref type="table" coords="10,273.69,572.43,4.98,8.74" target="#tab_2">3</ref> and Table <ref type="table" coords="10,331.67,572.43,4.98,8.74" target="#tab_3">4</ref> that the performance of all the classifiers using BOW features are better than the same using UMLS features. Moreover, Table <ref type="table" coords="10,208.74,596.34,4.98,8.74" target="#tab_2">3</ref> and Table <ref type="table" coords="10,263.87,596.34,4.98,8.74" target="#tab_4">5</ref> show that all the classifiers using the BOW features perform better than the same using the combination of BOW and UMLS features. This indicates that UMLS features have little influence on the performance of the classifiers. It is manually checked that the number of UMLS features are too small and there are absence of biomedical terms related to depression in the documents. This may be the reason of poor performance. Consequently, we have submitted the results of Ada Boost, LR, RF and SVM classifiers using BOW features on the test set to the challenge.</p><p>We have also submitted a result of RNN using Fasttext embedding, as RNN has been widely used for text categorization in recent years. However, the performance of RNN on the validation set is not as good as the other classifiers using BOW features. The precision, recall and fmeasure of the same is 0.64, 0.60 and 0.62 respectively. Note that we have fixed the sequence length of each sentence considered by RNN as 150 due to the limitation in the resources. The results of RNN may be improved by increasing the sequence length in the model, which is beyond the scope of this article.</p><p>The results of Ada Boost, LR, RF and SVM classifiers using BOW features and RNN classifier using Fasttext embedding on the given test set in terms of ERDE 5 , ERDE 50 , precision, recall and fmeasure are reported in Table <ref type="table" coords="11,472.84,572.43,3.87,8.74" target="#tab_5">6</ref>. RKMVERIA, RKMVERIB, RKMVERIC, RKMVERID indicate the results of LR, SVM, Ada boost, and RF classifiers respectively using BOW features. RK-MVERIE indicates the result of RNN classifier using fasttext embedding. Table <ref type="table" coords="11,134.77,620.25,4.98,8.74" target="#tab_5">6</ref> shows that precision of the RKMVERIC framework is better than the precision of the other RKMVERI frameworks and RKMVERIC achives the best score in terms of the precision of 45 submissions in the eRisk 2018 challenge. It can be seen from Table <ref type="table" coords="11,240.47,656.12,4.98,8.74" target="#tab_5">6</ref> RKMVERID performs better than other RKMVERI frameworks in terms of fmeasure and the same is the fourth best fmeasure in the competition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Task2</head><p>We have reported the performance of Ada Boost, LR, RF and SVM classifiers on the validation set using BOW features, UMLS features and the combination of BOW and UMLS features respectively in Table <ref type="table" coords="12,357.64,309.90,3.87,8.74" target="#tab_6">7</ref>, Table <ref type="table" coords="12,396.50,309.90,4.98,8.74" target="#tab_7">8</ref> and Table <ref type="table" coords="12,452.16,309.90,3.87,8.74" target="#tab_8">9</ref>. The performance of these classifiers are measured in terms of fmeasure in these tables.</p><p>It can be seen from Table <ref type="table" coords="12,255.16,345.77,4.98,8.74" target="#tab_6">7</ref> that the performance of SVM is better than the other classifiers in terms of precision recall and fmeasure. Table <ref type="table" coords="12,409.82,357.72,4.98,8.74" target="#tab_7">8</ref> shows that the performance of SVM is the best among all other classifiers in terms of fmeasure. It can be observed from Table <ref type="table" coords="12,275.81,381.63,4.98,8.74" target="#tab_8">9</ref> that Ada Boost classifier outperforms other classifiers in terms of fmeasure.</p><p>It may be noted from Table <ref type="table" coords="12,273.69,417.50,4.98,8.74" target="#tab_6">7</ref> and Table <ref type="table" coords="12,331.67,417.50,4.98,8.74" target="#tab_7">8</ref> that the performance of all the  Moreover, Table <ref type="table" coords="13,208.74,324.13,4.98,8.74" target="#tab_6">7</ref> and Table <ref type="table" coords="13,263.87,324.13,4.98,8.74" target="#tab_8">9</ref> show that all the classifiers using the BOW features perform better than the same using the combination of BOW and UMLS features. This indicates that UMLS features have little influence on the performance of the classifiers. We have manually checked that the number of UMLS features are too small, which may be a reason of poor performance. Consequently, we have submitted the results of Ada Boost, LR, RF and SVM classifiers using BOW features on the test set to the challenge. We have also submitted a result of RNN using GloVe embedding, as RNN has been widely used for text categorization. However, the performance of RNN on the validation set is not as good as the other classifiers using BOW features. The fmeasure of the same is 0.56.</p><p>The results of Ada Boost, LR, RF and SVM classifiers using BOW features and RNN classifier using GloVe embedding on the given test set in terms of ERDE 5 , ERDE 50 , precision, recall and fmeasure are reported in Table <ref type="table" coords="13,405.29,479.55,8.49,8.74" target="#tab_9">10</ref>. RKMVERIA, RKMVERIB, RKMVERIC, RKMVERIE indicate the results of SVM, LR, RF, and Ada Boost classifiers respectively using BOW features. RKMVERID indicates the result of RNN classifier using GloVe embedding. Table <ref type="table" coords="13,420.05,515.41,9.96,8.74" target="#tab_9">10</ref> shows that precision of the RKMVERIC framework is better than the precision of the other RKMVERI frameworks and it is the fourth best score among the precision of 35 submissions in the eRisk 2018 challenge. RKMVERIA performs better than other RKMVERI frameworks in terms of ERDE 5 , ERDE 50 , recall and fmeasure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>The eRisk 2018 shared task highlights a variety of challenges for early detection of depression and anorexia using the data over social forums. Depression is a type of mental disorder that has adverse affects on feelings, thoughts and behav-iors and can harm regular activities like sleeping, working etc. Anorexia is also a mental disorder distinguished by a refusal to maintain a normal body weight, intense fear of weight gain and disturbance in the perception of body shape and weight. However, it is generally difficult to identify depression or anorexia from different symptoms. The treatment for these diseases can be started on time, if the alarming symptoms are diagnosed properly. The aim of this challenge is to detect signs of such diseases from the posts or comments of individuals over social media. Various machine learning frameworks have been developed using different types of features from the free text to accomplish this task. We have examined the performance of both bag of words features and UMLS features using different classifiers to identify depression. However, it is observed that a few UMLS features exist in the corpus. Hence the proposed methodologies relied on the BOW features. The experimental results show that the performance of these methodologies are reasonably good. We have also implemented the RNN classifier using the Fasttext and GloVe word embeddings. However, the performance of these RNN models are not so good as we have to fix the sequence length of each sentence as 150 only due to limitation of resources. In future, we can implement RNN using higher length of word embeddings for better performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="10,293.07,214.23,187.32,8.74;10,215.65,228.57,17.17,9.65;10,265.46,228.57,215.62,8.74;10,215.65,242.92,263.00,9.65;10,215.65,257.27,7.75,8.74;10,265.46,257.27,218.74,8.74;10,134.77,279.46,345.83,9.65;10,134.77,291.41,345.83,9.65;10,134.77,303.37,345.83,8.74;10,134.77,315.32,313.34,8.74"><head></head><label></label><figDesc>positive AND ground truth=negative (FP) c f n , if d = negative AND ground truth=positive (FN) lc o (k)c tp , if d = positive AND ground truth=positive (TP) 0, if d = negative AND ground truth=negative (TN) The values of c f p and c f n depend on the application domain and the implications of FP and FN decisions. The function lc o (k) is a monotonically increasing function of k, which is parameterized by o. The minimum value of o is considered as 5 and the maximum value as 50. Note that ERDE lies in range [0, 1]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,135.76,215.30,345.52,105.77"><head>Table 1 .</head><label>1</label><figDesc>Overview of the Corpus for Task1</figDesc><table coords="7,333.44,236.09,147.84,29.78"><row><cell>Training Set</cell><cell>Test Set</cell></row><row><cell cols="2">Depressed Control Depressed Control</cell></row><row><cell>Group</cell><cell>Group</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,137.07,115.91,341.21,105.77"><head>Table 2 .</head><label>2</label><figDesc>Overview of the Corpus for Task2</figDesc><table coords="8,339.62,136.71,138.66,29.78"><row><cell>Training Set</cell><cell>Test Set</cell></row><row><cell cols="2">Anorexic Control Anorexic Control</cell></row><row><cell>Group</cell><cell>Group</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="11,171.93,115.91,271.50,72.90"><head>Table 3 .</head><label>3</label><figDesc>Performance of Different Classifiers Using BOW Features</figDesc><table coords="11,177.44,136.71,260.49,52.10"><row><cell>Classifiers</cell><cell>Precision</cell><cell>Recall</cell><cell>Fmeasure</cell></row><row><cell>Ada Boost</cell><cell>0.75</cell><cell>0.76</cell><cell>0.75</cell></row><row><cell>Logistic Regression</cell><cell>0.75</cell><cell>0.73</cell><cell>0.74</cell></row><row><cell>Support Vector Machine</cell><cell>0.72</cell><cell>0.71</cell><cell>0.72</cell></row><row><cell>Random Forest</cell><cell>0.71</cell><cell>0.74</cell><cell>0.73</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="11,170.27,204.62,274.82,72.90"><head>Table 4 .</head><label>4</label><figDesc>Performance of Different Classifiers Using UMLS Features</figDesc><table coords="11,177.44,225.42,260.49,52.10"><row><cell>Classifiers</cell><cell>Precision</cell><cell>Recall</cell><cell>Fmeasure</cell></row><row><cell>Ada Boost</cell><cell>0.41</cell><cell>0.50</cell><cell>0.45</cell></row><row><cell>Logistic Regression</cell><cell>0.46</cell><cell>0.43</cell><cell>0.37</cell></row><row><cell>Support Vector Machine</cell><cell>0.48</cell><cell>0.46</cell><cell>0.41</cell></row><row><cell>Random Forest</cell><cell>0.46</cell><cell>0.43</cell><cell>0.40</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="11,134.77,293.33,345.83,82.11"><head>Table 5 .</head><label>5</label><figDesc>Performance of Different Classifiers Using the Combination of BOW and UMLS Features</figDesc><table coords="11,177.44,323.34,260.49,52.10"><row><cell>Classifiers</cell><cell>Precision</cell><cell>Recall</cell><cell>Fmeasure</cell></row><row><cell>Ada Boost</cell><cell>0.61</cell><cell>0.62</cell><cell>0.61</cell></row><row><cell>Logistic Regression</cell><cell>0.64</cell><cell>0.63</cell><cell>0.63</cell></row><row><cell>Support Vector Machine</cell><cell>0.62</cell><cell>0.63</cell><cell>0.62</cell></row><row><cell>Random Forest</cell><cell>0.63</cell><cell>0.64</cell><cell>0.63</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="12,134.81,115.91,345.73,83.85"><head>Table 6 .</head><label>6</label><figDesc>The Performance of Various Classifiers using Different Evaluation Measures</figDesc><table coords="12,136.16,136.71,339.55,63.06"><row><cell>Methods</cell><cell cols="5">ERDE5 ERDE50 Fmeasure Precision Recall</cell></row><row><cell>RKMVERIA (LR using BOW)</cell><cell cols="2">10.14% 8.68%</cell><cell>0.52</cell><cell>0.49</cell><cell>0.54</cell></row><row><cell>RKMVERIB (SVM using BOW)</cell><cell cols="2">10.66% 9.07%</cell><cell>0.47</cell><cell>0.37</cell><cell>0.65</cell></row><row><cell cols="3">RKMVERIC (Ada Boost using BOW) 9.81% 9.08%</cell><cell>0.48</cell><cell>0.67</cell><cell>0.38</cell></row><row><cell>RKMVERID (RF using BOW)</cell><cell cols="2">9.97% 8.63%</cell><cell>0.58</cell><cell>0.60</cell><cell>0.56</cell></row><row><cell>RKMVERIE (RNN using Fasttext)</cell><cell>9.89%</cell><cell>9.28%</cell><cell>0.21</cell><cell>0.35</cell><cell>0.15</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="12,171.93,449.12,271.50,72.90"><head>Table 7 .</head><label>7</label><figDesc>Performance of Different Classifiers Using BOW Features</figDesc><table coords="12,178.43,469.92,258.49,52.10"><row><cell>Text Classifiers</cell><cell>Precision</cell><cell>Recall</cell><cell>Fmeasure</cell></row><row><cell>AdaBoost</cell><cell>0.91</cell><cell>0.93</cell><cell>0.91</cell></row><row><cell>Logistic Regression</cell><cell>0.96</cell><cell>0.97</cell><cell>0.97</cell></row><row><cell>Random Forest</cell><cell>0.98</cell><cell>0.92</cell><cell>0.95</cell></row><row><cell>Support Vector Machine</cell><cell>0.97</cell><cell>0.98</cell><cell>0.98</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="12,134.77,555.25,345.83,109.60"><head>Table 8 .</head><label>8</label><figDesc>Performance of Different Classifiers Using UMLS Features</figDesc><table coords="12,134.77,576.05,345.83,88.80"><row><cell>Text Classifiers</cell><cell>Precision</cell><cell>Recall</cell><cell>Fmeasure</cell></row><row><cell>Ada Boost</cell><cell>0.54</cell><cell>0.52</cell><cell>0.46</cell></row><row><cell>Logistic Regression</cell><cell>0.56</cell><cell>0.51</cell><cell>0.47</cell></row><row><cell>Random Forest</cell><cell>0.47</cell><cell>0.49</cell><cell>0.16</cell></row><row><cell>Support Vector Machine</cell><cell>0.58</cell><cell>0.49</cell><cell>0.55</cell></row><row><cell cols="4">classifiers using BOW features are better than the same using UMLS features.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="13,134.77,115.91,345.83,82.11"><head>Table 9 .</head><label>9</label><figDesc>Performance of Different Classifiers Using the Combination of BOW and UMLS Features</figDesc><table coords="13,178.43,145.93,258.49,52.10"><row><cell>Text Classifiers</cell><cell>Precision</cell><cell>Recall</cell><cell>Fmeasure</cell></row><row><cell>Ada Boost</cell><cell>0.43</cell><cell>0.51</cell><cell>0.47</cell></row><row><cell>Logistic Regression</cell><cell>0.57</cell><cell>0.51</cell><cell>0.14</cell></row><row><cell>Random Forest</cell><cell>0.47</cell><cell>0.49</cell><cell>0.16</cell></row><row><cell>Support Vector Machine</cell><cell>0.46</cell><cell>0.48</cell><cell>0.16</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="13,134.77,212.25,345.83,83.85"><head>Table 10 .</head><label>10</label><figDesc>The Performance of Various Classifiers using Different Evaluation Measures</figDesc><table coords="13,136.16,233.05,336.09,63.06"><row><cell>Methods</cell><cell cols="4">ERDE5 ERDE50 Fmeasure Precision Recall</cell></row><row><cell>RKMVERIA (SVM using BOW)</cell><cell>12.17% 8.63%</cell><cell>0.67</cell><cell>0.82</cell><cell>0.56</cell></row><row><cell>RKMVERIB (LR using BOW)</cell><cell>12.93% 12.31%</cell><cell>0.46</cell><cell>0.81</cell><cell>0.32</cell></row><row><cell>RKMVERIC (RF using BOW)</cell><cell>12.85% 12.85%</cell><cell>0.25</cell><cell>0.86</cell><cell>0.15</cell></row><row><cell>RKMVERID (RNN using GloVe)</cell><cell>12.89% 12.89%</cell><cell>0.31</cell><cell>0.80</cell><cell>0.20</cell></row><row><cell cols="2">RKMVERIE (AdaBoost using BOW) 12.93% 12.31%</cell><cell>0.46</cell><cell>0.81</cell><cell>0.32</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,656.80,233.08,7.86"><p>www.who.int/mental health/management/depression/en/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,144.73,645.84,265.35,7.86"><p>https://www.nationaleatingdisorders.org/CollegiateSurveyProject</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,144.73,656.80,119.60,7.86"><p>https://metamap.nlm.nih.gov</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,144.73,645.84,227.78,7.86"><p>https://mmtx.nlm.nih.gov/MMTx/semanticTypes.shtml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,144.73,656.80,119.60,7.86"><p>https://metamap.nlm.nih.gov</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="8,144.73,645.84,220.44,7.86"><p>http://scikit-learn.org/stable/supervised learning.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="8,144.73,656.80,62.84,7.86"><p>https://keras.io</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="14,142.96,374.79,337.63,7.86;14,151.52,385.75,244.86,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="14,393.85,374.79,86.74,7.86;14,151.52,385.75,62.81,7.86">Predicting depression via social media</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">De</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Counts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,237.07,385.75,89.42,7.86">Proceedings of ICWSM</title>
		<meeting>ICWSM</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,396.38,337.63,7.86;14,151.52,407.34,329.07,7.86;14,151.52,418.30,115.51,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="14,350.75,396.38,129.84,7.86;14,151.52,407.34,128.17,7.86">Social media as a measurement tool of depression in populations</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">De</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Counts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,300.74,407.34,179.85,7.86;14,151.52,418.30,42.64,7.86">Proceedings of the Annual ACM Web Science Conference</title>
		<meeting>the Annual ACM Web Science Conference</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="47" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,428.93,337.63,7.86;14,151.52,439.89,329.07,7.86;14,151.52,450.85,172.48,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="14,330.03,428.93,150.56,7.86;14,151.52,439.89,78.94,7.86">Overview of eRisk -early risk prediction on the internet</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,252.27,439.89,228.32,7.86;14,151.52,450.85,72.53,7.86">Proceedings of the Ninth International Conference of the CLEF Association</title>
		<meeting>the Ninth International Conference of the CLEF Association<address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,461.48,337.64,7.86;14,151.52,472.44,329.07,7.86;14,151.52,483.40,315.61,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="14,389.55,461.48,91.05,7.86;14,151.52,472.44,236.37,7.86">Recognition and treatment of depression and anxiety symptoms in heart failure</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Cully</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Ledoux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Deswal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,398.63,472.44,81.96,7.86;14,151.52,483.40,175.86,7.86">Primary Care Companion to the Journal of Clinical Psychiatry</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="103" to="109" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,494.04,337.64,7.86;14,151.52,505.00,55.35,7.86" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">E</forename><surname>Egede</surname></persName>
		</author>
		<title level="m" coord="14,212.14,494.04,268.45,7.86;14,151.52,505.00,23.47,7.86">Failure to recognize depression in primary care: issues and challenges</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,515.63,337.64,7.86;14,151.52,526.59,329.07,7.86;14,151.52,537.55,264.09,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="14,155.86,526.59,316.47,7.86">Detecting depression and mental illness on social media: an integrative review</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">C</forename><surname>Guntuku</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">B</forename><surname>Yaden</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,151.52,537.55,159.24,7.86">Current Opinion in Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="43" to="49" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,548.18,337.64,7.86;14,151.52,559.14,329.07,7.86;14,151.52,570.10,329.07,7.86;14,151.52,581.06,116.41,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="14,466.48,548.18,14.11,7.86;14,151.52,559.14,329.07,7.86;14,151.52,570.10,31.17,7.86">Depression detection via harvesting social media: A multimodal dictionary learning solution</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,204.26,570.10,276.33,7.86;14,151.52,581.06,25.70,7.86">Proceedings of the International Joint Conference on Artificial Intelligence</title>
		<meeting>the International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3838" to="3844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,591.69,337.64,7.86;14,151.52,602.65,111.20,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="14,253.14,591.69,219.35,7.86">Anorexia nervosa: Role of the primary care physician</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Danila Musante</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,151.52,602.65,23.43,7.86">JCOM</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,613.29,337.64,7.86;14,151.52,624.25,215.54,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="14,201.18,613.29,279.41,7.86;14,151.52,624.25,52.22,7.86">Priority medicines for europe and the world: A public health approach to innovation</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Duthey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,215.01,624.25,96.37,7.86">WHO Background paper</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,634.88,337.98,7.86;14,151.52,645.84,329.07,7.86;14,151.52,656.80,100.34,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="14,258.80,634.88,221.79,7.86;14,151.52,645.84,55.57,7.86">A supervised term selection technique for effective text categorization</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Murthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,217.14,645.84,233.66,7.86">International Journal of Machine Learning and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="877" to="892" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,119.67,337.98,7.86;15,151.52,130.63,329.07,7.86;15,151.52,141.59,132.60,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="15,288.07,119.67,192.52,7.86;15,151.52,130.63,80.52,7.86">An overview of metamap: Historical perspective and recent advances</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,244.14,130.63,232.40,7.86">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="229" to="236" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,152.55,337.97,7.86;15,151.52,163.51,302.44,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="15,291.58,152.55,177.88,7.86">The representation of meaning in the UMLS</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Mccray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">J</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,151.52,163.51,144.06,7.86">Methods of Information in Medicine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">01/02</biblScope>
			<biblScope unit="page" from="193" to="201" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,174.47,337.98,7.86;15,151.52,185.43,315.40,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="15,306.77,174.47,128.79,7.86">A short introduction to boosting</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Abe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,446.71,174.47,33.88,7.86;15,151.52,185.43,168.85,7.86">Journal-Japanese Society for Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">1612</biblScope>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,196.39,337.98,7.86;15,151.52,207.34,296.10,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="15,325.21,196.39,155.39,7.86;15,151.52,207.34,88.87,7.86">Large-scale bayesian logistic regression for text categorization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Genkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Madigan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,251.40,207.34,56.22,7.86">Technometrics</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="291" to="304" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,218.30,337.98,7.86;15,151.52,229.26,250.89,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="15,315.75,218.30,164.84,7.86;15,151.52,229.26,74.77,7.86">An improved random forest classifier for text categorization</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,237.30,229.26,15.17,7.86">JCP</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2913" to="2920" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,240.22,337.98,7.86;15,151.52,251.18,329.07,7.86;15,151.52,262.14,49.66,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="15,250.61,240.22,229.99,7.86;15,151.52,251.18,80.98,7.86">Support vector machine active learning with applications to text classification</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,242.72,251.18,153.55,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="45" to="66" />
			<date type="published" when="2001-11">Nov. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,273.10,337.97,7.86;15,151.52,284.06,265.75,7.86" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="15,286.60,273.10,193.99,7.86;15,151.52,284.06,96.63,7.86">Recurrent neural network for text classification with multi-task learning</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.05101</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="15,142.62,295.02,337.98,7.86;15,151.52,305.98,269.66,7.86" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="15,421.44,295.02,59.15,7.86;15,151.52,305.98,100.04,7.86">Learning word vectors for 157 languages</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.06893</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="15,142.62,316.93,337.98,7.86;15,151.52,327.89,248.29,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="15,336.24,316.93,144.35,7.86;15,151.52,327.89,43.60,7.86">Glove: Global vectors for word representation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,216.88,327.89,89.92,7.86">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,338.85,337.97,7.86;15,151.52,349.81,221.74,7.86" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schutze</surname></persName>
		</author>
		<title level="m" coord="15,349.13,338.85,131.46,7.86;15,151.52,349.81,24.37,7.86">Introduction to Information Retrieval</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,360.77,337.98,7.86;15,151.52,371.73,329.07,7.86;15,151.52,382.69,100.34,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="15,271.37,360.77,209.22,7.86;15,151.52,371.73,172.10,7.86">A similarity based supervised decision rule for qualitative improvement of text categorization</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">A</forename><surname>Murthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,335.34,371.73,102.86,7.86">Fundamenta Informaticae</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="275" to="295" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,393.65,337.97,7.86;15,151.52,404.61,66.12,7.86" xml:id="b21">
	<monogr>
		<title level="m" type="main" coord="15,268.66,393.65,183.19,7.86">Introduction to Modern Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcgill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>Mc-Graw Hill</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,415.56,337.98,7.86;15,151.52,426.52,323.35,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="15,229.31,415.56,251.28,7.86;15,151.52,426.52,92.02,7.86">The unified medical language system (UMLS): Integrating biomedical terminology</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,254.97,426.52,91.58,7.86">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="267" to="D270" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,437.48,337.97,7.86;15,151.52,448.44,319.32,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="15,217.28,437.48,263.31,7.86;15,151.52,448.44,91.28,7.86">Effective mapping of biomedical text to the UMLS metathesaurus: The metamap program</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,265.74,448.44,131.72,7.86">Proceedings of AMIA Symposium</title>
		<meeting>AMIA Symposium</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="17" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,459.40,337.98,7.86;15,151.52,470.36,329.07,7.86;15,151.52,481.32,149.24,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="15,441.36,459.40,39.23,7.86;15,151.52,470.36,156.93,7.86">Liblinear: A library for large linear classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,319.57,470.36,156.84,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008-08">Aug. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,492.28,337.98,7.86;15,151.52,503.24,263.53,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="15,331.20,492.28,149.40,7.86;15,151.52,503.24,31.44,7.86">Boosting and rocchio applied to text filtering</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,203.77,503.24,129.46,7.86">Proceedings of SIGIR conference</title>
		<meeting>SIGIR conference</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,514.19,337.98,7.86;15,151.52,525.15,329.07,7.86;15,151.52,536.11,231.42,7.86" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="15,431.19,514.19,49.40,7.86;15,151.52,525.15,180.19,7.86">Advances in pre-training distributed word representations</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Puhrsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,353.19,525.15,127.41,7.86;15,151.52,536.11,203.22,7.86">Proceedings of the International Conference on Language Resources and Evaluation</title>
		<meeting>the International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,547.07,337.98,7.86;15,151.52,558.03,329.07,7.86;15,151.52,568.99,329.07,7.86;15,151.52,579.95,20.99,7.86" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="15,394.17,558.03,86.42,7.86;15,151.52,568.99,70.96,7.86">Scikit-learn: Machine learning in python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,233.56,568.99,150.90,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,590.91,337.98,7.86;15,151.52,601.87,329.07,7.86;15,151.52,612.82,179.45,7.86" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="15,273.33,590.91,207.26,7.86;15,151.52,601.87,50.71,7.86">A feature selection method for improved document classification</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">A</forename><surname>Murthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,224.53,601.87,256.06,7.86;15,151.52,612.82,97.63,7.86">Proceedings of the International Conference on Advanced Data Mining and Applications</title>
		<meeting>the International Conference on Advanced Data Mining and Applications</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="296" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,623.78,337.97,7.86;15,151.52,634.74,329.07,7.86;15,151.52,645.70,213.24,7.86" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="15,278.03,623.78,202.56,7.86;15,151.52,634.74,38.19,7.86">A test collection for research on depression and language use</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,211.65,634.74,268.94,7.86;15,151.52,645.70,94.64,7.86">International Conference of the Cross Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="28" to="39" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
