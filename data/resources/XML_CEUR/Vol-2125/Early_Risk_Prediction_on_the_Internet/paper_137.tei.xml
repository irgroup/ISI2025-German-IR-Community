<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,185.79,115.90,243.78,12.90">UNSL&apos;s participation at eRisk 2018 Lab</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,170.17,153.97,61.70,8.64"><forename type="first">Dario</forename><forename type="middle">G</forename><surname>Funez</surname></persName>
							<email>funezdario@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">LIDIC Research Group</orgName>
								<orgName type="institution">Universidad Nacional de San Luis</orgName>
								<address>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,241.32,153.97,35.42,8.64"><forename type="first">Ma</forename><surname>José</surname></persName>
						</author>
						<author>
							<persName coords="1,279.23,153.97,74.40,8.64"><forename type="first">Garciarena</forename><surname>Ucelay</surname></persName>
							<email>mjgarciarenaucelay@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">LIDIC Research Group</orgName>
								<orgName type="institution">Universidad Nacional de San Luis</orgName>
								<address>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,363.08,153.97,75.15,8.64"><forename type="first">Ma</forename><forename type="middle">Paula</forename><surname>Villegas</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LIDIC Research Group</orgName>
								<orgName type="institution">Universidad Nacional de San Luis</orgName>
								<address>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,134.77,165.93,75.84,8.64"><forename type="first">Sergio</forename><forename type="middle">G</forename><surname>Burdisso</surname></persName>
							<email>sergio.burdisso@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">LIDIC Research Group</orgName>
								<orgName type="institution">Universidad Nacional de San Luis</orgName>
								<address>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET)</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,226.85,165.93,74.90,8.64"><forename type="first">Leticia</forename><forename type="middle">C</forename><surname>Cagnina</surname></persName>
							<email>lcagnina@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">LIDIC Research Group</orgName>
								<orgName type="institution">Universidad Nacional de San Luis</orgName>
								<address>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET)</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,318.00,165.93,103.15,8.64"><forename type="first">Manuel</forename><surname>Montes-Y-Gómez</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Óptica y Electrónica (INAOE)</orgName>
								<orgName type="institution">Instituto Nacional de Astrofísica</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,447.39,165.93,33.20,8.64;1,280.83,177.88,49.23,8.64"><forename type="first">Marcelo</forename><forename type="middle">L</forename><surname>Errecalde</surname></persName>
							<email>merrecalde@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">LIDIC Research Group</orgName>
								<orgName type="institution">Universidad Nacional de San Luis</orgName>
								<address>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,185.79,115.90,243.78,12.90">UNSL&apos;s participation at eRisk 2018 Lab</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8F6054FD8969FBEABD12E246615E9667</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Early Risk Detection</term>
					<term>Early Depression Detection</term>
					<term>Early Anorexia Detection</term>
					<term>Semantic Analysis Techniques</term>
					<term>Flexible Temporal Variation of Terms</term>
					<term>Incremental Classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe the participation of the LIDIC Research Group of Universidad Nacional de San Luis (UNSL) -Argentina at CLEF eRisk 2018 Lab. The main goal of this Lab is considering early risk detection scenarios where the issue of getting timely predictions with a reasonable confidence level becomes critical. Two completely different approaches were used, that we will refer as flexible temporal variation of terms (FTVT) and sequential incremental classification (SIC). FTVT is a semantic representation of documents that explicitly considers the partial information that is made available in the different "chunks" to the early risk detection systems along the time. FTVT is an improvement on the TVT method [1] that allows varying the number of chunks considered in the representation according to the "level of urgency" required in the classification. SIC is a novel approach for text categorization that incrementally estimates the level of belonging of a piece of text to the different categories based on an accumulative process of evidence. In the test stage, FTVT obtained the lowest ERDE5 error in both pilot tasks and SIC achieved the highest precision for the anorexia detection task providing strong evidence that both approaches used by our team are interesting alternatives to deal with early risk detection tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The increasing use of Internet, social networks and other computer technologies allows the extraction of valuable information to early prevent some risks. In this context, early risk detection (ERD) on the Internet is an important research area due to the impact it might have in areas like health when people suffer depression, anorexia or other disorders that can threaten life and safety when criminals and sex offenders try to attack using web technologies.</p><p>The same as other predictive tasks, ERD methods have been mainly based on supervised machine learning approaches. In those cases, the task is generally addressed as a standard binary classification problem with two unbalanced classes: a minority (risky) positive class and a majority (control) negative class. However, beyond the difficulty that the unbalanced classes present to the learning algorithms, ERD introduces an added problem that is not usually present in other classification tasks: the incremental classification of sequential data (ICSD).</p><p>To effectively support ICSD two important aspects need to be considered. First, we must provide an adequate way to "remember" or "summarize" historical information read up to specific points of time. The informativeness level of these partial models will be critical to the effectiveness of the classifier in charge of detecting risky cases. Second, these models need to also provide support to a very important aspect of ERD: the decision of when (how soon) the system should stop reading from the input stream and classify it with an acceptable level of accuracy. This aspect, that we will refer as the supporting for early classification, is basically a multi-objective decision problem that attempts balancing accurate and timely classifications <ref type="bibr" coords="2,353.47,269.78,10.58,8.64" target="#b6">[7]</ref>. In fact, common evaluation measures of supervised classification like precision, recall and F -measure are no longer adequate in those cases because they do not take "time" into account. Thus, new "temporal" measures that penalize the system's delay in detecting risky cases are required. This is the case of the ERDE o error introduced in <ref type="bibr" coords="2,338.63,317.60,11.62,8.64" target="#b3">[4]</ref> and used in the 2017 eRisk pilot task <ref type="bibr" coords="2,153.74,329.55,11.62,8.64" target="#b4">[5]</ref> which allows specifying a threshold (the o value) that, when is surpassed, the penalty rapidly grows to 1.</p><p>The eRisk 2018 Lab presented two challenging tasks for ERD: early detection of signs of depression (task 1), and early detection of signs of anorexia (task 2). We participated in both tasks with two different approaches to deal with the ICSD issue: one that we will refer as flexible temporal variation of terms (FTVT) and the other named sequential incremental classification (SIC).</p><p>FTVT is a document representation that deals with the ICSD problem by keeping sequential information about the variation of terms occurring in the different chunks. The hypothesis behind this approach is that these variations can be informative to detect a risky case. SIC is a sequential approach that incrementally reads and estimates the evidence that words provide for both, positive and negative classes. SIC classifies a subject as risky as soon as the accumulated evidence of the risky (positive) class surpass the evidence of the negative one.</p><p>The experiments carried out on the training sets for both tasks were mainly aimed at determining adequate parameters for training the models (classifiers) for the test stage. Preliminary results reported by the Lab's organizers showed that our systems obtained the best (lowest) ERDE 5 error in both pilot tasks and SIC the highest precision for the anorexia detection task providing strong evidence that the used approaches are interesting alternatives to deal with early risk detection tasks.</p><p>The rest of the article is organized as follows: Section 2 gives general information of the data sets used in both pilot tasks and the methods used in our ERD systems. Next, in Section 3 the activities carried out in the training stage are described and the rationale behind the main design decisions made on our ERD systems, are presented. Section 4 shows the performance of our methods on the eRisk 2018 data sets released in the test stage. Finally, Section 5 depicts potential future works and the obtained conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Sets</head><p>The data sets supplied for the eRisk 2018 tasks<ref type="foot" coords="3,320.64,163.81,3.49,6.05" target="#foot_0">4</ref> are described in Losada et al. <ref type="bibr" coords="3,444.76,165.48,10.58,8.64" target="#b5">[6]</ref>. Both collections (for task 1 and task 2) of writings (post or comments) were extracted from Social Media. For each user (document in the data sets), the collections contain a sequence of writings (in chronological order) which has been partitioned into 10 chunks. The first chunk contains the oldest 10 % of the messages, the second chunk contains the second oldest 10%, and so forth. The corpus of task 1 is related to depression and for the task 2 is about anorexia. In the first one, there are two categories of users, "depressed" and "non-depressed", meanwhile in the corpus of anorexia the users are "anorexic" and "non-anorexic". The collection of depression was split into a training and a test set that we will refer as T R DS and T E DS , respectively. The T R DS set contains 887 users (135 positive, 752 negative) and the T E DS set contains 820 users (79 positive, 741 negative). The users labeled as positive are those that have explicitly mentioned that they have been diagnosed with depression. The corpus of anorexia was split into a training and a test set that we will refer as T R AX and T E AX , respectively. The T R AX set contains 152 users (20 positive, 132 negative) and the T E AX set contains 320 users (41 positive, 279 negative). In this case, the users labeled as positive are those that have been diagnosed with anorexia. Each task was divided by their organizers into a training stage and a test stage. In the first one, the participating teams had access to the set of training users with ten chunks of all training users. They could therefore tune their systems with the training data. Then, in the test stage, the ten chunks from test set were gradually released by the organizers one by one until completing all the chunks that correspond to the complete writings of the considered individuals. Each time that a chunk ch i was released, participants in the pilot tasks were asked to give their predictions on the users contained in the test set, based on the partial information read from chunks ch 1 to ch i . Once a class of an incoming stream is predicted, that decision is irreversible (it cannot be undone).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Methods</head><p>To deal with the problems posed in both pilot tasks we used two methods that previously referred as FTVT and HCI, which will describe below. An interesting aspect of those methods is that they are completely independent-domain. Thus, they do not require costly adaptation processes for each task, beyond the tuning of parameters that could depend of the used data set. In fact, due to limitations of time to carry out the experimental study, both methods were only evaluated on the data set of the task 1 (early depression detection) and the same parameters were used for task 2 (early anorexia detection).</p><p>Space constraints prevent us from giving detailed explanations of FTVT and HCI. However, the interested reader can obtain in <ref type="bibr" coords="3,320.95,636.52,11.62,8.64" target="#b0">[1]</ref> more implementation details of the TVT method on which FTVT is based on. SIC is only introduced from an intuitive point of view because the method is currently under review in a scientific journal. <ref type="foot" coords="4,459.40,129.60,3.49,6.05" target="#foot_1">5</ref>Flexible Temporal Variation of Terms (FTVT) The Flexible Temporal Variation of Terms (FTVT) is an improvement of the temporal variation of terms (TVT) method <ref type="bibr" coords="4,466.48,183.11,10.58,8.64" target="#b0">[1]</ref>, an approach for early risk detection that uses the temporal variation of terms between chunks as concept space of a concise semantic analysis (CSA) approach <ref type="bibr" coords="4,425.83,207.02,10.58,8.64" target="#b1">[2]</ref>. The main characteristic of the original TVT is that it allowed to address the unbalance of the minority class with information of the first 4 "chunks" of the users (that number was determined empirically). FTVT provides a more flexible approach than TVT by allowing the specification of a different number of chunks n for the distinct systems. This small extension on TVT is not a minor aspect. Several studies with FTVT showed that, depending on the urgency level required for the ERD task (determined by the threshold o) the number n used in FTVT produces very different ERDE o values. However, beyond this small difference between TVT and FTVT, there is no conceptual differences between both approaches and, therefore, we will only give a short description of the original TVT approach.</p><p>As we previously said, TVT is based on the concise semantic analysis (CSA) technique proposed in <ref type="bibr" coords="4,212.43,352.48,11.62,8.64" target="#b1">[2]</ref> and later extended in <ref type="bibr" coords="4,318.47,352.48,11.62,8.64" target="#b2">[3]</ref> for author profiling tasks. CSA is a semantic analysis technique that interprets words and text fragments in a space of concepts that are close (or equal) to the category labels. For instance, if documents in the data set are labeled with q different category labels (usually no more than 100 elements), words and documents will be represented in a q-dimensional space. That space size is usually much smaller than standard BoW representations which directly depend on the vocabulary size (more than 10000 or 20000 elements in general). CSA has been used in general text categorization tasks <ref type="bibr" coords="4,274.64,436.17,11.62,8.64" target="#b1">[2]</ref> and has been adapted to work in author profiling tasks under the name of Second Order Attributes (SOA) <ref type="bibr" coords="4,360.27,448.12,10.58,8.64" target="#b2">[3]</ref>.</p><p>In this context, the underlying idea of TVT is that variations of the terms used in different sequential stages of the documents may have relevant information for the classification task. With this idea in mind, this method enriches the documents of the minority class with the partial documents read in the first 4 chunks. These chunks correspond to the minority (depressed or positive) class. Also TVT uses the complete documents (chunk 10). All this information is considered as a new concept space for a CSA method.</p><p>TVT naturally copes with the sequential caracteristics of ERD problems and also gives a tool for dealing with unbalanced data sets. Preliminary results of this method in comparison to CSA and BoW representations <ref type="bibr" coords="4,333.71,571.67,11.62,8.64" target="#b0">[1]</ref> showed its potential to deal with ERD problems. FTVT, the variant of TVT used in the present work, arose from our observation that, varying the number n of initial chunks, different performance can be achieved depending on the ERDE o measure used to evaluate the results.</p><p>Sequential Incremental Classification (SIC) Sequential Incremental Classification (SIC) is a very simple method. During the training phase a dictionary of words is built for each category, in which frequency of each word is stored. Then, using those word frequencies, and during classification stage, a value for each word was calculated using a function gv(w, c) to value words in relation to categories. gv takes a word w and a category c and outputs a number in the interval [0,1] representing the degree of confidence with which w is believed to exclusively belong to c, for instance, suppose categories C = {f ood, music, health, sports}, we could have: gv('sushi', f ood) = 0.85; gv('the', f ood) = 0; gv('sushi', music) = 0.09; gv('the', music) = 0; gv('sushi', health) = 0.50; gv('the', health) = 0; gv('sushi', sports) = 0.02; gv('the', sports) = 0; Additionally, -→ gv(w) = (gv(w, c 0 ), gv(w, c 1 ), . . . , gv(w, c k )) is defined, where c i ∈ C (the set of all the categories). That is, -→ gv is only applied to a word and it outputs a vector in which each component is the gv of that word for each category c i . For instance, following the above example, we have: gv('sushi') = (0.85, 0.09, 0.5, 0.02); gv('the') = (0, 0, 0, 0);</p><p>We have called the vector -→ gv(w), the "confidence vector of w". Note that each category c i is assigned a fixed position, i, in -→ gv (for instance, in the example above (0, 0, 0, 0) is the confidence vector of "the" and the first position corresponds to f ood, the second to music, and so on).</p><p>Classification is finally carried out, for each subject, by means of the cumulative sum of all words -→ gv vectors, in symbols:</p><formula xml:id="formula_0" coords="5,274.20,478.68,66.95,25.98">- → d = w∈S -→ gv(w)</formula><p>where S is the subject's writing history. Note that -→ d is a vector with two components, one for the positive class (depressed or anorexic) and one for the negative (control) class. The policy to classify a subject as positive was performed by analyzing how -→ d changed over time (i.e. over "chunks"), as shown with an example in Figure <ref type="figure" coords="5,475.61,554.24,4.98,8.64" target="#fig_0">1</ref> for a depression case. Subjects were classified as depressed when the cumulated positive value exceeded the negative one, for instance the subject in the figure was classified as depressed after reading the 5th chunk.</p><p>It is worth mentioning that, to compute gv we used other two functions, lv and weight, as follows: gv(w, c) = lv σ (w, c) × weight λ (w, c) The more categories c i whose lv σ (w, c i ) is high, the smaller the weight λ (w, c) value. The λ hyperparameter controls how sensitive this sanction is.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setting</head><p>As we mentioned above, this year there were two tasks: one for the early detection of depression cases (task 1) and the other one for the early detection of people with anorexia (task 2). We only used the T R DS data set for setting the parameters of our methods because it is the largest and, therefore, it would seem to be more appropriate to obtain more confident statistics.</p><p>In order to find the best values for the parameters of our methods we perform a five-fold cross validation on the depression training set. Hence, we divided the T R DS set into five folds (see Table <ref type="table" coords="6,247.80,572.28,3.60,8.64" target="#tab_0">1</ref>). These folds maintain the same proportions of both kind of users and were randomly selected. Also each fold was divided into 10 chunks like they were provided by the organizers. We trained the classifiers with four folds and tested with the fifth fold. This process was repeated four times more, always choosing different folds, and later the results were averaged.</p><p>We used the Flexible Temporal Variation of Terms (FTVT) described previously to represent the documents. For this representation, a decision must be made related to the number n of chunks that will enrich the minority (positive) class. We considered different values for n, particularly we selected n from 0 to 5 for setting the initial chunks used.</p><p>FTVT was evaluated with different learning algorithms such as Logistic Regression (LR), Support Vector Machine (SVM) and Naïve Bayes (NB), among others. We used the implementation provided in the Scikit-learn package for Python 2.7 with the default parameters. That is, penalty = l2 and C = 1, for both SVM and LR.</p><p>We used the probability p assigned by the classifier to decide when to stop reading a document and giving its classification. Thus, our approach considered that when the probability p assigned to the positive class exceeds some particular threshold θ (p ≥ θ) the instance/document is classified as positive. We used different thresholds θ: 0.9, 0.8, 0.7 and 0.6.</p><p>We evaluated the performance of our approaches with the early risk detection error (ERDE) measure proposed in <ref type="bibr" coords="7,276.12,392.58,10.58,8.64" target="#b3">[4]</ref>. This measure takes into account not only the correctness of the decision made by the system but also the delay in making that decision. ERDE uses specific costs to penalize false positives and false negatives. However, ERDE has a different treatment with the two possible successful predictions (true negatives and true positives). True negatives have no cost (cost= 0) but ERDE associates a cost to the delay in the detection of true positives that monotonically increases with the number k of textual items seen before giving the answer. In a nutshell, that cost is low when k is lower than a threshold value o but rapidly approaches 1 when k &gt; o. In that way, o represents some type of "urgency" in detecting depression cases: the lowest the o values the highest the urgency in detecting the positive cases. A more detailed description of ERDE can be found in <ref type="bibr" coords="7,255.88,512.13,10.58,8.64" target="#b3">[4]</ref>. We considered the two values of o employed in both editions (2017 and 2018) of this pilot task: o = 5 (ERDE 5 ) and o = 50 (ERDE 50 ).</p><p>Due to space constraints, only combinations of n (parameter of FTVT), θ (probability threshold to classify an instance as positive) and the used classifier that allowed obtaining the best values of ERDE 5 and ERDE 50 metrics, are shown. These results are presented in Tables <ref type="table" coords="7,228.58,572.33,4.98,8.64" target="#tab_1">2</ref> and<ref type="table" coords="7,252.93,572.33,3.74,8.64" target="#tab_2">3</ref>, respectively.</p><p>If we analyze Table <ref type="table" coords="7,232.85,584.71,3.74,8.64" target="#tab_1">2</ref>, it can be seen that small values for n and a high threshold θ (more restrictive) generate a lower ERDE 5 . In particular, the best configuration for ERDE 5 is n = 0 and p ≥ 0.8 with the SVM algorithm obtaining 13.58. A higher threshold means that it is necessary more confidence to classify a user as positive. This is because as the urgency level to decide is also high, what can be classified as positive has to be precise, otherwise the penalty is higher. On the other hand, with regards to the ERDE 50 metric we can see in Table <ref type="table" coords="7,284.95,656.44,4.98,8.64" target="#tab_2">3</ref> that the best thresholds are a little lower than in Table 2 (θ = 0.6 and θ = 0.7). In particular, the best result is 9.59 and is obtained with n = 4, p ≥ 0.7 and SVM as classifier. However, the performance achieved when n = 2 is also good enough.</p><p>From these results we can conclude that FTVT with n = 0 in combination with the SVM classifier and a probability threshold θ = 0.8 seems to be adequate for the ERDE 5 . Hereafter, this configuration will be referred as U N SLA. The FTVT with n = 2 in combination with the Logistic Regression and θ = 0.6 seems to be an adequate balance between ERDE 5 and ERDE 50 (U N SLB). Finally, FTVT with n = 4 in combination with SVM and θ = 0.7 looks as a reasonable alternative for the ERDE 50 metric (U N SLC).</p><p>Regarding SIC, no hyper-parameter optimization was done and the same hyperparameter values were used for both tasks (anorexia and depression). Hyperparameters values were arbitrarily set to σ = 0.5 for both U N SLD and U N SLE, and λ = 3 and λ = 7 for U N SLD and U N SLE, respectively. U N SLD was meant to be less sensitive on penalizing words and thus considering more words as being "important" than U N SLE, hence favoring U N SLD to have a higher recall but with the risk of having a worse precision.</p><p>In summary, from the above study we selected the settings showed in Table <ref type="table" coords="8,464.42,567.24,4.98,8.64" target="#tab_3">4</ref> to participate in the 2018 pilot tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Stage</head><p>Our five systems, three variants of FTVT (U N SLA, U N SLB and U N SLC) and two variants of SIC (U N SLD and U N SLE) were trained with the full training set of the pilot task 1 (T R DS ) and tested with the corresponding T E DS (see Table <ref type="table" coords="8,424.54,656.44,3.82,8.64" target="#tab_4">5</ref>).In the same </p><formula xml:id="formula_1" coords="9,208.68,157.18,191.03,51.90">U N SLA FTVT n = 0, θ = 0.8 SVM U N SLB FTVT n = 2, θ = 0.6 LR U N SLC FTVT n = 4, θ = 0.7 SVM U N SLD SIC σ = 0.5, λ = 3 SIC U N SLE SIC σ = 0.5, λ = 7 SIC</formula><p>way, for task 2 the methods were trained with T R AX and tested with the corresponding T E AX (see Table <ref type="table" coords="9,206.61,248.82,3.60,8.64" target="#tab_5">6</ref>). Both test sets were incrementally released during the testing phase of the pilot tasks. In Table <ref type="table" coords="9,186.38,446.23,4.98,8.64" target="#tab_4">5</ref> we show the results of our 5 submissions and the results of those systems that obtained the best ERDE 5 , ERDE 50 , F 1 , precision and recall in the eRisk depression pilot task as reported in <ref type="bibr" coords="9,277.15,470.14,10.58,8.64" target="#b5">[6]</ref>. Best values are highlighted in boldface. There, we can observe that our U N SLA obtained the best ERDE 5 value. On the other hand, FHDO-BCSGB achieved the best ERDE 50 and F -measure although our U N SLC obtained a value quite similar (slightly worse) for ERDE 50 . U N SLE obtained the 3th best F 1 (0.60) measure (the 1st and the 2nd one belonged to the FHDO-BCSG team) and U N SLD obtained the 2nd best recall (0.85) measure <ref type="foot" coords="9,364.91,528.25,3.49,6.05" target="#foot_2">6</ref> .</p><p>Table <ref type="table" coords="9,174.10,541.87,4.98,8.64" target="#tab_5">6</ref> shows similar results for the anorexia pilot task. As we can see, our system (U N SLB in this case) obtained the best ERDE 5 again and U N SLD the best precision value. At this point it is important to note that we did not perform a parameter optimization of our methods for the anorexia task, such as we stated in the previous section. Then, it is not a minor aspect that our systems can perform well in a different domain from the used for setting the parameters. This independence of domain is such a really important aspect of the classifier systems for the optimization of real tasks.</p><p>With these results, we can conclude that our proposals are very reasonable and competitive alternatives for ERD tasks. This article presented the participation of UNSL at eRisk 2018 Pilot tasks on Early Detection of Depression and Anorexia. We used two completely different approaches to deal with those tasks: one based on the FTVT representation and other on a simple method named SIC. Those approaches showed to be very effective on both types of tasks obtaining the best ERDE 5 value over all participants in both tasks and the best precision value for the anorexia task. Besides, in the ERDE 50 measure, although we did not achieve the best value, our results were very close to it. Thus, the performance of our systems seem to indicate that the used methods are very robust approaches for ERD tasks. However, there are other aspects of our systems that we consider relevant. First of all, they are completely independent of the domain because they only relies on the terms present in the training set. That is to say, they do not require a costly process of feature engineering or very complex hand-crafted features specific of the problem under consideration. That independence was evident in this Lab where only a parameter setting was carried out on one of the data sets (depression) and the same configuration was used in the other one (anorexia). The excellent results obtained in both cases provide strong evidence of this independence and robustness. Another aspect that deserves special attention is that both approaches use very simple rules to decide when to stop reading and classify a user as positive. That contrasts with other approaches that require very complex and difficult to understand methods to make those decisions.</p><p>As future work we plan to extend the use of FTVT and SIC to other ERD problems such as the identification of sexual predators, people with suicide tendency and early rumour detection. In those cases, we consider that the ease and simplicity that our methods provide to be migrated from one domain to another make these applications a rather trivial process.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,134.77,321.56,345.83,8.12;6,134.77,332.87,33.62,7.77;6,137.60,115.83,340.15,190.99"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Subject-9579's cumulated positive and negative confidence values variation over time (chunks).</figDesc><graphic coords="6,137.60,115.83,340.15,190.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,222.11,115.83,171.14,103.27"><head>Table 1 .</head><label>1</label><figDesc>Distribution of the T RDS set in folds.</figDesc><table coords="7,255.10,139.19,105.16,79.90"><row><cell cols="4">Fold Positive Negative Total</cell></row><row><cell>1</cell><cell>27</cell><cell>150</cell><cell>177</cell></row><row><cell>2</cell><cell>27</cell><cell>151</cell><cell>178</cell></row><row><cell>3</cell><cell>27</cell><cell>151</cell><cell>178</cell></row><row><cell>4</cell><cell>27</cell><cell>150</cell><cell>178</cell></row><row><cell>5</cell><cell>27</cell><cell>150</cell><cell>177</cell></row><row><cell cols="2">Total 135</cell><cell>752</cell><cell>887</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,204.87,115.83,205.61,104.21"><head>Table 2 .</head><label>2</label><figDesc>Best performance of FTVT for ERDE5 metric.</figDesc><table coords="8,261.62,139.85,91.63,80.19"><row><cell cols="3">n Classifier θ ERDE5</cell></row><row><cell cols="3">0 SVM 0.8 13.58</cell></row><row><cell>1</cell><cell>LR</cell><cell>0.9 13.75</cell></row><row><cell>2</cell><cell>LR</cell><cell>0.8 13.74</cell></row><row><cell>3</cell><cell>LR</cell><cell>0.9 13.68</cell></row><row><cell cols="3">4 SVM 0.9 13.84</cell></row><row><cell cols="3">5 SVM 0.9 13.87</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,203.05,233.12,209.26,104.21"><head>Table 3 .</head><label>3</label><figDesc>Best performance of FTVT for ERDE50 metric.</figDesc><table coords="8,252.32,257.14,110.22,80.19"><row><cell cols="2">n Classifier</cell><cell>θ ERDE50</cell></row><row><cell>0</cell><cell>SVM</cell><cell>0.6 10.25</cell></row><row><cell cols="3">1 SVM (or LR) 0.6 9.91</cell></row><row><cell>2</cell><cell>LR</cell><cell>0.6 9.61</cell></row><row><cell>3</cell><cell>SVM</cell><cell>0.6 9.77</cell></row><row><cell>4</cell><cell>SVM</cell><cell>0.7 9.59</cell></row><row><cell cols="3">5 SVM (or LR) 0.7 9.69</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,190.62,115.83,234.12,32.08"><head>Table 4 .</head><label>4</label><figDesc>Settings of the submitted approaches.</figDesc><table coords="9,190.62,140.13,234.12,7.77"><row><cell>Submitted approach Method Parameters Learning algorithm</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,184.43,292.02,246.50,126.53"><head>Table 5 .</head><label>5</label><figDesc>Best in the ranking of the depression pilot task (T EDS set).</figDesc><table coords="9,213.83,316.04,187.70,102.51"><row><cell></cell><cell cols="2">ERDE5 ERDE50 F1 π</cell><cell>ρ</cell></row><row><cell>U N SLA</cell><cell>8.78</cell><cell cols="2">7.39 0.38 0.48 0.32</cell></row><row><cell>U N SLB</cell><cell>8.94</cell><cell cols="2">7.24 0.40 0.35 0.46</cell></row><row><cell>U N SLC</cell><cell>8.82</cell><cell cols="2">6.95 0.43 0.38 0.49</cell></row><row><cell>U N SLD</cell><cell>10.68</cell><cell cols="2">7.84 0.45 0.31 0.85</cell></row><row><cell>U N SLE</cell><cell>9.86</cell><cell cols="2">7.60 0.60 0.53 0.70</cell></row><row><cell cols="2">FHDO-BCSGB 9.50</cell><cell cols="2">6.44 0.64 0.64 0.65</cell></row><row><cell>RKMVERIC</cell><cell>9.81</cell><cell cols="2">9.08 0.48 0.67 0.38</cell></row><row><cell>UDCB</cell><cell>15.79</cell><cell cols="2">11.95 0.18 0.10 0.95</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,134.77,115.83,293.07,152.13"><head>Table 6 .</head><label>6</label><figDesc>Best in the ranking of the anorexia pilot task (T EAX set).</figDesc><table coords="10,134.77,139.85,267.01,128.11"><row><cell></cell><cell cols="2">ERDE5 ERDE50 F1 π</cell><cell>ρ</cell></row><row><cell>U N SLA</cell><cell>12.48</cell><cell cols="2">12.00 0.17 0.57 0.10</cell></row><row><cell>U N SLB</cell><cell>11.40</cell><cell cols="2">7.82 0.61 0.75 0.51</cell></row><row><cell>U N SLC</cell><cell>11.61</cell><cell cols="2">7.82 0.61 0.75 0.51</cell></row><row><cell>U N SLD</cell><cell>12.93</cell><cell cols="2">9.85 0.79 0.91 0.71</cell></row><row><cell>U N SLE</cell><cell>12.93</cell><cell cols="2">10.13 0.74 0.90 0.63</cell></row><row><cell cols="2">FHDO-BCSGD 12.15</cell><cell cols="2">5.96 0.81 0.75 0.88</cell></row><row><cell cols="2">FHDO-BCSGE 11.98</cell><cell cols="2">6.61 0.85 0.87 0.83</cell></row><row><cell cols="2">5 Conclusions and future work</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="3,144.73,657.08,106.74,7.77"><p>http://early.irlab.org/task.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="4,144.73,635.17,335.86,7.77;4,144.73,646.13,335.86,7.77;4,144.73,657.08,204.47,7.77"><p>The person interested in deeper technical details of both methods can obtain more information in https://sites.google.com/site/lcagnina/technicalreport-ftvt and https://sites.google.com/site/lcagnina/technicalreport-sic.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="9,144.73,657.08,222.03,7.77"><p>Although, the 1st one (UDCB) had a very low precision (0.1).</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,138.13,624.21,342.46,7.77;10,146.47,635.17,334.12,7.77;10,146.47,645.97,334.12,7.93;10,146.47,657.08,20.17,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,222.78,635.17,254.31,7.77">Temporal variation of terms as concept space for early risk prediction</title>
		<author>
			<persName coords=""><forename type="first">Marcelo</forename><forename type="middle">L</forename><surname>Errecalde</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ma</forename><forename type="middle">Paula</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dario</forename><forename type="middle">G</forename><surname>Funez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ma</forename><forename type="middle">José</forename><surname>Garciarena Ucelay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Leticia</forename><forename type="middle">C</forename><surname>Cagnina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,156.60,645.97,282.77,7.72">Working Notes of CLEF 2017 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1866</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.13,119.96,342.46,7.77;11,146.47,130.77,334.12,7.93;11,146.47,141.88,54.78,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,432.84,119.96,47.75,7.77;11,146.47,130.92,160.39,7.77">Fast text categorization using concise semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">Zhixing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhongyang</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yufang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chunyong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kuan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,317.83,130.77,100.26,7.72">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="441" to="448" />
			<date type="published" when="2011-02">February 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.13,152.84,342.46,7.77;11,146.47,163.80,334.12,7.77;11,146.47,174.60,281.83,7.93" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,275.17,163.80,205.43,7.77;11,146.47,174.76,102.32,7.77">Discriminative subprofile-specific representations for author profiling in social media</title>
		<author>
			<persName coords=""><forename type="first">Adrián</forename><surname>Pastor López-Monroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manuel</forename><surname>Montes Y Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><forename type="middle">Jair</forename><surname>Escalante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luis</forename><surname>Villaseñor-Pineda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,256.05,174.60,94.20,7.72">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="134" to="147" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.13,185.71,342.46,7.77;11,146.47,196.52,334.12,7.93;11,146.47,207.48,148.39,7.93" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,278.68,185.71,201.91,7.77;11,146.47,196.67,10.65,7.77">A test collection for research on depression and language use</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,178.89,196.52,301.70,7.72;11,146.47,207.48,37.27,7.72">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="28" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.13,218.59,342.46,7.77;11,146.47,229.40,334.12,7.93;11,146.47,240.36,312.49,7.93" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,341.99,218.59,138.60,7.77;11,146.47,229.55,176.47,7.77">erisk 2017: Clef lab on early risk prediction on the internet: Experimental foundations</title>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>David E Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Javier</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,340.76,229.40,139.84,7.72;11,146.47,240.36,192.41,7.72">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="346" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.13,251.47,342.46,7.77;11,146.47,262.27,334.12,7.93;11,146.47,273.23,334.12,7.72;11,146.47,284.34,84.26,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,338.23,251.47,142.36,7.77;11,146.47,262.43,66.22,7.77">Overview of eRisk -Early Risk Prediction on the Internet</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Javier</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,227.76,262.27,252.83,7.72;11,146.47,273.23,330.26,7.72">Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the Ninth International Conference of the CLEF Association (CLEF 2018)</title>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.13,295.30,342.46,7.77;11,146.47,306.11,207.68,7.93" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,329.02,295.30,148.30,7.77">A brief survey on sequence classification</title>
		<author>
			<persName coords=""><forename type="first">Zhengzheng</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eamonn</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,146.47,306.11,132.77,7.72">ACM Sigkdd Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="48" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
