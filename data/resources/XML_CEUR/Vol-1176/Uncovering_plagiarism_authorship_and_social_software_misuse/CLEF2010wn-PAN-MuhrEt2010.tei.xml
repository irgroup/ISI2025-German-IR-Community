<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,150.37,115.90,314.61,12.90;1,153.37,133.83,308.61,12.90;1,218.28,154.07,178.79,10.75">External and Intrinsic Plagiarism Detection using a Cross-Lingual Retrieval and Segmentation System Lab Report for PAN at CLEF 2010</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,172.65,190.86,52.63,8.64"><forename type="first">Markus</forename><surname>Muhr</surname></persName>
							<email>mmuhr@know-center.at</email>
							<affiliation key="aff0">
								<orgName type="institution">Know-Center Graz</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,232.70,190.86,49.00,8.64"><forename type="first">Roman</forename><surname>Kern</surname></persName>
							<email>rkern@know-center.at</email>
							<affiliation key="aff0">
								<orgName type="institution">Know-Center Graz</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,288.62,190.86,57.58,8.64"><forename type="first">Mario</forename><surname>Zechner</surname></persName>
							<email>mzechner@know-center.at</email>
							<affiliation key="aff0">
								<orgName type="institution">Know-Center Graz</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,369.95,190.86,72.76,8.64"><forename type="first">Michael</forename><surname>Granitzer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Know-Center Graz</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,150.37,115.90,314.61,12.90;1,153.37,133.83,308.61,12.90;1,218.28,154.07,178.79,10.75">External and Intrinsic Plagiarism Detection using a Cross-Lingual Retrieval and Segmentation System Lab Report for PAN at CLEF 2010</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B461E50156F5FB70F05EAEFD92B30676</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present our hybrid system for the PAN challenge at CLEF 2010. Our system performs plagiarism detection for translated and non-translated externally as well as intrinsically plagiarized document passages. Our external plagiarism detection approach is formulated as an information retrieval problem, using heuristic post processing to arrive at the final detection results. For the retrieval step, source documents are split into overlapping blocks which are indexed via a Lucene instance. Suspicious documents are similarly split into consecutive overlapping boolean queries which are performed on the Lucene index to retrieve an initial set of potentially plagiarized passages. For performance reasons queries might get rejected via a heuristic before actually being executed. Candidate hits gathered via the retrieval step are further post-processed by performing sequence analysis on the passages retrieved from the index with respect to the passages used for querying the index. By applying several merge heuristics bigger blocks are formed from matching sequences. German and Spanish source documents are first translated using word alignment on the Europarl corpus before entering the above detection process. For each word in a translated document several translations are produced. Intrinsic plagiarism detection is done by finding major changes in style measured via word suffixes after the documents have been partitioned by an linear text segmentation algorithm. Our approach lead us to the third overall rank with an overall score of 0.6948.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Plagiarism detection has gained increased interest in research as well as in the industry <ref type="bibr" coords="1,134.77,548.06,11.62,8.64" target="#b7">[8]</ref> over the last couple years. The PAN challenge accommodated this fact and provided researchers a basis to compare different approaches.</p><p>We refrain from giving an introduction on plagiarism detection as Grozea et. al <ref type="bibr" coords="1,468.97,572.36,11.62,8.64" target="#b1">[2]</ref> formulated an excellent overview of the matter in last year's lab report. Instead we will discuss the motivation for our approach for this year's challenge.</p><p>The first three ranked participants in the first PAN competition all used a documentcentric approach for external plagiarism detection as presented in <ref type="bibr" coords="1,407.25,620.57,10.58,8.64" target="#b5">[6]</ref>. Our approach in last year's competition was based on a block-level comparison of source and suspicious documents. Although our approach yielded acceptable results it was clear that the chosen block granularity, non-overlapping sentences, does not perform exceptionally well. To identify similar suspicious and source blocks we used a simple cluster pruning technique which, while easy to implement, also introduced several problems.</p><p>To improve on our last approach we reformulated our problem solution slightly. Instead of comparing non-overlapping blocks of sentences we used overlapping blocks of tokens with fixed sizes. The cluster pruning technique was replaced by an open-source document search engine called Lucene 1 . Source documents are first split into overlapping blocks. Each block is then indexed by a Lucene instance. Suspicious documents are similarly split into overlapping blocks which get transformed to boolean Lucene queries. Each query results in a ranked list of potentially plagiarized source blocks.</p><p>We also reworked our post-processing step. We adapted an approach based on sequence analysis similar to dot-plot <ref type="bibr" coords="2,274.10,238.86,11.62,8.64" target="#b6">[7]</ref> with further heuristic merging and filtering steps to increase the overall precision of the system.</p><p>In last years competition none of the participants tried to solve the cross-lingual plagiarism subtask. We decided to give it a try in this year's challenge, building upon techniques developed in the machine translation community. We performed word alignment with the BerkleyAligner software package <ref type="bibr" coords="2,306.16,298.64,11.62,8.64" target="#b4">[5]</ref> using the Europarl corpus <ref type="bibr" coords="2,425.80,298.64,11.62,8.64" target="#b3">[4]</ref> to provide us with potential translations for each word in German or Spanish source documents.</p><p>Intrinsic plagiarism detection <ref type="bibr" coords="2,272.99,322.55,11.62,8.64" target="#b0">[1]</ref> seems to be a much harder task which is supported by the fact that less related work is available. Last year's competition supports this notion as only one competitor (Stamatatos <ref type="bibr" coords="2,331.66,346.46,15.93,8.64" target="#b9">[10]</ref>) could beat the baseline. Previous approaches used stylometric features or semi-stylometric features like character n-grams on sliding windows over the text to form a mean vector. A major difference of a certain block to this mean vector is expected to mark a style change which is interpreted as author change and therefore plagiarism. This year we tried to detect intrinsic plagiarism by adapting the text segmentation algorithm from Kern et. al. <ref type="bibr" coords="2,423.56,406.24,11.62,8.64" target="#b2">[3]</ref> to segment a document into stylometric coherent segments to identify plagiarism instead of topic coherent segments.</p><p>To sum up our system consists of the following basic ideas which is outlined by a flowchart in figure <ref type="figure" coords="2,210.61,454.06,4.98,8.64" target="#fig_0">1</ref> -The external task is interpreted as retrieval task on a sub-document level -Post-processing based on sequence analysis with merge and filter heuristics -Translation on a word level by using word alignment of Europarl as translations -Intrinsic plagiarism detection using text segmentation by detecting ad hoc flows in the text due to style changes -Merging intrinsic and external plagiarism (intrinsic blocks are only taken, if there are none external ones for a specific document)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">External Plagiarism Detection</head><p>Our external plagiarism detection approach consists of two main steps. In the first step we search for potentially matching suspicious document blocks within an inverted index of overlapping source document blocks. In the second step we apply heuristic postprocessing on the potential matches to arrive at the final detection result. For Non-English source documents we have an additional pre-processing step to get translations  for each word in the Spanish or German source documents. Furthermore, the postprocessing step has to be slightly modified for translated plagiarism detection.</p><p>Translating Non-English Documents using Word Alignment To detect cross-lingual plagiarism we build upon techniques developed in the field of machine translation. Instead of applying a complete machine translation solution to translate whole documents or sentences we took the output of a word alignment algorithm. This kind of algorithm tries to find pairs of words that might be used as translation candidates and are a main component of many state-of-the-art machine translation systems. The base of the word alignment algorithms is a set of documents that are aligned on a sentence level. We used the Europarl aligned corpus (Release 5) <ref type="bibr" coords="3,322.72,507.09,10.58,8.64" target="#b3">[4]</ref>. To calculate the aligned words we employed the BerkeleyAligner<ref type="foot" coords="3,259.25,517.38,3.49,6.05" target="#foot_0">2</ref> software package <ref type="bibr" coords="3,340.53,519.04,10.58,8.64" target="#b4">[5]</ref>. The output of the word alignment algorithm is a list of English translation candidates for the German and Spanish words present in the Europarl corpus. For each source document that is not written in English we replaced each word with up to 5 translation candidates. If no translation candidate is available, the word is not replaced. After the words have been replaced the documents are treated similar like the English source documents.</p><p>Overlapping Source Blocks Indexing The translated as well as non-translated source documents were each transformed into overlapping blocks of 40 tokens. For translated passages 40 refers to words in the original text, so that the actual translated passage may have more words due to the replacement with up to five translations. These blocks are indexed via a Lucene instance. Besides the text of each block we also stored additional information such as the offset and length of each block in the source document as well as the ID of the source document the block originated from.</p><p>Heuristics to limit Executed Suspicious Queries Similarly to the source documents the suspicious documents were tokenized and overlapping blocks of tokens were transformed to boolean queries. As this results in a massive amount of potential queries we applied several heuristics to limit the overall complexity of our approach while trying to keep the recall of correct hits reasonable high.</p><p>The first heuristic employed was the selection of a window step size of 6 and a window size of 16 tokens for each block. We arrived at this settings after testing various combinations on a small development corpus. Each query is only executed if at least one of the tokens in it has a normalized document frequency below a given threshold (0.004 for the evaluation corpus). Note that a document is really a block of a document.</p><p>The terms of the boolean query are first sorted by their corpus frequency in increasing order. The first four terms of this sorted list must be included (AND query), the other 12 terms (OR query) are determining the final rank of a hit in the list of ranked query results. By this technique we can ease the work load of the search engine as it can prune many documents due to the limitation that the four least frequent terms must be included in the query results. We further prune the query result by only using blocks which have a score above a certain threshold. After some testing on the development set we arrived at a threshold of 8.0. By adjusting these mentioned parameters, one can alter the trade-off between the number of potential hits (recall) and the number of query invocations (faster runtime).</p><p>Although translations have more words in common due to multiple translations for each word, we did not see major changes for the results when using the same parameter settings. Finally, we store the offset and length in the suspicious document for each executed query as well as the source document ID with offset and length for each block found for a query.</p><p>Post-Processing using Word Sequence Analysis with Merge Heuristics and Similarity Filtering The retrieved potential plagiarized blocks must now be refined and filtered. The advantage of our approach is that the locations in the source and suspicious documents are roughly known after the retrieval part, so that we can neglect a detailed post-processing on whole document pairs. What we did so far was taking a suspicious document, split it into queries and search for potentially matching blocks for each query. As a first step we generate lists of query-block pairs. Note that a single query can have multiple matching blocks and thus generate several query-block pairs. Given a query-block pair we extend the text around the query in the suspicious document as well as the text around the block in the source document by a number of characters (2000 for the evaluation set). Given the offset of both the query and the source document block we can align these two extended text passages. The alignment is given in form of a token by token matrix on which we apply the sequence analysis. A bigger window around the query-block pair leads to higher run-time, but can detect the passages more accurately. A sequence of tokens in both texts is a match if the sequence is composed of at least 3 consecutive tokens and has a length of at least 10 characters.</p><p>As with other settings we arrived at these by playing with the development set. For translated source documents the sequence analysis is a little bit less strict to compensate the incomplete translation we used. In this case the minimum length of sequence must be 6, but gaps are allowed between consecutive words in the suspicious document. Furthermore, the order of consecutive words in a suspicious document must not be the same in the source document, in other words a match must be found in a window of 10 tokens in the source document to count as a match.</p><p>The result is a list of sequence matches grouped by the source document they arose from. These matches are potentially small and we thus try to further merge them in a follow-up step. First we inspect all sequence matches originating from the same source document and eliminate those that do not have other sequence matches in their neighbor hood (defined as the surrounding 3000 characters) in said source document and are smaller than 50 characters.</p><p>Next we merge all sequence matches in the suspicious document that point to the same source document. Sequences are again matched via a neighbor hood criterion. However, this time the neighborhoods in both the suspicious document as well as the source document are considered. For sequence matches to be merged they have to be within a 500 character neighborhood in the suspicious document and within a 3000 character neighborhood in the source document. This can result in asymmetrically sized spans in the source and suspicious document. After this merging step we remove any matches smaller than 200 characters.</p><p>The final list of merged sequence matches are filtered on more time by calculating a Jaccard Similarity between the suspicious document sequence text and the source document sequence text. Sequence matches smaller than 5000 characters are eliminated if their similarity is smaller than 0.55, bigger matches must have a minimum similarity of 0.7 in order to be accepted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Intrinsic Plagiarism Detection</head><p>The main idea of the intrinsic plagiarism detection algorithm is to detect changes in the style within a document. Base of our approach is a function that transforms a sequence of tokens (words, punctuations, ...) into a set of features that should represent the style of the author. Many different stylometric features have been proposed in the past. Among them are feature transformation functions based on parts of the word, for example character n-grams. Other stylometric features are constructed by using just a subset of words or tokens, for example pronouns. The usage and frequency of punctuation marks have also been investigated as a proxy for specific writing styles.</p><p>For our intrinsic plagiarism detection system we experimented with two different stylometric feature functions:</p><p>-Stop-words -This feature transformation is motivated by the intuition that different authors tend to resort to different stop words to construct grammatically correct sentences. For this feature transformation function to work all words need to be annotated as either function word or content word. This is accomplished by looking up all words in a manually crafted stop word list. All words that have been identified as stopword are added to the feature set and their frequency is additionally recorded. The remaining function words are ignored by this feature transformation function. As stop word list we took the stop word lists from the Snowball stemmer project. These list are available in a number of languages and also contain the set of pronouns. -Stem-Suffix -The last characters of words have already been used to identify specific author styles. The motivation for this feature transformation is the assumption that different authors may differ in their use of flections. One possible approach for this kind of function is to pick the last n characters of each words, where n is usually set to 3. For our system we used a flexible number of suffix characters. The suffix was determined by the number of characters a stemming algorithm would cut off or replace (we utilized the Snowball stemmer for this task). Finally this function produces a set of word suffixes.</p><p>To detect areas within a document that are written in a different style we first created a feature set out of the complete document, which can be seen as centroid of the whole document. This procedure assumes that the document is mostly written by a single author and the plagiarized sections do not cover the majority of the document. Next the document is split into blocks. This step is needed because the set of generated features by the stylometric transformation function tend to be sparse if applied on the sentence level. Partitioning the document into blocks of equal size (number of sentences) would be the most straightforward way to achieve this. For our system we have chosen to make use of a linear text segmentation algorithm <ref type="bibr" coords="6,338.07,367.24,10.58,8.64" target="#b2">[3]</ref>. Instead of producing blocks of equal size, the output of this algorithm is a list topically coherent blocks of multiple sentences. To identify changes in topics all words are first filtered out for stop-words and then stemmed. For each of the identified blocks a stylometric feature representation is generated. This set of features is then compared with the document-wide feature set, by calculating the cosing similarity. If the difference of the two feature sets exceeds a certain threshold, the block is considered to be written by another author than the majority of the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>This section starts with a short summary of the multiple parameters of our approach. Afterwards, we present and discuss detailed results on the development and on the evaluation corpus. We evaluate the quality of the retrieval step as well as provide performance measures for different obfuscation levels (none, low, high), for translated and non-translated plagiarism. Furthermore, we will compare our performance on external and intrinsic plagiarism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Parameter Settings</head><p>We have multiple parameters used on each step of our approach. Since they have all been mentioned in the detailed description of our method, we just want to summarize them in table 4.1. We have to admit that our approach has many parameters, but as a matter of fact we did not really optimize them with the exception of the merge and filter parameters. The parameters for the index and search step affect only the trade-off between precision and runtime, so a setting was used that gives a good precision with a reasonable runtime.  Furthermore, in table 4.2 a detailed evaluation of our detected plagiarism after the post-processing steps (sequence analysis, merge heuristics, similarity thresholding) is shown. Surprisingly our cross-lingual approach performs better than the plain English one in terms of recall and precision with a worse granularity. However, if we take a closer look this is mostly because of our quite bad performance on highly obfuscated plagiarism. High obfuscation means a high level of paraphrasing, exchanging words by synonyms, etc. which we do not deal with specifically. On the other hand for low and none obfuscation our results are better than the cross-lingual approach. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Corpus</head><p>In contrast to the development corpus the evaluation corpus does not explicitly separate external and intrinsic plagiarism, since in this years competition the winner should develop a hybrid system that can handle both types of plagiarism. Nevertheless, the following evaluation will distinguish between the different kinds of plagiarism considered as sub-tasks of the global problem. A detailed description of this corpus can be found in the overview paper. In table 4.3 the results of the retrieval step for the evaluation corpus are shown. In contrast to the results on the development corpus even for high obfuscated plagiarism we hit most of the blocks and the difference to low and none obfuscated passages is much less significant. However, for low and none obfuscation the results are also higher compared to the development corpus. Surprisingly, translated blocks are a little bit worse, but since we only used a split of 500 of the development corpus the amount of translated passages will most likely be smaller, so that the difference lies in statistical limits of variance. The retrieval step delivered a total of 1.7642292E7 query -block pairs, from which 1.4431375E7 are correct (are partially overlapping with a real plagiarism), so the ratio increased as well from 71.42 % to 81.8 %.This shows that heuristics like ranking score seem to be reasonable good to achieve very high recall values with a very good precision in this initial step. Furthermore, in table 4.3 a detailed evaluation of the final detected plagiarism blocks are shown. In contrast to the results on the development corpus our cross-lingual approach performs worse than the plain English plagiarism detection. This can be explained by the fact that on the evaluation corpus the recall on high-obfuscated plagiarism detection increased to 0.8122 compared to 0.4706 on the development corpus. For low and none obfuscation the recall values are in similar ranges, so that the overall evaluation on non-translated plagiarism detection could be increased considerable. Again it can be recognized that our performance on the translated blocks are especially bad concerning granularity, so it seems to be the case that there are several holes in the detected passages. As expected our performance on the intrinsic plagiarism detection sub-task is very poor and might have deteriorated our overall result more than expected. Despite the good results we have to admit that our current implementation is not very fast. The whole process takes about a week. However, we did not optimize our approach in any kind. There are many possible ways to improve our approach. For example, we can utilize some prefiltering on document basis or try to distribute our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We scored the 3rd place in the overall ranking of all systems, with our recall values being very close to the winning system. The precision of our system is still an area to be improved in future iterations. We attribute the performance of your system with respect to precision mainly to the results from the intrinsic plagiarism detection system which lowers the overall precision considerably. The post-processing step also needs some more tuning as evidenced by the poor granularity achieved.</p><p>We plan on transforming our approach into a web-service, seeded by the articles of Wikipedia as a source corpus. Handling other types of plagiarism such as stealth approaches or missing citations are also on our agenda. We'd also like to increase the scalability and performance of our system by employing distributed indices along with document-level cluster pruning for large datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,134.77,330.59,345.83,8.12;3,134.77,341.89,345.82,7.77;3,134.77,352.85,229.68,7.77"><head>Figure 1 .</head><label>1</label><figDesc>Figure1. This flowchart gives an overview over the different stages of our plagiarism detection system. The left part shows the indexing process of the source blocks while the right side presents our hybrid system of intrinsic and external plagiarism detection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,136.47,163.47,306.78,62.77"><head>Table 1 .</head><label>1</label><figDesc>Parameter settings for the external task. (suspicious) with a real plagiarism block), so 71.42 % of the pairs are correct ones.</figDesc><table coords="7,136.47,184.63,306.78,41.60"><row><cell>parameter</cell><cell>value</cell><cell>workflow step</cell></row><row><cell>sliding block length (source)</cell><cell>40</cell><cell>indexing</cell></row><row><cell>sliding block step (source)</cell><cell>20</cell><cell>indexing</cell></row><row><cell>sliding query length</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,134.77,152.69,345.82,106.20"><head>Table 2 .</head><label>2</label><figDesc>Performance evaluation of retrieval step for a sub set of 500 suspicious documents of the development corpus. The table shows values for the number of blocks that have been hit at least by one query -block pair in the retrieval step, the number of real plagiarism blocks in the suspicious documents and a ratio between these two.</figDesc><table coords="8,255.80,206.73,103.75,52.16"><row><cell>task</cell><cell>hit all ratio</cell></row><row><cell>high</cell><cell>2543 3676 0.6918</cell></row><row><cell>low</cell><cell>6614 6988 0.9465</cell></row><row><cell>none</cell><cell>9381 9592 0.9780</cell></row><row><cell cols="2">translated 2349 2543 0.9237</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,134.77,377.63,345.83,137.23"><head>Table 3 .</head><label>3</label><figDesc>Performance results of detected plagiarism separated by different sub-tasks for a sub set of 500 suspicious documents of the external development corpus and for the whole set of the intrinsic development corpus. Performance measures include precision, recall, granularity and the overall score.</figDesc><table coords="8,203.59,429.82,208.18,85.04"><row><cell>task</cell><cell cols="4">Precision Recall Granularity Score</cell></row><row><cell>non-translated all</cell><cell cols="2">0.5623 0.8105</cell><cell>1.071</cell><cell>0.6321</cell></row><row><cell>non-translated none</cell><cell>-</cell><cell>0.9619</cell><cell>1</cell><cell>-</cell></row><row><cell>non-translated low</cell><cell>-</cell><cell cols="2">0.8338 1.1709</cell><cell>-</cell></row><row><cell>non-translated high</cell><cell>-</cell><cell>0.4706</cell><cell>1.0</cell><cell>-</cell></row><row><cell>translated</cell><cell cols="2">0.8441 0.732</cell><cell cols="2">2.2785 0.4576</cell></row><row><cell>external</cell><cell cols="4">0.6211 0.7977 1.2618 0.5931</cell></row><row><cell>intrinsic</cell><cell cols="2">0.4709 0.245</cell><cell cols="2">1.0006 0.3221</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,134.77,247.38,345.82,95.24"><head>Table 4 .</head><label>4</label><figDesc>Performance evaluation of retrieval step on the evaluation corpus. The table shows values for the number of blocks that have been hit at least by one query -block pair in the retrieval step, the number of real plagiarism blocks in the suspicious documents and a ratio between these two.</figDesc><table coords="9,243.44,290.47,128.47,52.16"><row><cell>task</cell><cell cols="3">correct maximum ratio</cell></row><row><cell>high</cell><cell cols="3">13348 14756 0.9046</cell></row><row><cell>low</cell><cell cols="3">14832 14883 0.9966</cell></row><row><cell>none</cell><cell cols="2">16784 16784</cell><cell>1.0</cell></row><row><cell cols="2">translated 5462</cell><cell cols="2">6314 0.8651</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,134.77,527.76,345.83,137.63"><head>Table 5 .</head><label>5</label><figDesc>Performance results of detected plagiarism separated by different sub-tasks for the hybrid evaluation corpus. Performance measures include precision, recall, granularity and the overall score.</figDesc><table coords="9,201.35,568.99,212.66,96.39"><row><cell>task</cell><cell cols="4">Precision Recall Granularity Score</cell></row><row><cell>non-translated all</cell><cell cols="2">0.9299 0.8967</cell><cell cols="2">1.0553 0.8785</cell></row><row><cell>non-translated none</cell><cell>-</cell><cell>0.9497</cell><cell>1.0025</cell><cell>-</cell></row><row><cell>non-translated low</cell><cell>-</cell><cell>0.9207</cell><cell>1.0968</cell><cell>-</cell></row><row><cell>non-translated high</cell><cell>-</cell><cell>0.8122</cell><cell>1.0771</cell><cell>-</cell></row><row><cell>translated</cell><cell cols="4">0.8036 0.61616 2.1655 0.4195</cell></row><row><cell>external</cell><cell cols="2">0.9053 0.8631</cell><cell cols="2">1.1611 0.7949</cell></row><row><cell>intrinsic</cell><cell cols="2">0.212 0.1566</cell><cell>1.0</cell><cell>0.1802</cell></row><row><cell>Overall</cell><cell cols="2">0.8417 0.7057</cell><cell cols="2">1.1508 0.6948</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="3,144.73,657.08,150.20,7.77"><p>http://code.google.com/p/berkeleyaligner/</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As processing unit we used a desktop machine with a Intel Core 2 quad-core CPU (2.66 GHz) with 8 GB DDR2 RAM and a 1 Terra-byte hard disk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Development Corpus</head><p>The development corpus was the same one as in the first PAN competition from 2009 (a detailed description can be found in <ref type="bibr" coords="7,297.45,512.97,10.45,8.64" target="#b8">[9]</ref>). Since our approach is not very fast, we optimized our approach on a sub set of 500 suspicious documents, so the following performance measures are computed only for this sub set. However, note that as basis for the retrieval step still the complete set of source documents was used.</p><p>In table 4.2 the results of the retrieval step are shown. Basically the table shows the number of all real plagiarism blocks in the data set and the ones which are hit at least by one query -block pair. In other words, these are the blocks our post-processing step can extract at best (upper bound on the recall). These results show that we only loose a considerable amount of the high obfuscated blocks, but a very high percentage (above 90 %) of low or none obfuscated as well as translated plagiarism have been hit after the retrieval step. The difference for high obfuscated plagiarism can be explained by the fact that we do not handle for example synonyms which represent a big part of the deterioration of high-obfuscated plagiarism. The retrieval step delivered a total of</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.61,395.47,311.19,7.77;10,150.95,406.43,215.00,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,247.35,395.47,103.83,7.77">Intrinsic plagiarism detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Eissen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="10,369.13,395.47,84.67,7.77;10,150.95,406.43,64.47,7.77">ECIR. Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">3936</biblScope>
			<biblScope unit="page" from="565" to="569" />
			<date type="published" when="2006">2006</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,417.25,324.91,7.77;10,150.95,428.21,312.92,7.77;10,150.95,439.17,191.42,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,277.96,417.25,189.57,7.77;10,150.95,428.21,135.20,7.77">ENCOPLOT: Pairwise Sequence Matching in Linear Time Applied to Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grozea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gehl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,304.31,428.21,159.57,7.77;10,150.95,439.17,141.08,7.77">3rd PAN Workshop. Uncovering Plagiarism, Authorship and Social Software Misuse</title>
		<imprint>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,449.98,325.07,7.77;10,150.95,460.94,199.63,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,238.77,449.98,228.91,7.77;10,150.95,460.94,36.90,7.77">Efficient linear text segmentation based on information retrieval techniques</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Granitzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,205.99,460.94,43.27,7.77">MEDES &apos;09</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="167" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,471.76,322.82,7.77;10,150.95,482.71,48.56,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,190.00,471.76,218.28,7.77">Europarl: A parallel corpus for statistical machine translation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,413.86,471.76,42.60,7.77">MT summit</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="12" to="16" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,493.53,324.04,7.77;10,150.95,504.49,272.86,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,265.43,493.53,87.44,7.77">Alignment by agreement</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,371.27,493.53,95.38,7.77;10,150.95,504.49,175.56,7.77">Proceedings of the Human Language Technology Conference of the NAACL</title>
		<meeting>the Human Language Technology Conference of the NAACL</meeting>
		<imprint>
			<date type="published" when="2006-06">June 2006</date>
			<biblScope unit="page" from="104" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,515.30,315.66,7.77;10,150.95,526.26,301.11,7.77;10,150.95,537.22,306.44,7.77;10,150.95,548.18,138.46,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,284.70,515.30,173.57,7.77;10,150.95,526.26,301.11,7.77;10,150.95,537.22,62.79,7.77">A theoretical basis to the automated detection of copying between texts, and its practical implementation in the Ferret plagiarism and collusion detector</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lyon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Malcolm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,231.64,537.22,225.76,7.77;10,150.95,548.18,70.25,7.77">JISC (UK) Conference on Plagiarism: Prevention, Practice and Policies Conference</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,559.00,302.93,7.77;10,150.95,569.95,317.25,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,226.41,559.00,219.13,7.77;10,150.95,569.95,34.73,7.77">Enhanced graphic matrix analysis of nucleic acid and protein sequences</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Maizel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Lenk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,203.99,569.95,178.29,7.77">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="page" from="7665" to="7669" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,580.77,332.64,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,277.62,580.77,73.73,7.77">Plagiarism -a survey</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Maurer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kappe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,357.20,580.77,25.41,7.77">J. UCS</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1050" to="1084" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,591.59,311.09,7.77;10,150.95,602.54,315.22,7.77;10,150.95,613.50,243.23,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,383.09,591.59,70.61,7.77;10,150.95,602.54,180.34,7.77">Overview of the 1st International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Eiselt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barron-Cedeno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,349.45,602.54,116.72,7.77;10,150.95,613.50,183.92,7.77">3rd PAN Workshop. Uncovering Plagiarism, Authorship and Social Software Misuse</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,624.32,338.35,7.77;10,150.95,635.28,311.47,7.77;10,150.95,646.24,23.90,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,207.11,624.32,224.65,7.77">Intrinsic Plagiarism Detection Using Character n-gram Profiles</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,449.36,624.32,31.23,7.77;10,150.95,635.28,269.35,7.77">3rd PAN Workshop. Uncovering Plagiarism, Authorship and Social Software Misuse</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="38" to="46" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
