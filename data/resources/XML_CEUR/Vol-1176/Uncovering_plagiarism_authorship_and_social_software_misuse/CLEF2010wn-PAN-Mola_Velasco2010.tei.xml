<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,153.57,115.90,308.23,12.90;1,164.73,133.83,280.41,12.90;1,445.14,131.72,4.98,8.74;1,218.28,153.89,178.79,10.75">Wikipedia Vandalism Detection Through Machine Learning: Feature Review and New Proposals * Lab Report for PAN at CLEF 2010</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,254.83,190.50,72.23,8.64"><forename type="first">Santiago</forename><forename type="middle">M</forename><surname>Mola</surname></persName>
						</author>
						<author>
							<persName coords="1,329.55,190.50,30.98,8.64;1,295.20,212.03,24.95,7.77"><forename type="first">Velasco</forename><surname>Private</surname></persName>
						</author>
						<title level="a" type="main" coord="1,153.57,115.90,308.23,12.90;1,164.73,133.83,280.41,12.90;1,445.14,131.72,4.98,8.74;1,218.28,153.89,178.79,10.75">Wikipedia Vandalism Detection Through Machine Learning: Feature Review and New Proposals * Lab Report for PAN at CLEF 2010</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3297951D251F6CFD29AD213837595DAE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Wikipedia is an online encyclopedia that anyone can edit. In this open model, some people edits with the intent of harming the integrity of Wikipedia. This is known as vandalism. We extend the framework presented in <ref type="bibr" coords="1,418.12,287.39,34.12,7.77;1,163.11,298.34,93.24,7.77" target="#b6">(Potthast, Stein, and Gerling, 2008)</ref> for Wikipedia vandalism detection. In this approach, several vandalism indicating features are extracted from edits in a vandalism corpus and are fed to a supervised learning algorithm. The best performing classifiers were LogitBoost and Random Forest. Our classifier, a Random Forest, obtained an AUC of 0.92236, ranking in the first place of the PAN'10 Wikipedia vandalism detection task. * Thanks to the PAN'10 organizers, to the reviewers,</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Wikipedia is an online encyclopedia built upon the collaborations of thousands of editors. Its collaboration model is simple: anyone can edit any article at any time. This has made possible the great success of Wikipedia, but it comes with its own problems, one of them being destructive edits. There are many ways in which an edit can be destructive for Wikipedia, such as lobbying, spam, vandalism, tests, etc.</p><p>In PAN 2010 Lab's Task 2 we are focused on automatic detection of vandalism. The English Wikipedia defines vandalism as: [...] any addition, removal, or change of content made in a deliberate attempt to compromise the integrity of Wikipedia. <ref type="bibr" coords="1,319.41,518.98,14.11,8.64">[...]</ref> Common types of vandalism are the addition of obscenities or crude humor, page blanking, and the insertion of nonsense into articles. Any good-faith effort to improve the encyclopedia, even if misguided or illconsidered, is not vandalism. Even harmful edits that are not explicitly made in bad faith are not vandalism. <ref type="bibr" coords="1,151.70,591.13,127.51,8.64">(Wikipedia contributors, 2010a)</ref> The Wikipedia community maintains a project for studying vandalism (Wikipedia contributors, 2010b) and develops bots for automatic detection and reversion. Currently, the most prominent active bot in the English Wikipedia is ClueBot, a rule-based system. <ref type="bibr" coords="2,155.19,131.27,56.54,8.64" target="#b1">(Carter, 2010)</ref> ClueBot's rules rely on length increment of the edit and a scoring system based on regular expressions checking vulgarisms, grammar, etc. This system achieves a precision near to 1 but a very low recall. Similar systems can be found in other Wikipedias, such as AVBOT <ref type="bibr" coords="2,274.29,167.13,106.25,8.64" target="#b8">(Rodríguez Posada, 2010)</ref> in the Spanish edition. <ref type="bibr" coords="2,149.71,179.92,147.07,8.64" target="#b6">(Potthast, Stein, and Gerling, 2008)</ref> defined Wikipedia vandalism detection as a classification task, proposed a set of discriminating features and provided evaluation of them based on machine learning. Our work is founded in that definition, extending the set of features proposed in their work. We have built a system trying to reproduce previous results, and afterwards, extended it with a new range of features and tuning of previous ones.</p><p>We have used the PAN-WVC-10 corpus <ref type="bibr" coords="2,316.87,252.47,62.66,8.64" target="#b5">(Potthast, 2010)</ref>. The training set of this corpus comprises 15000 annotated edits, 924 of which are labeled as vandalism. Our goal is building a vandalism classifier using this corpus.</p><p>The rest of the paper is structured as follows. In Section 2 of this article, we will describe the preprocessing we have applied to the data. In Section 3 we discuss all edit features that we have used. In Section 4 we present the classifiers we have used.</p><p>In Section 5 we will evaluate our features and classifiers and present the classifier we have used for the PAN'10 result submission. Finally, we will present our conclusions in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preprocessing</head><p>In our feature framework, we have defined different representations of edits to use in different features. In this section we will describe these representations and the steps to construct them.</p><p>First, we defined a tokenization function. A token can be a word, a number, a punctuation mark or a wiki-syntax element. When describing features, we will consider a word as any of these tokens. The following symbols are considered independent tokens: ., ,, :, ;, ", «, », ', |, ?, !, =, (, ), * , [[, ]], <ref type="bibr" coords="2,356.44,486.50,15.19,7.01">[. ]</ref>, {{, }}, { and }.</p><p>We also need to produce diffs between the old and new revisions of an edit. To that end, we used google-diff-match-patch. <ref type="foot" coords="2,288.62,508.63,3.49,6.05" target="#foot_0">1</ref>Using these funcions, we define the following representations of edit text:</p><p>-Old text and new text. The old and new without any preprocess.</p><p>-Case-sensitive inserted words. The set of inserted words.</p><p>-Inserted words. The set of inserted words, and converted to lowercase.</p><p>-Concatenated inserted words. All inserted words concatenated and separated with spaces. This is defined both case-sensitive and insensitive. -Inserted text. Inserted lines as reported by the diff algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Edit Features</head><p>In this section, we describe our set of features. Features based on dictionaries will be explained separately. Features marked with * were already defined in <ref type="bibr" coords="3,416.75,153.68,63.84,8.64;3,134.77,165.64,76.18,8.64" target="#b6">(Potthast, Stein, and Gerling, 2008)</ref> and those marked with † are modifications of features also defined in that work.</p><p>Anonymous * Wether the editor is anonymous or not.</p><p>Vandals are likely to be anonymous. This feature is used in a way or another in most antivandalism working bots such as ClueBot and AVBOT. In the PAN-WVC-10 training set <ref type="bibr" coords="3,210.97,233.14,63.57,8.64" target="#b5">(Potthast, 2010)</ref> anonymous edits represent 29% of the regular edits and 87% of vandalism edits. Comment length * Length in characters of the edit summary.</p><p>Long comments might indicate regular editing and short or blank ones might suggest vandalism, however, this feature is quite weak, since leaving an empty comment in regular editing is a common practice. Upper to lower ratio † Uppercase to lowercase letters ratio, i.e., 1+|upper| 1+|lower| . Vandals often do not follow capitalization rules, writing everything in lowercase or in uppercase. Upper to all ratio † Uppercase letters to all letters to ratio, i.e., 1+|upper| 1+|lower|+|upper| .</p><p>Digit ratio Digit to all characters ratio, i.e., 1+|digit| 1+|all| . This feature helps to spot minor edits that only change numbers, which might help to find some cases of subtle vandalism where the vandal changes arbitrarily a date or a number to introduce misinformation. Non-alphanumeric ratio Non-alphanumeric to all characters ratio, i.e., 1+|nonalphanumeric| 1+|all| . An excess of non-alphanumeric characters in short texts might indicate excessive use of exclamation marks or emoticons. Character diversity Measure of different characters compared to the length of inserted text, given by the expression length 1 dif f erent chars . This feature helps to spot random keyboard hits and other non-sense. It should take into account QWERTY keyboard layout in the future. Character distribution † Kullback-Leibler divergence of the character distribution of the inserted text with respect the expectation. Useful to detect non-sense. Compressibility † Compression rate of inserted text using the LZW algorithm. <ref type="foot" coords="3,452.39,519.45,3.49,6.05" target="#foot_1">2</ref>Useful to detect non-sense, repetitions of the same character or words, etc. Size increment Absolute increment of size, i.e., |new| -|old|.</p><p>The value of this feature is already well-established. ClueBot uses various thresholds of size increment for its heuristics, e.g., a big size decrement is considered an indicator of blanking. Size ratio * Size of the new revision relative to the old revision, i.e., 1+|new| 1+|old| . Complements size increment.</p><p>Average term frequency * Average relative frequency of inserted words in the new revision.</p><p>In long and well-established articles too many words that do not appear in the rest of the article indicates that the edit might be including non-sense or non-related content. Longest word * Length of the longest word in inserted text.</p><p>Useful to detect non-sense. Longest character sequence * Longest consecutive sequence of the same character in the inserted text.</p><p>Long sequences of the same character are frequent in vandalism (e.g. aaggggghhhhhhh!!!!!, soooooo huge).</p><p>Size increment and ratio are closely related to all features, as can be seen in ClueBot and AVBOT source code, where thresholds for these measures are coded deep into most heuristics. This should be considered when building a classifier.</p><p>Upper to all, upper to lower, digit and non-alphanumeric ratios were computed using case-sensitive concatenated inserted words. These could also be computed using a diff or computing the difference of their values in the old and new text. Each method produces different results. We chose only inserted words for efficiency.</p><p>Antivandalism bots use lists of regular expressions with weights in order to compute a vandalism score. In <ref type="bibr" coords="4,246.18,366.10,140.66,8.64" target="#b6">(Potthast, Stein, and Gerling, 2008</ref>) a similar approach is described, where vulgarism frequency and impact are considered. Vulgarism frequency is the frequency of vulgarisms in an edit text relative to all words in the edit. Vulgarism impact is the percentage by which an edit increases the number of vulgarisms in the text. In the same way, pronoun frequency and impact were defined.</p><p>We have defined features analogous to vulgarism frequency and vulgarism impact, for different categories of words:</p><p>Vulgarisms Vulgar and offensive words, e.g., fuck, suck, stupid. Pronouns First and second person pronouns, including slang spellings, e.g., I, you, ya. Biased Colloquial words with high bias, e.g., coolest, huge. Sex Non-vulgar sex-related words, e.g., sex, penis, nipple. Bad Hodgepodge category for colloquial contractions (e.g. wanna, gotcha), typos (e.g. dosent), etc. All A meta-category, containing vulgarisms, pronouns, biased, sex-related and bad words. Good Words rarely used by vandals, mainly wiki-syntax elements (e.g. __TOC__, &lt;ref&gt;)</p><p>Word counters were computed using the inserted words in lowercase. In future work, it would be desirable to consider caseness and style. For example, dick is very likely to be slang for penis and DICK is a strong indicator of vandalism, but Dick is more likely to be the diminutive for Richard or a surname. Our current system does not make this distinction.</p><p>Classification has been conducted using the Weka framework <ref type="bibr" coords="5,383.20,144.01,69.38,8.64" target="#b3">(Hall et al., 2009)</ref>. After preliminary evaluations, we have tried to choose classifiers which fullfil all or most of the following conditions: a) require little or no preprocessing of data, b) require little parameter adjustment, c) do implicit feature selection, d) are resistant to noise and outliers and e) are resistant to severe class imbalance.</p><p>Our baseline classifier is C4.5 decision tree <ref type="bibr" coords="5,320.40,203.95,63.04,8.64" target="#b7">(Quinlan, 1993)</ref> which is a well-established algorithm and, to some extent, fullfils our criteria. LogitBoost <ref type="bibr" coords="5,388.16,215.90,92.42,8.64;5,134.77,227.86,69.64,8.64" target="#b2">(Friedman, Hastie, and Tibshirani, 2000)</ref> and Random Forest <ref type="bibr" coords="5,290.51,227.86,66.66,8.64" target="#b0">(Breiman, 2001)</ref> are attractive because of their implicit feature selection, generalization properties and a low number of parameters. We expect Random Forest to properly exploit relations between features such as those described in Section 3. Random Forest has another interesting property: it uses an internal test error estimation known as out of bag error which makes cross-validation prescindible.</p><p>We also chose Support Vector Machines (SVM) because of its resistance to class imbalance <ref type="bibr" coords="5,178.88,311.70,124.96,8.64" target="#b4">(Japkowicz and Stephen, 2002)</ref>, however, SVM has been discarded for inclusion in the PAN'10 results because of its high computational demands and amount of parameter to adjust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>The following measures have been evaluated in every experiment: Precision, Recall, F-Measure and Area Under ROC Curve (AUC).</p><p>In Table <ref type="table" coords="5,184.52,417.06,4.98,8.64" target="#tab_0">1</ref> we can see the performance of a C4.5 decision tree built for each feature. The C4.5 algorithm, considering only one feature and with severe class imbalance, will often produce a majority class classifier. In order to prevent this, we changed the weight of vandalism edits so the cost of a misclassified vandalism edit to be 10 times higher than a misclassified regular edit. This is meant to be orientative, not an accurate ranking of features.</p><p>In Table <ref type="table" coords="5,184.87,488.94,4.98,8.64" target="#tab_1">2</ref> we can see the performance of all the classifiers considering all features. Every classifier has been evaluated with 10-fold cross-validation. Parameters used for classifiers were:<ref type="foot" coords="5,201.17,511.19,3.49,6.05" target="#foot_2">3</ref> C4.5 minimum number of instances per leaf is 6, Laplace smoothing is used for predicted probabilites. LogitBoost 100, 500 and 1000 boost iterations. The weak classifier is a Decision Stump. Random Forest 100, 500 and 1000 iterations.</p><p>LogitBoost and Random Forest perform similarly in this task. Random Forest improves F-Measure and AUC as we increase the number of iterations. While LogitBoost shows slightly better performance than Random Forest, its results are less stable and decrease while increasing number iterations, suggesting a problem of overfitting. This is, presumably, because of LogitBoost's sensitiveness to noise and outliers.</p><p>Our final classifier was a Random Forest of 1000 trees, each one built while considering 5 random features<ref type="foot" coords="7,244.55,129.60,3.49,6.05" target="#foot_3">4</ref> , obtaining an AUC of 0.92236 when evaluated with the PAN-WVC-10 testing corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this work, we revisited <ref type="bibr" coords="7,240.82,206.51,143.30,8.64" target="#b6">(Potthast, Stein, and Gerling, 2008)</ref> approach on Wikipedia vandalism detection, tuning some features and introducing others. We further explored features based on word lists, expanding them beyond vulgarisms and improving results by creating new categories. We performed a brief comparison of different supervised learning techniques for this task. Random Forest and LogitBoost produced good results.</p><p>Our final classifier, a Random Forest, obtained an AUC of 0.92236, which was ranked in the first place in PAN'10 for the vandalism detection task. Precision and recall on the training test were 0.861 and 0.568, respectively. This is far better than current antivandalism systems in terms of F-Measure, but it has neither precision near to 1, which is required for a bot in order to operate autonomously, nor a recall high enough to be used as a filtering system for human editors. In any case, our results suggest that this machine learning based approach is a suitable path for the next-generation antivandalism bots.</p><p>Future work might include a more exhaustive feature evaluation; building bigger word lists using free lexical resources such as Wiktionary and WordNet and infer their weights; introducing a feature for detecting random keyboard hits considering QWERTY keyboard layout; introducing heuristics from current antivandalism bots and experiment with measures based on ngram language models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,185.91,115.83,243.54,378.34"><head>Table 1 .</head><label>1</label><figDesc>Evaluation of individual features with a C4.5 decision tree.</figDesc><table coords="6,197.40,134.96,218.30,359.21"><row><cell>Feature</cell><cell cols="4">Precision Recall F-Measure AUC</cell></row><row><cell>Anonymous</cell><cell cols="2">0.166 0.872</cell><cell>0.278</cell><cell>0.78</cell></row><row><cell>Comment length</cell><cell cols="2">0.102 0.663</cell><cell>0.177</cell><cell>0.661</cell></row><row><cell>Upper to lower ratio</cell><cell cols="2">0.131 0.629</cell><cell>0.217</cell><cell>0.755</cell></row><row><cell>Upper to all ratio</cell><cell cols="2">0.129 0.621</cell><cell>0.214</cell><cell>0.731</cell></row><row><cell>Digit ratio</cell><cell cols="2">0.128 0.718</cell><cell>0.217</cell><cell>0.75</cell></row><row><cell cols="3">Non-alphanumeric ratio 0.117 0.629</cell><cell>0.197</cell><cell>0.729</cell></row><row><cell>Character diversity</cell><cell cols="2">0.121 0.689</cell><cell>0.206</cell><cell>0.741</cell></row><row><cell>Character distribution</cell><cell>0.11</cell><cell>0.698</cell><cell>0.19</cell><cell>0.71</cell></row><row><cell>Compressibility</cell><cell>0.095</cell><cell>0.29</cell><cell>0.143</cell><cell>0.627</cell></row><row><cell>Size increment</cell><cell cols="2">0.111 0.669</cell><cell>0.191</cell><cell>0.69</cell></row><row><cell>Size ratio</cell><cell>0.1</cell><cell>0.195</cell><cell>0.132</cell><cell>0.572</cell></row><row><cell cols="3">Average term frequency 0.207 0.021</cell><cell>0.037</cell><cell>0.503</cell></row><row><cell>Longest word</cell><cell cols="2">0.124 0.712</cell><cell>0.211</cell><cell>0.742</cell></row><row><cell>Longest character seq.</cell><cell cols="2">0.115 0.514</cell><cell>0.189</cell><cell>0.628</cell></row><row><cell>All frequency</cell><cell cols="2">0.762 0.353</cell><cell>0.482</cell><cell>0.661</cell></row><row><cell>All impact</cell><cell cols="2">0.501 0.377</cell><cell>0.43</cell><cell>0.662</cell></row><row><cell>Vulgarism frequency</cell><cell cols="2">0.904 0.214</cell><cell>0.346</cell><cell>0.597</cell></row><row><cell>Vulgarism impact</cell><cell cols="2">0.618 0.227</cell><cell>0.332</cell><cell>0.599</cell></row><row><cell>Bad word frequency</cell><cell>0.747</cell><cell>0.08</cell><cell>0.145</cell><cell>0.532</cell></row><row><cell>Bad word impact</cell><cell cols="2">0.348 0.111</cell><cell>0.169</cell><cell>0.539</cell></row><row><cell>Biased frequency</cell><cell cols="2">0.623 0.082</cell><cell>0.145</cell><cell>0.536</cell></row><row><cell>Biased impact</cell><cell cols="2">0.311 0.173</cell><cell>0.223</cell><cell>0.561</cell></row><row><cell>Sex frequency</cell><cell cols="2">0.717 0.041</cell><cell>0.078</cell><cell>0.517</cell></row><row><cell>Sex impact</cell><cell cols="2">0.537 0.048</cell><cell>0.087</cell><cell>0.518</cell></row><row><cell>Pronoun frequency</cell><cell cols="2">0.588 0.152</cell><cell>0.241</cell><cell>0.562</cell></row><row><cell>Pronoun impact</cell><cell cols="2">0.311 0.173</cell><cell>0.223</cell><cell>0.561</cell></row><row><cell>Goodword frequency</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.545</cell></row><row><cell>Goodword impact</cell><cell cols="2">0.149 0.106</cell><cell>0.124</cell><cell>0.584</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,198.23,510.04,216.66,104.37"><head>Table 2 .</head><label>2</label><figDesc>Classifier evaluation.</figDesc><table coords="6,198.23,529.17,216.66,85.23"><row><cell>Classifier</cell><cell cols="4">Precision Recall F-Measure AUC</cell></row><row><cell>C4.5</cell><cell cols="2">0.773 0.543</cell><cell>0.638</cell><cell>0.93</cell></row><row><cell>Random Forest 100 it.</cell><cell cols="2">0.855 0.568</cell><cell>0.683</cell><cell>0.957</cell></row><row><cell>Random Forest 500 it.</cell><cell>0.86</cell><cell>0.565</cell><cell>0.682</cell><cell>0.962</cell></row><row><cell cols="3">Random Forest 1000 it. 0.861 0.568</cell><cell>0.684</cell><cell>0.963</cell></row><row><cell>LogitBoost 100 it.</cell><cell cols="2">0.845 0.566</cell><cell>0.678</cell><cell>0.966</cell></row><row><cell>LogitBoost 500 it.</cell><cell>0.82</cell><cell>0.606</cell><cell>0.697</cell><cell>0.964</cell></row><row><cell>LogitBoost 1000 it.</cell><cell cols="2">0.795 0.611</cell><cell>0.691</cell><cell>0.961</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,152.69,635.17,327.89,7.77;2,134.77,646.13,345.82,7.77;2,134.77,657.08,205.78,7.77"><p>Available at google-diff-match-patch. Behaviour of different parameters of the diff function has not been studied yet. The parameters used were Patch_Margin set to 0, Diff_EditCost to 6 and Match_Distance to 500.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,152.69,624.21,327.90,7.77;3,134.77,635.17,345.82,7.77;3,134.77,646.13,345.83,7.77;3,134.77,657.93,174.89,6.31"><p>LZW was chosen after evaluating the behaviour of LZW, gzip and bzip2, although, an exhaustive comparison is still pending. We used the TIFF LZW algorithm (Adobe Developers Association, 1992) as implemented in python-lzw 0.01 by Joe Bowers, available at http: //www.joe-bowers.com/static/lzw/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,152.69,646.13,327.90,7.77;5,134.77,657.08,292.99,7.77"><p>Any omitted parameter uses default parameters in Weka. For more information, check Weka API documentation at http://weka.sourceforge.net/doc.stable/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="7,152.69,656.80,40.92,8.06;7,193.74,661.08,3.65,5.24;7,199.42,656.80,157.87,8.06"><p>That is, log 2 M + 1, where M is the number of features.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,134.77,499.02,283.31,8.82" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,221.63,499.20,63.49,8.64">Random Forests</title>
		<author>
			<persName coords=""><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,292.59,499.02,71.89,8.59">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,134.77,511.90,345.83,8.64;7,149.71,524.79,181.82,7.01" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Jacobi</forename><surname>Carter</surname></persName>
		</author>
		<ptr target="http://www.acm.uiuc.edu/~carter11/ClueBot.pdf" />
		<title level="m" coord="7,228.05,511.90,152.21,8.64">ClueBot and Vandalism on Wikipedia</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,134.77,536.56,345.82,8.64;7,149.71,548.34,267.99,8.82" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,409.41,536.56,71.17,8.64;7,149.71,548.52,166.30,8.64">Additive Logistic Regression: a Statistical View of Boosting</title>
		<author>
			<persName coords=""><forename type="first">Jerome</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,323.87,548.34,75.39,8.59">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,134.77,561.22,345.82,8.64;7,149.71,573.00,330.88,8.82;7,149.71,584.95,108.05,8.82" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,243.93,573.18,189.03,8.64">The WEKA Data Mining Software: an Update</title>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Geoffrey</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernhard</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,444.07,573.00,36.52,8.59;7,149.71,584.95,49.68,8.59">SIGKDD Explorations</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,134.77,597.84,345.82,8.64;7,149.71,609.61,276.43,8.82" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,341.55,597.84,139.04,8.64;7,149.71,609.79,67.13,8.64">The Class Imbalance Problem: A Systematic Study</title>
		<author>
			<persName coords=""><forename type="first">Nathalie</forename><surname>Japkowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shaju</forename><surname>Stephen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,224.61,609.61,97.99,8.59">Intelligent Data Analysis</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="429" to="449" />
			<date type="published" when="2002-02">2002. February</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,134.77,622.32,345.83,8.82;7,149.71,634.27,233.22,8.82" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,243.73,622.50,192.38,8.64">Crowdsourcing a Wikipedia Vandalism Corpus</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,462.14,622.32,18.45,8.59;7,149.71,634.27,180.64,8.59">33rd Annual International ACM SIGIR Conference</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010-07">2010. July</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,134.77,119.31,345.82,8.64;8,149.71,131.27,330.88,8.64;8,149.71,143.04,330.89,8.82;8,149.71,155.00,330.89,8.82;8,149.71,167.13,90.48,8.64" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,378.29,119.31,102.30,8.64;8,149.71,131.27,80.25,8.64">Automatic vandalism detection in wikipedia</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Gerling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,306.57,143.04,137.46,8.59">Advances in Information Retrieval</title>
		<title level="s" coord="8,185.31,155.00,143.92,8.59">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vassilis</forename><surname>Plachouras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ian</forename><surname>Ruthven</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ryen</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">4956</biblScope>
			<biblScope unit="page" from="663" to="668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,134.77,178.91,345.83,8.82;8,149.71,191.04,166.58,8.64" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="8,240.80,178.91,152.00,8.59">C4.5: programs for machine learning</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Quinlan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ross</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,134.77,203.00,345.82,8.64;8,149.71,214.78,155.73,8.82" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,290.23,203.00,190.36,8.64;8,149.71,214.95,51.13,8.64">AVBOT: detección y corrección de vandalismos en Wikipedia</title>
		<author>
			<persName coords=""><forename type="first">Rodríguez</forename><surname>Posada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Emilio</forename><surname>José</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,208.79,214.78,37.71,8.59">NovATIca</title>
		<imprint>
			<biblScope unit="volume">203</biblScope>
			<biblScope unit="page" from="51" to="53" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,134.77,226.73,345.83,8.82;8,149.71,238.69,56.72,8.59;8,229.53,239.80,251.06,7.01;8,149.71,251.76,211.70,7.01;8,134.77,262.77,345.82,8.64;8,149.71,274.55,160.88,8.59;8,337.13,275.67,143.46,7.01;8,149.71,287.62,298.88,7.01;8,149.71,299.58,139.97,7.01" xml:id="b9">
	<monogr>
		<ptr target="http://en.wikipedia.org/w/index.php?title=Wikipedia:WikiProject_Vandalism_studies&amp;oldid=365253014" />
		<title level="m" coord="8,281.75,226.91,84.01,8.64;8,395.31,226.73,85.28,8.59;8,149.71,238.69,52.35,8.59;8,328.27,262.77,127.29,8.64;8,149.71,274.55,156.52,8.59">Wikipedia, The Free Encyclopedia</title>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
	<note>Wikipedia, The Free Encyclopedia</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
