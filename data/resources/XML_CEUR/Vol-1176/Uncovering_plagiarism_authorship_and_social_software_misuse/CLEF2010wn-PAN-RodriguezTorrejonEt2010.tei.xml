<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,244.40,150.37,114.11,14.40;1,210.10,169.14,175.21,12.60;1,207.50,187.90,180.54,10.80">CoReMo System (Contextual Reference Monotony) Lab Report for PAN at CLEF 2010</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,162.50,225.07,59.67,9.00"><forename type="first">Diego</forename><surname>Antonio</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad de Huelva (Spain)</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,224.76,225.07,79.06,9.00"><forename type="first">Rodríguez</forename><surname>Torrejón</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad de Huelva (Spain)</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,328.50,225.07,50.15,9.00"><forename type="first">José</forename><surname>Manuel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad de Huelva (Spain)</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,381.26,225.07,57.44,9.00"><forename type="first">Martín</forename><surname>Ramos</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad de Huelva (Spain)</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,226.45,247.85,51.55,8.10"><forename type="first">José</forename><surname>Caballero</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad de Huelva (Spain)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,244.40,150.37,114.11,14.40;1,210.10,169.14,175.21,12.60;1,207.50,187.90,180.54,10.80">CoReMo System (Contextual Reference Monotony) Lab Report for PAN at CLEF 2010</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8A74792B49C296F0333BF66C04DB23B0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>plagiarism detection</term>
					<term>n-gram</term>
					<term>contextual n-gram</term>
					<term>Referential Monotony</term>
					<term>Information Retrieval 2 External Plagiarism Detection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper a new approach is shown for a very fast monolingual external plagiarism detection system based on an altered n-gram concept (contextual n-gram), a new high precision contextual Information Retrieval engine, and a new pruning strategy (Referential Monotony) for plagiarism detection and its limits. The assessment results can be compared with the carried out by the winner team at PAN'09, but achieved with remarkable speed (35 min) and low hardware requirements (single laptop).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="842.0" lry="595.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, a new only external and monolingual plagiarism detection system is shown. Its goal is minimizing hardware resources and however, getting fastly high PAN performance measures. It's based on three innovative proposals:</p><p>1. Contextual n-gram: a new n-gram concept modification with two main features: describes the sentence context where it's on, and it is a highly discriminative fingerprint for its sentence between the others into a very wide collection. 2. New Information Retrieval System (IRS) with very high precision, specific for this goal, based on former concept. 3. Referential Monotony (RM): new pruning strategy to find plagiarism limits. The performances are in general better than PAN'09 best ranked teams, but got with a much lower computational cost. Because that, it's an interesting opportunity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">"Contextual N-gram" for Designing an Information Retrieval System.</head><p>The system shown in this paper, bases the plagiarism analysis on n-grams comparison <ref type="bibr" coords="2,124.90,182.97,10.58,9.00" target="#b1">[2]</ref>, but by using an special treatment to build them.</p><p>The "contextual n-gram" denomination is referred to the feature of these n-grams to describe the essential context with a very short group of word stems.</p><p>Because making n-grams by simple tokens extraction, gets analyzers very vulnerable to obfuscation, six steps are carried out when modeling documents by n-grams in order to improve the essential context definition, with gets highly useful n-grams to locate possible plagiarism, obfuscated or not:</p><p>1. Lowercase folding when tokenization (a very common practice). 2. Empty words (stopwords) filtering. This step gets n-grams much more context definitory. Stopwords are also easy to delete/change for obfuscation purposes. 3. One character tokens filtering. As they are very used in enumerations and having high frequency, they get few contextual meaningful. 4. Stem reduction (stemming) <ref type="bibr" coords="2,269.59,342.87,11.63,9.00" target="#b2">[3]</ref> contributes to get better recall for detecting plagiarisms when words are changed by derivative ones. 5. Alphabetic tokens order into every n-gram, processing the result as canonical representative for the all possible tokens permutations set. This step reduces effectivity of words order changes due to sentence rewriting or translation <ref type="bibr" coords="2,455.90,392.67,10.63,9.00" target="#b3">[4]</ref>, improving recall. 6. n -1 tokens overlapping (on its natural order) to extract consecutive contextual n-grams, gets better detection on former obfuscation types. May be thought that all these steps to help improving recall, may also get false positive increasing, but it is experimentally demonstrated that steps 2 and 3 gets enough compensation due to the final discriminative capacity got by contextual n-gram.</p><p>Studying PAN'09 corpuses, it was probated that a high percentage of this n-gram type behaves like a fingerprint for the passage/document they belong, specially if n-grams are 3th grade or higher. (figure <ref type="figure" coords="2,235.93,622.57,3.60,9.00" target="#fig_0">1</ref>).</p><p>This discriminative capacity is strengthened by the neighbor contextual n-grams, being an excellent base to develop specific IRS to detect and locate plagiarisms.</p><p>By analyzing the PAN'09 development corpus, it was found that the probability for to repeat a contextual trigram from a new non plagiarized document in a concrete existing document from corpus, was of 0,0026%. However, if it's a plagiarized one,  the probability to point to the correct source document is 94,37% (using only three document references max. for every trigram). Contextual bigrams gets 0,052% to be repeated in a concrete document, and 77,00% or 77,76% for pointing to correct document when existing plagiarism (using 5 or 9 references max respectively).</p><formula xml:id="formula_0" coords="2,287.60,544.66,178.00,43.13">[01] [02] [03] [04] [05] [06] [07] [08] [09] [10] [&gt;10] 0,00%<label>20</label></formula><p>Contextual n-gram groups are excellent for high precision calculation of the most similar passage/document by contextual similarity.</p><p>The only inconvenience is the necessary index size, several times bigger than the own text corpus. However, an approximation to VSM, but only based on df <ref type="foot" coords="3,467.80,234.24,2.90,5.22" target="#foot_0">1</ref>proportional weighting, and a limited document references amount, is enough to get a very high precision IRS with lower consumption (index stores df and 2~3 max. source references if using trigrams or 5~9 if bigrams).</p><p>As plagiarizers used to take several plagiarism fonts, having an available IRS as proposed in this paper, to reduce and strength the search space <ref type="bibr" coords="3,401.06,294.47,10.83,9.00" target="#b4">[5]</ref>, a change of strategy is preferable instead of returning a fix number of candidate fonts: After splitting the suspicious document, identifying only one candidate as possible source (for every split) and using the RM pruning strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Referential Monotony (RM)</head><p>When analyzing, it is highly probable that a big number of suspicious fragments should have a possible source document associated. Analyzing anything would need a lot of time and/or computational resources, getting many false positives. To avoid this annoyance, a new pruning strategy is used, named Referential Monotony, consisting in rejecting (as casual matching) all suspicious fragments appearing alone, without repeating reference at least certain times (monotony threshold). RM gets a fast filtering of so enough wide suspicious sections as to point that there is a continuous high correspondence with the right source document, getting also a fast gross detection for its limits.</p><p>In the figure <ref type="figure" coords="3,189.63,486.37,3.75,9.00" target="#fig_1">2</ref>, the detection process and search space reduction by RM is shown: dark gray emphasized splits give direct detection (5 consecutive splits pointing to reference doc #91) due to pass RM threshold (4 in this example). Light gray splits are included for fishing possible words out of direct detection borders. The system presented excellent results by using only this strategy with a split length of 25 contextual n-grams and 4 times for RM threshold. The annoyance for this strategy is that plagiarized fragments shorter than 4 splits are not detected (75 contextual n-grams, or about 150 words).</p><p>To detect short length (but almost verbatim) plagiarisms, RM threshold is reduced for a zone when any split gets high similarity value.</p><p>As many plagiarizers use to employ same fonts to take several fragments, after getting sources knowledge by RM from greater zones, feedback for a second pass may be arranged for fishing the smaller, as show in figure 2 left zone.</p><p>Our preliminary version for this idea (a necessary filtering is not yet implemented) only gets similar overall results (+/-0,5%), but with a better precision/recall balance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Time Processing Reduction</head><p>Although RM prune is the main reason, this goal was improved by several strategies:</p><p>• Using C (gcc) 64 bits version on GNU -Linux with ext4 filesystem.</p><p>• Using an unbalanced binary tree to sort n-grams and building partial inverted index, later mixed as ordered vectors for final inverted index.</p><p>• IRS uses binary search on former vector to locate n-grams matching with source documents. This gets similar efficiency order that a balanced tree but using less memory.</p><p>• Avoid repeating source-documents n-grams conversion by saving n-gram versions (while indexing), and caching last 50 analyzed. Hardware and software used for development and PAN2010 competition:</p><p>• Acer Aspire laptop 5920G (Intel T5750 2.0 GHz processor, 4GB RAM), upgraded to 7200 rpm 2,5" HD.</p><p>• Ubuntu GNU-Linux 10.04 64 bits edition using EXT4 file-systems.</p><p>• GNU -C language. Netbeans 6.8 as IDE and Valgrind were used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Plagiarism Detection Process</head><p>External analysis process is arranged by these main steps:</p><p>1. Language documents classification (to discard non English sources). 2. Building monolingual inverted index, saving on disk and memory loading.</p><p>3. Splitting suspicious documents by fix amount of contextual n-grams. 4. Using the new IRS to get only one source document for every split. 5. Determination of plagiarism existence by Referential Monotony. 6. Finding plagiarism border n-grams separately for suspicious zone by double search from start and end of detected gross zone over the IRS. 7. Using suspicious detected zone to search the best matching window into source document, getting better recall and precision than in suspicious section. Then a post-refinement is done for suspicious fragment limits. 8. Saving analysis results in XML files. 9. Evaluate results over training XML gold standard (if available).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>Thanks to its speed, more than 150 trials were carried out on PAN'09 training corpus while system development (started last year), with contextual n-grams grade 2 and 3.</p><p>The best PAN performance is got by contextual trigrams, however time and resources are better by bigrams. Ten folds 2 analysis confirmed behavior regularity.</p><p>PAN-PC-09 was only used to confirm former tweaks and prospects, on a 8GB RAM PC. For the competition, we used once again the same 4GB RAM laptop.</p><p>Table <ref type="table" coords="5,161.48,198.07,5.00,9.00">1</ref> shows results got in several corpuses and hardware used summary. As when writing this paper, no information is available for costs, hardware and times got by other PAN2010 teams, figure <ref type="figure" coords="5,223.18,246.27,5.00,9.00" target="#fig_2">3</ref> shows this for best ranked teams in PAN'09, compared to this system by trigrams (T) or bigrams (B). This comparative was estimated <ref type="bibr" coords="5,174.13,294.47,11.72,9.00" target="#b5">[6]</ref> by the available information from <ref type="bibr" coords="5,199.04,306.47,10.58,9.00" target="#b6">[7]</ref>, <ref type="bibr" coords="5,215.64,306.47,11.72,9.00" target="#b7">[8]</ref> and <ref type="bibr" coords="5,246.73,306.47,10.64,9.00" target="#b8">[9]</ref>.</p><p>No cross-lingual performance is expected. As experimental version gets lower plagdet score than monolingual, we used the last one (where non English source documents are excluded).</p><p>Overall performance got at PAN2010: 0.5851 (non official external: 0.6666 ). Timing: Indexing (1.6 GB) 20 min 06 sec + Analysis (3.2 GB) 55 min 44 sec</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>Good results, with remarkable high speed and low resources. Waiting improvements:</p><p>• Feedback filtering (+ recall and overall).</p><p>• Multilingual version refinement (+ recall and overall).</p><p>• Concurrent and/or parallel programing for multi-core machines (+ speed).</p><p>• Using SSD (Solid State Disk) HD (+ speed). Including a confidence attribute in detections would help to users and enforces hybrid analyzers development without present penalty.</p><p>Contextual n-grams could improve other NLP disciplines as clustering, classifying, reply oriented search, etc. RM prune should be also usefull in other fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Acknowledgements</head><p>Authors thanks to PAN-PC corpuses development team (excellent resources) and the rest of PAN organization and competitors for their motivative work and papers.</p><p>2 Similar size subsets got by dividing the suspicious corpus. Less is better at any bar</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,289.20,605.07,158.62,9.00;2,316.30,617.17,104.45,9.00"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: PAN'09 Development corpus Contextual trigrams index</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,127.20,552.97,340.22,9.00;3,136.20,567.87,333.69,9.00;3,124.90,579.87,345.05,9.00;3,124.90,591.97,344.93,9.00;3,124.90,603.97,165.21,9.00;3,136.20,616.07,334.04,9.00;3,124.90,628.07,207.02,9.00;3,136.20,640.17,333.48,9.00;3,124.90,652.17,345.59,9.00;3,124.90,664.27,278.39,9.00"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Only source candidate per split (basic for RM) -Recall improved by feedbackThe system presented excellent results by using only this strategy with a split length of 25 contextual n-grams and 4 times for RM threshold. The annoyance for this strategy is that plagiarized fragments shorter than 4 splits are not detected (75 contextual n-grams, or about 150 words).To detect short length (but almost verbatim) plagiarisms, RM threshold is reduced for a zone when any split gets high similarity value.As many plagiarizers use to employ same fonts to take several fragments, after getting sources knowledge by RM from greater zones, feedback for a second pass may be arranged for fishing the smaller, as show in figure 2 left zone.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,308.30,349.77,147.19,9.00;5,321.40,361.77,121.09,9.00;5,336.70,332.96,76.22,8.93"><head>Fig. 3 :</head><label>3</label><figDesc>Fig.3: PAN'09 comparative Analysis time -Hardware reqs. -Costs T 1º B 2º 3º</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,133.40,685.85,249.86,8.10"><p>Frequency of a term based in the number do documents containing it.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="7,129.15,179.47,341.47,9.00;7,143.40,191.57,327.16,9.00;7,143.40,203.57,326.21,9.00;7,143.40,215.67,326.02,9.00;7,143.40,227.57,327.13,9.00;7,143.40,239.67,49.13,9.00" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,391.50,179.47,79.12,9.00;7,143.40,191.57,214.70,9.00">Overview of the 1st International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Eiselt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="7,354.40,203.57,115.21,9.00;7,143.40,215.67,305.87,9.00">SEPLN 2009 Workshop on Uncovering Plagiarism, Authorship and Social Software Misuse (PAN 09)</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Stein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Rosso</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Koppel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Agirre</forename><forename type="middle">E</forename></persName>
		</editor>
		<meeting><address><addrLine>Donostia-San Sebastian, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-09">September 2009. 2009</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,129.15,257.67,341.21,9.00;7,143.40,269.77,325.87,9.00;7,143.40,281.77,274.13,9.00" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,274.40,257.67,195.96,9.00;7,143.40,269.77,84.75,9.00">On Automatic Plagiarism Detection based on n-grams Comparison</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,238.30,269.77,230.97,9.00;7,143.40,281.77,40.84,9.00">Proc. European Conference on Information Retrieval, ECIR-2009</title>
		<meeting>European Conference on Information Retrieval, ECIR-2009</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2009">5478. 2009</date>
			<biblScope unit="page" from="696" to="700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,129.15,299.87,286.14,9.00;7,143.40,311.87,130.53,9.00;7,143.40,321.52,277.04,11.63" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,213.10,299.87,202.19,9.00;7,143.40,311.87,33.78,9.00">An algorithm for suffix stripping.(Porter stemmer) Program</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
		<ptr target="http://tartarus.org/~martin/PorterStemmer/index.html" />
		<imprint>
			<date type="published" when="1980">1980</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,129.15,341.57,341.24,9.00;7,143.40,353.67,326.02,9.00;7,143.40,365.67,166.61,9.00" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,286.00,341.57,184.39,9.00;7,143.40,353.67,151.95,9.00">Monolingual and Crosslingual Plagiarism Detection -Towards the Competition</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,303.59,353.67,124.24,9.00">Proc. III Jornadas PLN-TIMM</title>
		<meeting>III Jornadas PLN-TIMM<address><addrLine>Madrid, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-06">February 5-6. 2009</date>
			<biblScope unit="page" from="29" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,129.15,383.77,341.29,9.00;7,143.40,395.77,326.05,9.00;7,143.40,407.87,77.73,9.00" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,270.00,383.77,200.44,9.00;7,143.40,395.77,141.01,9.00">On the Relevance of Search Space Reduction in Automatic Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,298.20,395.77,167.05,9.00">Procesamiento del Lenguaje Natural</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="141" to="149" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,129.15,425.87,341.07,9.00;7,143.40,437.97,326.64,9.00;7,143.40,449.97,209.90,9.00" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Rodríguez-Torrejón</surname></persName>
		</author>
		<title level="m" coord="7,255.72,425.87,214.50,9.00;7,143.40,437.97,322.23,9.00">Detección de plagio en documentos. Propuesta de sistema externo monolingüe de altas prestaciones basada en n-gramas</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">Master Dissertation -Universidad de Huelva</note>
</biblStruct>

<biblStruct coords="7,129.15,468.07,341.20,9.00;7,143.40,480.07,326.63,9.00;7,143.40,492.17,326.87,9.00;7,143.40,504.17,326.84,9.00;7,143.40,516.27,298.83,9.00" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,299.82,468.07,170.53,9.00;7,143.40,480.07,129.39,9.00">ENCOPLOT pairwise sequence matching linear time plagiarism detection</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grozea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gehl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">N</forename><surname>Popescu</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="7,252.27,492.17,218.00,9.00;7,143.40,504.17,221.60,9.00">SEPLN 2009 Workshop on Uncovering Plagiarism, Authorship and Social Software Misuse (PAN 09)</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Stein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Rosso</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Koppel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Agirre</forename><forename type="middle">E</forename></persName>
		</editor>
		<meeting><address><addrLine>Donostia-San Sebastian, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-09">September 2009. 2009</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,129.15,534.27,341.08,9.00;7,143.40,546.37,326.87,9.00;7,143.40,558.37,326.16,9.00;7,143.40,570.47,325.67,9.00;7,143.40,582.37,327.13,9.00;7,143.40,594.47,49.13,9.00" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,323.83,534.27,146.40,9.00;7,143.40,546.37,167.73,9.00">Finding Plagiarism by Evaluating Document Similarities &quot; (PAN&apos;09 papers)</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kasprzak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brandejs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kripac</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="7,296.90,558.37,172.66,9.00;7,143.40,570.47,279.16,9.00">SEPLN 2009 Workshop on Uncovering Plagiarism, Authorship and Social Software Misuse (PAN 09)</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Stein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Rosso</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Koppel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Agirre</forename><forename type="middle">E</forename></persName>
		</editor>
		<meeting><address><addrLine>Donostia-San Sebastian, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-09">September 2009. 2009</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,129.15,612.47,340.63,9.00;7,143.40,624.57,326.54,9.00;7,143.40,636.57,326.16,9.00;7,143.40,648.67,325.67,9.00;7,143.40,660.57,327.13,9.00;7,143.40,672.67,49.13,9.00" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,296.88,612.47,172.90,9.00;7,143.40,624.57,154.70,9.00">A plagiarism detection procedure in three steps: selection, matches and &apos;squares</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Benedetto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Caglioti</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="7,296.90,636.57,172.66,9.00;7,143.40,648.67,279.16,9.00">SEPLN 2009 Workshop on Uncovering Plagiarism, Authorship and Social Software Misuse (PAN 09)</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Stein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Rosso</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Koppel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Agirre</forename><forename type="middle">E</forename></persName>
		</editor>
		<meeting><address><addrLine>Donostia-San Sebastian, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-09">September 2009. 2009</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
