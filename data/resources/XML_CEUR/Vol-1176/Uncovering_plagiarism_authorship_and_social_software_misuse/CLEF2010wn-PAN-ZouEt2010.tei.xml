<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,138.50,148.76,329.80,15.96;1,207.77,169.24,179.87,12.00">A Cluster-Based Plagiarism Detection Method Lab Report for PAN at CLEF 2010</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,170.09,207.32,30.76,9.05"><forename type="first">Du</forename><surname>Zou</surname></persName>
							<email>duzou@scut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">South China University of Technology GuangZhou</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,397.30,207.42,46.81,8.96"><forename type="first">Zhang</forename><surname>Ling</surname></persName>
							<email>ling@scut.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="institution">jiang Long South China University of Technology GuangZhou</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,138.50,148.76,329.80,15.96;1,207.77,169.24,179.87,12.00">A Cluster-Based Plagiarism Detection Method Lab Report for PAN at CLEF 2010</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E3D17137CC164C2ADC70D8A514E60066</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Plagiarism detection</term>
					<term>Similar text</term>
					<term>Locating</term>
					<term>Cluster 1</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe a cluster-based plagiarism detection method, which we have used in the learning management system of SCUT to detect plagiarism in the network engineering related courses. And we also used this method to detect external plagiarism in the PAN-10 competition. The method is divided into three steps: the first step, called pre-selecting, is to narrow the scope of detection using the successive same fingerprint; the second step, called locating, is to find and merge all fragments between two documents using cluster method; the third step, called post-processing, is to deal with some merging errors. Our method ran 19 hours in the PAN-10 competition, and the result ranked the second place, which met our expectation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Plagiarism detection, also known as text copy detection, is designed to determine whether a document is copied from other documents in whole or in part without any reference indicated. Besides copying text without any change, changing the order of the original text and replacing synonym are also regarded as plagiarism <ref type="bibr" coords="1,413.54,466.81,10.66,9.05" target="#b0">[1]</ref>. Text copy detection technology is widely used in intellectual property protection, search engine, e-library and student paper checks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Text copy detection originated from program code similarity detection in the 1970's.</p><p>Natural language text copy detection technique appeared in the 1990s, and has produced three detection approaches <ref type="bibr" coords="1,281.00,578.08,10.87,9.05" target="#b1">[2]</ref>: 1) Grammar-based method. This method focuses on the grammatical structure of documents, and uses a string-based matching approach to measure similarity between the documents. Huang <ref type="bibr" coords="1,377.70,601.12,14.37,9.05" target="#b2">[3]</ref> proposed a similar web pages detection method based on the LCS(Largest Common Subsequence) algorithm by finding the largest common string between two pages to calculate the similarity of the two pages. Winnowing algorithm <ref type="bibr" coords="1,348.35,635.56,11.69,9.05" target="#b3">[4]</ref> uses overlapping k-gram method to get hashes of the documents, and it uses moving window to select the minimum hash value from each window to obtain the fingerprints of the document, and then it calculates the rate of the matching fingerprint to get the similarity between the two documents. Hashbreaking <ref type="bibr" coords="1,260.86,681.52,13.09,9.05" target="#b4">[5]</ref>, DCT <ref type="bibr" coords="1,297.82,681.52,15.87,9.05" target="#b5">[6]</ref> are also the grammar-based methods, the only difference between them is how to get the fingerprints of the document.</p><p>Using grammar -based method to detect verbatim copying can get better results than using it to detect the copied text including synonym replacement or rewriting. 2) Semantics-based method. This method uses the vector space model of the Information Retrieval Technology, and statistics word frequency in a document to obtain feature vector of the document, then uses dot product, cosine, etc. to measure the feature vector of the two documents. This feature vector is the key of the document similarity. This method is not always effective to detect partial plagiarism, because it is difficult to determine the location of copied text. 3) Grammar semantics hybrid method <ref type="bibr" coords="2,456.46,241.43,10.69,9.05" target="#b0">[1]</ref>. This method is used to solve the problems of the two methods mentioned above, and improve the detection results.</p><p>Locating is an important step of text copy detection technology. It is required to give the position of the plagiarized content in the document in addition to calculating the document similarity. By-word comparison is a common locating method. Sediyono et al proposed LCCW (Longest Commonly Consecutive Word) algorithm <ref type="bibr" coords="2,124.82,321.95,10.66,9.05" target="#b6">[7]</ref>. It regards a paragraph as a comparison unit, and splits it into a collection of consecutive words. The position of the words in the paragraph is recorded. Then using by-word comparison, the longest commonly successive word can be identified. Eventually, the content and position of the similar text in the document can be obtained. Zaslavsky et al proposed the MDR (Match detect Reveal) system <ref type="bibr" coords="2,428.50,367.91,10.66,9.05" target="#b7">[8]</ref>. In this system, preprocessed document is split into words or fixed-length strings. And using Matching Statistics Algorithm, a suffix tree is constructed for each fixed-length string, and then the longest common substring can be found among the suffix trees. According to the longest common substring, the similar text and its position in the document can be obtained. By-word comparison method builds the index by words, which is an exact matching method. Its locating performance is not good enough for the text which includes obfuscation. The top three of PAN-09 plagiarism detection contest <ref type="bibr" coords="2,155.65,459.85,16.72,9.05" target="#b9">[10]</ref> [11] <ref type="bibr" coords="2,194.18,459.85,16.61,9.05" target="#b11">[12]</ref> process the document by word or by sentence and combine with heuristic matching methods, to achieve approximate text matching. This method is suitable in English documents, however, it can not solve the Chinese word segmentation problem in Chinese documents.</p><p>The Cluster-based plagiarism detection method we propose is the grammar-based method. This method is divided into three steps: pre-selecting, locating and postprocessing. We use the pre-selecting step to find out the documents which may be copied, so as to shorten the locating time and improve the detecting efficiency. And we use clustering method to locate plagiarism fragments, which can reduce the impact of obfuscation to some extent. In the last step, we deal with some errors which are found in locating step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3</head><p>The datasets</p><p>We participated in the PAN-10 external plagiarism detection competition. The main objective of the external plagiarism detection is: given a collection of suspicious documents and source documents, to identify all possible copy fragments from the suspicious documents and their locations in the suspicious documents and the corresponding source documents. We merged PAN-09 training set and test set into a big set to debug our algorithm. This big set contains 14,429 source documents (training set 7214, and test set 7215), 14428 suspicious documents (training set 7214, and test set 7214). For each suspicious document, there is an xml document which notes all copy fragments in the suspicious document and their locations in the suspicious document and source documents.</p><p>Based on language, plagiarism fragments can be divided into monolingual (translation=false) and cross-lingual (translation=true). Based on the degree of obfuscation <ref type="bibr" coords="3,169.44,264.47,12.17,9.05" target="#b8">[9]</ref>, plagiarism fragments can be divided into none obfuscation (obfuscation=none), low obfuscation (obfuscation=low) and high obfuscation (obfuscation=high). The length of plagiarism fragments is distributed between several hundred characters to ten thousand characters. The data set contains 73522 plagiarism fragments, among which English fragments are 67141 and multi-language fragments are 6381. In all of the English fragments, the number of none obfuscation is 26855 and the number of low obfuscation is 26628. The remainders are high obfuscation fragments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Method</head><p>The plagiarism detection method we propose uses Winnowing's fingerprint extraction algorithm. The method consists of three steps: The first step is pre-selecting. For each suspicious document, the task is to find out a small list of candidate documents in which the plagiarized content may exist from the source document set quickly. The second step is locating, which compares the suspicious document with each candidate document to get the copy fragments out of the suspicious document. The last step is post-processing, which discards some fragments without plagiarism from the end result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Pre-selecting</head><p>Supposed it takes an average of 100ms to process a pair of documents, and then the total computation time will be more than 200 days. Even if parallelizing the tasks with multi-core processors, the time needed is still unacceptable to the competition.</p><p>We found out that the most important step is locating. When we analyzed the algorithm, the locating step cost the most time. So we use the pre-selecting method to reduce the number of candidate documents, thereby the time of locating is shortened. Using the pre-selecting method we can save 90% of the running time.</p><p>C.Basile <ref type="bibr" coords="3,178.72,636.40,16.93,9.05" target="#b10">[11]</ref> computed the distance between each suspicious and source document, then selected the top 10 source documents with minimum distance for further processing. At the beginning, we used this approach to calculate the similarity of each suspicious and source document, and we selected the top 50 source documents according to the similarity. However, during the testing, we found that there was possibility of false collision when using Winnowing method to obtain fingerprint. For example, the values of two fingerprints are 1024 and 2024, if they are divided by 1000, their remainders are both 24, but in fact the two fingerprints are not the same. We found that the larger the file is, the greater the probability of collision and the higher the similarity will be. So using this method affects the efficiency and accuracy of locating.</p><p>To improve the accuracy of pre-selecting, we use successive same fingerprint thresholds to get candidate documents. We define two parameters, valid interval and successive same fingerprint. There are two fingerprint vectors D1 and D2 representing two different documents, if the number of different fingerprint among a given pairs of the fingerprint is not greater than a given number, we consider the pairs of the fingerprint are the same. And this given number is a valid interval. The pair of the same fingerprint is called a successive same fingerprint if it meets the condition of valid interval. By comparing each source document with the suspicious document, the source document will be regarded as candidate document of the suspicious document if the value of the successive same fingerprint is greater than a given threshold.</p><p>By setting the successive same fingerprint threshold to pre-select, the results are as follows: we can find 99.9% of the documents which contain none obfuscation (obfuscation=none) fragments, 89.3% of the documents which contain only low obfuscation (obfuscation=low), and there are not a source document is selected which contains only high obfuscation fragments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Locating</head><p>Locating is done between a suspicious document and a source document. In this step, we compare the suspicious document with each source document in the candidate document set, and then get a plagiarism fragment list of the suspicious document. The steps of locating are as follows:</p><p>1) Preprocessing. The purpose of this step is to remove all symbols which do not affect document semantic information, such as punctuation, whitespace, etc., converting all letters to lower case. And then we record the position of each word before and after preprocessing.</p><p>2) Sampling. The overlapping word-5-grams approach is used to obtain the initial fingerprint of the document. Referring to Winnowing's fingerprint sampling algorithm, we use 6 fingerprints as a window, and select the minimum fingerprint as a sample fingerprint of the window. We move the window by a fingerprint until the end of the initial fingerprint, the fingerprint that is repeatedly selected in the same position will be discarded. Finally the sample fingerprint vector of the document can be obtained. The beginning and the end position of the original text before preprocessing can be recorded by each fingerprint of the vector. Then the inverted index of the document can also be generated. The position of the original text is computed by the following formula:</p><formula xml:id="formula_0" coords="4,146.92,650.91,165.44,13.74">2 1 1        k w P EP EP SP cur i i i ； Where i SP , i</formula><p>EP are the beginning and the end position of the original text which is represented by the i-th fingerprint, cur P is the beginning position of the current window, w is the size of the sample window, and k is the length of the original text.</p><p>3) Clustering and merging. Take the source-document10383.txt and suspicious-document07957.txt as example. The sample fingerprint vectors of the two documents have been obtained in previous steps. By comparing the two fingerprint vectors, a list of matches between the suspicious document and the source document can be obtained. We represent the pair of vectors in a bi-dimensional plane <ref type="bibr" coords="5,415.90,250.43,16.72,9.05" target="#b10">[11]</ref> with the vector of the suspicious document as x axis and the source document as y axis, and then we get the coordinates of all matches in the plane. A point in the figure <ref type="figure" coords="5,465.82,273.47,4.98,9.05">1</ref> represents a match in coordinates(x,y), namely, the x-th fingerprint in the vector of the suspicious document is equal to the y-th fingerprint in the vector of the source document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. the same fingerprint between documents</head><p>By analyzing the sample fingerprint vectors of the documents, we can know, if a successive text in the suspicious document is copied from the source document, there is a set of points distributed along the direction of 45 degrees in the figure. Noneobfuscated copy text corresponds to a line, and obfuscated copy text corresponds to a shadow square that contains a lot of lines and points. The task of our plagiarism detection method is to determine the location of copy text in respective document by the sample fingerprint vector.</p><p>We propose a two-stage approach. The first stage is merging, which uses the improved LCS (Longest Common Substring) algorithm to merge common substrings of the two vectors. The algorithm finds all common substrings from the two vectors, and sets a threshold. If the distance between two substrings is less than the threshold, then merge them. Finally a set of approximate successive fingerprint sections can be found. There is an example of an approximate successive fingerprint section in the figure <ref type="figure" coords="6,151.10,195.44,7.81,9.05">2:</ref> ... </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2. Approximate successive Fingerprint Section</head><p>The second stage uses the clustering method to reduce the impact of the obfuscated text on the locating. As shown in figure <ref type="figure" coords="6,357.67,314.15,3.77,9.05">1</ref>, a text with obfuscation corresponds to a shadow square that contains a lot of lines and points with a distribution along the direction of 45 degrees. Given ) , , (</p><formula xml:id="formula_1" coords="6,131.89,338.59,338.94,27.20">i i i l y x represents line i a , i</formula><p>x is the beginning position of line i a in the fingerprint vector of the suspicious document, i y is the beginning position of line i a in the fingerprint vector of the source document, i l is the length of the line </p><formula xml:id="formula_2" coords="6,144.86,397.90,212.07,153.44">y i j j i y x y x      ) ( x j i j j j i i i l l l y x l y x           ) ( 4 . 1 ) ( ) ( then i j a a  .</formula><p>By clustering, we can merge these small lines in the shadow square in figure <ref type="figure" coords="6,465.70,556.69,4.98,9.05">1</ref> into a long line. The beginning and the end positions of the long line are the lower left and upper right of the shadow square.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Post-processing</head><p>The locating step uses the distance between approximate successive fingerprint sections to decide whether needs to merge or not. If using the same clustering parameter to merge those copy texts, which have different lengths and different obfuscated degrees, may cause merging errors. The first error is the angle of the merged line deviates from 45 degree too much, because the length of the source fragment and the suspicious fragment that we found are so different. The second error is to merge sparse points. That means only a few fingerprints are the same in merged text. The third error is the same copy text in the suspicious document is found repeatedly in the source document.</p><p>There are two approaches to deal with these copy texts whose angles deviate from 45 degree too much. One approach is to reduce the cluster threshold to re-merge. Another approach is to directly discard these copy texts. Known by experiment, the re-merging will partly improve the precision, but the granularity will be worse, and has negative effects on the overall score, meanwhile, the re-merging impacts performance seriously. Therefore, in actual operation, we directly discard these copy texts.</p><p>For the second merging error, we use the similarity to decide whether discard copy texts. After merging, we compute the similarity of all copy texts, and discard those copy texts whose similarities are less than the threshold. This approach will discard some high-obfuscated copy texts, because the similarity of these copy texts is relatively low. Through repeated experiments, copy texts whose similarities are less than 0.05 have mostly merging error, so we discard them.</p><p>From the analysis of the third merging error, we can find that there are two reasons causing the merging error. One is that we merge some sparse points into a fragment that in fact is not plagiarism. Another is that some fragments in the source document are indeed similar to the same fragment in the suspicious document. In the real competition, we do not know the right answer, so for this situation, we rank the product of the copy text's length and the respective similarity, and then select the copy text whose product is the largest, and discard other copy texts. Through testing in the training dataset, this approach can get a good result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment</head><p>We tested our method in two datasets. One is the union of training and test corpus in PAN-09, including 14429 source documents and 14428 suspicious documents. The other is only test corpus for PAN-09, which is composed of 7215 source documents and 7214 suspicious document.</p><p>Our experiments ran on 8 entries HPC (High Performance Computing). Each entry has a Dual-route Intel Xeon 4 cores 5500 series processor and 4G memory. In each experiment, we started 24 threads, 3 threads of each entry. The total running time was 25 hours in the union corpus, and 7 hours in the test corpus.</p><p>There are 15925 suspicious documents and 11148 source documents in the PAN-10 corpus, and the source documents contain 665 non-English documents. We used google translation api to translate about two thirds of the non-English documents into English. We used the cluster-based plagiarism detection method mentioned above to run this corpus in the same experimental environment, and the overall score is 0.7087, and the rank is: 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The method we proposed is cluster-based plagiarism detection method, which has been used in South China University of Technology to check plagiarism in network engineering related courses. And we also used it to detect external plagiarism in PAN-10 competition. The method uses Winnowing's fingerprint extraction algorithm, consists of three steps: The first step is pre-selecting. For each suspicious document, the task is to find out a small list of candidate documents in which the plagiarized content may exist from the source documents set quickly. The second step is locating, which compares the suspicious document with each document in the candidate documents to get the copy fragments out of the suspicious document. The last step is post-processing, which discards some fragments without plagiarism from the end result</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,323.61,396.86,1.92,1.00;6,318.21,394.12,5.41,1.00;6,328.39,387.11,73.01,9.05;6,408.71,396.86,1.92,1.00;6,403.31,394.12,5.41,1.00;6,413.50,387.11,40.18,9.05;6,465.96,396.86,1.92,1.00;6,460.56,394.12,5.41,1.00;6,124.82,403.07,65.30,9.05;6,202.41,412.81,1.92,1.00;6,197.01,410.07,5.41,1.00;6,207.17,403.07,233.14,9.05;6,452.61,412.81,1.92,1.00;6,447.21,410.07,5.41,1.00;6,462.46,403.07,8.31,9.05;6,124.82,419.29,67.87,9.05;6,211.58,428.91,3.11,1.00;6,204.65,418.12,5.43,10.54;6,199.66,316.62,5.50,109.54;6,216.77,419.29,28.73,9.05;6,259.43,428.93,1.90,1.00;6,252.46,426.18,5.38,1.00;6,268.61,419.29,202.05,9.05;6,132.11,447.01,1.92,1.00;6,126.71,444.27,5.41,1.00;6,141.86,437.29,14.34,9.05;6,170.18,446.93,1.90,1.00;6,163.21,444.18,5.38,1.00;6,179.33,437.29,167.96,9.05;6,360.43,447.01,3.07,1.00;6,353.66,436.24,78.32,10.53;6,446.03,446.93,1.90,1.00;6,439.06,444.18,5.38,1.00;6,455.26,437.29,15.43,9.05;6,124.82,455.17,19.36,9.05;6,156.61,464.91,1.92,1.00;6,151.21,462.17,5.41,1.00;6,161.30,455.17,136.02,9.05;6,144.86,471.13,46.52,9.05;6,206.01,480.86,1.92,1.00;6,200.61,478.12,5.41,1.00;6,212.93,471.13,29.18,9.05;6,256.66,480.86,1.92,1.00;6,251.26,478.12,5.41,1.00;6,268.73,471.13,14.34,9.05;6,316.59,480.84,2.00,1.00;6,297.58,478.09,19.30,3.75;6,292.20,478.09,5.66,1.00;6,302.04,470.48,24.04,9.98;6,356.92,478.08,3.14,1.00;6,342.50,478.08,3.14,1.00;6,348.61,470.45,6.20,10.00;6,334.81,470.45,8.06,10.00;6,364.51,469.47,105.94,10.71;6,124.82,485.17,82.61,9.05"><head></head><label></label><figDesc>idea of the clustering is that, given a passage with</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,126.98,471.77,341.25,8.89;7,274.25,483.29,46.87,8.89;7,144.86,494.41,325.85,9.05;7,124.82,505.81,345.77,9.05;7,124.82,517.33,345.59,9.05;7,124.82,528.85,345.75,9.05;7,124.82,540.37,345.78,9.05;7,124.82,551.77,260.72,9.05;7,144.86,563.29,325.82,9.05;7,124.82,574.84,345.74,9.05;7,124.82,586.36,345.75,9.05;7,124.82,597.76,345.74,9.05;7,124.82,609.28,345.83,9.05;7,124.82,620.80,345.81,9.05;7,124.82,632.32,21.21,9.05;7,144.86,643.72,325.80,9.05;7,124.82,655.24,345.64,9.05;7,124.82,666.76,345.87,9.05;7,124.82,678.28,345.82,9.05;7,124.80,147.35,345.85,321.85"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Three merging errors: a is the first error, b is the second error, c is the third error Analysis to the experimental results shows, there are three major merging errors.The first error is the angle of the merged line deviates from 45 degree too much, because the length of the source fragment and the suspicious fragment that we found are so different. The second error is to merge sparse points. That means only a few fingerprints are the same in merged text. The third error is the same copy text in the suspicious document is found repeatedly in the source document.There are two approaches to deal with these copy texts whose angles deviate from 45 degree too much. One approach is to reduce the cluster threshold to re-merge. Another approach is to directly discard these copy texts. Known by experiment, the re-merging will partly improve the precision, but the granularity will be worse, and has negative effects on the overall score, meanwhile, the re-merging impacts performance seriously. Therefore, in actual operation, we directly discard these copy texts.For the second merging error, we use the similarity to decide whether discard copy texts. After merging, we compute the similarity of all copy texts, and discard those copy texts whose similarities are less than the threshold. This approach will discard some high-obfuscated copy texts, because the similarity of these copy texts is</figDesc><graphic coords="7,124.80,147.35,345.85,321.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="5,138.50,317.30,318.45,261.10"><head></head><label></label><figDesc></figDesc><graphic coords="5,138.50,317.30,318.45,261.10" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,145.82,149.01,309.59,7.31;9,145.82,158.24,261.36,7.32" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,340.21,149.01,115.20,7.31;9,145.82,158.25,59.34,7.31">A Survey on Natural Language Text Copy Detection[J]</title>
		<author>
			<persName coords=""><forename type="first">Bao</forename><surname>Jun-Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shen</forename><surname>Jun-Yi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liu</forename><surname>Xiao-Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Song</forename><surname>Qin-Bao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,211.83,158.24,60.68,7.32">Journal of Software</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1753" to="1760" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,145.82,167.49,295.84,7.31;9,145.82,176.60,313.09,7.32;9,145.82,185.84,172.58,7.32" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,269.83,167.49,171.83,7.31;9,145.82,176.61,55.64,7.31">Plagiarism Detection in Chinese Based on Chunk and Paragraph Weight</title>
		<author>
			<persName coords=""><forename type="first">Wang</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fan</forename><surname>Xiao-Zhong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liu</forename><surname>Jie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,217.73,176.60,241.18,7.32;9,145.82,185.84,51.00,7.32">Proceedings of the Seventh International Conference on Machine Learning and Cybernetics</title>
		<meeting>the Seventh International Conference on Machine Learning and Cybernetics<address><addrLine>Kunming</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-07">July 2008</date>
			<biblScope unit="page" from="2574" to="2579" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,145.82,194.97,307.21,7.31;9,145.82,204.21,92.70,7.31" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="9,202.48,194.97,204.39,7.31">On the Technologies for Building and Accessing a Web Archive</title>
		<author>
			<persName coords=""><forename type="first">Huang</forename><surname>Lian'en</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
		<respStmt>
			<orgName>Peking University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
	<note>Ch</note>
</biblStruct>

<biblStruct coords="9,145.82,213.45,289.95,7.31;9,145.82,222.56,284.68,7.32;9,145.82,231.80,217.41,7.32" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,290.97,213.45,144.80,7.31;9,145.82,222.57,45.28,7.31">Winnowing: Local Algorithms for Document Fingerprinting</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">S S</forename><surname>Schleimer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Aiken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,207.89,222.56,222.61,7.32;9,145.82,231.80,66.47,7.32">Proceedings of the 2003 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2003 ACM SIGMOD International Conference on Management of Data<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="76" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,145.82,240.93,311.89,7.31;9,145.82,250.19,210.94,7.32" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,366.72,240.93,90.99,7.31;9,145.82,250.20,66.35,7.31">Detecting the Origin of Text Segments Efficiently</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Abdel-Hamid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Behzadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Christoph</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Monika</forename><surname>Henzinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,220.37,250.19,36.43,7.32">WWW 2009</title>
		<meeting><address><addrLine>Madrid, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="61" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,145.82,259.43,292.03,7.32" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,225.98,259.44,88.24,7.31">Local Text Reuse Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,322.99,259.43,28.99,7.32">SIGIR&apos;08</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="571" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,145.82,268.56,304.84,7.31;9,145.82,277.79,322.08,7.32" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,258.37,268.56,192.29,7.31;9,145.82,277.80,146.89,7.31">Algorithm of the Longest Commonly Consecutive Word for Plagiarism Detection in Text Based Document</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sediyono</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Mahamud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,302.71,277.79,103.18,7.32">Digital Information Management</title>
		<imprint>
			<biblScope unit="page" from="253" to="259" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,145.82,286.92,297.96,7.31;9,145.82,296.15,318.72,7.32;9,145.82,306.23,217.45,7.32" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,229.52,286.92,214.26,7.31;9,145.82,296.16,159.33,7.31">Using Copy-Detection and Text Comparison Algorithms for Cross-Referencing Multiple Editions of Literature works</title>
		<author>
			<persName coords=""><forename type="first">Arkady</forename><surname>Zaslavsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,314.59,296.15,149.95,7.32;9,145.82,306.23,139.10,7.32">the 5th European Conference on Research and Advanced Technology for Digital Libraries</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="3" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,145.82,315.72,298.51,7.31;9,145.82,324.95,139.67,7.32;9,285.55,323.55,4.44,4.59;9,292.03,324.95,168.29,7.32;9,145.82,334.07,137.87,7.32" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,340.49,315.72,103.83,7.31;9,145.82,324.96,118.27,7.31">Overview of the1st International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Eiselt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,281.47,324.95,4.02,7.32;9,285.55,323.55,4.44,4.59;9,292.03,324.95,168.29,7.32;9,145.82,334.07,93.09,7.32">3 rd PAN Workshop. Uncovering Plagiarism, Authorship and Social Software Misuse</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,145.82,343.32,300.98,7.31;9,145.82,352.55,123.57,7.32;9,269.45,351.15,4.44,4.59;9,275.95,352.55,182.24,7.32;9,145.82,361.67,125.87,7.32" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,260.63,343.32,186.17,7.31;9,145.82,352.56,102.19,7.31">ENCOPLOT:Pairwise Sequence Matching in Linear Time Applied to Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grozea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gehl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,265.37,352.55,4.02,7.32;9,269.45,351.15,4.44,4.59;9,275.95,352.55,182.24,7.32;9,145.82,361.67,73.46,7.32">3 rd PAN Workshop. Uncovering Plagiarism, Authorship and Social Software Misuse</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,145.82,370.92,298.43,7.31;9,145.82,380.03,204.95,7.32;9,350.83,378.63,4.44,4.59;9,357.19,380.03,91.32,7.32;9,145.82,389.27,225.12,7.32" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,370.27,370.92,73.98,7.31;9,145.82,380.04,183.25,7.31">A Plagiarism Detection Procedure in Three Steps:Selection, Matches and Squares</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cristadoro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Benedetto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Caglioti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">Degli</forename><surname>Esposti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,346.75,380.03,4.02,7.32;9,350.83,378.63,4.44,4.59;9,357.19,380.03,91.32,7.32;9,145.82,389.27,170.83,7.32">3 rd PAN Workshop. Uncovering Plagiarism, Authorship and Social Software Misuse</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="19" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,145.82,398.52,299.59,7.31;9,145.82,407.63,57.21,7.32;9,203.09,406.23,4.44,4.59;9,209.45,407.63,240.76,7.32;9,145.82,416.89,73.42,7.32" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,302.48,398.52,142.93,7.31;9,145.82,407.64,36.45,7.31">Finding Plagiarism by Evaluating Document Similarities</title>
		<author>
			<persName coords=""><forename type="first">Jan</forename><surname>Kasprzak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michal</forename><surname>Brandejs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miroslav</forename><surname>Křipă</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,199.01,407.63,4.02,7.32;9,203.09,406.23,4.44,4.59;9,209.45,407.63,240.76,7.32;9,145.82,416.89,20.98,7.32">3 rd PAN Workshop. Uncovering Plagiarism, Authorship and Social Software Misuse</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="24" to="28" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
