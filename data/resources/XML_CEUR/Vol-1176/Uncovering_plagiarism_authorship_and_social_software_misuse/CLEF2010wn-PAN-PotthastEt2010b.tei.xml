<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,156.96,115.93,301.49,12.88;1,210.84,133.93,193.62,12.88">Overview of the 1st International Competition on Wikipedia Vandalism Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,209.52,171.57,60.44,9.03"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Web Technology</orgName>
								<orgName type="department" key="dep2">Information Systems</orgName>
								<orgName type="institution">Bauhaus-Universiät Weimar</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,276.24,171.57,47.62,9.03"><forename type="first">Benno</forename><surname>Stein</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Web Technology</orgName>
								<orgName type="department" key="dep2">Information Systems</orgName>
								<orgName type="institution">Bauhaus-Universiät Weimar</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,347.04,171.57,58.86,9.03"><forename type="first">Teresa</forename><surname>Holfeld</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Web Technology</orgName>
								<orgName type="department" key="dep2">Information Systems</orgName>
								<orgName type="institution">Bauhaus-Universiät Weimar</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,156.96,115.93,301.49,12.88;1,210.84,133.93,193.62,12.88">Overview of the 1st International Competition on Wikipedia Vandalism Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1A873F0FFE3887FB837C99B59879901C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper overviews 9 vandalism detectors that have been developed and evaluated within PAN'10. We start with a survey of 55 different kinds of features employed in the detectors. Then, the detectors' performances are evaluated in detail based on precision, recall, and the receiver operating characteristic. Finally, we set up a meta detector that combines all detectors into one, which turns out to outperform even the best performing detector.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Wikipedia allows everyone to edit its articles, and most of Wikipedia's editors do so for the best. Some, however, don't, and undoing their vandalism requires the time and effort of many. In recent years, a couple of tools have been developed to assist with detecting vandalism, but little is known about their detection performance, while research on vandalism detection is still in its infancy. To foster both research and development, we have organized the 1st competition on vandalism detection, held in conjunction with the 2010 CLEF conference. In this paper we overview the detection approaches of the 9 participating groups and evaluate their performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Vandalism Detection</head><p>We define an edit e as the transition from one Wikipedia article revision to another, where E is the set of all edits on Wikipedia. The task of a vandalism detector is to decide whether a given edit e has been done in bad faith or not. To address this task by means of machine learning three things are needed: a corpus E c ⊂ E of pre-classified edits, an edit model α : E → E, and a classifier c : E → {0, 1}. The edit model maps an edit e onto a vector e of numerical values, called features, where each feature quantifies a certain characteristic of e that indicates vandalism. The classifier maps these feature vectors onto {0, 1}, where 0 denotes regular edits and 1 vandalism edits. Some classifiers map onto [0, 1] instead, where values between 0 and 1 denote the classifier's confidence. To obtain a discrete, binary decision from such classifiers, a threshold τ ∈ [0, 1] is applied to map confidence values onto {0, 1}. In any case, the mapping of c is trained with a learning algorithm that uses the edits in E c as examples. If c captures the concept of vandalism, based on α and E c , then a previously unseen edit e ∈ E \ E c can be checked for vandalism by computing c(α(e)) &gt; τ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Evaluating Vandalism Detectors</head><p>To evaluate a vandalism detector, a corpus of pre-classified edits along with detection performance measures are required. The corpus is split into a training set and a test set. The former is used to train a vandalism detector, while the latter is used to measure its detection performance. For this purpose we have compiled the PAN Wikipedia vandalism corpus 2010, PAN-WVC-10 <ref type="bibr" coords="2,268.20,186.81,15.34,9.03" target="#b24">[10]</ref>. As detection performance measures we employ precision and recall as well as the receiver operating characteristic, ROC. Vandalism Corpus. Until now, two Wikipedia vandalism corpora were available <ref type="bibr" coords="2,464.88,213.69,15.69,9.03" target="#b25">[11,</ref><ref type="bibr" coords="2,134.76,225.69,11.86,9.03" target="#b27">13]</ref>, however, both have shortcomings which render them insufficient for evaluations: they disregard the true distribution of vandalism among all edits, and they have not been double-checked by different annotators. Hence, we have compiled a new, largescale corpus whose edits were sampled from a week's worth of Wikipedia edit logs. The corpus comprises 32 452 edits on 28 468 different articles. It was annotated by 753 annotators recruited from Amazon's Mechanical Turk, who cast more than 190 000 votes so that each edit has been reviewed by at least three of them. The annotator agreement was analyzed in order to determine whether an edit is regular or vandalism, and 2 391 edits were found to be vandalism. Detection Performance Measures. A starting point for the quantification of any classifier's performance is its confusion matrix, which contrasts how often its predictions on a test set match the actual classification:</p><formula xml:id="formula_0" coords="2,255.96,379.94,102.00,56.93">Classifier Actual Prediction P N P TP FP N FN TN</formula><p>In the case of vandalism detectors, vandalism is denoted as P and regular edits as N: TP is the number of edits that are correctly identified as vandalism (true positives), and FP is the number of edits that are untruly identified as vandalism (false positives).</p><p>Likewise, FN and TN count false negatives and true negatives. Important performance measures are computed from this matrix, such as the TP rate, the FP rate, or recall and precision:</p><formula xml:id="formula_1" coords="2,185.52,526.46,241.53,55.62">recall = TP -rate = TP TP + FN precision = TP TP + FP FP -rate = FP FP + TN</formula><p>Plotting precision versus recall spans the precision-recall space, and plotting the TP rate versus the FP rate spans the ROC space. The former is used widely in information retrieval as performance visualization, while the latter is used preferably in machine learning. Despite the fact that recall and TP rate are the same, both spaces visualize different performance aspects and they possess unique properties. In Figure <ref type="figure" coords="2,442.68,652.53,4.98,9.03" target="#fig_0">1</ref>   spaces are exemplified. Figure <ref type="figure" coords="3,260.04,511.17,9.46,9.03" target="#fig_0">1a</ref> lists 20 test edits along with the fact whether or not they are vandalism. For a vandalism detector A its predictions with regard to the classes of every edit are given. Figure <ref type="figure" coords="3,259.08,535.17,10.02,9.03" target="#fig_0">1b</ref> shows the confusion matrix of detector A when τ is set to 0.58 as well as the confusion matrices of three additional detectors B, C, and D. Note that every confusion matrix corresponds to one point in both spaces; Figures <ref type="figure" coords="3,471.24,559.05,9.46,9.03" target="#fig_0">1c</ref> and<ref type="figure" coords="3,151.68,570.93,10.02,9.03" target="#fig_0">1d</ref> show the precision-recall space and the ROC space:</p><p>-Precision-Recall Space. The corners of precision-recall space denote extreme cases: at (0,0) none of the edits classified as vandalism are in fact vandalism, at (1,1) all edits classified as vandalism are vandalism; close to (1,0) all edits are classified as vandalism, and close to (0,1) all edits are classified as being regular. Observe that the latter two points are gaps of definition and therefore unreachable in practice: when constructing a test set to approach them, the values of the confusion matrix become contradictory. The dashed line shows the expected performances of detectors that select classes at random. Note that the classifier characteristics shown in precision-recall space depend on the class distribution in the test set. -ROC Space. The corners of ROC space denote extreme cases: at (0,0) all edits are classified as regular, at (1,1) all edits are classified as vandalism; at (1,0) all edits are classified correctly, at (0,1) all edits are classified incorrectly. The diagonal from (0,0) to (1,1) shows the expected performances of detectors that select classes at random; the ROC space is symmetric about this diagonal by flipping a detector's decisions from vandalism to regular and vice versa. Note that classifier characteristics shown in ROC space are independent of the class distribution in the test set.</p><p>Changing the threshold τ of detector A will lead to a new confusion matrix and, consequently, to a new point in precision-recall space and ROC space respectively. By varying τ between 0 and 1 a curve is produced in both spaces, as shown in Figures <ref type="figure" coords="4,471.24,282.45,9.46,9.03" target="#fig_0">1c</ref> and<ref type="figure" coords="4,152.16,294.45,8.38,9.03" target="#fig_0">1d</ref>. Note that in precision-recall space such curves have sawtooth shape, while in ROC space they are step curves from (0,0) to (1,1). In information retrieval, precisionrecall curves are smoothed, which, however, is unnecessary in large-scale classification tasks, since the class imbalance is not as high as in Web search. By measuring the area under a curve, AUC, a single performance value is obtained that is independent of τ . The better a detector performs, the bigger its AUC. Observe that maximizing the ROC-AUC does not necessarily maximize the precision-recall-AUC <ref type="bibr" coords="4,414.96,366.09,10.60,9.03" target="#b18">[4]</ref>. For discrete classifiers, such as B, the curves can be induced as shown. The ROC-AUC is the same as the probability that two randomly sampled edits, one being regular and one vandalism, are ranked correctly. Ideally, AUC values are measured more than once for a detector on different pairs of training sets and test sets, so that variance can be measured o determine whether a deviation from the random baseline is in fact significant. Due to the limited size of the available corpus, and the nature of a competition, however, we could not apply this strategy.</p><p>From the above it becomes clear that detector A performs best in this example, closely followed by detectors B and D, which perform equally well. Detector C is no better than a random detector that classifies an edit as vandalism with probability 0.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Survey of Detection Approaches</head><p>Out of 9 groups, 5 submitted a report describing their vandalism detector, while 2 sent brief descriptions. This section surveys the detectors in a unified manner. We examine the edit model used, and the machine learning algorithms that have been employed to train the classifiers.</p><p>An edit model function α is made up of features that are supposed to indicate vandalism. A well-chosen set of features makes the task to train a classifier that detects vandalism much easier, whereas a not so well-chosen set of features forestalls a betterthan-chance detection performance. Hence, feature engineering is crucial to the success of a vandalism detector. Note in this connection that no single feature can be expected to separate regular edits from vandalism perfectly. Instead, a set of features does the trick, where each feature highlights different aspects of vandalism, and where the subsequently employed machine learning algorithm is left with using the information provided by the feature set to train a classifier.</p><p>We organize the features employed by all detectors into two categories: features based on an edit's content (cf. Table <ref type="table" coords="5,284.16,166.89,4.18,9.03" target="#tab_1">1</ref>) and features based on meta information about an edit (cf. Table <ref type="table" coords="5,207.12,178.77,3.63,9.03">2</ref>). Each table row describes a particular kind of feature. Moreover, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Edit Type Features Edit Type</head><p>The edit is an insertion, deletion, modification, or a combination.</p><p>[5] Replacement</p><p>The article (a paragraph) is completely replaced, excluding its title.</p><p>[14] Revert</p><p>The edit reverts an article back to a previous revision.</p><p>[14] Blanking Whether the whole article has been deleted. <ref type="bibr" coords="5,442.80,636.41,9.68,8.12" target="#b17">[3,</ref><ref type="bibr" coords="5,454.68,636.41,11.24,8.12" target="#b26">12,</ref><ref type="bibr" coords="5,468.12,636.41,7.99,8.12" target="#b28">14</ref>] Links and Files Number of added links (files) <ref type="bibr" coords="5,465.24,647.45,14.87,8.12" target="#b26">[12]</ref> Table <ref type="table" coords="6,225.24,115.94,3.34,8.05">2</ref>. Features based on meta information about an edit. Editor vandalized before.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature Description References</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Edit Comment Features</head><p>[14] Registration Time the editor was registered with Wikipedia. <ref type="bibr" coords="6,456.36,466.97,9.68,8.12">[5,</ref><ref type="bibr" coords="6,468.24,466.97,11.99,8.12" target="#b28">14]</ref> the right table column indicates who employed which feature in their detectors. Note that our descriptions are not as detailed as those of the original authors, and that they have been reformulated where appropriate in order to highlight similar feature ideas. Content-based features as well as meta information-based features further subdivide into groups of similar kinds. Content-based features on character-level aim at vandalism that sticks out due to unusual typing, whereas features on word-level use dictionaries to quantify the usage of certain word classes and words often used by vandals. Some features even quantify spelling and grammar mistakes. The size of an edit is measured in various ways, and certain edit types are distinguished. The meta information-based features evaluate the comment left by an editor, and the time-related information about an edit. Other features quantify certain characteristics about the edited article in order to better inform the machine learning algorithm about the prevalence of vandalism in an article's history. Moreover, information about an editor's reputation is quantified assuming that reputable editors are less likely to vandalize.</p><p>Finally, all groups, who submitted a description of their approach, employed decision trees in their detectors, such as random forests, alternating decision trees, naive Bayes decision trees, and C4.5 decision trees. Two groups additionally employed other classifiers in an ensemble classifier. The winning detector uses a random forest of 1000 trees at 5 random features each.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation Results</head><p>In this section we report on the detection performances of the vandalism detectors that took part in PAN. To determine the winning detector, their overall detection performance is measured as AUC in ROC space and precision-recall space. Moreover, the detectors' curves are visualized in both spaces to gain further insight into their performance characteristics. Finally, we train and evaluate a meta detector which combines the predictions made by the individual detectors to determine what performance can be expected from a detector that incorporates all of the aforementioned features. We find that the meta detector outperforms all of the other detectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overall Detection Performance</head><p>Table <ref type="table" coords="7,158.88,350.01,4.98,9.03">3</ref> shows the final ranking among the 9 vandalism detectors according to their area under the ROC curve. Further, each detector's area under the precision-recall curve is given as well as the different ranking suggested by this measure. Both values measure the detection performance of a detector on the 50% portion of the PAN-WVC-10 corpus that was used as test set, which comprises 17 443 edits of which 1481 are vandalism. The winning detector is that of Mola Velasco <ref type="bibr" coords="7,321.24,409.77,10.81,9.03">[9]</ref>; it clearly outperforms the other detectors with regard to both measures. The performances of the remaining detectors vary from good to poor performance. As a baseline for comparison, the expected detection performance of a random detector is given. Table <ref type="table" coords="7,157.80,464.54,3.34,8.05">3</ref>. Final ranking of the vandalism detectors that took part in PAN 2010. For simplicity, each detector is referred to by last name of the lead developer. The detectors are ranked by their area under the ROC curve, ROC-AUC. Also, each detector's area under the precision-recall curve, PR-AUC, is given, along with the ranking difference suggested by this measure. The bottom row shows the expected performance of a random detector. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ROC-AUC</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Visualizing Detection Performance in Precision-Recall Space and ROC Space</head><p>Figures <ref type="figure" coords="8,167.40,138.93,4.98,9.03" target="#fig_2">2</ref> and<ref type="figure" coords="8,192.12,138.93,4.98,9.03" target="#fig_3">3</ref> show the precision-recall space and the ROC space, and in each space the respective curves of the vandalism detectors are plotted. Note that all detectors supplied predictions for every edit in the test set, however, some detectors' prediction values are less fine-grained than those of others, which can be also observed by looking at the smoothness of a curve.</p><p>In precision-recall space, the detector of Mola Velasco is the only detector that achieves a nearly perfect precision at recall values smaller than 0.2. All other curves have lower precision values to begin with, and they fall off rather quickly with recall increasing to 0.2. An exception is the detector of Chichkov. While the curves of the detectors on ranks 5-8 behave similar at all times, those of the top 4 detectors behave different up to a recall of 0.7, but similar onwards. Here, the detectors of Chichkov and Javanmardi outperform the winning detector to some extent. Altogether, the winning  detector clearly outperforms the other detectors by far in precision-recall space, but it does not dominate all of them, which shows possibilities for improvements. Nevertheless, its threshold can be adjusted so that 20% of the vandalism cases will be detected with virtually perfect precision, i.e., it can be used without constant manual doublechecking of its decisions. This has serious practical implications and cannot be said of any other detector in the competition. By contrast, in ROC space, the detectors' curves appear to be much more uniform. Still, some detectors perform worse than others, but differences are less obvious. The top 4 detectors and the detectors on ranks 5-8 behave similar at FP rates below 0.4. The winning detector is outperformed by those of Chichkov and Javanmardi at FP rates between 0.1 and 0.  it does not set it apart from the rest, which may lead to the conclusion that the different approaches and feature sets employed are not so different, after all. Discussion. The differences between precision-recall space and ROC space underline that they indeed possess unique properties, but they also raise the question, who's right?</p><p>To answer this question for a particular classification task, it has to be determined whether the precision or the FP rate is more important. For vandalism detection, due to the class imbalance between regular edits and vandalism edits, precision may be more important, which questions our decision made before the competition to use the ROC-AUC to rank vandalism detectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Combining all Vandalism Detectors: The PAN'10 Meta Detector</head><p>Our evaluation shows that there is definite potential to improve vandalism detectors even further: the winning detector does not dominate all other detectors, and more importantly, no detector uses all features, yet. In what follows, we report on an experiment to determine what the performance of a detector that incorporates all features would be.</p><p>To this end, we have set up the PAN'10 meta detector that trains a classifier based on the predictions of all vandalism detectors for the set of test edits. The meta detector thus combines the feature information encoded in the detectors' predictions.</p><p>Let E c denote the PAN-WVC-10 corpus of edits whose classification is known, and let C denote the set of detectors developed for PAN, where every c ∈ C maps an edit model α c (e) = e, e ∈ E c , onto [0, 1]. E c was split into a training set E c|train and a test set E c|test . In the course of the competition, every c ∈ C was trained based on E c|train and then used to predict whether or not the edits in E c|test are vandalism. Instead of analyzing those predictions to determine the performance of the detectors in C-as was done in the previous section-E c|test is split again into E c|test|train and E c|test|test . The former is used to train our new meta detector c PAN , while the latter is used to test its performance. For c PAN an edit e ∈ E c|test is modeled as a vector e of predictions made by the detectors in C: e = (c 1 (α c1 (e)), . . . , c |C| (α c |C| (e))) where c i ∈ C. That way, without re-implementing the detectors, it is possible to test the impact of combining the edit models of all detectors. To train c PAN we employ a random forest of 1000 trees at 4 random features each. E c|test|train and E c|test|test both comprise 8721 edits of which 713 and 768 are vandalism, respectively.  Table <ref type="table" coords="11,174.48,331.53,4.98,9.03" target="#tab_5">4</ref> contrasts the overall performance of our meta detector with the top 4 vandalism detectors in the competition: the meta detector outperforms the winning detector by 5% ROC-AUC and by 16% PR-AUC. Note that, in order to make a fair comparison, we have recomputed both measures for the top 4 detectors based only on E c|test|test . Figure <ref type="figure" coords="11,163.92,379.41,4.98,9.03" target="#fig_4">4</ref> visualizes precision-recall space and ROC space for the 5 detectors. In both spaces, the meta detector's curves stick out notably. Observe that, in precision-recall space, the meta detector is still outperformed by the winning detector at recall values below 0.2. While in ROC space, the meta detector's curve lies uniformly above the others, the respective curve in precision-recall space shows that the meta detector gains more performance at recall values above 0.4. This shows that none of the detectors provide the meta detector with additional information to correct errors in high-confidence predictions, whereas, a lot of errors are corrected in low-confidence predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In summary, the results of the 1st international competition on vandalism detection are the following: 9 vandalism detectors have been developed, which include a total of 55 features to quantify vandalism characteristics of an edit. One detector achieves outstanding performance which allows for its practical use. Further, all vandalism detectors can be combined into a meta detector that even outperforms the single best performing detector. This shows that there is definite potential to develop better detectors.</p><p>Lessons learned from the competition include that the evaluation of vandalism detectors cannot be done solely based on the receiver operating characteristic, ROC, and the area under ROC curves. Instead, an evaluation based on precision and recall provides more insights. Despite the good performances achieved, vandalism detectors still have a long way to go, which pertains particularly to the development of vandalismindicating features. It is still unclear, which features contribute how much to the detection performance. Finally, the corpora used to evaluate vandalism detectors require further improvement with regard to annotation errors. Future evaluations of vandalism detectors will have to address these shortcomings.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,134.76,435.14,345.74,8.16;3,134.76,446.21,345.83,8.12;3,134.76,457.08,345.76,8.18;3,134.76,468.05,345.71,8.12;3,134.76,479.09,345.83,8.12;3,134.76,490.01,304.28,8.12"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. (a) A set of test edits, their actual classes, and predictions for them from a vandalism detector A which employs a continuous classifier. (b) Confusion matrices of four vandalism detectors A, B, C, and D. For A, threshold τ = 0.58 is assumed, whereas B, C, and D employ discrete classifiers. (c) Precision-recall space that illustrates the performances of the four detectors. The precision-recall curve for A is given. (d) ROC space that illustrates the performances of the four detectors. The ROC curve of A is given, and for B an ROC curve is induced.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,134.76,642.02,345.76,8.16;8,134.76,652.97,204.08,8.12"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Precision-recall curves of the vandalism detectors developed for PAN. The key is sorted according to the final ranking of the vandalism detectors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,134.76,622.10,345.64,8.16;9,134.76,633.05,166.52,8.12"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. ROC curves of the vandalism detectors developed for PAN. The key is sorted according to the final ranking of the vandalism detectors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="11,134.76,299.54,345.88,8.16;11,134.76,310.49,140.84,8.12"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Precision-recall curves and ROC curves of the PAN'10 meta detector and the top 4 vandalism detectors in the competition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,450.60,652.53,29.94,9.03"><head>the two Edit Actual Detector A</head><label></label><figDesc></figDesc><table coords="3,136.08,119.62,343.41,304.95"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Edit Actual Detector A</cell><cell cols="5">Detector A Actual</cell><cell cols="2">Detector B Actual</cell></row><row><cell cols="3">1 regular</cell><cell></cell><cell>0.93</cell><cell cols="2">11 vandalism</cell><cell>0.59</cell><cell cols="4">Prediction P N</cell><cell></cell><cell cols="2">Prediction P N</cell></row><row><cell cols="4">2 vandalism</cell><cell>0.89</cell><cell cols="2">12 regular</cell><cell>0.56</cell><cell></cell><cell></cell><cell></cell><cell>P 8 3</cell><cell></cell><cell></cell><cell>P 6 2</cell></row><row><cell cols="4">3 vandalism</cell><cell>0.86</cell><cell cols="2">13 vandalism</cell><cell>0.53</cell><cell></cell><cell></cell><cell></cell><cell>N 2 7</cell><cell></cell><cell></cell><cell>N 4 8</cell></row><row><cell cols="4">4 vandalism</cell><cell>0.83</cell><cell cols="2">14 regular</cell><cell>0.49</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">5 regular</cell><cell></cell><cell>0.79</cell><cell cols="2">15 vandalism</cell><cell>0.46</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">6 regular 7 vandalism</cell><cell>0.76 0.73</cell><cell cols="2">16 regular 17 regular</cell><cell>0.43 0.39</cell><cell cols="4">Detector C Actual Prediction P N</cell><cell></cell><cell cols="2">Detector D Actual Prediction P N</cell></row><row><cell cols="4">8 vandalism 9 vandalism</cell><cell>0.69 0.66</cell><cell cols="2">18 regular 19 regular</cell><cell>0.36 0.33</cell><cell></cell><cell></cell><cell></cell><cell>P 7 7</cell><cell></cell><cell></cell><cell>P 2 6</cell></row><row><cell cols="4">10 vandalism</cell><cell>0.63</cell><cell cols="2">20 regular</cell><cell>0.29</cell><cell></cell><cell></cell><cell></cell><cell>N 3 3</cell><cell></cell><cell></cell><cell>N 8 4</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(a)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(b)</cell><cell></cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell>B</cell><cell>A</cell><cell></cell><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Precision</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell></cell><cell>C</cell><cell></cell><cell></cell><cell>TP rate</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell>D</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell><cell></cell><cell>0</cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Recall</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">FP rate</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(c)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,135.24,197.78,344.87,387.48"><head>Table 1 .</head><label>1</label><figDesc>Features based on an edit's textual difference between old and new article revision.</figDesc><table coords="5,135.24,219.50,105.67,8.05"><row><cell>Feature</cell><cell>Description</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,134.76,238.65,345.90,369.72"><head></head><label></label><figDesc>2, as well as those of Adler et al., Hegedűs et al., and Seaward at FP rates above 0.6. Altogether, this visualization supports the winning detector but</figDesc><table coords="9,137.42,272.69,343.02,335.68"><row><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TP rate</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Adler Mola Velasco</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Javanmardi</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Chichkov</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Seaward</cell><cell></cell></row><row><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Harpalani Hegedüs</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>White</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Iftene</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Random Detector</cell><cell></cell></row><row><cell>0</cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>FP rate</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,134.76,525.50,345.71,121.92"><head>Table 4 .</head><label>4</label><figDesc>Detection performance of the PAN'10 meta detector and the top 4 detectors in the competition, measured by the areas under the ROC curve and the precision-recall curve, PR-AUC.</figDesc><table coords="10,212.40,560.06,190.54,87.36"><row><cell>ROC-AUC</cell><cell>PR-AUC</cell><cell>Detector</cell></row><row><cell>0.95690</cell><cell>0.77609</cell><cell>PAN'10 Meta Detector</cell></row><row><cell>0.91580</cell><cell>0.66823</cell><cell>Mola Velasco [9]</cell></row><row><cell>0.90244</cell><cell>0.49483</cell><cell>Adler et al. [1]</cell></row><row><cell>0.89915</cell><cell>0.45144</cell><cell>Javanmardi [8]</cell></row><row><cell>0.89424</cell><cell>0.56951</cell><cell>Chichkov [3]</cell></row><row><cell>0.50000</cell><cell>0.08805</cell><cell>Random Detector</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,135.24,278.81,222.80,8.12" xml:id="b0">
	<monogr>
		<title level="m" coord="5,135.24,278.81,219.29,8.12">Special Chars Ratio of non-alphanumeric chars to all chars</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,135.24,300.77,33.04,8.12;5,196.56,300.77,231.56,8.12" xml:id="b1">
	<monogr>
		<title level="m" coord="5,135.24,300.77,33.04,8.12;5,196.56,300.77,228.12,8.12">Diversity Length of all inserted lines to the (1 / number of different chars)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,135.24,311.69,37.36,8.12;5,196.56,311.69,130.04,8.12" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="5,135.24,311.69,37.36,8.12;5,196.56,311.69,126.21,8.12">Repetition Number of repeated char sequences</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,135.24,333.65,206.84,8.12" xml:id="b3">
	<monogr>
		<title level="m" coord="5,135.24,333.65,203.36,8.12">Compressibility Compression rate of the edit differences</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,462.69,333.65,17.41,8.12;5,135.24,344.57,28.84,8.12;5,196.56,344.57,203.12,8.12" xml:id="b4">
	<monogr>
		<title level="m" coord="5,135.24,344.57,28.84,8.12;5,196.56,344.57,199.31,8.12">Spacing Length of the longest char sequence without whitespace</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,135.24,355.49,28.24,8.12;5,196.56,355.49,212.12,8.12" xml:id="b5">
	<monogr>
		<title level="m" coord="5,135.24,355.49,28.24,8.12;5,196.56,355.49,208.61,8.12">Markup Ratio of new (changed) wikitext chars to all wikitext chars</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,196.56,392.93,268.64,8.12" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="5,196.56,392.93,265.56,8.12">Vulgarism impact: ratio of new vulgar words to those present in the article</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,135.24,403.85,33.73,8.12;5,196.56,403.85,150.32,8.12" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="5,135.24,403.85,33.73,8.12;5,196.56,403.85,146.39,8.12">Pronouns Frequency (impact) of personal pronouns</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,135.24,414.77,15.97,8.12;5,196.56,414.77,131.36,8.12" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="5,135.24,414.77,15.97,8.12;5,196.56,414.77,127.37,8.12">Bias Frequency (impact) of biased words</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,135.24,425.81,13.36,8.12;5,196.56,425.81,147.68,8.12" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="5,135.24,425.81,13.36,8.12;5,196.56,425.81,143.69,8.12">Sex Frequency (impact) of sex-related words</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,135.24,436.73,45.73,8.12;5,196.56,436.73,128.24,8.12" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="5,135.24,436.73,45.73,8.12;5,196.56,436.73,124.71,8.12">Contractions Frequency (impact) of contractions</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,135.24,447.65,36.33,8.12;5,196.56,447.65,143.36,8.12" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="5,135.24,447.65,36.33,8.12;5,196.56,447.65,139.37,8.12">Sentiment Frequency (impact) of sentiment words</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,462.69,447.65,17.41,8.12;5,135.24,458.69,261.80,8.12" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="5,135.24,458.69,258.15,8.12">Vandal words Frequency (impact) of the top-k words used by vandals</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,135.24,496.06,115.57,7.98;5,135.24,506.93,242.12,8.12" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="5,135.24,496.06,115.57,7.98;5,135.24,506.93,238.68,8.12">Spelling and Grammar Features Word Existence Ratio of words that occur in an English dictionary</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,135.24,517.85,29.92,8.12;5,196.56,517.85,136.04,8.12;5,447.24,517.85,32.87,8.12;5,135.24,528.89,34.31,8.12;5,196.56,528.89,111.56,8.12" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="5,135.24,517.85,29.92,8.12;5,196.56,517.85,132.74,8.12">Spelling Frequency (impact) of spelling errors</title>
		<imprint/>
	</monogr>
	<note>5, 9, 12] Grammar Number of grammatical errors</note>
</biblStruct>

<biblStruct coords="12,154.68,186.53,308.44,8.12;12,154.68,197.45,274.55,8.12;12,154.68,208.37,71.96,8.12" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="12,327.24,186.53,135.88,8.12;12,154.68,197.45,146.59,8.12">Detecting Wikipedia Vandalism using WikiTrust: Lab Report for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">Thomas</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luca</forename><surname>De Alfaro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Pye</surname></persName>
		</author>
		<editor>Braschler et al.</editor>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.68,219.41,305.13,8.12;12,154.68,230.33,281.75,8.12;12,154.68,241.25,71.96,8.12" xml:id="b16">
	<monogr>
		<title level="m" coord="12,389.40,219.46,70.41,7.98;12,154.68,230.38,118.62,7.98">Notebook Papers of CLEF 2010 LABs and Workshops</title>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Emanuele</forename><surname>Pianta</surname></persName>
		</editor>
		<meeting><address><addrLine>Padua, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-09">September. 2010</date>
			<biblScope unit="page" from="22" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.68,252.29,290.18,8.12;12,154.68,263.21,188.96,8.12" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Dmitry</forename><surname>Chichkov</surname></persName>
		</author>
		<title level="m" coord="12,222.36,252.29,222.50,8.12;12,154.68,263.21,73.42,8.12">Submission to the 1st International Competition on Wikipedia Vandalism Detection</title>
		<meeting><address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>SC Software Inc</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.68,274.13,311.50,8.12;12,154.68,285.05,299.78,8.12;12,154.68,296.09,319.17,8.12;12,154.68,307.01,98.12,8.12" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="12,273.96,274.13,192.22,8.12;12,154.68,285.05,21.77,8.12">The Relationship Between Precision-Recall and ROC curves</title>
		<author>
			<persName coords=""><forename type="first">Jesse</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Goadrich</surname></persName>
		</author>
		<idno type="DOI">10.1145/1143844.1143874</idno>
	</analytic>
	<monogr>
		<title level="m" coord="12,193.08,285.10,261.38,7.98;12,154.68,296.14,31.11,7.98">ICML&apos;06: Proceedings of the 23rd International Conference on Machine Learning</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.68,317.93,325.89,8.12;12,154.68,328.97,301.96,8.12;12,154.68,339.89,166.88,8.12" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="12,462.96,317.93,17.61,8.12;12,154.68,328.97,268.87,8.12">Wiki Vandalysis-Wikipedia Vandalism Analysis: Lab Report for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Manoj</forename><surname>Harpalani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thanadit</forename><surname>Phumprao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Megha</forename><surname>Bass</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rob</forename><surname>Johnson</surname></persName>
		</author>
		<editor>Braschler et al.</editor>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.68,350.81,307.60,8.12;12,154.68,361.85,317.13,8.12;12,154.68,372.77,224.12,8.12" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="12,405.12,350.81,57.16,8.12;12,154.68,361.85,317.13,8.12;12,154.68,372.77,22.03,8.12">Novel Balanced Feature Representation for Wikipedia Vandalism Detection Task: Lab Report for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">István</forename><surname>Hegedűs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Róbert</forename><surname>Ormándi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richárd</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Márk</forename><surname>Jelasity</surname></persName>
		</author>
		<editor>Braschler et al.</editor>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.68,383.69,316.10,8.12;12,154.68,394.73,199.04,8.12" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="12,208.20,383.69,262.58,8.12;12,154.68,394.73,33.34,8.12">Submission to the 1st International Competition on Wikipedia Vandalism Detection</title>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Iftene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,217.44,394.73,96.52,8.12">From the Universtiy of Iasi</title>
		<meeting><address><addrLine>Romania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.68,405.65,291.62,8.12;12,154.68,416.57,274.16,8.12" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="12,223.80,405.65,222.50,8.12;12,154.68,416.57,73.42,8.12">Submission to the 1st International Competition on Wikipedia Vandalism Detection</title>
		<author>
			<persName coords=""><forename type="first">Sarah</forename><surname>Javanmardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,257.52,416.57,119.45,8.12">From the Universtiy of California</title>
		<meeting><address><addrLine>Irvine, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.68,427.61,318.57,8.12;12,154.68,438.53,325.88,8.12;12,154.68,449.45,110.60,8.12" xml:id="b23">
	<monogr>
		<title level="m" type="main" coord="12,255.24,427.61,218.01,8.12;12,154.68,438.53,237.07,8.12">Wikipedia Vandalism Detection Through Machine Learning: Feature Review and New Proposals: Lab Report for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">Mola</forename><surname>Santiago</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Velasco</surname></persName>
		</author>
		<editor>Braschler et al.</editor>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.68,460.49,300.68,8.12;12,154.68,471.41,316.88,8.12;12,154.68,482.33,314.44,8.12;12,154.68,493.37,236.12,8.12" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="12,215.64,460.49,166.96,8.12">Crowdsourcing a Wikipedia Vandalism Corpus</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<idno type="DOI">10.1145/1835449.1835617</idno>
	</analytic>
	<monogr>
		<title level="m" coord="12,202.44,482.38,162.37,7.98">Annual International ACM SIGIR Conference</title>
		<editor>
			<persName><forename type="first">Hsin-Hsi</forename><surname>Chen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Efthimis</forename><forename type="middle">N</forename><surname>Efthimiadis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jaques</forename><surname>Savoy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Stéphane</forename><surname>Marchand-Maillet</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010-07">July 2010</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="789" to="790" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.68,504.29,307.60,8.12;12,154.68,515.21,319.24,8.12;12,154.68,526.25,318.40,8.12;12,154.68,537.17,293.80,8.12;12,154.68,548.09,314.03,8.12;12,154.68,559.13,269.36,8.12" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="12,338.04,504.29,124.24,8.12;12,154.68,515.21,35.28,8.12">Automatic Vandalism Detection in Wikipedia</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Gerling</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-540-78646-7_75</idno>
		<ptr target="http://dx.doi.org/10.1007/978-3-540-78646-7_75" />
	</analytic>
	<monogr>
		<title level="m" coord="12,222.12,526.29,250.96,7.98;12,154.68,537.21,144.57,7.98">Advances in Information Retrieval: Proceedings of the 30th European Conference on IR Research (ECIR 2008)</title>
		<title level="s" coord="12,354.72,537.17,93.76,8.12;12,154.68,548.13,63.96,7.98">LNCS of Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vassilis</forename><surname>Plachouras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ian</forename><surname>Ruthven</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ryen</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">4956</biblScope>
			<biblScope unit="page" from="663" to="668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.68,570.05,287.30,8.12;12,154.68,580.97,246.32,8.12" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="12,219.48,570.05,222.50,8.12;12,154.68,580.97,73.42,8.12">Submission to the 1st International Competition on Wikipedia Vandalism Detection</title>
		<author>
			<persName coords=""><forename type="first">Leanne</forename><surname>Seaward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,257.52,580.97,108.29,8.12">From the Universtiy of Ottawa</title>
		<meeting><address><addrLine>Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.68,592.01,313.70,8.12;12,154.68,602.93,313.94,8.12;12,154.68,613.85,318.20,8.12;12,154.68,624.89,238.28,8.12" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="12,341.04,592.01,127.34,8.12;12,154.68,602.93,171.10,8.12">Detecting Wikipedia Vandalism via Spatio-Temporal Analysis of Revision Metadata</title>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sampath</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Insup</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1145/1752046.1752050</idno>
	</analytic>
	<monogr>
		<title level="m" coord="12,342.84,602.97,125.78,7.98;12,154.68,613.89,163.14,7.98">EUROSEC &apos;10: Proceedings of the Third European Workshop on System Security</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="22" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.68,635.81,318.95,8.12;12,154.68,646.73,232.76,8.12" xml:id="b28">
	<monogr>
		<title level="m" type="main" coord="12,287.64,635.81,185.99,8.12;12,154.68,646.73,30.79,8.12">ZOT! to Wikipedia Vandalism: Lab Report for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rebecca</forename><surname>Maessen</surname></persName>
		</author>
		<editor>Braschler et al.</editor>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
