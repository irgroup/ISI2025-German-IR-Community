<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,155.04,150.38,297.04,14.47;1,193.20,167.90,209.07,14.47;1,207.36,187.96,180.60,10.80">Fuzzy Semantic-Based String Similarity for Extrinsic Plagiarism Detection Lab Report for PAN at CLEF 2010</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,236.64,224.56,64.23,9.07"><forename type="first">Salha</forename><surname>Alzahrani</surname></persName>
							<email>s.zahrani@tu.edu.sa</email>
						</author>
						<author>
							<persName coords="1,309.34,224.56,57.27,9.07"><forename type="first">Naomie</forename><surname>Salim</surname></persName>
							<email>naomie@utm.my</email>
							<affiliation key="aff1">
								<orgName type="department">FSKSM</orgName>
								<orgName type="institution">Universiti Teknologi Malaysia</orgName>
								<address>
									<settlement>Johor Bahru</settlement>
									<country key="MY">Malaysia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Faculty of computer Science and Information Systems</orgName>
								<orgName type="institution">Taif Univeristy</orgName>
								<address>
									<settlement>Taif</settlement>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,155.04,150.38,297.04,14.47;1,193.20,167.90,209.07,14.47;1,207.36,187.96,180.60,10.80">Fuzzy Semantic-Based String Similarity for Extrinsic Plagiarism Detection Lab Report for PAN at CLEF 2010</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D98CC570ADB07A6CA67CAC4078AD8F47</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This report explains our plagiarism detection method using fuzzy semantic-based string similarity approach. The algorithm was developed through four main stages. First is pre-processing which includes tokenisation, stemming and stop words removing. Second is retrieving a list of candidate documents for each suspicious document using shingling and Jaccard coefficient. Suspicious documents are then compared sentence-wise with the associated candidate documents. This stage entails the computation of fuzzy degree of similarity that ranges between two edges: 0 for completely different sentences and 1 for exactly identical sentences. Two sentences are marked as similar (i.e. plagiarised) if they gain a fuzzy similarity score above a certain threshold. The last step is post-processing whereby consecutive sentences are joined to form single paragraphs/sections. Our performance measures on PAN'09 training corpus for external plagiarism detection task (recall=0. 3097,  precision=0.5424, granularity=7.8867)  indicates that about 54% of our detections are correct while we detect only 30% of the plagiarism cases. The performance measures on PAN'10 test collection is less (recall= 0.1259, precision= 0.5761, granularity= 3.5828), due to the fact that our algorithm handles external plagiarism detection but neither intrinsic nor cross-lingual. Although our fuzzy semantic-based method can detect some means of obfuscation, it might not work at all levels. Our future work is to improve it for more detection efficiency and less time complexity. In particular, we need to advance the post-processing stage to gain more ideal granularity.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Plagiarism could be more fuzzy than clear, more complex than trivial copy and paste. Methods for plagiarism detection mostly track verbatim plagiarism; however, detecting excessive paraphrasing is a difficult task. Many current techniques rely on exactly matched substrings or some kinds of textual fingerprinting. But that may not be sufficient as cases of rephrasing and rewording the content treated as different (i.e. not plagiarised). Therefore, this work considers the problem of finding the suspected fragments that have the same semantics with the same/different syntax. In this regard, matching fragments of text becomes approximate or vague and can be implemented as a spectrum of values between 1 (i.e. exactly matched) and 0 (entirely different). The scale can be defined in a way similar to a human's judgement as in Figure <ref type="figure" coords="2,441.59,160.96,3.67,9.07">1</ref>.</p><p>Our work is similar to the work by <ref type="bibr" coords="2,287.76,184.00,85.51,9.07" target="#b6">Yerra and Ng (2005)</ref>. In their paper, a copy detection approach for web documents was developed using fuzzy information retrieval (IR) model. The fundamental concept in fuzzy IR shows that words in a document have certain degree with a fuzzy set that contains words with related meaning and two documents are considered similar although their semantic content may be different if they gain high similarity degree with the fuzzy set. Thus, fuzzy IR has proved to work well for partially related semantic content in web retrieval. Subsequent to the previous work, <ref type="bibr" coords="2,262.80,264.40,105.60,9.07" target="#b1">Koberstein and Ng (2006)</ref> developed a reliable tool using fuzzy IR for determining the degree of similarity between two web documents and clustering the collection based on words. In addition, <ref type="bibr" coords="2,358.56,287.44,112.08,9.07" target="#b0">Alzahrani and Salim (2009)</ref> adapted the fuzzy IR model for use with Arabic scripts. By using Arabic plagiarism corpus of 4477 source statements and 303 query/suspicious statements, the similarity score of two documents is the averaged similarity among statements treated as plagiarised even if they are restructured or reworded. Experimental results showed that fuzzy IR can find to what extent two Arabic statements are similar or dissimilar. On the other hand, semantic similarity between short passages can be obtained by using the information extracted from a structured lexical database and corpus statistics <ref type="bibr" coords="2,124.80,379.36,65.90,9.07" target="#b2">(Li et al., 2006)</ref>. The similarity of two sentences is derived from two similarities: semantic and order. The semantic vectors for two pairs of sentences are obtained by using unique terms in both sentences along with their synonyms from WordNet besides term weighting in the corpus. The order similarity defines that different words order may convey different meaning and should be count into total string similarity. Our work combines the fuzzy similarity model <ref type="bibr" coords="2,323.24,436.96,89.99,9.07" target="#b6">(Yerra and Ng, 2005)</ref> and semantic similarity model derived from a lexical database <ref type="bibr" coords="2,345.28,448.48,71.61,9.07" target="#b2">(Li et al., 2006)</ref>. Instead of constructing a fuzzy thesaurus derived from word-to-word correlation factors as in <ref type="bibr" coords="2,124.80,471.52,96.70,9.07" target="#b6">Yerra and Ng's (2005)</ref> model, we choose to work with synonyms extracted from WordNet lexical database as in <ref type="bibr" coords="2,252.00,483.04,58.11,9.07" target="#b2">Li et al. (2006)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Statement</head><p>In this report, we have considered the problem stated as follows.</p><p>Problem: Given a suspicious document dataset D q and a large source collection D, find all suspicious parts s q from d q :d q ϵD q that are similar to parts s x from d x :d x ϵD x based on fuzzy semantic-based similarity approach as will be described in section 3. threshold Requirements: First, extract a set of features for each d q ϵD q and dϵD. Second, find a list of most promising documents D x where D x ϲD based on shingling and Jaccard similarity coefficient known in IR. Third, perform sentence-wise in-depth analysis using fuzzy semantic-based approach. Last, perform post-processing operations to merge subsequent similar statements into passages or paragraphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations:</head><p>Neither intrinsic (i.e. variations in writing styles) nor cross-language plagiarism detection is handled by this algorithm. That is, the languages of both suspicious and candidate documents are considered homogeneous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">External Plagiarism Detection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Operational Framework</head><p>We implement an algorithm that tackles monolingual external plagiarism detection. In particular, it is designed to detect different degrees of obfuscation by using a fuzzy semantic-based approach. The operational framework is shown in Figure <ref type="figure" coords="3,442.55,355.84,3.78,9.07">2</ref>. The process starts with a set of source collection D and suspicious/query documents D q . Then new representatives are generated d′ and d′ q for each cleansed and tokenised d q and d documents respectively. d′ and d′ q are then used for shingling and computing the similarity between the shingles. The list of most similar documents for each d q ϵD q is called candidate set D x whereby D x ϲD. After generating D x , more sentence-wise detailed analysis is performed to obtain similar sentences (sq, sx) where sq∈dq, sx∈dx. The similarity score is gained by implementing a fuzzy semantic-based similarity measure between words in both sentences as will be seen shortly. Finally, the system performs post-processing in order to merge similar sentences into passages (pq, px) such that pq∈dq, px∈dx. Subsequent sections detail each stage. Computing Jaccard</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preprocessin</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phase II</head><p>(s q , s x ): s q ∈d q , s x ∈d x</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Report</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence-wise Fuzzy Semantic-Based Detailed Analysis</head><p>Postprocessing WordNet Lexical DB</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Phase I: Retrieval of Similar Documents</head><p>Near duplicate detection methods can be used to bring similar sources and discard dissimilar ones. We use shingling and Jaccard coefficient approach <ref type="bibr" coords="4,428.88,186.40,41.88,9.07;4,124.80,197.92,115.82,9.07" target="#b3">(Manning, Raghavan, &amp; Schütze, 2008)</ref>. The k-shingle (or word-k-gram) referred to a sequence of consecutive words of size k. The value for k is typically 3 or 4. Intuitively, two documents A and B are similar if they share enough k-shingles. By performing union and intersection operations between the k-shingles, we can find the Jaccard similarity coefficient between A and B as stated in equation (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J(A,B)=|shingles of A ∩ shingles of B| / |shingles of A ∪ shingles of B|</head><p>(1)</p><p>Therefore for each suspicious document d q , documents of Jaccard coefficient above a threshold value are taken to form the set of candidate documents D x . We set the threshold of Jaccard ≥ 0.1 because we found that this value derives about 1 to 30 candidate documents for each d q . It was that when we compare documents of Jaccard similarity less than 0.1, either none or about 1-2 plagiarised statements are detected. Also by using this method, we find that some suspicious documents do not have any candidates. That means that they might contain intrinsic plagiarism or do not contain plagiarism at all. More interesting, using this approach assumes the number of candidates for each suspicious document dynamic and may be small. That saves the computation time in contrast to having a fixed number of candidates for each suspicious document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Phase II: In-Depth Detailed Analysis of (dq , d x ) pairs</head><p>At this stage, a sentence-wise detailed analysis between each suspicious document d q and its candidate document d x ∈D x is performed. At first, d q and d x are segmented into sentences S q and S x respectively using end-of-sentence delimiters. To obtain the degree of similarity between two sentences (s q , s x ), a term-to-sentence correlation factor for each term w q in s q and the sentence s x is computed as:</p><formula xml:id="formula_0" coords="4,251.28,517.12,219.60,9.73">µ q,x = 1-∏ wk ∈Sx(1 -F q,k ) (2)</formula><p>where w k are words in s x and F q,k is a fuzzy similarity between w q and w k that we defined as follows:</p><p>1 if w k and w q are identical 0 .5 if w k is in the synset of w q 0 otherwise (3)</p><p>The synset of w q is extracted by querying the WordNet lexical database <ref type="bibr" coords="4,439.68,604.24,30.83,9.07;4,124.80,615.76,21.69,9.07" target="#b4">(Miller, 1995)</ref>. For example, the sentences S 1 ="this car consumes a lot of oil" and S 2 ="this car consumes a lot of petrol" are almost identical except the word oil replaced with petrol. Since the word petrol is found in the synonym set (synset) of oil, both sentences convey the same meaning and the degree of similarity between (s q , s x ) is expressed as a fuzzy number between 0 and 1 using the equation Sim(s q , s x ) = ( µ 1,x + µ 2,x + . . . + µ q,x +. . . + µ n,x ) / n (4)</p><formula xml:id="formula_1" coords="4,187.44,576.16,22.24,9.73">F q,k =</formula><p>where n is the total number of words in s q . Thus, we can calculate the degree of similarity between the S 1 and S 2 as shown in Figure <ref type="figure" coords="5,334.54,160.96,5.04,9.07" target="#fig_2">3</ref> (a) taking into account that stop words were removed and non-stop words were stemmed. Another example is the sentences S 1 ="the teacher gives each student a text that he authored" and S 2 ="a textbook authored by the instructor is given to his pupils" where the later was paraphrased from the first. Since the following word pairs (teach, instruct), <ref type="bibr" coords="5,436.06,207.04,34.70,9.07;5,124.80,218.56,22.73,9.07">(student, pupil)</ref>, (text, textbook) are synonyms, and the rest of words are identical, these sentences gain high similarity score of 0.7 as shown in Figure <ref type="figure" coords="5,387.11,230.08,5.04,9.07" target="#fig_2">3</ref>  <ref type="bibr" coords="5,395.75,230.08,10.53,9.07">(b)</ref>. This indicates that sentences are semantically alike. It is noticeable that stemming the words can handle some means of obfuscation. Both of the previous examples have sentences with equal number of words. An example of a sentence pair with different lengths and semantics is S 1 = "this car consumes a lot of oil" and S 2 ="the engine of this car is of poor quality and consumes a lot of petrol". In this case, Sim(S 1 ,S 2 )≠ Sim(S 2 ,S 1 ). Thus to judge two sentences as equal (i.e. plagiarised), the minimum similarity score should be above a threshold value (α &gt;0.65) as in ( <ref type="formula" coords="5,303.97,310.48,3.51,9.07">5</ref>). According to this, the last pair shown in Figure <ref type="figure" coords="5,163.90,322.00,14.80,9.07" target="#fig_2">3 (c</ref>) is considered dissimilar because the minimum similarity is less than α.</p><p>1 if MIN(Sim(s q , s x ), Sim(s q , s x )) ≥ α 0 otherwise (5) Finally, the output of this algorithm is a list of sentence pairs (s q , s x ): s q ∈d q , s x ∈d x , d x ∈D marked as similar/plagiarised. Because of using sentences as comparison scheme, post-processing is required to merge subsequent sentences marked as plagiarised into passages. Also, we consider small distances under the predicate less than or equal to 100 characters to merge subsequent plagiarised sentences into passages pairs (p q , p x ) : p q ∈d q , p x ∈d x , d x ∈D x . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Instrumentation</head><p>Our algorithm has been built using C#.NET 2008. By using different libraries such as Linq, we perform sets operation to compute Jaccard similarity. We used a server with 4-core processors, 2.8 GHz. To utilise all cores, we have migrated our code to work on Visual Studio.NET 2010 which has introduced the concept of parallel computing<ref type="foot" coords="6,461.52,236.94,3.00,5.40" target="#foot_0">1</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Code Configuration</head><p>Below is a list of some parameters and settings that we have configured in our code.  For pre-processing, stop words removal and porter stemmer <ref type="bibr" coords="6,411.59,298.00,59.04,9.07" target="#b5">(Porter, 1980)</ref> algorithms were used.  For generating k-shingles, the k was set to 3 (i.e. word-3-grams).  For computing Jaccard similarity and finding candidates, a threshold value of Jaccard=0.1 was set to filter out non-candidate documents.  For semantic-based analysis, WorldNet v3.0 using MySQL<ref type="foot" coords="6,389.28,357.18,3.00,5.40" target="#foot_1">2</ref> was used to query the Synset table and extract synonyms of the words.  For fuzzy similarity between two sentences, the equations ( <ref type="formula" coords="6,385.15,380.56,3.81,9.07">2</ref>)-( <ref type="formula" coords="6,400.38,380.56,3.81,9.07">5</ref>) was employed, and the threshold in ( <ref type="formula" coords="6,238.34,392.08,3.92,9.07">5</ref>) was set to α= 0.65 which was found to be the most suitable based on our experimental trials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation and Discussion on PAN'09 and PAN'10</head><p>In the PAN'09 extrinsic part, the recall was 0.3097 and the precision was 0.5424. In PAN'10, we submitted partial results of about 56.25% of the suspicious documents at first. Our full results on PAN'10 are presented in this paper (recall= 0.1259, precision= 0.5761, granularity= 3.5828). Our results are of both PAN'09 and PAN'10 are comparable as shown in Table <ref type="table" coords="6,266.16,514.96,3.78,9.07" target="#tab_0">1</ref>. The results in PAN'10 showed that we detected about 12% of the plagiarism cases and about 57% of the detections were correct. The low recall might be for the reasons: (i) the algorithm was designed for extrinsic plagiarism task and did not tackle intrinsic nor cross-lingual plagiarism, (ii) we used stems instead of lemmas in pre-processing; however, WordNet needs lemmas which needs to be corrected in the future model, and (iii) the candidates compared were not enough to find more plagiarism cases. The precision of the algorithm shows that 57% of the detections were correct. Two words may be synonyms but with different senses and hence different meaning that make sentences not plagiarised which may lead to more false positives by our algorithm. Moreover, statements of short lengths might get a fuzzy similarity score of more than 0.65 easily; another reason for false positives. The ability of detecting each plagiarism case at once was bigger than 1 because the algorithm enabled the merging process of sentences if and only if they are subsequent or with few characters in between. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Future Work</head><p>Our future work is to improve it for more detection efficiency and less time complexity. We will consider the following work: (i) using word-k-grams instead of sentences, (ii) using a Lemmatiser instead of the stemmer to get better results from WordNet, and (iii) modifying the post-processing stage to gain more ideal granularity.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,187.44,556.89,220.76,8.21"><head>Figure1.</head><label></label><figDesc>Figure1. Fuzzy Similarity Indication with Vague Boundaries</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,149.04,673.05,297.52,8.21"><head>Figure2.</head><label></label><figDesc>Figure2. Operational Framework of Our External Plagiarism Detection Algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,212.40,648.81,170.53,8.21"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Examples of different sentence pairs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,124.80,184.41,336.44,63.89"><head>Table 1 .</head><label>1</label><figDesc>Results of our fuzzy semantic-based approach in PAN'09 and PAN'10.</figDesc><table coords="7,124.80,196.41,336.44,51.89"><row><cell>Dataset</cell><cell cols="3">Recall Precision Granularity Plag. Score</cell></row><row><cell>PAN'09 PAN'09 Extrinsic Part</cell><cell>0.3097 0.5424</cell><cell>7.8867</cell><cell>0.1251</cell></row><row><cell>PAN'10 PAN'10 Extrinsic Part</cell><cell>0.1548 0.5758</cell><cell>3.5919</cell><cell>0.1109</cell></row><row><cell>PAN'10 All (partial)</cell><cell>0.0464 0.3460</cell><cell>17.3057</cell><cell>0.0195</cell></row><row><cell>PAN'10 All (complete)</cell><cell>0.1259 0.5761</cell><cell>3.5828</cell><cell>0.0941</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="6,131.76,672.81,207.98,8.21"><p>http://channel9.msdn.com/learn/courses/VS2010/Parallel/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="6,131.76,686.01,217.02,8.21"><p>http://wordnet.princeton.edu/wordnet/related-projects/#SQL</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank the organizers of PAN'10 evaluation lab, <rs type="person">Martin Potthast</rs> in particular, for his generous support and instantaneous answer through the PAN's mailing list.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="7,124.80,482.56,345.89,9.07;7,160.80,494.08,309.83,9.07;7,160.80,505.36,309.75,9.07;7,160.80,516.88,307.55,9.07" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,282.48,482.56,188.21,9.07;7,160.80,494.08,171.29,9.07">On the Use of Fuzzy Information Retrieval for Gauging Similarity of Arabic Documents</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Alzahrani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Salim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,160.80,505.36,309.75,9.07;7,160.80,516.88,148.47,9.07">International Conference on the Applications of Digital Information and Web Technologies (ICADIWT 2009)</title>
		<meeting><address><addrLine>London Metropolitan University, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>Paper presented at the Second</note>
</biblStruct>

<biblStruct coords="7,124.80,528.40,345.78,9.07;7,160.80,539.92,309.84,9.07;7,160.80,551.44,20.99,9.07" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,281.97,528.40,188.61,9.07;7,160.80,539.92,43.31,9.07">Using Word Clusters to Detect Similar Web Documents</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Koberstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y.-K</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,223.44,539.92,206.78,9.07">Knowledge Science, Engineering and Management</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="215" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,124.80,562.96,345.73,9.07;7,160.80,574.48,309.88,9.07;7,160.80,586.00,214.44,9.07" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,434.63,562.96,35.90,9.07;7,160.80,574.48,215.16,9.07">Sentence similarity based on semantic nets and corpus statistics</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mclean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">A</forename><surname>Bandar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>O'shea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Crockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,381.84,574.48,88.84,9.07;7,160.80,586.00,135.22,9.07">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1138" to="1150" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,124.80,597.52,345.84,9.07;7,160.80,609.04,310.08,9.07;7,160.80,620.56,138.83,9.07" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,361.60,597.52,109.04,9.07;7,160.80,609.04,97.64,9.07">Web search basics: Nearduplicates and shingling</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,277.44,609.04,152.29,9.07">Introduction to Information Retrieval</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="437" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,124.80,631.84,345.76,9.07;7,160.80,643.36,98.52,9.07" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,213.78,631.84,170.44,9.07">WordNet: A Lexical Database for English</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,391.68,631.84,78.88,9.07;7,160.80,643.36,32.59,9.07">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,124.80,654.88,328.20,9.07" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,210.45,654.88,130.23,9.07">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,347.28,654.88,33.53,9.07">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,124.80,666.40,345.78,9.07;7,160.80,677.92,287.16,9.07" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,252.68,666.40,217.90,9.07;7,160.80,677.92,43.31,9.07">A Sentence-Based Copy Detection Approach for Web Documents</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Yerra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y.-K</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,222.48,677.92,165.31,9.07">Fuzzy Systems and Knowledge Discovery</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="557" to="570" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
