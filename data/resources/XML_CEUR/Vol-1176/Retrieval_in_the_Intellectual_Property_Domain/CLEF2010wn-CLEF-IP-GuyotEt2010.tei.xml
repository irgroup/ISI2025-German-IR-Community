<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,187.22,151.77,217.98,16.20;1,219.29,172.53,158.49,16.20">myClass: A Mature Tool for Patent Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,184.70,228.10,70.15,10.80"><forename type="first">Jacques</forename><surname>Guyot</surname></persName>
							<email>jacques@simple-shift.com</email>
							<affiliation key="aff0">
								<orgName type="department">Simple Shift</orgName>
								<address>
									<addrLine>Ruelle du P&apos;tit-Gris 1</addrLine>
									<postCode>1228</postCode>
									<settlement>Plan-les-Ouates</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,265.01,228.10,79.07,10.80"><forename type="first">Karim</forename><surname>Benzineb</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Simple Shift</orgName>
								<address>
									<addrLine>Ruelle du P&apos;tit-Gris 1</addrLine>
									<postCode>1228</postCode>
									<settlement>Plan-les-Ouates</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,354.19,228.10,67.55,10.80"><forename type="first">Gilles</forename><surname>Falquet</surname></persName>
							<email>gilles.falquet@unige.ch</email>
							<affiliation key="aff1">
								<orgName type="department">Computer Science Center</orgName>
								<orgName type="institution">University of Geneva</orgName>
								<address>
									<addrLine>Route de Drize 7</addrLine>
									<postCode>1227</postCode>
									<settlement>Carouge</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,187.22,151.77,217.98,16.20;1,219.29,172.53,158.49,16.20">myClass: A Mature Tool for Patent Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E5CF4E57DF3A6918D5C9B695236DEFC4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this task 2,000 patents in three languages (English, French and  German)  were to be classified among approximately 600 categories. We used a classifier based on neural networks of the Winnow type. This classifier is already used for similar tasks in professional applications. We tested three different approaches to improve the classification accuracy: the first one aimed at solving the issue of poorly-documented categories, the second one was meant to enrich the overall training corpus and the third one was based on the processing of the corpus' collocations. Although we ranked first in this competition, none of the three approaches mentioned above provided for a clear improvement in classification accuracy; our results were essentially due to the implementation of the classification algorithm itself.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>When we first started studying the field of patent classification back in 2002, we were driven to choose a Winnow-type algorithm (training-based neural networks), for reasons which are explained in our first article <ref type="bibr" coords="1,432.35,648.72,11.77,9.94" target="#b0">[1]</ref>. Other possible choices included in particular the kNN and the SVM algo-rithms. kNN algorithms perform well but they are very slow to come up with a prediction. This is because they don't include any training phase; all the similarity calculations are performed at runtime, when a new document is to be classified. SVM algorithms also perform well from the point of view of classification accuracy, but they are slow to train. As for neural networks, they are relatively fast to train and fast to come up with predictions, and they have good performances. However, their parameters are slightly more complex to optimize. The first version of our classifier was developed in partnership with the University of Geneva <ref type="bibr" coords="2,380.57,251.11,11.77,9.94" target="#b1">[2]</ref>. The following versions were built internally at Simple Shift.</p><p>Classifying at finer-grain levels (Main Groups or Sub-groups) requires an interaction with the user, who must be allowed to shift from a level to the next one as required. Thus we had to build several hundreds of neural networks to allow for all the possible shifts. It quickly became obvious that the efficiency of the building process was a key factor of success to meet professional requirements. Being fast at building neural networks also facilitated the parameter tuning phase.</p><p>Patent classification requires to index very large training corpora (in this experience, the size of the raw corpus was 85 Gb). Thus we linked our classifier to a well-performing home-made indexer <ref type="bibr" coords="2,360.05,414.21,12.80,9.94" target="#b2">[3]</ref> and search engine. Both of those tools have functions which are specifically adapted to support the classifier, in particular through various linguistic processing such as pattern or collocation detection.</p><p>The classification task requires to work on a large number of features (the terms), some of which may turn out to be useless. We used an algorithm of the Balanced Winnow type <ref type="bibr" coords="2,293.80,502.17,12.93,9.94" target="#b3">[4]</ref> and applied the extensions described in <ref type="bibr" coords="2,179.04,514.77,11.77,9.94" target="#b4">[5]</ref>. Our main contribution was in the way we implemented the algorithm in terms of compression, optimization and parallelization.</p><p>Beyond its professional applications, the classifier and the indexer were used in academic research, including for thesaurus analysis <ref type="bibr" coords="2,420.32,564.69,12.91,9.94" target="#b5">[6]</ref> and prior art search in the field of patents <ref type="bibr" coords="2,298.80,577.41,11.83,9.94" target="#b6">[7]</ref>, or for disambiguation tasks in the field of information retrieval <ref type="bibr" coords="2,262.10,590.04,11.69,9.94" target="#b7">[8]</ref>.</p><p>A general introduction to patent classification can be found in <ref type="bibr" coords="2,426.19,614.64,11.70,9.94" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The experiment and its resources</head><p>Patent classification may be seen as the task of affecting a category (a code) to the description of an invention (a text). In the case at hand, the classification used was the one defined by the World Intellectual Property Organization (WIPO), which is known as the International Patent Classification (IPC). It is a tree classification composed of five levels, each lower level containing finer-grain categories.</p><p>The Advanced Level version of the IPC (2009) has the following tree structure: 8 Sections, 129 Classes, 639 Sub-classes, 7,352 Main Groups and 61,847 Sub-groups. In the experiments described below, classification was performed at the Sub-class level.</p><p>The training corpus contained about 2.6 million documents covering about 1.3 million patents. One patent could be linked to several documents corresponding to various stages of the patent filing process. The documents bore a code such as A1, A2, etc. or B1, B2, etc. The A code means the patent application is being examined, while the B code means the patent is granted.</p><p>A test and evaluation set containing 2,000 patents was also circulated. Those patents belonged to the A category.</p><p>The training and testing sets contained patents in French, English and German. Some documents were monolingual, while others contained two or even three languages. At least 150,000 patents were available for each language. All patents were in XML format, so their information content was well structured.</p><p>Each document of the training corpus contained an indication of the category, or categories, it was affected to.</p><p>The task was to affect a code to each patent in the test corpus. The maximum number of predictions allowed was 1,000, which was greater than the number of existing categories at Sub-class. The challenge was of course to identify all the correct categories of a given test patent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corpus processing</head><p>Previous experience had shown that working on the complete patent description actually degraded the classifier's performance. Indeed, in some cases this description may be very large and include up to several hundreds of thousands of characters. Thus we decided to keep only the first 4,000 characters of the full-text description. The following patent fields were selected for indexing:</p><formula xml:id="formula_0" coords="4,169.10,266.48,213.11,77.25"> Inventor  Applicant  Title  Abstract  Claims  Description (only the first 4,000 characters).</formula><p>On the basis of the initial corpus, we built a catalogue which listed, for each patent of the training corpus, all the IPC categories to which it was affected. We used the &lt;classification-ipcr&gt; and &lt;classification-ipc&gt; tags to identify those categories. Although we noticed that the various documents linked to a given patent were sometimes affected to differing categories, we did not harmonize the catalogue (i.e. so that a given patent would have been affected to streamlined categories). Therefore the data in our catalogue was of the following type: EP-0000001-A1 H04L F25B F28D B27F G06F G11B B23P EP-0000001-B1 B27F H04L F25B F28D F24J G06F G11B B23P EP-0000002-A1 C07D H04L A01N EP-0000002-B1 C07D H04L A01N EP-0000003-A1 E05B EP-0000004-A1 A47J B04B …</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language processing</head><p>In our previous experiments over multilingual corpora, the results had shown that building a classifier for each separate language did not provide better performances than building a single, multilingual classifier. In fact, mixing all the languages could even improve the performances because some technical terms could be shared between several languages (for ex-ample the word "laser"), and thus increase the number of available examples. Thus we decided to build a single classifier which was trained over all the languages. Although German is an agglutinative language, we did not use any specific linguistic processing because our experience had shown that when the training corpus is large enough, those types of processing don't make much of a difference. (However when the corpus is small we do use 5gram indexing on German).</p><p>We provided a list of stop-words for each of the three languages so as to eliminate from the index all the words which have a low classifying power (articles, prepositions, etc.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Objective of the experiment</head><p>The objective of our experiment was to systematically test the impact of three improvement tracks on the precision of the classification:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Extending the training corpus:</head><p>We added a collection of 1.6 million patents, covering the three languages, to the initial training corpus of 2.6 million patents. (This method is called "External_Collection" below).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Balancing the distribution of training examples across the categories:</head><p>In the categories which had the smallest numbers of training patents, we copied the available examples a number of times until we reached a minimum threshold. (This method is called "Over_Sampling" below).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Identifying collocations in the patent texts:</head><p>In all the training examples, collocations (defined here as a single concept described by two consecutive words, such as "spark plug") were automatically identified and indexed as a single feature. (This method is called "Collocations" below).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Indexing and collocation extraction</head><p>The first step was to index the corpus. The final index included over 5 billion terms, which were composed of over 14 million different terms.</p><p>The relatively high number of different terms is explained by the fact that the corpus included three languages with a large technical terminology (chemistry, biology, electronics...) The corpus also contained a number of typos.</p><p>We filtered out the words which occurred less than 4 times. After that operation, only about 3 million different terms remained available to train the classifier.</p><p>The extraction of collocations was performed on that filtered index. For each indexed term, our index stores not only the document where the term was found, but also its position in the text. Thus identifying a collocation comes down to asking the index the following question: "For terms X and Y, how many documents include term X in position n and term Y in the following position?" The choice of terms X and Y is made among the 3 million filtered terms, which amounts to 9x10 12 possibilities. However, a large number of possibilities may be eliminated by testing only the occurrences of X and Y which actually appear in the corpus (in this case, it reduced the calculation space to 5 billion possibilities).</p><p>The process of collocation extraction was the most calculationintensive in the entire classification task: it took a whole day and added about one million new terms to the corpus. We decided to select only the collocations which occurred more than 16 times in the corpus. We also kept the collocations which included a stop-word (such as "pomme de terre", which is "potato" in French).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results of the experiment</head><p>We performed eight runs so as to systematically test all the possible permutations in our planned tests. C0 is the baseline run, i.e. the only one which is strictly based on the CLEF-IP corpus with no additional processing. Practically all the runs got an 83% success score when asked to find a patent category with a single prediction (P_1 measure), and 93% of the categories were quoted in the top 25 predictions (R_25 measures).</p><p>Our results are the following : </p><formula xml:id="formula_1" coords="7,148.34,174.52,210.89,9.94">(MAP in %, P_1 in %) (E=External_Collection,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comments</head><p> None of our approaches managed to improve markedly the P_1 score. This shows that most of the classification precision comes from the implementation of the Winnow algorithm itself.  Smoothing out the distribution of training examples by using the over-sampling approach has in fact slightly degraded the performance. However, it did improve the classification into poorly-fed categories (but this criterion was not taken in account in the competition).  Doubling the number of examples did not improve much the performance.  Using collocations did allow to add relevant information and somewhat improved the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System Efficiency</head><p>All the experiments were performed on a workstation which cost less than 1,000 euros. The processing times of the classification task (without the collocation extraction) were the following:  2 hours to index the corpus  1 hour to train the application (for each run)  3 minutes to classify the 2,000 topics. This implementation of the classifier was parallelized and used the 4 cores of the processor, thus making the most out of the multicore architecture. It should therefore be possible to reach even higher performances with the new AMD processors which are built on 12 cores.</p><p>The final neural network built for the C0 (baseline) experiment had a size on disk smaller than 100 Mb. This allows to distribute it, along with the rest of the classifier, on a simple CD-ROM (this is sometimes required by some of our customers).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Our approach is to avoid, as much as possible, any linguistic processing which is language-dependent so as to guarantee similar performances for all languages (including, for example, Spanish, Russian and Chinese). To make up for the possible shortcomings of this approach, we chose to remain as exhaustive as possible and to apply the minimum number of filtering-out processes. Such a strategy seemed to be efficient in this competition since our results were ranked in first position.</p><p>The three approaches tested in this experiment either slightly degraded or slightly improved the baseline performance of the classifier. Thus the good performance was essentially due to our implementation of the Winnow algorithm. "myClass" has obviously evolved over the past eight years in professional contexts and might now be considered a mature classifier.</p></div>		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,164.04,177.88,288.99,9.94;9,130.46,190.60,230.09,9.94" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="9,258.66,177.88,194.36,9.94;9,130.46,190.60,164.73,9.94">Literature survey: Issues to be considered in the automatic classification of patents</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Fall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Benzineb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>WIPO</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,166.81,215.20,290.54,9.94;9,130.46,227.92,328.61,9.94;9,130.46,240.52,318.37,9.94;9,130.46,253.27,234.02,9.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,418.08,215.20,39.27,9.94;9,130.46,227.92,328.61,9.94;9,130.46,240.52,59.14,9.94">Computer-Assisted Categorization of Patent Documents in the International Patent Classification</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Fall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Benzineb</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guyot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Törcsvéri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Fiévet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,207.89,240.52,240.94,9.94;9,130.46,253.27,93.97,9.94">Proceedings of the International Chemical Information Conference (ICIC&apos;03)</title>
		<meeting>the International Chemical Information Conference (ICIC&apos;03)<address><addrLine>Nîmes, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-10">October 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,166.80,277.87,293.19,9.94;9,130.46,290.47,315.76,9.94;9,130.46,303.19,38.28,9.94" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guyot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Falquet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Benzineb</surname></persName>
		</author>
		<title level="m" coord="9,327.42,277.87,132.57,9.94;9,130.46,290.47,20.69,9.94">Construire un moteur d&apos;indexation</title>
		<meeting><address><addrLine>Paris</addrLine></address></meeting>
		<imprint>
			<publisher>Hermes</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note type="report_type">Technique et science informatique</note>
	<note>in French</note>
</biblStruct>

<biblStruct coords="9,164.04,327.79,265.00,9.94;9,130.46,340.51,311.04,9.94;9,130.46,353.11,70.56,9.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,230.06,327.79,198.98,9.94;9,130.46,340.51,198.82,9.94">Learning Quickly When Irrelevant Attributes Abound: A New Linear-Threshold Algorithm</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Littlestone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,336.87,340.51,59.17,9.94">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="285" to="318" />
			<date type="published" when="1988-04">Apr. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,164.04,377.71,290.43,9.94;9,130.46,390.43,327.40,9.94;9,130.46,403.03,212.57,9.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,331.15,377.71,123.31,9.94;9,130.46,390.43,85.95,9.94">Mistake-Driven Learning in Text Categorization</title>
		<author>
			<persName coords=""><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yael</forename><surname>Karov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,235.13,390.43,222.73,9.94;9,130.46,403.03,180.25,9.94">EMNLP-97, The Second Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,165.12,427.77,286.71,9.94;9,130.46,440.37,326.53,9.94;9,130.46,452.97,328.13,9.94;9,130.46,465.69,302.56,9.94;9,130.46,478.29,28.55,9.94" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,434.68,427.77,17.14,9.94;9,130.46,440.37,287.10,9.94">Ontology learning from thesauri: An experience in the urban domain</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nogueras-Iso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lacasta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Falquet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guyot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Teller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,264.07,452.97,194.52,9.94;9,130.46,465.69,124.43,9.94">Ontology Theory, Management and Design: Advanced Tools and Models</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Gargouri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Jaziri</surname></persName>
		</editor>
		<imprint>
			<publisher>IGI Intl publishing</publisher>
		</imprint>
	</monogr>
	<note>to be published in 2010</note>
</biblStruct>

<biblStruct coords="9,166.69,503.01,282.50,9.94;9,130.46,515.61,318.34,9.94;9,130.46,528.21,154.23,9.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,382.15,503.01,67.04,9.94;9,130.46,515.61,113.08,9.94">UniGE Experiments on Prior Art Search</title>
		<author>
			<persName coords=""><forename type="first">Jacques</forename><surname>Guyot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gilles</forename><surname>Falquet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karim</forename><surname>Benzineb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,416.02,515.61,27.32,9.94">LNCS)</title>
		<title level="s" coord="9,250.85,515.61,157.04,9.94">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>to be published in 2010</note>
</biblStruct>

<biblStruct coords="9,166.80,552.93,275.72,9.94;9,130.46,565.53,318.37,9.94;9,130.46,578.25,321.85,9.94;9,130.46,590.88,322.28,9.94;9,130.46,603.48,133.95,9.94" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,392.08,552.93,50.44,9.94;9,130.46,565.53,253.78,9.94">Analysis of Word Sense Disambiguation-Based Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guyot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Falquet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Radhouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Benzineb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,403.05,565.53,45.77,9.94;9,130.46,578.25,261.18,9.94">8th Workshop of the Cross-Language Evaluation Forum, CLEF 2008</title>
		<title level="s" coord="9,295.73,590.88,157.01,9.94;9,130.46,603.48,29.57,9.94">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5706</biblScope>
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="9,164.05,628.20,293.54,9.94;9,130.46,640.80,328.60,9.94;9,130.46,653.52,39.84,9.94" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,275.45,628.20,140.92,9.94">Automated Patent Classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guyot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Benzineb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,437.47,628.20,20.12,9.94;9,130.46,640.80,208.50,9.94">Current Challenges in Patent Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>to be published in 2011</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
