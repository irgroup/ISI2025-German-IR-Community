<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.31,150.85,308.78,12.52;1,176.67,166.93,242.37,12.52">Applying the KISS Principle for the CLEF-IP 2010 Prior Art Candidate Patent Search Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,233.18,193.33,52.57,8.88"><forename type="first">Walid</forename><surname>Magdy</surname></persName>
							<email>wmagdy@computing.dcu.ie</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="laboratory">Centre for Next Generation Localisation</orgName>
								<orgName type="institution" key="instit1">Dublin</orgName>
								<orgName type="institution" key="instit2">City University</orgName>
								<address>
									<settlement>Dublin 9</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,293.42,193.33,68.90,8.88"><forename type="first">Gareth</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
							<email>gjones@computing.dcu.ie</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="laboratory">Centre for Next Generation Localisation</orgName>
								<orgName type="institution" key="instit1">Dublin</orgName>
								<orgName type="institution" key="instit2">City University</orgName>
								<address>
									<settlement>Dublin 9</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.31,150.85,308.78,12.52;1,176.67,166.93,242.37,12.52">Applying the KISS Principle for the CLEF-IP 2010 Prior Art Candidate Patent Search Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E017C8CE0939B11789E378A688F05A03</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Patent Retrieval</term>
					<term>Query Formulation</term>
					<term>CLEF-IP track</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present our experiments and results for the DCU CNGL participation in the CLEF-IP 2010 Candidate Patent Search Task. Our work applied standard information retrieval (IR) techniques to patent search. In addition, a very simple citation extraction method was applied to improve the results. This was our second consecutive participation in the CLEF-IP tasks. Our experiments in 2009 showed that many sophisticated approach to IR do not improve the retrieval effectiveness for this task. For this reason of we decided to apply only simple methods in 2010. These were demonstrated to be highly competitive with other participants. DCU submitted three runs for the Prior Art Candidate Search Task, two of these runs achieved the second and third ranks among the 25 runs submitted by nine different participants. Our best run achieved MAP of 0.203, recall of 0.618, and PRES of 0.523.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Centre for Next Generation Localisation (CNGL) at Dublin City University (DCU) participated in the CLEF-IP track 2010 Candidate Patent Search Task using the KISS principle. KISS stands for "keep it simple and straightforward" which describes the methods adopted in our submissions for CLEF-IP 2010. Our participation used standard IR approaches with a very simple information extraction technique. The aim of the task is to automatically retrieve all of citations for a given patent (which is considered as the topic) <ref type="bibr" coords="1,288.76,549.94,10.68,8.88" target="#b2">[3]</ref>, <ref type="bibr" coords="1,305.43,549.94,10.67,8.88" target="#b6">[7]</ref>. We submitted three runs for the task: one is based in citation extraction from patent application descriptions, another one uses simple information retrieval techniques to search the patent documents collection using the patent topic, and the final one is a combination of the first two methods. Nine participants submitted 25 runs in total for this task. These were evaluated using three metrics: mean average precision (MAP), recall, and the patent retrieval evaluation scores (PRES). Our best run (which is the third one) achieved the second rank using all the scores among all runs submitted by participants.</p><p>The paper is organized as follows: Section 2 overviews the patent data collection provided by the track organizers, Section 3 gives full details of the experimental setup for our participation, Section 4 reports the results with some analysis to these result, and finally Section 5 concludes the paper and provides possible future directions.  For this task the organizers provided more than 2.68M XML documents representing different versions of 1.35M patents filed between 1978 and 2009 (see Figure <ref type="figure" coords="2,442.45,395.88,3.63,8.88" target="#fig_0">1</ref>). For our experiments, all different document versions for a single patent were merged into a single document with fields updated from its latest versions. The patent structure is very rich comprising the 'title' and 'claims', some fields are present in three languages (English "EN", German "DE", and French "FR"). In addition, the patent abstract of non-English patents has an English translation of the abstract included.</p><p>Only the patent 'title', 'abstract', 'description', 'claims', and 'classifications' fields are extracted from the patents. Some patents lack some of these fields. The only fields that are present in all patents are the 'title' and the 'classifications'. The 'description' field is related to the 'claims' field, thus if the 'claims' field is missing, then the 'description' is missing too. However, the opposite in not true, some documents contain the 'claims' field while the 'description' field is missing. The 'abstract' field is an optional part that is only present in some patents. 68% of the patents in the collection are English, 24% are German, and 8% are French. In keeping with our KISS approach to avoid complications with language processing, only the English fields were used for indexing. Hence, English patents were fully indexed, but for German and French patents the title, abstract and claims were only indexed where a translation into English was found. This simplification meant that 32% of the collection (the non-English portion) the description field was not indexed. Additionally, as mentioned above, since some sections were already missing, some patents had no English field content to be indexed except the title or the title and abstract. Figure <ref type="figure" coords="2,241.72,637.30,4.96,8.88" target="#fig_1">2</ref> shows the content that has been indexed for the patent collections based on the existing fields. It can be seen that 22% of the patents have only the titles indexed; leading them to effectively be very short indexed documents since they consist only of the single item of the title. Additionally 10% of the patents have only the titles and abstract indexed and 16% of the patents have only the title and the claims indexed, with some of them having the abstract section as well. Only 52% of the patents have nearly the full document indexed, where the title, description, and claims sections are present. This 52% of the collection are the English patents where all the main sections found. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>In this section we describe details of our experimental setup for our three submitted runs. The first run is a very standard information retrieval method where the patent topics were used to search the indexed collection after translating the non-English topics into English. The second run involves extracting the patent citation disclosed within the description of the patent topic without the use of any kind of IR techniques. Finally, the third run is generated through merging the first two runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">IR Experiment</head><p>Text pre-processing. Patent text contains many formulas, numeric references, chemical symbols, and patent-specific words (such as method, system, or device) that can cause a negative effect on the information retrieval process. In order to minimise these problems the text was filtered to remove predefined stop words <ref type="foot" coords="3,417.49,618.77,3.23,5.78" target="#foot_0">1</ref> , digits, and field-specific stop words.</p><p>To obtain the stop words for each field, the field frequency for each term in each field was calculated separately. The field frequency for a term "T" in field "X" is the number of fields of type "X" across all documents containing the term "T". For each field, all terms with field frequency higher than 5% of the highest term field frequency for this field were considered to be stop words <ref type="bibr" coords="4,367.45,172.69,10.68,8.88" target="#b3">[4]</ref>. For example, for the 'title' field, the following words were identified as stop words: method, device, apparatus, process, etc; for another field such as 'claims', the following words were identified as stop words: claim, according, wherein, said, etc.</p><p>In addition to stop word removal, Porter stemming was applied to the text in order to normalize different surface forms of a given word <ref type="bibr" coords="4,360.85,230.17,10.59,8.88" target="#b5">[6]</ref>.</p><p>Indexing. The Indri search toolkit <ref type="bibr" coords="4,264.63,257.77,11.70,8.88" target="#b7">[8]</ref> was used to index the extracted English parts of the patent collection. In the indexing process, the text of the following sections in the patents, if they existed in English, was included in the index:</p><p>1. Title 2. Abstract 3. Description 4. Claims In addition, the patent IPC classification [9] was included in the index to be used later in filtering the retrieved results in the search process. Only the top three classification levels were retained for the filtering process with the deeper levels being discarded (example: B01J, C01G, C22B). Further fields in the patent were not used; these included the fields which carry logistic information such as the patent filing date, institute, inventor's name and address, etc. Nevertheless, the 'inventors' field was tested using the training data assess its effectiveness in retrieving relevant documents. Results of these investigations showed it to have a weak effect on the quality of search. Hence, it was discarded from the index.</p><p>Translating non-English topics. 2,005 patent topics were provided including 1,351 English patent topics, 520 German topics, and 134 French topics. Out of these 5 topics were later excluded by the track organizers. Since the index was built only in English, German and French topics were translated into English using Google translate <ref type="foot" coords="4,158.67,512.94,3.23,5.78" target="#foot_1">2</ref> . The 'title', 'description', and 'claims' sections were translated into English, while the 'abstract' field already had its English translation. Query formulation. One major challenges in patent retrieval is query formulation <ref type="bibr" coords="4,124.83,565.66,10.68,8.88" target="#b1">[2]</ref>, <ref type="bibr" coords="4,141.75,565.66,10.68,8.88" target="#b6">[7]</ref>. As a full patent is taken to be the topic, extracting the best representative text with the proper weights is a key to achieving good retrieval results.</p><p>Earlier experiments from our participation in CLEF-IP 2009 showed that using the full patent text to search the collection achieves the best results, especially after filtering all results which do not carry any overlap in the 'classification' section (only the first three levels of classification are used) <ref type="bibr" coords="4,313.94,623.14,10.68,8.88" target="#b3">[4]</ref>. The same setup was used this year by forming the query as follows:</p><p>-Unigram tokens were extracted from the 'description' field after stemming and stop word removal.</p><p>-Bigram tokens of frequency higher than 3 were extracted from all the patent fields combined and added to the query after stemming and stop word removal. Extracted queries can be seen a bit long, however, this formulation proved to be the best in our experiments using the training set. This first run is called the "IR" run in our submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Citation Extraction</head><p>One of the features of patents is the presence of some of the cited patent numbers within the text of the description of the patents. These patent numbers were not filtered out of the text of the patent topics, which can be considered as the presence of part of the answer within the question. Despite this fact, we have not focused on building extra experiments based on this information, since in real life patent search situation this information is not always presented in the patent application, and hence, creating results on it can be considered as a misleading conclusion in the area of patent retrieval.</p><p>However, in the experimental results, adding this information to the tested methods is reported to demonstrate the impact of using this kind of information. Results show that a misleadingly high MAP can be achieved, but with a very low recall. This observation is significant since of course recall is usually the main objective for patent retrieval tasks.</p><p>For the large topic collection containing 2,005 patent topics, 2,307 citations were extracted from 771 patent topics and found to be IDs of patents in the indexed collection. Other extracted citations that do not exist in the collection were discarded. The extracted citations were put into the TREC format to be the second run submitted to the CLEF-IP track with the ID "Cit", standing for "citation".</p><p>The first run results list was appended to the second run list after removing the duplicates to act as our third run submitted to the track. This run ID is "IR+Cit".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Several evaluation scores have been used for evaluating the submitted runs. Here, we focus on five scores: mean average precision (MAP), recall, recall@100, patent retrieval evaluation score (PRES) <ref type="bibr" coords="5,265.72,569.98,10.68,8.88" target="#b4">[5]</ref>, and PRES@100. MAP and recall have so far been the two main metrics used for evaluating this task. However, our recently introduced PRES metric is designed to be a dedicated score for recall-oriented IR applications, such as patent search. PRES reflects the quality of the system in retrieving a large portion of the relevant documents in a relatively high ranks based on a user specific cut-off ( max ) <ref type="bibr" coords="5,241.82,627.46,10.59,8.88" target="#b4">[5]</ref>. This is the reason behind using the cut-off of 100, as it has been in shown in <ref type="bibr" coords="5,221.79,638.97,11.70,8.88" target="#b0">[1]</ref> that the average number of documents to be checked by a patent examiner is 100. In addition, PRES and recall are also calculated at the cut-off specified by the track organizers (1000).</p><p>Table <ref type="table" coords="5,168.99,673.41,4.96,8.88" target="#tab_1">1</ref> shows results for our three submitted runs for the large topic collection (2000 topics). The table shows two extreme runs, namely the "IR" run and the "Cit" run. The "IR" run achieved high recall and moderate precision. On the other hand, the "Cit" run achieved a very high precision while a very low recall. Although the MAP of the "IR" run is higher than "Cit" run, the "Cit" run has a very high precision, as was mentioned in section 3.2, that only 771 topics out of the 2000 had citations extracted, which means that the MAP for these topics alone is 0.3. The last run "IR+Cit" achieves the highest recall and precision since it comes from a simple merging of the two previous runs. The PRES and PRES@100 scores reflect both the recall and the quality of ranking of the system. The "IR+Cit" run and the "IR" runs achieved the second and the third best results among the 25 runs submitted to the track according to PRES and PRES@100. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper, we have described our participation in the CLEF-IP 2010 Prior Art Patent Search Task. Three runs were submitted to the track, with one of them achieving the second best run among 25 runs submitted by 9 participants in this task. The three runs represent very simple and straightforward approaches for achieving high effectiveness in this task. Our run using standard IR techniques achieved the third highest performance among all submitted runs by participants according to recall and PRES. Our second run using straightforward citation extraction from patent topics achieved a very high precision performance. The third run with is a very simple merging of the first two runs achieved both high recall and precision (both reflected in PRES) to act as the best second run among the 25 runs submitted by the participants. For future work, utilizing the information of the automatically extracted citation can be an interesting avenue for investigation. Semi-pseudo relevance feedback can be applied through extracting additional terms from these citations to help in improving the results. In addition, different approaches for translating the non-English patents can be tested, since further investigation showed that retrieval performance for the non-English topics was relatively lower than that of the English ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgment</head><p>This research is supported by the Science Foundation Ireland (Grant 07/CE/I1142) as part of the Centre for Next Generation Localisation (CNGL) at Dublin City University.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,180.39,361.32,234.53,8.88"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Distribution of patents collection by publishing year</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,136.59,407.63,322.33,8.88"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. Proportions of patent texts in the collection indexed by field combinations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,135.87,276.53,323.67,86.11"><head>Table 1 .</head><label>1</label><figDesc>MAP, recall, recall@100, PRES, and PRES@100 for the three submitted runs in CLEF-IP 2010.</figDesc><table coords="6,153.15,311.16,296.05,51.48"><row><cell>Run #</cell><cell>MAP</cell><cell>R</cell><cell>R@100</cell><cell>PRES</cell><cell>PRES@100</cell></row><row><cell>IR</cell><cell>0.1216</cell><cell>0.57</cell><cell>0.3036</cell><cell>0.4614</cell><cell>0.228</cell></row><row><cell>Cit</cell><cell>0.112</cell><cell>0.1187</cell><cell>0.1187</cell><cell>0.1186</cell><cell>0.1176</cell></row><row><cell>IR+Cit</cell><cell>0.2029</cell><cell>0.618</cell><cell>0.3846</cell><cell>0.5229</cell><cell>0.3162</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,130.11,686.18,197.24,8.03"><p>http://members.unine.ch/jacques.savoy/clef/index.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,130.11,686.18,98.87,8.03"><p>http://translate.google.com/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,142.83,177.30,327.74,8.03;7,142.83,187.47,327.89,8.18;7,142.83,197.94,24.11,8.03" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="7,338.54,177.30,132.03,8.03;7,142.83,187.62,222.96,8.03">A Survey on Patent Users Search Behavior, Search Functionality and System Requirements</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Joho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Vanderbauwhede</surname></persName>
		</author>
		<idno>2010-00001</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="report_type">IRF Report</note>
</biblStruct>

<biblStruct coords="7,142.83,208.38,327.79,8.03;7,142.83,218.55,327.90,8.18;7,142.83,228.87,314.12,8.18" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,293.30,208.38,172.72,8.03">Overview of patent retrieval task at NTCIR-4</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iwayama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,152.66,218.55,318.07,8.18;7,142.83,228.87,193.60,8.18">Proceedings of the fourth TCIR workshop on evaluation of information retrieval, automatic text summarization and question answering</title>
		<meeting>the fourth TCIR workshop on evaluation of information retrieval, automatic text summarization and question answering<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-04">June 2-4. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.83,239.34,327.93,8.03;7,142.83,249.50,327.87,8.18;7,142.82,259.82,80.87,8.18" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,240.03,239.34,230.73,8.03;7,142.83,249.66,21.57,8.03">A methodology for building a patent test collection for prior art search</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Graf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,181.58,249.50,289.11,8.18;7,142.82,259.82,50.49,8.18">Proceedings of the Second International Workshop on Evaluating Information Access (EVIA)</title>
		<meeting>the Second International Workshop on Evaluating Information Access (EVIA)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.83,270.42,327.87,8.03;7,142.83,280.58,327.90,8.18;7,142.83,290.90,54.58,8.18" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,307.70,270.42,163.00,8.03;7,142.83,280.73,171.42,8.03">Exploring Structured Documents and Query Formulation Techniques for Patent Retrieval</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Magdy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Leveling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,335.65,280.58,102.56,8.18">CLEF working notes 2009</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.83,301.37,327.88,8.03;7,142.83,311.54,327.91,8.18;7,142.83,321.86,327.90,8.18;7,142.82,332.45,72.11,8.03" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,263.53,301.37,207.17,8.03;7,142.83,311.69,126.81,8.03">PRES: A Score Metric for Evaluating Recall-Oriented Information Retrieval Applications</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Magdy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,287.17,311.54,183.56,8.18;7,142.83,321.86,243.10,8.18">Proceeding of the 33rd international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>eeding of the 33rd international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="611" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.83,342.62,304.82,8.18" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,186.98,342.77,122.60,8.03">An Algorithm for Suffix Stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,315.49,342.62,32.52,8.18">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.83,353.09,327.74,8.03;7,142.83,363.25,297.08,8.18" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,303.50,353.09,167.06,8.03;7,142.83,363.41,101.03,8.03">CLEF-IP 2009: retrieval experiments in the Intellectual Property domain</title>
		<author>
			<persName coords=""><forename type="first">Roda</forename><forename type="middle">G</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tait</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Zenz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,260.06,363.25,93.56,8.18">CLEF working notes 2009</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.83,373.73,327.75,8.03;7,142.83,383.89,327.88,8.18;7,142.82,394.33,103.90,8.18" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,353.53,373.73,117.05,8.03;7,142.83,384.05,128.66,8.03">Indri: A language model-based search engine for complex queries</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,290.29,383.89,180.41,8.18;7,142.82,394.33,73.96,8.18">Proceedings of the International Conference on Intelligence Analysis</title>
		<meeting>the International Conference on Intelligence Analysis</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
