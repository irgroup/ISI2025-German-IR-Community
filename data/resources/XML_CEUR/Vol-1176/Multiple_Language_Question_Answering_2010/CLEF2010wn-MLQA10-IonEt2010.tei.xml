<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,141.30,152.11,324.01,12.19;1,233.28,169.57,128.62,12.19">Monolingual and Multilingual Question Answering on European Legislation</title>
				<funder ref="#_qSS6ShP">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,136.50,207.81,38.85,8.74"><forename type="first">Radu</forename><surname>Ion</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Institute for Artificial Intelligence</orgName>
								<address>
									<addrLine>Romanian Academy Calea 13 Septembrie no. 13</addrLine>
									<postCode>050711</postCode>
									<settlement>Bucharest</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,182.86,207.81,81.22,8.74"><forename type="first">Alexandru</forename><surname>Ceauşu</surname></persName>
							<email>aceausu@racai.ro</email>
							<affiliation key="aff0">
								<orgName type="department">Research Institute for Artificial Intelligence</orgName>
								<address>
									<addrLine>Romanian Academy Calea 13 Septembrie no. 13</addrLine>
									<postCode>050711</postCode>
									<settlement>Bucharest</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,272.64,207.81,79.06,8.74"><forename type="first">Dan</forename><surname>Ştefănescu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Institute for Artificial Intelligence</orgName>
								<address>
									<addrLine>Romanian Academy Calea 13 Septembrie no. 13</addrLine>
									<postCode>050711</postCode>
									<settlement>Bucharest</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,360.16,207.81,44.40,8.74"><forename type="first">Dan</forename><surname>Tufiş</surname></persName>
							<email>tufis@racai.ro</email>
							<affiliation key="aff0">
								<orgName type="department">Research Institute for Artificial Intelligence</orgName>
								<address>
									<addrLine>Romanian Academy Calea 13 Septembrie no. 13</addrLine>
									<postCode>050711</postCode>
									<settlement>Bucharest</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,412.08,207.81,58.08,8.74"><forename type="first">Elena</forename><surname>Irimia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Institute for Artificial Intelligence</orgName>
								<address>
									<addrLine>Romanian Academy Calea 13 Septembrie no. 13</addrLine>
									<postCode>050711</postCode>
									<settlement>Bucharest</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,243.11,219.33,126.11,8.74"><forename type="first">Verginica</forename><forename type="middle">Barbu</forename><surname>Mititelu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Institute for Artificial Intelligence</orgName>
								<address>
									<addrLine>Romanian Academy Calea 13 Septembrie no. 13</addrLine>
									<postCode>050711</postCode>
									<settlement>Bucharest</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,141.30,152.11,324.01,12.19;1,233.28,169.57,128.62,12.19">Monolingual and Multilingual Question Answering on European Legislation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F00F9F123708B8D01A26BC02A496629A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Intelligence to the CLEF 2010 ResPubliQA lab. We answered questions in Romanian and English from Romanian documents of Acquis Communautaire and the European Parliament Proceedings. We extend the report from the previous ResPubliQA participation by introducing multi-factored paragraph relevance score training onto English-Romanian QA. We also investigate how our monolingual parametric QA system developed for the last year's ResPubliQA track scales up to current challenges.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Research Institute for Artificial Intelligence (RACAI) is at the 5 th participation in the CLEF (http://www.clef-campaign.org/) series of Question Answering systems evaluation. We have built Question Answering (QA) systems for the English-Romanian or the Romanian-Romanian tracks experimenting with each passing year. Beginning with last year, the QA task simplified in that the organizers asked for the single most relevant paragraph containing the answer to the user's natural language question. Also, questions were independent one from the other and no anaphora resolution was required in order to find referents of the question pronouns in previous questions and/or answers. Thus, the road for a reliable QA system development was opened and continues to be opened for the 2010 edition of the popular QA systems evaluation forum.</p><p>This year we participated to the Romanian-Romanian track of the ResPubliQA lab as we did in 2009, but we also enrolled in the English-Romanian cross-lingual QA in order to check some hypotheses that we put forward <ref type="bibr" coords="1,343.27,594.93,10.66,8.74" target="#b1">[2]</ref>. The approach that we took was to use the last year's test set comprised of 500 questions from the JRC Acquis corpus in order to train our paragraph relevance weights. The difference is that for ResPubliQA 2010, the Europarl corpus was added along with a new type of question for which we did not have any training data. This type of question (dubbed OPINION in the "ResPubliQA 2010 -Track Guidelines" document) was specific to the Europarl corpus in which each speaker in the European Parliament expresses an opinion about a given state of affairs.</p><p>In what follows, we will describe the document collection, our QA systems (both monolingual and cross-lingual) and the results we have obtained. In doing so, we will be brief on subjects that have already been presented at length elsewhere <ref type="bibr" coords="2,419.37,180.63,10.61,8.74" target="#b1">[2]</ref>, focusing on new aspects and discussions pertaining to the task at hand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The Document Collection</head><p>The document collection was composed from two corpora: the JRC Acquis <ref type="bibr" coords="2,440.28,257.43,11.68,8.74" target="#b8">[9]</ref> that was introduced last year and the new addition of Europarl <ref type="bibr" coords="2,379.89,268.95,10.61,8.74" target="#b3">[4]</ref>. The latter corpus consists of 142 documents in both English and Romanian containing almost 8.6M tokens in English and almost 9.3M tokens in Romanian (including punctuation). Both parts of the corpus were preprocessed using the TTL web service <ref type="bibr" coords="2,393.79,303.45,16.68,8.74" target="#b11">[12]</ref> to obtain POS tagging, lemma and chunking information (the same annotations as for the JRC Acquis corpus). As with the JRC Acquis corpus, we paragraph-aligned the Europarl corpus using the 1:1 sentence aligner developed by Moore <ref type="bibr" coords="2,362.68,337.95,10.64,8.74" target="#b5">[6]</ref>. We managed to obtain a percent of 98.76% English paragraphs that were 1:1 aligned to Romanian paragraphs which means that the corpus was already "almost" aligned with paragraph counts differing very little between English or Romanian parts for each pair of documents.</p><p>For this year's ResPubliQA competition, the JRC Acquis and the Europarl corpora were also word sense disambiguated using one of the algorithms with which we participated to the "Task #17: All-words Word Sense Disambiguation (WSD) on a Specific Domain" of the SemEval-2010 semantic evaluations forum 1 . We wanted to evaluate the impact of WSD onto the accuracy of our QA system by doing an informed, WSD-driven query expansion and WSD-enhanced document retrieval. The algorithm that we used to sense-annotate the document collection was the variant of RACAI-1 <ref type="bibr" coords="2,169.20,475.95,11.68,8.74" target="#b0">[1]</ref> which outputs the best two senses for the target word and whose reported accuracy is around 82.5% if it is applied onto highly domain-specific content words.</p><p>Figure <ref type="figure" coords="2,167.48,510.45,5.01,8.74" target="#fig_0">1</ref> exemplifies the level of corpus annotation used by our present QA system: In order to check for the query expansion benefits, for each sense disambiguated word, we also indexed its synonyms as given by respective ILIs<ref type="foot" coords="3,381.48,161.12,3.00,5.23" target="#foot_0">2</ref> . For instance, for the lemma "proposal", the index contained the synonym "proposition" since this literal appears next to "proposal" in the synset which is identified by ILI "ENG20-06719629-n".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The QA System</head><p>The QA system has no significant modifications since the ResPubliQA 2009 <ref type="bibr" coords="3,438.03,261.33,10.63,8.74" target="#b1">[2]</ref>. It is based on a flow of web services that takes a user's natural language question, preprocess it on the fly to obtain all the annotations from Figure <ref type="figure" coords="3,384.66,284.31,3.77,8.74" target="#fig_0">1</ref>, transforms it into a Boolean query using one of the two query generation algorithms [2; pages 7, 8] and then retrieves a list of relevant paragraphs that are very likely to contain the answer to the user's question.</p><p>The way in which the paragraph list is sorted (in order to extract and return the first paragraph as the single answer to the question) is the key to the trainable quality of our QA system. Thus, the sort key S of a paragraph p is a linear combination of paragraph relevance scores:</p><formula xml:id="formula_0" coords="3,248.22,371.37,222.40,28.30">1 , ) ( = = ∑ ∑ i i i i i s p S λ λ (1)</formula><p>where the weights sum to 1 and are estimated by the following MERT-like procedure <ref type="bibr" coords="3,124.74,414.81,10.85,8.74" target="#b6">[7]</ref>: given a training set of questions for which the correct paragraphs are known, run the QA system for all possible values of weights such that the increment step is 0.01 and compute the MRR of each run. Retain that set of weights for which the MRR is the highest.</p><p>In order to comply with the organizers' suggestion that an "I don't know/I'm not sure" answer (identified with NOA -standing for "NO Answer") is better than a wrong answer, we introduced the combined QA system which considers the outputs of the two different query generation algorithms in the following manner:</p><formula xml:id="formula_1" coords="3,126.72,506.18,343.54,27.10">( ) 50 , ) ( , ) ( , ) ( ) ( min arg 2 1 2 1 ≤ ≤ ≤ + K K p rank K p rank p rank p rank p (2)</formula><p>where ) ( p rank is the rank of the paragraph p in the list returned by the search engine and subscripts 1 and 2 indicate the paragraph lists returned by the respective query generation algorithm (1 for the TF-IDF one and 2 for the chunk-based one). Intuitively, the paragraph that is preferred by the combined QA system is the lowest numbered one that is common to both lists. When no such paragraph exists, the QA system returns NOA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The Monolingual Runs</head><p>We participated in the Romanian-Romanian section of the ResPubliQA 2010 Paragraph Selection (PS) track. As in the previous year, the requirement was to return exactly one paragraph containing the correct answer to each natural language question in the 200 questions test set. If the system is not sure, the NOA answer may be returned with an option to record an actual answer (paragraph) with the NOA so that the organizers may compute additional performance figures such as the percent of correct/incorrect answers out of the NOA ones.</p><p>We have submitted two Romanian-Romanian runs: icia101PSroro and icia102PSroro with the following characteristics:</p><p>• The first run is simply the QA system from ResPubliQA 2009 with global weights training as described in that paper <ref type="bibr" coords="4,339.27,301.17,11.71,8.74" target="#b1">[2]</ref> and using the TF-IDF query generation algorithm. We wanted to see how our 2009 QA system scales up to current challenges without any modifications; • The second run is a more elaborate one. We trained the weights of the QA system on ResPubliQA 2009 500 questions test set in order to derive a set of weights for each question class for each query generation algorithm (see tables 1 and 2). Then, we combined the outputs of the TF-IDF and CHUNK QA systems, using K=1 from eq. 2.</p><p>TF-IDF Q. Gen. Table <ref type="table" coords="5,152.38,291.51,5.01,8.74" target="#tab_2">3</ref> reveals the fact that MERT training procedure is rather sensitive to the training data: a c@1 measure of 0.49 is significantly lower than the one of 0.68 we obtained last year. Still, there is also the issue of the size of the test data which was 200 questions vs. 500 questions last year (more than double). This translates in a reduced margin of error.</p><p>For this year's ResPubliQA competition we also wanted to test the influence the WSD has on both document/paragraph retrieval and query generation. We have already explained how we index a term using its assigned senses.</p><p>For the query side, we opted to implement a query expansion mechanism based on performing WSD to the user's question and generate all synonyms from the Romanian WordNet for each semantically disambiguated term. In order to do that, we used the RACAI-1 WSD algorithm <ref type="bibr" coords="5,281.07,417.99,11.72,8.74" target="#b0">[1]</ref> with which we have obtained an 82.5% accuracy on a domain-limited lexical sample if we allowed it to output the first two senses for each target word. The query expansion algorithm works in the following way:</p><p>1. obtain a query from the natural language question using the TF-IDF query generation algorithm <ref type="bibr" coords="5,246.88,475.47,10.85,8.74" target="#b1">[2]</ref>; 2. for each term in that query, apply RACAI-1 WSD algorithm (which uses a WSD model derived from the document collection and always outputs the domain-computed most frequent sense of the term according to the modelthe "One Sense per Domain" hypothesis) to obtain the most probable 2 senses of the term; using Romanian WordNet, generate all its synonyms for each disambiguated sense. Evaluating the results of the WSD-enhanced QA system, we differentiated between several types of runs: with/without query expansion and with/without WSD-enhanced indexing. We tested both query generation algorithms (TF-IDF and chunk-based) but we could only expand queries produced by the TF-IDF algorithm. Every cell in this table contains three figures separated by '/': the MRR-1 (percentage of the correct paragraphs returned only on the 1 st place), the MRR (classical Mean Reciprocal Rank) and the COVERAGE (the percentage of the correct paragraphs found in the K=50 paragraphs list the search engine returns for each question). It clearly follows that WSD negatively impacts the performance of both IR and QA (a result that was put forward a while ago <ref type="bibr" coords="6,291.40,365.13,10.48,8.74" target="#b7">[8]</ref>). There are several explanations for this state of affairs:</p><p>• domain limited WSD works well only on a highly domain-relevant lexical sample (in mathematical terms, words that are indicative of a domain with high scores) but we sense-annotated almost all content words from the document collection in which case the WSD accuracy drops. We imposed a cut-off of 5 as the score for a domain relevant term -by comparison, the most informative term from the JRC Acquis, "emolient", has a score of 75.88; • we extracted terms along with document relevance scores and not domain relevance scores using the TF-IDF measure and not the one we developed specially for domain-relevant terms from <ref type="bibr" coords="6,327.71,493.05,10.83,8.74" target="#b0">[1]</ref>; • question formulation follows closely the phrasing in the document collection in which case, query expansion only produces noise. This judgment is not final since we did not experiment with any of the following:</p><p>• increase the term threshold (from 5 to what value?) when doing WSD on both the question and the document collection in order to improve WSD accuracy; • instead of indexing synonyms for every term, we could index the term's senses ids; when doing query generation, we could expand sense ids instead of synonyms with an expected effect of noise reduction; • train the system on the ResPubliQA 2009 500 questions test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">The Cross-lingual Runs</head><p>The cross-lingual system uses the same index as the monolingual Romanian QA but for the query generation it uses an already available statistical machine translation (SMT) system experimented in several RACAI projects <ref type="bibr" coords="7,350.55,150.03,10.64,8.74" target="#b2">[3]</ref>. The SMT system is based on Moses <ref type="bibr" coords="7,166.46,161.49,10.64,8.74" target="#b4">[5]</ref>, an open source framework for rapid prototyping of machine translation systems.</p><p>The training data for the translation system consisted of the JRC Acquis corpus and EMEA -European Medicines Agency documents <ref type="bibr" coords="7,350.48,195.99,15.33,8.74" target="#b9">[10]</ref>. The abundant foreign languages fragments were filtered-out as well as the translation units with significant length differences. After filtering, the remaining corpus had a total of 1.4 million translation units. Also, the translation pairs from the Romanian Wordnet <ref type="bibr" coords="7,421.66,230.49,16.70,8.74" target="#b10">[11]</ref> aligned to the Princeton Wordnet (http://wordnet.princeton.edu/) were added to the training data.</p><p>From the training data only the lemmas of the content words were kept. The first two letters of the morpho-syntactical description were added to the lemma in order to syntactically disambiguate the terms. For example, the sentence "The medicine can only be obtained with a prescription." is transformed into the sequence: "medicine^Nc obtain^Vm prescription^Nc". Using the Moses scripts and Giza++ alignments we extracted a phrase-table (3-gram maximum length) for content-words lemmas.</p><p>We used different query translation algorithms for the two submitted runs. For the first run, we selected from the translation table the translation equivalents for each content word lemma. For example, the question "Why was Perwiz Kambakhsh sentenced to death?" is translated into the query:</p><formula xml:id="formula_2" coords="7,124.74,386.01,345.92,20.20">de_ce Perwiz Kambakhsh (condamna OR condamnat OR condamnare) (deces OR moarte)</formula><p>For the second run, we used the Moses decoder to generate the n-best translation list. The terms from the lists were collected into a single query. For example, the same English question as above is translated into the query: de_ce Perwiz Kambakhsh condamna condamnat condamnare deces moarte fi</p><p>The two approaches have similar results as can be seen in the official results shown in Table <ref type="table" coords="7,160.34,484.47,3.90,8.74" target="#tab_5">5</ref> The performance measures are significantly lower than those of the monolingual counterpart suggesting the fact that either the translation can be improved or the issue of noise introduction with alternate translations for a term is to be addressed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>RACAI participated in the Romanian-Romanian and English-Romanian settings of the ResPubliQA 2010 Paragraph Selection track using the QA system that it has developed for the last year's ResPubliQA. The main aim of our participation this year was to test the scalability of our QA system to new challenges given the fact that it performed the best last year in the Romanian-Romanian setting out of 4 runs belonging to 2 participating groups but also overall out of the 28 runs in all languages.</p><p>Even if the results were lower than those of the last year, we acquired important insights on how to scale this QA system to new challenges. Thus, for instance, we validated the per-class training that gives the best results and also, we know now that MERT estimation is very sensitive to the training data set.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,145.02,625.41,316.74,8.74;2,120.66,541.26,355.44,78.54"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The annotations in a ready to be indexed file of the document collection</figDesc><graphic coords="2,120.66,541.26,355.44,78.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,128.82,405.87,337.74,157.24"><head>Table 1 .</head><label>1</label><figDesc>Weights for each paragraph relevance score and each question class trained from the last year's test set using the TF-IDF query generation algorithm</figDesc><table coords="4,131.82,405.87,331.69,157.24"><row><cell></cell><cell cols="5">Lexical Chains Class BLEU Paragraph Document</cell></row><row><cell>DEFINITION</cell><cell>0.03</cell><cell>0</cell><cell>0</cell><cell>0.08</cell><cell>0.89</cell></row><row><cell>FACTOID</cell><cell>0.06</cell><cell>0</cell><cell>0.12</cell><cell>0.28</cell><cell>0.54</cell></row><row><cell>PROCEDURE</cell><cell>0.09</cell><cell>0</cell><cell>0.09</cell><cell>0.17</cell><cell>0.65</cell></row><row><cell>REASON-PURPOSE</cell><cell>0.48</cell><cell>0</cell><cell>0.21</cell><cell>0.26</cell><cell>0.05</cell></row><row><cell>CHUNK Q. Gen.</cell><cell cols="5">Lexical Chains Class BLEU Paragraph Document</cell></row><row><cell>DEFINITION</cell><cell>0.11</cell><cell>0</cell><cell>0.12</cell><cell>0.1</cell><cell>0.76</cell></row><row><cell>FACTOID</cell><cell>0.11</cell><cell>0</cell><cell>0.27</cell><cell>0.14</cell><cell>0.48</cell></row><row><cell>PROCEDURE</cell><cell>0.59</cell><cell>0</cell><cell>0.29</cell><cell>0.03</cell><cell>0.09</cell></row><row><cell>REASON-PURPOSE</cell><cell>0</cell><cell>0</cell><cell>0.09</cell><cell>0.17</cell><cell>0.74</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,124.74,578.68,341.82,36.45"><head>Table 2 .</head><label>2</label><figDesc>Weights for each paragraph relevance score and each question class trained from the last year's test set using the CHUNK query generation algorithmThe official results of our two runs are given in Table3.</figDesc><table coords="5,310.98,150.63,156.02,8.74"><row><cell>icia101PSroro</cell><cell>icia102PSroro</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,174.90,274.84,245.44,7.85"><head>Table 3 .</head><label>3</label><figDesc>Official results on Romanian-Romanian ResPubliQA 2010</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,124.74,590.49,345.95,43.24"><head>Table 4</head><label>4</label><figDesc>summarizes the results that we have obtained on the ResPubliQA 2010 official 200 questions test set. The QA system ran with the same global weights (see eq. 1) as per last year ResPubliQA.</figDesc><table coords="6,140.46,170.79,314.45,92.74"><row><cell>Q. Gen. Algorithms</cell><cell cols="4">Query Expansion WSD Idx. No WSD Idx. WSD Idx. No WSD Idx. No Query Expansion</cell></row><row><cell>TF-IDF</cell><cell>0.2577/</cell><cell>0.2602/</cell><cell>0.2914/</cell><cell>0.4020/</cell></row><row><cell></cell><cell>0.3084/</cell><cell>0.3054/</cell><cell>0.3406/</cell><cell>0.4748/</cell></row><row><cell></cell><cell>0.4690</cell><cell>0.4438</cell><cell>0.6783</cell><cell>0.6934</cell></row><row><cell>CHUNK</cell><cell></cell><cell></cell><cell>0.3467/</cell><cell>0.3618/</cell></row><row><cell></cell><cell>-</cell><cell>-</cell><cell>0.4226/</cell><cell>0.4311/</cell></row><row><cell></cell><cell></cell><cell></cell><cell>0.7286</cell><cell>0.7286</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,141.60,279.94,312.17,18.89"><head>Table 4 .</head><label>4</label><figDesc>Runs to evaluate the WSD impact on our QA performance for the Romanian-Romanian setting.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,131.28,484.47,332.70,151.50"><head>Table 5 .</head><label>5</label><figDesc>Official results for English-Romanian ResPubliQA 2010</figDesc><table coords="7,131.28,484.47,332.70,128.74"><row><cell>:</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">icia101PSenro icia102PSenro</cell></row><row><cell>ANSWERED</cell><cell>197</cell><cell>193</cell></row><row><cell>UNANSWERED</cell><cell>3</cell><cell>7</cell></row><row><cell>ANSWERED with RIGHT candidate</cell><cell>58</cell><cell>56</cell></row><row><cell>ANSWERED with WRONG candidate</cell><cell>139</cell><cell>137</cell></row><row><cell>UNANSWERED with RIGHT candidate</cell><cell>0</cell><cell>0</cell></row><row><cell>UNANSWERED with WRONG candidate</cell><cell>0</cell><cell>0</cell></row><row><cell>UNANSWERED with EMPTY candidate</cell><cell>3</cell><cell>7</cell></row><row><cell>Overall accuracy</cell><cell>0.29</cell><cell>0.28</cell></row><row><cell>c@1 measure</cell><cell>0.29</cell><cell>0.29</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="3,130.80,676.12,339.80,7.85;3,133.26,686.50,182.92,7.85"><p>The Inter-Lingual Index (ILI) was a major outcome of the EuroWordNet project<ref type="bibr" coords="3,431.59,676.12,15.00,7.85" target="#b12">[13]</ref> and it ensures the cross-linguistic alignment of wordnets.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1" coords="8,142.80,122.74,313.36,7.85;8,124.74,134.74,128.75,7.85"><p>Radu ION, Alexandru CEAUŞU, Dan ŞTEFĂNESCU, Dan TUFIŞ, Elena IRIMIA and Verginica BARBU MITITELU</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>RACAI participation to CLEF series of QA systems evaluation was possible due to the <rs type="projectName">SIR-RESDEC</rs> national project (no. <rs type="grantNumber">D1.1.0.0.0.7/18.09.2007</rs>) that aims at developing an open-domain QA system with application to the European Legislation. This project is approaching the finish line and as such, we will leverage all our CLEF experience in order to put forward this QA system and make it available on the web.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_qSS6ShP">
					<idno type="grant-number">D1.1.0.0.0.7/18.09.2007</idno>
					<orgName type="project" subtype="full">SIR-RESDEC</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,128.12,443.92,342.55,7.85;8,141.72,454.24,328.88,7.85;8,141.72,464.62,293.22,7.85" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,272.16,443.92,198.50,7.85;8,141.72,454.24,41.81,7.85">RACAI: Unsupervised WSD Experiments @ SemEval-2, Task #17</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ştefănescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,201.16,454.24,265.71,7.85">Proceedings of the 5th International Workshop on Semantic Evaluations</title>
		<meeting>the 5th International Workshop on Semantic Evaluations<address><addrLine>SemEval-; Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-07-15">2010. 2010. July 15-16 2010. ACL 2010</date>
			<biblScope unit="page" from="411" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,128.12,474.94,342.50,7.85;8,141.72,485.26,328.84,7.85;8,141.72,495.64,314.24,7.85" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,465.12,474.94,5.50,7.85;8,141.72,485.26,131.87,7.85">A Trainable Multi-factored QA System</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ştefănescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Al</forename><surname>Ceauşu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tufiş</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Irimia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Barbu Mititelu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,387.51,485.26,83.05,7.85;8,141.72,495.64,79.88,7.85">Working Notes for the CLEF 2009 Workshop</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-09-30">2009. September, 30th -October, 2nd 2009</date>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,128.12,505.96,342.45,7.85;8,141.72,516.34,328.86,7.85;8,141.72,526.66,258.57,7.85" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,270.66,505.96,199.91,7.85;8,141.72,516.34,71.85,7.85">Dependency-based translation equivalents for factored machine translation</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Irimia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Al</forename><surname>Ceauşu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,325.06,516.34,145.51,7.85;8,141.72,526.66,123.26,7.85">Research In Computer Science, Special Issue on NLP and its Applications</title>
		<editor>
			<persName><forename type="first">Alexander</forename><surname>Gelbukh</surname></persName>
		</editor>
		<idno type="ISSN">1870-4069</idno>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="205" to="216" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,128.12,537.04,342.50,7.85;8,141.72,547.36,318.96,7.85" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,215.75,537.04,234.50,7.85">EuroParl: A Parallel Corpus for Statistical Machine Translation</title>
		<author>
			<persName coords=""><forename type="first">Ph</forename><surname>Koehn</surname></persName>
		</author>
		<ptr target="http://people.csail.mit.edu/koehn/publications/europarl/" />
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
			<pubPlace>MT Summit; Phuket, Thailand</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,128.12,557.74,342.52,7.85;8,141.72,568.06,328.95,7.85;8,141.72,578.44,328.90,7.85;8,141.72,588.76,328.85,7.85;8,141.72,599.14,100.70,7.85" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,170.76,578.44,234.12,7.85">Moses: Open Source Toolkit for Statistical Machine Translation</title>
		<author>
			<persName coords=""><forename type="first">Ph</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ch</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ch</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ch</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,411.33,578.44,59.29,7.85;8,141.72,588.76,294.67,7.85">Annual Meeting of the Association for Computational Linguistics (ACL), demonstration session</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-06">2007. June 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,128.12,609.46,342.53,7.85;8,141.72,619.84,328.93,7.85;8,141.72,630.16,328.91,7.85;8,141.72,640.54,157.23,7.85" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,226.79,609.46,228.36,7.85">Fast and Accurate Sentence Alignment of Bilingual Corpora</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">C</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,141.72,619.84,328.93,7.85;8,141.72,630.16,203.96,7.85">Machine Translation: From Research to Real Users (Proceedings, 5th Conference of the Association for Machine Translation in the Americas</title>
		<meeting><address><addrLine>Tiburon, California; Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="135" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,128.12,650.86,342.46,7.85;8,141.72,661.24,328.88,7.85;8,141.72,671.56,85.54,7.85" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,213.90,650.86,241.56,7.85">Minimal Error Rate Training in Statistical Machine Translation</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,141.72,661.24,325.36,7.85">Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003-07">2003. July 2003</date>
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,128.12,149.68,342.46,7.85;9,141.72,160.00,275.58,7.85" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="9,226.98,149.68,201.59,7.85">Word Sense Disambiguation and Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
		<idno>TR-1997-7</idno>
		<imprint>
			<date type="published" when="1997">1997. 1997</date>
			<pubPlace>Glasgow G12 8QQ, UK</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Glasgow</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="9,128.12,170.38,342.39,7.85;9,141.72,180.70,328.86,7.85;9,141.72,191.08,328.89,7.85;9,141.72,201.40,328.86,7.85;9,141.72,211.78,87.52,7.85" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,170.53,180.70,285.83,7.85">The JRC-Acquis: A Multilingual Aligned Parallel Corpus with 20+ Languages</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Steinberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pouliquen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Widiger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ignat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Erjavec</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tufiş</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Varga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,141.72,191.08,328.89,7.85;9,141.72,201.40,49.89,7.85">Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC 2006)</title>
		<meeting>the 5th International Conference on Language Resources and Evaluation (LREC 2006)<address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>ELRA -European Language Ressources Association</publisher>
			<date type="published" when="2006-05">2006. May 2006</date>
			<biblScope unit="page" from="2142" to="2147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.25,222.10,338.27,7.85;9,141.72,232.48,328.86,7.85;9,141.72,242.80,328.85,7.85;9,141.72,253.18,154.08,7.85" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,225.48,222.10,245.05,7.85;9,141.72,232.48,96.22,7.85">News from OPUS -A Collection of Multilingual Parallel Corpora with Tools and Interfaces</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,194.80,242.80,184.35,7.85">Recent Advances in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Nicolov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Bontcheva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Angelova</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Mitkov</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam/Philadelphia</addrLine></address></meeting>
		<imprint>
			<publisher>John Benjamins</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="237" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.24,263.50,338.34,7.85;9,141.72,273.82,328.92,7.85;9,141.72,284.20,328.93,7.85;9,141.72,294.52,328.91,7.85;9,141.72,304.90,15.73,7.85" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,433.56,263.50,37.02,7.85;9,141.72,273.82,207.34,7.85">Romanian WordNet: Current State, New Applications and Prospects</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tufiş</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bozianu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Al</forename><surname>Ceauşu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ştefănescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,338.31,284.20,132.34,7.85;9,141.72,294.52,86.64,7.85">Proceedings of 4th Global WordNet Conference, GWC-2008</title>
		<editor>
			<persName><forename type="first">Attila</forename><surname>Tanacs</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dora</forename><surname>Csendes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Veronika</forename><surname>Vincze</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Piek</forename><surname>Vossen</surname></persName>
		</editor>
		<meeting>4th Global WordNet Conference, GWC-2008<address><addrLine>University of Szeged, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-01-22">2008. January 22-25 2008</date>
			<biblScope unit="page" from="441" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.24,315.22,338.41,7.85;9,141.72,325.60,328.84,7.85;9,141.72,335.92,328.93,7.85;9,141.72,346.30,126.05,7.85" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,379.20,315.22,91.45,7.85;9,141.72,325.60,28.67,7.85">RACAI&apos;s Linguistic Web Services</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tufiş</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Al</forename><surname>Ceauşu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ştefănescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,186.00,325.60,284.56,7.85;9,141.72,335.92,42.85,7.85">Proceedings of the 6th Language Resources and Evaluation Conference -LREC 2008</title>
		<meeting>the 6th Language Resources and Evaluation Conference -LREC 2008<address><addrLine>Marrakech, Morocco</addrLine></address></meeting>
		<imprint>
			<publisher>ELRA -European Language Ressources Association</publisher>
			<date type="published" when="2008-05">2008b. May 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.24,356.62,338.34,7.85;9,141.72,367.00,187.31,7.85" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="9,236.04,356.62,234.54,7.85;9,141.72,367.00,32.24,7.85">EuroWordNet: A Multilingual Database with Lexical Semantic Networks</title>
		<editor>Vossen, P.</editor>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Dordrecht</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
