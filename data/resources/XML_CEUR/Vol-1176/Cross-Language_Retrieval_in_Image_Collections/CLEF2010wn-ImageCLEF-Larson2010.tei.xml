<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,144.12,66.13,326.98,12.67;1,217.80,84.13,179.77,12.67">Blind Relevance Feedback for the ImageCLEF Wikipedia Retrieval Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,275.88,121.80,63.86,8.85"><forename type="first">Ray</forename><forename type="middle">R</forename><surname>Larson</surname></persName>
							<email>ray@ischool.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,144.12,66.13,326.98,12.67;1,217.80,84.13,179.77,12.67">Blind Relevance Feedback for the ImageCLEF Wikipedia Retrieval Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B9DF8668672924881EE88CF4764916ED</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we will describe Berkeley's approach to the ImageCLEF Wikipedia Retrieval task for 2010. Our approach to this task was primarily to use text-based searches on the contents of the Wikipedia image metadata records. In addition we submitted one run using a database derived from the provided "bag.xml" set of 5000 descriptor "words" for each image and query example images. We had also intended to combine this one image-based approach to other image-based approaches and to the text-based approaches using fusion methods, but were unable to complete the coding in time. We submitted 8 runs for ImageCLEF Wikipedia Retrieval this year, of which 6 where monolingual English, German and French with differing search areas in the metadata record, one was multilingual and the remaining one was image-based using the data derived from bag.xml file. Our best performing run was ranked 24th among the 127 submitted runs by all participants with a MAP of 0.2014, while the image-only approach was ranked dead last (one wonders, in fact, if random results might have done better).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper discusses the retrieval methods and evaluation results for Berkeley's participation in the ImageCLEF Wikipedia Retrieval task. This year we used primarily text-based retrieval methods for ImageCLEF Wikipedia Retrieval, but also attempted to use some of the supplied image-derived information. We did manage to submit a single image-only run, but were not able to use it in combination with our text-based approach (unfortunately we were not able to complete the merger software in time for official submissions, although we hope to have some combined runs to report later).</p><p>This year Berkeley submitted 8 runs, of which 2 where English Monolingual, 2 German Monolingual, and 2 were French monolingual. The remaining runs included one multilingual run (using the English German and French topic text and the entire metadata record as a search target), and a single image-based run derived from the "bag.xml" file provided with the database.</p><p>This paper first describes the retrieval methods used, including our blind feedback method for text, followed by a discussion of our official submissions and the methods used for query expansion. Finally we present some discussion of the results and our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Retrieval Algorithms</head><p>(Note, this section repeats information provided in our 2006 ImageCLEF Notebook paper, since the basic retrieval algorithms used and the approaches to indexing the content have not been changed since then. This same algorithm and approach have been used in a wide variety of cross-language retrieval experiments in both CLEF and NTCIR (see, for example, <ref type="bibr" coords="2,334.64,185.76,11.11,8.84" target="#b8">[9,</ref><ref type="bibr" coords="2,347.49,185.76,13.15,8.84" target="#b9">10,</ref><ref type="bibr" coords="2,362.51,185.76,8.10,8.84" target="#b6">7,</ref><ref type="bibr" coords="2,372.36,185.76,12.89,8.84" target="#b10">11]</ref>)</p><p>The basic form and variables of the Logistic Regression (LR) algorithm used for all of our text-based submissions was originally developed by Cooper, et al. <ref type="bibr" coords="2,134.76,221.76,9.99,8.85" target="#b5">[6]</ref>. As originally formulated, the LR model of probabilistic IR attempts to estimate the probability of relevance for each document based on a set of statistics about a document collection and a set of queries in combination with a set of weighting coefficients for those statistics. The statistics to be used and the values of the coefficients are obtained from regression analysis of a sample of a collection (or similar test collection) for some set of queries where relevance and non-relevance has been determined. More formally, given a particular query and a particular document in a collection P (R | Q, D) is calculated and the documents or components are presented to the user ranked in order of decreasing values of that probability. To avoid invalid probability values, the usual calculation of P (R | Q, D) uses the "log odds" of relevance given a set of S statistics, s i , derived from the query and database, such that:</p><formula xml:id="formula_0" coords="2,241.32,373.67,239.32,31.09">log O(R | Q, D) = b 0 + S i=1 b i s i (1)</formula><p>where b 0 is the intercept term and the b i are the coefficients obtained from the regression analysis of the sample collection and relevance judgements. The final ranking is determined by the conversion of the log odds form to probabilities:</p><formula xml:id="formula_1" coords="2,238.56,459.11,136.43,24.69">P (R | Q, D) = e log O(R|Q,D) 1 + e log O(R|Q,D)</formula><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">TREC2 Logistic Regression Algorithm</head><p>For all of our ImageCLEF submissions this year we used a version of the Logistic Regression (LR) algorithm that has been used very successfully in Cross-Language IR by Berkeley researchers for a number of years <ref type="bibr" coords="2,390.73,546.47,12.37,8.85" target="#b3">[4]</ref> and which is also used in our GeoCLEF and Domain Specific submissions. For the ImageCLEF task we used the Cheshire II information retrieval system implementation of this algorithm. One of the current limitations of this implementation is the lack of decompounding for German document and query terms. As noted in our other CLEF notebook papers, the Logistic Regression algorithm used was originally developed by Cooper et al. <ref type="bibr" coords="3,256.68,69.12,10.57,8.85" target="#b4">[5]</ref> for text retrieval from the TREC collections for TREC2. The basic formula is:</p><formula xml:id="formula_2" coords="3,197.52,98.31,219.28,147.81">log O(R|C, Q) = log p(R|C, Q) 1 -p(R|C, Q) = log p(R|C, Q) p(R|C, Q) = c 0 + c 1 * 1 |Q c | + 1 |Qc| i=1 qtf i ql + 35 + c 2 * 1 |Q c | + 1 |Qc| i=1 log tf i cl + 80 -c 3 * 1 |Q c | + 1 |Qc| i=1 log ctf i N t + c 4 * |Q c |</formula><p>where C denotes a document component (i.e., an indexed part of a document which may be the entire document) and Q a query, R is a relevance variable,</p><formula xml:id="formula_3" coords="3,134.76,288.27,345.95,58.18">p(R|C, Q) is the probability that document component C is relevant to query Q, p(R|C, Q) the probability that document component C is not relevant to query Q, which is 1.0 -p(R|C, Q) |Q c |</formula><p>is the number of matching terms between a document component and a query, qtf i is the within-query frequency of the ith matching term, tf i is the within-document frequency of the ith matching term, ctf i is the occurrence frequency in a collection of the ith matching term, ql is query length (i.e., number of terms in a query like |Q| for non-feedback situations), cl is component length (i.e., number of terms in a component), and N t is collection length (i.e., number of terms in a test collection). c k are the k coefficients obtained though the regression analysis.</p><p>If stopwords are removed from indexing, then ql, cl, and N t are the query length, document length, and collection length, respectively. If the query terms are re-weighted (in feedback, for example), then qtf i is no longer the original term frequency, but the new weight, and ql is the sum of the new weight values for the query terms. Note that, unlike the document and collection lengths, query length is the "optimized" relative frequency without first taking the log over the matching terms.</p><p>The coefficients were determined by fitting the logistic regression model specified in log O(R|C, Q) to TREC training data using a statistical software package. The coefficients, c k , used for our official runs are the same as those described by Chen <ref type="bibr" coords="3,167.55,582.36,13.52,8.85" target="#b1">[2]</ref>. These were: c 0 = -3.51, c 1 = 37.4, c 2 = 0.330, c 3 = 0.1937 and c 4 = 0.0929. Further details on the TREC2 version of the Logistic Regression algorithm may be found in Cooper et al. <ref type="bibr" coords="3,315.23,606.24,9.99,8.85" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Blind Relevance Feedback</head><p>In addition to the direct retrieval of documents using the TREC2 logistic regression algorithm described above, we have implemented a form of "blind relevance feedback" as a supplement to the basic algorithm. The algorithm used for blind feedback was originally developed and described by Chen <ref type="bibr" coords="4,395.57,127.32,10.00,8.85" target="#b2">[3]</ref>. Blind relevance feedback has become established in the information retrieval community due to its consistent improvement of initial search results as seen in TREC, CLEF and other retrieval evaluations <ref type="bibr" coords="4,275.70,163.20,10.00,8.85" target="#b7">[8]</ref>. The blind feedback algorithm is based on the probabilistic term relevance weighting formula developed by Robertson and Sparck Jones <ref type="bibr" coords="4,194.78,187.08,14.68,8.85" target="#b12">[13]</ref>.</p><p>Blind relevance feedback is typically performed in two stages. First, an initial search using the original topic statement is performed, after which a number of terms are selected from some number of the top-ranked documents (which are presumed to be relevant). The selected terms are then weighted and then merged with the initial query to formulate a new query. Finally the reweighted and expanded query is submitted against the same collection to produce a final ranked list of documents. Obviously there are important choices to be made regarding the number of top-ranked documents to consider, and the number of terms to extract from those documents. For ImageCLEF this year, having no prior data to guide us, we chose to use the top 10 terms from 10 top-ranked documents. The terms were chosen by extracting the document vectors for each of the 10 and computing the Robertson and Sparck Jones term relevance weight for each document. This weight is based on a contingency table where the counts of 4 different conditions for combinations of (assumed) relevance and whether or not the term is, or is not in a document. Table <ref type="table" coords="4,341.92,366.84,4.98,8.85">1</ref> shows this contingency table.</p><formula xml:id="formula_4" coords="4,192.24,386.59,208.29,52.44">Relevant Not Relevant In doc Rt Nt -Rt Nt Not in doc R -Rt N -Nt -R + Rt N -Nt R N -R N Table 1.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contingency table for term relevance weighting</head><p>The relevance weight is calculated using the assumption that the first 10 documents are relevant and all others are not. For each term in these documents the following weight is calculated:</p><formula xml:id="formula_5" coords="4,261.48,507.11,219.16,30.61">w t = log Rt R-Rt Nt-Rt N -Nt-R+Rt (3)</formula><p>The 10 terms (including those that appeared in the original query) with the highest w t are selected and added to the original query terms. For the terms not in the original query, the new "term frequency" (qtf i in Equation 3 above) is set to 0.5. Terms that were in the original query, but are not in the top 10 terms are left with their original qtf i . For terms in the top 10 and in the original query the new qtf i is set to 1.5 times the original qtf i for the query. The new query is then processed using the same LR algorithm as shown in Equation 3 and the ranked results returned as the response for that topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approaches for ImageCLEF Wikipedia Retrieval</head><p>In this section we describe the specific approaches taken for our official submitted runs for the ImageCLEF Wikipedia Retrieval task. First we describe the indexing and term extraction methods used, and then the search features we used for the submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Indexing and Term Extraction</head><p>Cheshire II system uses the XML structure of documents and extracts selected portions of those record for indexing and retrieval. In our submitted runs this year we used separate indexes for each of the languages (English, German and French) as well as a global index combining all elements of the metadata records.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name Description Content Tags</head><p>Used names Image name names no topic Entire Record image yes texten English Text text@lang="en" yes textde German Text text@lang="de" yes textfr French Text text@lang="fr" yes Table <ref type="table" coords="5,226.44,348.10,4.12,7.89">2</ref>. Indexes for ImageCLEF Wikipedia Retrieval Table <ref type="table" coords="5,177.25,377.04,4.98,8.85">2</ref> lists the indexes created for the ImageCLEF database and the document elements from which the contents of those indexes were extracted. The "Used" column in Table <ref type="table" coords="5,243.11,400.92,4.98,8.85">2</ref> indicates whether or not a particular index was used in the submitted ImageCLEF runs. For all indexing we used language-specific stoplists to exclude function words and very common words from the indexing and searching. The German language runs, however, did not use decompounding in the indexing and querying processes to generate simple word forms from compounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Image Content Indexing and Processing</head><p>In earlier work we used the Berkeley Blobworld algorithms <ref type="bibr" coords="5,400.49,510.60,10.56,8.85" target="#b0">[1]</ref> in some digital library retrieval experiments with quite good results (see <ref type="bibr" coords="5,380.57,522.60,14.83,8.85" target="#b11">[12]</ref>). In that approach, the blobworld features for each "blob" (a coherent region of color and texture) were quantized and treated as a set of tokens, with token frequency based on weights for the different quanta. Retrieval then treated the tokenized image "blob" information as terms, and used simple text ranking methods to rank blobs and hence images. We had hoped to revive the blobworld segmentation software for this task, but were not able to complete the conversion from MatLab code to C in the time available for the task. In looking at the image feature data provided with the collection, we realized that a similar approach might be attempted with that data, so as a last-minute attempt, we tokenized the 5000 element "bag" vectors, using a very simple approach (probably too simple, considering the rather terrible results) and used the basic TREC2 algorithm (without blind feedback) to rank the results. The same approach was used on the provided sample images for the topics to provide the queries for processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Search Processing</head><p>Searching the ImageCLEF Wikipedia collection used Cheshire II scripts to parse the topics and submit a query to the system using the topic title in a particular language (or for all of the languages in the multilingual case). Depending on settings in the script, the queries were run against the language specific indexes, or the entire document. The TREC2 algorithm with blind feedback used the top 10 terms from the 10 top-ranked documents in the initial retrieval for the blind feedback.</p><p>Our single image-based run used the tokenized features derived from the example images to search the tokenized feature vector indices. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results for Submitted Runs</head><p>The summary results (as Mean Average Precision) for all of our official submitted runs are shown in Table <ref type="table" coords="7,178.44,513.24,4.98,8.85" target="#tab_0">3</ref> shows all of our submitted runs for the ImageCLEF Photo task. Precision and recall curves for the runs are shown in Figures <ref type="figure" coords="7,402.56,525.24,4.98,8.85" target="#fig_0">1</ref> and<ref type="figure" coords="7,430.16,525.24,3.90,8.85" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Conclusions</head><p>Our officially submitted runs using text retrieval with blind feedback did not perform as well as some of the other participants' text-only runs and definitely lagged behind the best performing mixed image and text runs. What was also apparent (both from the results and examination of the database itself) was that the multilingual character of the data was very spotty. Most of the metadata entries did not include all three target languages, and many records contained no text descriptions at all other than a caption in a single language, or in some cases terms in the image name itself. Thus, our runs that targetted the entire record did much better than those attempting to access the language-tagged text. Another interesting point is that simply combining the topic titles for each language was our best performing run. This is interesting primarily in comparison with previous CLEF multilingual tasks in other track, where this approach usually made results worse than monolingual approaches. It may be that the sparseness of the metadata records and uneven distribution of language use favors the multilingual approach.</p><p>As note above, our single image-only submission was a dismal failure. However, we hope to be able to further test using image element summarization and tokenization, but to do that effectively we first need to know much more about how the supplied feature vectors were created and what each element in those vectors represents. Considering the only real documentation is pointers to journal papers, where the data format is not described at all, it is probably not surprising that our last minute approach made some wrong assumptions and choices in representing the image features. We also still hope to be able to revive the blobworld sofware and use it for future experiments, but at present that is dependent on either getting funding to re-license Matlab, or completing the rewrite of the software in C or some other high-level language.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,134.76,76.51,345.89,7.96;6,134.76,87.55,28.08,7.96"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Berkeley Monolingual Runs -English (top left), German (top right) and French (lower)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,238.68,76.03,138.05,7.96"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Berkeley Multilingual Run</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,134.76,332.40,346.00,144.24"><head>Table 3 ,</head><label>3</label><figDesc>the Recall-Precision curves for the text-based runs are also shown in Figures1 (for monolingual) and 2 (for multilingual). In Figures1 and 2the names are abbrevated as indicated in the "Abbrev." column. 3.</figDesc><table coords="7,165.24,373.75,284.69,102.88"><row><cell>Run Name</cell><cell>Target</cell><cell>Description</cell><cell cols="2">Feedback MAP</cell></row><row><cell>BRK-T2BF-DE-DE</cell><cell>DE</cell><cell>Mono. German</cell><cell>Y</cell><cell>0.0505</cell></row><row><cell>BRK-T2BF-DE-ALL</cell><cell cols="2">ENDEFR Mono. German</cell><cell>Y</cell><cell>0.0820</cell></row><row><cell>BRK-T2BF-EN-EN</cell><cell>EN</cell><cell>Mono. English</cell><cell>Y</cell><cell>0.1386</cell></row><row><cell>BRK-T2BF-EN-ALL</cell><cell cols="2">ENDEFR Mono. English</cell><cell>Y</cell><cell>0.1941</cell></row><row><cell>BRK-T2BF-FR-FR</cell><cell>FR</cell><cell>Mono. French</cell><cell>Y</cell><cell>0.0623</cell></row><row><cell>BRK-T2BF-FR-ALL</cell><cell cols="2">ENDEFR Mono. French</cell><cell>Y</cell><cell>0.0853</cell></row><row><cell cols="3">BRK-T2BF-ENDEFR-ALL ENDEFR Multilingual</cell><cell>Y</cell><cell>0.2014</cell></row><row><cell>BRK-FEAT-T3</cell><cell>image</cell><cell>visual features</cell><cell>N</cell><cell>0.0001</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,228.72,481.51,158.06,7.96"><head>Table 3 .</head><label>3</label><figDesc>Submitted ImageCLEF Runs</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.88,387.79,337.56,7.96;8,151.56,398.71,329.14,7.96;8,151.56,409.63,329.14,7.96;8,151.56,420.55,107.89,7.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,437.05,387.79,43.39,7.96;8,151.56,398.71,329.14,7.96;8,151.56,409.63,68.12,7.96">Color-and texture-based image segmentation using EM and its application to image querying and classification</title>
		<author>
			<persName coords=""><forename type="first">Chad</forename><surname>Carson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hayit</forename><surname>Greenspan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,229.56,409.63,251.14,7.95;8,151.56,420.55,20.03,7.95">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.88,431.59,337.51,7.96;8,151.56,442.51,328.97,7.96;8,151.56,453.56,329.05,7.95;8,151.56,464.48,328.91,7.95;8,151.56,475.40,289.44,7.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,205.45,431.59,271.14,7.96">Multilingual information retrieval using english and chinese queries</title>
		<author>
			<persName coords=""><forename type="first">Aitao</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,459.73,442.51,20.80,7.95;8,151.56,453.56,329.05,7.95;8,151.56,464.48,188.76,7.95">Evaluation of Cross-Language Information Retrieval Systems: Second Workshop of the Cross-Language Evaluation Forum, CLEF-2001</title>
		<title level="s" coord="8,229.84,475.40,163.12,7.96">Springer Computer Scinece Series LNCS</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Kluck</surname></persName>
		</editor>
		<meeting><address><addrLine>Darmstadt, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-09">September 2001. 2002</date>
			<biblScope unit="volume">2406</biblScope>
			<biblScope unit="page" from="44" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.88,486.44,337.53,7.96;8,151.56,497.36,124.11,7.96" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="8,205.92,486.44,195.18,7.95">Cross-Language Retrieval Experiments at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Aitao</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002. 2003</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">2785</biblScope>
			<biblScope unit="page" from="28" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.88,508.28,337.64,7.96;8,151.56,519.32,328.85,7.96;8,151.56,530.24,40.24,7.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,284.69,508.28,195.83,7.96;8,151.56,519.32,203.54,7.96">Multilingual information retrieval using machine translation, relevance feedback and decompounding</title>
		<author>
			<persName coords=""><forename type="first">Aitao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,363.13,519.32,85.38,7.95">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="149" to="182" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.89,541.16,337.43,7.96;8,151.56,552.20,328.87,7.96;8,151.56,563.12,169.47,7.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,317.85,541.16,162.47,7.96;8,151.56,552.20,245.84,7.96">Full Text Retrieval based on Probabilistic Equations with Coefficients fitted by Logistic Regression</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">S</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,420.85,552.20,59.58,7.95;8,151.56,563.12,86.82,7.95">Text REtrieval Conference (TREC-2)</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.89,574.04,337.54,7.96;8,151.56,585.08,329.10,7.96;8,151.56,596.00,328.89,7.95;8,151.56,606.92,249.98,7.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,393.40,574.04,87.03,7.96;8,151.56,585.08,141.15,7.96">Probabilistic retrieval based on staged logistic regression</title>
		<author>
			<persName coords=""><forename type="first">William</forename><forename type="middle">S</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><forename type="middle">P</forename><surname>Dabney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,316.92,585.08,163.73,7.95;8,151.56,596.00,270.70,7.95">15th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting><address><addrLine>Copenhagen, Denmark; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1992">June 21-24. 1992</date>
			<biblScope unit="page" from="198" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.88,69.79,337.71,7.96;9,151.56,80.83,328.85,7.96;9,151.56,91.75,40.24,7.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,310.70,69.79,148.58,7.96">Patent mining: A baseline approach</title>
		<author>
			<persName coords=""><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ray</forename><forename type="middle">R</forename><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,151.56,80.83,186.00,7.95">Proceedings of the NTCIR-7 Workshop Meeting</title>
		<meeting>the NTCIR-7 Workshop Meeting<address><addrLine>Tokyo</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-12">December 2008. 2008</date>
			<biblScope unit="page" from="358" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.88,102.67,337.48,7.96;9,151.56,113.71,329.08,7.96;9,151.56,124.64,110.79,7.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,219.81,102.67,260.56,7.96;9,151.56,113.71,55.15,7.96">Probabilistic retrieval, component fusion and blind feedback for XML retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,223.32,113.71,42.82,7.95">INEX 2005</title>
		<title level="s" coord="9,373.79,113.71,106.86,7.96;9,151.56,124.64,59.19,7.96">Lecture Notes in Computer Science, LNCS</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">3977</biblScope>
			<biblScope unit="page" from="225" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.89,135.56,337.72,7.96;9,151.56,146.60,328.82,7.95;9,151.56,157.52,328.85,7.96;9,151.56,168.44,169.24,7.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,216.83,135.56,247.24,7.96">Cheshire at GeoCLEF 2007: Retesting text retrieval baselines</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,151.56,146.60,281.65,7.95">8th Workshop of the Cross-Language Evaluation Forum, CLEF 2007</title>
		<meeting><address><addrLine>Budapest, Hungary; Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09-21">September 19-21, 2007. September 2008</date>
			<biblScope unit="volume">5152</biblScope>
			<biblScope unit="page" from="811" to="814" />
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="9,142.55,179.48,81.49,7.96;9,245.00,179.48,235.48,7.96;9,151.56,190.40,232.80,7.96;9,412.40,190.40,67.74,7.96;9,151.56,201.31,228.36,7.97" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="9,245.00,179.48,235.48,7.96;9,151.56,190.40,196.94,7.96">Cheshire at GeoCLEF 2008: Text and fusion approaches for GIR: CLEF working notes</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Larson</surname></persName>
		</author>
		<ptr target="http://www.clef-campaign.org/2008/workingnotes/larsonGeoCLEF.pdf" />
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.56,212.35,338.09,7.96;9,151.56,223.27,188.43,7.96" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,223.91,212.35,114.28,7.96">Logistic regression for ir4qa</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,363.25,212.35,117.40,7.95;9,151.56,223.27,37.85,7.95">Proceedings of the NTCIR-8 Workshop</title>
		<meeting>the NTCIR-8 Workshop<address><addrLine>Tokyo</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-06">June 2010. 2010</date>
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.56,234.19,337.85,7.96;9,151.56,245.23,329.11,7.96;9,151.56,256.16,329.00,7.95;9,151.56,267.08,238.61,7.96" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,287.67,234.19,192.74,7.96;9,151.56,245.23,194.19,7.96">Information access for a digital library: Cheshire II and the Berkeley environmental digital library</title>
		<author>
			<persName coords=""><forename type="first">Ray</forename><forename type="middle">R</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chad</forename><surname>Carson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,451.45,245.23,29.22,7.95;9,151.56,256.16,329.00,7.95;9,151.56,267.08,11.31,7.95">Knowledge: Creation, Organization and Use: Proceedings of the 62nd ASIS Annual Meeting</title>
		<editor>
			<persName><forename type="first">Larry</forename><surname>Woods</surname></persName>
		</editor>
		<meeting><address><addrLine>Medford, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Information Today</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="515" to="535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.57,278.00,337.88,7.96;9,151.56,289.04,328.83,7.96" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,302.38,278.00,140.55,7.96">Relevance weighting of search terms</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,450.01,278.00,30.44,7.95;9,151.56,289.04,193.56,7.95">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="page" from="129" to="146" />
			<date type="published" when="1976-06">May-June 1976</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
