<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,156.31,116.95,302.75,12.62;1,222.49,134.89,170.36,12.62;1,165.18,152.82,285.00,12.62;1,186.19,170.75,242.99,12.62">TELECOM ParisTech at ImageCLEF 2010 Photo Annotation Task: Combining Tags and Visual Features for Learning-Based Image Annotation</title>
				<funder ref="#_Z8RMAyN">
					<orgName type="full">French National Research Agency (ANR)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,227.94,208.42,60.05,8.74"><forename type="first">Hichem</forename><surname>Sahbi</surname></persName>
							<email>hichem.sahbi@telecom-paristech.fr</email>
						</author>
						<author>
							<persName coords="1,345.43,208.42,22.55,8.74"><forename type="first">Xi</forename><surname>Li</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">CNRS LTCI</orgName>
								<orgName type="laboratory" key="lab2">UMR 5141</orgName>
								<orgName type="institution">TELECOM ParisTech</orgName>
								<address>
									<addrLine>46, rue Barrault</addrLine>
									<postCode>75634</postCode>
									<settlement>Paris Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">NLPR</orgName>
								<orgName type="institution" key="instit2">CASIA</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,156.31,116.95,302.75,12.62;1,222.49,134.89,170.36,12.62;1,165.18,152.82,285.00,12.62;1,186.19,170.75,242.99,12.62">TELECOM ParisTech at ImageCLEF 2010 Photo Annotation Task: Combining Tags and Visual Features for Learning-Based Image Annotation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">43D55D2F503B06092C95C28CE5D9CBDE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe the participation of TELECOM ParisTech in the ImageCLEF 2010 Photo Annotation challenge. This edition focuses on promoting combination between visual and tag features in order to enhance photo annotation. An image collection is supplied with tags which are used both for training and testing. Our training approach consists of building SVM classifiers and kernels which take into account the similarity between visual features as well as tags. The results clearly corroborate (i) the complementarity of tags and visual descriptors and (ii) the effectiveness of SVM classifiers in photo annotation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent years have witnessed a rapid increase of image sharing spaces, such as Flickr, due to the spread of digital cameras and mobile devices. An urgent need is how to effectively search these huge amounts of data and how to exploit the structure of these sharing spaces. A possible solution is CBIR (Content-Based Image Retrieval); where images are represented using low-level visual features (color, texture, shape, etc.) and searched by analyzing and comparing those features. However, low-level visual features are usually unable to deliver satisfactory semantics, resulting in a gap between them and the high-level human interpretations. To address this problem, a variety of machine learning techniques were introduced in order to discover the intrinsic correspondence between visual features and semantics of images and allow to predict keywords for images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Conventionally, image annotation is converted into a classification problem. Existing state of the art methods (for instance <ref type="bibr" coords="1,324.67,657.11,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="1,336.84,657.11,7.75,8.74" target="#b1">2]</ref>) treat each keyword or concept as an independent class, and then train the corresponding concept-specific classifier to identify images belonging to that class, using a variety of machine learning techniques such as hidden Markov models <ref type="bibr" coords="2,336.11,143.90,9.96,8.74" target="#b1">[2]</ref>, latent Dirichlet allocation <ref type="bibr" coords="2,467.31,143.90,9.96,8.74" target="#b2">[3]</ref>, probabilistic latent semantic analysis <ref type="bibr" coords="2,299.91,155.86,9.96,8.74" target="#b3">[4]</ref>, and support vector machines <ref type="bibr" coords="2,446.63,155.86,9.96,8.74" target="#b4">[5]</ref>. The aforementioned annotation methods may also be categorized into two branches; region-based requiring a preliminary step of image segmentation <ref type="bibr" coords="2,431.86,179.77,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="2,444.04,179.77,11.62,8.74" target="#b11">12]</ref>, and holistic <ref type="bibr" coords="2,168.87,191.72,10.52,8.74" target="#b5">[6,</ref><ref type="bibr" coords="2,181.04,191.72,12.73,8.74" target="#b24">25]</ref> operating directly on the whole image space. In both cases, training is achieved in order to learn how to attach keywords with the corresponding visual features.</p><p>The above annotation methods heavily rely on their visual features for image annotation. Due to the semantic gap, they are unable to fully explore the semantic information inside images. Another class of annotation methods has emerged that takes advantage of extra information (tags, context, users' feedback, ontologies, etc.) in order to capture the correlations between images and concepts. A representative work is the cross-media relevance model (CMRM) <ref type="bibr" coords="2,429.59,316.82,10.52,8.74" target="#b5">[6,</ref><ref type="bibr" coords="2,441.77,316.82,7.01,8.74" target="#b8">9]</ref>, which learns joint statistics of visual and concepts and its variants <ref type="bibr" coords="2,406.39,328.78,10.52,8.74" target="#b6">[7,</ref><ref type="bibr" coords="2,418.57,328.78,7.01,8.74" target="#b7">8]</ref>. The model uses the keywords shared by similar images to annotate new ones. In <ref type="bibr" coords="2,444.68,340.73,14.61,8.74" target="#b21">[22]</ref>, the similarity measure between images integrates contextual information for concept propagation. Semi-supervised annotation techniques were also studied and usually rely on graph inference <ref type="bibr" coords="2,272.84,376.60,12.45,8.74" target="#b9">[10]</ref><ref type="bibr" coords="2,285.29,376.60,4.15,8.74" target="#b10">[11]</ref><ref type="bibr" coords="2,285.29,376.60,4.15,8.74" target="#b11">[12]</ref><ref type="bibr" coords="2,289.44,376.60,12.45,8.74" target="#b12">[13]</ref>. The original work, in <ref type="bibr" coords="2,405.02,376.60,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="2,417.19,376.60,11.62,8.74" target="#b25">26]</ref>, is inspired from machine translation and considers images and keywords as two different languages; in that case, image annotation is achieved by translating visual words into keywords.</p><p>Other existing annotation methods focus on how to define an effective distance measure for exploring the semantic relationships between concepts in large scale databases. In <ref type="bibr" coords="2,198.08,477.79,14.61,8.74" target="#b18">[19]</ref>, the Normalized Google similarity Distance (NGD) is proposed by exploring the textual information available on the web. It is a measure of semantic correlations derived from counts returned by Google's search engine for a given set of keywords. Following the idea of <ref type="bibr" coords="2,356.76,513.65,14.61,8.74" target="#b18">[19]</ref>, the Flickr distance <ref type="bibr" coords="2,465.09,513.65,15.50,8.74" target="#b19">[20]</ref> is proposed to precisely characterize the visual relationships between concepts. Each one is represented by a visual language model in order to capture its underlying visual characteristics. Then, a Flickr distance is defined, between two concepts, as the square root of Jensen-Shannon (JS) divergence between the corresponding visual language models. Other techniques consider extra knowledge derived from ontologies (such as the popular WordNet <ref type="bibr" coords="2,369.50,585.38,12.87,8.74" target="#b13">[14]</ref><ref type="bibr" coords="2,382.37,585.38,4.29,8.74" target="#b14">[15]</ref><ref type="bibr" coords="2,386.66,585.38,12.87,8.74" target="#b15">[16]</ref>) in order to enrich annotations <ref type="bibr" coords="2,189.08,597.34,14.61,8.74" target="#b20">[21]</ref>. The method in <ref type="bibr" coords="2,279.08,597.34,15.50,8.74" target="#b13">[14]</ref> introduces a visual vocabulary in order to improve translation model in the preprocessing stage of visual feature extraction. A directed acyclic graph is used to model the causal strength between concepts, and image annotation is performed by inference on this graph <ref type="bibr" coords="2,412.93,633.20,14.61,8.74" target="#b14">[15]</ref>. In <ref type="bibr" coords="2,447.93,633.20,15.50,8.74" target="#b16">[17,</ref><ref type="bibr" coords="2,465.09,633.20,11.62,8.74" target="#b17">18]</ref>, the semantic ontology information is integrated in the post processing stage in order to further refine initial annotations.</p><p>3 Motivation and The Proposed Method at a Glance Among the most successful annotation methods, those based on machine learning and mainly support vector machines; show a particular interest as they are performant and theoretically well grounded <ref type="bibr" coords="3,312.64,180.71,14.61,8.74" target="#b23">[24]</ref>. Support vector machines <ref type="bibr" coords="3,445.26,180.71,14.61,8.74" target="#b22">[23]</ref>, basically require the design of similarity measures, also referred to as kernels, which should provide high values when two images share similar structures/appearances and should be invariant, as much as possible, to the linear and non-linear transformations. They also satisfy positive definiteness which ensures, according to Vapnik's SVM theory <ref type="bibr" coords="3,237.69,240.49,14.61,8.74" target="#b23">[24]</ref>, optimal generalization performance and also the uniqueness of the SVM solution. In practice, kernels should not depend only on intrinsic aspects of images (as images with the same semantic may have different visual and textual features), but also on different sources of knowledge including context.</p><p>In this work, we introduce an image annotation framework based on a new similarity measure which takes high values not only when images share the same visual content but also the same context. The context of an image is defined as the set of images, with the same tags, and exhibiting better semantic descriptions, compared to both pure visual and tag based descriptions. The issue of combining context and visual content for image retrieval is not new (see for instance <ref type="bibr" coords="3,173.99,386.53,12.86,8.74" target="#b27">[28]</ref><ref type="bibr" coords="3,186.85,386.53,4.29,8.74" target="#b28">[29]</ref><ref type="bibr" coords="3,191.14,386.53,12.86,8.74" target="#b29">[30]</ref>) but the novel part of this work aims to (i) integrate context, in similarity design useful for classification and annotation, and (ii) plug this similarity in support vector machines in order to take benefit from their well established generalization power <ref type="bibr" coords="3,269.59,422.40,14.61,8.74" target="#b23">[24]</ref>. This type of similarity will be referred to as context-based while those relying only on the intrinsic visual or textual content will be referred to as context-free. Again, our proposed method goes beyond the naive use of low level features and context-free similarities (established as the standard baseline in image retrieval) in order to design a similarity applicable to annotation and suitable to integrate the "contextual" information taken from tagged datasets. In the proposed method, two images (even with different visual content and even sharing different tags) will be declared as similar if they share the same visual context<ref type="foot" coords="3,236.04,516.47,3.97,6.12" target="#foot_0">1</ref> . This is usually useful as tags in data may be noisy and misspelled. Furthermore, the intrinsic visual content of images might not always be relevant especially for categories exhibiting large variation of the underlying visual aspects.</p><p>Through this work, an image database is modeled as a graph where nodes are pictures and edges correspond to shared tags (links) between images. We design our similarity as the solution of a constrained energy function containing a fidelity term which measures visual similarity between images and a context criterion that captures the similarity between the underlying links.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">MIR Flickr/ImageCLEF Collection</head><p>We evaluated our annotation method on the MIR Flickr dataset containing 18, 000 images belonging to 93 categories (for instance "sky, clouds, water, sea, river,..."), among them 8, 000 are used for training and 10, 000 for testing. The whole dataset is annotated but ground truth is provided only for the training set. The MIR Flickr collection contains 1, 386 tags (provided by the Flickr users) which occur in at least 20 images, with an average total number of 8.94 tags per image (see Fig. <ref type="figure" coords="4,203.87,238.27,4.98,8.74" target="#fig_0">1</ref> and <ref type="bibr" coords="4,231.54,238.27,14.76,8.74" target="#b31">[32]</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Indexing and Annotation</head><p>Recent years have witnessed a great success of the bag-of-features representation in a wide range of application, such as image retrieval, image classification, image segmentation, object recognition, etc. Inspired by text classification, visual feature spaces are conventionally partitioned by vector quantization (e.g. kmeans) into several subspaces, each of which corresponds to a visual word. As a consequence, the bag-of-feature representation is converted to the bag-of-words (BoW). Since using a basic histogram of orderless visual words, the BoW representation only reflects the global statistical properties of visual words, and ignores their spatial layout. Therefore, the orderless BoW representation has a low descriptive capability of capturing the geometric relationships among visual words. Motivated by this, we use, in this evaluation campaign, the same approach as in <ref type="bibr" coords="4,158.44,585.38,15.50,8.74" target="#b26">[27]</ref> in order to better capture the spatial layout of images. The algorithm is based on a spatial pyramid representation, which constructs a multi-level spatial pyramid by block division. For any block at each level, a traditional BoW representation in the SIFT feature space is used. In this way, we have a set of block-specific BoW histograms at multiple levels. As a result, the geometric relationships among visual words can be effectively captured.</p><p>Given a test picture, the goal is to predict which categories (object classes) are present into that picture. This task is commonly known as concept detection. For this purpose, we trained "one-versus-all" SVM classifiers for each category; we repeat this training process through different folds (20 times), for each category, and we take the average score of the underlying SVM classifiers on the test picture. This makes classification results less sensitive to sampling and unbalanced classes. Performances are reported using the Mean Average Precision (MAP), the Equal Error Rate (EER) and the Area Under Curve (AUC). Higher MAP, AUC and lower EER imply better performance. Figs. <ref type="bibr" coords="5,402.65,215.63,11.62,8.74" target="#b1">(2,</ref><ref type="bibr" coords="5,417.90,215.63,7.75,8.74" target="#b2">3,</ref><ref type="bibr" coords="5,429.28,215.63,8.86,8.74" target="#b3">4)</ref> show the annotation results of our best ImageCLEF run through different classes.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We introduced in this work our participation in the ImageCLEF 2010 Photo Annotation Task. Our annotation method takes into account image features as well as their context links (taken from tags in the MIR Flickr collection) in order to achieve SVM learning and classification. Future extensions of this work include extra processing of these tags prior to SVM learning and further evaluations in the next campaigns.    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,134.77,370.59,345.82,7.89;4,134.77,381.55,158.20,7.89;4,140.84,271.00,333.79,84.82"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. This figure shows samples of images taken from the ImageCLEF 2010 Photo Annotation Task Database.</figDesc><graphic coords="4,140.84,271.00,333.79,84.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,177.81,479.51,259.74,7.89"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. This figure shows the average precision per class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="6,176.95,354.26,261.46,7.89"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. This figure shows the Equal Error Rate per class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="6,174.13,631.79,267.10,7.89"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. This figure shows the Area Under Curve per class.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.73,657.79,274.87,7.86"><p>Visual context is defined as the set of images sharing the same tags.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This work is supported by the <rs type="funder">French National Research Agency (ANR)</rs> under the <rs type="projectName">AVEIR</rs> project.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_Z8RMAyN">
					<orgName type="project" subtype="full">AVEIR</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,138.35,212.28,342.25,7.86;7,146.91,223.24,213.89,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,285.77,212.28,194.83,7.86;7,146.91,223.24,102.85,7.86">Formulating semantic image annotation as a supervised learning problem</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,272.47,223.24,58.43,7.86">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,236.55,342.24,7.86;7,146.91,247.51,277.34,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,247.07,236.55,233.52,7.86;7,146.91,247.51,74.71,7.86">Automatic linguistic indexing of pictures by a statistical modeling approach</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,233.46,247.51,92.65,7.86">IEEE Trans. on PAMI</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1075" to="1088" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,260.83,342.24,7.86;7,146.91,271.79,260.96,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,415.57,260.83,65.02,7.86;7,146.91,271.79,49.10,7.86">Matching words and pictures</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Barnard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Duygululu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,206.89,271.79,172.74,7.86">The Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,285.10,342.24,7.86;7,146.91,296.06,333.68,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,277.85,285.10,202.74,7.86;7,146.91,296.06,66.28,7.86">PLSA-based Image AutoAnnotation: Constraining the Latent Space</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Monay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gaticaperez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,234.92,296.06,217.66,7.86">Proc. of ACM International Conference on Multimedia</title>
		<meeting>of ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,309.37,342.24,7.86;7,146.91,320.33,333.68,7.86;7,146.91,331.29,88.75,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,301.54,309.37,179.05,7.86;7,146.91,320.33,256.95,7.86">Automatic Image Annotation by Incorporating Feature Hierarchy and Boosting to Scale up SVM Classifiers</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,424.50,320.33,56.09,7.86;7,146.91,331.29,58.81,7.86">Proc. of ACM MULTIMEDIA</title>
		<meeting>of ACM MULTIMEDIA</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,344.60,342.24,7.86;7,146.91,355.56,327.31,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,313.64,344.60,166.95,7.86;7,146.91,355.56,139.95,7.86">Automatic image annotation and retrieval using cross-media relevance models</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,309.47,355.56,83.69,7.86">Proc. of ACM SIGIR</title>
		<meeting>of ACM SIGIR</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="119" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,368.88,342.25,7.86;7,146.91,379.84,136.30,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,326.27,368.88,154.33,7.86;7,146.91,379.84,31.19,7.86">A model for learning the semantics of pictures</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jeon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,199.72,379.84,54.55,7.86">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,393.15,342.24,7.86;7,146.91,404.11,280.05,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,321.57,393.15,159.01,7.86;7,146.91,404.11,111.10,7.86">Multiple Bernoulli relevance models for image and video annotation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,280.29,404.11,55.96,7.86">Proc. of ICCV</title>
		<meeting>of ICCV</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1002" to="1009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,417.42,342.25,7.86;7,146.91,428.38,333.40,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,370.34,417.42,110.26,7.86;7,146.91,428.38,110.36,7.86">Dual cross-media relevance model for image annotation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,279.54,428.38,118.61,7.86">Proc. of ACM MULTIMEDIA</title>
		<meeting>of ACM MULTIMEDIA</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="605" to="614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,441.70,337.97,7.86;7,146.91,452.65,271.42,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,295.90,441.70,184.69,7.86;7,146.91,452.65,100.24,7.86">Manifold-ranking based topic-focused multidocument summarization</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,269.86,452.65,58.32,7.86">Proc. of IJCAI</title>
		<meeting>of IJCAI</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="2903" to="2908" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,465.97,337.98,7.86;7,146.91,476.93,138.57,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,413.58,465.97,67.01,7.86;7,146.91,476.93,37.14,7.86">Ranking on data manifolds</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sch√∂lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,202.00,476.93,54.55,7.86">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,490.24,337.97,7.86;7,146.91,501.20,169.75,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,325.07,490.24,147.63,7.86">Image annotation via graph learning</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,146.91,501.20,78.16,7.86">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="218C" to="228" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,514.51,337.98,7.86;7,146.91,525.47,333.68,7.86;7,146.91,536.43,160.40,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,336.29,514.51,144.30,7.86;7,146.91,525.47,94.45,7.86">An adaptive graph model for automatic image annotation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,263.63,525.47,216.96,7.86;7,146.91,536.43,85.91,7.86">Proc. of ACM International Workshop on Multimedia Information Retrieval</title>
		<meeting>of ACM International Workshop on Multimedia Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="61C" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,549.74,337.97,7.86;7,146.91,560.70,272.10,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,381.08,549.74,99.51,7.86;7,146.91,560.70,112.38,7.86">Exploiting ontologies for automatic image annotation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Srikanth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Varner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bowden</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Moldovan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,281.56,560.70,58.95,7.86">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="552" to="558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,574.02,337.98,7.86;7,146.91,584.98,255.12,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,314.42,574.02,166.17,7.86;7,146.91,584.98,32.42,7.86">Multimodal metadata fusion using causal strength</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">L</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,201.26,584.98,118.61,7.86">Proc. of ACM MULTIMEDIA</title>
		<meeting>of ACM MULTIMEDIA</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="872" to="881" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,598.29,337.97,7.86;7,146.91,609.25,35.83,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,208.41,598.29,153.46,7.86">Wordnet: a lexical database for English</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,372.28,598.29,59.59,7.86">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,622.56,337.98,7.86;7,146.91,633.52,328.41,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,341.56,622.56,139.04,7.86;7,146.91,633.52,106.32,7.86">Image annotation refinement using random walk with restarts</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,274.56,633.52,118.61,7.86">Proc. of ACM MULTIMEDIA</title>
		<meeting>of ACM MULTIMEDIA</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="647" to="650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,646.84,337.98,7.86;7,146.91,657.79,321.89,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="7,327.55,646.84,153.04,7.86;7,146.91,657.79,100.63,7.86">Image annotations by combining multiple evidence &amp; wordNet</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Awad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,270.59,657.79,118.60,7.86">Proc. of ACM MULTIMEDIA</title>
		<meeting>of ACM MULTIMEDIA</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="706" to="715" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,120.67,337.98,7.86;8,146.91,131.63,206.02,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="8,297.44,120.67,120.12,7.86">The google similarity distance</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cilibrasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">M B</forename><surname>Vitanyi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,428.72,120.67,51.88,7.86;8,146.91,131.63,177.77,7.86">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,144.88,337.98,7.86;8,146.91,155.84,88.76,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="8,336.46,144.88,58.91,7.86">Flickr distance</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,422.51,144.88,58.08,7.86;8,146.91,155.84,58.81,7.86">Proc. of ACM MULTIMEDIA</title>
		<meeting>of ACM MULTIMEDIA</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,169.09,337.98,7.86;8,146.91,180.05,111.89,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="8,253.07,169.09,207.37,7.86">Translating Topics to Words for Image Annotation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,146.91,180.05,82.22,7.86">Proc. of ACM CIKM</title>
		<meeting>of ACM CIKM</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,193.30,337.97,7.86;8,146.91,204.26,155.17,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="8,314.66,193.30,165.93,7.86;8,146.91,204.26,23.42,7.86">Context-Based Multi-Label Image Annotation</title>
		<author>
			<persName coords=""><forename type="first">Zhiwu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Horace</forename><forename type="middle">H S</forename><surname>Ip</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,191.97,204.26,80.80,7.86">Proc. of ACM CIVR</title>
		<meeting>of ACM CIVR</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,217.51,337.98,7.86;8,146.91,228.47,333.68,7.86;8,146.91,239.42,64.02,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="8,307.79,217.51,172.80,7.86;8,146.91,228.47,38.65,7.86">An training algorithm for optimal margin classifiers</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,214.29,228.47,261.89,7.86">Fifth Annual ACM Workshop on Computational Learning Theory</title>
		<meeting><address><addrLine>Pittsburgh</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,252.68,337.97,7.86;8,146.91,263.63,25.60,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="8,202.89,252.68,109.26,7.86">Statistical Learning Theory</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,339.62,252.68,132.95,7.86">A Wiley-Interscience Publication</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,276.88,337.97,7.86;8,146.91,287.84,185.09,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="8,312.44,276.88,168.15,7.86;8,146.91,287.84,70.12,7.86">Multi-Label Sparse Coding for Automatic Image Annotation</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,243.68,287.84,58.43,7.86">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,301.09,337.98,7.86;8,146.91,312.05,333.68,7.86;8,146.91,323.01,63.70,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="8,389.43,301.09,91.16,7.86;8,146.91,312.05,289.66,7.86">Object Recognition as Machine Translation: Learning a Lexicon for a Fixed Image Vocabulary</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Duygulu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Barnard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,459.65,312.05,20.94,7.86;8,146.91,323.01,33.87,7.86">Proc. of ECCV</title>
		<meeting>of ECCV</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,336.26,337.97,7.86;8,146.91,347.22,317.43,7.86" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="8,311.37,336.26,169.22,7.86;8,146.91,347.22,207.08,7.86">Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,376.02,347.22,58.43,7.86">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,360.47,337.98,7.86;8,146.91,371.43,323.10,7.86" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="8,420.37,360.47,60.22,7.86;8,146.91,371.43,167.22,7.86">Image Annotation Using Personal Calendars as Context</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">G</forename><surname>Neustaedter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,336.72,371.43,103.03,7.86">Proc. of ACM Multimedia</title>
		<meeting>of ACM Multimedia</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,384.68,337.97,7.86;8,146.91,395.64,327.94,7.86" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="8,286.83,384.68,193.76,7.86;8,146.91,395.64,171.42,7.86">Annotating Photo Collection by Label Propagation According to Multiple Similarity Cues</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,341.05,395.64,103.55,7.86">Proc. of ACM Multimedia</title>
		<meeting>of ACM Multimedia</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,408.89,337.98,7.86;8,146.91,419.85,333.68,7.86;8,146.91,430.81,144.56,7.86" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="8,428.58,408.89,52.01,7.86;8,146.91,419.85,324.93,7.86">ContextSeer: Context Search and Recommendation at Query Time for Shared Consumer Photos</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">H</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,157.67,430.81,103.55,7.86">Proc. of ACM Multimedia</title>
		<meeting>of ACM Multimedia</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,444.06,337.97,7.86;8,146.91,455.02,333.68,7.86;8,146.91,465.98,82.65,7.86" xml:id="b30">
	<monogr>
		<title level="m" type="main" coord="8,210.36,444.06,178.46,7.86">Convolution Kernels on Discrete Structures</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Haussler</surname></persName>
		</author>
		<idno>UCSC-CRL-99-10</idno>
		<imprint>
			<date type="published" when="1999-07">July, 1999</date>
		</imprint>
		<respStmt>
			<orgName>University of California in Santa Cruz, Computer Science Department</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="8,142.62,479.23,337.98,7.86;8,146.91,490.18,333.67,7.86;8,146.91,501.14,105.10,7.86" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="8,276.93,479.23,203.66,7.86;8,146.91,490.18,194.06,7.86">New Strategies for Image Annotation: Overview of the Photo Annotation Task at ImageCLEF 2010</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Huiskes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,363.18,490.18,117.40,7.86;8,146.91,501.14,17.31,7.86">The Working Notes of CLEF 2010</title>
		<meeting><address><addrLine>Padova, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
