<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,150.24,65.63,314.85,15.68;1,253.32,87.59,108.93,15.68">A Novel Structural-Description Approach For Image Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,231.96,111.52,69.34,8.97"><forename type="first">Christoph</forename><surname>Rasche</surname></persName>
							<email>rasche15@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Laboratorul de Analiza si Prelucrarea Imaginilor</orgName>
								<orgName type="institution">Universitatea Politehnica din</orgName>
								<address>
									<addrLine>Bucuresti</addrLine>
									<postCode>061071</postCode>
									<settlement>Bucuresti</settlement>
									<country>RO</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,308.76,111.52,74.59,8.97"><forename type="first">Constantin</forename><surname>Vertan</surname></persName>
							<email>cvertan@alpha.imag.pub.ro</email>
							<affiliation key="aff0">
								<orgName type="department">Laboratorul de Analiza si Prelucrarea Imaginilor</orgName>
								<orgName type="institution">Universitatea Politehnica din</orgName>
								<address>
									<addrLine>Bucuresti</addrLine>
									<postCode>061071</postCode>
									<settlement>Bucuresti</settlement>
									<country>RO</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,150.24,65.63,314.85,15.68;1,253.32,87.59,108.93,15.68">A Novel Structural-Description Approach For Image Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DD9C5CAFDA3B7C99324E89982194D65B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We tested our image classification methodology in the photo-annotation task of the ImageCLEF competition <ref type="bibr" coords="1,266.28,218.65,60.84,9.96" target="#b6">[Nowak, 2010]</ref> using a visual-only approach performing automated labeling. Our labeling process consisted of three phases: 1) feature extraction using color histogramming and using a novel method of structural description, that was exploited in a statistical manner only; 2) classification using Linear Discriminant (LD) or Average-Retrieval Rank (ARR) methods that provided the confidence (scalar) values, which were then thresholded to obtain the binary values; 3) eliminating labels (setting binary values to 0) on the testing set thereby exploiting the calculated joint-probabilities for pairs of concepts from the training set. The results show that our present system performs better on 'whole-image' labels than on object labels.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The main novelty of the presented approach is the use of a decomposition of structure as introduced in Rasche <ref type="bibr" coords="1,286.08,390.25,60.44,9.96">[Rasche, 2010]</ref>. The decomposition output is particularly suited to represent the geometry of contours and the geometry of their relations (pairs or clusters of contours), but it is applied here only in a statstical form for reason of simplicity <ref type="bibr" coords="1,303.12,426.13,60.44,9.96">[Rasche, 2011]</ref>, together with a color histogramming approach as described in Vertan et al. <ref type="bibr" coords="1,350.88,438.13,130.70,9.96" target="#b17">[Vertan and Boujemaa, 2000b]</ref>. This statistical classification has already been shown to be useful for video indexing <ref type="bibr" coords="1,166.56,462.01,88.02,9.96" target="#b5">[Ionescu et al., 2010]</ref>.</p><p>Looking at the provided photo annotations we realized that the spatial size of the annotated object or scene can vary substantially in reference to the image size: an annotation can describe either the image content as a whole and is thus suitable for (semantic) image classification, or it can describe a part of a scene (e.g isolated objects) and is thus rather suited for object-detection systems. A clear distinction between whole or part annotation is difficult of course, but is in our opinion desirable to better exploit the annotations, e.g. by providing a scalar value denoting the size of the object (1=whole image, 0.3=part/object covering ca. one third of the image). A typical recognition system is specialized for one process, either image classification or object detection. Our methodology is geared toward image classification and therefore is limitedly useful for 'part' annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Feature Extraction</head><p>Color and texture characterization The classical histogram image content description approach was further refined by the classification of the image pixels in several classes, according to a local attribute (such as the edge strength). We can easily imagine a classification in three classes, consisting of pixels characterized by a small, medium and high edge strength. The number of classes is thus related to the number of quantization level of the pixel attribute's. At the limit, since every pixel has acquired a supplementary, highly relevant characteristic, we can easily imagine a one pixel per class approach, which will certainly provide a very accurate description of the image, but will require a very important size.</p><p>In order to keep the balance between the histogram size and the discrimination between pixels we propose to adaptively weight the contribution of each pixel of the image into the color distribution <ref type="bibr" coords="2,323.64,242.05,130.82,9.96" target="#b17">[Vertan and Boujemaa, 2000b]</ref>. This individual weighting allows a finer distinction between pixels having the same color and the construction of a weighted histogram that accounts both color distribution and statistical non-uniformity measures. Thus, we will use a modified histogram, defined as:</p><formula xml:id="formula_0" coords="2,194.16,310.28,286.46,30.43">h(c) = 1 M N M-1 i=0 N -1 j=0 w(i, j)δ (f (i, j) -c) , ∀c ∈ C (1)</formula><p>In the equation above w(i, j) is the weighting coefficient of the color at spatial position (i, j). We may notice that, since w(i, j) must be a scalar, we cannot use any color statistics (which are necessarily vector triples).</p><p>Intuitively the accounting within the color distribution of some local measures of each pixel could be considered as a way of integrating both color and texture, provided that the local measure have a textural background. The Laplacianweighted histograms <ref type="bibr" coords="2,224.52,423.37,130.82,9.96" target="#b17">[Vertan and Boujemaa, 2000b]</ref>, <ref type="bibr" coords="2,362.04,423.37,131.88,9.96">[Vertan and Boujemaa, 2000a]</ref> are defined as:</p><formula xml:id="formula_1" coords="2,185.76,453.68,294.86,30.43">h(c) = M-1 i=0 N -1 j=0 δ (f (i, j) -c) 1 1 + ∆ 2 (i, j) , ∀c ∈ C, or<label>(2)</label></formula><formula xml:id="formula_2" coords="2,203.52,496.04,277.11,30.42">h(c) = M-1 i=0 N -1 j=0 δ (f (i, j) -c) ∆ 2 (i, j), ∀c ∈ C (3)</formula><p>The relation (2) emphasizes the weight of pixels that belong to constant (uniform) regions: their Laplacian is very small, so they sum with an unitary weight; the pixels placed on the edges are characterized by an important Laplacian and thus their contribution to the corresponding c bin is very small. This behavior is thought to reduce the influence of the uncertain colors, situated at the border between different objects and is derived from the gray-scale image case of choosing the segmentation thresholds as the minima of the histogram. The relation from (3) corresponds to a dual behavior, counting the colors proportionally to their edge strength.</p><p>Colors are uniformly quantized with 6 bins per RGB color component, yielding a 216 components feature vector per image.</p><p>Structure characterization Images were downsampled to a maximum size of 300 pixels for any side length (width or height) to decrease computation time. The structural processing started with contour extraction ( <ref type="bibr" coords="3,397.12,158.29,57.72,9.96">[Canny, 1986]</ref>) at 4 different scales (sigma=1,2,3 and 5). Contours were then partitioned and represented as described in <ref type="bibr" coords="3,235.32,182.17,57.26,9.96">(Rasche 2010</ref>) leading to 7 geometric and 5 appearance parameters for each contour segment (arc, 'wiggliness', curvature, circularity, edginess, symmetry, contrast, 'fuzziness'). Contour segments are then paired and clustered leading to another 58 parameters describing various distance measurements (between segments end and center points) and structural biases (degree of parallelism, T feature, L feature,...), see <ref type="bibr" coords="3,326.64,241.93,61.92,9.96">[Rasche, 2010]</ref> for details. For each parameter a 10-bin histogram is generated; the histograms are then concatenated to form a single vector of 700 dimensions. The average processing time for structural processing is ca. 40 seconds per image on a 2.6 GHz machine.</p><p>-Integration: The color and structural parameters are then concatenated to a single image vector with 916 dimensions (700 structural and 216 color parameters).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Classification</head><p>-LDA: A Linear Discriminant Analysis was applied to train a one-versus-all classifier for each of the 93 concepts (on the 8000 training images). This resulted in an average number of 24.9 labels per photo, more than twice as much as the average number of labels per training image (12.0). The posterior values of the classifier are provided as confidence values.</p><p>-ARR: The concepts for any test image are assigned based on a weighted average retrieval rank (ARR) of all training images retrieved following the query by example with the said test image. The binary concepts are obtained by a conceptadaptive threshold; the concept thresholds are computed based on the training image set annotations under the assumption that the test image database is statistically similar to the train image database.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Label Elimination</head><p>Because the LDA method (see above) returned a much larger proportion of labels for the testing set (24.9 labels/image) than for the training set (12.0), we attempted to reduce the number of labels by eliminating unlikely labels based on the joint-probabilities observed in the training set. Within the training set, we determined which pairs appeared as mutual exclusive (joint probability equal 0). If a testing image contained a pair of labels that are mutual exclusive in the training set, then the one label (of the pair) was eliminated that showed a lower posterior value (obtained from the LDA classifier) in reference to the entire distribution of posterior values for each concept. After label elimination, the average number of labels was lower by ca. 6 labels, see last column in table number 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Runs</head><p>All runs contained the same structural preprocessing, but differed in their choice of color processing; thus, each run was tested with 916 parameters. The runs differed also in the choice of the classifier method and whether label elimination was used.</p><p>Table <ref type="table" coords="4,164.64,226.13,4.11,8.03">1</ref>. Runs. Structure information was used in all runs. After the LDA (runs 3 to 5), the average number of labels in the testing set was 24.9 labels without label elimination. RGB: equation 1; Laplinv: equation 2; Lapl: equation 3. 3 Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Comparison of our runs</head><p>Runs 1 and 2 performed substantially better than the other three runs, for the MAP (Mean Average Precision; concept-based) and the F-ex measure (Fmeasure; example-based). For the OS-fcs (Ontology Score with Flickr Context Similarity costmap; example-based), runs 1 and 2 also performed better but not as distinctively as for the other two measures: Thus, ARR classification without label elimination outperforms LDA classification and label-elimination, but whether the performance difference is due to choice of classifer (LDA) or the attempt to eliminate labels can not be determined.</p><p>The detailed results per concept are shown in figure <ref type="figure" coords="5,386.64,116.17,3.90,9.96">1</ref>. Concepts with low average precision are skateboard, horse, cat, fish, etc. and tend to be objects, some of them likely part of the image only. Concepts with high precision are neutral illumination, no visual season, no blur, no persons etc. and tend to be whole-image annotations. This is what we roughly expected.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison to other groups</head><p>In comparison to other classification systems, our best results (of run no. 1) rank as 22nd out of 46 for the first two measures (MAP and F-ex) and 15th for the ontology-score measure (OS-fcs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>Although we applied our structural decomposition in statistical manner only and on down-scaled image resolutions, it achieved already a performance comparable to other approaches. We do not expect a much better performance if the full image resolution was employed; rather, the long-term improvement lies in exploiting the individual contours and their relations, for which a proper learning algorithm needs to be developed <ref type="bibr" coords="6,233.16,148.21,60.44,9.96">[Rasche, 2011]</ref>. The fact that image size is not crucial for the extraction of semantic meaning -at least not for a human observer -was well pointed out by Torralba and co-workers <ref type="bibr" coords="6,309.60,172.09,92.96,9.96" target="#b15">[Torralba et al., 2008]</ref>. A quick solution to improve the present performance of our system could be to merge it with one of the appearance-based methods <ref type="bibr" coords="6,283.56,196.09,86.87,9.96" target="#b13">[Shotton et al., 2008</ref><ref type="bibr" coords="6,370.43,196.09,80.13,9.96">,Heitz et al., 2009]</ref>. That label elimination did not lead to a significant improvement was unexpected, indeed it may have been even detrimental. But we still think that a proper exploitation of the joint probabilities can lead to a better performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,232.32,520.48,147.75,87.09"><head>Table 2 .</head><label>2</label><figDesc>Performance</figDesc><table coords="4,232.32,541.48,147.75,66.09"><row><cell cols="2">Run # MAP</cell><cell>F-ex</cell><cell>OS-fcs</cell></row><row><cell>1</cell><cell>0.259</cell><cell>0.531</cell><cell>0.562</cell></row><row><cell>2</cell><cell>0.258</cell><cell>0.529</cell><cell>0.562</cell></row><row><cell>3</cell><cell>0.206</cell><cell>0.408</cell><cell>0.513</cell></row><row><cell>4</cell><cell>0.182</cell><cell>0.366</cell><cell>0.487</cell></row><row><cell>5</cell><cell>0.201</cell><cell>0.414</cell><cell>0.520</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,139.12,278.92,49.92,8.97" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Canny</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,194.28,278.92,286.32,8.97;6,142.32,289.96,298.36,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,269.52,278.92,179.61,8.97">A computational approach to edge-detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,458.28,278.92,22.32,8.96;6,142.32,289.96,238.25,8.96">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="679" to="698" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.72,299.92,69.87,8.97" xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Heitz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,213.72,299.92,266.95,8.97;6,142.32,310.84,338.33,8.97;6,142.32,321.88,92.80,8.97" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,453.24,299.92,27.43,8.97;6,142.32,310.84,209.86,8.97">Shapebased object localization for descriptive classification</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Elidan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,359.28,310.84,121.37,8.96;6,142.32,321.88,48.73,8.96">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="40" to="62" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.82,331.84,78.54,8.97" xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Ionescu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,222.48,331.84,258.06,8.97;6,142.32,342.88,338.32,8.97;6,142.32,353.80,338.22,8.97;6,142.32,364.72,32.20,8.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,473.64,331.84,6.90,8.97;6,142.32,342.88,338.32,8.97;6,142.32,353.80,23.69,8.97">A contour-color-action approach to automatic classification of several common video genres</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Rasche</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Vertan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Lambert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,183.84,353.80,269.69,8.96">AMR 8th International Workshop on Adaptive Multimedia Retrieval</title>
		<meeting><address><addrLine>Linz, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,139.36,374.80,51.48,8.97" xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Nowak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,196.08,374.80,284.44,8.97;6,142.32,385.72,338.20,8.97;6,142.32,396.64,60.04,8.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,328.32,374.80,152.20,8.97;6,142.32,385.72,229.40,8.97">New strategies for image annotation: Overview of the photo annotation task at imageclef 2010</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Huiskes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,404.76,385.72,75.76,8.96;6,142.32,396.64,35.41,8.96">the Working Notes of CLEF</title>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.90,406.72,52.89,8.97" xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Rasche</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,197.04,406.72,283.58,8.97;6,142.32,417.64,316.24,8.97" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,277.68,406.72,202.94,8.97;6,142.32,417.64,86.49,8.97">An approach to the parameterization of structure for fast categorization</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Rasche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,237.12,417.64,168.13,8.96">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="337" to="356" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.90,427.60,52.89,8.97" xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Rasche</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,197.04,427.60,283.51,8.97;6,142.32,438.64,338.20,8.97;6,142.32,449.56,59.56,8.97" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,276.48,427.60,204.07,8.97;6,142.32,438.64,65.24,8.97">Contour groupings and their description for structural recognition</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Rasche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,215.16,438.64,265.36,8.96;6,142.32,449.56,55.04,8.97">IEEE Transactions on Pattern Analysis and Machine Intelligence, Under Review</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,139.04,459.64,79.99,8.97" xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Shotton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,224.28,459.64,256.27,8.97;6,142.32,470.56,338.05,8.97;6,142.32,481.48,210.52,8.97" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="6,417.60,459.64,62.95,8.97;6,142.32,470.56,206.45,8.97">Multi-scale categorical object recognition using contour fragments</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,358.20,470.56,122.17,8.96;6,142.32,481.48,136.73,8.96">IEEE Transactions of Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1270" to="1281" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.87,491.56,83.05,8.97" xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Torralba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,227.04,491.56,253.51,8.97;6,142.32,502.48,338.07,8.97;6,142.32,513.40,338.20,8.96;6,142.32,524.43,71.56,8.97" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="6,451.92,491.56,28.63,8.97;6,142.32,502.48,334.16,8.97">80 million tiny images: a large dataset for non-parametric object and scene recognition</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,142.32,513.40,312.16,8.96">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1958" to="1970" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,139.00,534.40,341.54,8.97;6,142.32,545.32,338.08,8.97;6,142.32,556.36,109.00,8.97" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="6,424.44,534.40,56.11,8.97;6,142.32,545.32,186.40,8.97">Spatially constrained color distributions for image indexing</title>
		<author>
			<persName coords=""><surname>Vertan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Boujemaa ; Vertan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,349.44,545.32,79.66,8.96">Proc. of CGIP 2000</title>
		<meeting>of CGIP 2000<address><addrLine>Saint Etienne, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000. 2000</date>
			<biblScope unit="page" from="261" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,139.00,566.31,341.48,8.97;6,142.32,577.36,338.08,8.97;6,142.32,588.28,338.19,8.97;6,142.32,599.19,268.72,8.97" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="6,416.40,566.31,64.08,8.97;6,142.32,577.36,201.24,8.97">Upgrading color distributions for image retrieval: Can we do better</title>
		<author>
			<persName coords=""><surname>Vertan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Boujemaa ; Vertan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,443.64,577.36,36.76,8.96;6,142.32,588.28,121.38,8.96">Advances in Visual Information Systems</title>
		<title level="s" coord="6,334.92,588.28,145.59,8.96;6,142.32,599.19,60.00,8.97">Lectures Notes in Computer Science LNCS, chapter</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Laurini</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1929">2000. 2000b. 1929</date>
			<biblScope unit="page" from="178" to="188" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
