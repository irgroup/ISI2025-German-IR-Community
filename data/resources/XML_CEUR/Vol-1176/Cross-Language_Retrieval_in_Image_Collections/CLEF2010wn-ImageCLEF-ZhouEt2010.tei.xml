<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,149.52,115.72,316.29,12.93;1,231.60,133.72,152.06,12.93">The participation of the MedGIFT Group in ImageCLEFmed 2010</title>
				<funder ref="#_2CzCSeV">
					<orgName type="full">SWITCH</orgName>
				</funder>
				<funder ref="#_UBaUDJr">
					<orgName type="full">European Union</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,213.96,171.19,41.41,9.62"><forename type="first">Xin</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Geneva University Hospitals</orgName>
								<orgName type="institution" key="instit2">University of Geneva</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,265.80,171.19,46.20,9.62"><forename type="first">Ivan</forename><surname>Eggel</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Applied Sciences Western Switzerland</orgName>
								<address>
									<settlement>Sierre</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,322.44,171.19,68.09,9.62"><forename type="first">Henning</forename><surname>Müller</surname></persName>
							<email>henning.mueller@hevs.ch</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Geneva University Hospitals</orgName>
								<orgName type="institution" key="instit2">University of Geneva</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Applied Sciences Western Switzerland</orgName>
								<address>
									<settlement>Sierre</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,149.52,115.72,316.29,12.93;1,231.60,133.72,152.06,12.93">The participation of the MedGIFT Group in ImageCLEFmed 2010</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A5923F3678A2826AB5C1B08F95A8D7A2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This article presents the participation of the MedGIFT group in ImageCLEFmed 2010. Since 2004, the group has participated in the medical image retrieval tasks of ImageCLEF (ImageCLEFmed) each year. The main goal is to provide a baseline by using the same technology each year, and to search for further improvement if possible. There are three types of tasks for ImageCLEFmed 2010: modality classification, image-based retrieval and case-based retrieval. The MedGIFT group participated in all three tasks. For ad-hoc retrieval and case-based retrieval tasks, two existing retrieval engines were used: the GNU Image Finding Tool (GIFT) for visual retrieval and Apache Lucene for text. Fusion strategies were also tried out to combine results from two engines. For the modality classification, a purely visual approach was used with GIFT for the visual retrieval and a kNN (k-Nearest Neighbors) classifier for the classification. Results show that the best textual run outperforms the best visual run by a factor of 30 in terms of mean average precision. Baselines provided by Apache Lucene and GIFT are ranked above the average among textual runs and visual runs respectively in ad-hoc retrieval. In the casebased retrieval task the Lucene baseline is the third best automatic run. For modality classification, GIFT and the kNN-based approach perform slightly better than the average of visual approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>ImageCLEF is the cross-language image retrieval track<ref type="foot" coords="1,375.72,522.22,3.97,4.84" target="#foot_0">1</ref> of the Cross Language Evaluation Forum (CLEF). ImageCLEFmed is part of ImageCLEF focusing on medical images <ref type="bibr" coords="1,206.16,547.27,10.56,9.62" target="#b0">[1,</ref><ref type="bibr" coords="1,218.28,547.27,7.04,9.62" target="#b1">2]</ref>. The MedGIFT<ref type="foot" coords="1,298.92,546.10,3.97,4.84" target="#foot_1">2</ref> research group has participated in Im-ageCLEFmed using the same technology as baselines since 2004, with additional modifications of the basic techniques. Visual and textual baseline runs have been made available to other participants of ImageCLEFmed. The visual baseline is based on GIFT <ref type="foot" coords="1,201.72,593.86,3.97,4.84" target="#foot_2">3</ref> (GNU Image Finding Tool, <ref type="bibr" coords="1,332.28,595.03,10.82,9.62" target="#b2">[3]</ref>) whereas Lucene<ref type="foot" coords="1,418.56,593.86,3.97,4.84" target="#foot_3">4</ref> was used for textual retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>This section describes the basic techniques used for retrieval in ImageCLEFmed2010.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Retrieval Tools Reused</head><p>Text Retrieval The text retrieval approach in 2010 is based on Lucene using standard settings. 4 textual runs were submitted, 2 for case-based retrieval and 2 for image-based retrieval. For case-and image-based retrieval, image and full text were used.</p><p>The full text approach used all texts as downloaded as HTML. Links, metadata, scripts and style information were removed and only the remaining text was indexed. For image captions, an XML file containing captions of all the images was indexed. No specific terminologies such as MeSH (Medical Subject Headings) were used.</p><p>Visual Retrieval GIFT is a visual retrieval engine based on color and texture information <ref type="bibr" coords="2,202.51,331.99,12.82,9.62" target="#b2">[3]</ref>. Colors are compared in a color histogram. Texture information is described by applying Gabor filters and quantizing the responses into 10 strengths. The image is rescaled to 256x256 and partitioned into fixed regions to extract features for both global and local levels. GIFT uses a standard tf/idf strategy for feature weighting. It also allows image-based queries with multiple input images.</p><p>GIFT has been used for the ImageCLEFmed tasks since 2004. Each year the default setting has been used to provide a baseline. For classification, GIFT has been used to produce the distance (similarity) value followed by a nearest neighbor (kNN) classification.</p><p>Fusion Techniques In 2009, the ImageCLEF@ICPR fusion task was organized to compare fusion techniques using the best ImageCLEFmed visual and textual results <ref type="bibr" coords="2,166.56,493.99,9.99,9.62">[4]</ref>. Studies such as <ref type="bibr" coords="2,256.56,493.99,10.56,9.62" target="#b4">[5]</ref> show that combSUM (1) and combMNZ(2) proposed by <ref type="bibr" coords="2,175.92,505.87,10.56,9.62" target="#b5">[6]</ref> in 1994 are robust fusion strategies. With the data from the Image-CLEF@ICPR fusion task, combMNZ performed slightly better than combSUM, the difference was small and not statistically significant.</p><formula xml:id="formula_0" coords="2,256.44,551.08,224.19,30.79">S combSUM (i) = N k k=1 S k (i)<label>(1)</label></formula><formula xml:id="formula_1" coords="2,236.16,593.23,244.47,11.22">S combMNZ (i) = F (i) * S combSUM (i)<label>(2)</label></formula><p>where F (i) is the freqence of image i being returned by one input system with a non-zero score, and S(i) is the score assigned to image i. In ImageCLEFmed2010, the fusion approach was used in two cases:</p><p>fusing textual and visual runs to produce mixed runs (combMNZ was used);</p><p>fusing various images which belong to the same case (only for the case-based retrieval task, combSUM was used).</p><p>For case-based fusion, the frequency for one case is highly related to the number of images in this case. It is not optimal to include the frequency information, thus combSUM was used.</p><p>Score Normalization Techniques Studies performed by MedGIFT show that using a logarithmic function based on a rank number for score normalization was a stable solution for fusion <ref type="bibr" coords="3,253.92,226.15,9.99,9.62" target="#b4">[5]</ref>. The following formula was used:</p><formula xml:id="formula_2" coords="3,247.80,246.79,232.83,10.00">S ln (R) = ln N images -ln R,<label>(3)</label></formula><p>where R is the rank given by the input system, and S is the normalized similarity score. As a large performance difference exists between textual runs and visual runs, textual runs are weighted by a factor of 0.8 whereas visual runs are weighted by 0.2. In ImageCLEFmed 2010, this score normalization strategy was applied for all fusions as well as for k-NN classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Image Collection</head><p>77'506 medical images were available for ImageCLEFmed 2010. Among them, 2'390 images with modality labels were used as training data, another 2'620 images are selected as test data for the modality classification task. Details about the setup and collections of the ImageCLEFmed tasks can be found in overview paper <ref type="bibr" coords="3,203.76,410.83,9.99,9.62" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>This section describes our results for the three medical tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Modality Classification</head><p>Table <ref type="table" coords="3,163.44,512.35,4.98,9.62" target="#tab_0">1</ref> shows the number of images for each modality in the training data.</p><p>Even it was mentioned in the README file describing the data that there can be considerable intra-class heterogeneity (the PX class can contain microscopic images as well as photographs, PET can contain PET and PET/CT and XR can contain DXR and X-ray angiography), without precise labels. Manually dividing one class into sub-classes can generate errors rather than resulting in a gain.</p><p>The training data was separated by us into two parts: balanced classes and a set of remaining images. 200 images were selected randomly for each class, which created a set of 1'600 images. The remaining 790 images were used for kNN parameter tuning. Figure <ref type="figure" coords="3,268.32,619.87,4.98,9.62" target="#fig_0">1</ref> shows the performance related to the parameter k. Performance evaluation was based on the percentage of correctly classified images. The best performance with the training data was achieved by 5NN, which was then applied on the test data.  One run was submitted to the modality classification task. A binary classifier was used for the classification. For runs of various natures (textual, visual, mixed), the best accuracy and average accuracy are shown in Table <ref type="table" coords="5,446.52,142.63,3.90,9.62" target="#tab_1">2</ref>. Even with default settings of GIFT and a very simple kNN classification approach, the baseline run is above the average accuracy (59%) of all visual runs. Results also show that visual runs can achieve similar performance to textual runs in accuracy, which explains the high performance of mixed runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Image-based Retrieval</head><p>For the image-based retrieval task, 9 groups submitted 36 textual retrieval runs, 4 groups submitted 9 visual runs and 6 groups submitted 16 mixed runs combining textual and visual information. In total 5 runs were submitted by the MedGIFT group. In addition to the three baselines (1 visual baseline and 2 textual baselines), 2 mixed runs were produced using the combMNZ approach.</p><p>Results are shown in Table <ref type="table" coords="5,254.16,434.95,3.90,9.62" target="#tab_2">3</ref>. Mean average precision (MAP), binary preference (Bpref), and early precision (P10, P30) are shown as measures. In terms of mean average precision(MAP), the best textual run (0.338) outperforms the best visual run (0.0091) by a factor of 30, which shows a big performance gap between the two approaches. The average score of all textual runs is 0.253, whereas the average score of all visual retrieval runs is 0.0020. The performance of the baselines produced by Apache Lucene based on image caption information (HES-SO-VS CAPTIONS) and GIFT (MedGIFT GIFT8) are slightly above the averages. Performance of mixed runs depends largely on the fusion strategies: reordering a textual run obtains close or better performance compared with the original run, whereas merging textual runs with visual runs reduces the performance of a textual run. Two mixed runs submitted from MedGIFT are based on a merging approach and are punished by the large performance gap between textual and visual runs.</p><p>Case-Based Retrieval For the case-based retrieval task, one visual run, 43 textual runs and 4 mixed runs from 9 groups were submitted. The MedGIFT group submitted one visual run, two textual runs and two mixed runs. The visual and textual runs were obtained by processing a case-based fusion of all images of a case using the combSUM strategy. Based on visual and textual runs, mixed runs were produced by using the combMNZ strategy. Results are shown in Table <ref type="table" coords="6,173.52,326.83,3.90,9.62" target="#tab_3">4</ref>. Best performance in terms of MAP (0.3551) was obtained by purely textual retrieval. The Lucene baseline (HES-SO-VS FULLTEXT) is the third best run among all automatic runs. The GIFT baseline (MedGIFT GIFT8) is the only visual run and is ranked below all textual runs. All mixed runs are ranked below the GIFT baseline, showing that the fusion strategy was not optimal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Conclusions</head><p>Comparing the ad-hoc retrieval task in ImageCLEFmed2009 and ImageCLEFmed2010, the number of relevant documents per topic decreased by 50% (94.48 in 2009 and 62.44 in 2010), which can partly explain the general decrease of performance observed. However, in 2009, the Lucune baseline using fulltext (HES-SO-VS FULLTEXT) was ranked above the average, and the GIFT baseline (MedGIFT GIFT8) was the best run among all purely visual runs. In 2010, both baselines are ranked slightly lower, which shows that the average performance of systems improved.</p><p>Comparison of the case-based retrieval tasks in 2009 and 2010 show a different picture. The Lucene baseline performed slightly better than the average in 2009, but is the third best run in 2010. As only 4 case-based topics were available in 2009, the results might not be representative, and the task in 2010 was definitely at a larger scale.</p><p>Both in 2009 and 2010 the performance gap between textual and visual runs is larger in image-based retrieval than in case-based retrieval. This can be explained by the fact that textual runs for both image-based and case-based topics use case information, whereas the visual approach only uses case information in case-based topics. In other words, including case information in image-based retrieval could be able to improve the performance of visual runs.</p><p>Relevance is judged based on domain knowledge, which is often case-based rather than image-based. Case-based retrieval thus seems to be more coherent. So far the visual runs for case-based topics were produced by image-based approaches plus fusion, which is not optimal. Key words extracted from fulltext articles about one case directly are a good case descriptor, whereas robust case descriptors are needed for the visual approach.</p><p>Another important aspects that went wrong in our approach is the fusion of textual and visual results that actually decreased instead of increased the results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,185.52,624.90,244.12,8.66"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The performance obtained by the kNN classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,136.20,145.50,380.88,467.31"><head>Table 1 .</head><label>1</label><figDesc>Number of images for each modality in the training data.</figDesc><table coords="4,136.20,175.02,380.88,108.14"><row><cell>Label</cell><cell>Modality</cell><cell>Number</cell></row><row><cell>GX</cell><cell>Graphics, typically drawing and graphs</cell><cell>355</cell></row><row><cell>PX</cell><cell cols="2">optical imaging including photographs, micrographs, gross pathology etc 330</cell></row><row><cell>CT</cell><cell>Computerized tomography</cell><cell>314</cell></row><row><cell>US</cell><cell>Ultrasound including (color) Doppler</cell><cell>307</cell></row><row><cell>MR</cell><cell>Magnetic resonance imaging</cell><cell>299</cell></row><row><cell>XR</cell><cell>X-ray including X-ray angiography</cell><cell>296</cell></row><row><cell>PET</cell><cell>Positron emission tomography including PET/CT</cell><cell>285</cell></row><row><cell>NM</cell><cell>Nuclear Medicine</cell><cell>204</cell></row><row><cell>total</cell><cell></cell><cell>2390</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,177.00,175.38,261.39,73.58"><head>Table 2 .</head><label>2</label><figDesc>Results of the runs for the modality classification task.</figDesc><table coords="5,218.52,195.78,178.26,53.18"><row><cell>run ID</cell><cell cols="2">best accuracy average accuracy</cell></row><row><cell>mixed run</cell><cell>0.94</cell><cell>0.9</cell></row><row><cell>textual run</cell><cell>0.9</cell><cell>0.59</cell></row><row><cell>visual run</cell><cell>0.87</cell><cell>0.59</cell></row><row><cell>GIFT8 5NN</cell><cell>0.68</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,136.20,479.58,369.10,127.22"><head>Table 3 .</head><label>3</label><figDesc>Results of the runs for the image-based topics.</figDesc><table coords="5,136.20,509.22,369.10,97.58"><row><cell>Run</cell><cell cols="2">run type MAP Bpref P10 P30 num rel ret</cell></row><row><cell>best textual run (XRCE)</cell><cell>Textual 0.338 0.3828 0.5062 0.3062</cell><cell>667</cell></row><row><cell>HES-SO-VS CAPTIONS</cell><cell>Textual 0.2568 0.278 0.35 0.2917</cell><cell>657</cell></row><row><cell>HES-SO-VS FULLTEXT</cell><cell>Textual 0.1312 0.1684 0.1813 0.1792</cell><cell>658</cell></row><row><cell>best visual run (ITI)</cell><cell>Visual 0.0091 0.0179 0.0125 0.0125</cell><cell>66</cell></row><row><cell>MedGIFT GIFT8</cell><cell>Visual 0.0023 0.006 0.0125 0.0042</cell><cell>52</cell></row><row><cell>best mixed run (XRCE)</cell><cell>Mixed 0.3572 0.3841 0.4375 0.325</cell><cell>762</cell></row><row><cell>MedGIFT FUSION VIS CAPTIONS</cell><cell>Mixed 0.0208 0.0753 0.0375 0.0540</cell><cell>340</cell></row><row><cell>MedGIFT FUSION VIS FULLTEXT</cell><cell>Mixed 0.0245 0.0718 0.0375 0.0479</cell><cell>346</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,148.08,358.38,319.30,118.22"><head>Table 4 .</head><label>4</label><figDesc>Results of the runs for the case-based retrieval topics.</figDesc><table coords="6,148.08,378.78,319.30,97.82"><row><cell>Run</cell><cell cols="2">run type MAP Bpref P10 P30 num rel ret</cell></row><row><cell cols="2">best manual run (UIUCIBM) Manual 0.3551 0.3714 0.4714 0.3857</cell><cell>449</cell></row><row><cell cols="2">best textual run (UIUCIBM) Textual 0.2902 0.3049 0.4429 0.3524</cell><cell>441</cell></row><row><cell>HES-SO-VS CAPTIONS</cell><cell>Textual 0.1273 0.1375 0.25 0.2024</cell><cell>342</cell></row><row><cell>HES-SO-VS FULLTEXT</cell><cell>Textual 0.2796 0.2699 0.4214 0.3452</cell><cell>470</cell></row><row><cell>MedGIFT GIFT8</cell><cell>Visual 0.0358 0.0612 0.0929 0.0786</cell><cell>215</cell></row><row><cell>best mixed run (ITI)</cell><cell>Mixed 0.0353 0.0509 0.0429 0.0714</cell><cell>316</cell></row><row><cell>MedGIFT VIS CAPTIONS</cell><cell>Mixed 0.0143 0.0657 0.0357 0.019</cell><cell>301</cell></row><row><cell>MedGIFT VIS FULLTEXT</cell><cell>Mixed 0.0115 0.0786 0.0357 0.0167</cell><cell>274</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.72,624.42,117.03,7.62"><p>http://www.imageclef.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,144.72,635.46,149.91,7.62"><p>http://www.sim.hcuge.ch/medgift/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="1,144.72,646.38,154.59,7.62"><p>http://www.gnu.org/software/gift/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="1,144.72,657.30,117.03,7.62"><p>http://lucene.apache.org/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="4">Acknowledgments</head><p>This work was partially supported by <rs type="funder">SWITCH</rs> in the context of the <rs type="projectName">medLTPC</rs> project and the <rs type="funder">European Union</rs> in the context of the <rs type="projectName">Khresmoi project</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_2CzCSeV">
					<orgName type="project" subtype="full">medLTPC</orgName>
				</org>
				<org type="funded-project" xml:id="_UBaUDJr">
					<orgName type="project" subtype="full">Khresmoi project</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,138.32,492.30,342.20,8.66;7,146.88,503.22,333.67,8.66;7,146.88,514.14,333.74,8.66;7,146.88,525.18,106.24,8.66" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,196.56,503.22,215.79,8.66">The CLEF 2005 cross-language image retrieval track</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,436.32,503.22,44.23,8.66;7,146.88,514.14,128.05,8.66">Cross Language Evaluation Forum (CLEF</title>
		<title level="s" coord="7,304.32,514.14,176.30,8.66">Springer Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2005-09">2005. September 2006</date>
			<biblScope unit="page" from="535" to="557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.32,536.10,342.20,8.66;7,146.88,547.02,333.51,8.66;7,146.88,557.94,333.67,8.66;7,146.88,568.86,333.74,8.66;7,146.88,579.90,295.00,8.66" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,309.84,536.10,170.68,8.66;7,146.88,547.02,101.60,8.66">The CLEF cross-language image retrieval track (ImageCLEF) 2004</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,265.80,557.94,214.75,8.66;7,146.88,568.86,225.42,8.66">Multilingual Information Access for Text, Speech and Images: Result of the fifth CLEF evaluation campaign</title>
		<title level="s" coord="7,450.24,568.86,30.38,8.66;7,146.88,579.90,135.41,8.66">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Magnini</surname></persName>
		</editor>
		<meeting><address><addrLine>Bath, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="597" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.32,590.82,342.18,8.66;7,146.88,601.74,333.67,8.66;7,146.88,612.66,333.52,8.66;7,146.88,623.70,85.60,8.66" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,353.88,590.82,126.62,8.66;7,146.88,601.74,170.00,8.66">Content-based query of image databases: inspirations from text retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Pun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,448.27,601.74,32.28,8.66;7,146.88,612.66,303.46,8.66">Selected Papers from The 11th Scandinavian Conference on Image Analysis SCIA &apos;99)</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1193" to="1198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,236.04,623.70,127.47,8.66;7,134.76,634.62,345.84,8.66;7,146.88,645.54,333.55,8.66;7,146.88,656.46,333.74,8.66;8,146.88,119.34,333.67,8.66;8,146.88,130.38,22.60,8.66" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,288.72,634.62,191.88,8.66;7,146.88,645.54,276.73,8.66">The ImageCLEF medical retrieval task at icpr 2010 -information fusion to combine viusal and textual information</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">K</forename><surname>Ersboll</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eds</forename><forename type="middle">4</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,445.32,645.54,35.11,8.66;7,146.88,656.46,295.97,8.66">Proceedings of the International Conference on Pattern Recognition (ICPR 2010)</title>
		<title level="s" coord="7,450.24,656.46,30.38,8.66;8,146.88,119.34,139.77,8.66">Lecture Notes in Computer Science (LNCS</title>
		<meeting>the International Conference on Pattern Recognition (ICPR 2010)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010-08">August 2010</date>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct coords="8,138.32,141.30,342.23,8.66;8,146.88,152.22,333.63,8.66;8,146.88,163.26,211.78,8.66" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,304.56,141.30,175.99,8.66;8,146.88,152.22,90.68,8.66">Information fusion for combining visual and textual image retrieval</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Depeursinge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,260.28,152.22,198.86,8.66">Pattern Recognition, International Conference on</title>
		<meeting><address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.32,174.18,342.23,8.66;8,146.88,185.10,94.24,8.66" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,242.04,174.18,133.18,8.66">Combination of multiple searches</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,397.92,174.18,82.63,8.66;8,146.88,185.10,26.60,8.66">Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="243" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.32,196.14,342.20,8.66;8,146.88,207.06,333.66,8.66;8,146.88,217.98,179.62,8.66" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,146.88,207.06,237.39,8.66">Overview of the CLEF 2010 medical image retrieval track</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Eggel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Kahn</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,408.84,207.06,71.70,8.66;8,146.88,217.98,44.48,8.66">Working Notes of CLEF 2010</title>
		<meeting><address><addrLine>Padova, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-09">September 2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
