<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,164.08,133.89,287.20,12.62;1,242.04,151.82,125.05,12.62">Participation at ImageCLEF 2010 Photo Annotation Track</title>
				<funder ref="#_rAHK3kK">
					<orgName type="full">Ministry of Science and Higher Education Republic of Poland</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,195.10,189.43,60.40,8.80"><forename type="first">Michal</forename><surname>Stanek</surname></persName>
							<email>michal.stanek@pwr.wroc.pl</email>
						</author>
						<author>
							<persName coords="1,263.46,189.43,51.90,8.80"><forename type="first">Oskar</forename><surname>Maier</surname></persName>
							<email>oskar.maier@student.pwr.wroc.pl</email>
						</author>
						<author>
							<persName coords="1,342.71,189.43,77.54,8.80"><forename type="first">Halina</forename><surname>Kwasnicka</surname></persName>
							<email>halina.kwasnicka@pwr.wroc.pl</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">The Wroclaw University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Institute of Informatics</orgName>
								<orgName type="institution">Wrocław University of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,164.08,133.89,287.20,12.62;1,242.04,151.82,125.05,12.62">Participation at ImageCLEF 2010 Photo Annotation Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">581F5E946FB712007EB8B0BD853F5875</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we present three methods for image autoannotation used by the Wroclaw University of Technology group at Im-ageCLEF 2010 Photo Annotation track. All of our experiments focus on robustness of the global color and texture image features in connection with different similarity measures. To annotate training set we use two version of PATSI algorithm which searches for the most similar images and transferring annotations from them to the target image by applying transfer function. We use both the simple version of the algorithm working only on single similarity matrix, as well as multi-PATSI which uses many similarity measures in order to obtain the final annotations. As third approach to image auto-annotation we use Penalized Discriminant Analysis to train multi class classifier in One-vs-All manner. During training and optimization process of all annotators we use F-measure as evaluation measure trying to achieve its highest value on a training set. Obtained results indicate that our approach achieved a high quality measure only for a small group of terms and it is necessary to take into account also local image characteristics.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, Makadia et. al. <ref type="bibr" coords="1,251.62,496.43,10.52,8.80" target="#b0">[1]</ref> proposed a family of image annotation baseline methods that are build on the hypothesis that visually similar images are likely to share the same annotations. They treat image annotation as a process of transferring labels from nearest neighbours. Makadia's method does not solve the fundamental problem of determining the number of annotations that should be assigned to the target image. Thus they assume a constant number of annotations per image. The transfer is performed in two steps: all annotations from the most similar image are rewritten and the most frequent words are chosen from the whole neighbourhood until a given annotation length has been achieved.</p><p>We extend Makadia's approach by constructing PATSI (Photo Annotation through Similar Images) annotator which introduce transfer function <ref type="bibr" coords="1,437.84,615.98,10.52,8.80" target="#b1">[2]</ref> as well as optimization algorithm which can be used to find optimal number of neighbours and the best transfer threshold according to the specified quality measure <ref type="bibr" coords="2,155.57,142.84,9.96,8.80" target="#b2">[3]</ref>. During our experiments with different similarity metrics we extend this algorithm to multi-PATSI which perform annotation transfer process based onto many similarity matrices calculated using different feature sets and similarity measures and combine results into final annotation based on the quality of each annotator for specific words.</p><p>At ImageCLEF 2010 photo annotation track <ref type="bibr" coords="2,357.96,202.68,10.52,8.80" target="#b3">[4]</ref> we evaluate PATSI and multi-PATSI approach with global image features. During experiments we use grid segmentation and statistical color informations as well as features extracted using LIRE package <ref type="bibr" coords="2,227.14,238.55,9.96,8.80" target="#b4">[5]</ref>. As third type of automatic image annotator we train PDA <ref type="bibr" coords="2,159.67,250.50,10.52,8.80" target="#b5">[6,</ref><ref type="bibr" coords="2,173.50,250.50,7.75,8.80" target="#b6">7]</ref> classifier onto CEDD <ref type="bibr" coords="2,279.48,250.50,10.52,8.80" target="#b7">[8]</ref> and Jpeg Coefficient Histogram <ref type="bibr" coords="2,434.10,250.50,10.52,8.80" target="#b8">[9]</ref> in Onevs-All manner.</p><p>This paper is organized as follows. In the next section we describe used automatic image annotation methods with explanation of used features, distance measures and details of annotation algorithm. The third section describes the experiments and achieved results. The paper is finished with conclusions and remarks on possible further improvements of the method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Annotation process</head><p>In this section we describe automatic image annotation methods used during ImageCLEF 2010 Photo Annotation track <ref type="bibr" coords="2,326.46,390.64,10.52,8.80" target="#b3">[4]</ref> by our team. First we focus on types of visual features extracted from images and similarity measures used to build similarity matrices then we describe the annotation transfer process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Visual Features</head><p>The image I in a training dataset D is represented by a n-dimensional vector of visual features</p><formula xml:id="formula_0" coords="2,134.77,475.40,345.83,25.43">v I = (v I 1 , • • • , v I n ). All visual features are a m-dimensional vector of low level attributes v I i = (x i,I 1 , • • • , x i,I m ).</formula><p>The visual features must be extracted from the image and can represent information about color and texture for the entire image, or only selected area of the image I.</p><p>For all images in both training and tasting dataset we performed visual feature extraction using self made feature extractor and the image descriptors contained in the LIRE package <ref type="bibr" coords="2,260.26,549.79,9.96,8.80" target="#b4">[5]</ref>. We focused mainly on global image characteristics, but we use also more local information obtained after splitting image by rectangular 5-by-5 and 20-by-20 grid. The list of extracted features include:</p><p>1. From MPEG-7 standard <ref type="bibr" coords="2,268.32,595.92,10.52,8.80" target="#b8">[9]</ref>  x and y coordinates of the segment center -2 dimensions, -the mean value of color in each channel of the color space -3 dimensions, -standard deviations of color changes in each channel for a given color space -3 dimensions, -mean eigenvalues of color Hessian in each channel for a given color space -3 dimensions. 6. CoOccurance Matrix <ref type="bibr" coords="3,260.75,330.47,15.50,8.80" target="#b14">[15]</ref> calculated for each segment of 5-by-5 and 20by-20 segmentation -21 dimensions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Distance Metrics</head><p>To obtain the similarity or rather dissimilarity between two images, we measure the distance between vectors in metric space and divergence between distributions build onto visual vectors. In our experiments we use distance measures described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Minkowski distance</head><p>The Minkowski distance is widely used for measuring similarity between objects (e.g., images). The Minkowski metric between image A and B is defined as:</p><formula xml:id="formula_1" coords="3,232.26,509.04,248.33,32.84">d MK (A, B) = n i=1 v A i -v B i p 1/p<label>(1)</label></formula><p>where p is the Minkowski factor for the norm. Particularly, when p is equal one and two, it is the well known L1 and Euclidean distance respectively.</p><p>Cosine distance is a measure of similarity between two vectors of n dimensions by finding the cosine of the angle between them, often used to compare documents in text mining</p><formula xml:id="formula_2" coords="3,244.66,637.98,231.69,26.29">d Cos (A, B) = 1 -(v A )(v B ) T v A 2 v B 2 . (<label>2</label></formula><formula xml:id="formula_3" coords="3,476.35,646.24,4.24,8.80">)</formula><p>Manhattan distance also called cityblock distance or the taxicab metric is the metric of the Euclidean plane defined by:</p><formula xml:id="formula_4" coords="4,245.15,153.18,235.44,21.98">d Manh (A, B) = i (v A i -v B i )<label>(3)</label></formula><p>Correlation distance measures the similarity in shape between vectors defined by</p><formula xml:id="formula_5" coords="4,217.69,219.31,262.91,30.61">d Corr (u, v) = 1 -(v A -vA )(v B -vB ) T (v A -vA ) 2 (v B -vB ) T 2 ,<label>(4)</label></formula><p>where (u -ū) 2 is L2 distance between vector u and mean vector ū.</p><p>Jensen-Shannon Divergence Based on the visual feature vectors v I one can build a model M I for the image I. We can assume that M I is a multidimensional random variable described by multi-variate normal distribution and all vectors v I i are realizations of this model. The probability density function (PDF) for the model M I is defined as:</p><formula xml:id="formula_6" coords="4,174.68,360.23,305.91,22.49">M I (x, µ, Σ) = 1 (2π) N/2 |Σ| 1/2 exp - 1 2 (x -µ) Σ -1 (x -µ)<label>(5)</label></formula><p>where x is the observation vector, µ the mean vector, and Σ the covariance matrix. Both µ and Σ are parameters of the model calculated using Expectation-Maximization -algorithm <ref type="bibr" coords="4,244.75,416.04,15.50,8.80" target="#b15">[16]</ref> on all visual features</p><formula xml:id="formula_7" coords="4,352.61,414.53,50.63,12.20">[v I 1 , • • • , v I n ]</formula><p>of the image I. In order to avoid problems of inverting covariance matrix (avoid matrix singularity) one may perform regularization of the covariance matrix. Models of images are build for all images in the training set, as well as for the query image.</p><p>Distance between the models can be computed as Jensen-Shannon divergence, which is a symmetrized version of Kullback-Leibler divergence:</p><formula xml:id="formula_8" coords="4,198.81,497.60,281.79,22.31">d JS (A, B) = 1 2 D KL (M A M B ) + 1 2 D KL (M B M A ),<label>(6)</label></formula><p>where M A , M B are models (PDF) for the images A and B, and D KL is the Kullback-Leibler distance which for multivariate-normal distribution takes the form:</p><formula xml:id="formula_9" coords="4,189.41,584.36,291.18,49.31">D KL (M A M B ) = 1 2 log e det Σ B det Σ A + 1 2 tr Σ -1 B Σ A + 1 2 (µ B -µ A ) Σ -1 B (µ B -µ A ) - N 2 ,<label>(7)</label></formula><p>where Σ A , Σ B and µ A , µ B are covariance matrices and mean vectors from the respective image models A and B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Automatic Image Annotation Methods</head><p>We use three methods of automatic image annotation, such as PATSI (Photo Annotation through Similar Images) annotator, multi-PATSI annotator and multiclass PDA classificator. Details of all of those methods are described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PATSI Annotator</head><p>In the PATSI (Photo Annotation through Finding Similar Images) approach, for a query image Q, a vector of the k most similar images from the training dataset D needs to be found based on the similarity distance measure d. Let [r 1 , • • • , r k ] be the ranking of k the most similar images ordered decreasingly by similarity. Based on the hypothesis that images similar in appearance are likely to share the same annotation, keywords from the nearest neighbours are transferred to the query image. All labels for the image on position r in the ranking are transferred with a value designated by the transfer function ϕ(r i ).</p><p>To assure that labels from more similar images have a larger impact on resulting annotation we define ϕ as</p><formula xml:id="formula_10" coords="5,284.93,324.16,195.66,22.31">ϕ(r i ) = 1 i ,<label>(8)</label></formula><p>where r i is an image on position i in the ranking. All words associated with image r i are then transferred to the resulted annotation with the associated transfer value 1/i. If the words has been transferred before the transfer values are summed. The resulting query image annotation consists of all the words whose transfer values were greater than a specified threshold t. The threshold value t has an impact on the resulting annotation length and its optimal value as well as the optimal number of neighbours k which should be taken into account during the annotation process must both be found using an optimization process. The outline of the PATSI annotation method is presented in the figure <ref type="figure" coords="5,443.18,456.31,4.98,8.80">1</ref> and is summarized in the Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1. Schematic diagram of the PATSI algorithm</head><p>The optimal parameters k * and t * differ greatly not only for different databases, but also between feature sets, methods of distance measure and transfer functions. There exists no optimal choice of them that would be suitable in all cases. We need to adjusting them in each explicit case. 6: take k images with the smallest distances between the models and create a ranking of those images. 7: transfer all words from the images in the ranking with the value ϕ(r), where r is the position of the image in the ranking. 8: as a final annotation take the words which transfer values sum is greater or equal to the provided threshold t value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 PATSI image annotation algorithm</head><p>Finding t * and k * proves to be a non-trivial task. The commonly used optimization solvers are inapplicable due to the non-linear character of quality function Q (discrete domain on k and continues on t). To efficiently find t * and k * we propose and use the iterative refinement algorithm which is described in <ref type="bibr" coords="6,146.39,433.36,9.96,8.80" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-PATSI Annotator</head><p>During experiments we spot that some of the features as well as distance metrics are more suitable to detect some groups of words, while showing a weak performs for others. By combining them together we can increase overall annotation performance. We propose the multi-PATSI method that take advantage of this observation by joining together the strengths of a number of annotation techniques. The overall schema of multi-PATSI approach is presented in figure 2. In the first step we run PATSI algorithm separately for each features sets and distance functions to obtain annotation vectors. Each element of those vectors represent whether word should be assigned or not to the query image Q (class {-1, 1}).</p><p>For each of the PATSI annotators at learning stage the performance vector is calculated. The performance vector corresponds to the efficiency of the PATSIannotator for each of the annotated words on the testing set.</p><p>For each PATSI-annotator the resulted annotation vector is multiplied by a performance vector to obtain weighted annotator response. All weighted responses are then summed together creating final annotation. All concepts which obtain value greater than a threshold t multi are treated as a final annotation for a query image Q. Optimal threshold value t * multi can be calculated using crossvalidation method and optimization technique such as iterative refinement <ref type="bibr" coords="7,462.59,262.65,9.96,8.80" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Class Classification</head><p>As third annotation method we use Penalized Discriminant Analysis classifier <ref type="bibr" coords="7,271.25,305.11,10.89,8.80" target="#b5">[6,</ref><ref type="bibr" coords="7,285.85,305.11,7.75,8.80" target="#b6">7]</ref> from Python Machine Learning Module -MLPY <ref type="bibr" coords="7,167.69,317.07,15.50,8.80" target="#b16">[17]</ref> in One vs. All scenario.</p><p>In this approach for each concept we train a separate PDA classifier using the extracted image features. We use all features from images annotated by a specific concept as positive examples and others as negative. In training we use four fold cross-validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head><p>We submitted five runs for the annotators and features sets described in previous section:</p><p>1. PATSI with Kullback Leibler divergence -hsv color space and grid 20-by-20, 2. PATSI with Kullback Leibler divergence -rgb color space and grid 20-by-20, 3. Multi-PATSI with features presented in Table <ref type="table" coords="7,363.97,480.71,3.87,8.80" target="#tab_3">2</ref>, 4. PDA classifier with CEDD features, 5. PDA classifier with Jpeg Coefficient Histogram features.</p><p>The official results of the five runs in terms of Average Precision (AP ), Average Equal Error Rate (Avg. EER), Average Area Under Curve (Avg. AUC) are reported in Table <ref type="table" coords="7,233.66,551.20,3.87,8.80" target="#tab_2">1</ref>. A detailed overview of the quality of annotations for each of the submitted methods for the 30 best-annotated words is presented in Table <ref type="table" coords="7,162.16,575.11,3.87,8.80" target="#tab_4">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>During the training and optimization process the parameters of the classifiers was tuned using the F-measure (harmonic mean of precision and recall) instead of the Average Precision. F-measure resulted that in all submitted annotations The published results show that the highest measure of quality according to AP measure, reached the multi-class PDA classifier with CEDD features. On the other hand the worst in comparison was multi-PATSI annotator.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,191.38,655.00,232.59,7.92"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Schematic diagram of the multi-PATSI algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,160.49,594.95,6.08,22.91;9,160.49,568.73,6.08,23.53;9,160.49,485.57,6.08,22.92;9,160.49,460.50,6.08,22.39;9,160.49,353.73,6.08,43.96;9,160.49,274.37,6.08,17.03;9,160.49,242.43,6.08,29.26;9,160.49,187.48,6.08,17.02;9,160.49,125.55,6.08,59.24;9,170.06,649.08,6.08,13.84;9,170.06,617.64,6.08,28.66;9,170.06,556.17,6.08,11.24;9,170.06,508.84,6.08,28.66;9,170.06,447.38,6.08,11.24;9,170.06,400.05,6.08,28.66;9,170.06,338.57,6.08,11.24;9,170.06,291.26,6.08,28.65;9,170.06,236.48,6.08,5.88;9,170.06,228.44,6.08,5.36;9,170.06,182.46,6.08,28.66;9,170.06,120.99,6.08,11.24;9,184.62,654.02,6.08,3.97;9,184.62,620.02,6.08,26.28;9,184.62,574.63,6.08,42.70;9,184.62,552.72,6.08,18.13;9,184.62,511.23,6.08,26.28;9,184.62,465.84,6.08,42.70;9,184.62,443.92,6.08,18.14;9,184.62,402.43,6.08,26.28;9,184.62,357.04,6.08,42.70;9,184.62,335.12,6.08,18.14;9,184.62,293.63,6.08,26.28;9,184.62,248.25,6.08,42.70;9,184.62,226.33,6.08,18.14;9,184.62,184.83,6.08,26.28;9,184.62,139.45,6.08,42.70;9,184.62,117.53,6.08,18.14;9,194.19,654.02,6.08,3.97;9,194.19,636.44,6.08,9.85;9,194.19,611.84,6.08,21.92;9,194.19,585.71,6.08,23.44;9,194.19,552.72,6.08,18.14;9,194.19,527.65,6.08,9.85;9,194.19,503.04,6.08,21.92;9,194.19,476.92,6.08,23.44;9,194.19,443.92,6.08,18.14;9,194.19,418.85,6.08,9.85;9,194.19,394.25,6.08,21.91;9,194.19,368.12,6.08,23.44;9,194.19,335.13,6.08,18.13;9,194.19,310.06,6.08,9.85;9,194.19,285.45,6.08,21.92;9,194.19,259.33,6.08,23.44;9,194.19,226.33,6.08,18.14;9,194.19,201.26,6.08,9.85;9,194.19,176.66,6.08,21.92;9,194.19,150.53,6.08,23.44;9,194.19,117.53,6.08,18.14;9,203.75,654.02,6.08,3.97;9,203.75,636.44,6.08,9.85;9,203.75,607.28,6.08,26.48;9,203.75,552.72,6.08,18.14;9,203.75,527.65,6.08,9.85;9,203.75,509.62,6.08,15.34;9,203.75,443.92,6.08,18.14;9,203.75,418.85,6.08,9.85;9,203.75,389.69,6.08,26.48;9,203.75,335.13,6.08,18.14;9,203.75,310.06,6.08,9.85;9,203.75,280.89,6.08,26.48;9,203.75,226.33,6.08,18.14;9,203.75,201.26,6.08,9.85;9,203.75,183.24,6.08,15.34;9,203.75,117.53,6.08,18.14;9,213.32,654.02,6.08,3.97;9,213.32,636.44,6.08,9.85;9,213.32,618.42,6.08,15.34;9,213.32,552.72,6.08,18.14;9,213.32,527.65,6.08,9.85;9,213.32,498.49,6.08,26.48;9,213.32,443.92,6.08,18.14;9,213.32,418.85,6.08,9.85;9,213.32,400.83,6.08,15.34;9,213.32,335.12,6.08,18.14;9,213.32,310.06,6.08,9.85;9,213.32,292.03,6.08,15.34;9,213.32,226.33,6.08,18.14;9,213.32,201.26,6.08,9.85;9,213.32,172.10,6.08,26.48;9,213.32,117.54,6.08,18.14;9,222.88,654.02,6.08,3.97;9,222.88,621.07,6.08,25.23;9,222.88,552.72,6.08,18.14;9,222.88,512.28,6.08,25.23;9,222.88,443.92,6.08,18.14;9,222.88,403.48,6.08,25.23;9,222.88,335.13,6.08,18.14;9,222.88,290.61,6.08,29.30;9,222.88,226.33,6.08,18.14;9,222.88,185.89,6.08,25.23;9,222.88,117.53,6.08,18.14;9,232.44,654.02,6.08,3.97;9,232.44,616.99,6.08,29.30;9,232.44,552.71,6.08,18.14;9,232.44,508.20,6.08,29.30;9,232.44,443.92,6.08,18.14;9,232.44,399.40,6.08,29.30;9,232.44,335.12,6.08,18.14;9,232.44,305.97,6.08,13.95;9,232.44,226.33,6.08,18.14;9,232.44,181.82,6.08,29.30;9,232.44,117.54,6.08,18.14;9,242.01,654.02,6.08,3.97;9,242.01,632.35,6.08,13.95;9,242.01,552.71,6.08,18.14;9,242.01,523.56,6.08,13.94;9,242.01,443.92,6.08,18.14;9,242.01,414.77,6.08,13.94;9,242.01,335.12,6.08,18.14;9,242.01,294.69,6.08,25.23;9,242.01,226.33,6.08,18.14;9,242.01,197.17,6.08,13.95;9,242.01,117.53,6.08,18.14;9,251.57,654.02,6.08,3.97;9,251.57,633.53,6.08,12.77;9,251.57,552.72,6.08,18.14;9,251.57,524.73,6.08,12.77;9,251.57,443.92,6.08,18.14;9,251.57,414.11,6.08,14.60;9,251.57,335.13,6.08,18.14;9,251.57,305.31,6.08,14.60;9,251.57,226.33,6.08,18.14;9,251.57,196.52,6.08,14.60;9,251.57,117.53,6.08,18.14;9,261.14,654.02,6.08,3.97;9,261.14,631.70,6.08,14.60;9,261.14,552.72,6.08,18.14;9,261.14,522.90,6.08,14.60;9,261.14,443.92,6.08,18.14;9,261.14,418.85,6.08,9.85;9,261.14,394.25,6.08,21.92;9,261.14,373.53,6.08,18.03;9,261.14,335.13,6.08,18.14;9,261.14,310.06,6.08,9.85;9,261.14,285.45,6.08,21.92;9,261.14,264.74,6.08,18.03;9,261.14,226.33,6.08,18.14;9,261.14,201.26,6.08,9.85;9,261.14,176.66,6.08,21.92;9,261.14,155.94,6.08,18.03;9,261.14,117.53,6.08,18.14;9,270.70,652.03,6.08,7.94;9,270.70,624.26,6.08,22.04;9,270.70,552.72,6.08,18.14;9,270.70,527.65,6.08,9.85;9,270.70,503.04,6.08,21.92;9,270.70,482.33,6.08,18.03;9,270.70,443.92,6.08,18.14;9,270.70,415.93,6.08,12.77;9,270.70,335.12,6.08,18.14;9,270.70,307.13,6.08,12.77;9,270.70,226.33,6.08,18.14;9,270.70,189.33,6.08,21.78;9,270.70,160.25,6.08,26.39;9,270.70,117.54,6.08,18.14;9,280.26,652.03,6.08,7.94;9,280.26,609.77,6.08,36.52;9,280.26,583.07,6.08,24.02;9,280.26,552.71,6.08,18.14;9,280.26,500.98,6.08,36.53;9,280.26,474.27,6.08,24.02;9,280.26,443.92,6.08,18.13;9,280.26,406.79,6.08,21.92;9,280.26,388.84,6.08,15.26;9,280.26,335.12,6.08,18.14;9,280.26,297.87,6.08,22.04;9,280.26,226.33,6.08,18.14;9,280.26,198.34,6.08,12.77;9,280.26,117.53,6.08,18.14;9,289.83,652.03,6.08,7.94;9,289.83,636.44,6.08,9.85;9,289.83,611.84,6.08,21.92;9,289.83,591.13,6.08,18.03;9,289.83,552.71,6.08,18.14;9,289.83,515.46,6.08,22.04;9,289.83,443.92,6.08,18.14;9,289.83,412.39,6.08,16.31;9,289.83,335.12,6.08,18.14;9,289.83,303.59,6.08,16.31;9,289.83,226.33,6.08,18.14;9,289.83,194.80,6.08,16.31;9,289.83,117.53,6.08,18.14;9,299.39,652.03,6.08,7.94;9,299.39,622.43,6.08,23.86;9,299.39,552.72,6.08,18.14;9,299.39,513.63,6.08,23.87;9,299.39,443.92,6.08,18.14;9,299.39,404.83,6.08,23.87;9,299.39,335.13,6.08,18.14;9,299.39,310.06,6.08,9.85;9,299.39,285.45,6.08,21.92;9,299.39,264.10,6.08,18.67;9,299.39,226.33,6.08,18.14;9,299.39,189.08,6.08,22.04;9,299.39,117.54,6.08,18.14;9,308.96,652.03,6.08,7.94;9,308.96,624.38,6.08,21.91;9,308.96,606.43,6.08,15.26;9,308.96,552.72,6.08,18.14;9,308.96,515.58,6.08,21.92;9,308.96,497.63,6.08,15.26;9,308.96,443.92,6.08,18.14;9,308.96,418.85,6.08,9.85;9,308.96,394.25,6.08,21.92;9,308.96,372.90,6.08,18.67;9,308.96,335.12,6.08,18.14;9,308.96,298.13,6.08,21.78;9,308.96,269.05,6.08,26.39;9,308.96,226.33,6.08,18.14;9,308.96,201.26,6.08,9.85;9,308.96,176.66,6.08,21.92;9,308.96,155.31,6.08,18.67;9,308.96,117.54,6.08,18.14;9,318.52,652.03,6.08,7.94;9,318.52,623.29,6.08,23.01;9,318.52,595.33,6.08,25.27;9,318.52,552.71,6.08,18.14;9,318.52,514.49,6.08,23.01;9,318.52,486.54,6.08,25.27;9,318.52,443.92,6.08,18.14;9,318.52,406.92,6.08,21.78;9,318.52,377.85,6.08,26.39;9,318.52,335.13,6.08,18.14;9,318.52,296.04,6.08,23.87;9,318.52,226.33,6.08,18.14;9,318.52,187.25,6.08,23.87;9,318.52,117.53,6.08,18.14;9,328.09,652.03,6.08,7.94;9,328.09,623.35,6.08,22.94;9,328.09,552.71,6.08,18.14;9,328.09,521.18,6.08,16.31;9,328.09,443.92,6.08,18.14;9,328.09,406.67,6.08,22.04;9,328.09,335.13,6.08,18.14;9,328.09,297.99,6.08,21.92;9,328.09,280.04,6.08,15.26;9,328.09,226.33,6.08,18.14;9,328.09,188.16,6.08,22.95;9,328.09,117.54,6.08,18.13;9,337.65,652.03,6.08,7.94;9,337.65,629.98,6.08,16.31;9,337.65,552.71,6.08,18.14;9,337.65,514.55,6.08,22.95;9,337.65,443.92,6.08,18.14;9,337.65,409.30,6.08,19.41;9,337.65,335.13,6.08,18.14;9,337.65,296.96,6.08,22.95;9,337.65,226.33,6.08,18.14;9,337.65,185.56,6.08,25.55;9,337.65,117.54,6.08,18.14;9,347.21,652.03,6.08,7.94;9,347.21,620.74,6.08,25.55;9,347.21,552.72,6.08,18.13;9,347.21,511.95,6.08,25.55;9,347.21,443.92,6.08,18.14;9,347.21,405.69,6.08,23.01;9,347.21,377.74,6.08,25.27;9,347.21,335.13,6.08,18.14;9,347.21,283.38,6.08,36.53;9,347.21,256.68,6.08,24.02;9,347.21,226.33,6.08,18.14;9,347.21,189.19,6.08,21.92;9,347.21,171.25,6.08,15.26;9,347.21,117.54,6.08,18.13;9,356.78,652.03,6.08,7.94;9,356.78,624.51,6.08,21.78;9,356.78,595.44,6.08,26.39;9,356.78,552.72,6.08,18.14;9,356.78,515.72,6.08,21.78;9,356.78,486.64,6.08,26.40;9,356.78,443.92,6.08,18.14;9,356.78,403.16,6.08,25.55;9,356.78,335.12,6.08,18.14;9,356.78,299.86,6.08,20.05;9,356.78,226.33,6.08,18.14;9,356.78,188.79,6.08,22.33;9,356.78,117.53,6.08,18.14;9,366.34,652.03,6.08,7.94;9,366.34,626.89,6.08,19.41;9,366.34,552.72,6.08,18.14;9,366.34,527.65,6.08,9.85;9,366.34,503.04,6.08,21.92;9,366.34,481.69,6.08,18.67;9,366.34,443.92,6.08,18.14;9,366.34,405.76,6.08,22.94;9,366.34,335.12,6.08,18.14;9,366.34,294.36,6.08,25.55;9,366.34,226.33,6.08,18.14;9,366.34,174.59,6.08,36.52;9,366.34,147.88,6.08,24.02;9,366.34,117.53,6.08,18.14;9,375.91,652.03,6.08,7.94;9,375.91,636.44,6.08,9.85;9,375.91,611.84,6.08,21.92;9,375.91,590.49,6.08,18.67;9,375.91,552.72,6.08,18.14;9,375.91,518.10,6.08,19.41;9,375.91,443.92,6.08,18.14;9,375.91,408.65,6.08,20.05;9,375.91,335.12,6.08,18.14;9,375.91,300.50,6.08,19.41;9,375.91,226.33,6.08,18.14;9,375.91,190.29,6.08,20.83;9,375.91,164.28,6.08,23.33;9,375.91,117.54,6.08,18.14;9,385.47,652.03,6.08,7.94;9,385.47,624.72,6.08,21.57;9,385.47,552.71,6.08,18.14;9,385.47,519.10,6.08,18.39;9,385.47,443.92,6.08,18.14;9,385.47,406.94,6.08,21.77;9,385.47,335.12,6.08,18.14;9,385.47,297.58,6.08,22.33;9,385.47,226.33,6.08,18.13;9,385.47,191.07,6.08,20.05;9,385.47,117.53,6.08,18.14;9,395.03,652.03,6.08,7.94;9,395.03,627.90,6.08,18.39;9,395.03,552.71,6.08,18.14;9,395.03,515.92,6.08,21.58;9,395.03,443.92,6.08,18.14;9,395.03,399.20,6.08,29.51;9,395.03,375.43,6.08,21.08;9,395.03,335.12,6.08,18.14;9,395.03,299.09,6.08,20.83;9,395.03,273.07,6.08,23.33;9,395.03,226.33,6.08,18.14;9,395.03,187.40,6.08,23.71;9,395.03,159.35,6.08,25.37;9,395.03,117.53,6.08,18.14;9,404.60,652.03,6.08,7.94;9,404.60,623.97,6.08,22.33;9,404.60,552.72,6.08,18.13;9,404.60,515.74,6.08,21.77;9,404.60,443.92,6.08,18.14;9,404.60,400.91,6.08,27.80;9,404.60,335.12,6.08,18.14;9,404.60,298.34,6.08,21.57;9,404.60,226.33,6.08,18.14;9,404.60,181.60,6.08,29.51;9,404.60,157.84,6.08,21.08;9,404.60,117.53,6.08,18.14;9,414.16,652.03,6.08,7.94;9,414.16,625.18,6.08,21.12;9,414.16,552.72,6.08,18.14;9,414.16,504.95,6.08,32.55;9,414.16,464.85,6.08,37.42;9,414.16,443.92,6.08,18.14;9,414.16,407.58,6.08,21.12;9,414.16,335.12,6.08,18.14;9,414.16,290.40,6.08,29.51;9,414.16,266.63,6.08,21.08;9,414.16,226.33,6.08,18.14;9,414.16,189.99,6.08,21.12;9,414.16,117.53,6.08,18.14;9,423.73,652.03,6.08,7.94;9,423.73,629.88,6.08,16.41;9,423.73,601.61,6.08,25.59;9,423.73,552.72,6.08,18.14;9,423.73,521.09,6.08,16.41;9,423.73,492.81,6.08,25.59;9,423.73,443.92,6.08,18.14;9,423.73,406.38,6.08,22.33;9,423.73,335.13,6.08,18.13;9,423.73,287.37,6.08,32.55;9,423.73,247.26,6.08,37.42;9,423.73,226.33,6.08,18.14;9,423.73,183.32,6.08,27.79;9,423.73,117.54,6.08,18.13;9,433.29,652.03,6.08,7.94;9,433.29,622.59,6.08,23.70;9,433.29,594.54,6.08,25.37;9,433.29,552.72,6.08,18.14;9,433.29,516.38,6.08,21.12;9,433.29,443.92,6.08,18.14;9,433.29,407.88,6.08,20.83;9,433.29,381.87,6.08,23.33;9,433.29,335.13,6.08,18.14;9,433.29,292.12,6.08,27.79;9,433.29,226.33,6.08,18.14;9,433.29,189.35,6.08,21.77;9,433.29,117.53,6.08,18.14;9,442.85,652.03,6.08,7.94;9,442.85,613.75,6.08,32.55;9,442.85,573.64,6.08,37.42;9,442.85,552.72,6.08,18.13;9,442.85,512.73,6.08,24.78;9,442.85,443.92,6.08,18.14;9,442.85,405.00,6.08,23.70;9,442.85,376.95,6.08,25.37;9,442.85,335.12,6.08,18.14;9,442.85,296.20,6.08,23.71;9,442.85,268.15,6.08,25.37;9,442.85,226.33,6.08,18.14;9,442.85,178.57,6.08,32.55;9,442.85,138.47,6.08,37.42;9,442.85,117.53,6.08,18.14;9,452.42,652.03,6.08,7.94;9,452.42,624.53,6.08,21.77;9,452.42,552.71,6.08,18.14;9,452.42,517.45,6.08,20.05;9,452.42,443.92,6.08,18.14;9,452.42,392.18,6.08,36.52;9,452.42,365.48,6.08,24.02;9,452.42,335.12,6.08,18.14;9,452.42,303.50,6.08,16.41;9,452.42,275.22,6.08,25.59;9,452.42,226.33,6.08,18.14;9,452.42,186.34,6.08,24.78;9,452.42,117.53,6.08,18.14;9,461.98,652.03,6.08,7.94;9,461.98,626.25,6.08,20.04;9,461.98,552.71,6.08,18.14;9,461.98,516.67,6.08,20.83;9,461.98,490.67,6.08,23.32;9,461.98,443.92,6.08,18.13;9,461.98,396.16,6.08,32.55;9,461.98,356.06,6.08,37.42;9,461.98,335.13,6.08,18.14;9,461.98,298.79,6.08,21.12;9,461.98,226.33,6.08,18.13;9,461.98,189.54,6.08,21.57;9,461.98,117.54,6.08,18.13"><head>PATSI</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,168.01,115.90,276.66,77.01"><head>Table 1 .</head><label>1</label><figDesc>Official results of submitted runs on testing dataset</figDesc><table coords="8,168.01,137.99,276.66,54.92"><row><cell>Submited run</cell><cell>AP</cell><cell>EER</cell><cell>AUC</cell></row><row><cell>PDA + CEDD</cell><cell>0.188821</cell><cell>0.361605</cell><cell>0.419472</cell></row><row><cell>PDA + JpegCoefficientHistogram</cell><cell>0.186649</cell><cell>0.375593</cell><cell>0.398008</cell></row><row><cell>PATSI + RGB</cell><cell>0.183472</cell><cell>0.464731</cell><cell>0.125210</cell></row><row><cell>PATSI + HSV</cell><cell>0.180601</cell><cell>0.461858</cell><cell>0.128203</cell></row><row><cell>Multi-PATSI</cell><cell>0.174149</cell><cell>0.427712</cell><cell>0.240389</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,134.77,217.96,345.82,406.40"><head>Table 2 .</head><label>2</label><figDesc>Feature sets and distance metrics with its optimal transfer parameters used in multi-PATSI annotator</figDesc><table coords="8,134.77,246.11,345.82,378.26"><row><cell></cell><cell></cell><cell>L1</cell><cell></cell><cell></cell><cell>L2</cell><cell></cell><cell></cell><cell>Cosine</cell><cell cols="3">Manhattan</cell><cell>correlation</cell></row><row><cell>Feature set</cell><cell>F</cell><cell cols="2">t  *  n  *</cell><cell>F</cell><cell>t  *</cell><cell>n  *</cell><cell>F</cell><cell cols="2">t  *  n  *  F</cell><cell cols="2">t  *  n  *  F</cell><cell>t  *  n  *</cell></row><row><cell>Auto Color Correlo-</cell><cell cols="3">0.211 0.1 30</cell><cell></cell><cell cols="2">0.1 29</cell><cell></cell><cell>0.1 24</cell><cell></cell><cell cols="2">0.10 30</cell><cell>0.10 29</cell></row><row><cell>gram</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CEDD</cell><cell cols="8">0.225 0.10 19 0.240 0.26 24 0.238 0.28 22</cell><cell></cell><cell cols="2">0.10 19</cell><cell>0.1 25</cell></row><row><cell>FCTH</cell><cell cols="3">0.221 0.10 20</cell><cell></cell><cell cols="2">0.10 24</cell><cell></cell><cell>0.10 23</cell><cell></cell><cell cols="2">0.10 20 0.219 0.1 26</cell></row><row><cell>Fuzzy Color His-</cell><cell cols="3">0.208 0.10 30</cell><cell></cell><cell cols="2">0.10 28</cell><cell></cell><cell>0.1 29</cell><cell></cell><cell cols="2">0.10 30</cell><cell>0.10 27</cell></row><row><cell>togram</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>General Color Lay-</cell><cell></cell><cell cols="5">0.02 32 0.199 0.10 31</cell><cell></cell><cell>0.02 35</cell><cell></cell><cell cols="2">0.02 32</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>out</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Jpeg Coefficient His-</cell><cell cols="8">0.229 0.10 9 0,243 0.34 19 0.236 0.18 13</cell><cell></cell><cell cols="2">0.10 9</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>togram</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Gabor</cell><cell></cell><cell cols="2">0.02 35</cell><cell></cell><cell cols="4">0.02 35 0.196 0.015 36</cell><cell></cell><cell cols="2">0.02 35</cell><cell>0.015 36</cell></row><row><cell>Tamura</cell><cell cols="2">0.06 29</cell><cell></cell><cell cols="2">0.05 33</cell><cell></cell><cell cols="2">0.10 27</cell><cell cols="3">0.06 29 -</cell><cell>-</cell><cell>-</cell></row><row><cell>Grid 20x20 -RGB</cell><cell></cell><cell cols="2">0.1 30</cell><cell></cell><cell cols="2">0.1 30</cell><cell></cell><cell cols="4">0.10 33 0.213 0.1 27</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Grid 20x20 -RGB +</cell><cell></cell><cell cols="2">0.1 27</cell><cell>-</cell><cell cols="2">0.1 29</cell><cell></cell><cell>0.1 30</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>dev.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Grid 20x20 -RGB +</cell><cell></cell><cell cols="2">0.12 29</cell><cell></cell><cell cols="4">0.1 30 0.219 0.14 30</cell><cell></cell><cell cols="2">0.1 32</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>dev. + hes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Grid 20x20 -HSV</cell><cell></cell><cell cols="5">0.1 30 0.213 0.1 31</cell><cell></cell><cell cols="4">0.01 34 0.215 0.1 30</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Grid 20x20 -HSV +</cell><cell></cell><cell cols="2">0.1 27</cell><cell></cell><cell cols="7">0.1 30 0.216 0.14 36 0.1 27 -</cell><cell>-</cell><cell>-</cell></row><row><cell>dev.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Grid 20x20 -HSV +</cell><cell></cell><cell cols="2">0.1 30</cell><cell></cell><cell cols="7">0.1 29 0.219 0.14 36 0.1 30 -</cell><cell>-</cell><cell>-</cell></row><row><cell>dev. + hes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Grid 20x20 -CoOc-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell cols="2">0.06 33</cell><cell></cell><cell>0.06 33</cell><cell></cell><cell cols="2">0.02 32</cell><cell>-</cell><cell>-</cell></row><row><cell>curanceMatrix</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Grid 5x5 -RGB</cell><cell></cell><cell cols="2">0.10 30</cell><cell></cell><cell cols="2">0.1 30</cell><cell></cell><cell>0.1 30</cell><cell></cell><cell cols="2">0.10 30</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Grid 5x5 -RGB +</cell><cell></cell><cell cols="2">0.10 30</cell><cell></cell><cell cols="2">0.1 30</cell><cell></cell><cell cols="4">0.1 30 0.10 30 -</cell><cell>-</cell><cell>-</cell></row><row><cell>dev.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Grid 5x5 -RGB +</cell><cell></cell><cell cols="2">0.10 30</cell><cell></cell><cell cols="7">0.1 30 0.217 0.1 30 0.10 30 -</cell><cell>-</cell><cell>-</cell></row><row><cell>dev. + hes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Grid 5x5 -HSV</cell><cell></cell><cell cols="2">0.10 30</cell><cell></cell><cell cols="2">0.1 29</cell><cell></cell><cell>0.1 33</cell><cell></cell><cell cols="2">0.1 29</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Grid 5x5 -HSV +</cell><cell></cell><cell cols="5">0.10 29 0.219 0.1 25</cell><cell></cell><cell cols="4">0.10 24 0.221 0.1 29</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>dev.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Grid 5x5 -HSV +</cell><cell></cell><cell cols="7">0.10 27 0.1 25 0.225 0.16 27</cell><cell cols="3">0.1 27 -</cell><cell>-</cell><cell>-</cell></row><row><cell>dev. + hes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Grid 5x5 -CoOccu-</cell><cell cols="8">0.18 32 0.1 32 0.10 28 0.219 0.18 32</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>ranceMatrix</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="12">results we optimize annotation length by providing annotation vectors contained</cell></row><row><cell cols="12">only {-1, 1} values. Using vectors prepared in such a way results in low Average</cell></row><row><cell>Precision quality.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,147.81,237.49,6.14,303.78"><head>Table 3 .</head><label>3</label><figDesc>Average Precision for the 30 best annotated concepts in all submitted results</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>The results show that the method of transferring annotations seems to be very interesting concept. However, it will be necessary to use outside the global characteristics of the image also the local features as well as adaptive metric functions.</p></div>
			</div>
			<div type="funding">
<div><p>This work is partially financed from the <rs type="funder">Ministry of Science and Higher Education Republic of Poland</rs> resources in 2008-2010 years as a <rs type="programName">Poland-Singapore joint</rs> research project <rs type="grantNumber">65/N-SINGAPORE/2007/0</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_rAHK3kK">
					<idno type="grant-number">65/N-SINGAPORE/2007/0</idno>
					<orgName type="program" subtype="full">Poland-Singapore joint</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,155.24,202.48,325.36,7.92;10,155.24,213.44,252.26,7.92" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,313.85,202.48,147.06,7.92">A new baseline for image annotation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Makadia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pavlovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,155.24,213.44,40.32,7.92">ECCV &apos;08</title>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="316" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.24,223.53,325.35,7.92;10,155.24,234.49,325.35,7.92;10,155.24,245.45,304.89,7.92" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,311.53,223.53,169.07,7.92;10,155.24,234.49,200.92,7.92">Patsi -photo annotation through finding similar images with multivariate gaussian models</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Stanek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Broda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kwasnicka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,367.31,234.49,113.28,7.92;10,155.24,245.45,276.22,7.92">Lecture Notes in Computer Science, International Conference on Computer Vision and Graphics</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.24,255.54,325.35,7.92;10,155.24,266.50,325.35,7.92;10,155.24,277.45,236.00,7.92" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,311.33,255.54,169.26,7.92;10,155.24,266.50,175.37,7.92">PATSI -photo annotation through similar images with annotation length optimization</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Stanek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kwasnicka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,353.07,266.50,123.30,7.92">Intelligent information systems</title>
		<imprint>
			<publisher>Publishing House of University of Podlasie</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="219" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.24,287.55,325.35,7.92;10,155.24,298.51,325.35,7.92;10,155.24,309.46,25.60,7.92" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,259.63,287.55,220.96,7.92;10,155.24,298.51,157.99,7.92">New strategies for image annotation: Overview of the photo annotation task at imageclef 2010</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Huiskes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,345.13,298.51,131.26,7.92">the Working Notes of CLEF 2010</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.24,319.56,325.36,7.92;10,155.24,330.51,325.35,7.92;10,155.24,341.47,249.34,7.92" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,289.35,319.56,191.25,7.92;10,155.24,330.51,44.09,7.92">Lire: lucene image retrieval: an extensible java cbir library</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Chatzichristofis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,223.12,330.51,257.47,7.92;10,155.24,341.47,57.25,7.92">MM &apos;08: Proceeding of the 16th ACM international conference on Multimedia</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1085" to="1088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.24,351.57,325.36,7.92;10,155.24,362.52,226.99,7.92" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,203.45,351.57,277.15,7.92;10,155.24,362.52,81.80,7.92">Penalized discriminant methods for the classification of tumors from gene expression data</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,245.22,362.52,42.95,7.92">Biometrics</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="992" to="1000" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.24,372.62,325.35,7.92;10,155.24,383.58,110.03,7.92" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,307.18,372.62,125.54,7.92">Penalized discriminant analysis</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Buja</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,441.75,372.62,38.84,7.92;10,155.24,383.58,36.96,7.92">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="73" to="102" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.24,393.67,325.35,7.92;10,155.24,404.63,325.35,7.92;10,155.24,415.58,60.92,7.92" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,292.26,393.67,188.33,7.92;10,155.24,404.63,210.68,7.92">Cedd: Color and edge directivity descriptor: A compact descriptor for image indexing and retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chatzichristofis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Boutalis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,375.01,404.63,105.58,7.92">Computer Vision Systems</title>
		<imprint>
			<biblScope unit="page" from="312" to="322" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.24,425.68,325.35,7.92;10,155.24,436.64,292.34,7.92" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,301.81,425.68,145.17,7.92">Overview of the MPEG-7 Standard</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sikora</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Puri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,458.45,425.68,22.14,7.92;10,155.24,436.64,202.76,7.92">IEEE Trans. Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="688" to="695" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.25,446.73,325.34,7.92;10,155.24,457.69,325.35,7.92;10,155.24,468.64,264.55,7.92" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,309.81,446.73,170.78,7.92;10,155.24,457.69,189.72,7.92">Fcth: Fuzzy color and texture histograma low level feature for accurate image retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Chatzichristofis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Boutalis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,354.20,457.69,126.39,7.92;10,155.24,468.64,192.19,7.92">Image Analysis for Multimedia Interactive Services, International Workshop on</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page" from="191" to="196" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.25,478.74,325.34,7.92;10,155.24,489.70,296.45,7.92" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,314.55,478.74,166.04,7.92;10,155.24,489.70,40.75,7.92">Texture features corresponding to visual perception</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Yamawaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,204.15,489.70,210.49,7.92">IEEE Transactions on System, Man and Cybernatic</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.25,499.79,325.35,7.92;10,155.24,510.75,121.81,7.92" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,216.26,499.79,244.22,7.92">Image information retrieval: An overview of current research</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Goodrum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,476.75,499.79,3.84,7.92;10,155.24,510.75,63.25,7.92">forming Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">2000</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.25,520.84,325.34,7.92;10,155.24,531.80,325.35,7.92;10,155.24,542.76,325.35,7.92;10,155.24,553.71,118.04,7.92" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,394.68,520.84,85.91,7.92;10,155.24,531.80,72.46,7.92">Image indexing using color correlograms</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,250.76,531.80,229.83,7.92;10,155.24,542.76,200.86,7.92">CVPR &apos;97: Proceedings of the 1997 Conference on Computer Vision and Pattern Recognition (CVPR &apos;97)</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page">762</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.25,563.81,325.34,7.92;10,155.24,574.77,271.06,7.92" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,336.32,563.81,144.27,7.92;10,155.24,574.77,88.24,7.92">Content-based image retrieval using gabor texture features</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Indrawan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,265.43,574.77,106.09,7.92">IEEE Transactions PAMI</title>
		<imprint>
			<biblScope unit="page" from="13" to="15" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.25,584.86,325.34,7.92;10,155.24,595.82,325.35,7.92;10,155.24,606.77,57.34,7.92" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,343.34,584.86,137.25,7.92;10,155.24,595.82,28.67,7.92">Textural features for image classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Dinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,192.11,595.82,220.86,7.92">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="610" to="621" />
			<date type="published" when="1973-11">November 1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.25,616.87,325.34,7.92;10,155.24,627.83,282.95,7.92" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,284.24,616.87,140.79,7.92">The EM Algorithm and Extensions</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J</forename><surname>Mclachlan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,432.20,616.87,48.39,7.92;10,155.24,627.83,116.46,7.92">Wiley Series in Probability and Statistics)</title>
		<imprint>
			<publisher>Wiley-Interscience</publisher>
			<date type="published" when="2008-03">March 2008</date>
		</imprint>
	</monogr>
	<note>2 edn</note>
</biblStruct>

<biblStruct coords="10,155.25,637.92,325.34,7.92;10,155.24,648.88,248.53,7.92" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Albanese</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Merler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Jurman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Visintainer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Furlanello</surname></persName>
		</author>
		<ptr target="http://mloss.org/software/view/66/" />
		<title level="m" coord="10,441.00,637.92,39.59,7.92;10,155.24,648.88,68.89,7.92">Mlpy machine learning py</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
