<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,162.19,118.30,291.16,12.29;1,172.78,136.23,270.04,12.29;1,262.23,154.16,91.03,12.29">ITC-UT: Tweet Categorization by Query Categorization for On-line Reputation Management</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,151.46,191.93,67.69,8.59"><forename type="first">Minoru</forename><surname>Yoshida</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Tokyo</orgName>
								<address>
									<addrLine>7-3-1, Hongo, Bunkyo-ku</addrLine>
									<postCode>113-0033</postCode>
									<settlement>Tokyo</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,227.12,191.93,73.38,8.59"><forename type="first">Shin</forename><surname>Matsushima</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Tokyo</orgName>
								<address>
									<addrLine>7-3-1, Hongo, Bunkyo-ku</addrLine>
									<postCode>113-0033</postCode>
									<settlement>Tokyo</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,308.89,191.93,48.45,8.59"><forename type="first">Shingo</forename><surname>Ono</surname></persName>
							<email>ono@r.dl.itc.u-tokyo.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Tokyo</orgName>
								<address>
									<addrLine>7-3-1, Hongo, Bunkyo-ku</addrLine>
									<postCode>113-0033</postCode>
									<settlement>Tokyo</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,365.92,191.93,39.68,8.59"><forename type="first">Issei</forename><surname>Sato</surname></persName>
							<email>sato@r.dl.itc.u-tokyo.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Tokyo</orgName>
								<address>
									<addrLine>7-3-1, Hongo, Bunkyo-ku</addrLine>
									<postCode>113-0033</postCode>
									<settlement>Tokyo</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,432.74,191.93,31.36,8.59;1,285.88,203.89,43.71,8.59"><forename type="first">Hiroshi</forename><surname>Nakagawa</surname></persName>
							<email>nakagawa@r.dl.itc.u-tokyo.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Tokyo</orgName>
								<address>
									<addrLine>7-3-1, Hongo, Bunkyo-ku</addrLine>
									<postCode>113-0033</postCode>
									<settlement>Tokyo</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,162.19,118.30,291.16,12.29;1,172.78,136.23,270.04,12.29;1,262.23,154.16,91.03,12.29">ITC-UT: Tweet Categorization by Query Categorization for On-line Reputation Management</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">48D0356F3FAC9F03DEA7ABAFD058A7F0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Organization Name Disambiguation</term>
					<term>Two-Stage Algorithm</term>
					<term>Naive Bayes</term>
					<term>Twitter</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our system, called ITC-UT, for the task-2 (on-line reputation management task) in WePS-3. Our idea is to categorize each query into 3 or 4 classes according to how much the tweets retrieved by the query contain the "true" entity names that refer to the target entity, and then categorize each tweet by the rules defined for each class of queries. We show the evaluation results for our system along with the details of results of query categorization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="843.024"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="843.024"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="843.024"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="843.024"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="843.024"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="843.024"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="843.024"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="843.024"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="843.024"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper reports the algorithms and results of the ITC-UT (Information Technology Center, the University of Tokyo) team for the WePS-3 task-2 (on-line reputation management task.) The supposed situation of this task is where you search reputation of some organization in Twitter. Assuming that tweets are retrieved by the organization name query, the problem is to decide whether each organization name found in each tweet represents the target organization or not (such as "Apple PC" for the former and "Apple Pie" for the latter for the query "Apple".) This is one type of name disambiguation problems that have been extensively studied through previous WePS workshops <ref type="bibr" coords="1,359.73,543.88,13.87,8.59" target="#b0">[1,</ref><ref type="bibr" coords="1,375.28,543.88,7.01,8.59" target="#b1">2]</ref>. However, the current task setting is challenging because generally each tweet is small and provides little context for disambiguation.</p><p>Our algorithm to solve this problem is based on the intuition that organization names can be classified into "organization-like names" and "general-wordlike names", such as "McDonald's" for the former and "Pioneer" for the latter. This intuition is supported by the fact that the ratio of TRUE 1 (or FALSE) tweets in the training data vary widely from entity to entity. For example, over 98% of tweets were labeled TRUE for entity "nikon", while the ratio for entity "renaissance technologies" (for which the query term was "Renaissance") was under 1%. Our strategy is to make aggressive use of such unbalance by predicting whether each query in the test set is biased towards TRUE or FALSE as described in detail in section 3.1. Then the heuristic rules suited for the bias of query are applied to categorize the tweets. For instance, if a query is highly likely to be an organization name, each tweet is labeled TRUE unless some strong evidences indicate the opposite. The detail is described in section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Definitions</head><p>In this section, we briefly give the definition of the task required for the description of our algorithm. Both the training and test data contain the entity name (e.g., "marriott international"), the query term used to retrieve tweets (e.g., "Marriott"), the URL of the home page for the entity, and 700 tweets (per entity name) retrieved by the query term. The training data also contain the label "TRUE" or "FALSE" for each tweet that indicate whether the tweet mentioned the entity or not. The task is to predict whether each tweet in the test data (provided with no label) are TRUE (i.e., mentions the entity) or FALSE (i.e., doesn't mention the entity.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Algorithm</head><p>As mentioned above, our algorithm is mainly divided into two stages: the query categorization stage (stage 1) and the tweet categorization stage (stage 2). In this section, we describe each stage in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Stage 1: Query Categorization</head><p>The first stage categorizes each query into 3 or 4 classes according to the confidence of "how the query indicates the given organization if no contexts are given".</p><p>For training data, the class of each query was determined by the ratio of the number of TRUE tweets (represented by t) to the number of all tweets for the query. We used two different configurations for the number of classes: 3 and 4. In the 3-class settings, each query is categorized into: The threshold values θ i and θ i were determined manually by looking at the training data. The values were θ 1 = 0.66.. and θ 2 = 0.33.. for 3-class labeling, and θ 1 = 0.9, θ 2 = 0.1, and θ 3 = 0.5 for 4-class labeling.</p><formula xml:id="formula_0" coords="2,134.83,571.88,177.65,9.96">class 1: TRUE-biased queries: if t &gt;</formula><p>For categorization, we did not use linguistic features (e.g., frequent words in tweets) other than very simple ones by pattern matching (such as "Is an acronym?" feature described below) because useful linguistic features for classification seem to be different for different entities and it is difficult to find the features common between training and test data. Instead, we made an extensive use of meta-data such as URLs. The categorization was performed by the simple Naive Bayes classifier (in the Weka<ref type="foot" coords="3,287.36,256.75,3.97,6.97" target="#foot_1">2</ref> toolkit) with following 6 binary features.</p><p>Is the query identical to the entity name? This feature value is true for query "Apple" for entity "Apple" and false for query "Amazon" for entity "Amazon.com", for example. This feature is introduced based on the intuition that the difference between the query and the entity name suggests that the entity requires the full name to be specified, such as "Delta Holding" which may tend to be confused with other organizations including "Delta Air Lines" when the query "Delta" is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Does the domain name in URL include the query or entity name? This</head><p>feature value is true if, for example, the URL can be described by the regular expression http://(www.)?apple.[a-z]/ for the query "Apple". This feature being true may indicate that the organization has an original domain, and therefore a not so minor organization. Does Wikipedia have "disambiguation page" for the query? This feature is introduced based on the intuition that highly ambiguous names, for which the disambiguation task is difficult, might have a disambiguation page in Wikipedia (www.wikipedia.org). Is the query an acronym? This feature is based on the observation that acronyms tend to have high ambiguity because they have typically only 2 or 3 characters and therefore many different concepts are expressed by the same acronym.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Does the given URL indicate the top page of Web search results? If the</head><p>given entity is a major concept represented by the query word, the URL for the entity will come to the first of the search result list if we enter the query to an internet search engine, in which case the feature value is set to "true." Is the query an entry of a dictionary? This feature is introduced to detect whether the query word is a general word or not. If the former is the case, it will be a risk of the query being used not as the specific organization name, but as some general words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Stage 2: Tweet Categorization</head><p>Stage 2 categorizes each tweet into "mentioning on the organization" (TRUE) or not (FALSE). The categorization is decided by simple heuristic rules defined for each class of queries.</p><p>The system obtains Part of Speech (POS) tags and Named Entity (NE) labels of the queries in each tweet by using Stanford POS tagger<ref type="foot" coords="4,383.12,186.95,3.97,6.97" target="#foot_2">3</ref> and NE Recognizer<ref type="foot" coords="4,473.40,186.95,3.97,6.97" target="#foot_3">4</ref> . Each tweet is categorized by rules that use these extracted POS and NE labels. These rules are defined for each class of queries as follows.</p><p>Class 1: TRUE-Biased Queries Each tweet for this class is categorized into TRUE unless it is strongly suggested that, by the following rules, the query represents something other than organizations.</p><p>1. If the NE tag of the query is a "PERSON" or "LOCATION", label FALSE. 2. Otherwise, label TRUE.</p><p>Class 2: FALSE-Biased Queries On the contrary to the class 1 rules, the tweet for this class of queries is categorized into FALSE unless it is strongly suggested, by the following rules, that the query does represent the orgznization.</p><p>1. If the entity name consists of two or more words (such as "Cisco Systems"), and it is contained in the tweet, label TRUE. 2. If the tweet contains the URL for the entity, label TRUE. 3. Otherwise, label FALSE.</p><p>Class 3: Neutral Queries Rules for the tweets for the queries of class 3 are the same as the rules for class 1 except that we add another rule (the second one) to detect FALSE tweets because the ratio of FALSE tweets may be larger than the class 1. The rules for class 3 therefore are defined in the following way.</p><p>1. If the NE tag of the query is "PERSON" or "LOCATION", label FALSE. 2. If the POS tag of the query is not a proper noun, label FALSE. 3. Otherwise, label TRUE.</p><p>We have another version of the rules that replaces the second rule with the following one. This difference of the versions adjusts the filtering power of the additional rule where the above one is stronger (filtering out (i.e., labeling FALSE) more tweets) and the below one is weaker (filtering out less tweets)<ref type="foot" coords="4,422.42,581.28,3.97,6.97" target="#foot_4">5</ref> . We call the original version of rule 2 the strong filter and the alternative one the weak filter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">If the POS tag of the query is not a noun, label FALSE.</head><p>Class 4: Weakly FALSE-Biased Queries This class is optional and the following rules are used. The rules for this class are the same as the rules for class 2 except that we add another rule (the third one) to find more TRUE tweets because more TRUE tweets are expected for this class than class 2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>We participated in the WePS-3 evaluation campaign with the four systems mentioned above. In this section, we report the performances of our methods. As described above, the systems are different in their rules for tweet categorization and the number of classes for query categorization. These specifications are again shown in Table <ref type="table" coords="5,204.07,454.98,3.87,8.59" target="#tab_2">1</ref>.</p><p>The accuracy, precision, recall and F-measure of each method were calculated both for positive and negative examples. We show those values of our algorithms and the top system (indicated by "LSIR,EPF 1") in Table <ref type="table" coords="5,393.27,490.88,3.87,8.59" target="#tab_3">2</ref>.</p><p>Among our methods, ITC-UT 1 achieved the best accuracy, which took the second position in the evaluation campaign. When we introduced "weakly FALSE-biased class", the performance degraded in most of the measures while only recall for negative example increased in both cases. It is natural that recall for negative example increased when we introduced "weakly FALSE-biased class" because tweets in this class are more likely to be classified to FALSE than the neutral class. Performance drop in the other measures suggests that the number of queries categorized to "weakly FALSE-biased class" was unnecessarily large, which may be because the conditions to specify "weakly FALSE-biased class" for the training data was too loose.</p><p>As shown in the table, when the rule 2 for class 3 changed from the strong filter (proper noun) to the weak filter (noun), most of values degraded while only recall for positive example increased. The "weak filter" contributes to save (i.e., label TRUE) more TRUE tweets (i.e., true positives) while it also saves more FALSE tweets (i.e., false positives.) The result showed that the increase of the former (true positives) was surpassed by the increase of latter (false positives).</p><p>We also compared our methods with the top system in the campaign (LSIR,EPFL 1). Our algorithm tend to show higher precision for positive examples and higher recall for negative examples, which implies our methods are biased to labeling FALSE. We think that our tweet classification rules, especially for class 3 ("neutral class"), leaves much room for improvement.</p><p>In Table <ref type="table" coords="6,188.27,530.27,4.98,8.59">3</ref> we show the classification results in the first stage. Roughly speaking, the result indicates that our algorithms could catch the biases of each query. However, it is not fully obvious whether each query was successfully labeled.</p><p>Note that labeling of the training queries was different between 3-class and 4-class settings because the threshold values are different between them. We show the detailed results of labeling of training queries in Table <ref type="table" coords="6,411.72,598.54,3.87,8.59" target="#tab_4">4</ref>. Currently, we did not perform any adjustment to tune the threshold values for labeling of the training queries to be better fit to the stage-2 rules for each class of queries. We think these threshold values of labeling of training queries can be improved by, for example, cross validation on the training data or simply maximizing accuracy of training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This paper reported the ITC-UT system for tweet categorization for the on-line reputation management task, which uses the 2-stage algorithm that categorizes each query in the first stage, and categorizes each tweet in the second stage using the rules customized for each class of queries. Our categorization rules are rather simple, therefore they still leave for improvement. For example, we can adjust the threshold values used in stage-1 to label the queries more appropriately for fitting to the stage-2 rules. We think we can also improve the results by using more sophisticated rules for tweet categorization for each classified class of queries. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,139.03,179.15,341.67,8.59;5,151.76,191.10,84.67,8.59;5,139.03,203.09,265.21,8.59;5,139.03,215.08,292.16,8.59;5,139.03,227.06,120.90,8.59;5,134.83,257.12,345.83,8.59;5,134.83,269.07,322.62,8.59;5,134.83,291.16,345.86,8.59;5,151.76,303.11,23.33,8.59;5,134.83,315.10,327.27,8.59;5,134.83,327.09,345.86,8.59;5,151.76,339.05,23.33,8.59;5,134.83,351.03,327.27,8.59"><head>1 .</head><label>1</label><figDesc>If the entity name consists of two or more words and it is contained in the tweet, label TRUE. 2. If the tweet contains the URL for the entity, label TRUE. 3. If the NE tag of the query is "ORGANIZATION", label TRUE. 4. Otherwise, label FALSE. System Parameters We used four different configurations for submission, resulting in four runs and outputs. The four configurations are listed below. ITC-UT 1: used 3 classes and the strong filter (proper noun) for the class 3 rules. ITC-UT 2: used 3 classes and the weak filter (noun) for the class 3 rules. ITC-UT 3: used 4 classes and the strong filter (proper noun) for the class 3 rules. ITC-UT 4: used 4 classes and the weak filter (noun) for the class 3 rules.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,134.83,571.88,334.15,52.34"><head>θ 1 , class 2: FALSE-biased queries: if t &lt; θ 2 , class 3: neutral queries: otherwise.</head><label></label><figDesc></figDesc><table coords="2,149.77,615.62,319.21,8.59"><row><cell>On the other hand, in the 4-class settings, each query is categorized into:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,134.83,633.85,195.13,35.27"><head>class 1: TRUE-biased queries: if t &gt; θ 1 , class 2: FALSE-biased queries: if t &lt; θ 2 , class 3: neutral queries: if θ 3 &lt; t ≤ θ 1 , class 4: weakly FALSE-biased queries: otherwise.</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,226.48,118.12,162.52,95.65"><head>Table 1 .</head><label>1</label><figDesc>Specification of Each Methods</figDesc><table coords="6,251.59,150.84,110.90,62.93"><row><cell>Method</cell><cell>rules</cell><cell>number of category</cell></row><row><cell cols="2">ITC-UT 1 NE</cell><cell>3</cell></row><row><cell cols="2">ITC-UT 2 Noun</cell><cell>3</cell></row><row><cell cols="2">ITC-UT 3 NE</cell><cell>4</cell></row><row><cell cols="2">ITC-UT 4 Noun</cell><cell>4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,136.22,256.86,374.38,115.83"><head>Table 2 .</head><label>2</label><figDesc>Performances of Methods</figDesc><table coords="6,136.22,298.80,374.38,73.89"><row><cell>Method</cell><cell>Accuracy</cell><cell>Precision (Positive)</cell><cell>Recall (Positive)</cell><cell>F-measure (Positive)</cell><cell>Precision (Negative)</cell><cell>Recall (Negative)</cell><cell>F-measure (Negative)</cell></row><row><cell cols="2">LSIR,EPFL 1 0.83</cell><cell>0.71</cell><cell>0.74</cell><cell>0.63</cell><cell>0.84</cell><cell>0.52</cell><cell>0.56</cell></row><row><cell>ITC-UT 1</cell><cell>0.75</cell><cell>0.75</cell><cell>0.54</cell><cell>0.49</cell><cell>0.74</cell><cell>0.60</cell><cell>0.57</cell></row><row><cell>ITC-UT 2</cell><cell>0.73</cell><cell>0.74</cell><cell>0.62</cell><cell>0.51</cell><cell>0.74</cell><cell>0.49</cell><cell>0.47</cell></row><row><cell>ITC-UT 3</cell><cell>0.67</cell><cell>0.70</cell><cell>0.47</cell><cell>0.41</cell><cell>0.71</cell><cell>0.65</cell><cell>0.56</cell></row><row><cell>ITC-UT 4</cell><cell>0.64</cell><cell>0.69</cell><cell>0.55</cell><cell>0.43</cell><cell>0.70</cell><cell>0.55</cell><cell>0.46</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,145.63,118.61,324.15,610.82"><head>Table 4 .</head><label>4</label><figDesc>Results of labeling the queries in training set (left:3-class,right:4-class)</figDesc><table coords="9,185.11,149.44,245.27,579.99"><row><cell>query</cell><cell>entity</cell><cell>Labeled Class</cell><cell></cell></row><row><cell>nikon</cell><cell>nikon</cell><cell>1</cell><cell>1</cell></row><row><cell>linux</cell><cell>linux</cell><cell>1</cell><cell>1</cell></row><row><cell>Lufthansa</cell><cell>lufthansa</cell><cell>1</cell><cell>1</cell></row><row><cell>Foxtel</cell><cell>foxtel</cell><cell>1</cell><cell>1</cell></row><row><cell>alcatel</cell><cell>alcatel</cell><cell>1</cell><cell>1</cell></row><row><cell>Renault</cell><cell>renault</cell><cell>1</cell><cell>1</cell></row><row><cell>lamborghini</cell><cell>lamborghini</cell><cell>1</cell><cell>1</cell></row><row><cell>Yamaha</cell><cell>yamaha</cell><cell>1</cell><cell>1</cell></row><row><cell>Fujitsu</cell><cell>fujitsu</cell><cell>1</cell><cell>1</cell></row><row><cell>Marriott</cell><cell>marriott international</cell><cell>1</cell><cell>1</cell></row><row><cell>Marvel</cell><cell>marvel comics</cell><cell>1</cell><cell>3</cell></row><row><cell>philips</cell><cell>philips</cell><cell>1</cell><cell>3</cell></row><row><cell>Mercedes</cell><cell>mercedes-benz</cell><cell>1</cell><cell>3</cell></row><row><cell cols="2">Mandalay mandalay bay resort and casino</cell><cell>1</cell><cell>3</cell></row><row><cell>armani</cell><cell>armani</cell><cell>1</cell><cell>3</cell></row><row><cell>barclays</cell><cell>barclays</cell><cell>1</cell><cell>3</cell></row><row><cell>Blockbuster</cell><cell>blockbuster inc.</cell><cell>1</cell><cell>3</cell></row><row><cell>bayer</cell><cell>bayer</cell><cell>3</cell><cell>3</cell></row><row><cell>fender</cell><cell>fender</cell><cell>3</cell><cell>3</cell></row><row><cell>cadillac</cell><cell>cadillac</cell><cell>3</cell><cell>3</cell></row><row><cell>Rover</cell><cell>land rover</cell><cell>3</cell><cell>3</cell></row><row><cell>BART</cell><cell>bart</cell><cell>3</cell><cell>4</cell></row><row><cell>Luxor</cell><cell>luxor hotel and casino</cell><cell>3</cell><cell>4</cell></row><row><cell>Boingo</cell><cell>boingo (wifi for travelers)</cell><cell>3</cell><cell>4</cell></row><row><cell>MGM</cell><cell>mgm grand hotel and casino</cell><cell>3</cell><cell>4</cell></row><row><cell>Harpers</cell><cell>harpers</cell><cell>3</cell><cell>4</cell></row><row><cell>Edmunds</cell><cell>edmunds.com</cell><cell>3</cell><cell>4</cell></row><row><cell>MTA</cell><cell>mta bike plus (nyc)</cell><cell>3</cell><cell>4</cell></row><row><cell>Southwest</cell><cell>southwest airlines</cell><cell>2</cell><cell>4</cell></row><row><cell>dunlop</cell><cell>dunlop</cell><cell>2</cell><cell>4</cell></row><row><cell>Amadeus</cell><cell>amadeus it group</cell><cell>2</cell><cell>4</cell></row><row><cell>pioneer</cell><cell>pioner company</cell><cell>2</cell><cell>2</cell></row><row><cell>Magnum</cell><cell>magnum research</cell><cell>2</cell><cell>2</cell></row><row><cell>mdm</cell><cell>mdm (event agency)</cell><cell>2</cell><cell>2</cell></row><row><cell>MEP</cell><cell>mep</cell><cell>2</cell><cell>2</cell></row><row><cell>Mercer</cell><cell>mercer consulting</cell><cell>2</cell><cell>2</cell></row><row><cell>Impulse</cell><cell>impulse (records )</cell><cell>2</cell><cell>2</cell></row><row><cell>elf</cell><cell>elf corporation</cell><cell>2</cell><cell>2</cell></row><row><cell>Apollo</cell><cell>apollo hospitals</cell><cell>2</cell><cell>2</cell></row><row><cell>Craft</cell><cell>craft magazine</cell><cell>2</cell><cell>2</cell></row><row><cell>nordic</cell><cell>nordic airways</cell><cell>2</cell><cell>2</cell></row><row><cell>Emperor</cell><cell>emperor entertainment group</cell><cell>2</cell><cell>2</cell></row><row><cell>folio</cell><cell>folio corporation</cell><cell>2</cell><cell>2</cell></row><row><cell>Smarter</cell><cell>smarter travel</cell><cell>2</cell><cell>2</cell></row><row><cell>Liquid</cell><cell>liquid entertainment</cell><cell>2</cell><cell>2</cell></row><row><cell>Lynx</cell><cell>lynx express</cell><cell>2</cell><cell>2</cell></row><row><cell>bulldog</cell><cell>bulldog solutions</cell><cell>2</cell><cell>2</cell></row><row><cell>shin</cell><cell>shin corporation</cell><cell>2</cell><cell>2</cell></row><row><cell>pierce</cell><cell>pierce manufacturing</cell><cell>2</cell><cell>2</cell></row><row><cell>Renaissance</cell><cell>renaissance technologies</cell><cell>2</cell><cell>2</cell></row><row><cell>Mack</cell><cell>mack group</cell><cell>2</cell><cell>2</cell></row><row><cell>Delta</cell><cell>delta holding</cell><cell>2</cell><cell>2</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.79,648.01,335.84,7.73;1,144.79,658.97,180.24,7.73"><p>TRUE indicates that the tweet mentions the target organization (as defined in the next section). FALSE indicates the opposite.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,144.79,658.97,158.95,7.73"><p>http://www.cs.waikato.ac.nz/ml/weka/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,144.79,637.06,186.57,7.73"><p>http://nlp.stanford.edu/software/tagger.shtml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,144.79,648.01,203.93,7.73"><p>http://nlp.stanford.edu/software/CRF-NER.shtml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,144.79,658.97,158.44,7.73"><p>Note that proper nouns are also nouns.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="7,138.41,284.24,342.17,7.73;7,146.97,295.20,333.65,7.73;7,146.97,306.16,333.67,7.73" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,296.64,284.24,183.93,7.73;7,146.97,295.20,206.86,7.73">The SemEval-2007 WePS evaluation: Establishing a benchmark for the web people search task</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Artiles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sekine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,375.22,295.20,105.41,7.73;7,146.97,306.16,196.06,7.73">Proceedings of the Fourth International Workshop on Semantic Evaluations</title>
		<meeting>the Fourth International Workshop on Semantic Evaluations<address><addrLine>SemEval</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="64" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.41,317.12,342.13,7.73;7,146.97,328.08,333.68,7.73;7,146.97,339.04,215.03,7.73" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,286.59,317.12,193.95,7.73;7,146.97,328.08,108.97,7.73">Web people search: results of the first evaluation and the plan for the second</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Artiles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,277.10,328.08,203.55,7.73;7,146.97,339.04,122.34,7.73">Proceeding of the 17th international conference on World Wide Web (WWW &apos;08)</title>
		<meeting>eeding of the 17th international conference on World Wide Web (WWW &apos;08)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1071" to="1072" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
