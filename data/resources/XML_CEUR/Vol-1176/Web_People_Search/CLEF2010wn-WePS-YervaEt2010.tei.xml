<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,141.40,115.96,332.57,12.62;1,271.16,133.89,73.03,12.62">It was easy, when apples and blackberries were only fruits</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,186.29,171.56,70.21,8.74"><forename type="first">Surender</forename><surname>Reddy</surname></persName>
							<email>surenderreddy.yerva@epfl.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">EPFL IC LSIR Lausanne</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,290.56,171.56,58.64,8.74"><forename type="first">Zoltán</forename><surname>Miklós</surname></persName>
							<email>zoltan.miklos@epfl.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">EPFL IC LSIR Lausanne</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,376.41,171.56,52.66,8.74"><forename type="first">Karl</forename><surname>Aberer</surname></persName>
							<email>karl.aberer@epfl.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">EPFL IC LSIR Lausanne</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,141.40,115.96,332.57,12.62;1,271.16,133.89,73.03,12.62">It was easy, when apples and blackberries were only fruits</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">61DCFA656520485FAFB5687443962A35</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Ambiguities in company names are omnipresent. This is not accidental, companies deliberately chose ambiguous brand names, as part of their marketing and branding strategy. This procedure leads to new challenges, when it comes to finding information about the company on the Web. This paper is concerned with the task of classifying Twitter messages, whether they are related to a given company: for example, we classify a set of twitter messages containing a keyword apple, whether a message is related to the company Apple Inc. Our technique is essentially an SVM classifier, which uses a simple representation of relevant and irrelevant information in the form of keywords, grouped in specific "profiles". We developed a simple technique to construct such classifiers for previously unseen companies, where no training set is available, by training the meta-features of the classifier with the help of a general test set. Our techniques show high accuracy figures over the WePS-3 dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Twitter<ref type="foot" coords="1,170.25,446.82,3.97,6.12" target="#foot_0">1</ref> is a popular service where users can share short messages (a.k.a. tweets) on any subject. Twitter is currently one of the most popular sites of the Web, as of February 2010, Twitter users send 50 million messages per day <ref type="foot" coords="1,418.47,470.73,3.97,6.12" target="#foot_1">2</ref> . As users are sharing information on what matters to them, analyzing twitter messages can reveal important social phenomena, indeed there are number of recent works, for example in <ref type="bibr" coords="1,203.84,508.17,14.61,8.74" target="#b9">[11]</ref>, exploring such information. Clearly, twitter messages are also a rich source for companies, to study the opinions about their products. To perform sentiment analysis or obtain reputation-related information, one needs first to identify the messages which are related to a given company. This is a challenging task on its own as company or product names are often homonyms. This is not accidental, companies deliberately choose such names as part of their branding and marketing strategy. For example, the company Apple Inc. shares its name with the fruit apple, which again could have a number of figurative meanings depending on the context, for example, "knowledge" (Biblical story of Adam, Eve and the serpent) or New York (the Big Apple).</p><p>In this paper, we focus on how to relate tweets to a company, in the context of the WePS-3 challenge, where we are given a set of companies and for each company a set of tweets, which might or might not be related to the company (i.e. the tweets contain the company name, as a keyword). Constructing such a classifier is a challenging task, as tweet messages are very short (maximum 140 characters), thus they contain very little information, and additionally, tweet messages use a specific language, often with incorrect grammar and specific abbreviations, which are hard to interpret by a computer. To overcome this problem, we constructed profiles for each company, which contain more rich information. For each company, in fact, we constructed several profiles, some of them automatically, some of them manually. The profiles are essentially sets of keywords, which are related to the company in some way. We also created profiles, which explicitly contains unrelated keywords. Our technique is essentially an SVM classifier, which uses this simple representation of relevant and irrelevant information in the "profiles". We developed a simple technique to construct such classifiers for previously unseen companies, where no training set is available, by training the meta-features of the classifier with the help of a general test set, available in WePS-3. Our techniques show high accuracy figures over the WePS-3 dataset.</p><p>The rest of the paper is organized as follows. Section 2 gives a more precise problem definition. Section 3 presents our techniques, while Section 4 gives more details on the classification techniques we used. Section 5 gives details on the experimental evaluation of our methods. Section 6 summarizes related work and finally Section 7 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Statement</head><p>In this section we formulate the problem and our computational framework more formally. The task is concerned to classify a set of Twitter messages Γ = {T 1 , . . . , T n }, whether they are related to a given company C. We assume that each message T i ∈ Γ contains the company name as a sub-string. We say that the message T i is related to the company C, related(T i , C), if and only if the Twitter message refers to the company. It can be that a message refers both to the company and also to some other meaning of the company name (or to some other company with the same name), but whenever the message T i refers to company C we try to classify as TRUE otherwise as FALSE. The task has some other inputs, such as the URL of the company url(C), the language of the webpage, as well as the correct classification for a small number of messages (for some of the companies).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Information representation</head><p>The tweet messages and company names alone contain very little information to realize the classification task with good accuracy. To overcome this problem, we created profiles for the companies, several profiles for each company. These set of profiles can be seen as a model for the company. In this section, we discuss how we represent tweet messages and companies and we also discuss how we obtained these profiles. In the the classification task we eventually compare a tweet against the profiles representing the company (see Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Tweet Representation</head><p>We represented a tweet as a bag of words (unigrams and bigrams). We do not access the tweet messages directly in our classification algorithm, but apply a preprocessing step first, which removes all the stop-words, emoticons, and twitter specific stop-words (such as, for example, RT,@username). We store a stemmed<ref type="foot" coords="3,476.12,228.31,3.97,6.12" target="#foot_2">3</ref> version of keywords (unigrams and bigrams), i.e.</p><p>T i = set{wrd j }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Company Representation</head><p>We represent each company as a collection of profiles, formally</p><formula xml:id="formula_0" coords="3,255.95,332.28,103.46,12.20">E k = {P k 1 , P k 2 , . . . , P k n }.</formula><p>Each profile is a set of weighted keywords i.e. P k i = {wrd j : wt j }, with wt j ≥ 0 for positive evidence and wt j &lt; 0 for negative evidence.</p><p>For the tweets classification task, we eventually compare the tweet with the entity (i.e. company) profile. For better classification results, the entity profile should have a good overlap with the tweets. Unfortunately, we do not know the tweet messages in advance, so we tried to create such profiles from alternative sources, independently of the tweet messages. The entity profile should not be too general, because it would result many false positives in the classification and also not too narrow, because then we could miss potential relevant tweets.</p><p>We generated most of our profiles automatically, i.e. if one would like to construct a classifier for a previously unseen company, one can automatically generate the profiles. Further, small, manually constructed profiles could further improve the accuracy of the classification, as we explain in Section 5.</p><p>In the following we give an overview of the profiles we used, and their construction.</p><p>Homepage Profile For each company name, the company homepage URL was provided in the WePS-3 data. To construct the homepage profile, we crawled all the relevant links up to a depth of level d(=2), starting from the given homepage URL. We extracted all the keywords present on the relevant pages, then we removed all the stopwords, finally we stored in the profile the stemmed version of these keywords. From this construction process one would expect that homepage-profile should capture all the important keywords related to the company. However, since the construction is an automated process, it was not always possible to capture good quality representation of the company, for various reasons: the company Webpages use java-scripts, flash, some company pages contain irrelevant links, there are non-standard homepages etc. Metadata Profile HTML standards provides few meta tags <ref type="foot" coords="4,402.39,165.96,3.97,6.12" target="#foot_3">4</ref> , which enables a webpage to list set of keywords that one could associate with the webpage.</p><p>We collect all such meta keywords in this profile whenever they are present. If these meta-keywords are present in the HTML code, they have high quality, the meta-keywords are highly relevant for the company. On the negative side, only a fraction of webpages have this information available. Category Profile The category, to which the company belongs, is a good source of relevant information of the company entity. The general terms associated with the category would be a rich representation of the entity. One usually fails to find this kind of keywords in the homepage profile. We make use of wordnet, a network of words, to find all the terms linked to the category keywords. This kind of profile helps us assign keywords like: software,install, update, virus, version, hardware, program, bugs etc to a software company. GoogleSet/CommonKnowledge Profile GoogleSet is a good source of obtaining "common knowledge" about the company. We make use of Google-Sets 5 to get words closely related to the company name. This helps us identify companies similar to the company under consideration, we get to know the products, competitor names etc. This kind of information is very useful, especially for twitter streams, as many tweets compare companies with others. With this kind of profile, we could for example associate Mozilla, Firefox, Internet Explorer, Safari keywords to Opera Browser entity. UserFeedback Positive Profile The user himself enters the keywords which he feels are relevant to the company, that we store in the manually constructed UserFeedback profile. In case of companies where sample ground truth is available, we can infer the keywords from the tweets (in the training set) belonging to the company. UserFeedback Negative Profile The knowledge of the common entities with which the current company entity could be confused, would be a rich source of information, using which one could classify tweets efficiently. The common knowledge that "apple" keyword related to "Apple Inc" company could be interpreted possibly as the fruit, or the New York city etc. This particular profile helps us to collect all the keywords associated with other entities with similar keyword. An automated way of collecting this information would be very helpful, but it is difficult. For now we make use of few sources as an initial step to collect this information. The user himself provides us with this information. Second, the wiki disambiguation pages 6 contains this information, at least for some entities. Finally this information could be gathered in a dynamic way i.e., using the keywords in all the tweets, that do not belong to the company. This information could also be obtained if we have training set for a particular company with tweets that do not belong to the company entity.</p><p>Table <ref type="table" coords="5,178.50,172.29,4.98,8.74" target="#tab_0">1</ref> shows how an "Apple Inc"<ref type="foot" coords="5,309.54,170.71,3.97,6.12" target="#foot_6">7</ref> company entity is represented using different profiles. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Classification Task</head><p>In machine learning literature, the learning tasks could be broadly classified as supervised and unsupervised learning. The problem scenario for the WePS-3 task, classification of tweets with respect to a company entity can be seen as a problem where one needs a machine learning technique between supervised and unsupervised learning, since we have no training set for the actual classification task, but a test training set is provided for a separate set of companies. Here we briefly discuss the different classes of machine learning techniques, and outline our classification method.</p><p>Supervised Learning for Classification Task Supervised learning is a machine learning technique for deducing a function from training data. The training data consist of pairs of input objects (typically vectors), and desired outputs. The output of the function can predict a class label of the input object (called classification). The task of the supervised learner is to predict the value of the function for any valid input object after having seen a number of training examples (i.e. pairs of input and target output). To achieve this, the learner has to generalize from the presented data to unseen situations in a "reasonable" way. An example of supervised learning in our current setting is: given a training set of tweets for a particular company(XYZ company), with example of tweets belonging to and not belonging to the company, one learns a classifier for this particular company(XYZ company). Using this classifier the new unseen tweets related to this company(XYZ company) can be classified as belonging or not belonging to that company.</p><p>Unsupervised Learning In machine learning, unsupervised learning is a class of problems in which one seeks to determine how the data are organized. Many methods employed here are based on data mining methods used to preprocess data. It is distinguished from supervised learning in that the learner is given only unlabeled examples. In broad sense, the task of classifying tweets of an unknown company, without seeing any relevant examples can fall into this category.</p><p>Generic Learning For the current scenario (WePS-3 -challenge 2), we are provided with training sets corresponding to few companies (C T R ). Finally we have to classify test sets corresponding to new companies(C T est ), with C T R C T est = 0. This particular scenario can be seen as in-between supervised and unsupervised learning. It is unsupervised as we are not given any labeled tweets corresponding to the test set. At the same time it is also related to supervised learning as we have access to few training sets, with labeled tweets corresponding to the companies. This kind of generic learning needs the classifier to identify the generic features from the general training set, based on which one can make accurate classification of tweets corresponding to the unseen companies. The classifiers based on the features of the tweet decides if it belongs to a company or not. In the following section 4.1, we discuss the features which our classifiers take as input. After the features are introduced, we propose different ways of developing a generic classifier in section 4.2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Features Extraction</head><p>We define a feature extraction function, which compares a tweet T i to the company entity representation E k and outputs a vector of features.</p><formula xml:id="formula_1" coords="6,189.97,628.73,235.42,38.17">F n(T i , E k ) = { meta-f eatures G 1 , . . . , G m , F 1 , . . . , F n tweet-specif ic , heuristics U 1 , . . . , U z }</formula><p>Here the G i are generic/meta features, which are entirely based on the quality of the entity profiles and do not depend on Tweet message T i . One could use different ways of quantifying the quality of the profiles.</p><p>-Boolean: In this work we make use of boolean metrics to represent if a profile is empty or has sufficient keywords. -Other possibility is that a human can inspect the profiles and assign a metric of x ∈ [0,1] based on the perceived quality. One could think of exploring an automated way of assigning this number.</p><p>The F i features are tweet specific features, i.e. they quantify how close a tweet overlaps with the entity profiles. We use a comparison function to compare the tweet message T i , which is a bag of words, with j th profile P k j , which is also a bag of weighted keywords, to get the F th j feature. In this work we make use of a simple comparison function, which compares two bags of words looking for exact overlap of keywords, and for all such keywords the sum of their weights quantify how close the tweet message is to the entity profile. Formally with T i = Set{w t 1 , w t 2 , . . . , w t k } and P k j = Set{w p 1 : wt 1 , w p 2 : wt 2 , . . . , w p m : wt m }, we compute the F j feature using the simple comparison function as:</p><formula xml:id="formula_2" coords="7,194.67,346.84,115.43,21.69">F j = CmpF n(T i , P k j ) = q</formula><p>wt q , where q such that</p><formula xml:id="formula_3" coords="7,205.27,363.04,275.32,24.94">w p q ∈ Set{w t 1 , w t 2 , . . . , w t k } Set{w p 1 , w p 2 , . . . , w p m }<label>(1)</label></formula><p>The above comparison function is simple and easy to realize, but it may miss out some semantically equivalent words. One could make use of cosine similarity, or semantic similarity based comparison functions.</p><p>The U i features encapsulate some user based rules, for example, presence of the company URL domain in the tweet URL list, is a big enough evidence to classify the tweet as belonging to the company.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Generic Classifier</head><p>The classifier is a function which takes the feature vector as input and classifies the tweet as {T RU E, F ALSE}, with TRUE label if the tweet is related to the company and as FALSE otherwise. We are provided with training data corresponding to a set of companies (C T R ). Based on the training data we have the task of training a generic classifier, which should be used to classify the tweets corresponding to a new set of companies (C T est ). We present here two possible ways of designing this generic classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ensemble of Naive Bayes Classifiers:</head><p>We adapt the Naive Bayes Classifier model for this task. For each company in the training set(C T R ), based on the company tweets we find the conditional distribution of values over features for two classes i.e. a class of tweets which are related to the company and another class of tweets which are not related to the company. With these conditional probabilities, shown in equations <ref type="bibr" coords="8,277.85,118.99,13.24,8.74" target="#b0">(2,</ref><ref type="bibr" coords="8,291.08,118.99,8.82,8.74" target="#b1">3)</ref> and by applying Bayes theorem, we can classify an unseen tweet whether it is related to the company or not.</p><p>Let us denote the probability distribution of features of the tweets that are related to a given company with</p><formula xml:id="formula_4" coords="8,262.68,179.16,217.91,9.65">P (f 1 , f 2 , . . . , f n | C),<label>(2)</label></formula><p>and the probability distribution of features of the tweets that are not related to the company with</p><formula xml:id="formula_5" coords="8,262.68,228.96,217.91,9.65">P (f 1 , f 2 , . . . , f n | C).<label>(3)</label></formula><p>Then, for an unseen tweet t, using the features extraction function we compute the features values:(f 1 , f 2 , . . . , f n ). The posterior probabilities of whether the tweet is related to the company or not, are calculated as in equations <ref type="bibr" coords="8,454.29,273.98,11.62,8.74" target="#b2">(4,</ref><ref type="bibr" coords="8,468.97,273.98,7.75,8.74" target="#b3">5)</ref>.</p><formula xml:id="formula_6" coords="8,180.36,306.75,300.23,63.02">P (C | t) = P (C) * P (t | C) P (t) = P (C) * P (f 1 , f 2 , . . . , f n | C) P (f 1 , f 2 , . . . , f n ) (4) P (C | t) = P (C) * P (t | C) P (t) = P (C) * P (f 1 , f 2 , . . . , f n | C) P (f 1 , f 2 , . . . , f n )<label>(5)</label></formula><p>Depending on whether P (C | t) is greater than P (C | t) or not, the naive Bayes classifier decides whether the tweet t is related to the given company or not, respectively.</p><p>Corresponding to each company c i ∈ C T R , we train a naive Bayes classifier <ref type="bibr" coords="8,156.40,430.18,14.42,8.74" target="#b10">[12]</ref> [15], N BC i , for which the input features are tweet specific features F 1 , . . . , F n and heuristics based features U 1 , . . . , U z , as discussed in the section 4.1. Along with training a naive Bayes classifier, we also assign an accuracy measure for this classifier and keep a note of meta features G 1 , . . . , G m of this classifier.</p><p>The generic classifier makes use of ensemble function which either chooses the best classifier or combines the decision of classifiers from this set, to classify an unseen tweet corresponding to a new company i.e. c i ∈ C T est . The ensemble function would make use of the meta-features and accuracy measures to pick up the right classifier or the right combination of classifiers. We refer to <ref type="bibr" coords="8,436.10,538.57,10.52,8.74" target="#b7">[9]</ref>  <ref type="bibr" coords="8,449.89,538.57,15.50,8.74" target="#b19">[21]</ref> for details about the design of such ensemble functions.</p><p>SVM Classifier: Alternatively one could train a single classifier based on all the features: meta-features, tweet-specific features and heuristics-features. This single classifier can be seen as using an ensemble function implicitly in either picking an apt classifier or aptly combing the classifier decisions. In the current work, we train an SVM Classifier <ref type="bibr" coords="8,287.16,632.21,15.01,8.74" target="#b8">[10]</ref>, <ref type="bibr" coords="8,305.91,632.21,15.01,8.74" target="#b14">[16]</ref> as a generic classifier, which makes use of all features: meta-features, tweet-specific features and heuristics-based features, in its classification task.</p><p>Our experimental setup was the following. We are given a general training set, which consists tweets related to about 50 companies (we denote this set as C T R ). For each company c ∈ C T R we are provided around 400 tweets with their corresponding ground truth, i.e. if the tweet is related to the company or not. For each company, we are provided with the following meta-information: URL, Language, Category. We have trained a generic classifier based on this training set. The test set for this task consisted tweets of around 50 new companies. We denote this set of companies as C T est . There was no overlap with the training set, C T R C T est = 0. For each company c ∈ C T est there are about 400 Tweets, which are to be classified. We classified them with our trained generic classifier, as explained in Section 4. The WePS-3 dataset is available at http://nlp.uned.es/weps/weps-3/data.</p><p>The task is of classifying the tweets into two classes: one class which represents the tweets related to the company (positive class) and second class represents tweets that are not related to the company (negative class). For evaluation of the task, the tweets can be grouped into four categories: true positives (T P ), true negatives (T N ), false positives (F P ) and false negatives (F N ). The true positives are the tweets that belong to positive class and in fact belong to the company and the other tweets which are wrongly put in this class are false positives. Similarly for the negative class we have true negatives which are correctly put into this class and the wrong ones of this class are false negatives.</p><p>We use the following metrics to study the performance of our classification process.</p><p>Accuracy = T P +T N T P +F P +T N +F N P recsion (+) = T P T P +F P ; Recall + = T P T P +F N ; F -M easure + = 2 * P recsion + * Recall + P recsion + +Recall + P recsion -= T N T N +F N ; Recall -= T N T N +F P ; F -M easure -= 2 * P recsion - * Recall - P recsion -+Recall -</p><p>In Table <ref type="table" coords="9,189.82,462.45,4.98,8.74" target="#tab_1">2</ref> we show the average values of the different performance metrics, along with the corresponding variances. The results show high accuracy figures for our classifier. The precision and recall values corresponding to positive class can be further increased by refining the profiles corresponding to positive evidence, for example by using more sources to accumulate more relevant keywords and by using efficient quality metrics for rejecting irrelevant keywords. In spite of using very few sources for populating the negative profile of a company, we are still able to have high precision and decent recall values for the negative class. Similarly, by using more sources for negative evidences we can further improve these performance measures.</p><p>Next we study the impact of the different profiles, we have used in the entity representation, on the classification task. We study the importance of the negative-keywords-profile and the category-based profile on the performance of the classification process. We considered the following cases:</p><p>LSIR.EPFL 1 (ALL) We make use of all the profiles of a company the classification process. LSIR.EPFL 2 (No-Neg) We make use of all the profiles except the negativeevidence profile, of a company to classify unseen tweets. LSIR.EPFL 3 (No-Cat) To study the impact of using the category-related profile in the classification process, we make an experiment which uses all the profiles of a company except the profile corresponding to category and common-sense-keywords profile. LSIR.EPFL 4 (Only-HP) Company homepage URL is provided as a representation of the entity. We want to study how accurate the classifier performs when a profile is built only based on the keywords, extracted through crawling the homepage. From the results shown in table <ref type="table" coords="10,293.84,554.83,3.87,8.74" target="#tab_2">3</ref>, it is clear that the homepage URL does provide us some very relevant information for the classification task, however the accuracy is low. The accuracy can be improved if one uses also other sources of information, like negative evidence, category and common sense based keywords.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related work</head><p>The classification of tweets has already been addressed in the literature, in different contexts. Some of the relevant works include <ref type="bibr" coords="10,360.50,656.12,26.15,8.74">[5][18]</ref>[17] <ref type="bibr" coords="10,401.60,656.12,14.94,8.74" target="#b11">[13]</ref>.</p><p>In <ref type="bibr" coords="11,161.73,118.99,9.96,8.74" target="#b3">[5]</ref>, the authors take up the task of classifying the tweets from twitter into predefined set of generic categories such as News, Events, Opinions, Deals and Private Messages. They propose to use a small set of domain-specific features extracted from the tweets and the user's profile. The features of each category are learned from the training set. This task which can be seen as a supervised learning scenario is different from our current task which is a generic learning task.</p><p>The authors in <ref type="bibr" coords="11,217.41,204.90,14.61,8.74" target="#b16">[18]</ref>, build a news processing system based on Twitter. From the twitter stream they build a system that identifies the messages corresponding to late breaking news. Some of the issues they deal with are separating the noise from valid tweets, forming tweet clusters of interest, and identifying the relevant locations associated with the tweets. All these tasks are done in an online manner. They build a naive Bayes classifier for distinguishing relevant news tweets from irrelevant ones. They construct the classifier from a training set. They represent intermediate clusters as a feature vector, and they associate an incoming tweet with cluster if the distance metric to a cluster is less than a given threshold.</p><p>In <ref type="bibr" coords="11,162.93,314.72,15.50,8.74" target="#b11">[13]</ref> and <ref type="bibr" coords="11,202.64,314.72,14.61,8.74" target="#b15">[17]</ref>, the authors make use of twitter for the task of sentiment analysis. They build a sentiment classifier, based on a tweet corpus. Their classifier is able to classify tweets as positive, negative, or neutral sentiments. The papers identify relevant features (presence of emoticons, n-grams), and train the classifier on an annotated training set. Their work is complementary to ours: the techniques proposed in our work could serve as an essential preprocessing step to these sentiment or opinion analysis, which identifies the relevant tweets for the sentiment analysis.</p><p>The paper <ref type="bibr" coords="11,196.81,412.58,15.50,8.74" target="#b17">[19]</ref> proposes a technique to retrieve photos of named entities with high precision, high recall and diversity. The innovation used is query expansion, and aggregate rankings of the query results. Query expansion is done by using the meta information available in the entity description. The query expansion technique is very relevant for our work, it could be used for better entity profile creation.</p><p>Many works based on entity identification and extraction, for example in <ref type="bibr" coords="11,467.31,486.53,9.96,8.74" target="#b2">[4]</ref>, <ref type="bibr" coords="11,134.77,498.48,9.96,8.74" target="#b6">[8]</ref>, <ref type="bibr" coords="11,151.91,498.48,14.61,8.74" target="#b12">[14]</ref>, <ref type="bibr" coords="11,174.06,498.48,14.61,8.74" target="#b19">[21]</ref>, usually make use of the rich context around the entity reference for deciding if the reference relates to the entity. However, in the current work, the tweets which contain the entity references usually have very little context, because of the size-restrictions of tweet messages. Our work addresses these issues, namely how to identify an entity in scenarios where there is very little context information.</p><p>Bishop <ref type="bibr" coords="11,182.98,572.43,10.52,8.74" target="#b4">[6]</ref> discusses various machine learning algorithms for supervised and unsupervised tasks. The task we are addressing in this paper is generic learning, which can be seen as in between supervised and unsupervised learning. Yang et al. <ref type="bibr" coords="11,149.34,608.30,15.50,8.74" target="#b18">[20]</ref> discuss generic learning algorithms for solving the problem of verification of unspecified person. The system learns generic distribution of faces, and intra-personal variations from the available training set, in order to infer the distribution of the unknown new subject, which is very related to the current task. We adapt techniques from <ref type="bibr" coords="11,276.59,656.12,10.52,8.74" target="#b4">[6]</ref> and <ref type="bibr" coords="11,309.80,656.12,10.52,8.74" target="#b7">[9]</ref> for the tweets classification task.</p><p>There are many ways to represent entities. In Okkam <ref type="bibr" coords="12,372.27,118.99,15.57,8.74" target="#b5">[7]</ref> project, which aimed to enable the Web of entities, an entity is represented as a set of attribute-value pairs, along with the meta information related to the evolution of entity, and relationships with other entities. In dbpedia[1] and linked data <ref type="bibr" coords="12,401.11,154.86,12.81,8.74" target="#b0">[2]</ref> the entities are usually represented using RDF models. These rich models are needed for allowing sophisticated querying and inferences. Since we use the entity representation for our classification algorithms, we resort to representing an entity simply as a bag of weighted keywords instead of the rich representations of entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and future work</head><p>Twitter is a real time pulse of the opinions of the people. Researchers have analyzed the twitter streams for different purposes: finding influential tweeters, opinion mining, categorizing tweets, summarizing tweets, etc. In some of these tasks, like opinion and sentiment mining, the classification of the twitters based on entities forms an important preprocessing step, as the accuracy of further analysis depends on this step. In this paper we address the task of classifying tweets based on entities, for which we use a simple entity representation. We realized an efficient classification process with the help of entity profiles, which we constructed using different information sources.</p><p>One can observe that the accuracy of our classification technique depends on the quality of the entity profiles. As future work, we would like to explore other techniques to further improve the quality of the entity profiles, including ensemble techniques <ref type="bibr" coords="12,220.58,397.13,12.58,8.74" target="#b7">[9]</ref>, <ref type="bibr" coords="12,242.16,397.13,14.61,8.74" target="#b19">[21]</ref>. We would also like to explore dynamic ways of adapting the entity profiles, where the information from the twitter stream can be used to add or remove keywords from the entity profiles. Further we think that there is need for efficient quality metrics, similar to the ones used in information retrieval literature <ref type="bibr" coords="12,218.66,444.95,9.96,8.74" target="#b1">[3]</ref>, in order to decide if a particular keyword is relevant or not, to the representation of entity.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,136.16,214.49,350.64,276.13"><head>Table 1 .</head><label>1</label><figDesc>Apple Inc Company Profiles Profile Type Keywords WebPage iphone, ipod, mac, safari, ios, iphoto, iwork, leopard, forum, items, employees, itunes, credit, portable, secure, unix, auditing, forums, mar-User Positive ipad, imac, iphone, ipod, itouch, itv, iad, itunes, keynote, safari, leopard, tiger, iwork, android, droid, phone, app, appstore, mac, macintosh User Negative fruit, tree, eat, bite, juice, pineapple, strawberry, drink</figDesc><table /><note coords="5,203.33,270.55,283.47,7.86;5,203.33,281.51,268.01,7.86;5,136.16,292.87,101.47,7.86;5,150.03,304.23,36.63,7.86;5,203.33,304.23,283.47,7.86;5,203.33,315.19,283.47,7.86;5,203.33,326.14,283.47,7.86;5,203.33,337.10,283.47,7.86;5,203.33,348.06,283.47,7.86;5,203.33,359.02,283.46,7.86;5,203.33,369.98,283.46,7.86;5,203.33,380.94,283.46,7.86;5,203.33,391.90,283.46,7.86;5,203.33,402.86,283.47,7.86;5,203.33,413.82,283.46,7.86;5,203.33,424.77,31.79,7.86;5,147.96,436.13,338.83,7.86;5,203.33,447.09,120.13,7.86"><p>keters, browse, dominicana, music, recommend, preview, type, tell, notif, phone, purchase, manuals, updates, fifa, 8GB, 16GB, 32GB,. . . HTML Metatag {empty} Category opera, code, brainchild, movie, telecom, cruncher, trade, cathode-ray, paper, freight, keyboard, dbm, merchandise, disk, language, microprocessor, move, web, monitor, diskett, show, figure, instrument, board, lade, digit, good, shipment, food, cpu, moving-picture, fluid, consign, contraband, electronic, volume, peripherals, crt, resolve, yield, server, micro, magazine, dreck, byproduct, spiritualist, telecommunications, manage, commodity, flick, vehicle, set, creation, procedure, consequence, second, design, result, mobile, home, processor, spin-off, wander, analog, transmission, cargo, expert, record, database, tube, payload, state, estimate, intersect, internet, print, factory, contrast, outcome, machine, deliver, effect, job, output, release, turnout, convert, river,. . . GoogleSet itunes, intel, belkin, 512mb, sony, hp, canon, powerpc, mac, apple, iphone, ati, microsoft, ibm,. . .</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,174.82,504.04,265.72,114.14"><head>Table 2 .</head><label>2</label><figDesc>Performance of Classifier which makes use of all profiles</figDesc><table coords="9,199.21,524.82,213.86,93.37"><row><cell>Metric</cell><cell cols="2">(Mean)Value Variance</cell></row><row><cell>Accuracy</cell><cell>0.83</cell><cell>0.02</cell></row><row><cell>Precision (positive class)</cell><cell>0.71</cell><cell>0.07</cell></row><row><cell>Recall (positive class)</cell><cell>0.74</cell><cell>0.13</cell></row><row><cell>F-Measure (positive class)</cell><cell>0.63</cell><cell>0.1</cell></row><row><cell>Precision (negative class)</cell><cell>0.84</cell><cell>0.07</cell></row><row><cell>Recall (negative class)</cell><cell>0.52</cell><cell>0.17</cell></row><row><cell>F-Measure (negative class)</cell><cell>0.56</cell><cell>0.15</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,200.82,413.43,210.65,114.14"><head>Table 3 .</head><label>3</label><figDesc>Importance of Different Profiles</figDesc><table coords="10,200.82,434.20,210.65,93.37"><row><cell>Metric</cell><cell cols="3">ALL No-Neg No-Cat Only-HP</cell></row><row><cell>Accuracy</cell><cell>0.83 0.77</cell><cell>0.79</cell><cell>0.66</cell></row><row><cell cols="2">Precision (positive) 0.71 0.81</cell><cell>0.69</cell><cell>0.73</cell></row><row><cell>Recall (positive)</cell><cell>0.74 0.53</cell><cell>0.71</cell><cell>0.27</cell></row><row><cell cols="2">F measure (positive) 0.63 0.56</cell><cell>0.64</cell><cell>0.3</cell></row><row><cell cols="2">Precision (negative) 0.84 0.7</cell><cell>0.86</cell><cell>0.6</cell></row><row><cell>Recall (negative)</cell><cell>0.52 0.83</cell><cell>0.52</cell><cell>0.89</cell></row><row><cell cols="2">F measure (negative) 0.56 0.68</cell><cell>0.56</cell><cell>0.66</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,635.53,84.73,7.47"><p>http://twitter.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,144.73,646.48,254.20,7.47;1,144.73,657.44,234.15,7.47"><p>http://www.telegraph.co.uk/technology/twitter/7297541/ Twitter-users-send-50-million-tweets-per-day.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,144.73,645.84,335.86,7.86;3,144.73,656.80,82.96,7.86"><p>Porter stemmer from python based natural language toolkit available at http://www.nltk.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,144.73,634.88,205.69,7.86"><p>http : //www.w3schools.com/html/html meta.asp</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,144.73,645.84,111.26,7.86"><p>http://labs.google.com/sets</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="4,144.73,656.80,330.15,7.86"><p>http://en.wikipedia.org/wiki/Apple (disambiguation) page contains apple entities</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="5,144.73,656.80,91.90,7.86"><p>http://www.apple.com</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="12,142.96,517.33,169.59,8.12" xml:id="b0">
	<monogr>
		<ptr target="http://linkeddata.org/" />
		<title level="m" coord="12,151.53,517.33,46.71,7.86">Linked data</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,527.69,337.63,7.86;12,151.52,538.65,293.94,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="12,358.44,527.69,118.32,7.86">Modern Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Ricardo</forename><forename type="middle">A</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Berthier</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Addison-Wesley Longman Publishing Co., Inc</publisher>
			<pubPlace>Boston, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,549.01,337.64,7.86;12,151.52,559.97,329.07,7.86;12,151.52,570.93,159.68,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,317.76,549.01,162.83,7.86;12,151.52,559.97,93.27,7.86">Disambiguating web appearances of people in a social network</title>
		<author>
			<persName coords=""><forename type="first">Ron</forename><surname>Bekkerman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,269.02,559.97,211.58,7.86;12,151.52,570.93,67.54,7.86">Proceedings of the 14th international conference on World Wide Web</title>
		<meeting>the 14th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="463" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,581.29,337.63,7.86;12,151.52,592.25,329.07,7.86;12,151.52,603.20,283.55,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,196.94,592.25,267.30,7.86">Short text classification in twitter to improve information filtering</title>
		<author>
			<persName coords=""><forename type="first">Enngin</forename><surname>Demir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hakan</forename><surname>Ferhatosmanoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bharath</forename><surname>Sriram</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Fuhry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Murat</forename><surname>Demirbas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,151.52,603.20,227.13,7.86">Proceedings of the ACM SIGIR 2010 Posters and Demos</title>
		<meeting>the ACM SIGIR 2010 Posters and Demos</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,613.56,337.64,7.86;12,151.52,624.52,329.07,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="12,251.38,613.56,229.21,7.86;12,151.52,624.52,89.17,7.86">Pattern Recognition and Machine Learning (Information Science and Statistics)</title>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer-Verlag New York, Inc</publisher>
			<pubPlace>Secaucus, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,634.88,337.64,7.86;12,151.52,645.84,329.07,7.86;12,151.52,656.80,267.51,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,389.14,634.88,91.45,7.86;12,151.52,645.84,205.83,7.86">Okkam: Towards a solution to the &quot;identity crisis&quot; on the semantic web</title>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Bouquet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heiko</forename><surname>Stoermer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Giacomuzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,392.67,645.84,87.92,7.86;12,151.52,656.80,184.91,7.86">Proceedings of SWAP 2006, the 3rd Italian Semantic Web Workshop</title>
		<meeting>SWAP 2006, the 3rd Italian Semantic Web Workshop</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="18" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,119.67,337.64,7.86;13,151.52,130.63,329.07,7.86;13,151.52,141.59,329.07,7.86;13,151.52,152.55,20.99,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,405.41,119.67,75.19,7.86;13,151.52,130.63,232.48,7.86">Exploiting context analysis for combining multiple entity resolution systems</title>
		<author>
			<persName coords=""><forename type="first">Zhaoqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dmitri</forename><forename type="middle">V</forename><surname>Kalashnikov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sharad</forename><surname>Mehrotra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,407.09,130.63,73.50,7.86;13,151.52,141.59,260.70,7.86">Proceedings of the 35th SIGMOD international conference on Management of data</title>
		<meeting>the 35th SIGMOD international conference on Management of data</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="207" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,163.51,337.63,7.86;13,151.52,174.47,329.07,7.86;13,151.52,185.43,329.07,7.86;13,151.52,196.39,99.47,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,352.22,163.51,128.37,7.86;13,151.52,174.47,22.06,7.86">Ensembles of region based classifiers</title>
		<author>
			<persName coords=""><forename type="first">Sungha</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Byungwoo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jihoon</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,198.80,174.47,281.79,7.86;13,151.52,185.43,152.90,7.86">CIT &apos;07: Proceedings of the 7th IEEE International Conference on Computer and Information Technology</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="41" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,207.34,337.98,7.86;13,151.52,218.30,329.07,7.86" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Nello</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<title level="m" coord="13,322.56,207.34,158.03,7.86;13,151.52,218.30,184.39,7.86">An Introduction to Support Vector Machines and other kernel-based learning methods</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,229.26,337.98,7.86;13,151.52,240.22,329.07,7.86;13,151.52,251.18,316.93,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,230.10,240.22,250.49,7.86;13,151.52,251.18,52.93,7.86">Outtweeting the Twitterers -Predicting Information Cascades in Microblogs</title>
		<author>
			<persName coords=""><forename type="first">Wojciech</forename><surname>Galuba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karl</forename><surname>Aberer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dipanjan</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zoran</forename><surname>Despotovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wolfgang</forename><surname>Kellerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,224.28,251.18,215.05,7.86">3rd Workshop on Online Social Networks (WOSN&apos;10)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,262.14,337.98,7.86;13,151.52,273.10,147.22,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,227.53,262.14,178.53,7.86">A tutorial on learning with bayesian networks</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Heckerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,151.52,273.10,118.69,7.86">Learning in Graphical Models</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="13,142.62,284.06,337.98,7.86;13,151.52,295.02,329.07,7.86;13,151.52,305.98,88.26,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,375.21,284.06,105.38,7.86;13,151.52,295.02,96.58,7.86">Twitter power: Tweets as electronic word of mouth</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">J</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Sobel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chowdury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,255.82,295.02,224.77,7.86;13,151.52,305.98,59.98,7.86">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,316.93,337.97,7.86;13,151.52,327.89,329.07,7.86;13,151.52,338.85,237.06,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,151.52,327.89,180.13,7.86">Web People Search via Connection Analysis</title>
		<author>
			<persName coords=""><forename type="first">Dmitri</forename><forename type="middle">V</forename><surname>Kalashnikov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhaoqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sharad</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rabia</forename><surname>Nuray-Turan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,342.14,327.89,138.45,7.86;13,151.52,338.85,88.35,7.86">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1550" to="1565" />
			<date type="published" when="2008-11">November 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,349.81,337.97,7.86;13,151.52,360.77,197.01,7.86" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="13,219.43,349.81,261.16,7.86;13,151.52,360.77,51.01,7.86">Naive (bayes) at forty: The independence assumption in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Springer Verlag</publisher>
			<biblScope unit="page" from="4" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,371.73,337.98,7.86;13,151.52,382.69,329.07,7.86;13,151.52,393.65,104.80,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="13,385.43,371.73,95.17,7.86;13,151.52,382.69,95.77,7.86">Similarity Measures for Short Segments of Text</title>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Susan</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,270.56,382.69,139.84,7.86">Advances in Information Retrieval</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4425</biblScope>
			<biblScope unit="page" from="16" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,404.61,337.97,7.86;13,151.52,415.56,329.07,7.86;13,151.52,426.52,329.07,7.86;13,151.52,437.48,169.05,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="13,310.03,404.61,170.56,7.86;13,151.52,415.56,74.92,7.86">Twitter as a corpus for sentiment analysis and opinion mining</title>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><surname>Pak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>Paroubek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,244.18,415.56,236.41,7.86;13,151.52,426.52,173.22,7.86">Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC&apos;10)</title>
		<meeting>the Seventh conference on International Language Resources and Evaluation (LREC&apos;10)<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA</publisher>
			<date type="published" when="2010-05">May 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,448.44,337.97,7.86;13,151.52,459.40,329.07,7.86;13,151.52,470.36,329.07,7.86;13,151.52,481.32,280.84,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="13,250.33,459.40,115.82,7.86">Twitterstand: news in tweets</title>
		<author>
			<persName coords=""><forename type="first">Jagan</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hanan</forename><surname>Samet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><forename type="middle">E</forename><surname>Teitler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><forename type="middle">D</forename><surname>Lieberman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jon</forename><surname>Sperling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,386.12,459.40,94.47,7.86;13,151.52,470.36,329.07,7.86;13,151.52,481.32,81.65,7.86">GIS &apos;09: Proceedings of the 17th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="42" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,492.28,337.98,7.86;13,151.52,503.24,329.07,7.86;13,151.52,514.19,329.07,7.86;13,151.52,525.15,67.83,7.86" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="13,386.80,492.28,93.79,7.86;13,151.52,503.24,276.85,7.86">Gathering and ranking photos of named entities with high precision, high recall, and diversity</title>
		<author>
			<persName coords=""><forename type="first">Bilyana</forename><surname>Taneva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mouna</forename><surname>Kacimi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<editor>Brian D. Davison, Torsten Suel, Nick Craswell, and Bing Liu</editor>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="431" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,536.11,337.97,7.86;13,151.52,547.07,329.07,7.86;13,151.52,558.03,261.70,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="13,347.28,536.11,133.31,7.86;13,151.52,547.07,325.44,7.86">Incorporating generic learning to design discriminative classifier adaptable for unknown subject in face verification</title>
		<author>
			<persName coords=""><forename type="first">Qiong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaoqing</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,151.52,558.03,210.90,7.86">Computer Vision and Pattern Recognition Workshop</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page">32</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,568.99,337.97,7.86;13,151.52,579.95,329.07,7.86;13,151.52,590.91,329.07,7.86;13,151.52,601.87,75.36,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="13,391.45,568.99,89.14,7.86;13,151.52,579.95,202.62,7.86">Towards better entity resolution techniques for Web document collections</title>
		<author>
			<persName coords=""><forename type="first">Surender</forename><surname>Reddy Yerva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zoltán</forename><surname>Miklós</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karl</forename><surname>Aberer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,371.40,579.95,109.19,7.86;13,151.52,590.91,329.07,7.86;13,151.52,601.87,46.63,7.86">1st International Workshop on Data Engineering meets the Semantic Web (DESWeb&apos;2010) (co-located with ICDE&apos;2010)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
