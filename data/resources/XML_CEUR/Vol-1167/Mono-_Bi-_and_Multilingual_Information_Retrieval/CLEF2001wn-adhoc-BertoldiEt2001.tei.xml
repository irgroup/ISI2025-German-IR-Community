<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,230.28,40.26,145.43,12.91;1,198.12,58.14,209.87,12.91">ITC-irst at CLEF 2001: Monolingual and Bilingual Tracks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,205.32,86.65,77.36,10.76"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ITC-irst -Centro per la Ricerca Scientifica e Tecnologica</orgName>
								<address>
									<postCode>38050</postCode>
									<settlement>Povo, Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,307.92,86.65,92.86,10.76"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ITC-irst -Centro per la Ricerca Scientifica e Tecnologica</orgName>
								<address>
									<postCode>38050</postCode>
									<settlement>Povo, Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,230.28,40.26,145.43,12.91;1,198.12,58.14,209.87,12.91">ITC-irst at CLEF 2001: Monolingual and Bilingual Tracks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">68EF015BCA9E5846CF7B0BFDD6268557</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports on the participation of ITC-irst in the Cross Language Evaluation Forum (CLEF) of 2001. ITC-irst has taken part to two tracks: the monolingual retrieval task, and the bilingual retrieval task. In both cases, Italian was chosen as the query language, while English was chosen as the document language of the bilingual task. The employed retrieval engine combines scores computed by an Okapi model and a statistical language model. The cross language system employes a statistical query translation model, which is estimated on the target document collection and on a translation dictionary.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This paper reports on the participation of ITCirst in two Information Retrieval (IR) tracks of the Cross Language Evaluation Forum (CLEF) 2001: the monolingual retrieval task, and the bilingual retrieval task. The language for the queries was always Italian, and English documents were searched for in the bilingual task. With respect to the 2000 CLEF evaluation <ref type="bibr" coords="1,105.72,344.34,116.60,8.97" target="#b0">(Bertoldi and Federico, 2000)</ref>, the monolingual IR system was just slightly refined, while most of the effort was dedicated to develop an original crosslanguage IR system. The basic IR engine, used for both evaluations, combines scores of a standard Okapi model and of a statistical language model. For cross-language IR, a light-weight statistical model for translating queries was developed, which does not need any parallel or comparable corpora to be trained, but just the target document collection and a bilingual dictionary. This paper is organized as follows. In Section 2, the employed text pre-processing modules are presented. Section 3 describes the employed IR models, Section 4 introduces the cross-language specific models, namely the query translation model and the retrieval model. Section 5 presents the official evaluation results. Finally, Section 6 gives some conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Text Pre-Processing</head><p>Text pre-processing is performed in several stages, which may differ according to the task and language. In the following a list of modules used to pre-process documents and queries is given, by also specifying to which languages they apply.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Tokenization -IT+EN</head><p>Text tokenization is performed in order to isolate words from punctuation marks, recognize abbreviations and acronyms, correct possible word splits across lines, and discriminate between accents and quotation marks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Morphological analysis -IT</head><p>A morphological analyzer decomposes each Italian inflected word into its morphemes, and suggests all possible POSs and base forms of each valid decomposition. By base forms we mean the usual not inflected entries of a dictionary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">POS tagging -IT</head><p>Words in a text are tagged with parts-of-speech (POS) by computing the best text-POS alignment through a statistical model. The employed tagger works with 57 tag classes and has an accuracy around 96%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Base form extraction -IT</head><p>Once the POS and the morphological analysis of each word in the text is computed, a base form can be assigned to each word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Stemming -EN</head><p>Word stemming is just performed on English words by using the Porter's algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.">Stop-terms removal -IT+EN</head><p>Words that are not considered relevant for IR are discarded in order to save index space. Words are filtered out on the basis either of their POS (if available) or their inverted document frequency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7.">Multi-word recognition -EN</head><p>Multi-words are just used for the sake of the query translation. Hence, the statistics used by the translation models do contain multi-words. After translation, multi-words are split into single words. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>¢¡ ¤£ ¥¡ ¤¦</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Information Retrieval Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Okapi Model</head><p>To score the relevance of a document versus a query § , the following Okapi weighting function is applied:</p><formula xml:id="formula_0" coords="2,113.40,238.45,180.70,27.20">0 1 32 4 % 65 87 @9 BA ! " § ¡ DC A B E GF<label>(1)</label></formula><p>where:</p><formula xml:id="formula_1" coords="2,95.40,283.75,198.70,38.50">C A H2 ! " I¡ QP 1R HS UT P R V @T XW `Y S $P R aY Db dc A e f g S $! " #¡ (2)</formula><p>scores the relevance of in , and the inverted document frequency:</p><p>G GF 32 ih qp sr ! tW `! u% vS "w Ix y ! % S $w Dx y</p><p>(3) evaluates the relevance of term inside the collec- tion. The model implies two parameters P R and Y to be empirically estimated over a development sample.</p><p>As in previous work, the setting P R 2 T sx y and Y 2 w Dx were used. An explanation of the involved terms can be found in <ref type="bibr" coords="2,131.28,450.42,94.40,8.97" target="#b7">(Robertson et al., 1994)</ref> and other papers referred in it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Language Model</head><p>According to this model, the match between a query random variable and a document random variable ¦ is expressed through the following conditional probability distribution:</p><formula xml:id="formula_2" coords="2,83.28,537.55,210.82,65.95">B ¦ ' 2 ' ¦ ¦ (4) where B ' ¦ represents the likelihood of , given ¦ , ¦</formula><p>represents the a-priori probability of ¦ , and is a normalization term. By assuming a uniform a-priori probability distribution about the documents, and disregarding the normalization factor, documents can be ranked, with respect to , just by the likelihood term B ' ¦ . If we assume an order-free multinomial model, the likelihood is:</p><formula xml:id="formula_3" coords="2,98.50,665.85,195.63,43.30">s $ © d G e gf ih j k sl m e n o p 8 q o f rk sl (5)</formula><p>The probability that a term is generated by can be estimated by a statistical language model (LM). Previous work on statistical information retrieval <ref type="bibr" coords="2,494.52,204.54,28.22,8.97;2,312.00,216.54,48.37,8.97" target="#b2">(Miller et al., 1998;</ref><ref type="bibr" coords="2,363.84,216.54,41.24,8.97" target="#b4">Ng, 1999)</ref> proposed to interpolate relative frequencies of each document with those of the whole collection, with interpolation weights empirically estimated from the data. In this work we use an interpolation formula which applies the smoothing method proposed by <ref type="bibr" coords="2,492.72,276.30,30.07,8.97;2,312.00,288.18,59.12,8.97" target="#b8">(Witten and Bell, 1991)</ref>. This method linearly smoothes word frequencies of a document, and the amount of probability assigned to never observed terms is proportional to the number of different words contained in the document, i.e.:</p><formula xml:id="formula_4" coords="2,325.20,340.75,197.53,41.86">s q sf ak sl t u qk G Hl u qk sl #v f w H qk sl f v f w H qk sl f u qk sl Iv $f w x qk sl f q l (6)</formula><p>where B</p><p>, the word probability over the collection, is estimated by interpolating the smoothed relative frequency with the uniform distribution over the vocabulary : 8 q Hl m u q Hl u v f w f v f w f u v "f w zyf w Hf (7)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Combined model</head><p>Previous work <ref type="bibr" coords="2,371.76,484.02,118.28,8.97" target="#b0">(Bertoldi and Federico, 2000)</ref> showed that Okapi and the statistical model rank documents almost independently. Hence, information about the relevant documents can be gained by integrating the scores of both methods. Combination of the two models is implemented by just taking the sum of scores. Actually, in order to adjust scale differences, scores of each model are normalized in the range { w ¡ T a| before summation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Blind Relevance Feedback</head><p>Blind relevance feedback (BRF) is a well known technique that allows to improve retrieval performance. The basic idea is to perform retrieval in two steps. First, the documents matching the original query § are ranked, then the } best ranked documents are taken and the ~most relevant terms in them are added to the query. Hence, the retrieval phase is repeated with the augmented query. In this work, new search terms are extracted by sorting all the terms of the } top documents according to (Johnson et al.,   1999):</p><p>% % S $w Dx y ! W `! % W } S % S $w Dx y ! u% W r% S $w Dx y } W i% vS $w Dx y</p><formula xml:id="formula_5" coords="3,282.48,73.98,11.62,8.97">(8)</formula><p>where i%</p><p>is the number of documents, among the top } documents, which contain word . In all the per- formed experiments the values } 2 y and ~2 T iy were used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Cross-language IR Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Query Translation Model</head><p>Query translation is based on a hidden Markov model (HMM) <ref type="bibr" coords="3,116.88,207.06,60.44,8.97" target="#b6">(Rabiner, 1990)</ref>, in which the observable part is the query in the source language (Italian), and the hidden part is the corresponding query £ in the target language (English). Hence, the joint probability of a pair ¢¡ ¤£ can be decomposed as follows:</p><formula xml:id="formula_6" coords="3,109.60,264.75,184.50,53.80">B 2 U R ¡ x ax ax ¡ @ G ¡ @£ U2 U R ¡ x ax rx ¡ ¤ ) D 2 2 n © R ' B ' i R (9)</formula><p>Given a query 2 R ¡ x ax rx ¡ ¤ E and estimates of the discrete distributions in the right side of equation ( <ref type="formula" coords="3,283.48,343.86,3.53,8.97">9</ref>), the most probable translation £ X2 U V R ¡ x rx ax ¡ d V can be determined through the well known Viterbi algorithm <ref type="bibr" coords="3,83.28,379.74,60.44,8.97" target="#b6">(Rabiner, 1990)</ref>. Probabilities B ' ) are estimated from a translation dictionary as follows:</p><formula xml:id="formula_7" coords="3,163.10,400.25,130.94,30.10">' 2 d¡ d U q E ¡ ¤ (10)</formula><p>where d¡ d d2 T if the English term is one of the translations of Italian term and ¡ ¤ $2 w otherwise. For the CLEF evaluation an Italian-English dictionary of about 45K entries was used.</p><p>Probabilities ' are estimated on the target document collection, through the following bigram LM, that tries to compensate for different word orderings induced by the source and target languages:</p><formula xml:id="formula_8" coords="3,138.30,541.35,155.74,30.20">B ' 2 B 1¡ ¤ 1¡ ¤ (11)</formula><p>where B 1¡ ¤ is the probability of co-occurring with , regardless of the order, within a text window of fixed size. Smoothing of the probability is performed through absolute discounting and interpolation as follows:</p><formula xml:id="formula_9" coords="3,83.70,643.75,210.36,46.60">s E © ql m ` a 1 # ) l t u ¡ ¢ £v v s al E 8 © ¤l (12) ¥ 1¡ ¤</formula><p>is the number of co-occurrences appearing in the corpus, B )</p><p>is estimated according to equation ( <ref type="formula" coords="3,315.53,22.38,3.53,8.97">7</ref>), and the absolute discounting term ¦ is equal to the estimate proposed in <ref type="bibr" coords="3,411.60,34.38,68.24,8.97" target="#b3">(Ney et al., 1994)</ref>:</p><formula xml:id="formula_10" coords="3,387.60,36.75,135.16,36.60">¦ 2 § R § R S ©¨ § mª (13)</formula><p>with § representing the number of term pairs occur- ring exactly P times in the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Cross-Language IR Model</head><p>As a first method to perform cross-language retrieval, a simple plug-in method was devised, which decouples the translation and retrieval phases. Hence, given a query in the source language, the Viterbi decoding algorithm is applied to compute the most probable translation £ in the target language, according to the statistical query translation model explained above. Then, the document collection is searched by applying a conventional monolingual IR method.</p><p>1. Find the best translation of query :</p><p>£ 2 U« s¬ ¤r 3 ¢« V® ¯ ¢¡ @£ 2. Order documents by using the translation £ Table <ref type="table" coords="3,347.64,289.26,3.88,8.97">2</ref>: Plug-in method for cross-language IR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Monolingual Track</head><p>Two monolingual runs were submitted to the Italian monolingual track. The first run used all the information available for the topics, while the second one just the title and description parts. The track consisted of 47 topics, for a total of 1,246 documents to be retrieved inside a collection of 108,578 documents. A detailed description of the used system follows now:</p><p>°Document/query pre-processing: tokenization, POS tagging, base form extraction, stop-term removal.</p><p>°Retrieval step 1: separate Okapi and LM runs. °BRF: performed on each model output. °Retrieval step 2: same as step 1 with the expanded query.</p><p>°Final rank: sum of Okapi and LM normalized scores.</p><p>Results of the submitted runs are given in Table <ref type="table" coords="3,504.12,604.02,3.74,8.97" target="#tab_1">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Bilingual IR Evaluation</head><p>Two runs were submitted to the Italian-to-English bilingual track, with the same modalities of the monolingual track. The bilingual track consisted of 47 topics, for a total of 856 documents to be retrieved inside a collection of 110,282 documents. A detailed description of the used system follows now: °Final rank: sum of Okapi and LM normalized scores.</p><p>An important issue concerns with the use of multiwords. Multi-words were only used for the target language, i.e. English, and just for the translation process. After translation, multi-words in the query are split again into single words. As a term of comparison, our statistical query translation model was replaced with the Babelfish text translation service powered by Systran and available on the Internet<ref type="foot" coords="4,130.08,516.78,3.49,6.28" target="#foot_0">1</ref> . Cross-language retrieval performance was measured by keeping all the other components of the system fixed. Results obtained by the submitted runs and by the Babelfish translator are shown in Table <ref type="table" coords="4,108.48,566.22,3.74,8.97">4</ref>. The mean average precision achieved with the commercial translation system shows to be about 5%-10% better, depending to the retrieval mode. Detailed results of the experiments are shown in Table <ref type="table" coords="4,286.68,602.10,3.74,8.97">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this work we presented the monolingual and crosslanguage information retrieval systems developed at ITC-irst and evaluated at the CLEF 2001. In particular, the cross-language system uses a statistical query translation algorithm that requires minimal language resources: a bilingual dictionary and the target document collection. Results on the CLEF 2001 evaluation data show that satisfactory performance can be achieved with this simple translation model. However, experience gained from the many performed experiments suggest that a fair comparison between different systems would require a much larger amount of queries. The retrieval performance shows in fact to be very sensitive to the translation step. Current work is in the direction of further developing the here proposed statistical model for crosslanguage IR. In particular, significant improvements have been achieved by closely integrating the translation and retrieval models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,105.40,20.45,356.28,127.17"><head>Table 1 :</head><label>1</label><figDesc>List of often used symbols.</figDesc><table coords="2,105.40,20.45,356.28,105.33"><row><cell>§ ¡ ¤©¡ ¤ ¡ ¤ ¡ ¤</cell><cell>random variables of query, translation, and document instances of query, query translation, and document generic term, Italian term, English term</cell></row><row><cell></cell><cell>collection of documents</cell></row><row><cell>, ! ¡ ! " ! " ©¡ ! " #¡ ©¡ ! $  § ¡ ! &amp;% ' )( '</cell><cell>set of terms occurring in number of term occurrences in , and in document , and in a document frequency of term in , in document , and in query  § number of documents in which contain term size of a set</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,83.28,21.18,211.04,359.85"><head>Table 3 :</head><label>3</label><figDesc>Results on the Italian monolingual tracks.</figDesc><table coords="4,83.28,21.18,211.04,289.17"><row><cell cols="3">Retrieval Mode Official Run mAvPr</cell></row><row><cell cols="2">title+desc+narr IRSTit1</cell><cell>48.59</cell></row><row><cell>title+desc</cell><cell>IRSTit2</cell><cell>46.44</cell></row><row><cell>Retrieval Mode</cell><cell>Official Runs</cell><cell>mAvPr</cell></row><row><cell>title+desc+narr</cell><cell>IRSTit2en1</cell><cell>42.51</cell></row><row><cell>title+desc</cell><cell>IRSTit2en2</cell><cell>34.11</cell></row><row><cell cols="3">Retrieval Mode Non Official Runs mAvPr</cell></row><row><cell>title+desc+narr</cell><cell>Babelfish</cell><cell>44.53</cell></row><row><cell>title+desc</cell><cell>Babelfish</cell><cell>37.99</cell></row><row><cell cols="3">Table 4: Results on the Italian-English bilingual</cell></row><row><cell>tracks.</cell><cell></cell><cell></cell></row><row><cell cols="3">°Document pre-processing: tokenization, stem-ming, stop-term removal. °Query pre-processing: tokenization, POS tag-</cell></row><row><cell cols="3">ging, base form extraction, stop term removal,</cell></row><row><cell cols="3">translation, multi-words split, stemming.</cell></row></table><note coords="4,93.90,297.35,45.53,16.60;4,141.72,320.94,145.41,8.97;4,93.90,316.95,31.02,16.60;4,127.32,340.50,132.59,8.97;4,93.90,336.55,45.53,16.60;4,143.40,360.06,150.74,8.97;4,103.32,372.06,56.01,8.97"><p>°Retrieval step 1: separate Okapi and LM runs. °BRF: performed on each model output. °Retrieval step 2: same as step 1 with the expanded query.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,99.48,699.14,91.98,8.07"><p>http://world.altavista.com</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The authors would like to thank their colleagues at <rs type="institution">ITC-irst</rs> <rs type="person">Bernardo Magnini</rs> and <rs type="person">Emanuele Pianta</rs> for putting at disposal an electronic Italian-English dictionary.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="4,312.00,304.62,210.74,8.97;4,321.84,316.50,200.85,8.97;4,321.84,328.50,154.45,8.97" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,464.64,304.62,58.10,8.97;4,321.84,316.50,142.95,8.97">Italian text retrieval for CLEF 2000 at ITC-irst</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,489.36,316.50,33.33,8.97;4,321.84,328.50,78.72,8.97">Working notes of CLEF 2000</title>
		<meeting><address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,312.00,340.98,210.71,8.97;4,321.84,352.86,200.86,8.97;4,321.84,364.86,200.89,8.97;4,321.84,376.74,104.70,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,397.68,352.86,125.02,8.97;4,321.84,364.86,134.12,8.97">Spoken document retrieval for TREC-8 at Cambridge University</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Jourlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Spark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">C</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Woodland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,475.08,364.86,47.65,8.97;4,321.84,376.74,21.67,8.97">Proc. of 8th TREC</title>
		<meeting>of 8th TREC<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,312.00,389.22,210.67,8.97;4,321.84,401.22,200.88,8.97;4,321.84,413.10,200.77,8.97;4,321.84,425.10,130.26,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,392.52,401.22,130.20,8.97;4,321.84,413.10,161.31,8.97">BBN at TREC-7: Using hidden Markov models for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">R H</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tim</forename><surname>Leek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><forename type="middle">M</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,501.24,413.10,21.38,8.97;4,321.84,425.10,47.11,8.97">Proc. of 7th TREC</title>
		<meeting>of 7th TREC<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,312.01,437.58,210.81,8.97;4,321.85,449.46,200.83,8.97;4,321.85,461.46,201.06,8.97;4,321.85,473.46,92.33,8.97" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,348.25,449.46,174.43,8.97;4,321.85,461.46,120.45,8.97">On structuring probabilistic dependences in stochastic language modelling</title>
		<author>
			<persName coords=""><forename type="first">Herman</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ute</forename><surname>Essen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Reinhard</forename><surname>Kneser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,451.57,461.46,71.34,8.97;4,321.85,473.46,55.25,8.97">Computer Speech and Language</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,312.01,485.82,210.75,8.97;4,321.85,497.82,200.85,8.97" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,392.89,485.82,129.87,8.97;4,321.85,497.82,101.31,8.97">A maximum likelihood ratio information retrieval model</title>
		<author>
			<persName coords=""><forename type="first">Kenney</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,444.13,497.82,73.15,8.97">Proc. of 8th TREC</title>
		<meeting>of 8th TREC</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,321.85,509.82,75.18,8.97" xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Gaithersburg</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,312.01,522.18,210.69,8.97;4,321.85,534.18,200.83,8.97;4,321.85,546.18,200.84,8.97;4,321.85,558.06,200.82,8.97;4,321.85,570.06,189.04,8.97" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,444.73,522.18,77.97,8.97;4,321.85,534.18,200.83,8.97;4,321.85,546.18,74.96,8.97">A tutorial on hidden Markov models and selected applications in speech recognition</title>
		<author>
			<persName coords=""><forename type="first">Lawrence</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,369.49,558.06,130.61,8.97">Readings in Speech Recognition</title>
		<editor>
			<persName><forename type="first">Alex</forename><surname>Weibel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kay-Fu</forename><surname>Lee</surname></persName>
		</editor>
		<meeting><address><addrLine>Los Altos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="267" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,312.01,582.54,210.67,8.97;4,321.85,594.42,200.87,8.97;4,321.85,606.42,201.15,8.97;4,321.85,618.42,18.54,8.97" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,498.37,594.42,24.35,8.97;4,321.85,606.42,41.63,8.97">Okapi at TREC-3</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,385.45,606.42,74.35,8.97">Proc. of 3rd TREC</title>
		<meeting>of 3rd TREC<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,312.01,630.78,210.66,8.97;4,321.85,642.78,200.90,8.97;4,321.85,654.78,200.86,8.97;4,321.85,666.66,177.03,8.97" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="4,484.21,630.78,38.46,8.97;4,321.85,642.78,200.90,8.97;4,321.85,654.78,169.41,8.97">The zerofrequency problem: Estimating the probabilities of novel events in adaptive text compression</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Timothy</forename><forename type="middle">C</forename><surname>Bell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,501.13,654.78,21.58,8.97;4,321.85,666.66,86.05,8.97">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1085" to="1094" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
