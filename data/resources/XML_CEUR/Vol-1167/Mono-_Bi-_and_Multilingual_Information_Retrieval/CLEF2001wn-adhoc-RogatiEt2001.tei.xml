<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,97.20,72.62,373.52,15.41">CMU PRF using a Comparable Corpus: CLEF Working Notes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,126.24,88.49,58.76,10.89"><forename type="first">Monica</forename><surname>Rogati</surname></persName>
							<email>mrogati@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,97.20,72.62,373.52,15.41">CMU PRF using a Comparable Corpus: CLEF Working Notes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3862E3E083C38FA94C4A06C11AF10DA5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We applied a PRF (Pseudo-Relevance Feedback) system, for both the monolingual task and the German(-&gt;English task. We focused on the effects of extracting a comparable corpus from the given newspaper data; our corpus doubled the average precision when used together with the provided parallel corpus. The PRF performance was lower for the queries with few relevant documents. We also examined the effects of the PRF first-step retrieval in the source language half of the parallel corpus vs. the entire document collection .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>For its first year at CLEF, the CMU group applied a PRF (Pseudo-Relevance Feedback) system, for both the monolingual task and the German-&gt;English task. We focused on the effects of extracting a comparable corpus from the given newspaper data; our corpus doubled the average precision when used together with the provided parallel corpus. The PRF performance was lower for the queries with few relevant documents. We also examined the effects of the PRF first-step retrieval in the source language half of the parallel corpus (official runs), when compared to the entire document collection (unofficial runs). This provides a relative upper bound (modulo the document collection) for the bilingual PRF method, since the entire collection is not available as bilingual text.</p><p>Section 2 briefly presents the PRF system; section 3 discusses the comparable corpus, and section 4 details the experimental setup and results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The CMU Pseudo-Relevance Feedback system</head><p>The Pseudo-Relevance Feedback procedure is well known approach to query expansion in Information Retrieval. Its uses for both monolingual and translingual IR have been previously explored <ref type="bibr" coords="1,423.26,410.57,10.45,10.89" target="#b2">[3]</ref>. For the monolingual case, the algorithm assumes the top K retrieved documents are relevant and expands the original query using words selected from these documents. To cross the language barrier using PRF, a parallel bilingual collection is used for retrieval in the query (source) language, followed by query expansion/substitution using the corresponding documents in the target language.</p><p>A good parallel collection that closely matches the statistical profile of the target collection is essential for the success of this method. Given such a collection, the parameters that need to be tuned are the number of top relevant document used (K) , the number of words in the new query (E) and the weighting scheme for the retrieval engine (in our case, SMART). Section 4 contains more details about the experimental setup and the parameter values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The comparable corpus</head><p>Intrigued by the IBM success in TREC 7 &amp; 8 in the CLIR track <ref type="bibr" coords="1,334.14,562.25,10.45,10.89" target="#b0">[1]</ref>, we adapted their approach to the extraction of a comparable corpus.</p><p>A web-based parallel collection was provided by the CLEF organizers; however, we believed that a parallel corpus that closely matched the document collection would be beneficial to the PRF performance. In the absence of such corpus, a comparable corpus that is derived from the given German and English newspapers could still be a useful resource. To obtain such a corpus, we used the statistical machine translation-based methodologies from IBM <ref type="bibr" coords="1,63.60,631.37,10.45,10.89" target="#b0">[1]</ref>, adapted to our own resources and goals. As our results section shows, the comparable corpus doubled the 11-pt. average precision on the 2001 CLEF queries.</p><p>The fundamental assumption that underlines the generation of the comparable corpus is that the data itself is "comparable"; more specifically, that the articles in the newspapers contain the same events and ideas. This proved to be somehow difficult with the CLEF data, where the articles come from newspapers with very different characteristics. A similar mismatch has been previously observed when using the SDA data; we believe the LA Times/German newspapers mismatch to be more pronounced. The results are even more encouraging when this mismatch is taken into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The algorithm for generating the comparable corpus</head><p>1) Divide the German and English newspaper articles into overlapping N days long windows.</p><p>2) Initialize a dictionary (similarity thesaurus) D 3) While the results are improving, a. For each window, i. Break the articles into fixed-size (P) paragraphs ii. Do a word-by-word translation of the paragraphs, using dictionary D and fertility F<ref type="foot" coords="2,499.20,197.33,3.24,7.17" target="#foot_0">1</ref> iii. Use each paragraph in one language as a query, and retrieve the top matching paragraph among the ones in the other language iv. Repeat, switching languages v. If two paragraphs retrieved each other with a score above a certain threshold S, consider them "mates" and add them to the comparable corpus C b. Extract a dictionary D' from C using CHI-SQUARED (see below) as a similarity measure between words c. D = D'</p><p>The CHI-SQUARED statistic is measure we found useful in several contexts, which captures the crosslingual lexical associations based on co-occurrence in the training corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CHI-SQUARED (t,s) = N(AD-BC) 2 /[(A+C)(A+B)(D+B)(D+C)]</head><p>where t = term in the target language s = term in the source language N = number of document pairs A = number of documents where t occurs in the target language document and s occurs in the corresponding source language document B = number of documents where t occurs in the target language document and s DOES NOT occur in the corresponding source language document C = number of documents where t DOES NOT occur in the target language document and s occurs in the corresponding source language document D = N-A-B-C</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Setup and Results</head><p>We used the Porter stemmer and the SMART stopword list for the English collection. For the German collection, we used Morphix <ref type="bibr" coords="2,178.75,559.85,11.47,10.89" target="#b1">[2]</ref> as a German stemmer / compound analysis tool. We also used a short corpusderived German stopword list. Morphix significantly improved the performance in the early stages of system development , and was used in all subsequent experiments.</p><p>The PRF parameters were tuned using the CLEF-200 data. Good empirical values were 15-25 for K (number of top documents considered relevant), 200-300 for E (number of query words after expansion), and ltc and ntc term weighting. The same values proved to be best for the CLEF-2001 queries, with the exception of the term weighting scheme (ntc performed significantly worse than ltc on the new queries).</p><p>We used one week windows overlapping by half when generating the comparable corpus, because some of the newspapers were published weekly and a more fine-grained distinction was not needed. The best results were obtained when the starting dictionary was not initialized (i.e. the first retrieval step was based on names and cognates). The resulting corpus had cca. 20000 paragraph pairs. A paragraph size of 250 bytes (plus the bytes necessary to keep the entire last word) worked best.</p><p>The quality of the comparable corpus was fairly low (most paragraphs were far from being translations of each other). This is understandable given that the only thing linking the German and English articles was the time period; the culture, continent and the newspapers' political goals and interpretations were different. The monolingual runs were obtained by using the German (source language) half of the parallel corpus for the first retrieval step, in order to be consistent with the bilingual runs and provide a collection-dependent upper bound for them. Subsequent experiments revealed a significant difference between this procedure and the one using the entire collection (see figure below). Another important factor that affected our performance was the number of relevant documents. When a query only has one or two relevant documents, the basic assumption of the PRF idea is violated. Specifically, PRF assumes the first K documents to be relevant, which is false for at least 75% of the CLEF-2001 queries (if K&gt;=20), even with a perfect search engine. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Official runs and results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>precision and the number of relevant documents</head><p>Our method's sensitivity to the low number of relevant documents is illustrated in the figure above, where PRF is compared to the best method for each query. The correlation between the fictional "best" method and the number of relevant documents was practically non-existent (-0.07), while CMU-PRF was comparatively more affected by the low number of relevant documents (the correlation is 0.26). We do not know how the individual runs from which the best result was selected were affected by the low number of relevant documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Unofficial results and experiments</head><p>After the release of the relevance judgments, we conducted several experiments to examine the effect different parameters had on the bilingual PRF system. The most impressive was the gain obtained from using the comparable corpus in addition to the given parallel corpus (the performance was doubled). The number of documents used for query expansion did not significantly affect the average precision, although the effects on individual queries remain to be examined. The fixed paragraph size of the comparable corpus was another important factor. Paragraphs that were too short produced unreliable co-occurrence statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>The most important finding in our experiments was the effect of the comparable corpus had on the average performance of the PRF method. Since the quality and quantity of parallel or comparable text is crucial to this method, we plan to gather more such data from the web. Preliminary results showed improvements over the official and unofficial CLEF runs and will be discussed elsewhere. We are also planning to expand our CLEF toolkit to other methods previously implemented at CMU, such as GVSM, LSI, EBT and LLSF <ref type="bibr" coords="6,197.77,201.29,10.45,10.89" target="#b2">[3]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,163.44,521.69,268.12,10.89"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Monolingual Performance Using the Entire Collection</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,120.48,223.13,353.93,10.89"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2:Correlations between avg. precision and the number of relevant documents</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,170.16,616.25,255.04,10.89"><head>Figure 4 :</head><label>4</label><figDesc>Figure 3: The Comparable Corpus Doubles the Performance</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,190.32,418.01,214.28,10.89"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Figure 5: The effect of two term weighting schemes</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,69.18,679.37,437.53,10.89;2,63.60,690.89,55.74,10.89"><p>The fertility is the number of words used to translate one word in the other language. This is different for every language pair.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,97.99,251.69,398.69,10.89;6,81.60,263.21,86.63,10.89" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,158.12,251.69,212.84,10.89">Ad hoc and Multilingual Information Retrieval at IBM</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,389.28,251.69,107.40,10.89;6,81.60,263.21,86.63,10.89">The Seventh Text REtrieval Conference (TREC-8)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,95.53,274.73,378.26,10.89" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Neumann</surname></persName>
		</author>
		<ptr target="http://www.dfki.de/~neumann/morphix/morphix.html" />
		<title level="m" coord="6,150.74,274.73,105.83,10.89">Morphix Software Package</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,95.53,286.25,420.58,10.89;6,81.60,297.77,101.12,10.89" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,152.92,286.25,271.97,10.89">Translingual Information Retrieval: Learning from Bilingual Corpora</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,107.56,297.77,75.16,10.89">Best of IJCAI 1997</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,95.53,309.29,423.99,10.89;6,81.60,320.81,408.59,10.89;6,81.60,332.33,36.07,10.89" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,184.48,309.29,244.06,10.89">Query Expansion Using Local and Global Document Analysis</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,445.73,309.29,73.79,10.89;6,81.60,320.81,408.59,10.89;6,81.60,332.33,36.07,10.89">Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
