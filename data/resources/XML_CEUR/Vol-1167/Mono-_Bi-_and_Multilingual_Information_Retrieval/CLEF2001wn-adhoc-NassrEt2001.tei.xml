<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,225.60,138.99,47.46,16.00"><forename type="first">N</forename><surname>Nassr</surname></persName>
							<email>fnassr@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="department">IRIT/SIG</orgName>
								<orgName type="institution">Campus Univ. Toulouse III</orgName>
								<address>
									<addrLine>118, Route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse Cedex</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,283.68,138.99,93.36,16.00"><forename type="first">M</forename><surname>Boughanem</surname></persName>
							<email>boughaneg@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="department">IRIT/SIG</orgName>
								<orgName type="institution">Campus Univ. Toulouse III</orgName>
								<address>
									<addrLine>118, Route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse Cedex</settlement>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">25A05038AC5B3BAC049A3EDB42CDB972</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the experiments undertaken by our team (IRIT team) in multilingual, bilingual and monolingual tasks at CLEF programme. Our approach to CLIR is based on query translation. In bilingual experiment a dictionary is used to translate the queries from French t o English and two techniques for desambiguiation were tested: aligned corpus and dictionary strategy. D e s a m biguiation technique is applied to select the best terms from the (translated) targed queries. All these experiments were done using Mercure system 2] which is presented in section 2 of this paper. The section 3 describes our general CLIR methodology, and nally, section 4 describes experiments and results performed at CLEF programme.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2 Mercure model</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Model description</head><p>Mercure is an information retrieval system based on a connectionist approach and modelled by a m ulti-layered network. The network is composed of a query layer (set of query terms), a term layer representing the indexing terms and a document l a yer 1], 2]. Mercure includes the implementation of a retrieval process based on spreading activation forward and backward through the weighted links. Queries and documents can be either inputs or outputs of the network.The links between two l a yers are symmetric and their weights are based on the tf idf measure inspired from the OKAPI 3] term weighting formula. the term-document l i n k w eights are expressed by:</p><formula xml:id="formula_0" coords="1,234.48,591.87,278.40,36.96">d ij = tf ij (h 1 + h 2 log( N ni )) h 3 + h 4 dlj d + h 5 tf ij<label>(1)</label></formula><p>the query-term (at stage s) links are weighted as follows:</p><p>q (s) ui = nqu qtfui nqu;qtfui si (nq u &gt; q t f ui ) qtf ui otherwise</p><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query evaluation</head><p>A query is evaluated using the spreading activation process described as follows :</p><p>1. The query Q u is the input of the network. Each node from the term layer computes an input value from this initial query: I n (t i ) = q ui and then an activation value : Out(t i ) = g(I n (t i )) where g is the identity function. 2. These signals are propagated forwards through the network from the term layer to the document l a yer. Each document node computes an input : I n (d j ) = P T i=1 Out(t i ) w ij and then an activation , Out(d j ) = RSV (Q u d j ) = g(I n (d j )): Notations : T : the total number of indexing terms, N : the total number of documents, q ui : t h e w eight of the term t i in the query u, t i : the term t i , d j : the document d j , w ij : the weight of the link between the term t i and the document d j , dl j : document length in words (without stop words), d: a verage document length, tf ij : the term frequency of t i in the document d j , n i : t h e n umb e r o f d o c u m e n ts containing term t i , nq u : the query length, (number of unique terms) qtf ui : query term frequency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">General Clir Methodology</head><p>Our CLIR approach is based on query translation. It is illustrated by three main steps: Indexing, Translation and Dismabiguation described as follows:</p><p>Indexing : a separate index is built for the documents in each language. English words are stemmed using Porter algorithm, French w ords are stemmed using a truncature (7 rst characters), no stemming for the German, Italian and Spanish words. The German, Italian and Spanish stoplists were downloaded from Internet.</p><p>Translation : is based on \dictionaries". For the CLEF2 experiments, ve bilingual dictionaries were used all of which w ere actually simply a list of terms in language l1 that were paired with some equivalent terms in language l2. Desambiguiation: w h e n m ultiple translations exist for a given term, desambiguiation was performed by selecting the bests target query terms equivalent for each source query term.</p><p>Two strategies of desambiguiation were tested. The rst one is based on aligned corpus and the second one is based on dictionary. The rst desambiguiation based on aligned corpus consist of:</p><p>1. Retrieving the top documents (X=20) for each source query term t i in aligned corpus. 2. Retrieving the top documents (X'=20) for each translation t ij for t i in the same aligned corpus. t ij is one translation for t i among another. 3. Desambiguiation of the translated query consist of matching the retrieval documents (pro les) from the di erent translation against the source query pro le. The best terms are the terms which h a ve the best matchnig.</p><p>The second desambiguiation based on dictionary is described as follows :</p><p>1. Each source query term t i is translated in target language using bilingual dictionary. 2. Each translation t ij from t i is transalted in source language using bilingual dictionary. t ij is the one translation for t 1 among another. 3. The desambiguiation of the transalted query consist of retaining only target terms that return the source query term.</p><p>However if a speci c term has an unique substitution this term is retained in all cases.</p><p>4 Experiment and Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Multilingual experiment</head><p>One run iritmuEn2A using English topics and retrieving documents from the pool of documents in all four languages (German, French, Italian, Spanish and English), was submitted. The queries were translated using the downloaded dictionaries. No desambiguiation, all the translated words were retained in the target queries. The run was performed by doing individual runs for pair languages and merging the results to form the nal ranked list. Table <ref type="table" coords="3,121.44,571.47,5.04,14.40" target="#tab_2">2</ref> shows the results of pair languages (example, E2F means English queries translated to French and compared to French documents, etc.). We can easily notice that the monolingual (E2E) search performs much more better than all the pair (E2F, E2G, E2I, E2S) searches. Moreover, all the pair searches have their average precision better than the multilingual search. The merging strategy caused the loss of relevant documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Bilingual experiment</head><p>Two runs using French topics and retrieving documents from the pool of document in English language, were submitted. The bilingual experiment w as carried on using French to English free dictionary + desambiguiation. Two desambiguiation strategies were tested :</p><p>Aligned corpus strategy : desambiguiation based on aligned corpus was performed using WAC ( W ord-wide-web Aligned Corpus) parallel corpus built by RALI Lab (http://wwwrali.iro.umontreal.ca/wac/). (English-French) dictionary strategy: desmabiguiation based on dictionary was performed using free (English-French) dictionary. T able 1, shows the source and the number of entries in (English-French) dictionary.</p><p>Two r u n s w ere submitted: irit1bFr2En where desambiguiation based on dictionary and irit2bFr2En where desmabiguiation based on aligned corpus</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>O cial results</head><p>Run-Id P5 P10 P15 P30 Excat Avg.Prec. irit1bFr2En 0.3660 0.2979 0.2468 0.1844 0.3258 0.3294. irit2bFr2En 0.3787 0.2957 0.2440 0.1794 0.3250 0.3398.  <ref type="table" coords="4,118.56,497.07,5.04,14.40" target="#tab_4">4</ref> compares the results between the runs irit1bFr2En and irit2bFr2En (Dictionary+desambiguiation) and Dictionary only. It can be seen that the desambiguiation based on aligned corpus is better than the dictionary and the desambiguiation based on dictionary. The desambiguiation based on aligned corpus is e ective t h e a verage precision improves of 4%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Monolingual experiments</head><p>Four runs were submitted in monolingualtasks : iritmonoFR, iritmonoIT,iritmonoGE, iritmonoSP</p><p>Table <ref type="table" coords="4,120.48,603.15,5.04,14.40" target="#tab_5">5</ref> shows that French monolingual results seem to be better than both Italian, Spanish and the German. Italian results are better than Spanish and German. Spanish results are better than German. These runs were done using exactly the same procedures the only di erence concerns the stemming which w as used only for French. We notice clearly that the monolingual search i s much better than both the multilingual and the bilingual searches.</p><p>Run </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper we h a ve presented, our experiments for CLIR at CLEF programme. In multilingual IR, we s h o wed that the merging strategy caused the loss of relevant documents, In bilingual IR, we showed that the desambiguiation technique based on aligned corpus for translated queries is e ective. Results of experiments have also showed that using free dictionaries are fesaible, and desambiguiation based on aligned corpus give the good results even though the documents of aligned corpus are independent from those of database.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,114.96,509.79,397.92,112.32"><head>Table 1</head><label>1</label><figDesc>, shows the source and the numb e r o f e n tries in each dictionary.</figDesc><table coords="2,200.88,544.59,201.12,77.52"><row><cell>Type Source</cell><cell>nb. entries</cell></row><row><cell cols="2">E2F http://www.freedict.com 42443 E2G http://www.freedict.com 87951 E2I http://www.freedict.com 13478 E2S http://www.freedict.com 20700 F2E http://www.freedict.com 35200</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,223.20,629.55,156.24,14.40"><head>Table 1 :</head><label>1</label><figDesc>Dictionaries characteristics</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,121.44,442.83,360.00,109.20"><head>Table 2 :</head><label>2</label><figDesc>Comparison results of pair search a n d m ultilingual list</figDesc><table coords="3,121.44,442.83,360.00,87.36"><row><cell>-Id iritmuEn2A(50 queries) 0.4040 0.3520 0.3173 0.2760 0.1509 0.1039 P5 P10 P15 P30 Exact Avg. Prec. Pair language P5 P10 P15 P30 Exact Avg. Prec. E2F (49 queries) 0.2204 0.2102 0.1823 0.1415 0.2005 0.2044 E2S (49 queries) 0.3633 0.3265 0.3116 0.2537 0.2589 0.2281 E2I (47 queries) 0.1872 0.1596 0.1475 0.1255 0.1320 0.1321 E2E (47 queries) 0.5149 0.4085 0.3518 0.2716 0.4564 0.4863</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,90.00,250.11,422.88,203.76"><head>Table 3 :</head><label>3</label><figDesc>Comparison between the desmabiguiation strategies Table3compares the desambiguiation strategies. It can be seen that the desambiguiation based on aligned corpus is slightly better than the desambiguation based on dictionary at average precison but no di erence at excat precision.</figDesc><table coords="4,90.00,332.67,378.72,121.20"><row><cell>Non o cial results</cell></row><row><cell>Run-id (33 queries) P5 irit1bFr2En 0.2638 0.1915 0.1660 0.1312 0.2304 0.2375 P10 P15 P30 Exact Avg.Prec Dico 0.3660 0.2936 0.2397 0.1809 0.3161 0.3305 Impr (%) -27,92 -34.77 -30,74 -27.47 -27.11 -28.13 irit2bFr2En 0.3787 0.3043 0.2496 0.1851 0.3249 0.3436 Dico 0.3660 0.2936 0.2397 0.1809 0.3161 0.3305 Impr (%) 3.46 3.64 4.13 2.32 2.78 4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,90.00,461.31,298.56,50.16"><head>Table 4 :</head><label>4</label><figDesc>Impact of the desambiguiationTable</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,110.64,56.43,381.36,84.48"><head>Table 5 :</head><label>5</label><figDesc>47 queries) 0.4723 0.3894 0.3574 0.2730 0.3568 0.3491 iritmonoGE GE (49 queries) 0.4327 0.3816 0.3442 0.2884 0.2736 0.2632 iritmonoSP SP (49 queries) 0.4694 0.4347 0.4082 0.3626 0.3356 0.3459 Comparison between monolingual search</figDesc><table coords="5,110.64,56.43,381.36,38.88"><row><cell>-id (33 queries) iritmonoFR FR (49 queries) 0.4286 0.3898 0.3483 0.2830 0.3565 0.3700 P5 P10 P15 P30 Exact Avg. Prec. iritmonoIT IT (</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,105.60,316.83,407.52,14.40;5,105.60,328.59,388.32,14.40" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,311.76,316.83,201.36,14.40;5,105.60,328.59,150.76,14.40">Query modi cation based on relevance backpropagation in Adhoc environment</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Boughanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Chrisment</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Soule-Dupuy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,264.24,328.59,172.61,14.40">Information Processing and Managment</title>
		<imprint>
			<date type="published" when="1999-04">April 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.60,348.51,407.52,14.40;5,105.60,360.51,407.52,14.40;5,105.60,372.51,154.08,14.40" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,324.96,348.51,75.16,14.40">Mercure at trec7</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Boughanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Dkaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mothe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Soule-Dupuy</surname></persName>
		</author>
		<idno>NIST SP 500-236</idno>
	</analytic>
	<monogr>
		<title level="m" coord="5,409.44,348.51,103.68,14.40;5,105.60,360.51,234.64,14.40">Proceedings of the 7th International Conference on Text REtrieval TREC7</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>the 7th International Conference on Text REtrieval TREC7</meeting>
		<imprint>
			<date type="published" when="1997-11">Nov. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.60,392.43,407.52,14.40;5,105.60,404.43,327.84,14.40" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,239.04,392.43,34.15,14.40">TREC-6</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Okapi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,283.44,392.43,229.68,14.40;5,105.60,404.43,98.32,14.40">Proceedings of the 6th International Conference on Text REtrieval TREC6</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>the 6th International Conference on Text REtrieval TREC6</meeting>
		<imprint>
			<publisher>NIST SP</publisher>
			<date type="published" when="1997-11">Nov. 1997</date>
			<biblScope unit="page" from="500" to="236" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
