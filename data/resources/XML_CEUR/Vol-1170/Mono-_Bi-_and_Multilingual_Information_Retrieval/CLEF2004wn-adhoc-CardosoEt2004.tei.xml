<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,191.64,160.73,227.88,20.74">The XLDB Group at CLEF 2004</title>
				<funder ref="#_yE76Wky #_xDkEUuh">
					<orgName type="full">Portuguese Fundação para a Ciência e Tecnologia</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,190.32,194.39,67.03,14.41"><forename type="first">Nuno</forename><surname>Cardoso</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Grupo XLDB -Departamento de Informática Faculdade de Ciências</orgName>
								<orgName type="institution">Universidade de Lisboa {ncardoso</orgName>
								<address>
									<settlement>mjs</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,265.70,194.39,67.14,14.41"><forename type="first">Mário</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Grupo XLDB -Departamento de Informática Faculdade de Ciências</orgName>
								<orgName type="institution">Universidade de Lisboa {ncardoso</orgName>
								<address>
									<settlement>mjs</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,355.96,194.39,64.62,14.41"><forename type="first">Miguel</forename><surname>Costa</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Grupo XLDB -Departamento de Informática Faculdade de Ciências</orgName>
								<orgName type="institution">Universidade de Lisboa {ncardoso</orgName>
								<address>
									<settlement>mjs</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,191.64,160.73,227.88,20.74">The XLDB Group at CLEF 2004</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B960555C543576915B0D53B0E96A11C8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of the XLDB Group in the Monolingual IR task for the Portuguese language. We present tumba!, a Portuguese search engine, and we describe its architecture and asumptions. We discuss the way we used tumba! in CLEF, detailing the submitted runs and our experiments with ranking algorithms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In 2004, for the first time, CLEF included Portuguese document collections for Monolingual &amp; Bilingual Information Retrieval and Question Answering tasks. This collection <ref type="bibr" coords="1,151.18,414.51,16.66,12.00" target="#b12">[14]</ref> was based on news of several categories taken from Publico [13], a Portuguese newspaper, and compiled by Linguateca <ref type="bibr" coords="1,296.54,426.39,10.60,12.00" target="#b6">[7]</ref>. This year, the XLDB Group made its debut participation in CLEF.</p><p>This paper is organized as follows: in Section 2, we introduce the XLDB Group. In section 3, we describe tumba!, our IR system, and the modifications we made to it to handle the CLEF 2004 data set. Section 4 describes the official runs with the implemented algorithms for CLEF 2004, and Section 5 presents our results. 6 summarizes a conclusion of our participation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The XLDB Group</head><p>The XLDB Group is a research unit of LaSIGE (Large Scale Information Systems Laboratory) at FCUL -Faculdade de Ciências da Universidade de Lisboa. We research data management systems for data analysis, information integration and user access to large quantities of complex data from heterogeneous platforms. Current research lines span Web search, mobile data access, temporal web data management and bioinformatics.</p><p>The XLDB Group is involved in several projects and activities. One of our main projects is tumba! <ref type="bibr" coords="1,209.68,625.83,10.78,12.00" target="#b7">[8,</ref><ref type="bibr" coords="1,223.70,625.83,11.86,12.00" target="#b13">15]</ref>, a Portuguese Web search engine. Tumba! is described in Section 3.</p><p>The XLDB Group hosts a node of Linguateca, a distributed language resource center for Portuguese, since January 2004 <ref type="bibr" coords="1,288.76,661.59,10.60,12.00" target="#b5">[6]</ref>. The participation of the XLDB Group in the Monolingual Task for Portuguese language, with the tumba! search engine, was motivated by two main reasons:</p><p>1. Although we had previous experiences in evaluation contests, namely in the biotext task of the KDD Cup 02 <ref type="bibr" coords="2,277.79,298.11,11.75,12.00" target="#b3">[4]</ref> and in the BioCreative workshop <ref type="bibr" coords="2,427.50,298.11,10.60,12.00" target="#b4">[5]</ref>, this was our first opportunity for evaluating tumba! jointly with other IR systems, with the advantage of the evaluation being conducted on a Portuguese collection.</p><p>2. Although we were aware that our system was out of its natural environment, the Web, we could take the opportunity to tune the indexing and ranking engines of tumba!, by submitting our results using different ranking configurations and then analyzing the results.</p><p>3 Tumba in the Monolingual Task</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview of tumba!</head><p>Tumba! is a search engine specially crafted to archive and provide search services to a community Web formed by those interested in subjects related to Portugal and the Portuguese people <ref type="bibr" coords="2,210.86,476.79,10.60,12.00" target="#b7">[8]</ref>. Tumba! is being offered as a public service since November 2002.</p><p>Tumba is mainly written in Java and built on open-source software, such as the Linux operating system. It has an index of over 3.5 million Web documents and a daily traffic of up to 20.000 queries per day. Its response time is less than 0.5 seconds for 95% of the requests. It is also a platform for PhD and MSc research projects at our university.</p><p>Tumba! has a similar architecture to global search engines and adopts many of the algorithms used by them <ref type="bibr" coords="2,235.32,572.43,10.60,12.00" target="#b0">[1]</ref>. However, its configuration data is much richer in its domain of specialisation. Tumba! has a better knowledge of the location and organization of Portuguese Web sites (both in qualitative and quantitative terms) <ref type="bibr" coords="2,403.62,596.43,15.33,12.00" target="#b13">[15]</ref>.</p><p>The data flows from the Web to the user through a pipeline of the following tumba! sub-systems (See Figure <ref type="figure" coords="2,233.53,620.31,3.72,12.01" target="#fig_0">1</ref>): Crawlers: collect documents from the Web, given an initial URL list. They parse and extract URLs from each document, which will be used to collect new documents. These steps are performed recursively until a stop condition is met <ref type="bibr" coords="2,425.57,663.51,15.24,12.00" target="#b9">[10]</ref>.</p><p>Web Repository: The Web data collected by the crawlers is stored in Versus, a repository of Web documents and associated meta-data <ref type="bibr" coords="3,358.80,137.55,10.60,12.00" target="#b8">[9]</ref>.</p><p>Indexing system: the indexing system Sidra creates indexes over the documents in the Web Repository <ref type="bibr" coords="3,240.03,168.99,10.60,12.00" target="#b2">[3]</ref>, so that when a query is received, Sidra uses the indexes built to find the documents that match that query.</p><p>Ranking system: computes, for each document d returned by the indexing system, a similarity value between d and the submitted query using a set of heuristics. Then, it sorts the documents by these similarities.</p><p>Presentation Engine: formats the result sets received from the ranking engine for the user's access platforms such as Web browsers, PDA devices or WAP phones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Portuguese Monolingual Task</head><p>The previous CLEF tasks showed that the top performing groups for Monolingual IR tasks were systems which performed robust stemming, well-known weighting schemes (BM25, Lnu.ltn or Berkeley ranking) and blind feedback or query expansion <ref type="bibr" coords="3,458.00,326.91,15.33,12.00" target="#b11">[12]</ref>. Tumba's system doesn't have a stemmer and a blind feedback or query expansion system, and the term weighting scheme is tuned for Web searches. Still, we decided that tumba! should suffer no architectural change to be used in this evaluation. We wanted to evaluate tumba!'s performance with its current components, so that we could have a baseline for comparison on future CLEF tasks. Nonetheless, we felt that our participation in CLEF would provide us with valuable ideas to optimize our search engine results, and resources to evaluate our system performance.</p><p>One of the difficulties we encountered on the CLEF Monolingual task was related to the SGML-format used on collection of Portuguese documents. The documents have tags for associated metadata like author, category and date of publication. The contents are in plain text, with no additional tags. Tumba! was not conceived to work with document collections organized like this. Its ranking system was developed to profit from annotations extracted from the Web documents, such as:</p><p>• Information obtained from the Web graph, like links and anchor text, which are a valuable resource to find related pages that might interest the user;</p><p>• Documents' structural elements like titles and headings, which provide valuable information of the document subject.</p><p>We used the same alghorithms designed for the Web in CLEF, despite the different search context. The lack of this kind of "light semantic" annotation in the collection was a major handicap for the tumba! system, since the only semantic information we managed to extract from the documents was the news' titles. Our heuristic for extracting documents? titles consisted in finding paragraphs in the collection with a maximum of 15 terms and ending with no punctuation. We disabled the query-independent ranking calculations and most of the emphasis ranking augmenters of the Indexing and Ranking system, since there wasn't such information on the collection. Tumba's Crawlers and Presentation Engine weren't used for the CLEF Portuguese Monolingual IR task. We loaded the document collection directly into the Web Repository, bypassing the system's crawlers. The collection was then indexed by the Sidra Indexing system. Queries were sent directly to Sidra, bypassing the Presentation Engine, and the matching documents were then ranked according to some heuristics to compute document relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Runs</head><p>The Monolingual IR task limited, for groups in their first participation, the number of submitted runs to 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Manual Run (XLDBTumba01)</head><p>Since this was the first time that CLEF used Portuguese collections in an evaluation campaign, this task didn't have previous relevant judgements and training collections. In order to have a prior evaluation of tumba!, we created our own baseline against which we could compare our runs to measure how much we were improving our system.</p><p>For each one of the 50 given topics, we created several different queries related to the topic and we used them to retrieve documents matching the query terms. Then, the returned results were manually examined by two doctoral students, with some IR systems usage experience but unfamiliar with the tumba! system, and classified the documents as relevant or irrelevant according to the topic criteria. This was a laborious work, which consumed most of the time for this task.</p><p>After that, we compiled a list of the relevant documents and submitted it to CLEF as our run XLDBTumba01, to measure the offset of our baseline compared to the CLEF solutions.</p><p>When the relevant judgements were released by CLEF, we observed that we had many errors in our manual review; from incorrect topic interpretation to bad query formulation. In the end, this was the run that had the worst performance. Yet, this run clearly showed to us how difficult it is to formulate queries that correctly match an information need.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Flat Ranking Run (XLDBTumba02)</head><p>For subsequent runs, we chose among the different queries used to create the XLDB-Tumba01 run to select which 50 queries would be used on the remaining runs. Note that we didn't use more than one query per topic, neither did any kind of query expansion.</p><p>This run was produced by submitting the 50 queries directly to the Sidra Indexing and Ranking system, configured to perform an exact matching (flat-ranking algorithm), returning only the documents that match all the query terms.</p><p>We see this run as our automatic baseline run, and we were anticipating that the other runs would improve precision and recall compared to this run. Yet, this run outperformed all the other runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Distances Run (XLDBTumba05)</head><p>This run was generated using the following ranking algorithm:</p><p>• distMinTerms(d,q) -uses the minimum distances between any pair of query terms q in documents d, minDist, to increase the ranking of documents whose query terms are closer on the document. For distances above 10, the function gives similarity 0 to the document. If all query terms are adjacent on a document, their minDist value equals 1.</p><formula xml:id="formula_0" coords="5,183.72,243.99,237.65,45.96">distMinTerms(d, q) =    1 minDist = 1 1 -minDist-1 9 1 &lt; minDist &lt; 10 0 minDist ≥ 10</formula><p>This function indeed improved the results accordingly to our own evaluation, as the queries with more than one term we used for the topic tend to be adjacent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Distances + Titles Run (XLDBTumba04)</head><p>This run was generated by using two ranking algorithms in Sidra:</p><formula xml:id="formula_1" coords="5,148.68,369.75,83.55,11.90">• distMinTerms(d,q)</formula><p>• termsInTitle(d,q) -this is a similarity function between the terms in the title of each document d, denoted T, and the query terms in a query q, denoted Q.</p><formula xml:id="formula_2" coords="5,234.72,430.95,140.36,25.46">termsInTitle(d, q) = |T ∩ Q| max(|T |, |Q|)</formula><p>This run evaluated the importance of the title in the document ranking, and turned out as the one with the worst performance in our self-evaluation. This was probably caused by the heuristic used to extract titles from the documents, which was a very naive approach and may have mislead the ranking engine. The tumba! search engine gives great importance to title texts, as many people search named entities on search engines and these are usually clearly stated in the titles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>For a prior evaluation of our automatic runs, we compared the results with manual run XLDBTumba01. We used precision@1, precision@3, precision@10, recall and F-Measure (β = 1) metrics in our self-evaluation. The results are summarized in Table <ref type="table" coords="5,133.80,615.75,3.77,12.01" target="#tab_0">1</ref>.</p><p>The results obtained in CLEF are presented on Table <ref type="table" coords="5,362.17,627.63,5.03,12.01" target="#tab_1">2</ref> and Figure <ref type="figure" coords="5,415.27,627.63,3.77,12.01" target="#fig_1">2</ref>. The Average Precision (non-interpolated) for all relevant documents and the R-Precision (precision after R documents retrieved) are the measures presented by the trec_eval program. <ref type="bibr" coords="5,466.27,651.63,3.59,12.01">[</ref>  The XLDBTumba02, XLDBTumba05 and XLDBTumba04 runs have the same overall precision and recall values, because we used the same queries which retrieved the same documents, differing only in the order on which the documents were submitted for each topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We used the Web search engine tumba! in the CLEF 2004 Monolingual task for the Portuguese language. Our main objective was to test, compare, and improve the quality of tumba's results, and gather ideas on how to do it. However, the enviroment that we work on, the Web, is different from the flat and small collection of document texts that we used on the CLEF task.</p><p>As we didn't have a baseline of relevant judgements, we manually annotated relevant and non relevant documents for the 50 topics. We found that this task is not easy. It is time consuming and requires experienced human annotators to review hundreds of documents, cross the results and eliminate erroneous judgements. The other submitted runs used combinations of two algorithms used on the tumba! ranking engine. We did our own evaluation with several metrics based on our own relevance judgements, and submitted 4 runs for CLEF evaluation. We presented both evaluations in this paper.</p><p>Tumba! does not perform stemming or query expansion and relies heavily on detecting the presence of query terms in document titles and URLs. As these were not available for this evaluation, the performance of tumba! was below average when compared to other systems. During the creation of the XLDBTumba01 run and while analysing our results together with the CLEF relevant judgements, we realized that in many cases, a simple query couldn't retrieve all the relevant documents. Take for instance, topic #204, for retrieving documents concerning avalanche victims. In the Portuguese Monolingual task, this topic had 7 relevant judgements, which contained the relevant words of the 'avalanche' noun and the 'morrer' verb (to die) / 'morte' (death) family shown in Table <ref type="table" coords="7,133.80,410.79,3.77,12.01" target="#tab_2">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word</head><p>Rel We can see that it would be impossible on a system like tumba! to achieve a good recall value with a query containing 'avalanche' 'morte' terms only. This is a situation that is not uncommon and systems must be able to deal with it. We intend to extend our Web search system to provide much better results in situations where the documents are not rich in HTML features, such as hyperlinks and meta-tags. Tumba! is effective in named-page finding tasks, in particular when these have properly chosen titles and have multiple links, but needs to become more effective on supporting other queries as well.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,245.40,224.91,120.58,12.00"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: tumba's architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,157.56,306.99,295.84,12.00"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Recall-Precision Values for our runs, according to CLEF results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,133.80,651.63,343.25,23.88"><head>Table 1 :</head><label>1</label><figDesc>Automatic Submitted Runs, compared to the Manual Run XLDBTumba01</figDesc><table coords="5,469.87,651.63,7.19,12.00"><row><cell>2,</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,209.64,358.95,191.81,12.00"><head>Table 2 :</head><label>2</label><figDesc>XLDB official runs evaluated by CLEF</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,148.68,431.55,313.69,169.57"><head>Table 3 :</head><label>3</label><figDesc>Relevant words in the relevant documents of the topic 204</figDesc><table coords="7,148.68,431.55,313.69,138.01"><row><cell></cell><cell></cell><cell cols="5">#1 Rel #2 Rel #3 Rel #4 Rel #5 Rel #6 Rel #7</cell></row><row><cell>avalanche</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell></row><row><cell>avalanches</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell></cell><cell>x</cell></row><row><cell>avalancha</cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell></row><row><cell>mortos</cell><cell>x</cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell></row><row><cell>mortas</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell></row><row><cell>morte</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell></row><row><cell>morreu</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell></row><row><cell>morreram</cell><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell></row><row><cell>morrido</cell><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell></row><row><cell>mata</cell><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7">Acknowledgements</head><p>We would like to thank to <rs type="person">Bruno Martins</rs> and <rs type="person">Daniel Gomes</rs> for making changes on tumba! components for the CLEF task and their valuable comments, <rs type="person">Marcírio Chaves</rs> and <rs type="person">Lauro Nakayama</rs> for their manual retrieval and judgement of the documents for the XLDBTumba01 run, and <rs type="person">Diana Santos</rs> and <rs type="person">Luís Costa</rs> for their valuable suggestions and comments.</p><p>This work was financed by the <rs type="funder">Portuguese Fundação para a Ciência e Tecnologia</rs> through grant <rs type="grantNumber">POSI / PLP / 43931 / 2001</rs> (Linguateca) and by grant <rs type="grantNumber">POSI / SRI / 40193 / 2001</rs> (<rs type="projectName">XMLBase</rs> Project).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_yE76Wky">
					<idno type="grant-number">POSI / PLP / 43931 / 2001</idno>
				</org>
				<org type="funded-project" xml:id="_xDkEUuh">
					<idno type="grant-number">POSI / SRI / 40193 / 2001</idno>
					<orgName type="project" subtype="full">XMLBase</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,155.38,344.07,321.68,12.00;8,155.40,356.07,321.90,12.00;8,155.40,369.20,235.37,10.80" xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">Arvind</forename><surname>Arasu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Junghoo</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hector</forename><surname>Garcia-Molina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andreas</forename><surname>Paepcke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sriram</forename><surname>Raghavan</surname></persName>
		</author>
		<ptr target="http://www.acm.org/pubs/contents/journals/toit" />
	</analytic>
	<monogr>
		<title level="j" coord="8,228.03,356.07,75.83,11.90">Searching the Web</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2" to="43" />
			<date type="published" when="2001-08">August 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,155.39,387.03,321.86,12.00;8,155.40,399.03,321.84,12.00;8,155.40,410.91,296.37,12.00" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,301.28,387.03,175.96,12.00;8,155.40,399.03,321.84,12.00;8,155.40,410.91,66.10,12.00">CLEF 2002 Methodology and Metrics, Advances in Cross-Language Information Retrieval: Results of the CLEF 2002 Evaluation Campaign</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="8,229.70,410.91,139.09,11.90">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">2758</biblScope>
			<date type="published" when="2003">Spring 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,155.39,429.99,321.87,12.00;8,155.40,441.87,321.82,12.00;8,155.40,453.87,322.03,12.00;8,155.40,465.75,22.64,12.00" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,301.41,429.99,175.85,12.00;8,155.40,441.87,149.53,12.00">Sidra: a Flexible Distributed Indexing and Ranking Architecture for Web Search</title>
		<author>
			<persName coords=""><forename type="first">Miguel</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mário</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,323.69,441.87,153.54,11.90;8,155.40,453.87,202.93,11.90">Proceedings of the VIII Conference on Software Engineering and Databases JISBD 2003</title>
		<meeting>the VIII Conference on Software Engineering and Databases JISBD 2003<address><addrLine>Alicante, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-11">November 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,155.38,484.83,321.73,12.00;8,155.40,496.71,321.86,12.00;8,155.40,508.71,321.93,12.01" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,441.15,484.83,35.97,12.00;8,155.40,496.71,317.67,12.00">Classifying Biomedical Articles using Web Resources: application to KDD Cup 02</title>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><surname>Couto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bruno</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mário</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Coutinho</surname></persName>
		</author>
		<idno>DI/FCUL TR 03-24</idno>
		<imprint>
			<date type="published" when="2003-07">July 2003</date>
		</imprint>
		<respStmt>
			<orgName>Department of Informatics, University of Lisbon</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="8,155.38,527.79,321.96,12.00;8,155.40,539.67,321.59,12.00;8,155.40,551.67,199.56,12.00" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,363.72,527.79,113.62,12.00;8,155.40,539.67,165.46,12.00">Finding Genomic Ontology Terms in Text using Information Content</title>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><surname>Couto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mário</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Coutinho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,454.92,539.67,22.07,12.01;8,155.40,551.67,91.58,12.00">BMC Bioinformatics Journal</title>
		<imprint>
			<date type="published" when="2004-03">March 2004</date>
			<pubPlace>Granada, Spain</pubPlace>
		</imprint>
	</monogr>
	<note>accepted for publication</note>
</biblStruct>

<biblStruct coords="8,155.38,570.63,292.02,12.00" xml:id="b5">
	<monogr>
		<ptr target="http://xldb.di.fc.ul.pt/linguateca/" />
		<title level="m" coord="8,155.38,570.63,104.81,12.00">Pólo XLDB da Linguateca</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,155.39,589.71,321.50,12.00;8,155.40,602.72,98.24,10.80" xml:id="b6">
	<monogr>
		<ptr target="http://www.linguateca.pt" />
		<title level="m" coord="8,155.39,589.71,284.19,12.00">Linguateca Distributed Resource Center for the Portuguese Language</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,155.39,620.67,263.41,12.00" xml:id="b7">
	<monogr>
		<ptr target="http://www.tumba.pt" />
		<title level="m" coord="8,155.39,620.67,157.39,12.00">Tumba! Portuguese Web Search Engine</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,155.39,639.63,321.94,12.00;8,155.40,651.63,321.83,12.00;8,155.40,663.51,51.05,12.00" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,369.21,639.63,103.95,12.00">Versus: a Web Repository</title>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">João</forename><forename type="middle">P</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mário</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,167.27,651.63,224.51,11.90">WDAS -Workshop on Distributed Data and Structures</title>
		<meeting><address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-03">2002. March 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,155.38,125.55,321.95,12.00;9,155.40,137.55,101.30,12.00;9,256.80,136.35,3.72,8.80;9,264.60,137.55,212.97,12.00;9,155.40,149.43,89.75,12.00" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,290.82,125.55,186.50,12.00;9,155.40,137.55,28.67,12.00">Tarântula -Sistema de Recolha de Documentos da Web</title>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mário</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,208.50,137.55,48.20,11.90;9,256.80,136.35,3.72,8.80;9,264.60,137.55,162.61,11.90">CRC&apos;01 -4 a Conferência de Redes de Computadores</title>
		<imprint>
			<date type="published" when="2001-11">November 2001</date>
		</imprint>
	</monogr>
	<note>in Portuguese</note>
</biblStruct>

<biblStruct coords="9,155.38,169.35,321.21,12.00;9,155.40,182.48,123.68,10.80" xml:id="b10">
	<monogr>
		<ptr target="http://ir.iit.edu/~dagr/cs529/files/project_files/trec_eval_desc.htm" />
		<title level="m" coord="9,196.13,169.35,45.75,12.00">TREC Eval</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,155.38,201.27,321.86,12.00;9,155.40,213.27,321.92,12.00;9,155.40,225.15,22.64,12.00" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,301.87,201.27,175.36,12.00;9,155.40,213.27,113.24,12.00">Cross-Language Evaluation Forum: Objectives, Results, Achievements</title>
		<author>
			<persName coords=""><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,277.77,213.27,85.40,11.90">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1/2</biblScope>
			<biblScope unit="page" from="7" to="31" />
			<date type="published" when="2004-04">January/April 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,155.38,264.99,321.94,12.00;9,155.40,276.99,171.40,12.00" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,281.34,264.99,195.98,12.00;9,155.40,276.99,85.03,12.00">CHAVE: Topics and Questions on the Portuguese Participation in CLEF</title>
		<author>
			<persName coords=""><forename type="first">Diana</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paulo</forename><surname>Rocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,249.40,276.99,47.87,12.00">This volume</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,155.38,296.91,322.01,12.00;9,155.40,308.91,201.23,12.00" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,227.31,296.91,198.29,12.00">The Case for a Portuguese Web Search Engine</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mário</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,452.33,296.91,25.06,11.90;9,155.40,308.91,127.83,11.90">IADIS WWW/Internet 2003 Conference</title>
		<imprint>
			<date type="published" when="2003-11">November 2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
