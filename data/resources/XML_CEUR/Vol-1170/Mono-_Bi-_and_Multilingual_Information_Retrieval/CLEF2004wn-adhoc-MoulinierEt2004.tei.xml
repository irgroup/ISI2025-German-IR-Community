<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,121.34,148.86,360.33,15.15;1,185.36,170.78,232.30,15.15">Report on Thomson Legal and Regulatory Experiments at CLEF-2004</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,221.45,204.67,77.85,8.74"><forename type="first">Isabelle</forename><surname>Moulinier</surname></persName>
							<email>isabelle.moulinier@thomson.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Thomson Legal and Regulatory</orgName>
								<address>
									<addrLine>610 Opperman Drive</addrLine>
									<postCode>55123</postCode>
									<settlement>Eagan</settlement>
									<region>MN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,321.99,204.67,59.55,8.74"><forename type="first">Ken</forename><surname>Williams</surname></persName>
							<email>ken.williams@thomson.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Thomson Legal and Regulatory</orgName>
								<address>
									<addrLine>610 Opperman Drive</addrLine>
									<postCode>55123</postCode>
									<settlement>Eagan</settlement>
									<region>MN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,121.34,148.86,360.33,15.15;1,185.36,170.78,232.30,15.15">Report on Thomson Legal and Regulatory Experiments at CLEF-2004</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9EEBCDF21E44CF840882CEC4E97DA8F0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Thomson Legal and Regulatory participated in the CLEF-2004 monolingual and bilingual tracks. Monolingual experiments included Portuguese, Russian and Finnish. We investigated a new query structure to handle Finnish compounds.</p><p>Our main focus was bilingual search from German to French. Our approach used query translation and post-translation pseudo-relevance feedback. We compared two translation models for query translation, and captured compound translations through fertility probabilities. While the fertility-based approach picks good terms, it does not help improve bilingual retrieval. Pseudo-relevance feedback, on the other hand, resulted in improved average precision.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>During the 2004 CLEF campaign, Thomson Legal and Regulatory participated in monolingual and bilingual information retrieval. With our monolingual experiments, we revisited our approach to handling compounds for Finnish retrieval. Previously, we would attempt to match on compounds and phrases. Our new approach restricts matches to compounds only.</p><p>Removing stopwords is generally beneficial. With no language expertise in Finnish, Russian, and Portuguese, we investigated building stopword lists using collection and query log statistics, with no manual editing. Our experiments measured the effect of these lists on retrieval.</p><p>Our main focus, however, was bilingual search. Our approach relied on word-based query translation, and we investigated building bilingual lexicons from corpora using statistical machine translation. We were particularly interested in assessing whether a more sophisticated model (IBM Model 3) would outperform a simpler model (IBM Model 1). We focused on the notion of fertility introduced by Model 3, which allows a source term to translate to zero or more target terms. In the case of German to French translations, we used fertilities to capture translating German compounds into French phrases.</p><p>In addition to investigating translation approaches, we introduced post-translation pseudorelevance feedback in our runs. That lead to improved average precision. As reported in prior research, we observed a great variability on a per-query basis.</p><p>We present our experimental platform and some background in Section 2. Section 3 presents our bilingual effort, while monolingual experiments are described in 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>We briefly describe the retrieval system we used during our CLEF participation, and the pseudorelevance feedback approach we adopted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The WIN system</head><p>The WIN system is a full-text natural language search engine, and corresponds to TLR/West Group's implementation of the inference network retrieval model. While based on the same retrieval model as the INQUERY system <ref type="bibr" coords="2,262.75,154.32,34.75,8.74" target="#b2">[CCB92]</ref>, WIN has evolved separately and focused on the retrieval of legal material in large collections in a commercial environment that supports both Boolean and natural language searches <ref type="bibr" coords="2,262.72,178.23,29.81,8.74" target="#b19">[Tur94]</ref>.</p><p>Indexing Indexing of European languages considers tokens (words) as indexing units. Tokens are identified by localized tokenization rules (e.g. detecting apostrophes in French). Tokens are also stemmed using a morphological stemmer<ref type="foot" coords="2,285.56,226.21,3.97,6.12" target="#foot_0">1</ref> which also identifies compounds and their parts for compound-rich languages such as Finnish or German.</p><p>WIN does not apply a stopword list during indexing, but it does when searches are performed. As a result, all terms are indexed, although it is possible to omit some terms in document length statistics.</p><p>Document retrieval Document retrieval in WIN can be decomposed into two components: query formulation and document scoring. Query formulation identifies query concepts, while scoring find matches for such concepts in documents.</p><p>Query formulation identifies "concepts" in natural language text, and imposes a Bayesian belief structure on these concepts. In many cases, each term in the natural language text represents a concept, and a flat structure gives the same weight to all concepts. However, phrases, compounds or misspellings can introduce more complex concepts, using operators such as "natural phrase," "compound," or "synonym."</p><p>We used a standard tf-idf scheme for computing term beliefs in all our runs. The belief of a single concept is given by: bel term (Q) = 0.4 + 0.6 * tf norm * idf norm where tf norm = log(tf + 0.5) log(tf max + 1.0) and idf norm = log(C + 0.5) -log(df ) log(C + 1.0) and tf is the number of occurrences of the term within the document, tf max is the maximum number of occurrences of any term within the document, df is the number of documents containing the term and C the total number of documents in the collection. tf max is a weak approximation for document length. The final document score is an average of the document score as a whole and the score of the best portion, where the best portion is dynamically computed based on query concept occurrences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Pseudo-relevance feedback</head><p>Past research has reported on the benefits of pseudo-relevance feedback. For example, the relevance feedback incorporated in OKAPI BM-25 model has been successful at CLEF (cf. <ref type="bibr" coords="2,475.37,605.00,29.27,8.74" target="#b16">[Sav01]</ref>). Recently, alternative approaches to selecting relevant documents have been introduced; for example, Sakai and Sparck-Jones [SSJ01] investigated using document summaries to support pseudorelevance feedback.</p><p>Our approach to pseudo-relevance feedback follows the work outlined by Haines and Croft <ref type="bibr" coords="2,90.00,664.77,30.17,8.74" target="#b3">[HC93]</ref> where feedback was added to Inquery.</p><p>Term selection We use a Rocchio-like formula to select terms for expansion:</p><formula xml:id="formula_0" coords="2,171.81,708.74,336.95,28.50">sw = β |R| d∈R (tf norm * idf norm ) - γ |R| d∈R (tf norm * idf norm ) (<label>1</label></formula><formula xml:id="formula_1" coords="2,508.75,715.48,4.24,8.74">)</formula><p>where R is the set of documents considered relevant, R the set of documents considered not relevant, and |X| denotes the cardinality of set X. tf norm and idf norm are defined in the previous section. The β and γ weights are set experimentally. We select terms for expansion solely on the basis of documents. We do not favor terms that appear in the original query during term selection. The sets of documents R and R are extracted from the document list returned by the original search: R correspond to the top n documents, and R to the bottom m, where n and m are determined through experiments on training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reformulated query</head><p>We append N selected terms to the query, eliminating any terms already present in the original query. In addition, each added term is weighted by the tf norm part of the selection weight. Weights of original query terms remain unchanged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Bilingual experiments</head><p>Our approach to bilingual search relies on word-by-word query translation using bilingual lexicons. We build our lexicons from parallel corpora using a statistical machine translation toolkit. In particular, we investigate how parameters from the translation models can be leveraged for selecting translations for German compounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Background</head><p>In a cross-lingual search system, user queries and documents may not share the same language. Before matching between documents and queries can happen, some level of translation is required. Conventional approaches separate the translation and retrieval processes, with translation occurring prior to retrieval. However, recent efforts use language modeling <ref type="bibr" coords="3,420.73,406.33,36.26,8.74" target="#b7">[KNS03]</ref> to integrate translation and retrieval in a unified model.</p><p>We focused on query translation <ref type="bibr" coords="3,256.46,430.24,28.77,8.74" target="#b4">[HG96]</ref>, rather than document translation <ref type="bibr" coords="3,450.16,430.24,30.72,8.74" target="#b11">[OH97]</ref> or the translation of both queries and documents <ref type="bibr" coords="3,282.15,442.20,33.42,8.74" target="#b1">[BRS01]</ref>. Query translation can be performed using machine translation tools <ref type="bibr" coords="3,207.83,454.15,31.00,8.74" target="#b16">[Sav01]</ref> such as Systran, machine readable dictionaries <ref type="bibr" coords="3,458.31,454.15,28.76,8.74" target="#b4">[HG96]</ref>, and bilingual lexicons learned from parallel or comparable corpora. Such bilingual lexicons include similarity thesauri <ref type="bibr" coords="3,171.89,478.06,33.64,8.74" target="#b17">[SBS97]</ref> which capture the notion of translation and related terms at once; and probability tables from statistical machine translation (e.g. the table constructed by IBM Model 1) which attempt to encode exact translations only.</p><p>With queries being translated term-by-term using bilingual lexicons, a term may have multiple possible translations. By taking advantage of query structures available in INQUERY, Pirkola <ref type="bibr" coords="3,90.00,537.84,28.95,8.74" target="#b15">[Pir98]</ref> has shown that grouping translations for a given term is a better technique than allowing all translations to contribute equally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">German to French translation: translating compounds</head><p>In previous CLEF campaigns, we constructed similarity thesauri from comparable corpora, and used the thesauri to translate queries concept-by-concept. Such an approach worked fairly well, and we obtained promising results on French-English and Spanish-English retrieval. This year, we used the statistical machine translation toolkit GIZA++ <ref type="bibr" coords="3,334.19,631.94,30.73,8.74" target="#b12">[ON00]</ref> to build bilingual lexicons. Future work will include comparing both translation approaches for term-by-term query translation.</p><p>Translation models 1 and 3 <ref type="bibr" coords="3,238.23,669.79,60.47,8.74" target="#b0">[BDPDPM93]</ref> introduced five models of increasing complexity. We chose to compare Model 1 and Model 3. Model 1 is intended to capture individual word translations, while Model 3 introduces modeling of local alignments and fertilities. We were particularly interested in the notion of fertility, which allows a source term to translate to zero or more target terms. In the case of German to French translations, we hoped that fertilities would capture translating German compounds into French phrases.</p><p>Using translation and fertility probabilities Using the GIZA++ toolkit, we trained models 1 and 3 on the Europarl corpus <ref type="bibr" coords="4,231.03,123.98,31.24,8.74" target="#b8">[Koe02]</ref>. We did not use the decoding phase typically associated with statistical machine translation. We simply used the translation and fertility probabilities generated by GIZA++ for each source term d and target term f :</p><p>• t 1 (f |d), model 1 translation probabilities for model 1,</p><p>• t 3 (f |d), model 3 translation probabilities for model 3,</p><p>• n(φ|d) where φ = 0 . . . 9, fertility probabilities for model 3, and • p 0 , the fertility probability for the empty notion.</p><p>We subsequently defined two translation methods: a word-based method and a fertility-based method.</p><p>The word-based method lex selects the n most probable translations of each source term d using the translation probabilities. To limit adding spurious translations, we threshold translation probilities to a fixed value p min . Consequently, the lex method may select 0 to n translations for a given term.</p><p>The fertility-based approach fert represents our attempt at capturing the translation of German compounds. With this approach, we select one translation per source term, but each translation may include multiple terms. The fert model generates for each source term d a translation set of the m most probable target terms f 1 , . . . , f m , ranked according to their translation probabilities t 3 (f i |d). The number of selected terms m is given by ArgMax</p><formula xml:id="formula_2" coords="4,219.38,392.37,174.73,24.59">φ n(φ|d) * p 0 if φ = 0 n(φ|d) * φ i=1 t 3 (f i |d) if φ &gt; 0</formula><p>Examples of selected translations are reported in Table <ref type="table" coords="4,354.13,423.87,3.88,8.74" target="#tab_0">1</ref>. The first three examples capture the adequate translation for the German term. The last example, "Lawinenunglücken," is only partially translated to "avalanches" (the disaster aspect is missing). In addition, the fert method selects far too many terms because the mass of translation probabilities outweighs the fertility factor.</p><p>Additional processing of non-translated terms We performed some additional processing for non-translated terms, i.e. terms with no entry in the bilingual lexicons. In particular, we focused on compounds that did not appear in the parallel corpus.</p><p>When no translation was found for a German term, we first stemmed the German term. If translations were found for the stemmed term, we associated these translations to the original term. If still no translation was found and the stemmed term was identified as a compound, we applied the translation process to each stemmed part. The original term was associated with the translations of the compound parts. Finally, when no translation was found, the original German term was kept as the translation. Examples of compounds translated via this additional processing are given in Table <ref type="table" coords="4,171.67,605.19,3.88,8.74" target="#tab_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query formulation</head><p>We followed <ref type="bibr" coords="4,251.17,631.08,28.95,8.74" target="#b15">[Pir98]</ref> and others in structuring translated queries to give the same importance to each original term, regardless of the number of translations. We grouped multiple translations under a weighted #SUM node. The weight associated with each translation is its translation probability.</p><p>We also investigated using a proximity operator when translating compound terms. When the original German term was a compound, we grouped all translations under the #NPHR operator </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results and discussion</head><p>Base runs We ran our first set of experiments set to determine whether the more sophisticated translation model (Model 3) improves retrieval performance over the simpler Model 1. We compared Model 1 (t 1 ) and Model 3 (t<ref type="foot" coords="6,243.61,335.99,3.97,6.12" target="#foot_2">3</ref> ) with the lex translation selection. Results are reported in Table <ref type="table" coords="6,117.08,349.52,3.88,8.74">3</ref>. Model 3 with lex provided a strong baseline with the #SUM operator. The lex method using Model 3 outperforms the lex method using Model 1, although the difference is not statistically significant. We found that many queries improved by a noticeable margin when Model 3 was introduced, and that some of that queries that degraded were affected by poor post-translation stopword removal.</p><p>Fertility runs Our attempt to capture the translation of compounds using fertilities had limited success. We find the fert method promising inasmuch as it is able to identify adequate compound translations but suffers from selecting a single, possibly multi-term translation. The difference between runs lex and fert using Model 3 (cf. Table <ref type="table" coords="6,337.13,459.10,4.43,8.74">3</ref>) is statistically significant 3 . We have already seen ("Lawinenungglücken") that the fert approach may select too many terms when the probability mass of the candidate set outweighs the fertility probability factor. In addition, selecting a single translation as does the fert approach, limits the effectiveness of retrieval. We evaluated the lex approach selecting a single translation (n = 1), and the average precision dropped to 0.2641<ref type="foot" coords="6,170.66,517.30,3.97,6.12" target="#foot_3">4</ref> . This result confirms our suspicion that the fert approach is hindered by selecting a single, possibly multi-term translation.</p><p>Translated compounds as phrases Next we studied the impact of query formulation with the fert approach. The fert approach captures the translation of German compounds into multiple French terms. We expected that introducing the #NPHR operator would positively impact retrieval, since French phrases were a better representation of German compounds. The results reported in Table <ref type="table" coords="6,201.45,604.55,4.98,8.74" target="#tab_2">4</ref> did not support our intuition: the #NPHR operator did not improve average precision. We think that partial credit diluted results, because with partial credit the children of a phrase contribute independently as concepts to document scores. In future work, we will explore alternative scoring approaches for the phrase proximity to retain the translations of a source term as a single concept.</p><p>Seeding translation models We also investigated seeding the translation models with a machinereadable dictionary. We tested only with Model 3 and found no differences between the two translation probability tables.  <ref type="table" coords="7,118.37,217.57,3.88,8.74">5</ref>: Experimental results using post-translation pseudo-relevance feedback. All runs with PRF used N = 20, n = 5, m = 20, β = 1. indicates that PRF improves over the base run, and the difference is statistically significant with α = 0.01 using the Wilcoxon signed-rank test.</p><p>Runs using pseudo-relevance feedback Finally we report on experiments using post-translation pseudo-relevance feedback (PRF). After the initial retrieval, we selected the five highest-ranked documents as relevant documents. We also selected the twenty lowest-ranked documents as nonrelevant. We use the non-relevant documents as a filter to prevent common words from being selected by PRF. As can be observed in Table <ref type="table" coords="7,227.26,333.08,3.88,8.74">5</ref>, the introduction of PRF was beneficial. We observed the typical behavior when comparing base runs and PRF. In the best case (run "t 3 , lex"), PRF helps improve the performance of 59% of queries and degrade 38% of the queries. In the two other runs, PRF is helpful for 50% of queries, and not so helpful for 44% of queries.</p><p>A point of interest is the comparison to the median. There is a significant difference in average precision between the base run and the PRF run using lex and Model 3; however each run compares similarly to the median of all runs. After analysis, we observed the well-documented seesaw effect of pseudo-relevance feedback: 10 queries fell below the median when PRF was added, while 8 queries rose above the median.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Monolingual experiments</head><p>We participated in the monolingual track with three new languages: Finnish, Portuguese and Russian. We revisited our approach to compound handling and experimented with the creation of stopword lists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Compound handling in Finnish retrieval</head><p>Prior research During past CLEF campaigns, the handling of compounds has received a fair amount of attention. Prior research has found that, for German, Dutch, or Finnish, breaking compounds into parts and searching on the parts was beneficial to both monolingual and crosslingual retrieval [HKP + 02, Md02]. Alternatively, some researchers have focused on character n-grams as indexing units for European languages (cf. <ref type="bibr" coords="7,284.23,601.50,36.70,8.74" target="#b10">[MMP01]</ref>), limiting the reliance on compound identification. Indeed character n-grams may capture compound parts without explicitly identifying compounds.</p><p>Compounds are not like phrases At CLEF 2000, we investigated the impact of decompounding on monolingual retrieval for German. In those experiments, we found that decompounding was useful and that representing compounds using the #NPHR operator with partial credit was the most effective. The #NPHR operator corresponds to an unordered proximity of 3, and partial credit allows the children of the proximity operator to contribute to the final belief score, independently of the operator.</p><p>With this year's experiments, we revisited the operator and proposed a stricter proximity #NPHR0. In order to contribute to the document belief score, parts of the compound must appear in a compound, not in a "phrase" environment. Partial credit is still applied. In other words, we replaced the unordered proximity of 3 with a proximity of 0. This is made possible by our indexing scheme, where compounds and their parts are indexed.</p><p>Experimental results and discussion Table <ref type="table" coords="8,314.54,250.58,4.98,8.74" target="#tab_4">6</ref> summarizes our experimental results with Finnish compounds. We observe a small improvement in both average precision and R-Precision, although the difference is not statistically significant.</p><p>Let us note that all documents that satisfy the #NPHR0 operator also satisfy the #NPHR operator, although their belief score may be different under each condition. For some queries, e.g. query 208, the #NPHR run ranks relevant documents higher in the list, suggesting that it finds useful proximities in addition to the exact compounds. On the other hand, for other queries, e.g. query 203, the additional proximities found in documents degrade the ranked list by pushing relevant documents further down the list. We suspect that the difference in ranking is linked to the different idf values associated with the #NPHR and #NPHR0 operators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiments with stopword lists</head><p>Two sources to identify stopwords At NTCIR-4, we built upon Savoy's work <ref type="bibr" coords="8,462.13,404.46,30.99,8.74" target="#b16">[Sav01]</ref> and we compared using collection and query log statistics to create stopword lists. We found little differences in retrieval effectiveness.</p><p>For our CLEF experiments, we merged both approaches. We selected the most frequent terms in the collection as stopwords. We subsequently enriched that list with terms extracted from query logs. No manual review of the list was performed.</p><p>For our runs, we selected the most frequent 100 and 200 stemmed terms in collections. To those collection-based lists, we added stemmed terms that occurred in over 20% of the query logs. For each language, a query log consisted of collected CLEF queries from previous campaigns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and discussion</head><p>In Table <ref type="table" coords="8,248.73,525.99,3.88,8.74">7</ref>, we compare our base runs with no stopword removal (none) with removing stopwords extracted from collection statistics and query logs. Stopword lists are a useful tool to make search more effective in terms of average precision. We observe statistically significant differences in average precison for all runs.</p><p>We conclude our discussion on stopword lists by outlining the need for human review. In the Finnish stopword list, we noticed cities such as Helsinki and Tampere, as well as terms like suomi (Finland, finnish language) and suomalainen (finnish). Similarly the Portuguese list contains Lisboa, Portugal, português, governo or ministro. While such terms are frequent in the collection, they are not truly stopwords and interfered with some queries (e.g. query 231).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Our bilingual experiments with IBM Model 3 are promising. Using a word by word translation, we were able to capture the translation of German compounds using translation and fertility probabilities. In the future, we will expand our work to select more than one translation per source term. In addition we will investigate alternative scoring for the #NPHR operator, where partial credit is not allowed to dilute the contribution of other concepts. Finally, we will investigate whether there is added value in using Model 4 or 5 in the context of word-by-word translation.  <ref type="table" coords="9,117.91,253.43,3.88,8.74">7</ref>: Summary of our monolingual runs, with an emphasis on using stopword lists. Finnish runs use the #NPHR0 operator. The , sign indicates a statistical difference with the base run "none" with α = 0.01, 0.05 using the Wilcoxon signed-rank test.</p><p>We find our monolingual runs satisfactory. Our reformulated compound handling in Finnish improved was beneficial when compared to our previous approach. Compound handling may also benefit from improved partial credit. We have observed similar findings with German and Korean. Our stopword experiments confirmed well-established results about stopword removal and retrieval effectiveness.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,505.76,689.28,7.24,10.31"><head>Table 1 :</head><label>1</label><figDesc>2 .</figDesc><table coords="5,118.67,120.50,359.68,578.00"><row><cell>Term: globale</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>f</cell><cell>t 3 (f |d)</cell><cell>φ</cell><cell>n(φ|d)</cell><cell cols="2">lex translation fert translation</cell></row><row><cell>globale</cell><cell>0.306778</cell><cell>1</cell><cell>0.746871</cell><cell>globale</cell><cell>globale</cell></row><row><cell>mondiale</cell><cell>0.152177</cell><cell>0</cell><cell>0.165741</cell><cell>mondiale</cell><cell></cell></row><row><cell>global</cell><cell>0.115814</cell><cell>2</cell><cell cols="2">0.0617001 global</cell><cell></cell></row><row><cell>mondial</cell><cell cols="2">0.0928475 3</cell><cell>0.0207158</cell><cell></cell><cell></cell></row><row><cell>chelle</cell><cell>0.0456918</cell><cell></cell><cell>. . .</cell><cell></cell><cell></cell></row><row><cell cols="3">Term: Klimaveränderungen</cell><cell></cell><cell></cell><cell></cell></row><row><cell>f</cell><cell>t 3 (f |d)</cell><cell>φ</cell><cell>n(φ|d)</cell><cell cols="2">lex translation fert translation</cell></row><row><cell>climatiques</cell><cell>0.269569</cell><cell>2</cell><cell>0.589625</cell><cell>climatiques</cell><cell>climatiques</cell></row><row><cell cols="2">changements 0.258488</cell><cell>1</cell><cell>0.105312</cell><cell>changements</cell><cell>changements</cell></row><row><cell>changement</cell><cell>0.105622</cell><cell>3</cell><cell cols="2">0.0936477 changement</cell><cell></cell></row><row><cell>climatique</cell><cell>0.103034</cell><cell>4</cell><cell>0.07117</cell><cell></cell><cell></cell></row><row><cell>climat</cell><cell>0.0250892</cell><cell></cell><cell>. . .</cell><cell></cell><cell></cell></row><row><cell cols="2">Term: Treibhauseffektes</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>f</cell><cell>t 3 (f |d)</cell><cell>φ</cell><cell>n(φ|d)</cell><cell cols="2">lex translation fert translation</cell></row><row><cell>effet</cell><cell>0.265273</cell><cell>2</cell><cell>0.283692</cell><cell>effet</cell><cell>effet</cell></row><row><cell>serre</cell><cell>0.26525</cell><cell>1</cell><cell>0.246126</cell><cell>serre</cell><cell>serre</cell></row><row><cell>venir</cell><cell cols="2">0.0380016 3</cell><cell>0.174969</cell><cell></cell><cell></cell></row><row><cell>mes</cell><cell cols="2">0.0191118 9</cell><cell>0.0651408</cell><cell></cell><cell></cell></row><row><cell cols="2">Term: Lawinenunglücken</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>f</cell><cell>t 3 (f |d)</cell><cell>φ</cell><cell>n(φ|d)</cell><cell cols="2">lex translation fert translation</cell></row><row><cell>avalanches</cell><cell>0.10976</cell><cell>1</cell><cell>0.404492</cell><cell>avalanches</cell><cell>avalanches</cell></row><row><cell cols="2">programmer 0.10976</cell><cell>2</cell><cell>0.231625</cell><cell>programmer</cell><cell>programmer</cell></row><row><cell>servir</cell><cell>0.10976</cell><cell>3</cell><cell>0.1003</cell><cell>servir</cell><cell>servir</cell></row><row><cell>court</cell><cell>0.10976</cell><cell>0</cell><cell>0.0752761</cell><cell></cell><cell>court</cell></row><row><cell cols="2">interventions 0.10976</cell><cell>9</cell><cell>0.0611943</cell><cell></cell><cell>interventions</cell></row><row><cell>diverses</cell><cell>0.109759</cell><cell>4</cell><cell>0.0435146</cell><cell></cell><cell>diverses</cell></row><row><cell>série pourquoi zones</cell><cell>0.109759 0.109759 0.109624</cell><cell></cell><cell>. . .</cell><cell></cell><cell>série pourquoi zones</cell></row><row><cell></cell><cell cols="2">Compound term</cell><cell cols="3">Identified Translations ( t(f |d) )</cell></row><row><cell></cell><cell cols="3">Wohnungsbrände logement</cell><cell cols="2">(0.453006)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>incendie</cell><cell cols="2">(0.319306)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>au</cell><cell cols="2">(0.256685)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>feu</cell><cell cols="2">(0.153006)</cell></row><row><cell></cell><cell>Weltmeisterin</cell><cell></cell><cell>du</cell><cell cols="2">(0.172959)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>champions</cell><cell cols="2">(0.135024)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>monde</cell><cell cols="2">(0.135023)</cell></row></table><note coords="5,130.97,542.49,321.23,8.74;5,452.20,540.91,3.97,6.12;5,456.67,542.49,56.33,8.74;5,90.00,554.44,206.50,9.02;5,296.51,552.87,3.97,6.12;5,300.98,554.44,212.02,8.74;5,90.00,566.40,302.07,9.02"><p>Examples of German to French translations. We used the probabilities t 3 (.|.) to select translations in the lex method. We used both t 3 (.|.), the translation probabilities, and n(φ|.), the fertilities from Model 3 to generate translation in the fert approach.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,90.00,711.63,423.00,32.65"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table coords="6,90.00,110.82,423.00,127.81"><row><cell>Run</cell><cell cols="3">Avg. Prec, R-Prec. Prec. at 20 doc.</cell></row><row><cell>t 1 , lex, #SUM</cell><cell>0.2934</cell><cell>0.2951</cell><cell>0.2224</cell></row><row><cell>t 3 , lex, #SUM</cell><cell>0.3225</cell><cell>0.3250</cell><cell>0.2541</cell></row><row><cell cols="2">t 3 , fert, #SUM 0.2717</cell><cell>0.2868</cell><cell>0.2133</cell></row><row><cell cols="4">Table 3: Comparisons between bilingual base runs. The lex approach using Models 1 (t 1 ) and 3</cell></row><row><cell>(t 3 ) used n = 3 and p min = 0.1.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Run</cell><cell cols="3">Avg Prec. R-Prec. Prec. at 20 doc.</cell></row><row><cell>t 3 , fert, #SUM</cell><cell>0.2717</cell><cell>0.2868</cell><cell>0.2133</cell></row><row><cell>t 3 , fert, #NPHR</cell><cell>0.2708</cell><cell>0.2779</cell><cell>0.2153</cell></row></table><note coords="5,130.35,711.63,382.65,8.74;5,90.00,723.58,422.99,9.65;5,90.00,735.54,20.53,8.74"><p>Examples of compounds translated through additional processing for terms outside the lexicon. Translation is performed using lex, n = 3, p min = 0.1 and Model 3 translation probabilities.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,90.00,251.48,423.01,20.69"><head>Table 4 :</head><label>4</label><figDesc>Capturing the translation of German compounds. Comparison between the #SUM and the #NPHR operators.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,90.00,110.82,401.29,115.48"><head>Table</head><label></label><figDesc></figDesc><table coords="7,111.71,110.82,379.59,93.90"><row><cell>Run</cell><cell cols="4">Avg Prec. R-Prec. Prec. at Above/equal/below</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">20 doc. Median</cell></row><row><cell>t 1 , lex, nd, NoPRF</cell><cell>0.2934</cell><cell>0.2951</cell><cell>0.2224</cell><cell>-</cell></row><row><cell>t 1 , lex, nd, γ = 4 (tlrde2fr4)</cell><cell>0.3289</cell><cell>0.3005</cell><cell>0.2531</cell><cell>23 / 1 / 24</cell></row><row><cell>t 3 , lex, nd, NoPRF (tlrde2fr2)</cell><cell>0.3225</cell><cell>0.3250</cell><cell>0.2541</cell><cell>32 / 2 / 14</cell></row><row><cell>t 3 , lex, nd, γ = 1 (tlrde2fr3)</cell><cell>0.3750</cell><cell>0.3409</cell><cell>0.3000</cell><cell>31 / 2 / 15</cell></row><row><cell>t 3 , fert, d (tlrde2fr1)</cell><cell>0.2723</cell><cell>0.2877</cell><cell>0.2153</cell><cell>25 / 1 / 22</cell></row><row><cell>t 3 , fert, d, γ = 1</cell><cell>0.3250</cell><cell>0.2915</cell><cell>0.2571</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,90.00,110.82,423.00,66.86"><head>Table 6 :</head><label>6</label><figDesc>Experimental results using different operators in the representation of Finnish compounds. Differences are not statistically significant.</figDesc><table coords="8,187.22,110.82,228.56,33.05"><row><cell>Run</cell><cell cols="3">Avg. Prec. R-Prec. Prec. at 20 doc.</cell></row><row><cell>#NPHR</cell><cell>0.5418</cell><cell>0.4903</cell><cell>0.2722</cell></row><row><cell>#NPHR0</cell><cell>0.5562</cell><cell>0.5027</cell><cell>0.2744</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,90.00,110.82,348.15,151.35"><head>Table</head><label></label><figDesc></figDesc><table coords="9,164.85,110.82,273.31,129.48"><row><cell>Run</cell><cell cols="3">Avg. Prec. R-Prec. Above/equal/below</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Median</cell></row><row><cell>fi, none</cell><cell>0.5466</cell><cell>0.4947</cell><cell>-</cell></row><row><cell>fi, 100 (tlrfi1)</cell><cell>0.5551</cell><cell>0.4994</cell><cell>23/8/13</cell></row><row><cell>fi, 200 (tlrfi2)</cell><cell>0.5562</cell><cell>0.5027</cell><cell>23/9/12</cell></row><row><cell>pt, none</cell><cell>0.4250</cell><cell>0.3992</cell><cell>-</cell></row><row><cell>pt, 100 (tlrpt1)</cell><cell>0.4458</cell><cell>0.4017</cell><cell>16/15/14</cell></row><row><cell>pt, 200 (tlrpt2)</cell><cell>0.4469</cell><cell>0.4044</cell><cell>16/17/12</cell></row><row><cell>ru, none (tlrru2)</cell><cell>0.3176</cell><cell>0.2783</cell><cell>9/7/17</cell></row><row><cell>ru, 100 (tlrru1)</cell><cell>0.3702</cell><cell>0.3183</cell><cell>13/9/11</cell></row><row><cell>ru, 200</cell><cell>0.3820</cell><cell>0.3364</cell><cell>-</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.24,747.01,314.76,6.99"><p>We are using the stemmer commercialized by Inxight within the LinguistX platform.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,105.24,709.79,407.75,6.99;4,90.00,719.25,306.02,6.99"><p>The WIN #NPHR operator corresponds to Inquery phrase operator, and includes partial credit. Partial credit enables both the operator and its children to contribute to document belief scores.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="6,105.24,721.10,203.64,6.99"><p>We used the Wilcoxon signed-rank test, with α = 0.05.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="6,105.24,730.61,191.77,6.99"><p>This difference is also found statistically significant.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,155.45,411.76,357.56,8.74;9,155.45,423.71,357.55,8.74;9,155.45,435.67,75.41,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,424.37,411.76,88.64,8.74;9,155.45,423.71,231.00,8.74">The mathematics of statistical machine translation: parameter estimation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">Della</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,395.65,423.71,113.20,8.74">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1993-06">June 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,155.45,455.59,357.56,8.74;9,155.45,467.55,248.44,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,367.53,455.59,145.48,8.74;9,155.45,467.55,102.04,8.74">Experiments with the eurospider retrieval system for clef</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Braschler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ripplinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Schäuble</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,361.51,467.55,31.78,8.74">PBGK</title>
		<editor>
			<persName><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">02</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,155.45,487.47,357.56,8.74;9,155.45,499.43,71.53,8.74;9,226.98,497.85,8.06,6.12;9,239.10,499.43,273.90,8.74;9,155.45,511.38,100.21,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,332.26,487.47,138.79,8.74">The INQUERY retrieval system</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Broglio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,493.89,487.47,19.11,8.74;9,155.45,499.43,71.53,8.74;9,226.98,497.85,8.06,6.12;9,239.10,499.43,273.90,8.74;9,155.45,511.38,39.78,8.74">Proceedings of the 3 rd International Conference on Database and Expert Systems Applications</title>
		<meeting>the 3 rd International Conference on Database and Expert Systems Applications<address><addrLine>Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,155.45,531.31,357.55,8.74;9,155.45,543.26,357.55,8.74;9,155.45,555.22,267.11,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,274.26,531.31,182.79,8.74">Relevance feedback and inference networks</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Haines</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,477.09,531.31,35.91,8.74;9,155.45,543.26,357.55,8.74;9,155.45,555.22,183.76,8.74">Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="2" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,155.45,575.14,357.55,8.74;9,155.45,587.10,313.44,8.74;9,468.88,585.53,7.68,6.12;9,481.66,587.10,31.34,8.74;9,155.45,599.05,357.55,8.74;9,155.45,611.01,146.29,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,289.60,575.14,223.40,8.74;9,155.45,587.10,193.40,8.74">Querying across languages: a dictionary-based approach to multilingual information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hull</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,374.09,587.10,94.80,8.74;9,468.88,585.53,7.68,6.12;9,481.66,587.10,31.34,8.74;9,155.45,599.05,357.55,8.74;9,155.45,611.01,57.95,8.74">Proceedings of the 19 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 19 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="49" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,96.19,630.94,18.58,8.74" xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Hkp</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,155.45,630.94,357.55,8.74;9,155.45,642.89,357.55,8.74;9,155.45,654.85,141.27,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,468.95,630.94,44.05,8.74;9,155.45,642.89,302.96,8.74">Utaclir at CLEF 2001 -effects of compound splitting and N-gram techniques</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hedlund</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Keskustalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pirkola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Airio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,186.20,654.85,31.78,8.74">PBGK</title>
		<editor>
			<persName><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">02</biblScope>
			<biblScope unit="page" from="118" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,155.45,674.77,357.55,8.74;9,155.45,686.73,357.55,8.74;9,155.45,698.68,22.70,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,333.34,674.77,179.66,8.74;9,155.45,686.73,165.99,8.74">Web-based statistical translation models in cross-language information retrieval</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Simard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,329.54,686.73,112.98,8.74">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="381" to="419" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,155.45,718.61,357.55,8.74;9,155.45,730.56,52.20,8.74" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="9,204.04,718.61,304.80,8.74">Europarl: A multilingual corpus for evaluation of machine translation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>Draft</note>
</biblStruct>

<biblStruct coords="10,155.45,112.02,357.55,8.74;10,155.45,123.98,357.55,8.74;10,155.45,135.93,37.64,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,279.35,112.02,233.65,8.74;10,155.45,123.98,204.42,8.74">Shallow morphological analysis in monolingual information retrieval for dutch, german, and italian</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,443.19,123.98,31.78,8.74">PBGK</title>
		<editor>
			<persName><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">02</biblScope>
			<biblScope unit="page" from="262" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.45,155.86,357.55,8.74;10,155.45,167.81,197.45,8.74" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="10,349.38,155.86,163.62,8.74;10,155.45,167.81,98.35,8.74">A language-independent approach to european text retrieval</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Piatko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="129" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.45,187.74,357.55,8.74;10,155.45,199.69,357.55,8.74;10,155.45,211.65,357.55,8.74;10,155.45,223.60,22.70,8.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,272.69,187.74,240.31,8.74;10,155.45,199.69,129.04,8.74">Document translation for cross-language text retrieval at the university of maryland</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Hackett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,309.42,199.69,203.57,8.74;10,155.45,211.65,64.02,8.74">Proceedings of the 6th Text REtrieval Conference (TREC-6)</title>
		<meeting>the 6th Text REtrieval Conference (TREC-6)</meeting>
		<imprint>
			<date type="published" when="1997-11">November 1997</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.45,243.53,328.84,8.74;10,484.29,241.95,7.68,6.12;10,496.68,243.53,16.32,8.74;10,155.45,255.48,357.55,8.74;10,155.45,267.44,142.83,8.74" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,262.18,243.53,166.45,8.74">Improved statistical alignment models</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,453.07,243.53,31.21,8.74;10,484.29,241.95,7.68,6.12;10,496.68,243.53,16.32,8.74;10,155.45,255.48,281.47,8.74">The 38 th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Hongkong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-10">October 2000</date>
			<biblScope unit="page" from="440" to="447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.45,287.36,357.56,8.74;10,155.45,299.32,357.55,8.74;10,155.45,311.27,40.16,8.74" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,422.58,287.36,90.42,8.74;10,155.45,299.32,172.51,8.74">Evaluation of Cross-Language Information Retrieval Systems</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brashler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kluck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,403.90,299.32,23.36,8.74">LNCS</title>
		<imprint>
			<biblScope unit="volume">2406</biblScope>
			<date type="published" when="2001-09">September 2001</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.45,331.20,357.56,8.74;10,155.45,343.15,357.55,8.74;10,155.45,355.11,357.55,8.74;10,155.45,367.06,342.40,8.74" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,423.10,331.20,89.91,8.74;10,155.45,343.15,244.27,8.74">Evaluation of Cross-Language Information Retrieval Systems: revised papers</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Braschler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kluck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,407.81,343.15,105.19,8.74;10,155.45,355.11,207.98,8.74">Second Workshop of the Cross-Languague Evaluation Forum, CLEF 2001</title>
		<title level="s" coord="10,272.71,367.06,152.10,8.74">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Darmstadt, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000">September 3-4, 2000. 2002</date>
			<biblScope unit="volume">2406</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.45,386.99,357.55,8.74;10,155.45,398.94,297.41,8.74;10,452.86,397.37,7.67,6.12;10,464.84,398.94,48.16,8.74;10,155.45,410.90,357.55,8.74;10,155.45,422.85,224.57,8.74" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,212.54,386.99,300.45,8.74;10,155.45,398.94,183.20,8.74">The effects of query structure and dictionary setups in dictionarybased cross-language information retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pirkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,360.45,398.94,92.41,8.74;10,452.86,397.37,7.67,6.12;10,464.84,398.94,48.16,8.74;10,155.45,410.90,357.55,8.74;10,155.45,422.85,37.33,8.74">Proceedings of the 21 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 21 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="55" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.45,442.78,357.56,8.74;10,155.45,454.74,162.76,8.74" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="10,196.34,442.78,316.67,8.74;10,155.45,454.74,37.66,8.74">Report on CLEF-2001 experiments: Effective combined query-translation approach</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
		<editor>Peters et al.</editor>
		<imprint/>
	</monogr>
	<note>PBGK01</note>
</biblStruct>

<biblStruct coords="10,155.45,474.66,357.56,8.74;10,155.45,486.62,357.55,8.74;10,155.45,498.57,357.55,8.74;10,155.45,510.53,22.70,8.74" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,350.30,474.66,162.71,8.74;10,155.45,486.62,118.60,8.74">Cross-lingual information retrieval in a multilingual legal domain</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sheridan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Braschler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Schuble</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,297.93,486.62,215.06,8.74;10,155.45,498.57,237.56,8.74">Proceedings of the First European Conference on Research and Advanced Technology for Digital Libraries</title>
		<meeting>the First European Conference on Research and Advanced Technology for Digital Libraries<address><addrLine>Pisa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="253" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.45,530.45,357.56,8.74;10,155.45,542.41,357.55,8.74;10,155.45,554.36,331.54,8.74" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,302.12,530.45,210.89,8.74;10,155.45,542.41,34.67,8.74">Generic summaries for indexing in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Sparck-Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,211.70,542.41,301.30,8.74;10,155.45,554.36,233.55,8.74">Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 24th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="190" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.45,574.29,357.55,8.74;10,155.45,586.24,195.54,8.74;10,350.99,584.67,7.68,6.12;10,362.68,586.24,150.31,8.74;10,155.45,598.20,357.55,8.74;10,155.45,610.15,95.37,8.74" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="10,207.56,574.29,305.44,8.74;10,155.45,586.24,82.51,8.74">Natural language vs. boolean query evaluation: a comparison of retrieval performance</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,259.43,586.24,91.56,8.74;10,350.99,584.67,7.68,6.12;10,362.68,586.24,150.31,8.74;10,155.45,598.20,286.54,8.74">Proceedings of the 17 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 17 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="212" to="220" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
