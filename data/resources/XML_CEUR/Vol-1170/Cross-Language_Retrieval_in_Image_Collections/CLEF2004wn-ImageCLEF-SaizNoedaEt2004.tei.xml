<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.45,113.60,328.42,15.06;1,174.32,131.54,260.45,15.06">Pattern-based image retrieval with constraints and preferences on ImageCLEF 2004</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,167.51,170.41,104.36,10.46"><forename type="first">Maximiliano</forename><surname>Saiz-Noeda</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Lenguajes y Sistemas Informáticos</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,279.86,170.41,73.17,10.46"><forename type="first">José</forename><forename type="middle">Luis</forename><surname>Vicedo</surname></persName>
							<email>vicedo@dlsi.ua.es</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Lenguajes y Sistemas Informáticos</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,375.73,170.41,72.12,10.46"><forename type="first">Rubén</forename><surname>Izquierdo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Lenguajes y Sistemas Informáticos</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.45,113.60,328.42,15.06;1,174.32,131.54,260.45,15.06">Pattern-based image retrieval with constraints and preferences on ImageCLEF 2004</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">749C412AA542A2402F6AAE1576C97E56</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the approach used by the University of Alicante in the ImageCLEF 2004 adhoc retrieval task. This task is performed by multilingual search requests (topics) against an historic photographic collection in which images are accompanied with English captions. This approach uses these captions to make the retrieval and is based in a set constraints and preferences that will allow the rejection or the scoring of the images for the retrieval task. The constraints are implemented through a set of co-occurrence patterns based on regular expressions and the approach is extended in one of the experiments with the use of WordNet synonym relations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Bilingual ad hoc retrieval is one of the tasks defined within the ImageCLEF 2004 campaign <ref type="bibr" coords="1,205.92,442.52,10.52,10.46" target="#b0">[1]</ref> as part of the Cross Language Evaluation Forum <ref type="bibr" coords="1,450.15,442.52,26.09,10.46">(2004)</ref>. The objective of this task, celebrated since last 2003 campaign <ref type="bibr" coords="1,409.63,454.47,9.96,10.46" target="#b1">[2]</ref>, is to retrieve relevant photographic documents belonging to a historic photographic collection in which images are accompanied with English captions. These photographs integrate the St Andrews photographic archive consisting of 28,133 (aproximately 10% of the total) photographs from St Andrews University Library photographic collection <ref type="bibr" coords="1,179.33,514.25,9.96,10.46">[3]</ref>.</p><p>The method followed to retrieve the relevant images is based on three experiments where a set of preferences and constraints are applied. The constraints, based on a set of co-occurrence patterns will reject the potential incompatible (non-relevant) images related to the question. Preferences will score the images in order to give a list according to their relevance degree. Furthermore, a Wordnet-based query expansion is tested. This is the first time that the University of Alicante participates in this specific task and the main objective in the starting premise is to make a simple and low cost approach just to test its possibilities.</p><p>Next sections describe specific characteristics of the dataset, relevant for the retrieval process, just as the strategy set up by the University of Alicante's team in order participate in the forum. Finally, some evaluation results will be discussed and some of the future intervention lines in order to improve the system and provide better results will be presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Photographic dataset</head><p>As mentioned, the photographic dataset used for the Image Clef 2004 evaluation is a collection of 28,133 historical images from St Andrews University Library photographic collection. Photos are primarily historic in nature from areas in and around Scotland; although pictures of other locations also exist.</p><p>All images have an accompanying textual description consisting of a set of fields. In this apporach, we have used a file containing all image captions in TREC-style format as detailed below:</p><p>The 28,133 captions consist of 44,085 terms and 1,348,474 word occurrences; the maximum caption length is 316 words, but on average 48 words in length. All captions are written in British English, although the language also contains colloquial expressions. Approximately 81% of captions contain text in all fields, the rest generally without the description field. In most cases the image description is a grammatical sentence of around 15 words. The majority of images (82%) are in black and white, although colour images are also present in the collection.</p><p>The type of information that people typically look for in this collection include the following: Social history, e.g. old towns and villages, children at play and work. Environmental concerns, e.g. lanscapes and wild plants. History of photography, e.g. particular photographers. Architecture, e.g. specific or general places or buildings. Golf, e.g. individual golfers or tournaments. Events, e.g. historic, war related. Transport, e.g. general or specific roads, bridges etc. Ships and shipping, e.g. particular vessels or fishermen.</p><p>Although all these fields can be used individually or collectively to facilitate image retrieval, in this approach only a few of them have been used, in particular, fields related to the photographer, location and date, apart from the headline, have been selected for the retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Technique description</head><p>As it is the first time this group participates in this task, we decided to make a naive approach with the smallest possible quantity of resources and timeconsuming. So, this technique does not use any kind of indexing, dictionary or entity recognition and it makes use of a single POS tagging. Nevertheless, within the three developed experiments, improvements of the method includes the use of co-occurrence patterns and WordNet for the query expansion.</p><p>Figure <ref type="figure" coords="3,180.69,391.08,4.98,10.46" target="#fig_1">1</ref> shows the process followed by the system. This figure includes three steps related to the three experiments carried out for the evaluation that will be detailed below.</p><p>For the application of the basic strategy it is necessary to count on a file with question files and image dataset. As mentioned, the file with the whole set of images in trec format has been used for the retrieval.</p><p>Constraints and preferences applied to the retrieval process make use of morphological information. Furthermore, the retrieval process is based on word lemmas. So, a POS tagging of both the question and the image info is necessary. This POS tagging has been made using the TreeTagger analyzer <ref type="bibr" coords="3,430.07,499.11,9.96,10.46" target="#b2">[4]</ref>. For the retrieval process itself, a file of stop words have been used in order to eliminate useless words and improve the system speed.</p><p>In order to cope with multilingual retrieval aspects, the use of a translator has been planned. In concrete Babelfish <ref type="bibr" coords="3,294.65,547.15,10.52,10.46" target="#b3">[5]</ref> translator has been used. This resource has allowed to test the system with topics in German, Chinese, Spanish, French, Dutch, Italian, Japanese and Russian. Following this, all the languages have been equally treated from their translation into English.</p><p>According to the information needed for the retrieval, three different experiments have been carried out: At the beginning of the process, all the images are suggested as solution for each question <ref type="foot" coords="4,210.03,534.01,3.97,7.32" target="#foot_1">1</ref> . From this scoring, some images will be added punctuation according to the experiment development.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">First experiment. Preferences</head><p>For the preference applying, a single word matching between the question and the HEADLINE field of the image is used. This experiment is used as a baseline and its main interest, as it will be discussed later, is the way the information added in the other experiments affects to the retrieval process.</p><p>For the scoring in this experiment, we have assumed the relevance of proper nouns, nouns and verbs so we have scored following this order when the matching is related to these elements.</p><p>Furthermore, if applicable, relations between nouns and verbs with the same lemma are also scored (if we are looking for "golfers swinging their clubs" probably we are interested in a "golfer's swing").</p><p>It seems almost obvious that a good performance of this technique should be based in a good entity recognition that ensure the correct detection of proper nouns in the question and in the image text info. Probably, as it will be discussed later, counting on a named entities recognizer would improve the overall performance of this experiment is not as good as desired.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Second experiment. Constraints and preferences. The patterns</head><p>This experiment makes use of the previously described preferences and integrates the constraints as a new selection criterion. The main aspect of the constraint is that it should be a rule strong enough to reject an image based on a compatibility guideline. This rule is built through the definition of a set of co-occurrence patterns that establish rejecting rules related to three of the fields contained in the image information: DATE, PHOTOGRAPHER and LOCATION.</p><p>These patterns are applied to the question (topic) and generates a XML-style file with the information provided by the patterns. For example, topic: where labels &lt; DAT E &gt;, &lt; P HOT OGRAP HER &gt; and &lt; LOCAT ION &gt; contain all the information extracted about these information items.</p><p>The patterns are built over regular expressions that allow the extraction of a string contained in any of the mentioned labels. DATE constraints treat to reject images not only comparing question and image years, but applying extra information such as months or quantifiers. This way, if the topic asks for "Pictures of Edinburgh Castle taken before 1900", all the photos taken after 1900 will be discarded. PHOTOGRAPHER constraints are based in the whole name of the photographer. LOCATION constraints use not only the location itself but also, if applicable, possible relations with other locations (city, country, . . . ).</p><p>As can be seen, this technique is very general and, therefore, the possibility of errors is high. To soften this error possibility, the strategy has also in mind statistical information from the image corpus. This way, things that can be incorrectly treated by the pattern as photographers or locations are considered as noise and rejected because of their low or null appearance frequency in the corresponding field in the image. In fact, we can use the same pattern for both location and photographer and then decide what to apply depending on the image. For example, according to the image info, a capitalized word after a comma can be consider both a photographer or a location (as shown in topics "Men in military uniform, George Middlemass Cowie" and "College or university buildings, Cambridge"). After including the extracted string in both fields of the topic generated, the statistical information will determine what is a photographer and what is a location (unless there is a town called George Middlemass or a photographer called Cambridge).</p><p>Once the constraint features are determined and included in the topic through their corresponding labels, the system makes a matching task to reject noncompatible images. So, if it is determined that the photographer of the searched pictures is "Thomas Rodger", all the images that don't contain "Thomas Rodger" (or any of its parts) in the PHOTOGRAPHER label are rejected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Third experiment. Query expansion. Wordnet</head><p>The last experiment has been designed to incorporate extra information regarding to the potential synonym relation between terms in query and image. In this case, the system expands the topic with all the synoyms of nouns and verbs contained in WordNet <ref type="bibr" coords="6,234.42,460.61,9.96,10.46" target="#b4">[6]</ref>.</p><p>According to this, in this case, the scoring for each image is increased if not only a lemma of a word in the topic, but its synonyms in WordNet, appear in the image HEADLINE text.</p><p>Due to there is no lexical disambiguation in the proccess, noun synonyms are best scored than verb synonyms assuming that the former tend to be less generic than the latter. If the synonym is found but with different POS tag, a smaller score is added.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>Although we knew this is a very general approach to this task, the results obtained after the evaluation of the system are not as successful as desired. At the moment of the writing of this paper we are trying to determine if there is any kind of computing processing mistake that has affected the final scoring. Anyway, there are some considerations extracted from the results.</p><p>For the evaluation results, the system was prepared to give always 1000 images as output. This is an error because some (sometimes a lot of) images given by the system are not relevant at all (they have no specific nor score).</p><p>Another problematic issue is the way the system score the images. This scoring is also very general and provides many times the same score for a big quantity of images (in fact, all the images can be grouped in four or five different scores). All the images that are equally scored have, for the system, the same order in the final evaluation scored list, but for the evaluation comparing results there are big differences depending on the order provided for the images.</p><p>Related to the results of the three experiments, one of the most "eye-catching" thing is that, in general, the preferences-baseline experiment gives the best result or is improved in a very small degree by the rest of experiments. This situation can be put down to the lack of additional information regarding to the entities or proper nouns recognition.</p><p>Another interesting thing extracted from the evaluation is that although there is no big differences between the monolingual and the bilingual results, it is clear that automatic translation such as the used one in these experiments incorporates some errors and noise that decrease the system's performance.</p><p>Furthermore, basic techniques of lexical disambiguation and restricted-domain ontologies could improve the use of WordNet and give it new use dimensions.</p><p>Summarizing, although the results are not very good, the system itself presents a lot of improvement possibilities through the refinement of the scoring system, the addition of new techniques based on entity-recognition, the use of better translators and dictionaries and the incorporation of new semantic and ontological information that enforces WordNet access.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper we have described the system carried out by the University of Alicante in the ImageCLEF 2004 adhoc retrieval task. A deep detailed information about the process itself and the strategies and experiments developed for the retrieval task has been given.</p><p>The results of the evaluation has been justified and different solutions to improve these results have been outlined in order to define near future steps for getting a better system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,185.94,488.86,243.39,9.41"><head>1 .Fig. 1 .</head><label>11</label><figDesc>Fig. 1. Image retrieval process and for different experiments</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,149.71,418.86,298.13,10.46;5,149.71,442.81,108.01,10.46;5,134.77,464.94,31.38,10.46;5,140.00,476.90,94.15,10.46;5,140.00,488.86,303.36,10.46;5,145.23,500.81,88.92,10.46;5,140.00,512.77,73.22,10.46;5,140.00,524.72,245.82,10.46;5,140.00,536.67,115.06,10.46;5,134.77,548.64,36.61,10.46"><head>1 .</head><label>1</label><figDesc>Portrait pictures of church ministers by Thomas Rodger is converted into the file: &lt;PREG&gt; &lt;PREGNO&gt;1&lt;/PREGNO&gt; &lt;HEADLINE&gt; Portrait pictures of church ministers by Thomas Rodger&lt;/HEADLINE&gt; &lt;DATE&gt; &lt;/DATE&gt; &lt;PHOTOGRAPHER&gt; by Thomas Rodger &lt;/PHOTOGRAPHER&gt; &lt;LOCATION&gt; &lt;/LOCATION&gt; &lt;/PREG&gt;</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0" coords="1,144.73,644.34,335.72,9.41;1,144.73,655.31,119.25,9.41"><p>This work has been partially supported by the Spanish Government (CICYT) with grant TIC2003-07158-C04-01.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1" coords="4,144.73,633.39,335.72,9.41;4,144.73,644.34,335.73,9.41;4,144.73,655.31,107.26,9.41"><p>This condition is guided by the idea of giving 1000 images for each question, what constitute a misunderstanding of the evaluation process and will be discussed bellow as an evaluation handicap.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,138.35,589.40,31.08,9.41;7,190.25,589.40,290.20,9.41;7,146.91,600.36,315.04,9.41" xml:id="b0">
	<monogr>
		<ptr target="http://ir.shef.ac.uk/imageclef2004/index.html" />
		<title level="m" coord="7,223.24,589.40,227.55,9.41">CLEF in the Cross Language Evaluation Forum</title>
		<imprint>
			<date type="published" when="2004-02">2004. 2004. 2-Aug-2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,611.40,342.10,9.41;7,146.91,622.35,333.54,9.41;7,134.77,633.39,34.66,9.41;7,204.59,633.39,275.86,9.41;7,146.91,644.34,333.53,9.41;7,146.91,655.31,20.98,9.41" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,257.42,611.40,204.71,9.41">The CLEF 2003 cross language image retrieval task</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
		<ptr target="http://specialcollections.st-and.ac.uk/photcol.htm" />
	</analytic>
	<monogr>
		<title level="m" coord="7,146.91,622.35,181.51,9.41">Working Notes for the CLEF 2003 WorkShop</title>
		<meeting><address><addrLine>Trondheim, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>St Andrews University Library photographic</publisher>
			<date type="published" when="2003">2003. 2004. 2-Aug-2004</date>
			<biblScope unit="page" from="379" to="388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,118.18,342.11,9.41;8,146.91,129.14,333.54,9.41;8,146.91,140.10,23.03,9.41" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,196.63,118.18,230.88,9.41">Probabilistic Part-of-Speech Tagging Using Decision Trees</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,448.19,118.18,32.27,9.41;8,146.91,129.14,233.77,9.41">International Conference on New Methods in Language Processing</title>
		<meeting><address><addrLine>Manchester, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="44" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,151.06,342.10,9.41;8,146.91,162.02,20.98,9.41" xml:id="b3">
	<monogr>
		<ptr target="http://world.altavista.com/" />
		<title level="m" coord="8,172.80,151.06,81.34,9.41">BabelFish translator</title>
		<imprint>
			<date type="published" when="2004-02">2004. 2-Aug-2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,172.97,342.10,9.41;8,146.91,183.94,333.66,9.41;8,146.91,194.89,13.82,9.41" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,419.01,172.97,61.44,9.41;8,146.91,183.94,34.28,9.41">Five Papers on WordNet</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Beckwith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,189.90,183.94,232.40,9.41">Special Issue of the International Journal of Lexicography</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="235" to="312" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
