<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,91.02,109.79,413.10,17.49">A probabilistic approach to the medical retrieval task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2004-08">August, 2004</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,155.82,141.21,60.82,9.61"><forename type="first">Koen</forename><surname>Lubbers</surname></persName>
							<email>k.f.lubbers@ewi.utwente.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Twente Enschede</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,225.46,141.21,62.86,9.61"><forename type="first">Arjen</forename><surname>De Vries</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Centrum voor Wiskunde en Informatica (CWI)</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,297.14,141.21,58.47,9.61"><forename type="first">Theo</forename><surname>Huibers</surname></persName>
							<email>t.w.c.huibers@ewi.utwente.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Twente Enschede</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,364.42,141.21,71.62,9.61"><forename type="first">Paul</forename><surname>Van Der Vet</surname></persName>
							<email>p.e.vandervet@ewi.utwente.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Twente Enschede</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,91.02,109.79,413.10,17.49">A probabilistic approach to the medical retrieval task</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2004-08">August, 2004</date>
						</imprint>
					</monogr>
					<idno type="MD5">450F27BA87D572F4A2FC50BDEB56F045</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The amount of information available through all kinds of sources is growing larger and larger. The goal of information retrieval systems is to help a user in efficiently finding relevant information. Image retrieval is a subdomain of information retrieval. This relatively new research area is about gaining access to images that match a certain query. Apart from text, such a query can consist of a sketch or an actual image. Several information retrieval techniques have been applied to the image retrieval field lately <ref type="bibr" coords="1,492.75,335.79,11.38,9.61" target="#b8">[9]</ref>. Although probabilistic retrieval methods are often used to determine the relevance of textual documents, they have hardly been applied to image retrieval tasks. The goal of our research is to find out the possibilities of the probabilistic Westerveld image retrieval method <ref type="bibr" coords="1,430.21,371.31,16.41,9.61" target="#b14">[15]</ref>. In recent years, much research has been done into specific medical image retrieval systems <ref type="bibr" coords="1,485.07,383.19,11.57,9.61" target="#b3">[4,</ref><ref type="bibr" coords="1,499.85,383.19,8.01,9.61" target="#b5">6,</ref><ref type="bibr" coords="1,87.42,395.01,8.01,9.61" target="#b7">8,</ref><ref type="bibr" coords="1,100.05,395.01,13.41,9.61" target="#b9">10,</ref><ref type="bibr" coords="1,118.01,395.01,12.72,9.61" target="#b11">12]</ref>. Because of this, we have chosen to test the non-specific Westerveld method in a medical environment. A part of testing a method is to compare it to other (specific) systems. Until recently, a fair comparison of content-based image retrieval methods under similar circumstances was lacking <ref type="bibr" coords="1,141.88,430.59,16.42,9.61" target="#b12">[13]</ref>. The ImageCLEF medical retrieval task <ref type="bibr" coords="1,337.84,430.59,12.51,9.61" target="#b1">[2]</ref> is an evaluation that tries to change this. We have participated in CLEF to experiment with a medical image collection and to be able to compare our results with other systems. Few studies are known in which medical experts have participated in the evaluation of medical retrieval systems <ref type="bibr" coords="1,164.61,477.93,16.40,9.61" target="#b10">[11]</ref>. Therefore, in addition to our participation in CLEF, we have involved a medical physicist from the Academic Medical Centre (AMC) in Amsterdam in our research. We have asked the expert to identify useful applications of image retrieval techniques within the medical domain, and to reflect upon the setup of ImageCLEF's medical search task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Image retrieval in a medical environment</head><p>Researchers from the University of Berkeley estimate that about 2 billion x-rays are produced in hospitals worldwide each year <ref type="bibr" coords="1,225.75,563.73,12.45,9.61" target="#b6">[7]</ref> (this corresponds to approximately 5.5 million new medical images every day!). A growing number of hospitals is switching to handling their image data in digital format. Current Picture Archiving and Communication Systems (PACS) offer the possibility to save images with additional relevant information, like a patients name or number, and additional information from a medical case. Subsequently, all this data will be available from the different workstations throughout the hospital.</p><p>To identify useful applications of image retrieval systems, we first looked at the present situation with the PACS in the AMC. When images are produced they will be stored automatically with information like patient name, number, body region, and modality as metadata. This metadata is available because of the electronic request a doctor has to submit before the image is produced. This means that searching by body part or modality with a content-based retrieval method will often not be useful, because most of the time the correct modality and body part are available in text. However, an image retrieval system could serve as a control tool. People do make mistakes, and images could, for example, end up at the wrong patient or a doctor who produces an image of the left knee is actually supposed to deliver an image of the right knee. This is where a retrieval system could be convenient: on a basis of already classified images it can determine how much the new image differs from the expectated visual features.</p><p>An important finding in this study is that the PACS used at AMC does not associate images and pathology. When a medical doctor wants to look at images with the same or similar pathology, for example for comparison to the image shown on his screen, no suitable solution exists. The AMC medical experts therefore indicated three particularly useful fields for application of image retrieval tools: education, research and diagnosis. For educational purposes, a medical doctor would like to find images in a corresponding field of pathology. These images could serve as cases for medical students. In the research area, image retrieval could be used to analyze the visual features of clusters of images with corresponding syndromes. This could result in a thesaurus of visual features connected to different kinds of images and syndromes. The third application is the diagnosis of problematic cases. When a medical doctor is not sure about a certain image, he would like to be able to use a retrieval method to find other images of the same kind. In this way, he will find useful information in the cases connected to the retrieved images.</p><p>Apart from identifying useful applications, image retrieval research in a medical environment shows medical experts a way in which technology can support their daily activities. Medical doctors do not always believe in the abilities of computer systems to offer added value to their work. By involving them in image retrieval research, the technological frontiers of the medical sector are explored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head><p>The Westerveld image retrieval approach has not been designed for a specific image collection. It has been mainly tested on collections with a large variety in images. Westerveld, following Vasconcelos <ref type="bibr" coords="2,144.93,539.31,16.39,9.61" target="#b13">[14]</ref>, models the visual features by using Gaussian Mixture Models (GMMs) <ref type="bibr" coords="2,487.26,539.31,16.44,9.61" target="#b14">[15]</ref>. The basic idea is that an image consists of a certain number of 'aspects', where each of these aspects can be described in one component of the GMM. Each sample that is taken from an image is assumed to have been generated by one of these components. A Gaussian Mixture Model (GMM) is a weighted sum of multivariate Gaussian distributions, where the weights are considered as prior probabilities of the different components. We will explain briefly what happens when the parameters for a GMM are estimated. For a more detailed explanation of the generative probabilistic retrieval model the reader is referred to <ref type="bibr" coords="2,361.02,622.23,16.42,9.61" target="#b14">[15]</ref>. The first step in the creation of an image model is to convert the RGB representation of the image into YCbCr colour space. After this step, each of the colour channels of the image is divided into samples of 8 by 8 pixels. Then, a discrete cosine transform (DCT) is performed on every sample. By default, the different samples are described by 14-dimensional vectors. Each vector consists of the first 10 DCT coefficients from the Y channel, the DC coefficient of both the Cb and the Cr channel, and the x en y position of the sample in the image. The feature vectors of an image are fed to the EM algorithm to find the parameters of the mixture models <ref type="bibr" coords="3,240.44,131.49,16.40,9.61" target="#b14">[15]</ref>. The algorithm starts with introducing a given number of components by grouping the samples randomly. This is the first expectation step. In the maximization step, the parameters of each component are calculated, based on the samples assigned to that component. A component represents the average colour and texture of the samples assigned to it. In the second expectation step, the samples are regrouped. For example: a sample of a blue sky will be assigned to the component that explains best the visual characteristics of the blue sky. The Estep and the M-step iterate until the algorithm converges <ref type="bibr" coords="3,177.70,332.97,16.41,9.61" target="#b14">[15]</ref>.</p><p>A collection of images can be indexed by estimating the GMM for each of the images. Query images are represented as a collection of samples. The basis of the retrieval step is to estimate, for each model of the collection images, the probability that the query samples could be observed given that collection image model. In other words, the goal is to find the document that is most likely to have produced a certain query. The joint probability of a document producing this certain query is calculated by multiplying the probabilities for each individual sample of the query <ref type="bibr" coords="3,220.93,486.94,16.35,9.61" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental setup</head><p>The main research question in our ImageCLEF experiments is how a generic image retrieval system would perform on a domain-specific retrieval problem. We decided to ignore the textual information in the medical cases, to provide a solid basis to judge the possible merits of contentbased retrieval techniques for search in medical image archives. The combination with textual information is postponed to future research.</p><p>When the Westerveld method is applied without changes it will work with the following settings: The default values of the method are the point of departure of testing with different parameters.</p><formula xml:id="formula_0" coords="3,87.96,616.21,52.51,10.50">parameter</formula><p>During the process of testing with different parameter settings we varied one parameter at a time.</p><p>We have tested with both values for each of the binary parameters. The basic rule for adjusting the other values is that we will not throw away information with respect to the default settings.</p><p>First, we indexed a subcollection of the medical CLEF collection to find out which parameters would qualify to be used to get the results for the submission. The selected settings from this experiment were used to build eight different indices of the whole medical collection. We then chose the four best indices by ranking all retrieval results with all queries, based on an 'educated guess' of the precision at a document cut-off level of 20 (doing manual assessments ourselves). We distinguished precision A and precision B. The first value is based on an image being relevant or not according to the CLEF task (image being relevant on both body part and modality) and the second one is only based on the modalities of the images. A modality describes the way in which medical images are produced: MRI, CT, etc.</p><p>After the submission of the runs, we have performed more experiments with the system. Several new experiments indicated that the conversion to YCbCr affected the performance of the system negatively. These new experiments were performed with a new subcollection, which consisted of ten relevant images per query. The relevant images were manually selected from the medical CLEF collection with the help of the medical expert from the AMC. Because we knew the number of relevant images for each query in de subcollection, we were able to follow Kraaij <ref type="bibr" coords="4,163.74,369.51,12.49,9.61" target="#b4">[5]</ref> and compare the retrieval results with R-recall. This means that recall is measured at a document cut-off level, which equals the number of relevant images for a certain query.</p><p>Because of the new findings with the second subcollection, we indexed the whole medical collection with parameter convert=0 in order to create a new run. Furthermore, we used the setting without conversion as a new basic state and started varying the other parameters to find another way to improve retrieval results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Analysis</head><p>The experiment we used to select four out of eight runs for submission resulted in the following overview: We submitted the first four runs. Since new experiments showed that results were far better when conversion was not applied, we did not expect very good results from the official medical evaluation. After indexing the medical CLEF collection without conversion, retrieval with the queries proved that results with the whole collection were indeed far better. The following table shows these results; the average precision A equals 0.47. Further experiments with the second subcollection showed that there were no parameter settings that improved the retrieval results of the new basic state with convert=0. We concluded that the best way to use the current version of the Westerveld method with the medical CLEF collection is with only one adjustment: disable the conversion to the YCbCr colour space.</p><formula xml:id="formula_1" coords="4,104.76,516.93,13.58,9.61">res</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>query precision</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query precision query precision query precision</head><p>We found that R-recall in the experiments with the second subcollection varied from 0.41 to 0.48. We got these results by testing with the fixed settings convert=0, while varying the other parameters one by one. After the release of the judgements from the CLEF medical task (the socalled qrels), we were able to calculate R-recall values for the results we found after retrieval with the total medical image collection. The average R-recall value over the 26 queries equals 0.29. This means that our subcollection may have been a more ideal test environment than the whole CLEF collection, but it can also imply that we evaluated the results less strictly than the CLEF assessors did.</p><p>Although the official CLEF evaluation results have been released <ref type="foot" coords="5,372.72,402.98,3.41,6.14" target="#foot_0">3</ref> , it is still difficult to compare methods across systems. We submitted four automatic runs without using the medical cases, while other participants may have used text retrieval methods in addition to an initial visual run. However, our results should be comparable with the initial results of the VIPER <ref type="foot" coords="5,439.50,438.50,3.41,6.14" target="#foot_1">4</ref> system. These results are only based on visual similarity and available for participants who do not use their own content-based image retrieval system. Based on the released VIPER results, which were meant for participants who only used text-based methods, we calculated the R-recall value in the same way as we did with our results. The average R-recall for VIPER over the 26 queries equals 0.37.</p><p>The official results are expressed in Mean Average Precision (MAP). The best results of an automatic run submitted to the CLEF medical task scores 0.34885. However, the systems that perform this well did use textual information from the medical cases in addition to the visual features from the image. The best result from the runs we submitted has a MAP of 0.1065. The use of the new parameter settings showed the improvement we expected: the Westerveld method performs about twice as good when the colour space is not converted. Using the RGB representation of the images, the systems scores a MAP of 0.2359, which is a satisfying initial retrieval result.</p><p>The </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Conversion of colour spaces</head><p>Based on our experience with the retrieval model on other image retrieval tasks, we expected that indexing the collection without conversion to the YCbCr colour space would have given inferior results <ref type="foot" coords="6,115.32,321.08,3.41,6.14" target="#foot_2">5</ref> . The results after the submission of the runs however, showed that without conversion the retrieval method performed about twice as good. This finding proved to be reproducible.</p><p>Since earlier testing with the Westerveld method turned out that better results were obtained when working with YCbCr colour space, the following question remains: why does conversion perform less well with the medical collection? We have not yet found a perfect explanation for the degraded retrieval effectiveness after conversion to YCbCr color space. We believe that the cause of the observed change in performance is to be found in the difference between the medical collection and the previously used testing collections: the medical collection consists almost completely of black and white images.</p><p>In colour images, the three channels in RGB all contain information on both intensity and colour, so the different dimensions are correlated. The motivation for conversion is that in YCbCr colour space, the intensity channel (Y) is separated from the colour channels (Cb and Cr), and the information in each channel is independent from the information in the other channels.</p><p>In a greyscale situation however, there is no colour information, and the three channels represent the same amount of intensity: R=G=B. The formulas for conversion from RGB to YCbCr are the following: Y = 0.257R + 0.504G + 0.098B + 16 Cb = -0.148R -0.291G +0.439B + 128 Cr = 0.439R -0.368G -0.071B + 128</p><p>Given a greyscale image, Y will be created as usual, but the Cb and the Cr channel both equal 128 in every possible greyscale situation. Now, recall that the feature vectors to represent the image samples are computed from the DCT transformation over 8x8 pixel blocks. In the feature vectors for an RGB image, the first DCT coefficient (corresponding to the average intensity in the pixel block) is represented in three dimensions. In the YCbCr case, this information is only represented in one dimension.</p><p>Theoretically, because we assume a diagonal covariance matrix, the complete correlation between the three dimensions in the RGB case (those corresponding to the first DCT coefficient of the three (identical) color channels) should however affect retrieval negatively rather than improve its results. Yet, the experiments proof otherwise.</p><p>Our current intuition is that the duplicated information separates, in feature space, the intensity information more than the textural information (which is represented in the higher coefficients of the DCT transformation). This 'encourages' the EM algorithm model during training to prefer textural information over the intensity information in the image samples. For medical images, the textural information is more important than the intensity information, so this could explain the improved effectiveness of the model. This hypothesis is further supported by observations in earlier experiments (on TRECVID data) <ref type="bibr" coords="7,285.38,178.89,16.40,9.61" target="#b16">[17]</ref>, where we demonstrated that the textural information in images was dominated by colour information (on YCbCr colour space). Further research is however needed to (in)validate this explanation of the experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Interactive experiments</head><p>After identifying useful applications of medical image retrieval systems, we applied the probabilistic approach in an interactive retrieval system. This system tries to learn from the relevance feedback given by the user <ref type="bibr" coords="7,255.77,266.85,11.34,9.61" target="#b0">[1]</ref>, attempting to reduce the semantic gap by inserting a human 'in-the-loop'. More information about this research activity can be found in <ref type="bibr" coords="7,444.79,278.67,11.33,9.61" target="#b2">[3]</ref>. In order to realise a suitable system, we had to shorten the retrieval time and make the method user-friendly.</p><p>Again, since we want to learn the strengths of the content-based image retrieval method, we did not use the text in the medical case descriptions. Note that Smeulders describes two other ways to deal with semantics: interpretation and similarity between features <ref type="bibr" coords="7,390.69,326.07,16.41,9.61" target="#b12">[13]</ref>. Because the medical images are not yet classified as relevant or irrelevant for a certain topic, we cannot use these two ways yet.</p><p>After a medical doctor of the AMC uploads a query image, the system estimates the parameters of its GMM. It then compares the query model to the GMMs of the images in the CLEF collection and presents an initial retrieval result. For efficiency reasons, an approximation of the Kullback Leibler distance between the image models is used as an alternative to the likelihood of observing the query image samples. The results obtained are very similar to those of the original system. After this initial retrieval step, the medical doctor marks retrieved images as relevant or irrelevant; the next iteration takes the feedback into account to re-rank the remaining images.</p><p>The interactive system turned out to be very intuitive and easy to use, partially because the doctors in the AMC are already used to a web-based interface for accessing the PACS system. After a query has been uploaded the system is sufficiently fast in presenting the retrieval results. Within a minute, a medical doctor can go through about five iterations. Figure <ref type="figure" coords="7,460.17,492.99,5.34,9.61" target="#fig_1">2</ref> shows a screenshot of the interactive retrieval system (it shows the results after uploading topic 24 of the medical CLEF collection).</p><p>The interactive experiment pointed out two possible improvements for our retrieval system. First, although the medical CLEF collection is representative for the type of images encountered in the AMC, two main differences are observed in relation to the background and the greyscale representation of the images. When we save an AMC image as JPEG and make it anonymous, all black and white images are represented as greyscale instead of RGB. Of course, only a minor modification fixes this. A more significant difference is that the AMC data consist for a large part of the image of black background only. The subjects within the images of the CLEF collection seem to have been cropped cleverly. Finally, explaining the search task applied at the ImageCLEF medical retrieval task to the medical expert has raised some issues with the task evaluated at this first medical image CLEF evaluation, and also demonstrated clearly the existence of 'the semantic gap'. From the system point of view, the results did not look bad, and any mistakes could be easily explained from its inner workings.</p><p>The system performs well at retrieving images with the same kind of visual features, which often means the same modality. However, medical doctors are interested in finding images with corresponding syndromes, or at least corresponding body parts. It is far more interesting to retrieve a CT of the brain with an MRI of the brain as a query, than to find an abdomen MRI with it. It may be more useful to measure the performance of retrieval systems using body part only (as opposed to the performance on modality only).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>The main goal of our research was to investigate if a generic image retrieval model could also be applied to a domain-specific task such as the retrieval of medical images. We have tested the probabilistic image retrieval model developed by Westerveld using the CLEF medical image test collection, which allows the objective comparison of different approaches to the retrieval problem. We also evaluated an interactive version of our system with a medical expert from the AMC.</p><p>The best performance of the Westerveld method has been obtained after adjusting one of the parameters in the representation of the image data. When the medical images are not converted from RGB to YCbCr colour space, the Mean Average Precision in our runs equals 0.2359. This is a satisfying result, especially when considering that we have not used the text of the medical cases in our system.</p><p>It is essential that medical doctors -the future users of image retrieval systems -are involved in image retrieval research. With the help from the AMC we identified a number of useful medical retrieval applications. Evaluating the CLEF images with a medical expert showed that the collection seems to be a rather ideal representation of the images present in the hospital. Furthermore, an experiment with the probabilistic Westerveld method indicated the semantical gap. Retrieval results are most likely to be useful when a system can deal with this gap. Since we neglected text in our approach, we tried to apply the retrieval method in an interactive system. This system proved to be easy to use and to work fast. However, it still needs to learn from the relevance feedback of experts. Improvements of the Westerveld method itself and allowing the interactive system to learn from medical doctors can lead to adequate support of the daily activities in medical practise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Future work</head><p>The AMC image collection showed that an image retrieval method needs to be able to work with greyscale images. Furthermore, it seemed that images from this hospital contained a large black background. An experiment with the smoothing function of the Westerveld can show if the system can automatically neglect this background.</p><p>To obtain better retrieval results, we have to deal with the semantic gap. The interactive system will only improve when real users give relevance feedback to initial results. Further research should point out if the system is really able to learn from experience.</p><p>An other way to deal with semantics, is to embrace a text retrieval method. The Westerveld method has already been tested in combination with a probabilistic text retrieval approach <ref type="bibr" coords="9,475.18,383.13,16.44,9.61" target="#b14">[15]</ref>. During a next medical retrieval task it may be possible to increase the performance of retrieval systems through interpretation and similarity between features. The clusters of relevant images per query offer the possibility to create a sort of medical thesaurus, which consists of visual features of certain modalities, body parts, or even syndromes.</p><p>Evaluation with the AMC showed that searching for images with identical modality and body part is not a useful task for image retrieval systems. This means that the present CLEF task will not reach. Medical doctors will be interested in a certain pathology: they want to find images with corresponding syndromes. It would be useful if the next medical CLEF collection contained a number of subcollections. A subcollection can, for example, contain images with corresponding body parts. A challenge for image retrieval systems is to distinguish the visual features of images that do contain a certain abnormality, and images that do not.</p><p>Finally, we would like to add another challenge for image retrieval research. The basis of an image retrieval method is a certain image collection that can be indexed. However, when a medical doctor wants to use an application to search for clues regarding the diagnosis of his query image, he might not find satisfying results in the image collection at his own hospital. Retrieval systems can really add value when experts from several hospitals can learn from each others experience. This implies the need for a standard way of indexing and searching. Such a standard can only be reached when different research groups meet to evaluate their results together. This shows the importance of evaluations like ImageCLEF in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,280.74,427.02,222.86,8.77;3,370.68,437.88,42.97,8.77;3,270.54,99.42,253.08,324.30"><head>Figure 1 -</head><label>1</label><figDesc>Figure 1 -Building a Gaussian Mixture Model from animage<ref type="bibr" coords="3,397.41,437.88,16.23,8.77" target="#b17">[18]</ref> </figDesc><graphic coords="3,270.54,99.42,253.08,324.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="8,87.42,421.02,323.98,8.77;8,87.42,105.66,414.30,310.44"><head>Figure 2 -</head><label>2</label><figDesc>Figure 2 -Screenshot of the initial retrieval results after searching with query 24</figDesc><graphic coords="8,87.42,105.66,414.30,310.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,87.18,616.53,405.01,117.55"><head>default value</head><label></label><figDesc></figDesc><table coords="3,87.18,616.53,386.82,105.61"><row><cell></cell><cell></cell><cell>Description</cell></row><row><cell>blocksize</cell><cell>8</cell><cell>size of the samples in pixels</cell></row><row><cell>c</cell><cell>8</cell><cell>number of mixture components</cell></row><row><cell>convert</cell><cell>1</cell><cell>binary, convert image from RGB to YCbCr colour space</cell></row><row><cell>imagesize</cell><cell>240x352</cell><cell>size to which an image is scaled before samples are taken</cell></row><row><cell cols="2">ncoeffcbcr 1</cell><cell>number of DCT coefficients from Cb and Cr channel</cell></row><row><cell>ncoeffy</cell><cell>10</cell><cell>number of DCT coefficients from Y channel</cell></row><row><cell>overlap</cell><cell>0</cell><cell>binary, samples will overlap or not</cell></row><row><cell>scale</cell><cell>1</cell><cell></cell></row></table><note coords="3,228.04,712.53,206.77,9.61;3,87.18,724.47,25.67,9.61;3,148.06,724.47,5.34,9.61;3,228.04,724.47,264.15,9.61"><p>binary, image is scaled before samples are taken xypos 1 binary, x and y position of a sample are used in feature vector</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,87.42,107.85,420.42,162.85"><head></head><label></label><figDesc>following table shows the official average precisions (AP) per query. It is separated in c=16 (best result with conversion to YCbCr) and RGB (no conversion).</figDesc><table coords="6,100.38,141.57,389.21,129.13"><row><cell>query</cell><cell>AP</cell><cell></cell><cell>query</cell><cell>AP</cell><cell></cell><cell>query</cell><cell>AP</cell></row><row><cell></cell><cell>c=16</cell><cell>RGB</cell><cell></cell><cell>c=16</cell><cell>RGB</cell><cell>c=16</cell><cell>RGB</cell></row><row><cell>1</cell><cell cols="2">0.0028 0.1267</cell><cell>10</cell><cell cols="2">0.1031 0.1136</cell><cell>19</cell><cell>0.1024 0.0776</cell></row><row><cell>2</cell><cell cols="2">0.0096 0.4920</cell><cell>11</cell><cell cols="2">0.0011 0.0014</cell><cell>20</cell><cell>0.0004 0.0283</cell></row><row><cell>3</cell><cell cols="2">0.0379 0.2423</cell><cell>12</cell><cell cols="2">0.0047 0.0822</cell><cell>21</cell><cell>0.0677 0.0253</cell></row><row><cell>4</cell><cell cols="2">0.0014 0.0096</cell><cell>13</cell><cell cols="2">0.0231 0.1663</cell><cell>22</cell><cell>0.0145 0.0915</cell></row><row><cell>5</cell><cell cols="2">0.0003 0.0285</cell><cell>14</cell><cell cols="2">0.0914 0.1121</cell><cell>23</cell><cell>0.0055 0.1941</cell></row><row><cell>6</cell><cell cols="2">0.0592 0.4274</cell><cell>15</cell><cell cols="2">0.0056 0.6750</cell><cell>24</cell><cell>0.0300 0.7961</cell></row><row><cell>7</cell><cell cols="2">0.9341 0.8702</cell><cell>16</cell><cell cols="2">0.0439 0.2757</cell><cell>25</cell><cell>0.6077 0.5636</cell></row><row><cell>8</cell><cell cols="2">0.0003 0.0498</cell><cell>17</cell><cell cols="2">0.0015 0.0237</cell><cell>26</cell><cell>0.5458 0.5157</cell></row><row><cell>9</cell><cell cols="2">0.0241 0.0905</cell><cell>18</cell><cell cols="2">0.0500 0.0534</cell><cell>MAP</cell><cell>0.1065 0.2359</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="5,94.32,752.64,353.83,8.77"><p>See http://ir.shef.ac.uk/imageclef2004/med_results/medical_results.html for official results</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="5,94.32,763.56,294.00,8.77"><p>See http://viper.unige.ch/ for a list of publications about the VIPER system.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="6,91.56,749.16,408.93,8.77;6,92.82,760.08,401.28,8.77"><p>The first experiment with the subcollection confirmed this expectation. We assume that the subcollection was accidentally converted in this experiment, while the samples of the queries were not, or vice versa.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>Without the help of <rs type="person">Thijs Westerveld</rs> we would not have been able to participate and test with a probabilistic approach to image retrieval. We would also like to thank <rs type="person">Lioudmila Boldareva</rs> for making it possible to combine the used method with the interactive relevance feedback system. Finally, we thank <rs type="person">Jan Habraken</rs>, who helped us evaluating our image retrieval work from a medical point of view.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="10,122.44,124.89,385.43,9.61;10,122.40,136.71,24.07,9.61" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="10,188.34,124.89,315.42,9.61">Improving object&apos;s similarities with relevance judgements from the user</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Boldareva</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,122.43,148.53,385.33,9.61;10,122.40,160.41,120.34,9.61" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="10,297.41,148.53,210.35,9.61;10,122.40,160.41,66.80,9.61">A proposal for the CLEF Cross Lanuage Image Retrieval Track</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,122.40,172.23,385.41,9.61;10,122.40,184.11,213.97,9.61" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">F</forename><surname>Lubbers</surname></persName>
		</author>
		<title level="m" coord="10,196.79,172.23,311.02,9.61;10,122.40,184.11,98.77,9.61">Image retrieval in de medische praktijk: mogelijkheden van een probabilistische aanpak</title>
		<imprint>
			<date type="published" when="2004-08">August 2004</date>
		</imprint>
	</monogr>
	<note type="report_type">Msc thesis</note>
</biblStruct>

<biblStruct coords="10,122.43,195.93,385.31,9.61;10,122.40,207.75,385.33,9.61;10,122.40,219.63,189.94,9.61" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,429.01,195.93,78.73,9.61;10,122.40,207.75,160.69,9.61">Fast and effective retrieval of medical tumor shapes</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Korn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Protopapas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,294.96,207.75,212.77,9.61;10,122.40,219.63,50.90,9.61">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="889" to="904" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,122.44,231.45,376.96,9.61;10,122.40,243.33,179.83,9.61" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="10,172.64,231.45,247.77,9.61">Variations on language modeling for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
		<idno>No. 04-62</idno>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Neslia Paniculata</publisher>
		</imprint>
	</monogr>
	<note type="report_type">CTIT PhD thesis series</note>
</biblStruct>

<biblStruct coords="10,122.40,255.15,385.62,9.61;10,122.40,267.03,385.53,9.61;10,122.40,278.85,256.10,9.61" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,312.39,267.03,195.53,9.61;10,122.40,278.85,52.92,9.61">Content-based Image Retrieval in Medical Applications</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">O</forename><surname>Güld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Thies</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Spitzer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kohnen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">B</forename><surname>Wein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,182.46,278.85,152.94,9.61">Methods of Information in Medicine</title>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct coords="10,122.44,290.67,241.39,9.61" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="10,232.14,290.67,100.38,9.61">How Much Information</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Lyman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">R</forename><surname>Varian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,122.44,302.55,385.38,9.61;10,122.40,314.37,385.33,9.61;10,122.40,326.31,226.78,9.61" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,456.10,302.55,51.72,9.61;10,122.40,314.37,300.11,9.61">PathMaster: Content-based cell image retrieval using automated feature extraction</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Mattie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Staib</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stratmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">D</forename><surname>Tagare</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,429.72,314.37,78.01,9.61;10,122.40,326.31,143.92,9.61">Journal American Medical Information Asssociation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="404" to="415" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,122.43,338.13,385.40,9.61;10,122.40,349.95,385.55,9.61;10,122.40,361.83,24.07,9.61" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,368.54,338.13,139.28,9.61;10,122.40,349.95,182.01,9.61">Content-based query of image databases: inspirations from text retrieval</title>
		<author>
			<persName coords=""><surname>Mcg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Pun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,312.42,349.95,120.49,9.61">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1193" to="1198" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,122.41,373.65,385.30,9.61;10,122.40,385.53,324.19,9.61" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,353.33,373.65,154.38,9.61;10,122.40,385.53,151.28,9.61">Comparing feature sets for contentbased medical information retrieval</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Vallée</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Geissbuhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,280.14,385.53,95.96,9.61">SPIE Medical Imaging</title>
		<imprint>
			<date type="published" when="2004">Februari 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,122.42,397.35,385.39,9.61;10,122.40,409.23,385.41,9.61;10,122.40,421.06,160.74,9.61" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,363.44,397.35,144.36,9.61;10,122.40,409.23,319.21,9.61">A review of content-based image retrieval systems in medicine -clinical benefits and future directions</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Michoux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bandon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Geissbuhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,451.32,409.23,56.49,9.61;10,122.40,421.06,132.26,9.61">International Journal of Medical Informatics</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,122.43,432.88,385.42,9.61;10,122.40,444.76,385.43,9.61;10,122.40,456.58,315.29,9.61" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,122.40,444.76,385.43,9.61;10,122.40,456.58,39.27,9.61">ASSERT -A physician-in-the-loop content-based retrieval system for HRCT image databases</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">R</forename><surname>Shyu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Brodley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Kak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kosaka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Aisen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">S</forename><surname>Broderick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,168.72,456.58,180.36,9.61">Computer Vision an Image Understanding</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="111" to="132" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,122.42,468.46,385.36,9.61;10,122.40,480.28,385.38,9.61;10,122.40,492.10,233.83,9.61" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,416.18,468.46,91.60,9.61;10,122.40,480.28,174.40,9.61">Content-based image retrieval at the end of the early years</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">W M</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Santini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,306.48,480.28,201.30,9.61;10,122.40,492.10,89.12,9.61">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2000-12">December 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,122.43,503.98,385.37,9.61;10,122.40,515.80,216.69,9.61" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="10,208.32,503.98,233.45,9.61">Bayesian models for visual information retrieval</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000-06">June 2000</date>
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="10,122.41,527.68,385.36,9.61;10,122.40,539.50,385.40,9.61;10,122.40,551.38,385.44,9.61;10,122.40,563.20,162.36,9.61" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,500.07,527.68,7.71,9.61;10,122.40,539.50,276.83,9.61">A Probabilistic Multimedia Retrieval Model and Its Evaluation</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Westerveld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Vries</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ballegooij</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Van</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,409.44,539.50,98.36,9.61;10,122.40,551.38,115.11,9.61">EURASIP Journal on Applied Signal Processing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>Special Issue on Unstructured Information Management from Multimedia Data Sources</note>
</biblStruct>

<biblStruct coords="10,122.43,575.02,385.31,9.61;10,122.40,586.90,322.38,9.61" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,459.55,575.02,48.19,9.61;10,122.40,586.90,172.00,9.61">Combining Information Sources for Video Retrieval</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Westerveld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ianeva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Boldareva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Vries</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,301.20,586.90,111.67,9.61">TRECVID 2003 Workshop</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,122.44,598.72,385.41,9.61;10,122.40,610.60,268.33,9.61;10,390.78,608.36,5.33,6.14;10,399.12,610.59,108.65,9.61;10,122.40,622.41,385.38,9.61;10,122.40,634.23,47.29,9.61" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,291.72,598.72,216.13,9.61;10,122.40,610.60,154.45,9.61">Experimental Result Analysis for a Generative Probabilistic Image Retrieval Model</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Westerveld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Vries</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>De</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,296.22,610.60,94.51,9.61;10,390.78,608.36,5.33,6.14;10,399.12,610.59,108.65,9.61;10,122.40,622.41,299.69,9.61">Proceedings of the 26 th International Conference on Research and Development in Information Retrieval (SIGIR&apos;03)</title>
		<meeting>the 26 th International Conference on Research and Development in Information Retrieval (SIGIR&apos;03)<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-07">July, 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,122.41,646.11,385.38,9.61;10,122.40,657.93,385.30,9.61;10,122.40,669.81,131.73,9.61" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,274.17,646.11,233.62,9.61;10,122.40,657.93,175.11,9.61">Experimental Evaluation of a Generative Probabilistic Image Retrieval Model on &apos;Easy&apos;Data</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Westerveld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Vries</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>De</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,308.16,657.93,199.54,9.61;10,122.40,669.81,100.67,9.61">Proceedings of the Multimedia Information Retrieval Workshop &apos;03</title>
		<meeting>the Multimedia Information Retrieval Workshop &apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
