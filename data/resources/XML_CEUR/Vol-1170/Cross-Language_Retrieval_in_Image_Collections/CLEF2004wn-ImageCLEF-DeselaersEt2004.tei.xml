<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,127.92,148.42,347.17,15.15;1,179.69,169.90,243.63,15.15">FIRE -Flexible Image Retrieval Engine: ImageCLEF 2004 Evaluation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,193.25,203.52,77.10,8.74"><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
							<email>deselaers@cs.rwth-aachen.de</email>
							<affiliation key="aff0">
								<orgName type="department">Lehrstuhl für Informatik VI -Computer Science Department</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<postCode>D-52056</postCode>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,277.99,203.52,63.26,8.74"><forename type="first">Daniel</forename><surname>Keysers</surname></persName>
							<email>keysers@cs.rwth-aachen.de</email>
							<affiliation key="aff0">
								<orgName type="department">Lehrstuhl für Informatik VI -Computer Science Department</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<postCode>D-52056</postCode>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,349.11,203.52,60.63,8.74"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
							<email>ney@cs.rwth-aachen.de</email>
							<affiliation key="aff0">
								<orgName type="department">Lehrstuhl für Informatik VI -Computer Science Department</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<postCode>D-52056</postCode>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,127.92,148.42,347.17,15.15;1,179.69,169.90,243.63,15.15">FIRE -Flexible Image Retrieval Engine: ImageCLEF 2004 Evaluation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EA7D805D931BD1D7D35BDF79E0832CB4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we present FIRE, a content-based image retrieval system and the methods we used in the ImageCLEF 2004 evaluation. In FIRE, different features are available to represent images. This diversity of available features allows the user to adapt the system to task specific characteristics. A weighted combination of these features admits very flexible query formulations and helps in processing specific queries. For the ImageCLEF 2004 evaluation, we used content-based methods only and the experimental results compare favorably well with other systems that make use of the textual information in addition to the images.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Content-based image retrieval is an area of active research in the field of pattern analysis and image processing. The need for content-based techniques becomes obvious when considering the enormous amounts of digital images produced day by day e.g. by digital cameras or digital imaging methods in medicine. The alternative of annotating large amounts of images manually is a very time consuming task. Another very important aspect is that images can contain information that cannot be expressed precisely in textual annotation <ref type="bibr" coords="1,312.64,484.08,14.61,8.74" target="#b16">[17]</ref>. Thus, even the most complete annotation is useless if it does not contain the details that might be of importance to the actual users. The only way to solve these problems is to use fully automatic, content-based methods.</p><p>Several content-based image retrieval systems have been proposed. One of the first systems was the QBIC system <ref type="bibr" coords="1,187.84,530.94,9.97,8.74" target="#b4">[5]</ref>. Other popular research systems are BlobWorld <ref type="bibr" coords="1,412.95,530.94,9.96,8.74" target="#b0">[1]</ref>, VIPER/GIFT <ref type="bibr" coords="1,494.74,530.94,14.61,8.74" target="#b17">[18]</ref>, SIMBA <ref type="bibr" coords="1,126.12,542.66,14.61,8.74" target="#b15">[16]</ref>, and SIMPLIcity <ref type="bibr" coords="1,221.31,542.66,14.62,8.74" target="#b19">[20]</ref>.</p><p>In this work we present FIRE, a content-based image retrieval system and the methods we used in the ImageCLEF 2004 evaluation. FIRE is easily extendable, offers a wide repertory of available features and distance functions and these varieties allow for assessing the performance of different features for different tasks. FIRE is freely available under the terms of the GNU General Public License<ref type="foot" coords="1,152.88,599.66,3.97,6.12" target="#foot_0">1</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Retrieval techniques</head><p>In content-based image retrieval, images are searched by their appearance and not by textual annotations. Thus, images have to be represented by features and these features are compared to search for images similar to a given query image. In FIRE, each image is represented by a set of features. To find images similar to a given query image, the features from the images in the database are compared to those of the query image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Query by Example</head><p>Query by example means that the system is given a query image Q and the goal is to find images from the database which are similar to the given query image. In FIRE, images are represented by features and compared using feature-specific distance measures. These distances are combined in a weighted sum:</p><formula xml:id="formula_0" coords="2,226.21,176.05,150.57,30.20">D(Q, X) := M m=1 w m • d m (Q m , X m )</formula><p>where Q is the query image, X ∈ B is an image from the database B, Q m and X m are the mth features of the images Q and X, respectively, d m is the corresponding distance measure, and w m is a weighting coefficient. For each d m , X∈B d m (Q m , X m ) = 1 is enforced by re-normalization. The K database images with lowest D(Q, X) are returned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Relevance Feedback</head><p>Relevance Feedback is a widely used technique <ref type="bibr" coords="2,294.51,293.90,15.49,8.74" target="#b12">[13]</ref> that allows for good user interaction and easy query refinements. After a query has been processed, the user is presented a reasonably large set of results. From these, the user can select some images as relevant results Q + and some images as irrelevant results Q -and requery the system with these sets. To process this query, we calculate scores S(Q, X) = e -γD(Q,X) with γ = 1.0 for the images and combine these into one score</p><formula xml:id="formula_1" coords="2,189.40,362.60,224.21,22.68">S(Q + , Q -, X) = q∈Q + S(q, X) + q∈Q - (1 -S(q, X)).</formula><p>The set of the K images with the highest scores is returned. The interface used for for relevance feedback is shown in Figure <ref type="figure" coords="2,213.98,409.07,3.88,8.74">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Query Expansion</head><p>A frequent method for enhancing the query results is query expansion. In FIRE, query expansion is implemented as an "automatic relevance feedback" <ref type="bibr" coords="2,325.21,466.55,14.62,8.74" target="#b12">[13]</ref>. The user specifies a number of images G that he expects to be relevant after the first query. Then a query is processed in two steps: First the query is evaluated and the first G images are returned. These G images are automatically used as set of relevant images Q + to requery the database and the K best matches are returned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Features and Associated Distance Measures</head><p>This section gives a short description of each of the features used in the FIRE image retrieval system for the ImageCLEF 2004 evaluation. Table <ref type="table" coords="2,288.57,567.58,4.98,8.74" target="#tab_0">1</ref> gives an overview of the features and associated distance measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Appearance-based Image Features</head><p>The most straight-forward approach is to directly use the pixel values of the images as features. For example, the images might be scaled to a common size and compared using the Euclidean distance. In optical character recognition and for medical data improved methods based on image features usually obtain excellent results <ref type="bibr" coords="2,265.18,660.20,10.52,8.74" target="#b8">[9,</ref><ref type="bibr" coords="2,279.02,660.20,12.73,8.74" target="#b9">10,</ref><ref type="bibr" coords="2,295.07,660.20,11.62,8.74" target="#b10">11]</ref>.</p><p>In this work, we used 32 × 32 and 32 × X(keeping the aspect ration) versions of the images. The 32 × 32 images are compared using Euclidean distance and the 32 × X images are compared using image distortion model distance (IDM) <ref type="bibr" coords="2,290.14,695.35,9.97,8.74" target="#b8">[9]</ref>.</p><p>IDM is a zero-order image comparison measure that allows local pixel displacements. Local dependencies in the displacement grid are neglected. We consider a deformation grid x IJ 11 , y IJ   11   explaining an I × J image A = {a ij }, i = 1, . . . , I, j = 1, . . . , J with an X × Y image B = Figure <ref type="figure" coords="3,122.57,468.31,3.88,8.74">1</ref>: Interface for relevance feedback. The user is presented with the best matches from the database (top left is the query image) and can select for each image whether it is relevant, irrelevant or neutral.</p><p>{b xy }, x = 1, . . . , X, y = 1, . . . , Y . Given this deformation grid, the distance between the aligned images is computed as</p><formula xml:id="formula_2" coords="3,210.05,543.03,182.91,21.98">C(A, B, (x IJ 11 , y IJ 11 )) = i,j ||a ij -b xij ,yij || 2 .</formula><p>and the IDM distance is calculated as</p><formula xml:id="formula_3" coords="3,215.01,589.45,167.17,19.71">D(A, B) = min x IJ 11 ,y IJ 11 C(A, B, (x IJ 11 , y IJ 11 ))</formula><p>taking into account a global warp range limiting the displacement range for the pixels. Instead of using only single pixels, here local context of 3 × 3 pixels of the horizontal and vertical Sobel derivatives of the images are used <ref type="bibr" coords="3,240.21,641.66,9.97,8.74" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Color Histograms</head><p>Color histograms are widely used in image retrieval <ref type="bibr" coords="3,316.12,687.06,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="3,329.75,687.06,7.75,8.74" target="#b4">5,</ref><ref type="bibr" coords="3,340.61,687.06,12.73,8.74" target="#b14">15,</ref><ref type="bibr" coords="3,356.45,687.06,11.63,8.74" target="#b16">17]</ref>. Color histograms are one of the most basic approaches and to show performance improvements, image retrieval systems often are compared to a system using only color histograms. The color space is partitioned and for each partition the pixels with a color within its range are counted, resulting in a representation of the relative frequencies of the occurring colors. In accordance with <ref type="bibr" coords="3,365.65,733.93,14.61,8.74" target="#b14">[15]</ref>, we use the Jeffrey divergence to compare histograms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Invariant Feature Histograms</head><p>A feature is called invariant with respect to certain transformations if it does not change when these transformations are applied to the image. The transformations considered here are translation, rotation, and scaling. In this work, invariant feature histograms as presented in <ref type="bibr" coords="4,480.30,153.60,15.50,8.74" target="#b15">[16]</ref> are used. These features are based on the idea of constructing features invariant with respect to certain transformations by integration over all considered transformations. The resulting histograms are compared using the Jeffrey divergence <ref type="bibr" coords="4,277.71,188.75,14.62,8.74" target="#b14">[15]</ref>. Previous experiments have shown that the characteristics of invariant feature histograms and color histograms are very similar and that invariant feature histograms often outperform color histograms <ref type="bibr" coords="4,324.93,212.18,9.96,8.74" target="#b3">[4]</ref>. Thus, in this work color histograms are not used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Tamura Features</head><p>In <ref type="bibr" coords="4,101.94,269.66,15.50,8.74" target="#b18">[19]</ref> the authors propose six texture features corresponding to human visual perception: coarseness, contrast, directionality, line-likeness, regularity, and roughness. From experiments testing the significance of these features with respect to human perception, it was concluded that the first three features are very important. Thus in our experiments we use coarseness, contrast, and directionality to create a histogram describing the texture <ref type="bibr" coords="4,343.10,316.52,10.52,8.74" target="#b1">[2]</ref> and compare these histograms using the Jeffrey divergence <ref type="bibr" coords="4,188.16,328.24,14.62,8.74" target="#b14">[15]</ref>. In the QBIC system <ref type="bibr" coords="4,302.43,328.24,10.51,8.74" target="#b4">[5]</ref> histograms of these features are used as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Global Texture Descriptor</head><p>In <ref type="bibr" coords="4,102.99,374.00,10.52,8.74" target="#b1">[2]</ref> a texture feature consisting of several parts is described: Fractal dimension measures the roughness or the crinkliness of a surface. In this work the fractal dimension is calculated using the reticular cell counting method <ref type="bibr" coords="4,224.55,397.43,9.96,8.74" target="#b6">[7]</ref>. Coarseness characterizes the grain size of an image. Here it is calculated depending on the variance of the image. Entropy is used as a measure of unorderedness or information content in an image. The Spatial gray-level difference statistics (SGLD) describes the brightness relationship of pixels within neighborhoods. It is also known as co-occurrence matrix analysis <ref type="bibr" coords="4,159.42,444.29,9.97,8.74" target="#b7">[8]</ref>. . The Circular Moran autocorrelation function measures the roughness of the texture. For the calculation a set of autocorrelation functions is used <ref type="bibr" coords="4,394.33,456.01,9.97,8.74" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Region-based Features</head><p>Another approach to representing images is based on finding image regions which roughly correspond to objects or parts of objects in the images. To this purpose, the image is segmented into regions. The task of segmentation has been thoroughly studied <ref type="bibr" coords="4,372.35,525.20,14.62,8.74" target="#b13">[14]</ref>, but most of the algorithms are limited to special tasks because image segmentation is closely connected to understanding arbitrary images, a yet unsolved problem. Nevertheless, some image retrieval systems successfully use image segmentation techniques <ref type="bibr" coords="4,249.31,560.35,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="4,264.11,560.35,11.63,8.74" target="#b19">20]</ref>. We use the approach presented in <ref type="bibr" coords="4,443.51,560.35,15.49,8.74" target="#b19">[20]</ref> to compare region descriptions of images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Color/Gray Binary Feature</head><p>Since the databases contain both color images and gray value images, an obvious feature is whether the image is a color or gray valued image. This can be extracted easily by examining a reasonably large amount of pixels in the image. If all of these pixels are gray valued, the image is considered to be a gray valued images, otherwise it is considered to be a color image. This feature can easily be tested for equality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Submissions to the ImageCLEF 200Evaluation</head><p>The ImageCLEF 2004 evaluation covered 3 tasks: 1. Bilingual ad-hoc task using the St. Andrews database of historic photographs, 2. Medical Retrieval Task using the Casimage database of medical images, and 3. Interactive Retrieval task using the St. Andrews database. We participated in the bilingual ad-hoc task and the medical retrieval task. First a set of features was extracted from each of the images from both databases and the given query images. Table <ref type="table" coords="5,117.21,294.60,4.98,8.74" target="#tab_0">1</ref> gives an overview of the features extracted from the databases and the distance measures used to compare these features. The features extracted were chosen based on previous experiments with other databases <ref type="bibr" coords="5,184.23,318.03,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="5,198.07,318.03,7.01,8.74" target="#b3">4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Medical Retrieval Task</head><p>The Medical Retrieval Task consisted of 26 query images for which similar images had to be retrieved from the Casimage database, a database of 8725 medical images from various medical domains. Along with the images a set of 2078 text documents describing the medical cases is available, which were not used in the system, however. Each of the images belongs to one of the cases, thus several images may belong to one case.</p><p>In ImageCLEF 2004 it was possible to submit results to the medical retrieval task under different conditions:</p><p>• only visual retrieval • query expansion textual/visual • manual feedback from the first 20 results images visual • manual feedback from the first 20 results images visual/textual We submitted results to the first three categories using visual information only. We did not make use of the textual data at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Fully Automatic Queries / Only visual retrieval</head><p>Fully Automatic Query means that the system is given the query image and has to return a list of the most similar images without any further user interaction.</p><p>To this task we submitted 3 runs differing in the feature weightings used. The precise feature weightings are given in Table <ref type="table" coords="5,222.47,598.36,3.88,8.74">2</ref>. The table clearly shows that the parameters optimized for this task outperformed the other parameters and thus that optimizing the feature weightings in image retrieval for a given task improves the results. The feature weightings were chosen on the following basis:</p><p>• Use all available features equally weighted. This run can be seen as a baseline and is labelled with the run-tag i6-111111. • Use the features in the combination that produces the best results on the IRMA database <ref type="bibr" coords="5,114.91,688.04,14.61,8.74" target="#b11">[12]</ref>, labelled i6-020500. • Use the features in a combination which was optimized towards the given task. See Section 4.1.4 on how we optimized the parameters towards this task. This run is labelled with the run-tag i6-025501.</p><p>Three example queries are given in Figure <ref type="figure" coords="5,277.11,742.57,3.88,8.74" target="#fig_0">2</ref>. Table <ref type="table" coords="6,116.69,369.69,3.88,8.74">2</ref>: Different feature weightings and the mean average precision (MAP) from the ImageCLEF 2004 evaluation used for the medical retrieval task for the fully automatic runs. feature number run-tag 0 1 2 3 4 5 6 MAP i6-111111 1 1 1 1 1 1 1 0.2857 i6-020500 0 5 0 2 0 0 0 0.2665 i6-025501 5 5 0 2 1 0 0 0.3407</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Fully Automatic Queries with Query Expansion</head><p>This task was similar to the fully automatic task. The system was given the query image only and could perform the query in two steps, but without any user interaction. This method is described in Section 2.3:</p><p>1. normal query 2. query expansion, i.e. use the query image and its first nearest neighbor to requery the database.</p><p>We decided to use this method after we observed that for most query images the best match is a relevant one. In our oppinion, this method slightly enhanced the retrieval result, but the results are worse than the single-pass runs in two of three cases in the ImageCLEF 2004 evaluation. In Table <ref type="table" coords="6,116.56,615.23,4.98,8.74" target="#tab_1">3</ref> the results for these runs are given in comparison to the fully automatic runs without query expansion described in Section 4.1.1. For these experiments we used the same three settings for the fully automatic runs with and without query expansion. The fact that the results deteriorate (against our expectation) might be explained by missing medical relevance of the first query result. Another reason might be that we only looked into the first 20 to 30 results, but for the evaluation the first 1000 results were assessed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Queries with Relevance Feedback</head><p>In the runs described in the following, relevance feedback was used. The system was queried with the given query image and a user was presented the 20 most similar images from the database. Then the user marked one or more of the images presented (including the query image) as relevant, feature number run-tag 0 1 2 3 4 5 6 MAP i6-rfb1 10 0 0 2 1 0 0 0.3437 irrelevant or neutral. The sets of relevant and irrelevant images were then used to requery the system as described in Section 2.2. Although in some scenarios several steps of relevance feedback might be useful, here only one step of query refinement was used.</p><p>As user interaction was involved here, a fast system was desirable. To allow for faster retrieval, the image distortion model was not used for the comparison of images. The feature weighting used is given in Table <ref type="table" coords="7,187.80,351.99,3.88,8.74" target="#tab_2">4</ref>.</p><p>The mean average precision of 0.3437 reached here is slightly better than in the best of the fully automatic runs (0.3407).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Manual selection</head><p>To find a good set of parameters for this task, we performed some manual experiments. To be able to compare different parameter sets, we manually created relevance estimates for some of the images. These relevance estimates were submitted as "human visual system (of a computer scientist)". These experiments were carried out as follows:</p><p>1. Start with an initial feature weighting. 2. Query the database with all query images using this weighting. 3. Present the first 30 results for each query image to the user. 4. The user marks all images as either relevant or irrelevant. The system calculates the number of relevant results in total. 5. Slightly change the weighting and go back to 2.</p><p>We performed experiments to assess the quality of particular features, i.e. we used only one feature at a time (cf. Table <ref type="table" coords="7,181.10,562.83,3.87,8.74" target="#tab_3">5</ref>). With this information in mind we started to combine different features. First we tried to use all features with identical weight at the same time and the setting which proved best on the IRMA task. Then we modified these settings to improve the results. In this way we could approximately assess the quality of the results for different settings. We tried 11 different settings in total. The complete results from these experiments are given in Table <ref type="table" coords="7,485.93,609.69,3.88,8.74" target="#tab_4">6</ref>.</p><p>The mean average precision for this run is very low (0.279) because not enough images were viewed and assessed, and thus the number of returned images was far too small. In average only 53 results were returned with a minimum number of 6 images and a maximum of 142 images for the 26 queries. feature number precision of the 0 1 2 3 4 5 6 first 30 results 1 1 1 1 1 1 1 0.60 0 5 0 2 0 0 0 0.65 0 5 0 2 2 0 0 0.61 0 10 0 2 2 0 0 0.63 0 5 0 2 0 2 0 0.59 10 0 0 2 2 0 0 0.65 0 10 0 2 0.5 0 0 0.63 5 0 0 2 0 0 0 0.65 0 10 0 2 1 0 0 0.65 5 5 0 2 1 0 0 0.67 10 0 0 2 0.5 0 0 0.65 Table <ref type="table" coords="8,117.69,308.35,3.88,8.74">7</ref>: Different feature weightings used for the bilingual retrieval task for the fully automatic runs and the run with relevance feedback. feature number run-tag 0 1 2 3 4 5 6 MAP i6-111111 1 1 1 1 1 1 0 0.0859 i6-010012 0 0 0 1 2 1 0 0.0773 i6-010101 0 1 0 1 1 0 0 0.0859 i6-rfb1 0 0 0 1 1 0 0 0.0839</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Bilingual Retrieval Task</head><p>The Bilingual Retrieval Task consisted of 25 queries given as a short textual description in several languages, a slightly longer textual description in English, and an example image fitting the query.</p><p>In our system we only used the 25 example images to query the database. The database is the St. Andrews Image Collection consisting of approximately 30 000 images.</p><p>In the experiments described in the following, the provided example images were used to query the database. Unfortunately, no other group participated in this track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Fully Automatic Queries</head><p>Here, the example images given were used to query the database. Different feature weightings were used:</p><p>1. equal weight for each feature (run-tag i6-111111) 2. two weightings which have proven to work well for general purpose photographs <ref type="bibr" coords="8,459.85,589.93,10.52,8.74" target="#b1">[2]</ref> (run-tags i6-010012 and i6-010101).</p><p>The exact weightings are given in Table <ref type="table" coords="8,271.72,621.33,4.98,8.74">7</ref> together with the results from the ImageCLEF 2004 evaluation.</p><p>A look at the query topics clearly showed that pure content-based image retrieval would not be able to deliver satisfactory results as queries like "Portrait pictures of church ministers by Thomas Rodger" are not processible by image content only (church ministers do not differ in their appearance from any other person, and it is usually not possible to see from an image who made it). The mean average precision values clearly show that visual information alone is not sufficient to obtain good results, although the results from queries are visually quite promising as shown in Figure <ref type="figure" coords="8,121.43,715.06,3.88,8.74" target="#fig_1">3</ref>. Due to the fact that this task was quite futile we did not focus on this task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Queries with Relevance Feedback</head><p>Using the feature weighting given in Table <ref type="table" coords="9,284.83,385.18,3.88,8.74">7</ref>, i.e. column i6-rfb, we submitted one run using relevance feedback for this task. No improvement can be seen: A mean average precision of 0.0839 was measured. This is even worse than the best of the fully automatic runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Summary of the Evaluation</head><p>In this section, our results are compared to the results of other groups in the ImageCLEF 2004 evaluation. For the medical retrieval task, the results of the evaluation (cf. <ref type="bibr" coords="9,428.51,474.50,36.91,8.74">Table 8)</ref> show that the methods presented here compare favorably well with the other systems. There are three better systems, however the differences are very small and it is not yet clear to which extend the other systems used the textual information in addition to the images. For the bilingual retrieval task, the comparison with the other systems seems to show that the textual information is very important. Note that all results presented in this paper were obtained using visual information only. Furthermore, the results in the medical retrieval task show that suitable selection and weighting of the features used improves the results strongly. The optimization here is not to be seen as "training on the testing data" as only a few different settings were compared.</p><p>For the future it is planned to extend the FIRE system to be able to use textual features in the retrieval process. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,98.37,338.36,406.26,8.74"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Three example queries with results from the fully automatic medical retrieval task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,90.00,338.30,423.00,8.74;9,90.00,350.01,53.44,8.74"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Query results for the bilingual retrieval task for three different queries using only visual information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="9,90.00,618.09,423.01,8.74;9,90.00,629.81,249.56,8.74;9,122.10,668.14,32.13,8.74;9,177.81,652.01,48.98,44.38;9,207.48,663.10,37.89,33.29;9,237.14,652.01,48.98,44.38;9,266.81,663.10,37.89,33.29;9,296.48,652.01,48.98,44.38;9,326.14,652.01,48.98,44.38;9,344.19,689.59,11.63,8.74;9,379.39,655.71,45.28,40.68;9,397.43,689.59,11.63,8.74;9,432.63,666.80,34.19,29.59;9,122.10,701.70,23.39,8.74;9,166.19,701.70,272.54,8.74"><head>Table 8 :</head><label>8</label><figDesc>Exemplary results (mean average precision, MAP) from the ImageCLEF 2004 evaluation for the fully automatic runs in the medical retrieval task. run-tag U B M e d I m T x t 0 1 k i d s _ r u n 2 i c _ c l 0 4 _ b a s e i 6 -0 2 5 5 0 1 i 6 -q e 0 2 5 5 0 1 0 G E _ 4 g _ 4 d _ v i s . . . m i _ c o m b i n e 1 . . . e n i d 1 r u n MAP 0.35 0.35 0.35 0.34 0.33 0.32 . . . 0.27 . . . 0.18</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="3,136.53,108.86,329.94,344.57"><head></head><label></label><figDesc></figDesc><graphic coords="3,136.53,108.86,329.94,344.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,90.00,118.94,423.00,126.17"><head>Table 1 :</head><label>1</label><figDesc>Features extracted for the ImageCLEF 2004 evaluation and their associated distance measures.</figDesc><table coords="5,446.04,140.25,44.12,8.74"><row><cell>associated</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,90.00,118.94,423.01,69.53"><head>Table 3 :</head><label>3</label><figDesc>Results from the ImageCLEF evaluation for the experiments with query expansion in comparison to the fully automatic runs.</figDesc><table coords="7,178.81,142.19,242.07,46.28"><row><cell>run-tag</cell><cell cols="2">fully automatic with query expansion</cell></row><row><cell>i6(qe)-020500</cell><cell>0.2665</cell><cell>0.3115</cell></row><row><cell>i6(qe)-025501</cell><cell>0.3407</cell><cell>0.3323</cell></row><row><cell>i6(qe)-111111</cell><cell>0.2857</cell><cell>0.2495</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,90.00,212.48,423.00,20.45"><head>Table 4 :</head><label>4</label><figDesc>Feature weighting used for the experiments with relevance feedback in the medical retrieval task.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,108.43,695.30,386.14,32.39"><head>Table 5 :</head><label>5</label><figDesc>The subjective performance of particular features on the medical retrieval task.</figDesc><table coords="7,129.34,706.84,341.00,20.85"><row><cell>feature number</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell></row><row><cell cols="8">precision of the first 30 images 0.55 0.44 0.31 0.54 0.40 0.36 0.03</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,172.10,118.94,258.81,8.74"><head>Table 6 :</head><label>6</label><figDesc>Effect of various feature combination on precision.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,105.24,721.20,230.41,6.99"><p>http://www-i6.informatik.rwth-aachen.de/˜deselaers/fire.html</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,110.48,133.31,402.52,7.86;10,110.48,144.05,402.52,7.86;10,110.48,154.79,299.91,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,381.15,133.31,131.85,7.86;10,110.48,144.05,147.25,7.86">Blobworld: A System for Region-Based Image Indexing and Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Carson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,279.26,144.05,229.43,7.86">International Conference on Visual Information Systems</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1999-06">June 1999</date>
			<biblScope unit="page" from="509" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,167.29,402.52,7.86;10,110.48,178.03,219.96,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="10,169.85,167.29,115.80,7.86">Features for Image Retrieval</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003-12">December 2003</date>
			<pubPlace>Aachen, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Lehrstuhl für Informatik VI, RWTH Aachen University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Diploma thesis</note>
</biblStruct>

<biblStruct coords="10,110.48,190.54,402.52,7.86;10,110.48,201.28,402.53,7.86;10,110.48,212.02,140.74,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,279.82,190.54,233.19,7.86;10,110.48,201.28,158.49,7.86">Classification Error Rate for Quantitative Evaluation of Content-based Image Retrieval Systems</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,288.99,201.28,194.88,7.86">International Conference on Pattern Recognition</title>
		<meeting><address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-08">August 2004</date>
		</imprint>
	</monogr>
	<note>In press</note>
</biblStruct>

<biblStruct coords="10,110.48,224.52,402.52,7.86;10,110.48,235.26,402.52,7.86;10,110.48,246.00,58.23,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,264.09,224.52,232.51,7.86">Features for Image Retrieval -A Quantitative Comparison</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,110.48,235.26,236.97,7.86">DAGM 2004, Pattern Recognition, 26th DAGM Symposium</title>
		<meeting><address><addrLine>Tübingen, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>LNCS</publisher>
			<date type="published" when="2004-09">September 2004</date>
		</imprint>
	</monogr>
	<note>In press</note>
</biblStruct>

<biblStruct coords="10,110.48,258.51,402.52,7.86;10,110.48,269.25,402.52,7.86;10,110.48,279.99,60.80,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,479.85,258.51,33.16,7.86;10,110.48,269.25,167.79,7.86">Efficient and Effective Querying by Image Content</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Barber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Flickner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Niblack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Petkovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Equitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,287.44,269.25,171.27,7.86">Journal of Intelligent Information Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="231" to="262" />
			<date type="published" when="1994-07">July 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,292.49,402.52,7.86;10,110.48,303.23,402.53,7.86;10,110.48,313.97,296.96,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,110.48,303.23,402.53,7.86;10,110.48,313.97,45.32,7.86">Comparison of Techniques for Measuring Cloud Texture in Remotely Sensed Satellite Meteorological Image Data</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">N</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Renshaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Mugglestone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">F N</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">M</forename><surname>Grant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,164.35,313.97,113.36,7.86">Radar and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="236" to="248" />
			<date type="published" when="1989-10">October 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,326.48,402.52,7.86;10,110.48,337.22,90.37,7.86" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Haberäcker</surname></persName>
		</author>
		<title level="m" coord="10,177.54,326.48,242.27,7.86">Praxis der Digitalen Bildverarbeitung und Mustererkennung</title>
		<meeting><address><addrLine>München, Wien</addrLine></address></meeting>
		<imprint>
			<publisher>Carl Hanser Verlag</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,349.72,402.51,7.86;10,110.48,360.46,321.32,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,314.94,349.72,166.73,7.86">Texture Features for Image Classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Dinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,490.72,349.72,22.27,7.86;10,110.48,360.46,192.82,7.86">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="610" to="621" />
			<date type="published" when="1973-11">November 1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,372.97,402.52,7.86;10,110.48,383.71,366.79,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,264.94,372.97,248.06,7.86;10,110.48,383.71,26.82,7.86">Classification of Medical Images using Non-linear Distortion Models</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gollan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,157.37,383.71,127.97,7.86">Bildverarbeitung für die Medizin</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-03">March 2004</date>
			<biblScope unit="page" from="366" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.47,396.21,402.53,7.86;10,110.48,406.95,402.52,7.86;10,110.48,417.69,58.23,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,251.46,396.21,261.55,7.86;10,110.48,406.95,88.51,7.86">Local Context in Non-linear Deformation Models for Handwritten Character Recognition</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gollan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,217.05,406.95,192.44,7.86">International Conference on Pattern Recognition</title>
		<meeting><address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-08">August 2004</date>
		</imprint>
	</monogr>
	<note>In press</note>
</biblStruct>

<biblStruct coords="10,110.47,430.20,402.53,7.86;10,110.48,440.94,402.53,7.86;10,110.48,451.68,79.79,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,326.34,430.20,186.66,7.86;10,110.48,440.94,87.06,7.86">Adaptation in Statistical Pattern Recognition using Tangent Vectors</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dahmen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,204.69,440.94,260.02,7.86">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="269" to="274" />
			<date type="published" when="2004-02">February 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.47,464.18,402.53,7.86;10,110.48,474.92,402.52,7.86;10,110.48,485.66,402.52,7.86;10,110.48,496.40,176.48,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,167.52,474.92,345.48,7.86;10,110.48,485.66,84.01,7.86">The IRMA Project -A State of the Art Report on Content-Based Image Retrieval in Medical Applications</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Güld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Thies</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Spitzer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kohnen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Wein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,216.12,485.66,292.86,7.86">Korea-Germany Joint Workshop on Advanced Medical Image Processing</title>
		<meeting><address><addrLine>Seoul, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-10">October 2003</date>
			<biblScope unit="page" from="161" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.47,508.91,402.53,7.86;10,110.48,519.65,402.52,7.86;10,110.48,530.39,194.48,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,352.11,508.91,160.89,7.86;10,110.48,519.65,183.09,7.86">Squire Strategies for positive and negative Relevance Feedback in Image Retrieval</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Marchand-Maillet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mcg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,311.74,519.65,197.22,7.86">International Conference on Pattern Recognition</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-09">September 2000</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1043" to="1046" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.47,542.89,402.53,7.86;10,110.48,553.63,135.19,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,226.50,542.89,190.07,7.86">A Review on Image Segmentation Techniques</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">R</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,429.41,542.89,79.55,7.86">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1277" to="1294" />
			<date type="published" when="1993-11">November 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.47,566.14,402.52,7.86;10,110.48,576.88,402.53,7.86;10,110.48,587.62,138.83,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,323.88,566.14,189.11,7.86;10,110.48,576.88,87.57,7.86">Empirical Evaluation of Dissimilarity Measures for Color and Texture</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Rubner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,219.01,576.88,185.26,7.86">International Conference on Computer Vision</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-09">September 1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1165" to="1173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.47,600.12,402.53,7.86;10,110.48,610.86,272.14,7.86" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="10,171.72,600.12,224.49,7.86">Feature Histograms for Content-Based Image Retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Siggelkow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<pubPlace>Freiburg, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Freiburg, Institute for Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="10,110.47,623.37,402.53,7.86;10,110.48,634.11,402.52,7.86;10,110.48,644.85,139.16,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,385.70,623.37,127.30,7.86;10,110.48,634.11,116.10,7.86">Content-Based Image Retrieval: The End of the Early Years</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">W M</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Santini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,238.15,634.11,271.14,7.86">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1349" to="1380" />
			<date type="published" when="2000-12">December 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.47,657.35,402.53,7.86;10,110.48,668.09,402.52,7.86;10,110.48,678.83,401.83,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,314.89,657.35,198.11,7.86;10,110.48,668.09,384.47,7.86">Content-Based Query of Image Databases, Inspirations from Text Retrieval: Inverted Files, Frequency-Based Weights and Relevance Feedback</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Raki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,110.48,678.83,177.00,7.86">Scandinavian Conference on Image Analysis</title>
		<meeting><address><addrLine>Kangerlussuaq, Greenland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-06">June 1999</date>
			<biblScope unit="page" from="143" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.47,691.34,402.52,7.86;10,110.48,702.08,293.34,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,269.20,691.34,214.30,7.86">Textural Features Corresponding to Visual Perception</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Yamawaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,490.72,691.34,22.27,7.86;10,110.48,702.08,186.12,7.86">IEEE Transaction on Systems, Man, and Cybernetcs</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="460" to="472" />
			<date type="published" when="1978-06">June 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.47,714.58,402.53,7.86;10,110.48,725.32,402.53,7.86;10,110.48,736.06,66.59,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="10,277.04,714.58,235.97,7.86;10,110.48,725.32,67.21,7.86">SIMPLIcity: Semantics-Sensitive Integrated Matching for Picture LIbraries</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wiederhold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,185.36,725.32,262.65,7.86">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="947" to="963" />
			<date type="published" when="2001-09">September 2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
