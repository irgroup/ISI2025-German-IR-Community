<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,207.06,75.29,192.40,12.58">MIRACLE at ImageCLEF 2004</title>
				<funder ref="#_McWGSaE">
					<orgName type="full">MIRACLE (Regional Government of Madrid, Regional Plan for Research</orgName>
				</funder>
				<funder ref="#_wu5Rzd4">
					<orgName type="full">OmniPaper (European Union</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,93.84,113.76,98.64,9.02"><forename type="first">J</forename><forename type="middle">L</forename><surname>Martínez-Fernández</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="laboratory">Advaced Databases Group</orgName>
								<orgName type="institution">Universidad Carlos III de Madrid</orgName>
								<address>
									<addrLine>Avda. Universidad 30</addrLine>
									<postCode>28911</postCode>
									<settlement>Leganés, Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Decisiond and Language</orgName>
								<orgName type="laboratory">DAEDALUS -Data</orgName>
								<orgName type="institution">S.A. Centro de Empresas &quot;La Arboleda&quot;</orgName>
								<address>
									<addrLine>Ctra. N-III km. 7</addrLine>
									<postCode>300, 28031</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,204.98,113.76,79.38,9.02"><forename type="first">Ana</forename><surname>García Serrano</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Artificial Intelligence Department</orgName>
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
								<address>
									<addrLine>Campus de Montegancedo s/n, Boadilla del Monte</addrLine>
									<postCode>28660</postCode>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,292.35,113.76,51.38,9.02"><forename type="first">Julio</forename><surname>Villena</surname></persName>
							<email>jvillena@it.uc3m.es</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Telematic Engineering</orgName>
								<orgName type="institution">Universidad Carlos III de Madrid</orgName>
								<address>
									<addrLine>Avda. Universidad 30</addrLine>
									<postCode>28911</postCode>
									<settlement>Leganés, Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Decisiond and Language</orgName>
								<orgName type="laboratory">DAEDALUS -Data</orgName>
								<orgName type="institution">S.A. Centro de Empresas &quot;La Arboleda&quot;</orgName>
								<address>
									<addrLine>Ctra. N-III km. 7</addrLine>
									<postCode>300, 28031</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,356.22,113.76,113.69,9.02"><forename type="first">Víctor</forename><surname>David Méndez Sáenz</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Artificial Intelligence Department</orgName>
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
								<address>
									<addrLine>Campus de Montegancedo s/n, Boadilla del Monte</addrLine>
									<postCode>28660</postCode>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,477.80,113.76,35.02,9.02;1,169.14,125.52,70.88,9.02"><forename type="first">Santiago</forename><surname>González Tortosa</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Artificial Intelligence Department</orgName>
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
								<address>
									<addrLine>Campus de Montegancedo s/n, Boadilla del Monte</addrLine>
									<postCode>28660</postCode>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,248.02,125.52,104.15,9.02"><forename type="first">Michelangelo</forename><surname>Castagnone</surname></persName>
							<email>mcastagnone@isys.dia.fi.upm.es</email>
							<affiliation key="aff1">
								<orgName type="department">Artificial Intelligence Department</orgName>
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
								<address>
									<addrLine>Campus de Montegancedo s/n, Boadilla del Monte</addrLine>
									<postCode>28660</postCode>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,367.92,125.52,55.23,9.02"><forename type="first">Javier</forename><surname>Alonso</surname></persName>
							<email>jalonso@daedalus.es</email>
							<affiliation key="aff3">
								<orgName type="department">Decisiond and Language</orgName>
								<orgName type="laboratory">DAEDALUS -Data</orgName>
								<orgName type="institution">S.A. Centro de Empresas &quot;La Arboleda&quot;</orgName>
								<address>
									<addrLine>Ctra. N-III km. 7</addrLine>
									<postCode>300, 28031</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,207.06,75.29,192.40,12.58">MIRACLE at ImageCLEF 2004</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7FEFE3FEB76800C02CC7E9244E82A1EA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The second participation of the MIRACLE (Multilingual Information RetrievAl for the CLEf campaign) research group in the ImageCLEF task is described in this paper. New techniques, devoted to the combination of linguistic and statistical language processing methods, have been tested, continuing with the experiments carried out in last year</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This is the second time for the MIRACLE (Multilingual Information RetrievAl for the CLEf campaign) research group as a participant in the Image CLEF task. The work presented in this paper is the continuation of the experiments carried out in CLEF 2003. Some new techniques, like the inclusion of linguistic information for monolingual English tasks or the application of EuroWordnet as a translation and query expansion tool, have been developed and tested.</p><p>In Image CLEF task, the objective is to deal with textual descriptions of pictures and the corresponding image files. This kind of texts has some specific characteristics, like size and structure of descriptions, making them different from texts used in cross-language tracks. As stated in last year <ref type="bibr" coords="1,370.38,510.15,10.63,8.74" target="#b7">[8]</ref>, the main focus of the MIRACLE team is to find the way to apply linguistic knowledge to improve the Information Retrieval task. Therefore, for this CLEF call English texts have been treated using tools like the Brill tagger <ref type="bibr" coords="1,395.30,533.13,10.61,8.74" target="#b1">[2]</ref>, a linguistic parser, a proper noun extraction module and WordNet <ref type="bibr" coords="1,225.08,544.65,11.72,8.74" target="#b3">[4]</ref> to include semantic information.</p><p>On the other side, this year the MIRACLE team has made a first attempt in analyzing the content of supplied images. For this purpose, GIFT 0.1.9 <ref type="bibr" coords="1,229.14,579.15,10.61,8.74" target="#b5">[6]</ref>, a public package devoted to image processing has been used. This software can be installed as a server, and some adapted clients based on Viper <ref type="bibr" coords="1,401.76,590.61,11.72,8.74" target="#b5">[6]</ref> have been used. Although different search algorithms can be adapted to this tool as plugins, in these experiments the provided separate normalisation algorithm has been used.</p><p>Image CLEF 2004 offered three different tasks: an adhoc bilingual retrieval task, where images are accompanied by english captions, a medical retrieval task, where a set of scan, x-ray, pictures and short textual descriptions about medical diagnosis are provided, and a user centered search task, where the main goal is to take into account user interaction in the retrieval process. MIRACLE team has taken part in the first two tasks, the first one paying more attention to textual descriptions and the second one to test the content based image indexing and searching tool previously mentioned. As a result, 45 runs have been submitted for both tasks, and a great human effort has been set for this CLEF track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Adhoc Retrieval Task</head><p>Figure <ref type="figure" coords="2,99.54,101.82,5.01,9.02">1</ref> shows a graphic representation of the different processes followed in the retrieval process according to considered languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Query processing applied for the Adhoc Retrieval task</head><p>As can be seen in the figure, different tools have been used to process english queries: BRILL: A tagger, based on Brill's work <ref type="bibr" coords="2,270.45,534.33,10.63,8.74" target="#b1">[2]</ref>, can be used to attach a morphosyntactic tag to each word. Proper Names: A Proper Name detection module can be applied at the output of the Brill tagger, although plain text can also be used as input to this module. SETA Module: In a final step, the text can be divided in sentences and their constituent phrases can be extracted using this module. Thus, this module is a linguistic parser for english, implemented using prolog. EWN synonym: This box represents a subsystem used to extract the corresponding WordNet synonyms for a given word. So, a query expansion is implemented based on semantic information contained in WordNet database. Optionally, the linguistic category of a given word is used when the semantic expansion is performed. For example, if a word acting as a name is going to be expanded, only synonyms of the given word that can act as a name are considered.</p><p>The rest of languages have been treated using EuroWordNet, where available, or translation tools, like Systran <ref type="bibr" coords="2,70.92,683.79,11.70,8.74" target="#b0">[1]</ref> or Translation Experts <ref type="bibr" coords="2,179.04,683.79,10.64,8.74" target="#b6">[7]</ref>. These experiments where devoted to test the quality of EuroWordNet when used in translation tasks and as a synonym expansion tool. For translation purposes, the inter-lingual index (ILI) supplied with EuroWordNet has been applied. Again, it is possible to consider the linguistic category of the word when asking for its translations. So, if a name is going to be translated, only words that can act as a name in the target language are taken into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Monolingual English experiments</head><p>Figure <ref type="figure" coords="3,100.62,96.42,5.01,9.02">1</ref> shows how given queries are processed prior to the search process. Of course, equivalent treatments must be applied in the indexing process. For the English language, Table <ref type="table" coords="3,387.13,108.18,5.01,9.02">1</ref> shows the four different index databases considered and the treatments executed to get each one. In all of them, some common tasks have been applied, like obtaining the stem of the word.</p><p>For the rest of languages, only the baseline index database has been used to search translated queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Index/Tasks</head><p>Tokenize Filter Stopwords</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Brill Tagger</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Filter Nouns</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stem ming</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Filter Proper</head><p>Nouns</p><formula xml:id="formula_0" coords="3,84.00,220.02,398.17,64.88">DB1 -Baseline √ √ × × × × DB2 -Only Nouns × × √ √ × × DB3 -Proper Names + Baseline √ √ × × √ √ DB4 -Proper Names + Nouns × × √ √ √ √</formula><p>Table <ref type="table" coords="3,207.11,300.18,3.76,9.02">1</ref>. Index databases used in the Adhoc Retrieval task Table <ref type="table" coords="3,96.18,317.94,5.01,9.02" target="#tab_0">2</ref> summarizes the different ways applied for query processing, the name given to each experiment and the index database used to perform the search process. expand the query, without any refinement. 'Nouns' stands for the situation where the query text is tagged and only words acting as nouns are selected as part of the final query. 'Proper Names' is used to mark that only recognized proper names in the text are used as part of the query. 'Synonyms with category' is used to distinguish the process in which not all the synonyms of a words are taken into account, but only those synonyms that can act with the same category than the initial word are included in the query. Finally, in the last two experiments included in the table, the narrative of the query (only available for the english queries) is used as the input to the SETA module, in charge of parsing the text and getting a more precise category for the word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Monolingual English Results</head><p>Table <ref type="table" coords="4,96.18,198.89,5.01,9.02" target="#tab_1">3</ref> shows average precision figures (MAP column) and the position obtained for each defined run (described in the previous section). Regarding these results, it is important to highlight some points: first of all, the basic experiment (taken as the baseline) produces the best results. Very different results are obtained from the fourth result in advance and again a gap in the average precision can be seen from the eighth result in advance. These differences in precision show that, when all words are used in the characterization of the textual captions results are better and the inclusion of more linguistic information (like proper nouns or synonyms) does not lead to an improvement. On the other side, if only common or proper nouns are used to represent the documents there is a loss in precision, perhaps due to the fewer number of words used for document characterization. Also, its worth mentioning that the experiment using all linguistic information that available tools can extract is among the worse ones</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bilingual Experiments</head><p>For the bilingual experiments two different approaches, depending on available information, have been applied. These two approaches are:</p><p>A EuroWordNet based approach, where information contained in the ILI index provided by EuroWordNet is used to translate the original query. This approach has been applied for the following languages: Spanish, German, French and Italian.</p><p>A translator based approach, where online translation tools, in particular Systran and Translation Experts tools, have been applied to translate the queries from the initial language to the target language (English in Image CLEF tasks).</p><p>In both approaches, the index database used corresponds to the baseline, i.e., the one where all words (excluding stopwords) are considered as indexes. Table <ref type="table" coords="4,261.96,716.22,5.01,9.02" target="#tab_2">4</ref> summarizes the features of the experiments defined for this multilingual task. According to these results, one important fact to mention is the loss of precision, taking into account the best monolingual experiment. As can be seen, a decrease of 34,07% in precision, marking again the importance of the quality of the translators used in multilingual environments. Cases where EuroWordNet has been used as a translation tool can be compared with CLEF 2003 obtained results <ref type="bibr" coords="5,339.63,647.13,11.70,8.74" target="#b7">[8]</ref> and an important decrease in precision can be noticed. Last year bilingual experiments with French, German, Italian and Spanish where around 40% average precision, while this year average precision for these languages is around 30%. It is also worth mentioning that other participants, according to official results, have obtained only a decrease of 10% in precision for some bilingual tasks, so, in our situation, there is room for improvement. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multilingual Experiments</head><note type="other">Tokenize</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mixing text based retrieval with content based image retrieval (CBIR) for the Adhoc task</head><p>This year, the MIRACLE team has made a first step in image content retrieval. This first step has led to the definition of experiments where content based image retrieval (CBIR) is applied. This is the case of the adhoc retrieval task, where some runs mixing results obtained using textual search and CBIR search have been submitted. The CBIR subsystem used for this experiment is based on GIFT 0.1.9 and will be described in the next section. The text retrieval subsystem is the one used in text based experiments, although for initial test and tuning of the overall system, last year data and text search systems have been used.</p><p>The process of mixing textual and image results begins taking the list with the images returned by the text search subsystem and their relevance figures and building a query for the CBIR subsystem. The content search is performed and a new search is performed considering the 5 first elements returned. Finally, results obtained with this last relevance feedback approach are combined with the original results list returned by the textual search subsystem. The expression used to combine these partial lists is: In this expression, REL_VIS and REL_TXT are the relevance value returned by the CBIR subsystem and the text search subsystem respectively. factor_vis, factor_txt, weight_vis and weight_txt are parameters to be defined and can be used to adjust the overall system according to obtained results, for example, giving more importance to textual results or CBIR results.</p><formula xml:id="formula_1" coords="6,108.84,264.73,190.09,7.63">k txt weight</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results of the text and CBIR mixing experiments</head><p>Two sets of experiments have been done. Results for the first set are included in Table <ref type="table" coords="6,418.83,493.07,3.77,9.02" target="#tab_7">6</ref>, where the initial set of text search results have been some of the experiments defined in Table <ref type="table" coords="6,356.52,504.83,3.76,9.02" target="#tab_0">2</ref>.  <ref type="table" coords="6,155.88,641.76,3.77,9.02" target="#tab_1">3</ref>, these results are very close (and always below) of the ones where only textual search is applied. This can be due to the chosen configuration of the combination algorithm. More tests should be made to extract a valid conclusion. Some other experiments where executed using a different textual search subsystem. Obtained results for these experiments (Table <ref type="table" coords="6,152.76,699.54,5.01,9.02" target="#tab_8">7</ref> and Table <ref type="table" coords="6,205.27,699.54,4.19,9.02">8</ref>) have been always worse than the previously mentioned ones. One of these sets of experiments, Table <ref type="table" coords="6,184.68,711.36,3.77,9.02">8</ref>, is a bilingual one with English as a target language and Spanish as the initial language.  <ref type="table" coords="7,139.24,241.62,3.76,9.02">8</ref>. Average Precision values using a different text retrieval system (bilingual Spanish)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run Name</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MAP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Medical Retrieval Task</head><p>This year ImageCLEF organizers have defined a new task where the main focus is image content based retrieval. For this purpose a set of medical images, including scans, x-ray images and photographs of different illness has been made available to ImageCLEF participants. The CBIR system used has been GIFT 0.1.9 <ref type="bibr" coords="7,253.41,343.14,11.68,9.02" target="#b5">[6]</ref> developed under GNU licence which allows query by example, using an image as a starting point for the search process, and implements relevance feedback methods. This software has been developed by the Vision Group at the CUI of the University of Geneva. Although the first step in the search process for this task must involve an image, textual descriptions of the medical cases have been used to try to improve retrieval results. The search process can be divided in the following steps:</p><p>1. The initial query, formed by one image, is introduced in the CBIR system to obtain a set of images to define the query. 2. The CBIR system returns a list of images along with the corresponding relevance values. The number of images used in the search process is called relevance threshold and constitutes a system configuration parameter. 3. Previous steps have produced a valid query which is introduced in the overall system. The complete system is formed by a textual subsystem and a CBIR subsystem. In a first step both subsystemas are used to perform the search process. 4. Partial results lists are combined using an intersection operator: images not appearing in both partial lists are dropped. Two special parameters make it possible to consider textual results more important than CBIR ones or vice versa. 5. The previous step produces a unique results list that is again introduced in the CBIR subsystem. The new results list obtained is again combined, applying the intersection operator, with the output of the textual subsystem.</p><p>The overall process is depicted in Figure <ref type="figure" coords="7,236.20,602.16,3.76,9.02" target="#fig_1">2</ref>. The expression used to obtain a unique relevance value according to the partial results lists produced by textual and CBIR subsystems is:  Some other models, based on different ways to combine the output of the textual and CBIR subsystems, have been tested but the one described here has produced the best results. Four different runs have been defined according to different values for the configuration parameters defined for the overall system. These parameters include: the minimum threshold to build the initial query, the number of results used for relevance feedback and the weights given to textual and image results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Medical Retrieval Task Results</head><p>Average precision figures obtained for the submitted experiments are included in Table <ref type="table" coords="8,433.14,383.40,3.77,9.02" target="#tab_9">9</ref>. As can be seen, the difference in precision among the first and the last run is around 2%, not enough to extract some conclusions about which method (or configuration parameters set) is the best. On the other hand, according to the obtained rank for these runs, there is still room for improvement in this task, perhaps testing new configurations or new values for defined parameters or taking the most of textual descriptions related to each medical case. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>This is the second year for the MIRACLE team taking part in the CLEF campaign and in the ImageCLEF track in particular. The main goal pursued this year was to continue with the research in finding a right combination of linguistic and statistical methods to improve the Information Retrieval process. MIRACLE group is also very interested in the field of multimedia retrieval so, the content based image retrieval task defined this year as part of the ImageCLEF track was a great opportunity to take a first step in the field. From out point of view, obtained results for the adhoc retrieval task are very good. Average precision values for the monolingual english task are a little bit better than the ones obtained last year, pointing that is difficult to improve results for this task. Perhaps the best performance figures that can be obtained with actual technology have been reached. On the contrary, bilingual tasks, in the way we have developed them, can be improved. A mention apart must be made for the content based image retrieval task, where obtained results are not as good as for the textual task. This fact drives us to increase efforts devoted to this kind of retrieval for the following campaigns.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,126.84,654.32,3.11,6.11;7,309.90,652.76,7.01,6.11;7,284.76,652.76,18.69,6.11;7,210.36,652.76,7.78,6.11;7,185.10,652.76,18.69,6.11;7,261.48,654.88,20.69,10.47;7,230.58,654.88,21.36,10.47;7,165.78,654.88,17.34,10.47;7,135.24,654.88,21.36,10.47;7,305.10,652.76,3.50,6.11;7,205.50,652.76,3.50,6.11;7,253.98,654.88,6.01,10.47;7,158.64,654.88,6.01,10.47;7,221.58,650.69,6.58,14.70;7,321.90,655.92,2.51,9.02;7,376.89,655.92,99.04,9.02;7,376.92,671.22,129.95,9.02;7,70.92,683.04,22.04,9.02;7,124.92,706.56,7.55,9.02;7,376.92,706.56,147.52,9.02;7,376.92,718.32,40.27,9.02"><head></head><label></label><figDesc>elements appearing only in one partial list</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="8,183.72,257.64,227.91,9.02;8,115.26,70.86,364.80,181.32"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Text and CBIR subsystems combination model</figDesc><graphic coords="8,115.26,70.86,364.80,181.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="2,70.92,145.62,453.48,316.32"><head></head><label></label><figDesc></figDesc><graphic coords="2,70.92,145.62,453.48,316.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,70.92,357.54,453.54,390.67"><head>Table 2</head><label>2</label><figDesc></figDesc><table coords="3,92.82,357.54,400.70,343.22"><row><cell></cell><cell cols="2">Monolingual English Experiments</cell><cell></cell></row><row><cell></cell><cell>Query Process</cell><cell>Database</cell><cell>Run Name</cell></row><row><cell></cell><cell></cell><cell>Searched</cell><cell></cell></row><row><cell></cell><cell>Topic Words</cell><cell>DB 1</cell><cell>mirobaseen</cell></row><row><cell>Baseline</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Topic Words + Synonyms</cell><cell>DB 1</cell><cell>mirosbaseen</cell></row><row><cell></cell><cell>Nouns</cell><cell>DB 2</cell><cell>mironounen</cell></row><row><cell>Only Nouns</cell><cell>Nouns + Synonyms without category</cell><cell>DB 2</cell><cell>mirosnounen</cell></row><row><cell></cell><cell>Nouns + Synonyms with category</cell><cell>DB 2</cell><cell>miroscnounen</cell></row><row><cell>Baseline +</cell><cell>Topic Words + Proper Names</cell><cell>DB 3</cell><cell>miroppbaseen</cell></row><row><cell>Proper Names</cell><cell>Topic Words +Synonyms + Proper Names</cell><cell>DB 3</cell><cell>mirosppbaseen</cell></row><row><cell></cell><cell>Nouns + Proper Names</cell><cell>DB 4</cell><cell>miroppnounen</cell></row><row><cell>Nouns + Proper Names</cell><cell>Nouns + Synonyms without category + Proper Names</cell><cell>DB 4</cell><cell>mirosppnounen</cell></row><row><cell></cell><cell>Nouns + Synonyms with category + Proper Names</cell><cell>DB 4</cell><cell>miroscppnounen</cell></row><row><cell></cell><cell>Topic and Narration Words</cell><cell>DB 3</cell><cell>mirorppbaseen</cell></row><row><cell>SETA</cell><cell>Topic and Narration Words + Synonyms with category</cell><cell>DB 3</cell><cell>mirorscppbaseen</cell></row></table><note coords="3,220.17,710.04,183.99,9.02;3,70.92,727.95,453.47,8.74;3,70.92,739.47,453.54,8.74"><p><p>. Run definitions for the Adhoc Retrieval task</p>In this table, 'Topic Words' means that all simple words (excluding stopwords) are used to search the corresponding index database. 'Synonyms' means that all synonyms for a word found in WordNet are used to</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,154.20,246.60,286.88,191.84"><head>Table 3 .</head><label>3</label><figDesc>Average precision results for monolingual english experiments</figDesc><table coords="4,203.76,246.60,174.66,168.08"><row><cell>Name</cell><cell>MAP</cell><cell>Rank</cell></row><row><cell>mirobaseen</cell><cell>0,5865</cell><cell>1</cell></row><row><cell>mirosbaseen</cell><cell>0,5623</cell><cell>4</cell></row><row><cell>miroppbaseen</cell><cell>0,5609</cell><cell>6</cell></row><row><cell>mirosppbaseen</cell><cell>0,5388</cell><cell>8</cell></row><row><cell>miroppnounen</cell><cell>0,3384</cell><cell>87</cell></row><row><cell>mirosnounen</cell><cell>0,3383</cell><cell>88</cell></row><row><cell>mirorppbaseen</cell><cell>0,3366</cell><cell>90</cell></row><row><cell>mirosppnounen</cell><cell>0,3337</cell><cell>92</cell></row><row><cell>mirorscppbaseen</cell><cell>0,2703</cell><cell>112</cell></row><row><cell>miroscppnounen</cell><cell>0,2568</cell><cell>116</cell></row><row><cell>mironounen</cell><cell>0,2525</cell><cell>119</cell></row><row><cell>miroscnounen</cell><cell>0,2461</cell><cell>120</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,70.92,301.38,383.81,43.04"><head>Table 4 .</head><label>4</label><figDesc>Description of Multilingual Experiments for the Adhoc Retrieval task</figDesc><table coords="5,70.92,335.40,72.53,9.02"><row><cell>Bilingual Results</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,70.92,358.14,453.56,216.08"><head>Table 5</head><label>5</label><figDesc>shows average precision figures obtained for the multilingual experiments defined in the previous section.</figDesc><table coords="5,173.58,406.14,237.00,168.08"><row><cell>Run Name</cell><cell>MAP</cell><cell>%Monolingual</cell><cell>Rank</cell></row><row><cell>mirobaseru</cell><cell>0,3866</cell><cell>65,93</cell><cell>73</cell></row><row><cell>mirobasedu</cell><cell>0,3807</cell><cell>64,91</cell><cell>76</cell></row><row><cell>mirobasesw</cell><cell>0,3043</cell><cell>51,89</cell><cell>99</cell></row><row><cell>mirowbaseit</cell><cell>0,2857</cell><cell>48,72</cell><cell>106</cell></row><row><cell>mirobaseda</cell><cell>0,2799</cell><cell>47,72</cell><cell>107</cell></row><row><cell>mirowbasees</cell><cell>0,2687</cell><cell>45,82</cell><cell>113</cell></row><row><cell>mirowbaseesc</cell><cell>0,2615</cell><cell>44,59</cell><cell>114</cell></row><row><cell>mirowbasege</cell><cell>0,2455</cell><cell>41,87</cell><cell>122</cell></row><row><cell>mirobaseja</cell><cell>0,2358</cell><cell>40,21</cell><cell>124</cell></row><row><cell>mirowbasefr</cell><cell>0,2188</cell><cell>37,31</cell><cell>127</cell></row><row><cell>mirobasezh</cell><cell>0,1777</cell><cell>30,30</cell><cell>135</cell></row><row><cell>mirobasefi</cell><cell>0,17</cell><cell>28,99</cell><cell>141</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,150.36,589.20,294.51,9.02"><head>Table 5 .</head><label>5</label><figDesc>Average precision for Multilingual Adhoc Retrieval experiments</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="6,70.92,540.84,373.57,109.94"><head>Table 6 .</head><label>6</label><figDesc>Average Precision values for text and CBIR mixing experimentsComparing to Table</figDesc><table coords="6,161.94,540.84,263.50,74.12"><row><cell>Name</cell><cell>MAP</cell><cell>Rank</cell><cell>Initial Text search Experiment</cell></row><row><cell>enenrunexp1</cell><cell>0,5838</cell><cell>2</cell><cell>mirobaseen</cell></row><row><cell>enenrunexp7</cell><cell>0,5339</cell><cell>9</cell><cell>mirosppbaseen</cell></row><row><cell>enenrunexp4</cell><cell>0,3373</cell><cell>89</cell><cell>mirosnounen</cell></row><row><cell>enenrunexp10</cell><cell>0,2533</cell><cell>118</cell><cell>miroscppnounen</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="7,113.94,74.82,326.66,175.82"><head>Table 7 .</head><label>7</label><figDesc>Average Precison values using a different text retrieval system</figDesc><table coords="7,113.94,74.82,291.12,175.82"><row><cell></cell><cell></cell><cell></cell><cell>Rank</cell></row><row><cell cols="2">enenrun8</cell><cell>0,4173</cell><cell>52</cell></row><row><cell cols="2">enenrun7</cell><cell>0,3389</cell><cell>86</cell></row><row><cell cols="2">enenrun1</cell><cell>0,3362</cell><cell>91</cell></row><row><cell cols="2">enenrun4</cell><cell>0,0737</cell><cell>186</cell></row><row><cell>Run Name</cell><cell>MAP</cell><cell cols="2">%Monolingual</cell><cell>Rank</cell></row><row><cell>esenrun8ok</cell><cell>0,1226</cell><cell>20,91</cell><cell></cell><cell>164</cell></row><row><cell>esenrun2ok</cell><cell>0,1206</cell><cell>20,57</cell><cell></cell><cell>166</cell></row><row><cell>esenrun7ok</cell><cell>0,0787</cell><cell>13,42</cell><cell></cell><cell>183</cell></row><row><cell>esenrun1ok</cell><cell>0,0783</cell><cell>13,35</cell><cell></cell><cell>184</cell></row><row><cell>Table</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="8,159.18,465.66,276.96,74.30"><head>Table 9 .</head><label>9</label><figDesc>Average Precision values for Medical Retrieval experiments</figDesc><table coords="8,218.88,465.66,160.44,62.06"><row><cell>Name</cell><cell>MAP</cell><cell>Rank</cell></row><row><cell>enid1run</cell><cell>0.1798</cell><cell>32</cell></row><row><cell>enid3run</cell><cell>0.1752</cell><cell>33</cell></row><row><cell>enid0run</cell><cell>0.1650</cell><cell>34</cell></row><row><cell>enid2run</cell><cell>0.1542</cell><cell>35</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7.">Acknowledgements</head><p>This work has been partially supported by the projects <rs type="funder">OmniPaper (European Union</rs>, <rs type="programName">5th Framework Programme for Research and Technological Development</rs>, <rs type="grantNumber">IST-2001-32174</rs>) and <rs type="funder">MIRACLE (Regional Government of Madrid, Regional Plan for Research</rs>, <rs type="grantNumber">07T/0055/2003</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_wu5Rzd4">
					<idno type="grant-number">IST-2001-32174</idno>
					<orgName type="program" subtype="full">5th Framework Programme for Research and Technological Development</orgName>
				</org>
				<org type="funding" xml:id="_McWGSaE">
					<idno type="grant-number">07T/0055/2003</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,85.14,191.58,406.73,9.02" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="9,89.08,191.58,169.41,9.02">Altavista&apos;s Babel Fish Translation Service</title>
		<ptr target="http://babelfish.altavista.com/" />
		<imprint>
			<date type="published" when="2004-08-12">12.08.2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,85.14,203.34,439.35,9.02;9,85.14,215.10,209.48,9.02" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,127.79,203.34,271.16,9.02">Some Advances in Transformation Based Part of Speech Tagging</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,411.84,203.34,112.65,9.02;9,85.14,215.10,183.10,9.02">proceedings of the Twelfth National Conference on Artificial Intelligence</title>
		<meeting>the Twelfth National Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,85.14,226.86,439.27,9.02;9,85.14,238.62,163.58,9.02" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="9,89.72,226.86,421.51,9.02">Eurowordnet: Building a Multilingual Database with Wordnets for several European Languages</title>
		<ptr target="http://www.let.uva.nl/ewn/" />
		<imprint>
			<date type="published" when="1996-03">March, 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,85.14,250.44,435.09,9.02" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,142.06,250.44,161.18,9.02">WordNet: A lexical database for English</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,314.13,250.44,115.41,9.02">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,87.66,262.20,436.86,9.02;9,85.14,273.96,201.55,9.02" xml:id="b4">
	<monogr>
		<ptr target="http://www.tartarus.org/~martin/PorterStemmer/" />
		<title level="m" coord="9,92.67,262.20,149.02,9.02">The Porter Stemming Algorithm</title>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Porter</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2004-08-12">12.08.2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,85.14,285.72,424.17,9.02" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="9,89.93,285.72,119.59,9.02">The GNU Image-Finding Tool</title>
		<ptr target="http://www.gnu.org/software/gift/" />
		<imprint>
			<date type="published" when="2004-08-12">12.08.2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,85.14,297.48,299.17,9.02" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="9,89.40,297.48,78.54,9.02">Translation Experts</title>
		<ptr target="http://www.transexp.com" />
		<imprint>
			<date type="published" when="2004-08-12">12.08.2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,85.14,309.03,439.41,8.10;9,87.90,319.59,436.51,8.10;9,87.90,330.21,18.00,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,148.40,319.59,156.12,8.10">Image Retrieval: the MIRACLE Approach</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Villena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Martinez-Fernandez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Fombella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García-Serrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ruíz-Cristina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Goñi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>González-Cristóbal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,327.13,319.59,89.29,8.10">CLEF 2003 Proceedings</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
