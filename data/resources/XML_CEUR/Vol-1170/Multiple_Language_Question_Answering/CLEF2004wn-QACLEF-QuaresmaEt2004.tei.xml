<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,145.44,147.87,149.16,17.22;1,302.76,143.67,47.83,17.22;1,357.07,147.87,100.36,17.22;1,231.48,169.83,140.06,17.22">The University of Évora approach to QA</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,98.28,204.07,72.05,9.96"><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Informática</orgName>
								<orgName type="institution">Universidade de Évora</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,192.76,204.07,62.47,9.96"><forename type="first">Luís</forename><surname>Quintano</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Informática</orgName>
								<orgName type="institution">Universidade de Évora</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,277.78,204.07,69.05,9.96"><forename type="first">Irene</forename><surname>Rodrigues</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Informática</orgName>
								<orgName type="institution">Universidade de Évora</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,369.38,204.07,43.98,9.96"><forename type="first">José</forename><surname>Saias</surname></persName>
							<email>jsaias@di.uevora.pt</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Informática</orgName>
								<orgName type="institution">Universidade de Évora</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,435.91,204.07,68.69,9.96"><forename type="first">Pedro</forename><surname>Salgueiro</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Informática</orgName>
								<orgName type="institution">Universidade de Évora</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,145.44,147.87,149.16,17.22;1,302.76,143.67,47.83,17.22;1,357.07,147.87,100.36,17.22;1,231.48,169.83,140.06,17.22">The University of Évora approach to QA</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">79D6BFBBD15198F7E61A22EF4435B98D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The approach followed by the University of Évora team in order to build a system able to participate in the QA-CLEF task is described.</p><p>The system is based in two steps: for each question, a first information retrieval task selects a set of potentially relevant documents; then, each of these documents is analysed trying to obtain their semantic representation and the answer to the initial query.</p><p>The proposed approach was applied to the test set of the QA-CLEF for the Portuguese language and the obtained results were quite interesting and motivating and allowed the identification of strong and weak characteristics of the system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Question answering systems are an important topic of research in the natural language processing field and much work has been done by many researchers in the last years. Several international conferences have special tracks for analysing this topic, namely, the TREC -Text REtrieval Conference (http://trec.nist.gov) or the CLEF -Cross Language Evaluation Forum (http://www.clefcampaign.org).</p><p>For the 2004 campaign, CLEF has added the Portuguese language as a possible language for the queries and for the target documents.</p><p>In the last years, the Informatics Department of the University of Évora has been working in the natural language processing field, namely trying to develop specialised tools for the Portuguese language.</p><p>This paper describes the University of Évora approach to the question answering task for the Portuguese language of CLEF 2004. The collection of target documents is the set of news published by the Portuguese newspaper "Público" during 1994 and 1995. Questions (200) can be factoids or definitions and some of them may have no answer in the target set of documents.</p><p>The proposed system is based in two steps:</p><p>• For each question, a first information retrieval task selects a set of potentially relevant documents.</p><p>• Then, for each of these documents that where analysed in the preparatory phase trying to extract the facts they conveyed, the user query is interpreted on each selected text knowledge base. When an answer to the query is obtained, the process stops and the system outputs the answer and then identifies the document from where the answer was obtained.</p><p>Our question answer system needs to have a preliminary information retrieval task, defining a smaller set of potentially relevant documents due to computational complexity problems. In fact, our main approach is to deeply analyse the set of documents and to obtain a partial semantic representation of their content. Then, each query would be transformed into its semantic form and an inference process would try to obtain the answer to the query. However, this approach showed many scalability problems due to the large number of documents and associated data and it was necessary to strongly reduce its cardinality.</p><p>Section 2 describes the preparatory phase where the set of documents are preprocessed in order to build the IR indexes and the knowledge base for each text.</p><p>Section 3 describes the proposed architecture for the question-answer system and section 4 describes each of the architecture modules. A preliminary evaluation is presented in section 5 and some conclusions and future work is discussed in section 6.</p><p>2 Pre-processing the set of target documents There exists an important pre-processing phase of the target collection of documents in order to obtain the input data necessary for our question answer system.</p><p>In this phase two main tasks are done:</p><p>• Semantic/Pragmatic Interpretation -gives rise to a set of knowledge bases, Text facts collection, where each knowledge base has the facts conveyed by each text.</p><p>• Information retrieval indexing -creates the files that index the full set of documents with a reference to the knowledge base associated to each document, Sino Index Files.</p><p>The other tasks of this phase are:</p><p>• Portuguese Parser -each text of the collection is analysed by the Portuguese parser PALAVRAS <ref type="bibr" coords="2,114.96,620.95,10.43,9.96" target="#b2">[3]</ref> developed in the context of the VISL 1 project in the Institute of Language and Communication of the University of Southern Denmark. The output of the parser is a file with the syntactic analysis of each text.</p><p>We've chosen to keep the first syntactic analysis for each sentence; this option is one of our sources of problems.</p><p>• Semantic Interpretation -each syntactic structure is rewritten into a First-Order Logic expression. The technique used for this analysis is based on DRS's (Discourse Representation Structures) <ref type="bibr" coords="2,160.42,716.59,12.40,9.96" target="#b6">[6]</ref>.</p><p>This technique identifies triggering syntactic configurations on the global sentence structure, which activates the rewriting rules. We always rewrite the pp's by the relation 'rel(prep,A,B)' postponing its interpretation to the semantic pragmatic module.</p><p>The semantic representation of sentence is a DRS build with two lists, one with the new sentence rewritten and the other with the sentence discourse referents.</p><p>One of the most important requirements of the proposed QA system is to have a knowledge base of facts inferred from the analysis of the set of target documents and an ontology containing the concepts referred in the documents.</p><p>• Ontology -From the output of the DRS's generation and from an existent top ontology of concepts, a new ontology containing the concepts referred in the documents was created <ref type="bibr" coords="3,114.96,249.19,15.46,9.96" target="#b10">[10,</ref><ref type="bibr" coords="3,133.66,249.19,7.03,9.96" target="#b9">9]</ref>.</p><p>This step showed to be very problematic, due to the large number of concepts referred in the documents and to the complexity and difficulty of finding correct relations between them.</p><p>The obtained ontology was created in the OWL (Ontology Web Language) format and in a logic programming framework, ISCO <ref type="bibr" coords="3,293.00,303.91,10.43,9.96" target="#b0">[1,</ref><ref type="bibr" coords="3,307.88,303.91,7.03,9.96" target="#b1">2]</ref>, which allows the integration of Prolog-like inference mechanisms with classes and inheritance, and constraint solving algorithms.</p><p>• Knowledge base -From this ontology and from each sentence semantic representation we could obtain the interpretation of each text sentence that will give rise to a set of facts to add into out knowledge base <ref type="bibr" coords="3,242.41,358.75,9.98,9.96" target="#b7">[7]</ref>.</p><p>However, this task showed to be very complex in its computational time and space and the obtained knowledge base was very large and it created many problems to the inference processes.</p><p>Accordingly, it was decided to first decrease the set of relevant documents to each query (via IR techniques) and, then, to create a set smaller knowledge base.</p><p>The knowledge base referred in figure <ref type="figure" coords="3,287.50,440.83,5.03,9.96" target="#fig_0">1</ref> was build with a set of facts extracted from the target text collection and with rules and facts that we import from other applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Semantic/Pragmatic Interpretation of text sentences</head><p>In order to obtain the set of facts of each text sentence we need to use the ontology in order to obtain the meaning of each text sentence. The semantic/pragmatic module receives the sentence rewritten (into a First Order Logic form) and tries to interpret it in the context of the document database information (ontology).</p><p>In order to achieve this behaviour the system tries to find the best explanations for the sentence logic form to be true in the knowledge base for the semantic/pragmatic interpretation. This strategy for interpretation is known as "interpretation as abduction" <ref type="bibr" coords="3,393.07,570.31,9.98,9.96" target="#b4">[5]</ref>.</p><p>The knowledge base for the semantic/pragmatic interpretation is built from the Ontology. The inference in this knowledge base uses abduction, restrictions (GNU Prolog Finite Domain (FD) constraint solver).</p><p>The knowledge base rules contains the information for the interpretation of each term in the sentence logic form as a prolog term.</p><p>As an example consider the sentence: "O gato do João comeu o rato do Manuel/John's cat ate Manuel's mouse." is transformed into a DRS-like term showing the 4 referents and their relations:</p><formula xml:id="formula_0" coords="3,105.72,685.83,167.62,68.89">drs([def-A-m-s, def-B-m-s, def-C-m-s, def-D-m-s], [cat(A), rel(of,A,B), name(B,'João'), comer(A,C), mouse(C), rel(of,C,D), name(D,'Manuel')]).</formula><p>The semantic interpretation module using the ontology will rewrite this DRS into: The interpretation of rel(of,A,B) as owns(A,B) is possible due to the existence of the relation owns that relates persons and animals.</p><formula xml:id="formula_1" coords="4,105.72,133.95,141.52,33.01">drs([def-A-m-s, def-B-m-s, def-C-m-s, def-D-m-s], [cat(A),</formula><p>Other important step in this task is to create new individuals (new identifiers) for discourse referents when they are not instantiated during the interpretation. This last step is a source of problems for our QA-system since it is possible to have different identifiers for the same individual if this task fails to identify the sentences entities. The opposite can also happen, this task may unify individuals that are different.</p><p>The option of building a knowledge base with the facts extracted for each documents helps us to deal with this problems, there are fewer entities.</p><p>A problem that we still have to solve is the way how we choose the best meaning for a sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Information retrieval indexing</head><p>SINO <ref type="bibr" coords="4,118.06,368.95,10.43,9.96" target="#b8">[8,</ref><ref type="bibr" coords="4,132.21,368.95,6.95,9.96" target="#b3">4]</ref>, originally from the Australasian Legal Information Institute, was used to index the full set of documents. It allows the creation of inverted index files and in the new version it uses information specific to the Portuguese language: stop words and lemmatization. In fact, SINO was extended to use a set of Portuguese stop words (such as, articles, pronouns, prepositions) and to transform each word in its lemma (using the Portuguese lexicon POLARIS). Documents are indexed by a specialized search engine for the Portuguese language -SINO <ref type="bibr" coords="4,90.00,440.71,10.55,9.96" target="#b8">[8,</ref><ref type="bibr" coords="4,104.03,440.71,7.79,9.96" target="#b3">4]</ref> -and an information retrieval system for this collection is built. As it will be described in more detail in the next section, the information retrieval system will be used, for each query, to decrease the cardinality of the target set of documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Architecture</head><p>The architecture is composed by several independent modules. Figure <ref type="figure" coords="4,403.08,519.31,5.03,9.96" target="#fig_2">2</ref> shows a graphical view of their relations.</p><p>In the next sub-sections a brief description of each module is presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Query processing</head><p>Each query is processed using the same natural language tools used to analyse the full set of documents, The Portuguese syntactic Parser Palavras and the DRS's generation. After obtaining the Query DRS there are two task that are performed concurrently:</p><p>• The Semantic Pragmatic Interpretation of the query. The query semantic representation is obtained taking into account the ontology of concepts and a knowledge base with some general world knowledge.</p><p>• The query preprocessing and the interrogation of the IR system. After obtaining the query DRS, it is transformed into a search term to the IR engine -SINO. This step is needed because it was computationally impossible to handle inferences over the complete knowledge base created in the pre-processing phase of the documents. So, we use an information retrieval system to obtain a set of relevant documents to make inferences only over the knowledge base created with the information conveyed by these documents. The IR queries are created from the semantic representation, DRS, of each query and their structure will be described in the next section.</p><p>Using the IR queries, the search engine obtains an ordered set of relevant documents. This set is used to create a smaller knowledge base of DRS containing only the information conveyed by these relevant documents.</p><p>In this way it is possible to strongly decrease the complexity of the knowledge base and it is possible to handle inferences over it.</p><p>Finally the Process answer task receives the set of relevant knowledge bases where the query semantic/pragmatic representation should be evaluated and tries to infer the answer to the query.</p><p>The inference process is based in a logic programming framework, ISCO <ref type="bibr" coords="5,428.61,549.07,10.55,9.96" target="#b0">[1,</ref><ref type="bibr" coords="5,443.00,549.07,6.95,9.96" target="#b1">2]</ref>, which allows the integration of Prolog-like inference mechanisms with classes and inheritance, and constraint solving algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Modules</head><p>In this section a more detailed description of the most relevant modules of the architecture is presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Natural Language Query Processing</head><p>This module tasks: Palavras+Drs generation and the Pragmatic Interpretation follow an approach similar with the semantic-pragmatic interpretation of the documents sentences and it uses the same natural language tools: the PALAVRAS parser, the DRS generation and semantic-pragmatic interpreter.</p><p>After the DRS generation we are able to identify the referents which are the focus of each query and the kind of query performed.</p><p>For instance, the query: "Quem comeu o rato do Manuel/Who ate Manuel's rat?" is transformed into the DRS-like term:</p><formula xml:id="formula_2" coords="6,105.72,145.83,198.97,9.13">drs([who-A-X-Y, def-B-m-s, def-C-m-s],</formula><p>[eat(A,B), mouse(B), rel(de,B,C), name(C,'Manuel')]).</p><p>After obtaining the query DRS, the semantic-pragmatic interpretation using the ontology of concepts created in the pre-processing phase gives rise to the final query representation:</p><p>For the above example it will be:</p><formula xml:id="formula_3" coords="6,105.72,249.51,198.97,45.01">drs([who-A-X-Y, def-B-m-s, def-C-m-s], [eat(A,B), mouse(B), owns(C,B),person(C), name(C,'Manuel')]).</formula><p>This final query representation will be evaluated in each knowledge base selected by the last sino query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Query preprocessing</head><p>After obtaining the query DRS, it is transformed into a search term to the IR engine -SINO.</p><p>The approach followed was to create three IR query terms for each natural language query and to order the set of documents retrieved. The overall idea is to create a very restrictive query, a very general one, and one in the middle. The created IR queries are boolean ones and they are obtained from the DRS of each query: ''Em que cidade se encontra a prisão de San Vittore?'' cidade AND encontrar AND prisão AND (San AND Vittore) cidade AND (encontrar OR prisão OR (San AND Vittore))</p><p>cidade OR encontrar OR prisão OR (San AND Vittore)</p><p>The first query is the more specific, obtained from the boolean AND of each term; the second query is obtained from the boolean AND of the head of the query with the OR of the other terms; and the third query is the more general, obtained from the OR of each term.</p><p>From the ordered set of documents, the first 50 are selected and they are the basis for the creation of each query-related knowledge base.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Sino -Relevant documents DRS extraction</head><p>This module receives the three IR queries and it retrieves the correspondent relevant documents. As it was already described, the IR engine used was an extension of the SINO engine from the AustLII institute.</p><p>SINO retrieves the relevant documents (using the boolean operators) and it orders the selection using a ranking function. This ranking function gives higher priority to documents with more word hits or with hits in the title. It is important to point out that first documents are ordered accordingly with the kind of query: first the documents retrieved from the more specific query and with last priority the documents retrieved from the more general one. Inside each set of retrieved documents, the order is obtained through the SINO ranking function.</p><p>After having a ordered list of relevant documents, the first 50 were selected as the basis to create a knowledge base of facts relevant to the query. The reason why the first 50 were chosen is related with the goal of reducing the computational complexity and assuming a good performance of the SINO engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Answer inference process</head><p>This module is the responsible for finding the correct, exact answer to each query. It receives the semantic-pragmatic interpretation of each query (in a DRS-like format) and a logic-programming based knowledge base built from the set of the most relevant 50 documents of each query.</p><p>The inference process is done via the use of the Prolog resolution algorithm, which tries to unify the referent in the query with facts extracted from the documents. This unification takes into account the information associated with the referents, such as, genre and number. Moreover, the inference process uses the "kind of" question, such as, where/when/who, to identify the feature that is queried about. For instance, if the query is about a place of a specific entity, "Em que cidade se encontra a prisão de San Vittore?", the system tries to find a feature of that entity that is a place and it is not referred in the query.</p><p>As it can be seen from this description, the proposed system relies on the quality of the inferred ontology and in a good semantic-pragmatic interpretation of sentences and queries.</p><p>As a consequence of our approach, the system has always a confidence value for each answer of 1: if it finds an answer, then it is sure about it!</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>The proposed system was applied to the set of 200 questions (in fact they were 199, because one question was not considered by the judges).</p><p>It obtained 47 correct answers, 18 inexact and 134 wrong with an overall accuracy of correct answers of 23.62% and a confidence-weighted score of 0.21619. If the accuracy is calculated over the correct and the inexact answers, then its value is 32.66%.</p><p>We believe these are quite interesting results, that show the potential of the proposed approach. However, they also show the main problem of the system: it gave 127 "nil" answers and only 9 of them were correct.</p><p>The most important question now is: what happened in the 118 questions that had no answer from the system?</p><p>A preliminary evaluation showed that there were two main causes of problems:</p><p>• the information retrieval system</p><p>• the ontology The information retrieval system, which was used to decrease the complexity of the knowledge base, quite often was not able to find the relevant documents. In fact, this problem can be clearly seen in the results of the IR task of CLEF'04, in which SINO showed very low recall values. This problem can be overcome by changing the SINO queries to better ones or by solving the complexity problems that made impossible the construction of a large, unique knowledge base. We intend to explore both possibilities.</p><p>The second problem was the quality of the ontology. In fact, the inference process relies heavily on the ontology. For instance, it is important to know what are places, persons, dates, synonyms. In the example presented previously, if the ontology does not have information relating "cidade" with the class of "places", then the system would not be able to answer the query. We will also continue to develop new strategies for constructing and merging ontologies. This proposal represents a first approach for a question answering system for the Portuguese language.</p><p>Our system uses natural language processing techniques to create a knowledge base from the information conveyed by the target documents. Queries are analysed by NLP tools and inferences are done over the knowledge base trying to find a correct answer. The inference process is done using a logic programming framework and the Prolog resolution.</p><p>The initial idea of creating a unique, large knowledge base with the facts extracted from all the documents was not feasible due to computational complexity problems. These problems led to the creation of an IR pre-analysis of the queries to decrease the complexity of the knowledge base. However, the IR engine showed some recall problems and lead to the incapacity of the QA system to answer many queries.</p><p>The ontology used was also a major problem and it was the origin of many other wrong answers. As the QA@CLEF task uses general domain documents, this is a very complex problem: how to obtain a good general purpose ontology?</p><p>As future work, we intend to try to develop new strategies for (partially) overcome these problems. Working with new implementation strategies it may be possible to have an unique knowledge base and using existent ontologies and Wordnets may improve the quality of the final ontology.</p><p>Finally, we also intend to explore the problem of inter-sentence anaphoric references and to be able to identify the correct referents in the documents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,236.88,456.31,129.35,9.96"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Texts preprocessing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,173.56,157.83,110.21,9.13;4,131.88,169.83,136.19,9.13;4,131.88,181.71,162.32,9.13;4,131.88,193.71,99.89,9.13"><head></head><label></label><figDesc>owns(B,A), person(B), name(B,'João'), eats(A,C), mouse(C), owns(D,C), person(D), name(D,'Manuel')]).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,223.80,395.59,155.38,9.96"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: QA System's architecture</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,110.51,415.15,402.22,9.96;8,110.52,427.15,302.81,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,186.29,415.15,326.45,9.96;8,110.52,427.15,15.92,9.96">Isco: A practical language for heterogeneous information system construction</title>
		<author>
			<persName coords=""><forename type="first">Salvador</forename><surname>Abreu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,147.22,427.15,100.93,9.96">Proceedings of INAP&apos;01</title>
		<meeting>INAP&apos;01<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>INAP</publisher>
			<date type="published" when="2001-10">October 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.51,446.95,402.38,9.96;8,110.52,458.83,401.82,9.96;8,110.52,470.83,402.07,9.96;8,110.52,482.71,188.25,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,425.62,446.95,87.28,9.96;8,110.52,458.83,100.50,9.96">A dialogue manager for accessing databases</title>
		<author>
			<persName coords=""><forename type="first">Salvador</forename><surname>Abreu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luis</forename><surname>Quintano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Irene</forename><surname>Rodrigues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,236.28,458.83,276.06,9.96;8,110.52,470.83,93.59,9.96">13th European-Japanese Conference on Information Modelling and Knowledge Bases</title>
		<meeting><address><addrLine>Kitakyushu, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2003-06">June 2003</date>
			<biblScope unit="page" from="213" to="224" />
		</imprint>
		<respStmt>
			<orgName>Kyushu Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note>To be published by</note>
</biblStruct>

<biblStruct coords="8,110.51,502.63,402.08,9.96;8,110.52,514.51,340.36,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,180.53,502.63,135.12,9.96">The Parsing System &quot;Palavras</title>
		<author>
			<persName coords=""><forename type="first">Eckhard</forename><surname>Bick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,329.41,502.63,183.18,9.96;8,110.52,514.51,196.63,9.96">Automatic Grammatical Analysis of Portuguese in a Constraint Grammar Framework</title>
		<imprint>
			<publisher>Aarhus University Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.51,534.31,402.16,9.96;8,110.52,546.31,369.15,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,296.00,534.31,216.66,9.96;8,110.52,546.31,63.90,9.96">Law on the net via austlii -14 m hypertext links can&apos;t be right?</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Greenleaf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mowbray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,205.37,546.31,206.50,9.96">Information Online and On Disk&apos;97 Conference</title>
		<meeting><address><addrLine>Sydney</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.51,566.11,402.15,9.96;8,110.52,578.11,207.64,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,389.28,566.11,118.76,9.96">Interpretation as abduction</title>
		<author>
			<persName coords=""><forename type="first">Jerry</forename><surname>Hobbs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Stickel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><surname>Appelt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,110.52,578.11,166.17,9.96">Technical Report SRI Technical Note</title>
		<imprint>
			<biblScope unit="volume">499</biblScope>
			<biblScope unit="page">333</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,322.24,578.11,190.60,9.96;8,110.52,589.99,22.88,9.96" xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Ravenswood</forename><surname>Ave</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">94025. 1990</date>
			<pubPlace>Menlo Park, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.51,609.79,402.09,9.96;8,110.52,621.79,402.17,9.96;8,110.52,633.79,69.89,9.96" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="8,238.56,609.79,274.04,9.96;8,110.52,621.79,347.59,9.96">From Discourse to Logic:An Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory</title>
		<author>
			<persName coords=""><forename type="first">Hans</forename><surname>Kamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Uwe</forename><surname>Reyle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>D. Reidel</publisher>
			<pubPlace>Dordrecht</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.51,653.59,402.25,9.96;8,110.52,665.47,402.27,9.96;8,110.52,677.47,402.08,9.96;8,110.52,689.35,373.43,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,319.86,653.59,192.90,9.96;8,110.52,665.47,163.41,9.96">A natural language interface for information retrieval on semantic web documents</title>
		<author>
			<persName coords=""><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Irene</forename><forename type="middle">Pimenta</forename><surname>Rodrigues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,145.65,677.47,219.67,9.96">AWIC&apos;2003 -Atlantic Web Intelligence Conference</title>
		<title level="s" coord="8,373.16,677.47,139.44,9.96;8,110.52,689.35,88.72,9.96">Lecture Notes in Artificial Intelligence LNCS/LNAI</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Menasalvas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Segovia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Szczepaniak</surname></persName>
		</editor>
		<meeting><address><addrLine>Madrid, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003-05">May 2003</date>
			<biblScope unit="volume">2663</biblScope>
			<biblScope unit="page" from="142" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.51,709.27,402.24,9.96;8,110.52,721.15,401.99,9.96;8,110.52,733.15,402.34,9.96;8,110.52,745.03,154.62,9.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,326.94,709.27,185.81,9.96;8,110.52,721.15,84.05,9.96">PGR: Portuguese attorney general&apos;s office decisions on the web</title>
		<author>
			<persName coords=""><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Irene</forename><forename type="middle">Pimenta</forename><surname>Rodrigues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,443.72,721.15,68.79,9.96;8,110.52,733.15,148.00,9.96">Web-Knowledge Management and Decision Support</title>
		<title level="s" coord="8,265.66,733.15,221.80,9.96">Lecture Notes in Artificial Intelligence LNCS/LNAI</title>
		<editor>
			<persName><forename type="first">Geske</forename><surname>Bartenstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yoshie</forename><surname>Hannebauer</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2543</biblScope>
			<biblScope unit="page" from="51" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.51,111.43,402.26,9.96;9,110.52,123.43,402.08,9.96;9,110.52,135.31,402.12,9.96;9,111.36,144.79,164.95,12.48" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="9,162.77,111.43,350.00,9.96;9,110.52,123.43,402.08,9.96;9,110.52,135.31,266.89,9.96">Uma metodologia para a construção automática de ontologias e a sua aplicação em sistemas de recuperação de informação -a methodology for the automatic creation of ontologies and its application in information retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Saias</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Portugal</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Évora</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
	<note>In Portuguese</note>
</biblStruct>

<biblStruct coords="9,110.50,167.23,402.23,9.96;9,110.52,179.23,401.97,9.96;9,110.52,191.11,401.95,9.96;9,110.52,203.11,238.11,9.96" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,261.32,167.23,251.41,9.96;9,110.52,179.23,230.00,9.96">Using nlp techniques to create legal ontologies in a logic programming based web information retrieval system</title>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Saias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,361.95,179.23,150.53,9.96;9,110.52,191.11,401.95,9.96;9,110.52,203.11,87.26,9.96">Workshop on Legal Ontologies and Web based legal information management of the 9th International Conference on Artificial Intelligence and Law</title>
		<meeting><address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
