<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,140.52,90.91,314.07,12.19">GIRT and the Use of Subject Metadata for Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,270.54,119.49,54.26,8.74"><forename type="first">Vivien</forename><surname>Petras</surname></persName>
							<email>vivienp@sims.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Management and Systems</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,140.52,90.91,314.07,12.19">GIRT and the Use of Subject Metadata for Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">19D98DEC6C2B78E0B1FDA9853BC852F9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The use of domain-specific metadata (subject keywords) is tested for monolingual and bilingual retrieval on the GIRT social science collection. A new technique, Entry Vocabulary Modules, which adds subject keywords selected from the controlled vocabulary to the query, has been tested. As in previous years, we compare our techniques of thesaurus matching and Entry Vocabulary Modules to simple machine translation techniques in bilingual retrieval. A combination of machine translation and thesaurus matching achieves better results, whereas the introduction of Entry Vocabulary Modules has negligent impact on the retrieval results. Retrieval results for the German and English GIRT collection for monolingual as well as bilingual retrieval (with English and German as query languages) will be represented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1</head></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>For several years now, the Berkeley group has been interested in how the use of subject metadata (additional to the full text of title and abstract of documents) can improve information retrieval and provide more precise results. For this year's CLEF evaluation, we once again focused on the GIRT collection with its thesaurusenhanced records, giving us an experimental playing field. We believe that leveraging the high-quality keywords provided by a controlled vocabulary could help in disambiguating the fuzziness of the searcher language and aid searchers in formulating effective queries in order to match relevant documents better.</p><p>We are experimenting with a technique called Entry Vocabulary Modules, which suggests subject keywords from the thesaurus when given a natural language query. Like blind feedback terms, these subject keywords are added to the query with the goal of matching the controlled vocabulary terms added to the documents. Using the bilingual feature of the GIRT thesaurus, we substitute suggested thesaurus terms from the Entry Vocabulary Module in the query language with those in the target document language, thereby providing a crude translation mechanism for bilingual retrieval. The improvements over baseline retrieval were minimal, however. A description of the technique is provided in the next section.</p><p>Once again, we also tested thesaurus matching for bilingual retrieval against machine translation (described in section 1.2). We report positive results for a combination of thesaurus matching and machine translation. We have used both the German and English GIRT document collection for monolingual and bilingual retrieval. English and German were used as query languages. All runs are TD (title, description) runs only.</p><p>For all retrieval experiments, the Berkeley group is using the technique of logistic regression as described in <ref type="bibr" coords="1,70.92,597.87,70.59,8.74" target="#b1">Chen et al. (1994)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Entry Vocabulary Modules</head><p>Entry Vocabulary Modules (EVMs) are intermediaries between natural language queries and the metadata "language" of a document repository. For a given query, they act as "interpreter" between the searcher and the system, (hopefully) proposing more effective query terms from the controlled vocabulary of the searched documents. The concept of Entry Vocabulary Modules is based on the idea that searching with the "correct" controlled vocabulary terms (i.e. thesaurus terms in the GIRT case) will yield better and more complete results than using any randomly chosen terms in the query. If using an EVM, the searcher is presented with a list of ranked controlled vocabulary terms that the EVM deems appropriate for the query. The searcher can then choose and add or substitute these terms in the query.</p><p>An Entry Vocabulary Module is created by building a dictionary of associations between terms and phrases of titles, authors, and / or abstracts of existing documents and the controlled vocabulary. A likelihood ratio statistic is used to measure the association between these and to predict which metadata terms best mirror the topic represented by the searcher's search vocabulary. The methodology of constructing Entry Vocabulary Indexes has been described in detail by <ref type="bibr" coords="2,180.65,119.49,42.48,8.74" target="#b5">Plaunt and</ref><ref type="bibr" coords="2,225.62,119.49,82.03,8.74" target="#b5">Norgard (1998), and</ref><ref type="bibr" coords="2,310.15,119.49,66.14,8.74" target="#b2">Gey et al. (1999)</ref>.</p><p>As the basic technique, a lexical collocation process between document words and controlled vocabulary terms is used. If words co-occur with a higher than random frequency, there exists a likelihood that they are strongly associated. The idea is that the stronger an association between the occurrence of two or more words (document word and controlled vocabulary term), the more likely it is that the collocation is meaningful. If an Entry Vocabulary Module is used to predict metadata vocabulary terms for a document, the association weights for document term and metadata term pairs are combined by adding them. By choosing the highest value of the added weights, the probability of relevance for metadata terms for a whole document can be determined.</p><p>For the GIRT experiments, we created an EVM for each of the English and German collections using the titles and abstracts and the controlled vocabulary terms. We then automatically added the top ranked terms to the query in the same way we would add blind feedback terms to a query. This leaves out the manual selection process where a searcher selects appropriate terms counting on the prediction that an EVM will rank the "best" or most effective controlled vocabulary terms first. Although the controlled vocabulary terms seem to represent the content of the query, the retrieval results didn't improve. More analysis is necessary to find the reason.</p><p>Using EVMs to add query terms automatically carries the risk of distorting the query and misrepresenting the content by putting to much weight on more ineffective query terms. Below is an example of the top 10 suggested controlled vocabulary terms from the German EVM for GIRT query number 2. We input the title and description of the query. &lt;num&gt; 102 &lt;/num&gt; &lt;DE-title&gt; Deregulierung des Strommarktes &lt;/DE-title&gt; &lt;DE-desc&gt; Finde Dokumente, die über die Deregulierung in der Elektrizitätswirtschaft berichten. &lt;/DE-desc&gt; &lt;cv&gt;Deregulierung &lt;/cv&gt; &lt;cv&gt;Flexibilität &lt;/cv&gt; &lt;cv&gt;Elektrizitätswirtschaft &lt;/cv&gt; &lt;cv&gt;Arbeitsmarkt &lt;/cv&gt; &lt;cv&gt;Telekommunikation &lt;/cv&gt; &lt;cv&gt;Wettbewerb &lt;/cv&gt; &lt;cv&gt;Ordnungspolitik &lt;/cv&gt; &lt;cv&gt;Privatisierung &lt;/cv&gt; &lt;cv&gt;Wirtschaftspolitik &lt;/cv&gt; &lt;cv&gt;Elektrizität &lt;/cv&gt; Although some controlled vocabulary terms are wrongly suggested (e.g. Arbeitsmarkt), these terms could be specific enough to add more information to the query and not distort the original sense of the query. Following however is an example from the English EVM for GIRT where the EVM doesn't necessarily suggest "wrong" controlled vocabulary terms but also doesn't seem to add much valuable content to the query. &lt;num&gt; 114 &lt;/num&gt; &lt;EN-title&gt; Illegal Employment in Germany &lt;/EN-title&gt; &lt;EN-desc&gt; Find documents reporting on illicit work in the Federal Republic of Germany. &lt;/EN-desc&gt; &lt;cv&gt;labor market &lt;/cv&gt; &lt;cv&gt;federal republic of germany &lt;/cv&gt; &lt;cv&gt;labor market policy &lt;/cv&gt; &lt;cv&gt;unemployment &lt;/cv&gt; &lt;cv&gt;employment policy &lt;/cv&gt; &lt;cv&gt;new bundeslaender &lt;/cv&gt; &lt;cv&gt;employment trend &lt;/cv&gt; &lt;cv&gt;employment &lt;/cv&gt; &lt;cv&gt;effect on employment &lt;/cv&gt; &lt;cv&gt;old bundeslaender &lt;/cv&gt;</p><p>The controlled vocabulary term "Federal Republic of Germany" occurs over 60,000 times in the collection and "Labor Market" and "Unemployment" over 4,000 times respectively. Adding these words is not discriminating for the search at all, just the opposite.</p><p>More analysis is necessary to find a more selective way of adding controlled vocabulary terms, maybe based on distribution measures within the document collection and appropriate fit with the query. It might be possible that EVMs cannot be used in a completely automatic manner (adding terms without manual pre-selection).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Thesaurus Matching</head><p>We have been experimenting with thesaurus matching for three years and yielded astonishingly good results. Thesaurus matching is a translation technique where the query is first split into words and phrases (the longest possible phrase is chosen). Secondly, these words and phrases are looked up in the thesaurus that is provided with the GIRT collection and, if found, substituted with the target language terms from the thesaurus. Words and phrases that cannot be translated (not found in the thesaurus) are kept in the original language. For a more detailed description of the technique, see <ref type="bibr" coords="3,241.23,294.27,77.85,8.74" target="#b4">Petras et al. (2002)</ref> and for a discussion of efficiency and advantages and disadvantages, see our paper from last year <ref type="bibr" coords="3,262.84,305.79,76.21,8.74" target="#b3">(Petras et al., 2003)</ref>.</p><p>Thesaurus matching is in essence leveraging the high-quality translations of controlled vocabulary terms in multilingual thesauri. The GIRT thesaurus provides a controlled vocabulary in English, German and Russian. We experimented with thesaurus matching from German to English and from English to German and achieved comparable results to machine translation.</p><p>Although thesaurus matching relies only on the exact terms and phrases as they appear in the query, enough seem to be found to achieve a reasonable representation of the query content in controlled vocabulary terms. Even though Entry Vocabulary Modules also represent the query content in controlled vocabulary terms, adding them to the query instead of substituting query terms with them doesn't yield as noticeable results in bilingual retrieval. This might have several reasons, among them the number of added terms, the preciseness and distinctiveness of the chosen terms and the size of the controlled vocabulary (how many records contain the same controlled vocabulary term and how effective is adding a controlled vocabulary term).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">The GIRT collection</head><p>The GIRT collection (German Indexing and Retrieval Test database) consists of 151,319 documents containing titles, abstracts and controlled vocabulary terms in the social science domain. The GIRT controlled vocabulary terms are based on the Thesaurus for the Social Sciences <ref type="bibr" coords="3,310.14,526.59,58.25,8.74" target="#b6">(Schott, 2000)</ref> and are provided in German, English and Russian.</p><p>In 2003, two parallel GIRT corpora were made available: (1) German GIRT 4 contains document fields with German text, and (2) English GIRT 4 contains the translations of these fields into English. Although these corpora are described as parallel, they are not identical.</p><p>Both collections contain 151,319 records, but the English collection contains only 26,058 abstracts (ca. one out of six records) whereas the German collection contains 145,941 -providing an abstract for almost all documents. Consequently, the German collection contains more terms per record to search on. The English corpus has 1,535,445 controlled vocabulary terms (7064 unique phrases) and 301,257 classification codes (159 unique phrases) assigned. The German corpus has 1,535,582 controlled vocabulary terms (7154 unique phrases) and 300,115 classification codes (158 unique phrases) assigned. On average, 10 controlled vocabulary terms and 2 classification codes have been assigned to each document.</p><p>Controlled vocabulary terms and classification codes are not uniformly distributed. For example, the top 12 most often assigned controlled vocabulary terms for both corpora make up about half of the number of assigned terms. Whereas the distribution of controlled vocabulary terms has no impact on the thesaurus matching technique, it influences the performance of the statistical association technique for Entry Vocabulary Modules, i.e. skews towards more often assigned terms. For this year's experiments, we haven't made efforts to normalize the data to ensure optimal training of the EVMs, which is a next step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">GIRT RETRIEVAL EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">GIRT Monolingual</head><p>For GIRT monolingual retrieval, six runs for each language are presented, five of which were official runs. We compared two ways of using controlled vocabulary terms provided by the EVMs and submitted one official run for each.</p><p>We submitted the required run against a GIRT document index without the added thesaurus terms. For both languages, this was the run with the lowest average precision. However, the English run is much worse than the German (both in the first column of tables 1 and 2), demonstrating the effect of added keywords to documents when a lot of the abstracts are missing (see section 1.3 for a small analysis of the GIRT collections).</p><p>As a baseline, a run against the full document collection (including thesaurus and classification terms) without additional query keywords was used (second column of both tables 1 and 2). This baseline run was only minimally surpassed by the EVM-enhanced runs, yielding an average precision of 0.4150 for German and 0.3834 for English respectively.</p><p>The first method of adding controlled vocabulary terms to the query was used in official runs BKGRMLGG2 and BKGRMLEE2 for German and English respectively. The top three ranked suggested thesaurus terms from the Entry Vocabulary Modules (one for German and one for English) were added to the title and description of the query. The added terms were then down weighted by half as compared to title and description terms in retrieval. In columns 3-5 of tables 1 and 2, retrieval runs adding one, three and five controlled vocabulary terms suggested by an EVM are compared.</p><p>The second method of utilizing EVMs was used in official runs BKGRMLGG1 and BKGRMLEE1. Whereas the terms from the title and description of the query were run against a full document index, the added thesaurus terms were run against a special index consisting of the controlled vocabulary terms added to the documents only. The results of these two runs were then merged by comparing values of the probability rank provided by our logistic regression retrieval algorithm. For both German and English, this merging yielded worse results than the baseline run indicating that the run against the index with thesaurus terms only distorted results. The thesaurus terms alone might not have enough distinctive power to discriminate against irrelevant documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">German Monolingual</head><p>For all runs against the German GIRT collection, we used our decompounding procedure to split German compound words into individual terms in both the documents and the queries. The procedure is described in <ref type="bibr" coords="4,70.92,551.85,78.19,8.74" target="#b0">Chen &amp; Gey (2004)</ref>. We also used a German stopword list and a stemmer in retrieval.</p><p>Additionally, we used our blind feedback algorithm for all runs except BKGRMLGG1 to improve performance. The blind feedback algorithm assumes the top 20 documents as relevant and selects 30 terms from these documents to add to the query. Using the decompounding procedure and our blind feedback algorithm usually increases the performance anywhere between 10 and 30%.</p><p>Table <ref type="table" coords="4,97.23,632.37,5.01,8.74" target="#tab_0">1</ref> summarizes the results for the German monolingual runs. The best run was adding 5 EVM-suggested thesaurus terms and then down weighting them in retrieval. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">English Monolingual</head><p>For all runs against the English GIRT collection, an English stopword list and stemmer were used. We also used our blind feedback algorithm for all runs except BKGRMLEE1.</p><p>The best run in this series was adding one EVM-suggested thesaurus term and down weighting it in retrieval. It is still unclear how many added thesaurus terms might be best, especially since this seems to differ between the German and English collection. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">GIRT Bilingual</head><p>For GIRT bilingual retrieval, 8 runs for each language are presented, 10 of which were official runs (5 for each language). For bilingual retrieval, we compared the behavior of machine translation, thesaurus matching, EVMs (suggesting controlled vocabulary terms and substituting them with their target language equivalent) and any combination of these.</p><p>The best bilingual runs rival the monolingual runs in average precision with one German English run (BKGRBLGE1) marginally outperforming all English monolingual runs.</p><p>Last year, we compared the Systran and L &amp; H Power Translator against each other with L &amp; H alone performing better on both English German and German English translations than Systran or the combination of both. All translations of the query title and description were therefore undertaken with the L &amp; H Power Translator only.</p><p>Both machine translation (L &amp; H Power Translator) and thesaurus matching performed equally well. However, the combination of machine translation and thesaurus matching (coupling the translated title and description from machine translation and thesaurus matching and then down weighting terms that are duplicates) achieved even better results. All three runs can be compared in the first 3 column of tables 3 and 4. The combination runs were official runs (BKGRBLEG1 and BKGRBLGE1). The combined run outperforms all other runs in the German English series and is second best in the English German series.</p><p>Thesaurus matching outperforms a run composed of 5 translated thesaurus terms suggested by an EVM. This is not surprising since 5 terms or phrases seem not enough for effective retrieval. It remains to be seen whether a higher number of suggested terms could achieve comparable results or deteriorate because of increasing impreciseness of query words.</p><p>Official runs BKGRBLEG2, BKGRBLEG5, BKGRBLGE2 and BKGRBLGE5 combined machine translation provided by L &amp; H and 5 or 3 EVM-suggested thesaurus terms respectively. Runs BKGRBLEG4 and BKGRBLGE4 combined thesaurus matching and 5 EVM-suggested thesaurus terms.</p><p>The last 2 columns of tables 3 and 4 show combination runs of machine translation, thesaurus matching and EVM-suggested thesaurus terms, BKGRBLEG3 and BKGRBLGE3 were official runs.  For English to German bilingual retrieval, the combination of machine translation and suggested EVM terms marginally outperforms machine translation alone but not the combination of machine translation and thesaurus matching. The combination of thesaurus matching and EVM suggested terms performs worse than thesaurus terms alone suggesting a deteriorating effect of the added terms. The combination of all three methods doesn't achieve better results than the combination of thesaurus matching and machine translation alone. For German to English bilingual retrieval, the addition of EVM suggested thesaurus terms generally seems to deteriorate results probably by adding "noise" words to the query instead of relevant discriminative terms. Looking at the suggested EVM terms, however, doesn't yet confirm this hypothesis. Most EVM suggestions seem quite sensible. It should be interesting to find out how much a manual selection of terms could improve results and how much "wrongly" suggested thesaurus terms worsen it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Bilingual English German</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Bilingual German English</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,89.04,77.18,418.13,244.79"><head>Table 1 .</head><label>1</label><figDesc>GIRT German Monolingual</figDesc><table coords="5,89.04,77.18,418.13,232.88"><row><cell></cell><cell>BKGRMLGG0</cell><cell></cell><cell></cell><cell>BKGRMLGG2</cell><cell></cell><cell>BKGRMLGG1</cell></row><row><cell></cell><cell>document index</cell><cell></cell><cell>TD terms are</cell><cell>TD terms are</cell><cell>TD terms are</cell><cell>CV terms against</cell></row><row><cell></cell><cell>w/o thesaurus</cell><cell>baseline</cell><cell>weighted</cell><cell>weighted</cell><cell>weighted</cell><cell>separate CV</cell></row><row><cell></cell><cell>terms</cell><cell>run</cell><cell>double</cell><cell>double</cell><cell>double</cell><cell>index</cell></row><row><cell></cell><cell></cell><cell></cell><cell>TD + 1 CV</cell><cell>TD + 3 CV</cell><cell>TD + 5 CV</cell><cell>TD &amp; 3 CV</cell></row><row><cell>Recall at</cell><cell></cell><cell>TD only</cell><cell>term</cell><cell>terms</cell><cell>terms</cell><cell>terms</cell></row><row><cell>0.00</cell><cell>0.7878</cell><cell>0.7273</cell><cell>0.7442</cell><cell>0.7843</cell><cell>0.8021</cell><cell>0.7290</cell></row><row><cell>0.10</cell><cell>0.6154</cell><cell>0.6587</cell><cell>0.6436</cell><cell>0.6725</cell><cell>0.6995</cell><cell>0.6666</cell></row><row><cell>0.20</cell><cell>0.5695</cell><cell>0.6025</cell><cell>0.5995</cell><cell>0.6268</cell><cell>0.6510</cell><cell>0.6101</cell></row><row><cell>0.30</cell><cell>0.5124</cell><cell>0.5584</cell><cell>0.5557</cell><cell>0.5703</cell><cell>0.5815</cell><cell>0.5631</cell></row><row><cell>0.40</cell><cell>0.4070</cell><cell>0.5033</cell><cell>0.5021</cell><cell>0.4921</cell><cell>0.4943</cell><cell>0.5038</cell></row><row><cell>0.50</cell><cell>0.3631</cell><cell>0.4457</cell><cell>0.4418</cell><cell>0.4505</cell><cell>0.4588</cell><cell>0.4206</cell></row><row><cell>0.60</cell><cell>0.3049</cell><cell>0.3841</cell><cell>0.3714</cell><cell>0.3835</cell><cell>0.3790</cell><cell>0.3728</cell></row><row><cell>0.70</cell><cell>0.2554</cell><cell>0.3093</cell><cell>0.2924</cell><cell>0.2960</cell><cell>0.2968</cell><cell>0.2958</cell></row><row><cell>0.80</cell><cell>0.2003</cell><cell>0.2509</cell><cell>0.2360</cell><cell>0.2287</cell><cell>0.2350</cell><cell>0.2324</cell></row><row><cell>0.90</cell><cell>0.1450</cell><cell>0.1723</cell><cell>0.1640</cell><cell>0.1614</cell><cell>0.1523</cell><cell>0.1579</cell></row><row><cell>1.00</cell><cell>0.0424</cell><cell>0.0525</cell><cell>0.0500</cell><cell>0.0678</cell><cell>0.0631</cell><cell>0.0604</cell></row><row><cell>Average</cell><cell>0.3706</cell><cell>0.4150</cell><cell>0.4079</cell><cell>0.4177</cell><cell>0.4280</cell><cell>0.4102</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,208.44,725.97,178.47,8.74"><head>Table 3 .</head><label>3</label><figDesc>GIRT English German Bilingual    </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,86.94,171.63,422.99,219.03"><head>Table 4 .</head><label>4</label><figDesc>GIRT German English Bilingual</figDesc><table coords="7,86.94,171.63,422.99,206.55"><row><cell></cell><cell></cell><cell></cell><cell cols="4">BKGRBLGE1 BKGRBLGE5 BKGRBLGE2 BKGRBLGE4</cell><cell></cell><cell>BKGRBLGE3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>MT + Thes.</cell><cell>MT + Thes.</cell></row><row><cell></cell><cell></cell><cell>Thes.</cell><cell>MT + Thes.</cell><cell>MT + 3 CV</cell><cell>MT + 5 CV</cell><cell>Thes. Match +</cell><cell>Match + 3</cell><cell>Match + 5 CV</cell></row><row><cell>Recall at</cell><cell>MT</cell><cell>Match</cell><cell>Match</cell><cell>terms</cell><cell>terms</cell><cell>5 CV terms</cell><cell>CV terms</cell><cell>terms</cell></row><row><cell>0.00</cell><cell>0.6559</cell><cell>0.6326</cell><cell>0.7434</cell><cell>0.6312</cell><cell>0.6386</cell><cell>0.6348</cell><cell>0.6990</cell><cell>0.7184</cell></row><row><cell>0.10</cell><cell>0.5371</cell><cell>0.5450</cell><cell>0.6626</cell><cell>0.5184</cell><cell>0.5398</cell><cell>0.5394</cell><cell>0.5992</cell><cell>0.5957</cell></row><row><cell>0.20</cell><cell>0.4891</cell><cell>0.4843</cell><cell>0.5636</cell><cell>0.4916</cell><cell>0.4737</cell><cell>0.4894</cell><cell>0.5362</cell><cell>0.5407</cell></row><row><cell>0.30</cell><cell>0.4470</cell><cell>0.4507</cell><cell>0.5173</cell><cell>0.4567</cell><cell>0.4260</cell><cell>0.4300</cell><cell>0.4876</cell><cell>0.4875</cell></row><row><cell>0.40</cell><cell>0.4186</cell><cell>0.4120</cell><cell>0.4845</cell><cell>0.4035</cell><cell>0.3748</cell><cell>0.3948</cell><cell>0.4422</cell><cell>0.4454</cell></row><row><cell>0.50</cell><cell>0.3710</cell><cell>0.3499</cell><cell>0.4106</cell><cell>0.3691</cell><cell>0.3218</cell><cell>0.3609</cell><cell>0.3955</cell><cell>0.3903</cell></row><row><cell>0.60</cell><cell>0.3047</cell><cell>0.3096</cell><cell>0.3675</cell><cell>0.3095</cell><cell>0.2733</cell><cell>0.3172</cell><cell>0.3325</cell><cell>0.3200</cell></row><row><cell>0.70</cell><cell>0.2423</cell><cell>0.2534</cell><cell>0.3074</cell><cell>0.2533</cell><cell>0.2156</cell><cell>0.2471</cell><cell>0.2889</cell><cell>0.2618</cell></row><row><cell>0.80</cell><cell>0.2060</cell><cell>0.1915</cell><cell>0.2421</cell><cell>0.1959</cell><cell>0.1280</cell><cell>0.1868</cell><cell>0.2322</cell><cell>0.2178</cell></row><row><cell>0.90</cell><cell>0.1368</cell><cell>0.1169</cell><cell>0.1835</cell><cell>0.1468</cell><cell>0.0818</cell><cell>0.1083</cell><cell>0.1684</cell><cell>0.1499</cell></row><row><cell>1.00</cell><cell>0.0250</cell><cell>0.0498</cell><cell>0.0762</cell><cell>0.0442</cell><cell>0.0203</cell><cell>0.0280</cell><cell>0.0775</cell><cell>0.0446</cell></row><row><cell cols="2">Average 0.3431</cell><cell>0.3370</cell><cell>0.4053</cell><cell>0.3370</cell><cell>0.3054</cell><cell>0.3340</cell><cell>0.3748</cell><cell>0.3668</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,70.92,501.57,453.44,8.74;7,70.92,513.03,440.90,8.74" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="7,207.02,501.57,317.35,8.74;7,70.92,513.03,226.16,8.74">Multilingual Information Retrieval Using Machine Translation, Relevance Feedback and Decompounding In: Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Gey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004-01">2004. Jan. -Apr. 2004</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="149" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.92,536.01,453.48,8.74;7,70.92,547.53,453.54,8.74;7,70.92,559.05,51.20,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,246.82,536.01,277.58,8.74;7,70.92,547.53,108.14,8.74">Full text retrieval based on probabilistic equations with coefficients fitted by logistic regression</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,281.46,547.53,197.30,8.74">The Second Text Retrieval Conference (TREC-2)</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1994-03">1994. March 1994</date>
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.92,582.03,453.52,8.74;7,70.92,594.69,245.10,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,158.21,582.03,220.45,8.74">Advanced Search Technology for Unfamiliar Metadata</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,399.83,582.03,124.61,8.74;7,70.92,594.69,83.91,8.74">Proceedings of the Third IEEE Metadata Conference</title>
		<meeting>the Third IEEE Metadata Conference<address><addrLine>Bethesda, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-04">1999. April 1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.92,621.81,453.56,8.74;7,70.92,633.33,439.14,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,253.54,621.81,270.95,8.74;7,70.92,633.33,106.04,8.74">UC Berkeley at CLEF-2003 -Russian Language Experiments and Domain-Specific Retrieval</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Petras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,197.03,633.33,165.48,8.74">Proceedings of the CLEF 2003 Workshop</title>
		<meeting>the CLEF 2003 Workshop</meeting>
		<imprint>
			<publisher>Springer Computer Science Series</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.92,656.31,453.52,8.74;7,70.92,667.83,411.95,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,250.76,656.31,273.68,8.74;7,70.92,667.83,78.75,8.74">Using Thesauri in Cross-Language Retrieval of German and French Indexed Collections</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Petras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,169.77,667.83,165.68,8.74">Proceedings of the CLEF 2002 Workshop</title>
		<meeting>the CLEF 2002 Workshop</meeting>
		<imprint>
			<publisher>Springer Computer Science Series</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.92,690.81,453.52,8.74;7,70.92,703.47,406.58,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,231.34,690.81,293.11,8.74;7,70.92,703.47,44.71,8.74">An Association-Based Method for Automatic Indexing with Controlled Vocabulary</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Plaunt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">A</forename><surname>Norgard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,122.64,703.47,227.52,8.74">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="888" to="902" />
			<date type="published" when="1998">1998. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.92,730.65,453.59,8.74;7,70.92,742.11,229.16,8.74" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="7,151.19,730.65,141.34,8.74">Thesaurus for the Social Sciences</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schott</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000. 2000</date>
			<publisher>Informations-Zentrum Sozialwissenschaften Bonn</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>German-English. English-German</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
