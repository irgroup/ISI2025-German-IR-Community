<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,103.12,148.86,396.77,15.15;1,236.10,170.78,130.82,15.15">CLEF 2004 Cross-Language Spoken Document Retrieval Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,133.70,204.67,76.85,8.74"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ITC-irst</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,221.11,204.67,66.03,8.74"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
							<email>bertoldi@itc.it</email>
							<affiliation key="aff0">
								<orgName type="institution">ITC-irst</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,297.69,204.67,78.25,8.74"><forename type="first">Gina-Anne</forename><surname>Levow</surname></persName>
							<email>levow@cs.uchicago.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Chicago</orgName>
								<address>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,386.50,204.67,78.33,8.74"><forename type="first">Gareth</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
							<email>gareth.jones@computing.dcu.ie</email>
							<affiliation key="aff2">
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,103.12,148.86,396.77,15.15;1,236.10,170.78,130.82,15.15">CLEF 2004 Cross-Language Spoken Document Retrieval Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">14120D48C05851AC75289E78387AFF89</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is a summary report about the Cross-Language Spoken Document Retrieval Track held at CLEF 2004. The report gives brief details of CL-SDR task based again this year on the TREC 8-9 SDR task. This year the CL-SDR task worked with an unknown story boundaries condition. The paper reports results from the participants showing that as expected cross-language results are reduced relative to a monolingual baseline, although the amount to which they are degraded varies for topic languages.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Cross Language Spoken Document Retrieval (CL-SDR) track aims to evaluate CLIR systems on noisy automatic transcripts of spoken documents. The CLEF 2004 CL-SDR track relies once again on data prepared by NIST for the TREC 8-9 SDR tracks <ref type="bibr" coords="1,364.10,445.87,9.96,8.74" target="#b0">[1]</ref>. In particular, the task consists of retrieving news stories within a repository of about 550 hours of American English news. The original English short queries were manually formulated in other languages, e.g. French or German, for CL-SDR. Retrieval is performed on automatic transcriptions made available by NIST, and generated by different speech recognition systems.</p><p>As a difference with respect to last year's task <ref type="bibr" coords="1,318.25,505.64,9.96,8.74" target="#b1">[2]</ref>, systems could not rely on known storyboundaries within the shows, an unknown story boundary condition. Whereas previously the transcription was manually divided into individual story units, participants were this year provided onto with the unsegmented transcript. Hence, for each query, systems had to produce a ranked list of relevant stories, based on identifying a complete news show and a time index within the news show. In this way, relevance is assessed by checking if the provided time indexes fall inside the manually judged relevant stories. According to the NIST evaluation protocol, systems generating results corresponding to the very same stories are penalized. In fact, successive time indexes falling in the same story are marked as non relevant results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Specifications</head><p>The target collection consists of 557 hours of American-English news recordings broadcast by: ABC, CNN, Public Radio International (PRI), and Voice of America (VOA) between February and June 1998. Spoken documents are accessible through automatic transcriptions produced by NIST and other sites, which participated in the TREC 9 SDR track. Transcripts are provided with and without story boundaries, for a total of 21,754 stories. For the application of blind relevance feedback, participants are allowed to use parallel document collections available through the Linguistic Data Consortium.</p><p>Queries are based on a collection of 100 English topics in short format for which relevance assessments are available. For the sake of CLIR, queries were translated by native speakers into Dutch, Italian, French, German, and Spanish. Retrieval scoring software is available both for the known and unknown story boundary conditions.</p><p>Of the available 100 topics, the first 50 (topic 074 to topic 123) were intended for system development, while the latter 50 (topic 124 to topic 173) for testing. Submission format and evaluation criteria followed the same conventions as the 2000 TREC-9 SDR track <ref type="foot" coords="2,445.31,182.18,3.97,6.12" target="#foot_0">1</ref> .</p><p>The following evaluation conditions were specified:</p><p>• Primary Conditions (mandatory for all participants):</p><p>-Monolingual IR on NIST transcripts, no parallel data.</p><p>-Bilingual IR from French/German on NIST transcripts, no parallel data.</p><p>• Secondary Conditions (optional):</p><p>-Bilingual IR from French/German, on NIST transcripts, with parallel data.</p><p>-Bilingual IR from any language, all transcripts,with parallel data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Participants</head><p>Two sites participated in the evaluation: University of Chicago (USA) and ITC-irst (Italy). A brief description of each system is provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">CL-SDR System by U. Chicago</head><p>The University of Chicago participated in the CLEF 2004 spoken document retrieval task. Runs were submitted for both the baseline English monolingual task and the French-English crosslanguage task, using only the resources provided by CLEF with no external resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Query Processing</head><p>Query processing aimed to enhance retrieval of the potentially errorful ASR transcriptions through pseudo-relevance feedback expansion. The baseline conditions required the use of only the CLEF provided resources. This restriction limited our source of relevance feedback to the ASR transcriptions, segmented as described below. For both the monolingual English and the English translations of the original French queries, we performed the same enrichment process. We employed the INQUERY API to identify enriching terms based on the top 10 ranked retrieved segments and integrated these terms with the original query forms. Our hope was that this enrichment process would capture both additional on-topic terminology as well as ASR-specific transcriptions.</p><p>For the French-English cross-language condition, we performed dictionary-based term-by-term translation, as described in <ref type="bibr" coords="2,209.05,566.22,9.96,8.74" target="#b2">[3]</ref>. We employed a freely available bilingual term list (www.freedict. com). After identifying translatable multi-word units based on greedy longest match in the term list, we used a stemming backoff translation approach with statistically derived stemming rules <ref type="bibr" coords="2,497.96,590.13,11.28,8.74" target="#b3">[4]</ref>, matching surface forms first and backing off to stemmed form if no surface match was found. All translation alternatives were integrated through structured query formulation <ref type="bibr" coords="2,424.90,614.04,12.74,8.74" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Spoken Document Processing</head><p>This year the SDR track focused on the processing of news broadcasts with unknown story boundaries. This formulation required that sites perform some automatic segmentation of the full broadcasts into smaller units suitable for retrieval. Using an approach inspired by <ref type="bibr" coords="2,435.78,681.64,9.96,8.74" target="#b5">[6]</ref>, we performed story segmentation as follows. First we created 30 second segments based on the word recognition time stamps using a 10 second step to create overlapping segment windows. These units were then indexed using the INQUERY retrieval system version 3.1p1 with both stemming and standard stopword removal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Retrieval Segment Construction</head><p>To produce suitable retrieval segments, we merged the fine-grained segments returned by the base retrieval process on a per-query basis. For each query, we retrieved 5000 fine-grained segment windows. We then stepped through the ranked retrieval list merging overlapping segments, assigning the rank of the higher ranked segment to the newly merged segment. We cycled through the ranked list until convergence. The top ranked 1000 documents formed the final ranked retrieval results submitted for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">CL-SDR System by ITC-irst</head><p>The ITC-irst system is based on the following three processing steps.</p><p>First, a collection of news segments is automatically created from the continuous stream of transcripts. Text segments are produced with a shifting time-window of 30 seconds, moved with steps of 10 seconds. Moreover, segments are also truncated if a silence period longer than 5 seconds is found.</p><p>Second, the resulting overlapping texts are used as target document collection by means of a text CLIR system <ref type="bibr" coords="3,171.48,308.19,9.96,8.74" target="#b7">[8]</ref>.</p><p>Third, entries in the ranking list which correspond to overlapping segments are properly merged.</p><p>The implemented method works as follows. All retrieved segments of the same news show are sorted by their start time. The first retrieved segment is assumed as the beginning of a new story. If the second segment overlaps with the first, the two are merged, and the time extent of the current story is adjusted, and so on. If a following segment does not overlap with the current story, the current story is saved in a stack, and a new story begins. Finally, for all stories in the stack, only the segments with the highest retrieval score are considered. The process is repeated for all news show files, with at least one entry in the rank list. The resulting list of non overlapping segments is then sorted according to the original retrieval score. The results in Table <ref type="table" coords="3,194.83,633.44,4.98,8.74" target="#tab_0">1</ref> show that, particularly in the primary condition, there is a considerable loss in retrieval effectiveness for cross-language relative to monolingual retrieval. This reduction in average precision varies between about 40% and 60%. These figures are larger than those observed for the known story boundary test condition in the CLEF 2003 CL-SDR task <ref type="bibr" coords="3,438.01,669.30,9.97,8.74" target="#b1">[2]</ref>. One possible explanation is the small size of the document segments used for the unknown story boundary condition. The combination errorfully short topic statements with the inaccurately transcribed document segments may be responsible for this effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Site</head><p>As we would expect the use of additional data resources produces an improvement in absolute retrieval performance figures in all cases, although the relative cross language reduction is still very large for all conditions except for Spanish topic translation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,168.46,491.28,266.09,115.08"><head>Table 1 :</head><label>1</label><figDesc>Mean average precision statistics of submitted runs.</figDesc><table coords="3,192.13,491.28,218.74,93.22"><row><cell></cell><cell>Source</cell><cell cols="2">Primary Secondary</cell></row><row><cell>ITC-irst</cell><cell>Monolingual</cell><cell>.3059</cell><cell>.3586</cell></row><row><cell></cell><cell>French</cell><cell>.1816</cell><cell>.2330</cell></row><row><cell></cell><cell>German</cell><cell>.1584</cell><cell>.2051</cell></row><row><cell></cell><cell>Italian</cell><cell></cell><cell>.2510</cell></row><row><cell></cell><cell>Spanish</cell><cell></cell><cell>.2990</cell></row><row><cell cols="2">U. Chicago Monolingual</cell><cell>.2963</cell><cell>-</cell></row><row><cell></cell><cell>French</cell><cell>.1084</cell><cell>-</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.24,747.01,254.52,7.21"><p>See http://www.nist.gov/speech/tests/sdr/sdr2000/sdr2000.htm.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,105.50,133.84,407.50,8.74;4,105.50,145.80,407.50,8.74;4,105.50,157.75,245.78,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,359.77,133.84,153.23,8.74;4,105.50,145.80,131.44,8.74">The TREC Spoken Document Retrieval Track: A Success Story</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Garafolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">G P</forename><surname>Auzanne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,258.40,145.80,254.60,8.74;4,105.50,157.75,134.05,8.74">Proceedings of the RIAO 2000 Conference: Content-Based Multimedia Information Access</title>
		<meeting>the RIAO 2000 Conference: Content-Based Multimedia Information Access<address><addrLine>Paris</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,177.68,407.50,8.74;4,105.50,189.63,407.51,8.74;4,105.50,201.59,292.96,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,246.64,177.68,266.36,8.74;4,105.50,189.63,22.86,8.74">The CLEF 2003 Cross-Language Spoken Document Retrieval Track</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,152.34,189.63,356.13,8.74">Proceedings of Workshop of the Cross-Language Evaluation Forum (CLEF 2003)</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting>Workshop of the Cross-Language Evaluation Forum (CLEF 2003)<address><addrLine>Trondheim, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,221.51,407.50,8.74;4,105.50,233.47,284.07,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,297.26,221.51,215.74,8.74;4,105.50,233.47,92.58,8.74">Dictionary-Based Techniques for Cross-Language Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">G.-A</forename><surname>Levow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,206.69,233.47,177.49,8.74">Information Processing and Management</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,253.39,407.50,8.74;4,105.50,265.35,407.50,8.74;4,105.50,277.30,407.49,8.74;4,105.50,289.26,135.69,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,293.47,253.39,219.52,8.74;4,105.50,265.35,245.87,8.74">CLEF Experiments at the University of Maryland: Statistical Stemming and Backoff Translation Strategies</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G.-A</forename><surname>Levow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cabezas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,374.58,265.35,138.42,8.74;4,105.50,277.30,214.58,8.74">Proceedings of Workshop of the Cross-Language Evaluation Forum (CLEF 2000)</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting>Workshop of the Cross-Language Evaluation Forum (CLEF 2000)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="176" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,309.18,407.50,8.74;4,105.50,321.14,407.50,8.74;4,105.50,333.09,407.50,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,157.08,309.18,355.92,8.74;4,105.50,321.14,136.80,8.74">The Fffects of Query Structure and Dictionary Setups in Dictionary-Based Cross-Language Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pirkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,262.38,321.14,250.62,8.74;4,105.50,333.09,291.90,8.74">Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="55" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,353.02,407.50,8.74;4,105.50,364.97,407.51,8.74;4,105.50,376.93,407.51,8.74;4,105.50,388.88,22.70,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,333.57,353.02,179.43,8.74;4,105.50,364.97,107.03,8.74">Retrieval Of Broadcast News Documents With the THISL System</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Abberley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Renals</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,236.35,364.97,276.65,8.74;4,105.50,376.93,7.96,8.74">Proceedings of the Seventh Text REtrieval Conference (TREC-7)</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Harman Editors</surname></persName>
		</editor>
		<meeting>the Seventh Text REtrieval Conference (TREC-7)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="500" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,408.81,407.50,8.74;4,105.50,420.77,407.50,8.74;4,105.50,432.72,123.48,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,301.97,408.81,141.01,8.74">The INQUERY Retrieval System</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Harding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,463.34,408.81,49.66,8.74;4,105.50,420.77,378.30,8.74">Proceedings of the Third International Conference on Database and Expert Systems Applications</title>
		<meeting>the Third International Conference on Database and Expert Systems Applications</meeting>
		<imprint>
			<publisher>Spinger Verlag</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="78" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,452.65,407.51,8.74;4,105.50,464.60,216.01,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,241.00,452.65,272.01,8.74;4,105.50,464.60,37.76,8.74">Statistical Models for Monolingual and Bilingual Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,151.87,464.60,92.98,8.74">Information Retrieval</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="51" to="70" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
