<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,140.56,71.25,325.61,15.54">Linguistic and Statistical Analysis of the CLEF Topics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,222.16,110.17,58.35,11.03"><forename type="first">Thomas</forename><surname>Mandl</surname></persName>
							<email>mandl@rz.uni-hildesheim.de</email>
							<affiliation key="aff0">
								<orgName type="department">Information Science</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<addrLine>Marienburger Platz 22</addrLine>
									<postCode>D-31141</postCode>
									<settlement>Hildesheim</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,287.82,110.17,96.96,11.03"><forename type="first">Christa</forename><surname>Womser-Hacker</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Science</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<addrLine>Marienburger Platz 22</addrLine>
									<postCode>D-31141</postCode>
									<settlement>Hildesheim</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,140.56,71.25,325.61,15.54">Linguistic and Statistical Analysis of the CLEF Topics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D74A22D4D18173176B4BF5D6226C0780</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports on an analysis of the CLEF topics from the year 2001. We investigated especially potential correlations between features of the topics and the performance of retrieval systems. Although there are some weak relations, we can claim as a result, that the properties of the CLEF topics do not introduce any bias for the results of the retrieval systems. We found one correlation for the English topics. The more linguistic challenges the topic texts included, the better the performance of the systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The effort in large scale evaluation studies can only be justified when the results are valid and can serve as a measure for the performance of the systems in real environments. One critical question has been the reliability of the assessors` relevance judgements. Reservations about the individuality of these assessments have been discussed widely. One study showed that the judgements between different jurors are in fact different. However, TREC and equally CLEF are comparison studies which aim at presenting a ranked list of systems. The absolute numbers of the performance values are not meant to exactly represent the quality of the systems. The study which assigned documents to several human relevance assessors showed the absolute numbers of the recall precision values are indeed affected by different judgements. However, the overall ranking of the systems does not change <ref type="bibr" coords="1,116.84,391.92,61.42,11.03" target="#b6">(Voorhees 1998</ref>). In research on information retrieval evaluation, it has been pointed out, that "the quality of requests (and hence queries) appears very important" (Sparck <ref type="bibr" coords="1,248.10,414.84,48.19,11.03" target="#b5">Jones 1995)</ref>. In CLEF, there might be a higher uncertainty about assessment done by different people for the same topic as well as about a bias free translation of the topics. The topic creation for a multilingual environment requires especial care in order to avoid cultural aspects to influence the meaning <ref type="bibr" coords="1,165.86,449.40,134.51,11.03" target="#b1">(Kluck &amp; Womser-Hacker 2002)</ref>. A thorough translation check of all translated topics was introduced in CLEF to assure that the translators who are only aware of two language versions of the topics do not omit or add any thematic aspects accidentally <ref type="bibr" coords="1,282.75,472.44,93.12,11.03" target="#b10">(Womser-Hacker 2002)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Topics in Information Retrieval Evaluation</head><p>The topics in information retrieval evaluation should express an information need. The topics are always formulated in natural language. In a real usage scenario, the information need is a state of mind. As a consequence, the transformation of the information need to the query is not tested in evaluation initiatives. The systems are confronted with a natural language formulation approximating the information need. The creation of appropriate topics or queries for testing systems has been a major concern in the research on the evaluation of information retrieval. In one of the first studies which were based on the Cranfield collection, the queries led to considerable objections against the validity of the results. The queries were derived from the documents and basically each pointed to one document (cf. Womser-Hacker 1997). TREC and subsequently CLEF have devoted considerable effort toward topic generation. TREC has seen a shift from elaborated topics to more and more shorter topics between <ref type="bibr" coords="1,334.65,641.16,185.54,11.03">TREC-3 and TREC-4 (cf. Sparck Jones 1994)</ref>. This may have been a result of the web reality where information retrieval systems have been available mostly for free and have been widely used and where the queries are usually very short. In the web-track, only a few words are used as the actual topic while the narrative is only used for the assessment (cf. <ref type="bibr" coords="1,425.74,675.72,60.22,11.03">Hawking 2002)</ref>. Retrieval systems can be optimized for short queries by relying more on term expansion techniques <ref type="bibr" coords="1,485.81,687.12,38.78,11.03;1,70.96,698.64,45.26,11.03" target="#b2">(Kwok &amp; Chan 1998)</ref>. Even proper similarity calculation functions have been developed for short queries (cf. <ref type="bibr" coords="1,473.29,698.64,51.24,11.03;1,70.96,710.16,29.56,11.03" target="#b8">Wilkinson et al. 1995</ref>). An investigation on TREC-1 topics has come to the conclusion that the topics are lexically distant from the relevant documents <ref type="bibr" coords="1,157.05,733.20,110.66,11.03" target="#b3">(Rorvig &amp; Fitzpatri 1998)</ref>. All judged documents for a topic were plotted in a two dimensional display in a way that the similarities from a similarity matrix were expressed by their distances as far as possible. Multidimensional scaling was used in this study. The relevant documents lied closer to each other and appeared denser than the non relevant documents. However, when the topics was plotted in the same display, it usually had a relatively large distance from the relevant clusters. It can be concluded that relevance judgements require more than simply counting appearances of words. However, the relevant documents exhibit some formally detectable similarities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Topics of CLEF 2001</head><p>As in previous years, the topics in CLEF 2001 have not been constructed e.g. from documents. Rather, they have been created in a natural way in order to closely resemble potential information needs. This research has been mainly directed toward the following questions:</p><p>• What are the important and typical characteristics of the CLEF topics?</p><p>• Do these features have any influence on the quality of the retrieval results?</p><p>• May this knowledge be exploited for the development of retrieval systems?</p><p>• Should the design of the CLEF topics be altered to eliminate a potential bias for the systems? For example, when looking at run EIT01M3N in the CLEF 2001 campaign, we see that it has a fairly good average precision of 0.341. However, for topic 44, which had an average difficulty, this run performs far below (0.07) the average for that topic (0.27). An intellectual analysis of the topics revealed that two of the most difficult topics contained no proper names and were both about sports (Topic 51 and 54). In more detail, we want to find out whether there are linguistic characteristics of the CLEF topics which may hint toward a better or worse performance of the systems. The rationale for this assumption lies in the retrieval systems. From the literature it is well known that system developers invest great effort in the language processing capabilities. As a result, topics with more linguistic challenges may pose problems for some systems.</p><p>In this context, it may be interesting to look at systems which perform well and demonstrate weaknesses for topics which are generally solved with good quality (or vice versa). Such an analysis seems to be especially interesting because the deviation between topics is larger than between systems and runs as the following table shows. Some features of the topics may have a higher influence on the result than the retrieval systems parameters. This phenomena is well known from TREC (cf. Womser-Hacker 1997).  <ref type="table" coords="2,97.00,575.17,4.98,11.03" target="#tab_0">1</ref> shows that the average of all systems does surprisingly neither differ much form the average of all runs with English as topic language nor from all runs with German. For further analysis we can consider the performance for the topics (all systems for one topic) and the performance of the systems (one system for all topics). In this case the deviation for topics is higher (&gt;0.14) than the deviation for the systems (&lt;0.12) regardless of whether we consider only English topics, German topics or all languages. However, there do not seem to be overall easy topics nor overall superior runs. The correlation between the average precision and the deviation for a topic over all runs is 0.83. That means, the better a topic is solved in average, the higher is the deviation of systems for that topic. Not all systems have achieved a similar quality of these easier topics. The same is true for runs. The average precision and the deviation for a run over all topics correlate with 0.84. We could draw the conclusion that no run performs well on all topics. In contrary, the better a run performed overall, the higher are the differences between its performance for single topics. We assume that linguistic phenomena like morphological modifications, abbreviations or proper names pose challenges to the retrieval systems which they might handle with different approaches and consequently different quality. For example, a system performing generally very well may have difficulties when being confronted with topics containing abbreviations and numbers. In such a case, these difficult queries could be handled by another system because they can be easily recognized automatically. We carried out an intellectual analysis of the topics during which we assessed the values for the properties in the following table. For some of the features, types as well as tokens were assessed. At first, we looked at the relation between topic features and the average precision of all runs for that topic without considering the systems properties. The overall quality of the run was measured with the following properties:</p><p>• Average precision (non-interpolated) for all relevant documents • Precision at 5 documents • For some analysis the runs were grouped into five buckets The correlation calculation between linguistic phenomena and average precision of all runs revealed the following. The only properties that had a correlation higher than 0.2 or lower than -0.2 for the number of phenomena and the precision were proper names. This indicates that the existence of proper names in the topic and consequently in the query makes a topic easier. Maybe proper names have a low frequency in the corpus and the same is true for other low frequency terms.  The sum of all linguistic phenomena also has a positive but lower correlation with the precision. However, if we consider the bucket analysis where the runs are grouped in five buckets, the correlation reaches 0.96 for the English topics. Each bucket contains 20% of all runs. Bucket one the worst runs and so forth. The relation can be seen in figure <ref type="figure" coords="4,131.10,169.92,3.76,11.03" target="#fig_0">1</ref>. The reported relations are not statistically significant since only 50 topics and 70 runs were analyzed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Topics and Runs of CLEF 2001</head><p>The global analysis of topics and runs needs to be refined by a more detailed inspection on the relation between topic and run properties. To allow such a investigation, some properties of the runs were also considered in the analysis. They can be found in the CLEF proceedings:</p><p>• Multi or bilingual run • Topic language • Used topic fields (title, description, narrative)</p><p>• Used for the pool or not As a target of a machine learning model, we used the average precision of the run for the topic in question. The basic data model is shown in figure <ref type="figure" coords="4,214.23,558.37,3.75,11.03" target="#fig_2">2</ref>. A statistical analysis was not carried out beforehand, because there is relatively little evidence for a statistical analysis. There were only 600 combinations of runs and German topics and 900 for English topics. As a consequence, we first used machine learning methods to find out whether a formal model can be built which established any relations between topic properties and system performance. If any relations were to be detected, subsequent statistical analysis could have been applied. We used the Waikato Environment for Knowledge Analysis (WEKA 1 ) which allows the testing of many machine learning algorithms within the same framework. WEKA is implemented in JAVA and is provided as open source software.</p><p>Neither the German nor the English training data resulted in a satisfying model. This was true for linear algorithms like Naive Bayes as well as for non linear models like neural networks. That means, the existing data cannot be used to build any predictive model to map from system and topic properties to the quality of the run measured by the average precision. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>works on creates</head><p>The investigations reported in this article have found no bias in the topics of the CLEF campaign. As a result, no reservations toward the validity of the results arise from this research. At this point, the topics of the 2002 campaign are evaluated. Further languages should also be included in the analysis. Furthermore, the features of the topics of 2002 are assessed once again. The assessment requires human judgement and therefore, we want to eliminate possible individual bias. Additional machine assessable properties like sentence complexity and part of speech frequency analysis are also considered. Domain specific words may also be worth an analysis. Another interesting question could be the comparison of topics with similar difficulty. Are these indeed similar topics? In other areas of TREC and CLEF, topics properties and tuning system toward them might play an even more crucial role. In the web track, two different types of topics have been developed. In addition to the topical searches adopted from the ad hoc track, homepage finding has been defined as a task. In multimedia retrieval, the topic creation gets more difficult. For example, the video track in TREC comprises several dimensions of topic properties. Topics are characterized formally by the multimedia elements contained. In addition to the mandatory text description, topics may embrace graphic, video or audio files. Furthermore, the topics content is much more diverse than for text retrieval. Their semantics differs greatly. Some demand video with certain graphical features, other require objects, other aim at certain persons during an activity <ref type="bibr" coords="5,419.63,271.32,84.15,11.03" target="#b4">(Smeaton et al. 2002)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,113.20,643.82,368.97,9.96"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Relation between sum of number of linguistic phenomena and the runs' performance bucket</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,207.28,530.54,180.97,9.96"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Data model for topics, systems and runs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,70.96,450.14,397.10,136.05"><head>Table 1 .</head><label>1</label><figDesc>Overall statistics of average precision</figDesc><table coords="2,70.96,468.37,397.10,117.83"><row><cell></cell><cell>Average</cell><cell cols="3">Std. Deviation Maximum Mininum</cell></row><row><cell>All Runs</cell><cell>0.273</cell><cell>0.111</cell><cell>0.450</cell><cell>0.013</cell></row><row><cell>Topics over all languages</cell><cell>0.273</cell><cell>0.144</cell><cell>0.576</cell><cell>0.018</cell></row><row><cell>English Runs</cell><cell>0.263</cell><cell>0.074</cell><cell>0.373</cell><cell>0.104</cell></row><row><cell>English Topics</cell><cell>0.263</cell><cell>0.142</cell><cell>0.544</cell><cell>0.018</cell></row><row><cell>German Runs</cell><cell>0.263</cell><cell>0.092</cell><cell>0.390</cell><cell>0.095</cell></row><row><cell>German Topics</cell><cell>0.263</cell><cell>0.142</cell><cell>0.612</cell><cell>0.005</cell></row><row><cell>Table</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,124.12,140.54,286.92,150.79"><head>Table 2 .</head><label>2</label><figDesc>Topic Properties</figDesc><table coords="3,124.12,157.33,286.92,134.00"><row><cell>German topics:</cell><cell>English topics:</cell></row><row><cell>• original topic language</cell><cell>• original topic language</cell></row><row><cell>• length</cell><cell>• length</cell></row><row><cell>• compound words</cell><cell>• abbreviations</cell></row><row><cell>• abbreviations</cell><cell>• nominal phrases</cell></row><row><cell>• nominal phrases</cell><cell>• proper names</cell></row><row><cell>• proper names</cell><cell>• negations</cell></row><row><cell>• negations</cell><cell>• subordinate clauses</cell></row><row><cell>• subordinate clauses</cell><cell>• foreign words</cell></row><row><cell>• foreign words</cell><cell>• parenthesis</cell></row><row><cell>• numbers or dates</cell><cell>• numbers of dates</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,150.28,71.06,296.52,51.81"><head>Table 3 .</head><label>3</label><figDesc>Correlation between number of proper names and precision</figDesc><table coords="4,150.28,87.85,296.52,35.03"><row><cell></cell><cell>Types</cell><cell>Tokens</cell><cell>Sum of all linguistic phenomena</cell></row><row><cell>English</cell><cell>0.446</cell><cell>0.473</cell><cell>0.293</cell></row><row><cell>German</cell><cell>0.440</cell><cell>0.464</cell><cell>0.286</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,70.96,336.61,453.61,11.03;5,82.36,348.13,22.61,11.03" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="5,244.54,336.61,169.87,11.03">Overview of the TREC-2001 Web Track</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">;</forename><surname>Hawking</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<publisher>Voorhees &amp; Harman</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.96,359.64,453.58,11.03;5,82.36,371.05,442.27,11.03;5,82.36,382.56,4.98,11.03;5,87.40,381.11,5.40,7.17;5,95.32,382.57,339.98,11.03" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,291.52,359.64,233.03,11.03;5,82.36,371.05,423.97,11.03">Inside the Evaluation Process of the Cross-Language Evaluation Forum (CLEF): Issues of Multilingual Topic Creation and Multilingual Relevance Assessment</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><forename type="middle">;</forename><surname>Kluck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christa</forename><surname>Womser-Hacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,82.36,382.56,4.98,11.03;5,87.40,381.11,5.40,7.17;5,95.32,382.57,257.62,11.03">3 rd International Conference on Language Resources and Evaluation</title>
		<meeting><address><addrLine>Las Palmas, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.96,394.09,453.64,11.03;5,82.36,405.60,24.90,11.03;5,107.32,404.15,4.32,7.17;5,114.40,405.61,410.22,11.03;5,82.36,417.13,150.86,11.03" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,204.32,394.09,237.39,11.03">Improving Two-Stage Ad-Hoc Retrieval for Short Queries</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,463.95,394.09,60.64,11.03;5,82.36,405.60,24.90,11.03;5,107.32,404.15,4.32,7.17;5,114.40,405.61,410.22,11.03;5,82.36,417.13,48.41,11.03">Proceedings of the 21 st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ´98)</title>
		<meeting>the 21 st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ´98)<address><addrLine>Melbourne</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="250" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.96,428.64,453.63,11.03;5,82.36,440.05,250.75,11.03" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,249.59,428.64,253.99,11.03">Visualization and Scaling of TREC Topic Document Sets</title>
		<author>
			<persName coords=""><forename type="first">Mark</forename><forename type="middle">;</forename><surname>Rorvig</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Fitzpatri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,82.36,440.05,164.41,11.03">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="135" to="149" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.96,451.56,453.61,11.03;5,82.36,463.08,57.03,11.03" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="5,296.63,451.56,154.37,11.03">The TREC-2001 Video Track Report</title>
		<author>
			<persName coords=""><forename type="first">Alan</forename><forename type="middle">;</forename><surname>Smeaton</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Over</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ramazan</forename><surname>Paul; Taban</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2002. 2001</date>
			<publisher>Voorhees &amp; Harman</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.96,474.60,453.69,11.03;5,82.36,486.12,20.10,11.03" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,191.77,474.60,84.90,11.03">Reflections on TREC</title>
		<author>
			<persName coords=""><forename type="first">Sparck</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karen</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,300.56,474.60,160.88,11.03">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="291" to="314" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.96,497.64,453.63,11.03;5,82.36,509.04,93.67,11.03;5,176.08,507.59,4.32,7.17;5,185.20,509.05,339.46,11.03;5,82.36,520.57,239.80,11.03" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,173.41,497.64,332.63,11.03">Variations in relevance judgments and the measurement of retrieval effectiveness</title>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,82.36,509.04,93.67,11.03;5,176.08,507.59,4.32,7.17;5,185.20,509.05,339.46,11.03;5,82.36,520.57,137.36,11.03">Proceedings of the 21 st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ´98)</title>
		<meeting>the 21 st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ´98)<address><addrLine>Melbourne</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="315" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.96,532.08,453.55,11.03;5,82.36,543.60,342.81,11.03;5,82.36,555.12,97.35,11.03" xml:id="b7">
	<monogr>
		<ptr target="http://trec.nist.gov/pubs/" />
		<title level="m" coord="5,264.85,532.08,197.29,11.03">The Tenth Text Retrieval Conference (TREC-10)</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">;</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">NIST Special Publication</note>
</biblStruct>

<biblStruct coords="5,70.96,566.64,453.53,11.03;5,82.36,578.04,442.18,11.03;5,82.36,589.56,320.24,11.03" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,312.87,566.64,154.74,11.03">Similarity Measures for Short Queries</title>
		<author>
			<persName coords=""><forename type="first">Ross</forename><forename type="middle">;</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Justin</forename><forename type="middle">;</forename><surname>Zobel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ron</forename><surname>Sacks-Davis</surname></persName>
		</author>
		<ptr target="http://trec.nist.gov/pubs/" />
	</analytic>
	<monogr>
		<title level="m" coord="5,136.13,578.04,200.17,11.03">The Fourth Text REtrieval Conference (TREC-4)</title>
		<editor>
			<persName><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>NIST Special Publication</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.96,601.08,453.69,11.03;5,82.36,612.60,442.40,11.03;5,82.36,624.12,52.91,11.03" xml:id="b9">
	<analytic>
		<author>
			<persName coords=""><forename type="first">Christa</forename><surname>Womser-Hacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,215.44,601.08,309.21,11.03;5,82.36,612.60,194.67,11.03">Das MIMOR-Modell. Mehrfachindexierung zur dynamischen Methoden-Objekt-Relationierung im Information Retrieval</title>
		<title level="s" coord="5,470.16,612.60,54.60,11.03;5,82.36,624.12,48.84,11.03">Informationswissenschaft</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>Universität Regensburg</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Habilitationsschrift</note>
</biblStruct>

<biblStruct coords="5,70.96,635.52,453.54,11.03;5,82.36,647.04,442.30,11.03;5,82.36,658.56,221.86,11.03" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,206.03,635.52,267.53,11.03">Multilingual Topic Generation within the CLEF 2001 Experiments</title>
		<author>
			<persName coords=""><forename type="first">Christa</forename><surname>Womser-Hacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,350.81,647.04,173.84,11.03;5,82.36,658.56,69.88,11.03">Evaluation of Cross-Language Information Retrieval Systems</title>
		<editor>
			<persName><forename type="first">Carol</forename><forename type="middle">;</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><forename type="middle">;</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><forename type="middle">;</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Kluck</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2406</biblScope>
			<biblScope unit="page" from="389" to="393" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
