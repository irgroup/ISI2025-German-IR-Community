<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,108.30,148.86,386.41,15.15">Some Experiments with the Dutch Collection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,185.29,182.75,74.69,8.74"><forename type="first">Arjen</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">CWI Amsterdam</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,326.37,182.75,63.79,8.74"><forename type="first">Anne</forename><surname>Diekema</surname></persName>
							<email>diekemar@syr.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Syracuse University Syracuse</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,108.30,148.86,386.41,15.15">Some Experiments with the Dutch Collection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7C1B2B259E41565FE0D36B28734EB6F4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We performed some basic monolingual Dutch and bilingual English-Dutch experiments. The retrieval approach is very basic, without stemming or decompounding, using only a simple language model to rank the documents. In the bilingual task, the English queries are analyzed by a system for question answering. The resulting queries are translated by dictionary lookup and ranked by the same basic retrieval system used in the monolingual task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Inspired by shared observations at the first CLEF workshop<ref type="foot" coords="1,348.28,398.46,3.97,6.12" target="#foot_0">1</ref> , the authors decided to initiate work on retrieval experiments that help understand the effect of the quality of the translation process on retrieval results.</p><p>We are primarily interested in the problem of multi-lingual retrieval from Dutch collections, and as we believe the quality of the resources for translation a significant factor in the retrieval results, we decided to focus on the bilingual English to Dutch task. Limiting ourselves to this task, we could deploy two high quality resources:</p><p>• a natural language processing toolkit aimed at (English) Question Answering, developed at CNLP [DLC + 01];</p><p>• the CD-ROM edition of the (excellent) 'Van Dale Groot woordenboek', a dictionary for English to Dutch translation (and vice versa) <ref type="bibr" coords="1,316.04,535.53,26.69,8.74">[vD97]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Experimental setup</head><p>For question processing we used the language to logic module from the Center for Natural Language Processing (CNLP) as the front-end of our system. The language to logic (L2L) module converts a natural language query or question into a generic logical representation, which can be interpreted by different search engines. The conversion from language to logic takes place based on an internal query sublanguage grammar, which has been developed by CNLP. Prior to conversion, query processing such as stemming, stopword removal, and phrase and Named Entity recognition take place. Certain terms in the question are expanded with their synonyms or spelling variants, e.g., the term 'Koweit' upon encountering 'Kuwait'. The terms occuring in the resulting expression are looked up in the dictionary. The Van Dale dictionary has been developed for interactive usage on the desktop only, for example to find a translation while writing a text document with your favourite word processor. Unfortunately, it lacks a command-line interface, which has rendered it unexpectedly difficult to apply as a component in an automatic translation system. As a workaround, we developed a screen-scraping tool based on the Win32 modules for the Perl scripting language: we discovered that the Van Dale application supports requests to lookup query words using DDE (a Windows protocol for data exchange). The results, displayed in the results pane, are copied through the Clipboard into our script by emulating the right sequence of keystrokes. The data captured on the Clipboard is then parsed and converted into a query-specific dictionary. Because some terms generate a large number of alternative translations for many different senses, we set some ad-hoc thresholds: a maximum amount of 10 translations per term, from a maximum of 5 different senses, but taking never more than 3 translations per sense.</p><p>The results of these two steps (as well as the documents in the collection) are converted to lowercase and stripped from 'strange' characters, and stopwords are removed. The retrieval backend is a database implementation of the simple -but proven effective -language models developed by Hiemstra <ref type="bibr" coords="2,132.27,255.48,30.17,8.74" target="#b2">[Hie01]</ref> (more information about the retrieval backend is given in <ref type="bibr" coords="2,412.37,255.48,33.15,8.74" target="#b1">[HdV00]</ref>). We intended to perform our experiments with an improved implementation that processes both phrases and disjunctive queries, but we did not finish our implementation work in time, so we have used the simple term-based model. The results of our experiments are summarized in Table <ref type="table" coords="2,362.57,446.76,3.88,8.74" target="#tab_0">1</ref>. We submitted four runs, their names encoding the task -monolingual ('mo') or bilingual ('bi') -and the portion of the topics that has been processed: title only ('t') or title and description ('td').</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Analysis</head><p>The difference in mean average precision between title-only and title-and-description topics is surprisingly small in both tasks, especially since the title-only topics are quite short (2.5 word on average). A very large difference is found in topic C110, which is however explained easily since the description gives the name 'Kazem Radjavi' and the title does not. Apparently, only a small number of query terms really help retrieving relevant documents, and those query terms do usually occur in both title and description. Further analysis is warranted to explain the small drop in performance.</p><p>The significantly decreased mean average precision of the bilingual runs when compared to the monolingual runs demonstrates that the query translation component of our system requires more work. A main cause of our disappointing results is the approach of using the Van Dale dictionary through screen-scraping. First, communication via Clipboard cut-and-paste sometimes malfunctioned: the data would not appear on the Clipboard, probably due to timing problems. This makes it particularly difficult to check whether no translation occurred in the dictionary, or, the answer is not there due to communication problems. For example, a term like 'space probe' is found in the Van Dale dictionary, but the translation was unfortunately 'dropped' by our script <ref type="bibr" coords="2,90.00,661.96,270.26,8.74">(other examples are 'telephone', 'administration' and 'fishing')</ref>. Second, the Van Dale application performs a fuzzy match if the query term is not found, but checking whether that has happened would require an additional cut-and-paste of a different text pane. Finally, the copied data is not trivially interpreted by a machine, as it does contain instructions aimed at people, such as 'compare to' or 'see also'.</p><p>A deeper problem with our current approach lies in the interaction between different process steps. As a simple example, the front-end adds 'Koweit' as an alternative for 'Kuwait', but this alternative does not exist in the dictionary so is ignored further on in the process. In this particular case, it does not hurt effectiveness during the retrieval step, as 'Koweit' will not be found in the Dutch collection. A more interesting example of this problem is exposed when the additional intelligence in the front-end actually reduces effectiveness. A particularly good example of this case is provided by topic 91, AI in Latin America. The L2L module makes two wrong assumptions in this case: 'AI' is not 'Artificial Intelligence', and 'America' does not always imply 'United States'. The final result of the process is the following complex query: ('Artificial Intelligence' ∨ ('United States' ∨ 'United States of America' ∨ 'US' ∨ 'USA'). Of course, the original untranslated query terms are added, but given that the retrieval model emphasizes frequent query words, most of the results discuss indeed artificial intelligence in the US, and not Amnesty International in Latin America as desired.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Next Steps</head><p>Summarizing our current experimental results, we must conclude we have not made much progress since the first CLEF workshop. Still, we find ourselves in need of basic resources such as the dictionary; while the chosen 'Van Dale' seems an excellent tool for interactive usage during a word processing session on a Windows desktop, its application in an automatic retrieval system seems difficult. Although some of the ambiguities in the translation instructions can be interpreted automatically, the current screen-scraping solution is not sufficiently reliable to base further retrieval experiments upon.</p><p>A more interesting challenge is to find a balance between the sophisticated (but sometimes mistaken) analysis of the query in the L2L module, and the brute-force term counting of the statistical retrieval model. While we are convinced that it should (some day) be possible to improve retrieval results with an intelligent analysis of the query, it is not yet clear how to detect -without human intervention -that a rule like 'America → US' does not apply for 'Latin America'.</p><p>The most urgent work to be done is however to finalize the implementation of an adaptation of our retrieval model that takes into account phrases and disjunctions. Even though most components are in place, more engineering is needed before these experiments can be performed.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,214.52,356.03,173.96,79.22"><head>Table 1 :</head><label>1</label><figDesc>Results of the submitted runs.</figDesc><table coords="2,214.52,356.03,173.96,57.36"><row><cell>Run</cell><cell>Mean average precision</cell></row><row><cell>AAmoNLtd</cell><cell>0.399</cell></row><row><cell>AAmoNLt</cell><cell>0.348</cell></row><row><cell>AAbiENNLtd</cell><cell>0.162</cell></row><row><cell>AAbiENNLt</cell><cell>0.133</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,105.24,740.73,101.02,6.99"><p>'We want better resources.'</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,138.13,496.52,374.88,8.74;3,138.13,508.48,374.88,8.74;3,138.13,520.43,374.88,8.74;3,138.13,532.39,373.57,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,138.13,508.48,324.94,8.74">Question Answering: CNLP at the TREC-9 Question Answering Track</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Diekema</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Mccracken</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Yilmazel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">D</forename><surname>Liddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,306.84,520.43,206.16,8.74;3,138.13,532.39,67.77,8.74">Proceedings of the Nineth Text Retrieval Conference TREC-9</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>the Nineth Text Retrieval Conference TREC-9</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="501" to="510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,138.12,552.31,374.89,8.74;3,138.13,564.27,374.87,8.74;3,138.13,576.22,238.38,8.74" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="3,300.73,552.31,212.28,8.74;3,138.13,564.27,181.35,8.74">Relating the new language models of information retrieval to the traditional retrieval models</title>
		<author>
			<persName coords=""><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arjen</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vries</forename></persName>
		</author>
		<idno>TR-CTIT-00-09</idno>
		<imprint>
			<date type="published" when="2000-05">May 2000</date>
		</imprint>
		<respStmt>
			<orgName>Centre for Telematics and Information Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="3,138.12,596.15,374.88,8.74;3,138.13,608.10,298.22,8.74" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="3,198.86,596.15,207.44,8.74">Using language models for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>Centre for Telematics and Information Technology, University of Twente</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="3,138.12,628.03,374.88,8.74;3,138.13,639.98,15.50,8.74" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="3,230.17,628.03,214.87,8.74">Nederlands-Engels/Engels-Nederlands. CD-ROM</title>
		<author>
			<persName coords=""><surname>Groot Woordenboek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
