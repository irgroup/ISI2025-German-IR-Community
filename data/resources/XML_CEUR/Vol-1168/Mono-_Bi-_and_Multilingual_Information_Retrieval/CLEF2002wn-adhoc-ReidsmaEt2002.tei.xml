<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,103.91,148.86,395.19,15.15">Cross-language Retrieval at Twente and TNO</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,139.80,182.75,70.40,8.74"><forename type="first">Dennis</forename><surname>Reidsma</surname></persName>
							<email>reidsma@cs.utwente.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">University of Twente</orgName>
								<address>
									<postBox>P.O. Box 217</postBox>
									<postCode>7500 AE</postCode>
									<settlement>Enschede</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,220.76,182.75,72.76,8.74"><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
							<email>hiemstra@cs.utwente.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">University of Twente</orgName>
								<address>
									<postBox>P.O. Box 217</postBox>
									<postCode>7500 AE</postCode>
									<settlement>Enschede</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,304.07,182.75,78.13,8.74"><forename type="first">Franciska</forename><surname>De Jong</surname></persName>
							<email>fdejong@cs.utwente.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">University of Twente</orgName>
								<address>
									<postBox>P.O. Box 217</postBox>
									<postCode>7500 AE</postCode>
									<settlement>Enschede</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">TNO TPD</orgName>
								<address>
									<postBox>P.O. Box 155</postBox>
									<postCode>2600 AD</postCode>
									<settlement>Delft</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,399.09,182.75,59.64,8.74"><forename type="first">Wessel</forename><surname>Kraaij</surname></persName>
							<email>kraaij@tpd.tno.nl</email>
							<affiliation key="aff1">
								<orgName type="institution">TNO TPD</orgName>
								<address>
									<postBox>P.O. Box 155</postBox>
									<postCode>2600 AD</postCode>
									<settlement>Delft</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,103.91,148.86,395.19,15.15">Cross-language Retrieval at Twente and TNO</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D52E26917AED505D66A68DD724105B31</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the official runs of the Twenty-One group for CLEF-2002. The Twenty-One group participated in the Dutch and Finnish monolingual and the Dutch bilingual tasks. This paper also reports on an experiment that was carried out during the assessment work. The experiment was designed to examine possible influences on the assessments caused by the use of highlighting in the assessment program.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper describes the CLEF participation of the Twenty-One group. <ref type="foot" coords="1,407.28,387.50,3.97,6.12" target="#foot_0">1</ref>Section 2 provides the context in which research on multilingual information retrieval is carried out at TNO TPD and the University of Twente. Section 3 discusses the Dutch and Finnish runs that the Twenty-One group submitted to CLEF 2002. First the retrieval model is described (section 3.1), after which our submissions to CLEF 2002 are presented. Section 4 describes and analyses the results of an experiment that has been carried out on some aspects of the assessment protocol and discusses its results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">CLIR as an aspect of multimedia retrieval</head><p>The work on cross-language information (CLIR) that has been carried out by a joint research group from TNO and the University of Twente since 1997 (TREC-6), has been part of a larger research area that can be described as content-based multimedia retieval. CLIR is just one of the themes in a series of collaborative projects on multimedia retrieval, of which Twenty-One provided the name of the search engine that has been developed and used for the participation in TREC and, later on, CLEF. Though the focus on CLIR-aspects is not in all projects as strong as it used to be in Twenty-One, the possibility to search in digital multimedia archives with different query languages and to identify relevant material in other languages than the query language has always been part of the envisaged functionality. Where the early projects exploited mainly the textual material avaliable in multimedia archives (production scripts, cut lists, etc.), the use of timecoded textual information (subtitles, transcripts generated by automatic speech recognition tools, etc.) has become more dominant in the current running projects, for which video and audio retrieval are the major goals, e.g. DRUID and the IST-projects ECHO and MUMIS 2 . In some projects the CLIR functionality is made available by allowing the users of the demonstator systems to select query terms from a closed list which is tuned to the domain of the media archive to be searched. Translation to other languages is then simply a matter of mapping these query terms to their translation equivalents. Ambiguity resolution and other problems inherent to CLIR-tasks are circumvented in this concept search like approach. However, there is always the additional user requirement to be able to search for terms that are not in the controlled list. Therefore, even in ontology driven projects such as MUMIS, the type of CLIR functionality that is central to the current CLEF-campaign remains relevant in the multimedia domain.</p><p>3 Retrieval experiments on the Dutch and Finnish document set</p><p>The Twenty-One group participated in the Dutch and Finnish monolingual task and the Duch bilingual task. In this section we present the retrieval model (section 3.1) and discuss the scores for the different tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The retrieval model</head><p>Runs were carried out with an information retrieval system based on a simple unigram language model. The basic idea is that documents can be represented by simple statistical language models. Now, if a query is more probable given a language model based on document d 1 , than given e.g. a language model based on document d 2 , then we hypothesise that the document d 1 is more likely to be relevant to the query than document d 2 . Thus the probability of generating a certain query given a document-based language model can serve as a score to rank the documents.</p><formula xml:id="formula_0" coords="2,163.48,377.19,349.52,30.32">P (T 1 , T 2 , • • • , T n |D)P (D) = P (D) n i=1 (1 -λ)P (T i ) + λP (T i |D)<label>(1)</label></formula><p>Formula 1 shows the basic idea of this approach to information retrieval, where the document-based language model P (T i |D) is interpolated with a background language model P (T i ) to compensate for sparseness. In the formula, T i is a random variable for the query term on position i in the query (1 ≤ i ≤ n, where n is the query length), which sample space is the set of all terms in the collection. The probability measure P (T i ) defines the probability of drawing a term at random from the collection, P (T i |D k ) defines the probability of drawing a term at random from the document; and λ is the smoothing parameter, which is set to λ = 0.15. The marginal probability of relevance P (D) is assumed to be uniformly distributed over the documents in which case it may be ignored in the above formula. For a description of the embedding of statistical word-by-word translation into our retrieval model, we refer to <ref type="bibr" coords="2,299.71,522.67,9.97,8.74" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Dutch runs</head><p>For Dutch three separate runs were submitted. First there was the manual run, in which we had a special interest because of our role in the assesment of all the runs submitted for Dutch (cf. section 4). The expected effect of submitting a run for which the queries were manually created from the topics, was to increase the size and quality of the pool of documents to be assessed. The engine applied was a slightly modified version of the NIST Z/Prise 2.0 system. The Dutch bilingual run is an automatic run done with the TNO retrieval system (also referred to as the Twenty-One engine) as developed and used for previous CLEF participations <ref type="bibr" coords="2,487.46,640.13,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="2,502.49,640.13,7.01,8.74" target="#b1">2]</ref>. Furthermore we used the VLIS lexical database developed by Van Dale Lexicography and the morphological analyzers developed by Xerox Research Centre Grenoble.</p><p>For completeness we did a post-evaluation automatic monolingual Dutch run. Mean average precision figures for the three runs are given in Table <ref type="table" coords="2,325.01,687.96,3.88,8.74">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Finnish run</head><p>Since we did not have a Finnish morphological analizer or stemmer, we decided to apply an Ngram approach, which has been advocated as a language independent, knowledge-poor approach run label m.a.p. description tnoutn1 0.4471 manual monolingual tnoen1 0.3369 EN-NL dictionary based tnofifi1 0.4056 automatic monolingual (Finnish) tnonn1 0.4247 automatic monolingual Table <ref type="table" coords="3,157.86,180.11,3.88,8.74">1</ref>: mean average precision of the runs on the Dutch and Finnish dataset by McNamee and Mayfield <ref type="bibr" coords="3,210.54,211.93,9.97,8.74" target="#b2">[3]</ref>. After applying a stoplist and lowercasing, documents and queries were indexed by character 5-grams. Unlike the JHU approach, the 5-grams did not span word boundaries. This extremely simple approach turned out to be very effective: for almost all topics the score of this run was at least as high as the median score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Assessment of the Dutch results</head><p>The University of Twente was responsible for assessing the results for the Dutch newspaper collections (articles from the newspapers 'NRC Handelsblad' and 'Algemeen Dagblad'). Besides assessing all topics in the standard way for the official ranking of the submitted runs, we also repeated some assessments without allowing highlighting of search terms. This section discusses the motivation for this additional experiment and reports on the findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Introduction</head><p>The program used to do the assessments is developed at NIST and offers the possibility to highlight terms in the documents. Highlighting words and phrases for which a search engine has detected a relation to the query terms might make it easier for the assessor to decide on the relevance of a document. Usually the assessor will be told explicitly that the presence or absence of highlighted terms in a document is not decisive in marking a document relevant. The assumption is that using or not using highlighting will not influence the assessment results, or more specifically the ranking of the search engines that follows from those results. We think however that this assumption can be questioned. The following subsection explains that highlighting can affect the assessments and that therefore the use of highlighting may influence the ranking of search engines. A simple experiment will be described that we applied to detect such differences.</p><p>If the assessment process would indeed be seriously influenced by the use of highlighting, the implications would be large. Not only the assessment protocol would have to change, but the validity of the assessments of previous years should also have to be reconsidered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Possible influences of highlighting on assessment results</head><p>We wanted to investigate two different aspects of the assessment results which might be affected by the use of highlighting. The first is the amount of documents that are marked as relevant, the second is the score of the participating search engines. We did not expect to find hard statistical evidence for presence or absence of either one of the influences, given the size of test data, but rather expected some trend to show up, which would warrant further investigation.</p><p>The amount of relevant documents Using highlighting might result in more (or less) documents being marked as relevant. Although the assessors are explicitly told not to let the highlighting affect their judgement it is still possible that that happens unintentionally. For example, assessors might read the documents where terms are highlighted less thouroughly, missing in those documents the relevant parts which do not contain highlighted terms. Or the assessors might just be biased in favor of documents containing highlighted terms.</p><p>The scores of search engines If the assessors are indeed biased towards documents containing highlighted terms this might influence the scores of the search engines. After all, many search engines rely on detecting the presence of query words for marking them as relevant. So in that case, those engines would perform better with the biased assessment than with assessments produced without using highlighting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">The experiments</head><p>The experiment was simple: 18 topics were each assessed at least twice, once with and once without highlighting. These assessments were assigned randomly over 10 people, in such a way that every assessor did some assessments with and without highlighting and no-one assessed one topic twice. The assessors were absolutely not allowed to talk to each other about these assessments until all assessments were finished.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">The results</head><p>The results of this experiment were not conclusive. For half of the topics, the assessments with highlighting resulted in more relevant documents than the assessments without highlighting. For the rest of the topics it was the other way around. Viewed from the perspective of the assessors, using highlighting did also not result in significantly more or less relevant documents relative to the other assessors working on that topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Conclusion</head><p>There was no trend discernible that confirmed our expectations. However, we could only test the first aspect described above; we did not have the necessary data to test the effect of the highlighting on the scores of the search engines. This second aspect however is where we expected the most interesting results. We recommend therefore testing that as well. If the amount of data is too small to get reliable results, more data should be collected. If the results show a significant change in the scores of the search engines when highlighting is turned off, the assessment protocol should be reconsidered. It is possible then that the benefits of highlighting do not outweigh the adverse effects on the quality of the assessments, in which case highlighting should not be used anymore.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,105.24,713.83,407.75,6.99;1,90.00,723.30,423.00,6.99;1,90.00,732.76,130.24,6.99"><p>Twenty-One was an information retrieval project funded by the with the TAP programme of the EU. Though the Twenty-One project was completed in June 1999, TNO TPD and the University of Twente still participate in the CLEF events under that name.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,105.24,742.27,325.84,6.99"><p>For details, cf. http://parlevink.cs.utwente.nl/projects, http://www.tpd.tno.nl/, and<ref type="bibr" coords="1,422.14,742.27,8.94,6.99" target="#b4">[5]</ref> </p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,110.48,532.77,402.52,8.74;4,110.48,544.72,402.52,8.74;4,110.48,556.68,402.52,8.74;4,110.48,568.63,164.53,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,377.74,532.77,135.26,8.74;4,110.48,544.72,316.91,8.74">Translation resources, merging strategies and relevance feedback for cross-language information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pohlmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Westerveld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,447.95,544.72,65.05,8.74;4,110.48,556.68,166.74,8.74;4,456.87,556.68,45.92,8.74">Cross-language Information Retrieval and Evaluation</title>
		<title level="s" coord="4,287.13,556.68,159.60,8.74">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="102" to="115" />
		</imprint>
	</monogr>
	<note>LNCS-2069</note>
</biblStruct>

<biblStruct coords="4,110.48,588.56,402.52,8.74;4,110.48,600.51,127.36,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,164.77,588.56,245.37,8.74">TNO at CLEF-2001: Comparing Translation Resources</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,434.73,588.56,78.27,8.74;4,110.48,600.51,95.23,8.74">Working Notes of CLEF 2001 Workshop</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,110.48,620.44,402.52,8.74;4,110.48,632.39,402.52,8.74;4,110.48,644.35,230.18,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,231.16,620.44,281.84,8.74;4,110.48,632.39,242.03,8.74">A Language-Independent Approach to European Text Retrieval In Cross-language Information Retrieval and Evaluation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mayfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,115.58,644.35,45.93,8.74">LNCS-2069</title>
		<title level="s" coord="4,360.37,632.39,152.62,8.74">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="102" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,110.48,664.28,402.52,8.74;4,110.48,676.23,333.80,8.74" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="4,189.23,664.28,228.23,8.74">Using Language Models for Information Retrieval Ph</title>
		<author>
			<persName coords=""><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001-01">January 2001</date>
		</imprint>
		<respStmt>
			<orgName>Centre for Telematics and Information Technology, University of Twente</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">D. Thesis</note>
</biblStruct>

<biblStruct coords="4,110.48,696.16,402.52,8.74;4,110.48,708.11,402.52,8.74;4,110.48,720.07,321.63,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,346.65,696.16,166.35,8.74;4,110.48,708.11,59.40,8.74">Language-Based Multimedia Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-L</forename><surname>Gauvain</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Dj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Netter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,195.57,708.11,317.43,8.74;4,110.48,720.07,48.06,8.74">Content-Based Multimedia Information Access, RIAO 2000 Conference Proceedings</title>
		<meeting><address><addrLine>Paris</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="713" to="722" />
		</imprint>
	</monogr>
	<note>C.I.D.-C</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
