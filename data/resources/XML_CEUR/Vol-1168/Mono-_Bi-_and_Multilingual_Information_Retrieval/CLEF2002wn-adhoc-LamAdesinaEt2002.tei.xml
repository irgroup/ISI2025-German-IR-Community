<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.11,86.24,418.94,12.63;1,187.46,102.32,220.37,12.63">EXETER AT CLEF 2002: Experiments with Machine Translation for Monolingual and Bilingual Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,207.62,131.75,101.61,8.96"><forename type="first">Adenike</forename><forename type="middle">M</forename><surname>Lam-Adesina</surname></persName>
							<email>a.m.lam-adesina@ex.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Exeter</orgName>
								<address>
									<postCode>EX4 4QF</postCode>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,316.46,131.75,71.45,8.96"><forename type="first">Gareth</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Exeter</orgName>
								<address>
									<postCode>EX4 4QF</postCode>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.11,86.24,418.94,12.63;1,187.46,102.32,220.37,12.63">EXETER AT CLEF 2002: Experiments with Machine Translation for Monolingual and Bilingual Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2100133C37B781079870D84BCD08B1AF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This year, the University of Exeter participated in both the CLEF 2002 monolingual and bilingual task for two languages: Italian and Spanish. We submitted 4 ranked results each for both Italian and Spanish Monolingual tasks and 5 each for the bilingual tasks. We report experimental results from our investigations of merging topic translations from two machine translation (MT) systems and recent experimental results for query expansion and term weighting from alternative collections. Our results show that although, query expansion and term weighting from a pilot collection has been shown to be effective in improving retrieval performance in information retrieval, the performance can be affected negatively if the lexicon of the pilot and the test collection differ.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The main objective of our participation in CLEF 2002 was to test the effectiveness of some of our methods developed after CLEF 2001, and also to investigate the retrieval behavior of document collection in Italian and Spanish using topic sets in several other languages. Our official submissions included Italian and Spanish monolingual tasks as well as bilingual tasks using topic sets in German, French, English, Italian and Spanish. To present a fair comparison of results across all language pairs and methods for the bilingual runs, we used the same translation resources for each pair and we also present results for each retrieval method for each pair. Both the collections and the topics were translated from the source language into English. Firstly, because we had intended to participate in the multilingual task and secondly because the retrieval system we used could not deal with accented words. We were unable to submit results for the multilingual task because of time constraints.</p><p>Our general approach was to use the collection and topic translation strategy for CLIR. The document collection and the topic statements were submitted to the selected MT system, the output was then collected and applied on the information retrieval (IR) system. For all our submissions and subsequent runs presented in this paper, we used both the Systran Version: 3.0 and the Globalink Power Translation Pro Version: 6.4 MT systems for topic translation. It should be noted that the two collections used in our experiments were translated using only Systran Version 3.0.</p><p>Pseudo-relevance feedback (PRF) has been shown to be an effective approach to improving retrieval performance in IR and also in CLIR <ref type="bibr" coords="1,237.20,517.03,11.28,8.96" target="#b0">[1]</ref>[2] <ref type="bibr" coords="1,259.76,517.03,11.28,8.96" target="#b2">[3]</ref>. In our experimental work in <ref type="bibr" coords="1,407.95,517.03,11.69,8.96" target="#b3">[4]</ref> <ref type="bibr" coords="1,419.64,517.03,11.69,8.96" target="#b4">[5]</ref> we demonstrated the effectiveness of a new PRF method using the Okapi BM25 probabilistic model <ref type="bibr" coords="1,393.77,528.43,10.63,8.96" target="#b5">[6]</ref>. In this work we investigated the idea of selecting expansion terms for document summaries and found this method to be more reliable than query expansion from full documents. Since CLEF 2001, we have also explored data combination techniques that merge the output of the two MT systems for the topics, and use this as the initial query set. Furthermore, we have also been investigating the use of a comparable collection (pilot) for generating expansion terms and term weighting. The method is described fully below. Our experiments for CLEF 2002 explore the effectiveness of these methods with automatically translated documents and topics.</p><p>The remainder of this paper is organized as follows: Section 2 reviews the information retrieval methods used, Section 3 gives a brief description of the data processing techniques used, Section 4 describes the different methods of PRF, Section 5 gives the experimental results and section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Retrieval Approach</head><p>The experiments were carried out using the City University research distribution version of the Okapi system. All stopwords were removed from the documents and search queries. All remaining terms were then suffix stripped using Porter stemming <ref type="bibr" coords="1,198.04,703.26,11.72,8.96" target="#b7">[7]</ref> and then indexed using a small set of synonyms. Documents terms are weighted using the Okapi BM25 formula <ref type="bibr" coords="1,324.16,714.78,11.67,8.96" target="#b5">[6]</ref> </p><formula xml:id="formula_0" coords="1,338.38,714.78,74.24,8.96">reproduced below. ) ( ))) ( ( ) 1 (( 1 ) 1 1 ( ) , ( ) ( ) , ( ij tf j ndl b b K K j i tf i cfw j i cw + × + - × + × × =</formula><p>where cw(i,j) = the weight of term i in document (j), cfw(i) = the standard collection frequency weight tf(i,j) = the document term frequency ndl(j) = the normalized document length calculated as follows</p><formula xml:id="formula_1" coords="2,72.75,170.73,144.48,23.03">ents oralldocum Averagedlf j dl j ndl ) ( ) ( =</formula><p>where dl(j) = the length of j K1 and b are empirically selected tuning constants for a particular collection. K1 modifies the effect of term frequency and b modifies the effect of document length. All our experiments were done with K1and b set to 1.4 and 0.6. The parameters were set using the CLEF 2001 data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Relevance Feedback</head><p>Relevance feedback is a method used to improve retrieval effectiveness by either improving the query terms (Query modification) or the term weights (term-reweighting). All our experiments used query expansion to modify the query to attempt to improve the quality of the initial query by adding new terms selected from a pool of potential expansion terms from the initial retrieval run.</p><p>Our query expansion method selects terms from summaries of the top 5 ranked documents. The summaries were generated using the method described in <ref type="bibr" coords="2,273.50,349.75,10.69,8.99" target="#b3">[4]</ref>. The summary generation method combines the Luhn's Keyword Cluster Method <ref type="bibr" coords="2,176.65,361.27,10.65,8.99" target="#b8">[8]</ref>, Title terms frequency method <ref type="bibr" coords="2,316.25,361.27,10.65,8.99" target="#b3">[4]</ref>, Location/header method <ref type="bibr" coords="2,433.66,361.27,11.69,8.99" target="#b9">[9]</ref> and the Query-bias method <ref type="bibr" coords="2,104.05,372.79,16.69,8.99" target="#b10">[10]</ref> to form an overall significance score for each sentence. For all our experiments we used the top 6 ranked sentences as the summary of each document. From this summary we collected all non-stopwords and ranked them using a slightly modified version of the Robertson selection value (rsv) <ref type="bibr" coords="2,411.99,395.83,16.76,8.99" target="#b11">[11]</ref> reproduced below. The top 20 terms was then selected in all our experiments.</p><formula xml:id="formula_2" coords="2,72.87,427.04,83.22,12.95">) ( ) ( ) ( i rw i rw i rsv × =</formula><p>where r(i) = number of relevant documents containing term i rw(i) is the standard Robertson/Sparck Jones relevance weight <ref type="bibr" coords="2,349.93,467.22,16.70,8.99" target="#b12">[12]</ref> reproduced below</p><formula xml:id="formula_3" coords="2,72.87,487.71,191.71,27.05">) 5 . 0 ) ( )( 5 . 0 ) ( ) ( ( ) 5 . 0 ) ( ) ( )( 5 . 0 ) ( ( log ) ( + - + - + + - - + = i r R i r i n i r R i n N i r i rw</formula><p>where n(i) = the total number of documents containing term i r(i) = the total number of relevant documents term i occurs in R = the total number of relevant documents for this query N = the total number of documents</p><p>In our modified version, although potential expansion terms are selected from the summaries of the top 5 ranked documents, they are ranked using the top 20 ranked documents from the initial run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data Processing</head><p>The two document collections used in our experiments, Italian and Spanish were translated to English using the Systran Translation Software version 3.0. This was necessitated by the inability of the retrieval system (Okapi) used for our experiments to deal with accented terms as well as languages other than English. All queries were translated from the source language into English using both the Systran Version 3.0 and Globalink Power Translation Pro version 6.4 MT software. All our experiments were done using both the title and description fields of the CLEF topics.</p><p>Our submissions to CLEF 2002 investigated a number of approaches to term weighting and query expansion as described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Standard Method</head><p>This method is the same as that used in our CLEF 2001 official submissions <ref type="bibr" coords="3,376.57,135.09,10.63,8.99" target="#b4">[5]</ref>. Initial retrieval run using translated queries was performed. The top 5 assumed relevant documents were summarized and the pool of potential expansion terms was generated from the summaries. The top 20 terms was then added to the initial query for the feedback run. (Indicated "Test coll. terms and weight" in the results).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Pilot searching</head><p>Query expansion is aimed at improving initial search topic in order to make it a better expression of user's information need. This is normally achieved by adding terms selected from assumed relevant document retrieved from the test collection, to the initial query. Another approach that has been shown to be effective is the selection of expansion terms from a larger collection, a subset of which would be the test collection. Based on the assumption that if additional documents from the same corpus as the test collection are available, these can be used for improved query expansion, we explore the idea of pilot searching <ref type="bibr" coords="3,385.04,263.96,15.36,8.99" target="#b13">[13]</ref>. The larger data collection is likely to enable more accurate parameter estimation and hopefully better retrieval and document ranking. The Okapi submissions for the TREC-7 <ref type="bibr" coords="3,219.32,286.88,16.72,8.99" target="#b13">[13]</ref> adhoc tasks used the TREC disks 1-5 of which the TREC-8 data is a subset, for parameter estimation and query expansion. The method was found to be very effective. Our post CLEF 2001 results for bilingual English also demonstrated the effectiveness of this approach <ref type="bibr" coords="3,450.03,309.92,15.44,8.99" target="#b14">[14]</ref>. The TREC-8 data collection consisting of more than half a million documents was used as "pilot collection" in our experiments. The CLEF 2002 English collection is a subset of the TREC-8 data collection. Two different approaches were taken to the pilot searching procedure. They are as follows 1 Apply the original query terms on the pilot collection using the Okapi system without feedback. Extract terms from the top R assumed relevant documents; rank the extracted terms and select the desired number of expansion terms from the top of the list. The corresponding cfw(i) term weights are also stored along with the expansion terms. The expansion terms are added to the initial query terms and applied on the test collection (Test coll. weight and Pilot coll. expansion terms). This approach is shown to give an improvement for the CLEF 2001 bilingual task <ref type="bibr" coords="3,278.78,424.87,10.69,8.99" target="#b0">[1]</ref>. <ref type="bibr" coords="3,70.95,436.39,4.99,8.99" target="#b1">2</ref> The second method involve using the expansion terms from the pilot collection as above but this time the cfw(i) weights from the pilot collection are used instead of the term weights from the test collection (Pilot coll. terms and weight). This method gave a further improvement for the CLEF 2001 bilingual task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Combination Methods</head><p>MT systems sometimes make translation errors due to the limitations of the dictionaries used in them. However, this problem can be tackled by combining the outputs of multiple MT systems. This idea is based on the proven notion that combination of evidence from multiple information sources is beneficial to text retrieval. Thus, in this method, for each untranslated query, two different translations of the query from the two different translators used in these experiments are merged into a single query. Furthermore, the merged queries are then used in two different ways as follows.</p><p>1 The first method uses only the combined queries as the initial query (Combined MT queries) <ref type="bibr" coords="3,70.95,588.17,4.99,8.99" target="#b1">2</ref> The second (exemgcnt) uses the combined queries and upweight the weight of terms occurring in both translation by 2 (Combined MT upweighted).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head><p>In this section we report the results of our investigation for all methods described above. Baseline results without feedback and results after the application of the different methods of feedback are presented for Italian and Spanish Monolingual and Bilingual tasks. All our official submissions are indicated by a *. In all cases the results use the Title and Description fields of the search topics and we present the average precision (Avep), the % change in average precision relative to the baseline for the MT system used (% chg) and the total number of relevant documents retrieved (R-ret). For feedback runs all initial query terms are upweighted by multiplying the original term weights by 3.5.  <ref type="table" coords="4,97.48,369.67,4.99,8.99" target="#tab_0">1</ref> above shows the results for Italian Monolingual task before and after various method of feedback are applied. Application of the different feedback methods resulted in improvement in precision except for method using the pilot collection for term selection and weighting for Systran translated topics. Investigation of this result shows that the lexicon of the translated query using Systran is usually different from that of the TREC-8 data used as the pilot collection. Also there were some query terms, which were not translated and were returned as the original Italian word. This resulted in a large number of mismatches between the query and the documents in the pilot collection. The Globalink translator fared better in this aspect because the untranslated query was closer after translation to the original English query and hence resulted in better selection and parameter estimation from the pilot collection. The feedback result was however affected by the differences in the lexicon used in the expanded query and the target collection. Systran translated topics gave better performance compared to Globalink topics, this is perhaps attributable to the fact that the document collection was translated using Systran. The best result (underlined) for both translations is achieved using the test collection generated expansion terms and their corresponding weights. Table <ref type="table" coords="4,96.88,530.70,4.99,8.99" target="#tab_1">2</ref> shows the effect of the application of merged queries from the two MT systems, on the retrieval system. Although the method resulted in about 8% improvement relative to the baseline result for Systran and about 21% relative to the baseline for Globalink, the result is still lower than that achieve by the best method. The result however suggests that merged queries may be useful in achieving better retrieval performance for poor MT systems.  <ref type="table" coords="6,97.24,164.97,4.42,8.99" target="#tab_2">3</ref>-8 shows the retrieval behavior for the language pairs before and after various methods of feedback for Italian bilingual runs. Result using pilot collection for query expansion and term weighting again gives the worst result for all pairs overall. This is almost certainly due to the differences in the lexicon used in the pilot and the test collection, which reduces the query-document matching and subsequently result in reduction in retrieval effectiveness. The result for the combined queries further strengthens the idea that combining the output from two MT systems might help in reducing the effect of poor MT systems on retrieval. The best result overall is given by the Italian-English run using test collection weight and pilot collection expansion terms. Globalink translated topics gave better performance overall compared to the results using Systran translated topics although French topics using Systran performed better than that using Globalink.  Table <ref type="table" coords="9,97.72,239.48,10.03,8.99" target="#tab_8">19</ref> Retrieval results for Bilingual Spanish using summary based term selection and cfw(i) from merged collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Italian Monolingual runs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Italian Bilingual runs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Spanish Monolingual runs</head><p>Table <ref type="table" coords="9,98.07,274.04,9.34,8.99" target="#tab_6">17</ref>-19 shows the results for using the merged collection (pilot and test) for query expansion and term weighting. Monolingual Results for Italian and Spanish shows that merging the two collections result in better estimation of term weight, which results in improved retrieval. This method resulted in about 14% improvement in retrieval compared to the baseline results and about 18% improvements over using the pilot collection for expansion and weighting for the Monolingual runs.</p><p>For the bilingual runs, an improvement of about 23% compared to the baseline runs for the Italian Bilingual run and about 20% for the Spanish bilingual runs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Further Work</head><p>In this paper we have presented our results for the CLEF 2002 monolingual and bilingual Italian and Spanish retrieval tasks. The results suggest that good retrieval results can be achieved by merging the output of two commercially available MT systems. It also shows that all language pairs behave very differently to different feedback method, this requires further investigation to determine the causes of such behavior and how they can be tackled. The combined query method is very effective in smoothing out the negative effects of bad translations in most cases. Using pilot collection to estimate term weight and for query expansion although shown to be very effective in <ref type="bibr" coords="9,190.38,460.26,15.44,8.99" target="#b13">[13]</ref>, the results shown here suggests that when there is a difference in the language of the pilot and the test collection the method might not be as effective. We show that further improvements can be achieved by merging the two collections to form a pilot collection. Further investigation is needed to determine the reason for the slightly poor performance of the Systran translated queries compared to the Globalink translated queries. We also noticed that some terms were left untranslated by the MT systems, this is more predominant in the Systran translations, and might have been reason for the lower performance achieved using the topics translated using Systran MT compared to the performance for Globalink topics in the bilingual results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,70.95,213.56,453.62,104.73"><head>Table 1 :</head><label>1</label><figDesc>Retrieval results for topic translation for Systran and Globalink MT, showing results before and after application of various method of feedback.</figDesc><table coords="4,171.75,262.42,239.56,55.88"><row><cell>Run-id</cell><cell>Avep</cell><cell>% chg</cell><cell>% chg</cell></row><row><cell></cell><cell></cell><cell>systran</cell><cell>Globalink</cell></row><row><cell>Combined MT queries</cell><cell>*421</cell><cell>8.51%</cell><cell>20.63%</cell></row><row><cell>Combined MT queries</cell><cell>*411</cell><cell>5.93%</cell><cell>17.77%</cell></row><row><cell>upweighted</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,70.95,335.23,453.82,43.42"><head>Table 2 :</head><label>2</label><figDesc>Retrieval results for combined queries from both translators with summary-based expansion term selection and cfw(i) weight from test collection.</figDesc><table coords="4,70.95,369.67,22.92,8.99"><row><cell>Table</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,70.95,95.61,388.23,635.69"><head>Table 3 :</head><label>3</label><figDesc>Results showing baseline results for Italian bilingual tasks for both MT systems.</figDesc><table coords="4,133.95,95.61,325.24,103.41"><row><cell></cell><cell></cell><cell>Systran MT</cell><cell></cell><cell></cell><cell>Globalink MT</cell><cell></cell></row><row><cell>Run-id</cell><cell>Avep</cell><cell>% chg</cell><cell>R-ret</cell><cell>Avep</cell><cell>% chg</cell><cell>R-ret</cell></row><row><cell>Baseline no feedback</cell><cell>388</cell><cell>-</cell><cell>966</cell><cell>349</cell><cell>-</cell><cell>853</cell></row><row><cell>Test coll. weight, pilot</cell><cell>*414</cell><cell>6.70%</cell><cell>993</cell><cell>378</cell><cell>8.31%</cell><cell>910</cell></row><row><cell>coll. expansion terms</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Test coll. term and</cell><cell>*453</cell><cell>16.75%</cell><cell>1004</cell><cell>394</cell><cell>12.89%</cell><cell>905</cell></row><row><cell>weight</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Pilot coll.term and</cell><cell>376</cell><cell>-3.09%</cell><cell>910</cell><cell>375</cell><cell>7.45%</cell><cell>880</cell></row><row><cell>weight</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,70.95,177.33,453.86,20.51"><head>Table 4 :</head><label>4</label><figDesc>Retrieval results for topic translation using both MT systems with summary-based expansion term selection from pilot collection and cfw(i) from test collection.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,70.95,280.64,453.82,20.50"><head>Table 5 :</head><label>5</label><figDesc>Retrieval results for merged queries from the two MT systems with summary-based expansion term selection and cfw(i) from test collection.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,70.95,406.87,453.82,20.50"><head>Table 6 :</head><label>6</label><figDesc>Retrieval results for merged queries from the two MT systems with summary-based expansion term selection and cfw(i) from test collection. Terms occurring in both translations are upweighted by 2.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="5,70.95,70.30,453.85,622.13"><head>Table 7 :</head><label>7</label><figDesc>Retrieval results for topic translation for both MT systems with summary-based expansion term selection and cfw(i) from test collection .</figDesc><table coords="5,129.51,70.30,334.07,622.13"><row><cell>Run-id</cell><cell></cell><cell></cell><cell cols="2">Systran MT</cell><cell></cell><cell></cell><cell>Globalink MT</cell></row><row><cell cols="2">Test coll. weight, pilot</cell><cell>Avep</cell><cell cols="2">% chg</cell><cell cols="2">R-ret</cell><cell>Avep</cell><cell>% chg</cell><cell>R-ret</cell></row><row><cell>expansion terms)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>German</cell><cell></cell><cell>347</cell><cell cols="2">18.43%</cell><cell></cell><cell>914</cell><cell>364</cell><cell>19.34%</cell><cell>867</cell></row><row><cell>Spanish</cell><cell></cell><cell>362</cell><cell cols="2">13.47%</cell><cell></cell><cell>904</cell><cell>379</cell><cell>12.46%</cell><cell>936</cell></row><row><cell>French</cell><cell></cell><cell>373</cell><cell cols="2">15.12%</cell><cell></cell><cell>965</cell><cell>359</cell><cell>15.81%</cell><cell>968</cell></row><row><cell>English</cell><cell></cell><cell>407</cell><cell cols="2">23.33%</cell><cell></cell><cell>976</cell></row><row><cell>Run-id</cell><cell></cell><cell></cell><cell cols="5">Avep % chg Systran % chg Globalink</cell></row><row><cell cols="3">Combined MT queries for</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>German</cell><cell></cell><cell></cell><cell>377</cell><cell cols="3">28.67%</cell><cell>23.60%</cell></row><row><cell>Spanish</cell><cell></cell><cell></cell><cell>*373</cell><cell cols="3">16.93%</cell><cell>10.68%</cell></row><row><cell>French</cell><cell></cell><cell></cell><cell>*348</cell><cell cols="3">7.41%</cell><cell>12.26%</cell></row><row><cell>Run-id</cell><cell></cell><cell></cell><cell></cell><cell>Avep</cell><cell></cell><cell cols="2">% chg</cell><cell>% chg</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Systran</cell><cell>Globalink</cell></row><row><cell cols="4">Combined MT queries upweighted</cell><cell></cell><cell></cell><cell></cell></row><row><cell>German</cell><cell></cell><cell></cell><cell></cell><cell>*368</cell><cell></cell><cell cols="2">25.60%</cell><cell>20.66%</cell></row><row><cell>Spanish</cell><cell></cell><cell></cell><cell></cell><cell>365</cell><cell></cell><cell cols="2">14.42%</cell><cell>8.31%</cell></row><row><cell>French</cell><cell></cell><cell></cell><cell></cell><cell>377</cell><cell></cell><cell cols="2">16.36%</cell><cell>21.61%</cell></row><row><cell>Run-id</cell><cell></cell><cell cols="3">Systran MT</cell><cell></cell><cell></cell><cell>Globalink MT</cell></row><row><cell>Test coll. terms</cell><cell cols="2">Avep</cell><cell>% chg</cell><cell cols="2">R-ret</cell><cell cols="2">Avep</cell><cell>% chg</cell><cell>R-ret</cell></row><row><cell>and weight</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>German</cell><cell cols="2">341</cell><cell>16.38%</cell><cell>869</cell><cell></cell><cell cols="2">377</cell><cell>28.67%</cell><cell>825</cell></row><row><cell>Spanish</cell><cell cols="2">363</cell><cell>13.79%</cell><cell>906</cell><cell></cell><cell cols="2">371</cell><cell>16.30%</cell><cell>922</cell></row><row><cell>French</cell><cell cols="2">375</cell><cell>15.74%</cell><cell>947</cell><cell></cell><cell cols="2">358</cell><cell>11.11%</cell><cell>955</cell></row><row><cell>English*</cell><cell cols="2">374</cell><cell>13.33%</cell><cell>938</cell><cell></cell><cell></cell></row><row><cell>Run-id</cell><cell></cell><cell cols="2">Systran MT</cell><cell></cell><cell></cell><cell></cell><cell>Globalink MT</cell></row><row><cell>Pilot coll. terms</cell><cell>Avep</cell><cell cols="2">% chg</cell><cell>R-ret</cell><cell></cell><cell>Avep</cell><cell>% chg</cell><cell>R-ret</cell></row><row><cell>and weight</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>German</cell><cell>335</cell><cell cols="2">14.33%</cell><cell>872</cell><cell></cell><cell>325</cell><cell>6.56%</cell><cell>851</cell></row><row><cell>Spanish</cell><cell>333</cell><cell cols="2">4.39%</cell><cell>830</cell><cell></cell><cell>360</cell><cell>6.82%</cell><cell>917</cell></row><row><cell>French</cell><cell>365</cell><cell cols="2">12.65%</cell><cell>929</cell><cell></cell><cell>352</cell><cell>13.55%</cell><cell>948</cell></row><row><cell>English*</cell><cell>399</cell><cell cols="2">20.91%</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="6,70.95,130.53,453.85,43.42"><head>Table 8 :</head><label>8</label><figDesc>Retrieval results for topic translation for both MT systems with summary-based expansion term selection and cfw(i) from pilot collection Table</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="6,70.95,432.07,453.58,90.94"><head>Table 9 :</head><label>9</label><figDesc>Retrieval results for topic translation for Spanish bilingual runs using Systran and Globalink MT, showing results before and after application of various method of feedback.</figDesc><table coords="6,171.75,467.10,237.90,55.90"><row><cell>Run-id</cell><cell cols="2">Avep %chg</cell><cell>%chg</cell></row><row><cell></cell><cell></cell><cell>Systran</cell><cell>Globalink</cell></row><row><cell>Combined MT queries</cell><cell>*470</cell><cell>6.33%</cell><cell>2479</cell></row><row><cell>Combined MT queries</cell><cell>*468</cell><cell>5.88%</cell><cell>2460</cell></row><row><cell>upweighted</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="6,70.95,314.12,453.81,301.40"><head>Table 10 :</head><label>10</label><figDesc>Retrieval results for combined queries from both translators sing summary-based expansion term selection and cfw(i) weight from test collection Table9and 10 monolingual Spanish results shows the same trend as the Italian monolingual results in Table1-2 above. Results again show that using pilot collection to estimate term weight and query expansion for Systran topics is not very effective, it resulted in about 5% reduction in average precision compared to the baseline. The combined query method (Table10) is also shown to reduce the negative effect of translation output on retrieval.</figDesc><table coords="6,133.95,314.12,325.07,103.41"><row><cell>Run-id</cell><cell></cell><cell>Systran MT</cell><cell></cell><cell></cell><cell>Globalink MT</cell><cell></cell></row><row><cell></cell><cell>Avep</cell><cell>% chg</cell><cell>R-ret</cell><cell>Avep</cell><cell>% chg</cell><cell>R-ret</cell></row><row><cell>Baseline no feedback</cell><cell>442</cell><cell>-</cell><cell>2413</cell><cell>419</cell><cell>-</cell><cell>2235</cell></row><row><cell>Test coll. weight, pilot</cell><cell>*473</cell><cell>7.01%</cell><cell>2538</cell><cell>466</cell><cell>11.22%</cell><cell>2412</cell></row><row><cell>coll. expansion terms</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Test coll. terms and</cell><cell>*475</cell><cell>7.46%</cell><cell>2517</cell><cell>445</cell><cell>6.21%</cell><cell>2266</cell></row><row><cell>weight</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Pilot coll. terms and</cell><cell>420</cell><cell>-4.98%</cell><cell>2249</cell><cell>431</cell><cell>2.86%</cell><cell></cell></row><row><cell>weight</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="9,70.95,84.57,453.54,20.39"><head>Table 18</head><label>18</label><figDesc>Retrieval results for Bilingual Italian using summary-based term selection and cfw(i) from merged collection.</figDesc><table /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Spanish Bilingual runs</head><p>Table <ref type="table" coords="7,96.40,207.20,8.57,8.99">11</ref>: Spanish Bilingual baseline retrieval results for topic translation from both MT systems.</p><p>Table <ref type="table" coords="7,97.70,357.43,10.03,8.99">12</ref> above: Retrieval results for topic translation using both MT systems with summary-based expansion term selection from pilot collection and cfw(i) from test collection Table <ref type="table" coords="7,98.06,472.26,8.57,8.99">13</ref>: Retrieval results for topic translation using merged queries from both MT systems with summarybased expansion term selection from test collection and cfw(i) from test collection. Results for Spanish bilingual runs (Table <ref type="table" coords="8,241.94,350.59,8.91,8.99">11</ref>-16) show that Globalink translated topics gave better performance overall compared to results using Babelfish translated topics. The Spanish to English pair using summary-based expansion term selection from pilot collection and cfw(i) from test collection gave the best results overall.</p><p>Combining the queries from the two MT systems (Table <ref type="table" coords="8,305.27,385.03,10.00,8.99">13</ref> and<ref type="table" coords="8,336.37,385.03,8.89,8.99">14</ref>) is again shown to be effective in reducing degradation in performance brought about by poor MT output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Further Runs</head><p>Query expansion and term weighting from a pilot collection has been shown to be very effective in information retrieval. The results above however suggests otherwise. This is probably due to the differences in the language of the pilot and the test collection. To test this theory, we did some further runs; the pilot and the test collection were merged to form a single collection. This merged collection was then used as the pilot collection, i.e. for query expansion and term weighting. The expanded query and the corresponding weight is then applied on the test collection. The tables below show the effect of this method on retrieval. In all cases we present the result for both Systran and Globalink translated topics. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,96.11,577.49,428.42,8.99;9,96.15,589.01,389.36,8.99;9,485.52,586.85,6.48,5.83;9,495.48,589.01,29.05,8.99;9,96.15,600.53,428.48,8.99;9,96.15,612.05,131.55,8.99" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,374.41,577.49,150.12,8.99;9,96.15,589.01,280.55,8.99">A Comparison of Query Translation Methods for English-Japanese Cross-Language Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">H</forename><surname>Collier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kumano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Sumita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,395.85,589.01,89.66,8.99;9,485.52,586.85,6.48,5.83;9,495.48,589.01,29.05,8.99;9,96.15,600.53,377.90,8.99">Proceedings of the 22 nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 22 nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="269" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,96.17,623.57,428.36,8.99;9,96.15,635.09,207.86,8.99;9,303.98,632.92,5.04,5.83;9,314.65,635.09,209.97,8.99;9,96.15,646.49,372.45,8.99" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,225.88,623.57,298.65,8.99;9,96.15,635.09,88.22,8.99">Phrasal Translation and Query Expansion Techniques for Cross-Language Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,207.84,635.09,96.18,8.99;9,303.98,632.92,5.04,5.83;9,314.65,635.09,209.97,8.99;9,96.15,646.49,207.25,8.99">Proceedings of the 20 th Annual International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 20 th Annual International ACM SIGIR conference on Research and Development in Information Retrieval<address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="84" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,96.12,658.01,428.53,8.99;9,96.15,669.53,260.21,8.99" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,211.88,658.01,242.58,8.99">Improving Retrieval performance by Relevance Feedback</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,464.27,658.01,60.38,8.99;9,96.15,669.53,167.29,8.99">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="page" from="288" to="297" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,96.09,681.04,428.56,8.99;9,96.15,692.56,204.47,8.99;9,300.62,690.40,5.04,5.83;9,311.41,692.56,213.21,8.99;9,96.15,704.08,364.51,8.99" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,265.43,681.04,259.22,8.99;9,96.15,692.56,83.61,8.99">Applying Summarization Techniques for Term Selection in Relevance Feedback</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Lam-Adesina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,204.10,692.56,96.53,8.99;9,300.62,690.40,5.04,5.83;9,311.41,692.56,213.21,8.99;9,96.15,704.08,207.20,8.99">Proceedings of the 24 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 24 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New Orleans</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,96.12,715.48,428.36,8.99;9,96.15,727.00,428.42,8.99;9,96.15,738.52,268.47,8.99;9,142.95,132.45,27.47,8.99;9,258.78,132.45,47.10,8.99;9,370.69,132.45,57.36,8.99;9,142.95,144.47,51.11,8.96;9,142.95,155.99,68.88,8.96;9,229.34,144.45,21.43,8.99;9,269.90,144.45,25.14,8.99;9,312.73,144.45,56.85,8.99;9,386.91,144.45,25.14,8.99;9,429.74,144.45,20.44,8.99;9,142.95,167.98,32.69,8.96;9,234.37,167.98,15.05,8.96;9,266.88,167.98,66.07,8.96;9,351.37,167.98,15.05,8.96;9,383.88,167.98,66.07,8.96;9,142.95,179.98,26.72,8.96;9,234.40,179.98,15.05,8.96;9,269.43,179.98,25.96,8.96;9,312.89,179.98,20.09,8.96;9,351.40,179.98,15.05,8.96;9,386.43,179.98,25.96,8.96;9,429.89,179.98,20.09,8.96;9,142.95,191.98,28.94,8.96;9,234.46,191.98,15.05,8.96;9,269.48,191.98,25.94,8.96;9,312.92,191.98,20.08,8.96;9,351.41,191.98,15.05,8.96;9,386.43,191.98,25.94,8.96;9,429.87,191.98,20.08,8.96;9,142.95,215.98,30.56,8.96;9,234.40,215.98,15.05,8.96;9,266.90,215.98,66.06,8.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,253.84,715.48,270.64,8.99;9,96.15,727.00,77.98,8.99">Exeter at CLEF 2001: Experiments with Machine Translation for Bilingual Retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Lam-Adesina</surname></persName>
		</author>
		<idno>.13% 2151 392 15.29% 2083 Italian 345 4.23% 2097 359 5.90% 2070 French 383 7.28% 2186 407 7.96% 2288 English 443 19.41% 2384</idno>
	</analytic>
	<monogr>
		<title level="m" coord="9,198.09,727.00,326.48,8.99;9,96.15,738.52,97.40,8.99">Proceedings of the CLEF 2001: Workshop on Cross-Language Information Retrieval and Evaluation</title>
		<meeting>the CLEF 2001: Workshop on Cross-Language Information Retrieval and Evaluation<address><addrLine>Darmstadt, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Systran MT Globalink MT Merged coll</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="59" to="77" />
		</imprint>
	</monogr>
	<note>terms and weight Avep % chg R-ret Avep % chg R-ret German 358 20</note>
</biblStruct>

<biblStruct coords="10,96.11,73.06,428.43,8.99;10,96.15,84.57,232.83,8.99;10,328.93,82.41,5.04,5.83;10,337.21,84.57,187.34,8.99;10,96.15,95.97,345.01,8.99" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,237.03,73.06,287.51,8.99;10,96.15,84.57,125.31,8.99">Some simple effective approximations to the 2-Poisson model for probabilistic weighted retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,240.03,84.57,88.95,8.99;10,328.93,82.41,5.04,5.83;10,337.21,84.57,187.34,8.99;10,96.15,95.97,219.71,8.99">Proceedings of the 17 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 17 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Dublin</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,443.71,95.97,30.12,8.99" xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C M</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,96.14,107.49,295.45,8.99" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,147.78,107.49,129.28,8.99">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,283.39,107.49,32.19,8.99">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="10" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,96.17,119.01,428.39,8.99;10,96.15,130.53,80.70,8.99" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,144.33,119.01,192.53,8.99">The Automatic Creation of Literature Abstracts</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">P</forename><surname>Luhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,344.24,119.01,175.65,8.99">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="165" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,96.14,142.05,405.34,8.99" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,168.93,142.05,157.87,8.99">New Methods in Automatic Abstracting</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">P</forename><surname>Edmundson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,333.43,142.05,76.14,8.99">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="264" to="285" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,96.07,153.57,428.55,8.99;10,96.15,164.97,93.43,8.99;10,189.63,162.80,4.32,5.83;10,198.86,164.97,325.77,8.99;10,96.15,176.49,239.13,8.99" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,227.19,153.57,282.18,8.99">The Advantages of Query-Biased Summaries in Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tombros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,96.15,164.97,93.43,8.99;10,189.63,162.80,4.32,5.83;10,198.86,164.97,325.77,8.99;10,96.15,176.49,85.02,8.99">proceedings of the 21 st Annual International ACM SIGIR Conference Research and Development in Information Retrieval</title>
		<meeting>the 21 st Annual International ACM SIGIR Conference Research and Development in Information Retrieval<address><addrLine>Melbourne</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="2" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,96.13,188.01,406.01,8.99" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,161.43,188.01,151.07,8.99">On term selection for query expansion</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,319.33,188.01,101.85,8.99">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="359" to="364" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,96.07,199.52,428.59,8.99;10,96.15,211.04,218.06,8.99" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,259.09,199.52,153.81,8.99">Relevance weighting of search terms</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,421.69,199.52,102.97,8.99;10,96.15,211.04,125.75,8.99">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="129" to="146" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,96.12,222.56,428.33,8.99;10,96.15,233.96,428.44,8.99;10,96.15,245.48,207.61,8.99" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,297.26,222.56,227.19,8.99;10,96.15,233.96,65.36,8.99">Okapi at TREC-7: automatic ad hoc, filtering, VLS and interactive track</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,354.45,233.96,170.15,8.99;10,96.15,245.48,86.70,8.99">Overview of the Seventh Text REtrieval Conference (TREC-7)</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="253" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,96.11,257.00,428.41,8.99;10,96.15,268.52,336.06,8.99;10,432.24,266.35,5.04,5.83;10,441.72,268.52,82.87,8.99;10,96.15,280.04,296.30,8.99" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,256.61,257.00,267.91,8.99;10,96.15,268.52,235.15,8.99">Combination Methods for improving the Reliability of Machine Translation Based Cross-Language Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Lam-Adesina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,339.65,268.52,92.56,8.99;10,432.24,266.35,5.04,5.83;10,441.72,268.52,82.87,8.99;10,96.15,280.04,176.49,8.99">Proceedings of the 13 th Irish Conference on Artificial Intelligence and Cognitive Science</title>
		<meeting>the 13 th Irish Conference on Artificial Intelligence and Cognitive Science</meeting>
		<imprint>
			<date type="published" when="2002-09">September 2002</date>
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
