<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,148.08,115.96,319.20,12.62;1,172.85,133.89,269.67,12.62;1,177.68,151.82,259.99,12.62">OAUC at CLEF2016 SBS Lab: Using Appeal Elements to Improve Automatic Book Recommendation -Proof of Concept</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,216.08,189.51,82.11,8.74"><forename type="first">Michael</forename><surname>Preminger</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Akershus University College of Applied Science</orgName>
								<address>
									<settlement>Oslo</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,325.35,189.51,69.45,8.74"><forename type="first">Gjertrud</forename><surname>Fludal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Akershus University College of Applied Science</orgName>
								<address>
									<settlement>Oslo</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,148.08,115.96,319.20,12.62;1,172.85,133.89,269.67,12.62;1,177.68,151.82,259.99,12.62">OAUC at CLEF2016 SBS Lab: Using Appeal Elements to Improve Automatic Book Recommendation -Proof of Concept</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B29652E150DB3DC8FCC48522DE68066F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this article we describe the OAUC's participation in the CLEF 2016 SBS Search Suggestion track. We are trying to represent appeal elements, used in readers' advisory theory and practice, to see if they can be used in an automatic retrieval and recommendation context. We are still working with the pace appeal element, used in fiction to capture how quickly the buildup of the story or the plot is. New this year is the use of intellectually coded appeal-element data done by EBSCO as part of the NoveList R service (our gratitude to EBSCO for providing the data).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As pointed out in <ref type="bibr" coords="1,217.96,396.90,9.96,8.74" target="#b0">[1]</ref>, There are many qualities to books besides their formal characteristics, such as title, author and subject (the latter being examples of metadata). Books, particularly fiction, also evoke the readers' emotions, which is arguably their major mission. This article continues our exploration of how the emotion-evoking as well as other subtle qualities can be discovered in user generated data and subsequently used in a system for automatic classification of books, as a part of an automatic recommender system. For this year's task we are still focusing on the pace subtle element. The challenge is twofold: try to identify certain emotion waking characteristics of books, and measure whether identification of such characteristics helps us match readers' wishes based on similar characterization of their recommendation requests. We are working on operationalizing the pace using document model creation as well as occurrences of adjectives / adjective types in fast-paced vs. leisurely-paced books.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Theoretic Approach and related work</head><p>Emotion evoking characteristics are properties of books that are not usually a part of the metadata, technically, because they are difficult to trace back. Even though most people might agree on one or the other subtle property of a book, there is potential for dispute</p><p>In addition to Saricks work on appeal elements <ref type="bibr" coords="1,353.14,644.16,9.96,8.74" target="#b1">[2]</ref>, introduced in <ref type="bibr" coords="1,429.29,644.16,9.96,8.74" target="#b0">[1]</ref>, a couple of works following it up are definately worth mentioning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Saricks framework of appeal</head><p>[2] has developed a framework / terminology that enables librarians, or other reading-promotors, to discuss books through short excerpts, user reviews and the like, boiling down to "appeal". Appeal has a number of elements Pace According to Saricks, pace is the most important appeal-element, and has the best potential of distinguishing potential readers. Pace has to do with the build up of the story / plot in a book, and how quickly the reader is drawn into it. Some readers (in some situations) will prefer fast paced books, other will rather endeavour on a slow-paced book. <ref type="bibr" coords="2,330.14,242.65,10.52,8.74" target="#b2">[3]</ref> also have a pace value they call "Intensifying", for which we do not have any books in our database.</p><p>Characterization This element has to do with the introversy or extroversy of the characters in the book. Readers often remember the characters in the book more easily than they remember the plot. Alas, the conception of a well developed character varies greatly among users<ref type="foot" coords="2,297.69,319.85,3.97,6.12" target="#foot_0">1</ref> , making this element less hospitable to analysis of appeal than the case is for the pace element.</p><p>Frame The frame is about the tone of a book (melancholic, positive), its feeling (funny or romantic), and its atmosphere (menacing or elevating). though difficult to define, this element is often decisive for the reader's choice. The book can be amusing, bleak, bittersweet <ref type="foot" coords="2,253.63,398.61,3.97,6.12" target="#foot_1">2</ref>Storyline The storyline is of course dependent on the previously discussed elements. But typical values<ref type="foot" coords="2,257.06,441.51,3.97,6.12" target="#foot_2">3</ref> will be Issue-oriented, Nonlinear or Open-ended.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Representing and modelling appeal elements</head><p>The appeal elements are not directly manifest in the book text, let alone its metadata, and we need to find some representation so that a recommender system can take them into account. To this end we need to find some manifest indicators that can automatically match a recommendation request and a book using the appeal elements as evidence (in addition to other evidence), when recommending a book based on this recommendation request.</p><p>Finding and using such indicators is a challenge, which character differs among the elements. Being metadata of different kinds rather than full content, the texts we have are sparse, but on the other hand (for a portion of the books) include reader reviews, which should be a condense summarization of the book done by readers, the target group of a recommender system. One way of implicitly representing an appeal element (element-name elementvalue) is, using occurrences of sentences that are characteristic to some value of an appeal element. Feeding these to a Natural Language Processing-system, the NLP system may identify functionally similar sentences in any analyzed bookreview to use in the classification of the books. In our implementation, a model of an appeal element is a summary of sentences that are likely to appear in a review of a book that has this value (or valence) of this element. This method has a potential for accuracy, but needs quite a large set of reader reviews given to books with known values (and valences) of the appeal element, and is extremely prone to overfitting. A simpler but less exact method will be identifying single words or word combinations, particularly adjectives used by readers when reviewing books of different values / valences of appeal elements. Such words need somehow to be classified, so that a system looking for appeal elements in reviews has a broader repertoire of words to look for than the one occurring in the training set.</p><p>Matching can thereafter be done by attempted applying the same, or a slightly different model to the recommendation request, assuming that a recommendation request and a review belong to the same genre. Here we have several options:</p><p>-Retrieving books by a traditional retrieval model (using text-based metadata elements for matching) and then reranking so that books with appeal element values matching that of the request, rank ahead of other books -Weighing up books with matching appeal at retrieval time -Traditional retrieval accompanied by pseudo relevance feedback based on the appeal models.</p><p>As our current main experimentation line is around pace, we will be more detailed discussing pace, than the other elements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Pace</head><p>Pace can be seen as a binary variable, either "High-paced" ("Fast-paced" in NoveList terminology) or "Low-Paced" ("Leisurely-paced"), making it the easiest element to model and represent, but at the same time less controllable. Saricks poses some questions the answers to which may provide clues as to the pacing:</p><p>-Is the book densely written? -Are there short sentences / short paragraphs, short chapters? -Is there a straight line plot 3 Related work and our approach Our work belongs in the realm of content based recommender systems, like for example <ref type="bibr" coords="3,173.65,644.16,9.96,8.74" target="#b3">[4]</ref>. The main advantage of such systems is their independence of users and their history of reading and recommendations. As such, these system have Saricks' framework is reportedly being extensively used in libraries, and in recent years it is starting to gain more systematic use, prominently in a Reader's Advisory resource like NoveList. NoveList<ref type="foot" coords="4,312.82,327.93,3.97,6.12" target="#foot_3">4</ref> is a paid service by EBSCO, marketed towards Reader Advisory (RA) services of libraries, active since the late 90's. Among other book characteristics used for recommendation, They have, since 2010 also been recording and utilizing Saricks appeal elements.</p><p>In a more research-related context, <ref type="bibr" coords="4,305.23,377.73,10.52,8.74" target="#b4">[5]</ref> has developed a conceptual approach (guiding the current research), of using Saricks elements in book recommendations. As a part of a Phd-work, <ref type="bibr" coords="4,293.37,401.64,10.52,8.74" target="#b5">[6]</ref> have experimented with automatic extraction of appeal elements from reviews using rules related to occurrences / co-ocurrences of types of words from reader reviews. Both the design approach and the evaluation approach are quite straight forward. The appeal element extraction is a combination of a finite list of words (mostly adjectives) expanded by wordnet-extracted synonyms, and rules for these words' occurrence in the sentences of a review. The rules analyse governor -subordinate relations between pairs of words.</p><p>Interestingly, <ref type="bibr" coords="4,208.51,504.45,10.52,8.74" target="#b5">[6]</ref> have assessed the quality of their ABET extractor by directly comparing its performance to NoveList's recommendations using appraisals by Amazon Mechanical Turk workers as the gold standard, finding ABET more accurate. They also compared the performance their entire system Rabbit (of which ABET is a component) to other recommendation services by using Mechanical Turk appraisers as gold standard when choosing new books that "best relate" to each one from a sample of ten books. The evaluation strategy taken here is very practical, and the results certainly promising. Still we feel that our challenge here is different, as we wish to match books with recommendation requests (not having other books to relate our recommendations to), and we therefore feel that we need to take a slightly more general approach, which is based on a broader classification of Parts of Speech, particularly adjectives.</p><p>Resembling <ref type="bibr" coords="5,201.70,118.99,9.96,8.74" target="#b5">[6]</ref>, we will also need to take a part / whole approach, trying to see (a) whether our NLP-classification has the potential to elicit individual appeal elements (b) whether it is possible to classify recommendation requests the same way as user reviews (whether or not those two types belong to the same genre) and (c) whether correct identification indeed gives us better recommendations on the basis of textual recommendation requests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data, Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Our Data</head><p>The SBS Suggestion Track's (SST) data consist of metadata drawn from Li-braryThing and Amazon, describing about 2,8 million books, keyed by their ISBN (meaning the number of distinct works is somewhat lower, as ISBN keys manifestations of works). About half of these, (over 1.3 millions) have reader reviews as a part of their metadata. It is these reviews (free texts) that constitute the most important data of this paper.</p><p>In order to prepare the data to adjective based analysis, we have so far been taking the following steps:</p><p>-POS-tagging of all free texts of the reviews using the Apache OpenNlp<ref type="foot" coords="5,461.18,351.90,3.97,6.12" target="#foot_4">5</ref> -Collecting all adjectives, basic (&lt; JJ &gt;), comparative (&lt; JJR &gt;) and superlative (&lt; JJS &gt;) normalizing the adjective-forms captured by the POS-tagger, and linking each review to the normalized forms of the adjectives.</p><p>As we were preparing this year's experiments, based on the approach we have taken, we have seen that the crunching of the data for preparing the adjectivebased is extremely time-consuming and at the moment of writing the data are still in the preparation stage. Therefore we will, in this paper, limit ourselves to experiments based on document categorization.</p><p>In addition, we have also, with great gratitude, obtained EBSCO NoveList data, categorizing books into value-categories based on several appeal elements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Our Purpose and Overall Research Design</head><p>As an overall, guiding design principle when approaching this issue, we intend to assign values or valences of appeal elements to unseen books (represented by their respective review texts), based on intellectually assigned values to a subset of the books, and building models based on reviews of the latter ones as described in the following subsections. We conduct a traditional text based search into an index created by selected parts of the metadata, and rerank the result so that books with appeal elements that match the appeal element of the request are assigned higher prominence in the result set, as depicted in Figure <ref type="figure" coords="5,134.77,640.02,3.87,8.74">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 2. Overall experiment design</head><p>Training the models The most straight-forward way of training appeal-element categorizers based on existing NLP-tools, is using reviews of books with known values (previously assigned by experts) to build document-categorization models, that can use reviews of unseen books (where available) to classify those into appropriate categories (low vs. high valence, different intervals of element values a.s.o). Classifying the recommendation requests as described in the previous section, can provide us with an additional piece of evidence when matching those requests to books.</p><p>In the pace case, with two mutually exclusive values, we are using the Apache OpenNLP (https://opennlp.apache.org/) Document Categorizer tool(https: //opennlp.apache.org/documentation/1.6.0/manual/opennlp.html#tools. doccat) in order to train a number of models for the ability to distinguish (unseen) Fast-paced from Leisurely-paced books by their review texts. The trained models differ by the number of training reviews (respectively 50, 75, 100, 150, 200, 250, 300, 400, 500, 750 and 1000 of each kind, respectively, 2000 reviews used to build the largest model), in order to find out the dependence of the ability to discriminate fast or leisurely paced books on the model size (number of reviews). The 2000 books (1000 of each value) comprising the largest model, constitute a superset of all the other training sets (See illustration in Figure <ref type="figure" coords="6,134.77,582.33,16.24,8.74" target="#fig_2">3(a)</ref>). We use the remaining NoveList pace-categorized books as a test set.</p><p>In Figure <ref type="figure" coords="6,194.61,596.34,4.56,8.74" target="#fig_2">3</ref>(b) we show the prediction power of the model as a function of the number of documents in the training set used to create it. It is interesting to see the trendwise increase in prediction power as a function of the size of the model. This indicates the soundness of the approach, meaning that the pace element tells something about the book, and that the reader review entails a kind of a representation of the pace value. Also interesting is the better prediction of the leisurely-paced books. This ows to the fact that in this case the test set is closer in size to the training set, so more of the variability of the latter is represented in the former. Paradoxically this also indicates the overall soundness of the approach. We stress that the categorizer is used with default settings, and that work still remains fine-tuning the tool for the categorization task.  ranking documents with traditional retrieval methods reranking afterwords by matching the paces of the recommendation request and the book reviews</p><p>The assumption is that the pace is additional evidence in the ranking process for recommendation satisfaction, and its affect is best measured at the primary part of the ranking list. We reorder the first n ranked documents returned for each topic, so that documents which pace value matches that of the request (as predicted by the procedure described below), are promoted to the top of the list, keeping their mutual order as in the original list, to that end using a stable sort. For the task of determining the pace of the topic itself, two approaches have been tested:</p><p>-Predicting the values of the works attached to the topic in the topic set and applying a majority vote of those as the request value (Figure <ref type="figure" coords="7,425.51,632.13,4.32,8.74" target="#fig_4">4</ref>(a)) -Treating the request text as a review text and predicting its value directly.</p><p>(Figure <ref type="figure" coords="7,187.01,656.12,4.43,8.74" target="#fig_4">4</ref>(b))</p><p>As the direct prediction strategy (the second above) gives better results in the current experiments, we only report the results of this strategy in the present paper, but hold the other strategy viable for later experiments. The attached work approach (first item above) also has the weakness that not all works attached to the topic have reader reviews associated with them.</p><p>Pace as evidence Appeal elements, pace among these, are expected to serve as evidence, contributing to the successful recommendation. One way of finding out the optimal contribution would be to rerank upper sublists of various lengths of the original ranked list so that works whose pace match the request pace (predicted by the direct approach from previous section) and measure the performance of these reranked lists up against that of the original list (baseline).</p><p>As seen in Figure <ref type="figure" coords="8,227.51,282.73,3.87,8.74" target="#fig_5">5</ref>, reranking only the sublists n=5-20 performs better than the baseline (level of evidence 0), whereas reranking longer parts of the list gives unpredictable results, introducing many books with matching pace but otherwise irrelevant to the recommendation request.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>As already explained, we see this as a continuous research endeavor, where the purpose is to directly utilize appeal elements in generating better recommendations based on recommendation requests. We have started out trying to model the pace appeal element in both books' reader reviews and the topics (recommendation requests), trying to see if matching those can give better recommendations. The result so far are promising in that they seem to indicate the overall soundness of the approach, but a better baseline would be needed to test the approach under more realistic conditions.</p><p>We have so far been using the document categorization strategy as proposed by <ref type="bibr" coords="8,147.90,486.27,10.52,8.74" target="#b4">[5]</ref> and <ref type="bibr" coords="8,179.70,486.27,9.96,8.74" target="#b0">[1]</ref>. The next endeavour is based on occurrence of adjectives in reviews (indirectly inspired by <ref type="bibr" coords="8,234.78,498.23,10.30,8.74" target="#b5">[6]</ref>).</p><p>Owing to the relatively large collection of pace values intellectually assigned to books, that we obtained from EBSCO, The current results are remarkably better than the 2015 results. Further use of the data, combining also other appeal elements than pace, indicate that the potential is far from exhausted.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,196.62,215.21,222.13,8.77;4,137.60,115.84,340.15,85.04"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Characteristics of the pace appeal elements</figDesc><graphic coords="4,137.60,115.84,340.15,85.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,147.35,349.94,105.34,7.86;7,147.35,360.90,32.31,7.86;7,290.95,349.94,167.14,7.86"><head></head><label></label><figDesc>(a) The EBSCO NoveList pace-set (b) Prediction power as a function of size</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,145.54,384.79,324.27,8.77;7,147.35,203.37,105.33,141.73"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The prediction power of the model in terms of prediction precision</figDesc><graphic coords="7,147.35,203.37,105.33,141.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,221.18,363.14,173.00,7.86;9,226.54,571.55,162.28,7.86"><head></head><label></label><figDesc>(a) Pace predicted through attached works (b) Pace directly predicted from request</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="9,167.09,595.94,281.18,8.77;9,216.41,382.47,182.53,184.25"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Overall design -two strategies of predicting request pace</figDesc><graphic coords="9,216.41,382.47,182.53,184.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="10,134.77,301.00,345.83,8.77;10,166.39,115.83,282.58,170.09"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Performance based on level of evidence (length of reordered upper sublist)</figDesc><graphic coords="10,166.39,115.83,282.58,170.09" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,634.88,226.05,7.86"><p><ref type="bibr" coords="2,144.73,634.88,9.73,7.86" target="#b2">[3]</ref> lists 30 types of characters that can appear in fiction</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,645.84,125.61,7.86"><p><ref type="bibr" coords="2,144.73,645.84,9.64,7.86" target="#b2">[3]</ref>lists 58 categories of "Tone".</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,144.73,656.80,109.03,7.86"><p><ref type="bibr" coords="2,144.73,656.80,9.73,7.86" target="#b2">[3]</ref> lists 9 types of storyline</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,144.73,657.44,160.05,7.47"><p>https://www.ebscohost.com/novelist</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,144.73,657.44,127.10,7.47"><p>https://opennlp.apache.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,138.35,612.57,342.25,7.86;8,146.91,623.53,333.68,7.86;8,146.91,634.49,239.08,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,286.25,612.57,194.35,7.86;8,146.91,623.53,64.40,7.86">Oauc&apos;s participation in the clef2016 sbs search suggestion track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Fugleberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Preminger</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org(2015" />
	</analytic>
	<monogr>
		<title level="m" coord="8,235.46,623.53,245.13,7.86;8,146.91,634.49,68.45,7.86">Working Notes of CLEF 2015 -Conference and Labs of the Evaluation forum</title>
		<imprint>
			<biblScope unit="volume">1391</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,645.84,342.24,7.86;8,146.91,656.80,108.03,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,192.11,645.84,185.75,7.86">Readers&apos; Advisory Service in the Public Library</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Saricks</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>American Library Association</publisher>
		</imprint>
	</monogr>
	<note>ALA editions</note>
</biblStruct>

<biblStruct coords="10,138.35,336.84,342.24,7.86;10,146.91,347.80,333.68,7.86;10,146.91,358.76,333.68,8.12;10,146.91,369.71,214.35,7.86" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Caplinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Coleman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Coulter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kage</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Keyser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Reaser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Young</surname></persName>
		</author>
		<ptr target="http://www.ebsco.com/promo/novelist-the-secret-language-of-books" />
		<title level="m" coord="10,280.63,347.80,195.84,7.86">The secret language of books, a guide to appeal</title>
		<imprint>
			<date type="published" when="2015-07-11">2015. 2015-07-11</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,380.67,342.25,7.86;10,146.91,391.61,333.68,7.89;10,146.91,402.59,72.45,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,352.30,380.67,128.29,7.86;10,146.91,391.63,192.25,7.86">Informed recommender: Basing recommendations on consumer product reviews</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Aciar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Simoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Debenham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,349.11,391.63,105.40,7.86">Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="39" to="47" />
			<date type="published" when="2007-05">May 2007</date>
		</imprint>
	</monogr>
	<note>IEEE</note>
</biblStruct>

<biblStruct coords="10,138.35,413.55,342.25,7.86;10,146.91,424.51,246.25,7.86" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Fugleberg</surname></persName>
		</author>
		<title level="m" coord="10,216.06,413.55,264.54,7.86;10,146.91,424.51,29.16,7.86">Automatisk klassifikasjon av bker basert p brukeranmeldelser: Et konsept</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
		<respStmt>
			<orgName>Hgskolen i Oslo og Akershus</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct coords="10,138.35,435.47,342.24,7.86;10,146.91,446.43,333.68,7.86;10,146.91,457.39,248.86,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,234.39,435.47,246.21,7.86;10,146.91,446.43,63.89,7.86">Automating readers&apos; advisory to make book recommendations for k-12 readers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Pera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">K</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,237.16,446.43,243.43,7.86;10,146.91,457.39,80.67,7.86">Proceedings of the 8th ACM Conference on Recommender Systems. RecSys &apos;14</title>
		<meeting>the 8th ACM Conference on Recommender Systems. RecSys &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
