<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,145.01,116.95,325.35,12.62;1,164.40,134.89,286.57,12.62">Erasmus MC at CLEF eHealth 2016: Concept Recognition and Coding in French Texts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,154.88,172.84,91.95,8.74"><forename type="first">Erik</forename><forename type="middle">M</forename><surname>Van Mulligen</surname></persName>
							<email>e.vanmulligen@erasmusmc.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,254.66,172.84,53.35,8.74"><forename type="first">Zubair</forename><surname>Afzal</surname></persName>
							<email>m.afzal@erasmusmc.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,315.58,172.84,76.41,8.74"><forename type="first">Saber</forename><forename type="middle">A</forename><surname>Akhondi</surname></persName>
							<email>s.ahmadakhondi@erasmusmc.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,400.28,172.84,36.03,8.74"><forename type="first">Dang</forename><surname>Vo</surname></persName>
							<email>v.dang@erasmusmc.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,281.14,184.80,53.08,8.74"><forename type="first">Jan</forename><forename type="middle">A</forename><surname>Kors</surname></persName>
							<email>j.kors@erasmusmc.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,145.01,116.95,325.35,12.62;1,164.40,134.89,286.57,12.62">Erasmus MC at CLEF eHealth 2016: Concept Recognition and Coding in French Texts</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AF796F5FA8C8F16264FF2E586061BFB5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Entity recognition</term>
					<term>Concept identification</term>
					<term>ICD-10 Coding</term>
					<term>Term translation</term>
					<term>French terminology</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We participated in task 2 of the CLEF eHealth 2016 challenge. Two subtasks were addressed: entity recognition and normalization in a corpus of French drug labels and Medline titles, and ICD-10 coding of French death certificates. For both subtasks we used a dictionary-based approach. For entity recognition and normalization, we used Peregrine, our open-source indexing engine, with a dictionary based on French terms in the Unified Medical Language System (UMLS) supplemented with English UMLS terms that were translated into French with automatic translators. For ICD-10 coding, we used the Solr text tagger, together with one of two ICD-10 terminologies derived from the task training material. To reduce the number of false-positive detections, we implemented several post-processing steps. On the challenge test set, our best system obtained F-scores of 0.702 and 0.651 for entity recognition in the drug labels and in the Medline titles, respectively. For entity normalization, F-scores were 0.529 and 0.474. On the test set for ICD-10 coding, our system achieved an F-score of 0.848 (precision 0.886, recall 0.813). These scores were substantially higher than the average score of the systems that participated in the challenge.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The CLEF eHealth Evaluation Lab 2016 task 2 consisted of two main subtasks <ref type="bibr" coords="1,470.07,561.47,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="1,134.77,573.43,7.01,8.74" target="#b1">2]</ref>: recognition and normalization of entities in a French biomedical corpus, and coding of French death certificates. The entity normalization had to be based on the Unified Medical Language System (UMLS) <ref type="bibr" coords="1,363.36,597.34,9.96,8.74" target="#b2">[3]</ref>, and involved assigning UMLS concept unique identifiers (CUIs) to the recognized entities. This task was also used in CLEF eHealth 2015 <ref type="bibr" coords="1,296.99,621.25,9.96,8.74" target="#b3">[4]</ref>. The coding task was new and involved the assignment of codes from the International Classification of Diseases, version 10 (ICD-10) <ref type="bibr" coords="1,191.44,645.16,10.52,8.74" target="#b4">[5]</ref> to the death certificates. Both tasks had to be performed fully automatically.</p><p>We addressed these tasks using dictionary-based indexing approaches. For entity recognition and normalization we used the system that we developed for the same task in the CLEF eHealth 2015 challenge <ref type="bibr" coords="2,385.84,143.90,9.96,8.74" target="#b5">[6]</ref>, but we trained it on the data that was made available in this year's challenge. Central in our approach is indexing with French terminologies from the UMLS supplemented with automatically translated English UMLS terms, followed by several postprocessing steps to reduce the number of false-positive detections. For ICD-10 coding, we used a terminology that was constructed based on the training data and again applied post-processing to improve precision. We describe our systems and their evaluation for each subtask. On the test data, our results for both tasks are well above the average performance of the systems that participated in the CLEF eHealth 2016 task 2 challenge <ref type="bibr" coords="2,297.40,251.50,9.96,8.74" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>In the following, we describe the corpora, terminologies, indexing, and postprocessing steps separately for each subtask..</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Corpora</head><p>Entity recognition and normalization. The training and test data are based on the Quaero medical corpus, a French annotated resource for medical entity recognition and normalization <ref type="bibr" coords="2,273.68,398.44,9.96,8.74" target="#b6">[7]</ref>. The Quaero corpus consists of three subcorpora: titles from French Medline abstracts, drug labels from the European Medicines Agency (EMEA), and patents from the European Patent Office. For the CLEF eHealth challenge, only Medline titles and EMEA documents were made available. The annotations in the Quaero corpus are based on a subset of the UMLS. An entity in the Quaero corpus was only annotated if the concept belonged to one of the following ten semantic groups (SGs) in the UMLS: Anatomy, Chemicals and drugs, Devices, Disorders, Geographic areas, Living beings, Objects, Phenomena, Physiology, and Procedures. Nested or overlapping entities were all annotated, as were ambiguous entities (i.e., if an entity could refer to more than one concept, all concepts were annotated). Also discontinuous spans of text that refer to a single entity could be annotated.</p><p>Coding. The data set for the coding of death certificates is called the CépiDC corpus. Each certificate consists of one or more lines of text and some metadata, including age and gender of the deceased, and location of death. The training set contained 65,843 certificates from the period 2006 to 2012, and the test set contained 27,850 certificates from 2013.</p><p>The annotations in the CépiDC corpus consist of codes from the ICD-10 and were assigned per text line. For each code that was assigned by the human coder, a term that supports the selection of the code was provided. This term was an excerpt of the text line or an entry of a coding dictionary (see below). Furthermore, the human coder provided for each code the duration that the deceased had been suffering from the coded cause, and a code rank with respect to the cause of death.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Terminologies</head><p>Entity recognition and normalization. We used the terminology that performed best in the CLEF eHealth 2015 concept recognition task <ref type="bibr" coords="3,415.19,249.16,9.96,8.74" target="#b5">[6]</ref>. This terminology was constructed from all French terms in the ten relevant SGs of UMLS version 2014AB (77,995 concepts with 161,910 terms). To increase the coverage of this baseline terminology, English UMLS terms were automatically translated into French. We used two translators, Google Translate (GT) <ref type="bibr" coords="3,406.18,296.98,10.52,8.74" target="#b7">[8]</ref> and Microsoft Translator (MT) <ref type="bibr" coords="3,211.14,308.94,9.96,8.74" target="#b8">[9]</ref>, and only included terms that had the same translation in the baseline terminology. The resultant French terminology contained 136,127 concepts with 386,617 terms. Finally, we expanded the terminology with terms from concepts in the training set that were not recognized by our indexing system (false negatives).</p><p>Coding. For coding, we constructed two ICD-10 terminologies. A baseline terminology was made by compiling the terms corresponding with each annotated ICD-10 code in the training corpus. The number of times that each code had been assigned in the training corpus, was also determined. For ambiguous terms, i.e., terms that corresponded with more than one ICD-10 code, the term was removed for those codes that occurred less than half as often as the most frequent code with that term. A second, expanded terminology was based on the baseline terminology, but also incorporated codes and terms from four versions of a manually curated ICD-10 dictionary. These dictionary versions have been developed at the Centre d'épidémiologie sur les causes médicales de décès (CépiDC) <ref type="bibr" coords="3,134.77,504.03,15.50,8.74" target="#b9">[10]</ref> and were made available by the task organizers. They contained many additional ICD-10 codes and terms that were not present in the training corpus (and thus were lacking in the baseline terminology). If a term was present in both the baseline terminology and a CépiDC dictionary but the corresponding codes were different, the code in the dictionary version was not included in the expanded terminology to avoid introducing ambiguity. If the term in the baseline terminology was ambiguous (had multiple codes), only the term-code combinations in the baseline terminology that were also present in the CépiDC dictionary were incorporated in the expanded terminology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Indexing</head><p>Entity recognition and normalization. The Quaero corpus was indexed with Peregrine, our dictionary-based concept recognition system <ref type="bibr" coords="3,418.15,657.11,14.61,8.74" target="#b10">[11]</ref>. Peregrine removes stopwords (we used a small list of (in)definite articles and, for French, partitive articles) and tries to match the longest possible text phrase to a concept. It uses the Lexical Variant Generator tool of the National Library of Medicine to reduce a token to its stem before matching <ref type="bibr" coords="4,339.15,155.86,14.61,8.74" target="#b11">[12]</ref>. Peregrine is freely available <ref type="bibr" coords="4,134.77,167.81,14.61,8.74" target="#b12">[13]</ref>.</p><p>Peregrine can find partially overlapping concepts, but it cannot detect nested concepts (it only returns the concept corresponding with the longest term). We therefore implemented an additional indexing step. For each term found by Peregrine and consisting of n words (n &gt; 1), all subsets of 1 to n-1 words were generated, under the condition that for subsets consisting of more than one word, the words had to be adjacent in the original term. All word subsets were then also indexed by Peregrine. We did not try to find discontinuous terms since there frequency was very low.</p><p>Coding. For the coding task, we employed the open-source Solr text tagger <ref type="bibr" coords="4,134.77,306.40,14.61,8.74" target="#b13">[14]</ref>, using the ICD-10 terminologies to index the death certificates. Several preprocessing steps were performed, including stopword filtering (using the default Solr stopword list for French), ASCII folding (converting non-ASCII Unicode characters to their ASCII equivalents, if existing), elision filtering (removing abbreviated articles that are contracted with terms), and stemming (using the French Snowball stemmer). Words were matched case-insensitive, except for selected abbreviations that were expanded using a synonym list prior to matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Post-processing</head><p>Entity recognition and normalization. To reduce the number of falsepositive detections that resulted from the indexing, we applied several postprocessing steps. First, we removed terms that were part of an exclusion list. The list was manually created by indexing the French part of the Mantra corpus, a large multilingual biomedical corpus developed as part of the Mantra project <ref type="bibr" coords="4,168.79,489.56,14.61,8.74" target="#b14">[15]</ref>, and selecting the incorrect terms from the 2,500 top-ranked terms.</p><p>Second, for any term-SG-CUI combination and SG-CUI combination that was found by Peregrine in the training data, we computed precision scores: true positives / (true positives + false positives). For a given term, only term-SG-CUI combinations with a precision above a certain threshold value were kept. If multiple combinations qualified, only the two with the highest precision scores were selected. If for a given term none of the found term-SG-CUI combinations had been annotated in the training data, but precision scores were available for the SG-CUI combinations, a term-SG-CUI combination was still kept if the precision of the SG-CUI combination was higher than the threshold. If multiple combinations qualified, the two with the highest precision were kept if they had the same SG; otherwise, only the combination with the highest precision was kept. If none of the SG-CUI combinations had been annotated, a single term-SG-CUI combination was selected, taking into account whether the term was the preferred term for a CUI, and the CUI number (lowest first).</p><p>Coding. To reduce the number of false-positive codes that were generated during the indexing step, we computed a precision score for each term-code combination that was recognized by the Solr tagger in the training data: true positives / (true positives + false positives). All codes that resulted from term-code combinations with precision values below a given threshold value, were removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Entity recognition and normalization</head><p>We indexed the Quaero training data, and added the false-negative terms to our terminology. We then ran the system on the Quaero test data, and submitted two runs for both the entity recognition and normalization tasks: one run using the system a precision threshold of 0.3 (run1, this threshold was also used in our last-year's submission for the same task <ref type="bibr" coords="5,344.93,296.20,10.30,8.74" target="#b5">[6]</ref>), the other with a precision threshold of 0.4 (run2). Table <ref type="table" coords="5,267.84,308.15,4.98,8.74" target="#tab_1">1</ref> shows our performance results for exact match on the test set. As expected, run1 (the system with the lower precision threshold) has lower precision and higher recall than run2, but the differences are small and the Fscores are nearly identical. The results are well above the average and median of the scores from all runs of the challenge participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Coding</head><p>To determine the optimal precision threshold for the coding task, we split the CépiDC training data in two equally-sized sets. Precision scores were generated for all term-code combinations that were found using the expanded ICD-10 terminology in one half of the training data and were then used to filter the recognized term-code combinations in the other half of the training data. Table <ref type="table" coords="5,134.77,657.11,4.98,8.74" target="#tab_2">2</ref> shows the performance for different threshold values on the second half. Without precision filtering (threshold 0.0), an F-score of 0.773 (precision 0.732, recall 0.818) was obtained. The highest F-score (0.827) was achieved for a threshold of 0.4, mainly because precision greatly improved (0.863), while recall only slightly deteriorated (0.795). The same optimal threshold value was obtained when we used the baseline ICD-10 terminology.</p><p>We submitted two runs on the CépiDC test set, one using the expanded ICD-10 terminology (run1), the other using the baseline terminology (run2). For both runs, precision scores were derived from all the training data and the threshold for precision filtering was set at 0.4. Table <ref type="table" coords="6,370.98,418.60,4.98,8.74" target="#tab_3">3</ref> shows the performance of our system, together with the average and median performance scores of the runs of all task participants. Our results indicate that the baseline terminology (run2) performed slightly better than the expanded terminology (run1) in terms of F-score. Remarkably, the baseline terminology had higher recall than the expanded terminology. Overall, our performance results, in particular recall, are considerably better than the average and median score of all submitted runs. We retrained our system for entity recognition and normalization that we developed for the same task in the CLEF eHealth 2015 challenge, and newly developed a dictionary-based system for ICD-10 coding of death certificates. For both systems, the performance on the test sets proved to be substantially better than the averaged results of all systems that participated in the challenge <ref type="bibr" coords="7,436.22,192.00,9.96,8.74" target="#b1">[2]</ref>.</p><p>Our system for entity recognition and normalization performed better on the EMEA subcorpus than on the Medline subcorpus, primarily because of a higher recall. This is in line with the results for this task in the CLEF eHealth 2015 challenge <ref type="bibr" coords="7,177.40,239.88,9.96,8.74" target="#b3">[4]</ref>. However, whereas we had expected the performance of our system to be similar or even better than last year (because of the larger training set this year), results actually were worse, in particular for entity normalization <ref type="bibr" coords="7,450.17,263.79,9.96,8.74" target="#b5">[6]</ref>. We are currently investigating what may have caused this performance decrease.</p><p>The baseline and expanded ICD-10 terminologies that we developed for our coding system, produced almost similar F-scores. Remarkably, although the expanded terminology contained much more codes and terms than the baseline terminology, recall for the baseline terminology was slightly higher. A probable explanation is that the term disambiguation that we performed when expanding the baseline terminology with the ICD-10 dictionaries supplied by the task organizers, effectively prevented some term-code combinations seen in the training data from being included in the expanded terminology. Moreover, since the codes and terms in the baseline terminology were derived from a very large training set, there may have been few new codes and terms in the test set.</p><p>Our coding system achieved a very high precision of 0.886, with a recall of 0.813. Reasons for the lower recall include disambiguation errors, spelling mistakes and typos in the death certificates, and missing terms in the terminology. Also, we noticed that some gold-standard code annotations erroneously corresponded with a line that preceded or followed the line that contained the term to be coded, which resulted in false-negative detections (and possibly false-positive detections that were actually correct). Further improvement of our system may be possible by using better curated terminologies and applying spelling correction techniques.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,134.77,446.26,345.83,44.60"><head></head><label></label><figDesc>The training set consisted of 1665 Medline titles and 6 full EMEA documents (comprising the training and test data previously released in CLEF eHealth 2015); a new test set contained 834 Medline titles and 4 EMEA documents.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,139.81,350.31,335.73,127.69"><head>Table 1 .</head><label>1</label><figDesc>Entity recognition and normalization performance on the Quaero test set</figDesc><table coords="5,141.59,371.11,332.19,106.89"><row><cell></cell><cell cols="3">Entity recognition</cell><cell cols="3">Entity normalization</cell></row><row><cell>Corpus Submission</cell><cell cols="3">Precision Recall F-score</cell><cell cols="3">Precision Recall F-score</cell></row><row><cell>EMEA Run1</cell><cell>0.623</cell><cell>0.797</cell><cell>0.699</cell><cell>0.578</cell><cell>0.488</cell><cell>0.529</cell></row><row><cell>Run2</cell><cell>0.634</cell><cell>0.786</cell><cell>0.702</cell><cell>0.588</cell><cell>0.481</cell><cell>0.529</cell></row><row><cell>Average score</cell><cell>0.525</cell><cell>0.411</cell><cell>0.435</cell><cell>0.476</cell><cell>0.322</cell><cell>0.376</cell></row><row><cell>Median score</cell><cell>0.600</cell><cell>0.378</cell><cell>0.444</cell><cell>0.447</cell><cell>0.269</cell><cell>0.315</cell></row><row><cell>Medline Run1</cell><cell>0.617</cell><cell>0.690</cell><cell>0.651</cell><cell>0.562</cell><cell>0.410</cell><cell>0.474</cell></row><row><cell>Run2</cell><cell>0.623</cell><cell>0.678</cell><cell>0.649</cell><cell>0.568</cell><cell>0.404</cell><cell>0.472</cell></row><row><cell>Average score</cell><cell>0.503</cell><cell>0.426</cell><cell>0.446</cell><cell>0.501</cell><cell>0.376</cell><cell>0.429</cell></row><row><cell>Median score</cell><cell>0.617</cell><cell>0.438</cell><cell>0.498</cell><cell>0.493</cell><cell>0.383</cell><cell>0.431</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,134.77,116.91,345.82,160.57"><head>Table 2 .</head><label>2</label><figDesc>ICD-10 coding performance on half of the CépiDC training set for different precision-score thresholds</figDesc><table coords="6,230.27,148.67,154.81,128.81"><row><cell></cell><cell cols="3">ICD-10 coding</cell></row><row><cell cols="4">Threshold Precision Recall F-score</cell></row><row><cell>0.0</cell><cell>0.732</cell><cell>0.818</cell><cell>0.773</cell></row><row><cell>0.1</cell><cell>0.799</cell><cell>0.812</cell><cell>0.806</cell></row><row><cell>0.2</cell><cell>0.818</cell><cell>0.808</cell><cell>0.813</cell></row><row><cell>0.3</cell><cell>0.844</cell><cell>0.803</cell><cell>0.823</cell></row><row><cell>0.4</cell><cell>0.863</cell><cell>0.795</cell><cell>0.827</cell></row><row><cell>0.5</cell><cell>0.887</cell><cell>0.770</cell><cell>0.822</cell></row><row><cell>0.6</cell><cell>0.893</cell><cell>0.742</cell><cell>0.810</cell></row><row><cell>0.7</cell><cell>0.902</cell><cell>0.724</cell><cell>0.803</cell></row><row><cell>0.8</cell><cell>0.913</cell><cell>0.704</cell><cell>0.795</cell></row><row><cell>0.9</cell><cell>0.932</cell><cell>0.631</cell><cell>0.753</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,183.68,485.80,247.99,83.85"><head>Table 3 .</head><label>3</label><figDesc>ICD-10 coding performance on the CépiDC test set</figDesc><table coords="6,222.71,506.60,169.95,63.06"><row><cell></cell><cell cols="3">ICD-10 coding</cell></row><row><cell>Submission</cell><cell cols="3">Precision Recall F-score</cell></row><row><cell>Run1</cell><cell>0.890</cell><cell>0.803</cell><cell>0.844</cell></row><row><cell>Run2</cell><cell>0.886</cell><cell>0.813</cell><cell>0.848</cell></row><row><cell>Average score</cell><cell>0.788</cell><cell>0.664</cell><cell>0.719</cell></row><row><cell>Median score</cell><cell>0.811</cell><cell>0.655</cell><cell>0.700</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,142.96,559.05,337.64,7.86;7,151.52,570.01,329.07,7.86;7,151.52,580.97,329.07,7.86;7,151.52,591.93,111.17,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,442.93,559.05,37.66,7.86;7,151.52,570.01,159.14,7.86">Overview of the CLEF eHealth Evaluation Lab</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,357.27,570.01,123.32,7.86;7,151.52,580.97,138.86,7.86">CLEF 2016 -7th Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="7,298.63,580.97,172.20,7.86">Lecture Notes in Computer Science (LNCS</title>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,602.94,337.64,7.86;7,151.52,613.90,329.07,7.86;7,151.52,624.86,329.07,7.86;7,151.52,635.82,72.95,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,355.00,613.90,125.60,7.86;7,151.52,624.86,155.23,7.86">Clinical Information Extraction at the CLEF eHealth Evaluation Lab</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lavergne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,335.63,624.86,140.73,7.86">CLEF 2016 Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,646.84,337.63,7.86;7,151.52,657.79,263.41,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,225.45,646.84,255.14,7.86;7,151.52,657.79,95.14,7.86">The Unified Medical Language System (UMLS): Integrating Biomedical Terminology</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,254.07,657.79,74.98,7.86">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="267" to="270" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,120.67,337.64,7.86;8,151.52,131.63,329.07,7.86;8,151.52,142.59,270.91,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,195.32,131.63,285.28,7.86;8,151.52,142.59,46.11,7.86">CLEF eHealth Evaluation Lab 2015 Task 1b: Clinical Named Entity Recognition</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,204.89,142.59,137.28,7.86">CLEF 2015 Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,153.55,337.64,8.12;8,151.52,165.15,32.95,7.47" xml:id="b4">
	<monogr>
		<ptr target="http://www.who.int/classifications/icd/en/" />
		<title level="m" coord="8,151.53,153.55,156.46,7.86">International Classification of Diseases</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,175.46,337.63,7.86;8,151.52,186.42,329.07,7.86;8,151.52,197.38,281.01,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,151.52,186.42,329.07,7.86;8,151.52,197.38,55.83,7.86">Biomedical Concept Recognition in French Text Using Automatic Translation of English Terms</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Afzal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Akhondi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">H B M</forename><surname>Van Haagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Van Mulligen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Kors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,215.00,197.38,137.28,7.86">CLEF 2015 Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,208.34,337.64,7.86;8,151.52,219.30,329.07,7.86;8,151.52,230.26,329.07,7.86;8,151.52,241.22,232.18,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,419.54,208.34,61.06,7.86;8,151.52,219.30,329.07,7.86;8,151.52,230.26,25.98,7.86">The QUAERO French Medical Corpus: a Ressource for Medical Entity Recognition and Normalization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Leixa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,196.99,230.26,283.60,7.86;8,151.52,241.22,156.83,7.86">Fourth Workshop on Building and Evaluating Resources for Health and Biomedical Text Processing (BioTxtM)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="24" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,252.18,214.75,8.12" xml:id="b7">
	<monogr>
		<ptr target="https://translate.google.com" />
		<title level="m" coord="8,151.53,252.18,67.28,7.86">Google Translate</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,263.14,238.26,8.12" xml:id="b8">
	<monogr>
		<ptr target="http://www.bing.com/translator" />
		<title level="m" coord="8,151.53,263.14,81.36,7.86">Microsoft Translator</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,274.09,337.97,7.86;8,151.52,285.05,286.93,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,260.55,274.09,220.04,7.86;8,151.52,285.05,21.27,7.86">Certification et Codification des Causes Médicales de Décès</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pavillon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Laurent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,180.12,285.05,160.97,7.86">Bulletin Epidémiologique Hebdomadaire</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">31</biblScope>
			<biblScope unit="page" from="134" to="138" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,296.01,337.97,7.86;8,151.52,306.97,329.07,7.86;8,151.52,317.93,140.04,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,314.30,296.01,166.28,7.86;8,151.52,306.97,132.89,7.86">Peregrine: Lightweight Gene Name Normalization by Dictionary Lookup</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Schuemie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jelier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Kors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,292.57,306.97,183.27,7.86">Proceedings of the BioCreAtIvE II Workshop</title>
		<meeting>the BioCreAtIvE II Workshop<address><addrLine>Madrid, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="131" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,328.89,337.97,7.86;8,151.52,339.85,329.07,7.86;8,151.52,350.81,191.68,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,326.29,328.89,154.30,7.86;8,151.52,339.85,131.79,7.86">Evaluating Lexical Variant Generation to Improve Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Divita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">C</forename><surname>Rindflesch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,289.95,339.85,190.65,7.86;8,151.52,350.81,106.89,7.86">Proceedings of the American Medical Informatics Association Symposium</title>
		<meeting>the American Medical Informatics Association Symposium</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="775" to="779" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,361.77,236.78,8.11" xml:id="b12">
	<monogr>
		<ptr target="https://trac.nbic.nl/data-mining" />
		<title level="m" coord="8,151.52,361.77,69.58,7.86">Peregrine Indexer</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,372.73,294.25,8.11" xml:id="b13">
	<monogr>
		<ptr target="https://github.com/OpenSextant/SolrTextTagger" />
		<title level="m" coord="8,151.52,372.73,66.17,7.86">Solr Text Tagger</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,383.68,240.63,8.12" xml:id="b14">
	<monogr>
		<ptr target="http://www.mantra-project.eu" />
		<title level="m" coord="8,151.52,383.68,92.35,7.86">Mantra project website</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
