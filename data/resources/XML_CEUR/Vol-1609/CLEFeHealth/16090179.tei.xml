<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,144.85,115.96,325.66,12.62;1,252.54,133.89,110.28,12.62">Semantic tagging and normalization of French medical entities</title>
				<funder>
					<orgName type="full">TUNER</orgName>
				</funder>
				<funder ref="#_mn5EpJQ">
					<orgName type="full">Spanish Ministerio de Economía y Competitividad</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,185.26,171.73,61.16,8.74"><forename type="first">Viviana</forename><surname>Cotik</surname></persName>
							<email>vcotik@dc.uba.ar</email>
							<affiliation key="aff0">
								<orgName type="institution">Universidad de Buenos Aires</orgName>
								<address>
									<settlement>Buenos Aires</settlement>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,256.97,171.73,81.00,8.74"><forename type="first">Horacio</forename><surname>Rodríguez</surname></persName>
							<email>horacio@lsi.upc.edu</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Universitat Politècnica de Catalunya</orgName>
								<orgName type="institution" key="instit2">UPC</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,367.91,171.73,57.72,8.74"><forename type="first">Jorge</forename><surname>Vivaldi</surname></persName>
							<email>jorge.vivaldi@upf.edu</email>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Universitat Pompeu Fabra</orgName>
								<orgName type="institution" key="instit2">UPF</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,144.85,115.96,325.66,12.62;1,252.54,133.89,110.28,12.62">Semantic tagging and normalization of French medical entities</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5B65ECA9E4ED08192D2515815436E0A5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Machine Learning</term>
					<term>SNOMED-CT</term>
					<term>UMLS</term>
					<term>DBPEDIA</term>
					<term>Bio-Portal</term>
					<term>Wikipedia</term>
					<term>semantic tagger</term>
					<term>binary classifiers</term>
					<term>distant learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we present two tools for facing task 2 in CLEF eHealth 2016. The first one is a semantic tagger aiming to detect relevant entities in French medical documents, tagging them with their appropriate semantic class and normalizing them with the Semantic Groups codes defined in the UMLS. It is based on a distant learning approach that uses several SVM classifiers that are combined to give a single result. The second tool is based on a symbolic procedure to obtain the English translation of each medical term and looks for normalization information in public accessible resources.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We developed a semantic tagger for the medical domain <ref type="bibr" coords="1,372.88,458.63,10.52,8.74" target="#b0">[1]</ref> performing on English Wikipedia pages <ref type="foot" coords="1,206.45,469.01,3.97,6.12" target="#foot_0">4</ref> (WP ) previously selected as belonging to the domain using a distant learning approach. Our aim here is exploring whether the approach can be applied to other language (French), other genre (scientific documents) and other tagset, and to normalize the semantic tags to the Unified Medical Language System (UMLS ). We performed these experiments within the framework of CLEF2016 eHealth contest <ref type="foot" coords="1,265.16,528.78,3.97,6.12" target="#foot_1">5</ref> (see details in <ref type="bibr" coords="1,338.17,530.36,10.30,8.74" target="#b1">[2]</ref>). More specifically in Task 2, Multilingual Information Extraction as described in <ref type="bibr" coords="1,363.96,542.31,10.52,8.74" target="#b2">[3]</ref>  <ref type="foot" coords="1,374.48,540.74,3.97,6.12" target="#foot_2">6</ref> .</p><p>Semantic Tagging is the task of assigning to some linguistic units of a text a unique tag from a semantic tagset. It can be divided in two subtasks: detection and tagging. The first one is similar to term detection and Named Entity Recognition, while the latter is closely related to Named Entity Classification.</p><p>The key elements of Semantic Tagging task are: (i) the document, or document genre, to be processed, (ii) the linguistic units to be tagged and (iii) the tagset. All these elements play a crucial role for the success of the task. In this concrete task our constraints are the following: (i) documents of medical domain, mainly scientific articles indexed in MEDLINE and some drug monographs published by the European Medicines Agency (EMEA), (ii) the linguistic units to be tagged are the terminological strings found in the source documents, (iii) the tagset will be a subset of the top UMLS categories. Such resources will be used also for the normalization on the medical entities as defined in the phase II.</p><p>Our approach consists of learning a binary classifier for each of the categories, whose results are combined using a simple voting schema. The cases to be classified are the mentions in the document corresponding to TCs, to refer to any of the concepts in the tagset. No co-reference resolution is attempted and, so, co-referring mentions may be tagged differently. For the normalization of the entities found we used the resources available through BioPortal 7 .</p><p>After this introduction, the organization of the article is as follows: In section 2 we sketch the state of the art of Semantic Tagging approaches. Section 3 presents the methodology followed in the current task. The experimental framework is described in section 4. Results are shown and discussed in section 5. Finally section 6 presents our conclusions and further work proposals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>English is, by far, the most supported language for biomedical resources and tools. The National Library of Medicine 8 (NLM R ) maintains the Unified Medical Language System 9 (UMLS R ) that groups an important set of resources to facilitate the development of computer systems to "understand" the meaning of the language of biomedicine and health. It is worth noting that only a small fraction of such resources exist for other languages.</p><p>A relevant aspect of information extraction is the recognition and identification of biomedical entities (like disease, genes, proteins . . . ). Several Named Entity Recognition techniques have been proposed to recognize such entities based on their morphology and context. NER can be used to recognize previously known names and also new names, but cannot be directly used to relate these names to specific biomedical entities found in external databases. For this identification task, a dictionary approach is necessary. A problem is that existing dictionaries are often incomplete and different variations may be found in the literature; therefore it is necessary to minimize this issue as much as possible.</p><p>2015 edition of CLEF eHealth contest contained two tasks focusing on information extraction and information retrieval. The topic of one of them was Clinical Named Entity Recognition in medical texts written in French (Task 1b) <ref type="bibr" coords="2,134.77,591.57,9.96,8.74" target="#b3">[4]</ref>. Seven teams participated in this task. Two types of biomedical documents were used: scientific articles indexed in the MEDLINE database, and full text drug monographs published by the European Medicines Agency (EMEA). The best system obtained F-measure of 0.756 for plain entity recognition, 0.711 for normalized entity recognition, and 0.872 for entity normalization <ref type="bibr" coords="3,420.75,130.95,9.96,8.74" target="#b4">[5]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our approach</head><p>For participating in CLEF e-Health 2016 Task 2 we have submitted two runs to the Plain Entity Recognition Task and one run to the Normalization task. A description of our approaches followed in these three runs are presented below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Run1: WP-based system using distant learning</head><p>In this run we follow basically the approach of our previous system, presented to CLEF e-Health 2015 <ref type="bibr" coords="3,240.62,500.70,9.96,8.74" target="#b5">[6]</ref>, in turn based on a semantic tagging system aiming to detect and classify medical entities in English WP pages <ref type="bibr" coords="3,400.17,512.66,9.96,8.74" target="#b0">[1]</ref>. A multilingual extension (to Arabic, French, and Spanish) of this latter system, can be found in <ref type="bibr" coords="3,134.77,536.57,9.96,8.74" target="#b6">[7]</ref>. We sketch next the approach we follow, highlighting the differences between the current and the previous system. Details of the latter can be found in <ref type="bibr" coords="3,467.30,548.52,9.96,8.74" target="#b5">[6]</ref>. Figure <ref type="figure" coords="3,166.20,560.48,4.98,8.74" target="#fig_0">1</ref> presents a overall vision of the system.</p><p>The core idea of the system is that for a term t known to belong to the semantic category c (one of the 10 UMLS categories we deal with) not only the occurrences of t in the training material can be considered positive examples for learning but also the occurrences of t in its associated WP page if existing. This hypothesis is important because for some semantic categories the training material contains not enough terms for accurate learning.</p><p>Following <ref type="bibr" coords="3,194.26,644.16,9.96,8.74" target="#b7">[8]</ref>, we generate training instances by automatically labelling each instance of a seed term with its designated semantic class. When we create feature vectors for the classifier, the seeds themselves are hidden and only contextual features are used to represent each training instance. Proceeding in this way the classifier is forced to generalize with limited overfitting.</p><p>We created a suite of binary contextual classifiers, one for each semantic class. The classifiers are learned using, as in <ref type="bibr" coords="4,325.73,167.03,9.96,8.74" target="#b7">[8]</ref>, Support Vector Machine models utilizing Weka toolkit <ref type="bibr" coords="4,231.04,178.98,9.96,8.74" target="#b8">[9]</ref>. Each classifier makes a weighted decision as to whether a term belongs or not to its semantic class.</p><p>For every file of the training corpus, each tagged term is considered as a positive example for the tagged class and negative example for the rest of the classes. Features are the words occurring in the local context of mentions. The context size and POS of the context words are parametrizable.</p><p>Examples for learning correspond to the mentions of the seed terms in the corresponding WP pages. Let t 1 , t 2 , . . . , t n the seed terms for the semantic class c, i.e. t i ∈ ST c . For each t i we obtain its WP page and we extract all the mentions of seed terms occurring in the page. Positive examples correspond to mentions of seed terms corresponding to semantic class c while negative examples correspond to seed terms from other semantic classes. Frequently, a positive example occurs within the text of the page but often many other positive and negative examples occur as well. Features are simply words occurring in the local context of mentions.</p><p>For French we have used for processing documents, in learning and test phases, the Freeling toolbox 10 [10].</p><p>Term candidates, TC, are selected according to morpho-syntactic criteria. We have used for filtering the following regular expression: NA*(PNA*)+. Additionally, in order to take into account the peculiarities of the term selection of CLEF organizers we also decompose each complex term in its components (see section 4.1 for more details and examples).</p><p>The learning process has been performed using for each semantic category the most likely relevant documents including EMEA and MEDLINE training documents and WP pages obtained as described above. From the WP pages, besides those with purity less than 1, short pages and pages consisting mainly of itemized material or non-textual fragments were removed too.</p><p>For each example, the feature vector captures a context window of n words to its left and right<ref type="foot" coords="4,218.42,513.43,7.94,6.12" target="#foot_4">11</ref> without surpassing sentence limits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Run2: Knowledge-based approach</head><p>A careful analysis of our results on CLEF e-Health 2015 participation revealed that some apparently easy to detect terms were not detected or were classified incorrectly. For instance French terms occurring in French DBPedia 12 or translated English terms occurring in English (Princeton) WN or in English DBPedia were not detected. We decided, thus, combining, in our run2, the results of run1 with two other systems, one based on the performance of a state-of-the-art term extractor, YATE, tuned to work in the medical domain, and the other based on an external knowledge source, the DBPedia. Although domain independent, DBPedia has a nice coverage of medical classified terminology and offers good interlingual capabilities.</p><p>Extracting Term Candidates using YATE and wikiYATE YATE <ref type="bibr" coords="5,465.09,194.09,15.50,8.74" target="#b10">[11]</ref> basically performs using the taxonomic structure of the nominal part of WN. Given a domain d, the medical domain here, YATE obtains the called Domain Borders, synsets that are likely to belong, both them and their descendants to d. These Domain Borders are used later for extracting from a document the set of mentions corresponding to terms belonging to d, i.e. those TC whose synsets are placed below a Domain Border. Right part of Figure <ref type="figure" coords="5,384.69,265.82,4.98,8.74" target="#fig_1">2</ref> shows this process. YATE uses English WN, therefore for applying this tool a translation of French TC s is needed. As the terms we are interested on are those represented in the French WP, we used the interwiki links between French and English WP (using DBPedia for getting these links). This process results on the extraction (tagging) of the medical terms occurring in the test documents. YATE is a term extractor, not a semantic tagger, so it is not able to classify the extracted terms, but, indirectly, these terms can be used as seed terms for learning the classifiers.</p><p>wikiYATE <ref type="bibr" coords="5,198.26,581.02,15.50,8.74" target="#b11">[12]</ref> is a similar term extractor but it is multilingual and uses WP as knowledge source for detecting terms. Both term extractors have been used in this task.</p><p>DBPedia-based approach Some useful information in WP is represented in infoboxes and, thus, has been automatically mapped into the corresponding DBPedia rdf triples. We take profit of several interesting properties of DBPedia:</p><p>-There exist DBPedia datasets for English (http://dbpedia.org/sparql) and French (http://fr.dbpedia.org/sparql). -Entities (resources) in the two datasets are frequently linked through sameAs properties.</p><p>-Entities in the datasets are frequently mapped to one or more linguistic referents, words and phrases, through label properties, sometimes in several languages. So an entity in the English DBPedia can be labelled with French words or phrases.</p><p>As shown in Figure <ref type="figure" coords="6,236.35,225.27,3.87,8.74" target="#fig_2">3</ref>, iterating over French and English terms and resources in French and English DBPedia datasets through the label and sameAs properties, we are able to collect from an initial French TC, t, the set of English resources likely corresponding to translations of t. In order to be able to classify t into one of the 10 semantic categories we proceed on the following way:</p><p>During training, for each semantic category c we collect all the French terms t occurring in the training dataset and tagged with c. We filter out from these sets the terms not occurring in French WP. We then collect, as described above, the set of English DBPedia resources associated to them. For each of such resources r we obtain the set of classes to which r belongs (we reduce our search to DBPedia and YAGO classes) using the type property. From each class we recursively collect the set of super-classes using the subClassOf property. Some of the super-classes belong unambiguously to one semantic category. For instance, http://dbpedia.org/class/yago/AliphaticCompound114601294 occurs as super-class of 6 terms all classified as CHEM. Others, as, http://dbpedia.org/ontology/Eukaryote, are ambiguous. This super-class occurs 4 times as PHYS, 8 times as LIVB, and 2 times as DISO.</p><p>For each semantic category we collect the set of unambiguous super-classes. For ambiguous cases we proceed as follows: If the total number of terms covered by the super-class is higher than a threshold THR1 and the ratio between the higher option and the second is higher than a threshold THR2 we assign the super-class to the set corresponding to the first option. THR1 and THR2 have been manually set to 30 and 4. For instance in http://dbpedia.org/class/yago/Location100027167, occurring 10 times as ANAT, 13 times as CHEM, and 76 times as GEOG, the two conditions hold (76+13+10 &gt;30 and 76/13 &gt;4, so the super-class is included into the set of super-classes corresponding to the semantic category GEOG.</p><p>In this way a number of super-classes have been associated to each semantic category. See in Table <ref type="table" coords="7,233.59,214.71,4.98,8.74" target="#tab_0">1</ref> the size of each set and an example of their members. Once collected these sets (during the training phase) the process at test phase is quite straightforward. See left part of Figure <ref type="figure" coords="7,367.25,414.25,3.87,8.74" target="#fig_1">2</ref>. For each TC in the test dataset, following the approach described above, we obtain the set of English DBPedia resources. The DBPedia and YAGO classes of these resources are then obtained and from them the set of super-classes. This set is intersected with the sets of super-classes associated to each semantic category. The sizes of all the intersections are computed and the category associated to the higher size is returned as category of the term (ties are solved according to the most frequent semantic category in the training dataset). Finally the results of run1 (a semantic category), DBP-based (a semantic category), and YATE-based (a Boolean) are combined for getting the final result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Normalization</head><p>For normalization we have used the BioPortal SPARQL endpoint. The a priori obvious way of accessing UMLS and obtaining the CUI of a term t consisted on getting a UMLS entity labelled with t and then getting the CUI of this entity. This simple procedure does not work because UMLS is not directly labelled with terms. We have used instead an indirect access to UMLS through other ontologies. We have employed for such process Snomed-CT, Mesh, and RCD. The process consists on translating French into English, using the approach described above and then accessing to any of the intermediate ontologies and from them to UMLS. In Figure <ref type="figure" coords="8,268.03,118.99,4.98,8.74" target="#fig_3">4</ref> one of the SPARQL templates used is presented. This template is instantiated into a real query just by replacing the placeholders '**ont**' by the name of one of our three ontologies and '**term**' by the name of the English TC. As can be seen in the Figure, this template uses the prefLabel (preferred label) link. We have also built templates using the altLabel (alternate label) link, and others using approximate string matching, for covering decreasingly confident matchings. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental framework</head><p>Participants of CLEF2016 are requested to perform named entity recognition and normalization on a dataset of scientific article titles and full-text drug inserts. For performing such tasks we designed the working frameworks that are described in following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Entity recognition</head><p>Our basic working framework for entity recognition was the same than in CLEF2015. But taking into account the results obtained in such contest (see <ref type="bibr" coords="8,429.13,471.17,10.79,8.74" target="#b5">[6]</ref>) we perform some experimentation based on such material in order to decide to include or not WP pages in our learning framework. We test several configuration of features selection as well as different number of WP pages for using in training stage. Such framework foresees to automatically select WP pages for each class. We manually check a number of such pages in order to correct some issues with automatic selection phase. The results clearly shown that there was not any improvement in adding WP material in the training phase. Therefore we decided to train our model using only the training material provided by the CLEF2016 organization and provide such results as run 1.</p><p>As mentioned in section 3.1 the learning phase was made using the distant learning paradigm. For each mention of a TC the vector of features is built and the nine 13 learned binary classifiers are applied to it. For building such classifiers all the documents of the training corpus were linguistically processed using the Freeling suite (see <ref type="bibr" coords="9,263.58,118.99,15.50,8.74" target="#b9">[10]</ref> for details). The vector of features was built using the lemmas of the context words that within a window of 3 tokens of the TC (excluding determiners and punctuation signs). We used the lemmas to as features but we defined several ways to select such lemmas: (i) Mode 0: any context word within the window, (ii) Mode 1: only nouns and adjectives and (iii) Mode 2: only verbs, nouns and adjectives.</p><p>The Quaero corpus takes into account nested terms as different terms. Given this fact, when the TC is poly-lexical, all the possible combinations of components are taken into account. Table <ref type="table" coords="9,292.03,214.64,4.98,8.74" target="#tab_1">2</ref> shows some examples. We also decided to include a second run that, starting with run 1 results, improves them by doing some symbolic processes as shown in Figure <ref type="figure" coords="9,454.71,365.60,4.98,8.74" target="#fig_1">2</ref> and described in the following paragraphs.</p><p>-Term extraction and analysis. For preparing run 2 we create a single document that includes all documents of the test corpus. We analyse such material with wikiYATE, a term extraction tool that uses WP for obtaining the TCs of a given text (see description in <ref type="bibr" coords="9,299.97,435.06,14.76,8.74" target="#b11">[12]</ref>). This tool ranks the TC according a termhood value; we create a set of string composed by: (i) those TC above a given threshold, (ii) those TC not found in WP and (iii) the list of all the adjectives that take part of the chosen TCs. We look in the DBpedia for the English translation of these units and if available processed them using YATE ( <ref type="bibr" coords="9,213.58,494.84,14.87,8.74" target="#b10">[11]</ref>), a medical term extraction tool that uses the Multilingual Central Repository 14 (MCR) <ref type="bibr" coords="9,305.31,506.79,15.50,8.74" target="#b12">[13]</ref> for analysing the TCs. This tool in addition to give a termhood value for each TC, provides with some basic class information that we mapped to UMLS classes. -DBpedia exploration as described in section 3.2.</p><p>Finally, the results of both analysis has been combined in a single result that was used to improve the result run 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Entity normalization</head><p>The process of Entity normalization was performed independently from the process of entity recognition. This is why we submitted runs for the task of plain entity recognition and not to the task of normalized entity recognition. See 3.3 for details on our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Table <ref type="table" coords="10,162.14,182.89,4.98,8.74" target="#tab_2">3</ref> depicts the global results as reported by the organization of CLEF2016 (phase I task entity recognition). The material officially delivered included two runs. Unfortunately, for the run 2 we incorrectly submitted the same material as in run 1. After detecting such issue the organisation kindly accepted to evaluate our actual run as an unofficial result. For this reason we tagged with an "*" run2 results showed in Table <ref type="table" coords="10,267.46,242.66,3.87,8.74" target="#tab_2">3</ref>. Additionally we performed an after challenge improvement of our system (noted as "/3*" in the table) introducing a simple voting mechanism for unifying the tags corresponding to multiple mentions of the same TC in the case enough evidence for one of the choices exists. The results obtained for the Phase I (entity recognition) are poor (although better than those proposed in CLEF2015, see <ref type="bibr" coords="10,339.52,615.59,10.79,8.74" target="#b5">[6]</ref>) and far from the results obtained from our previous experiments on French Wikipedia pages<ref type="foot" coords="10,419.97,625.97,7.94,6.12" target="#foot_7">15</ref> . As already shown in <ref type="bibr" coords="11,238.71,199.55,9.96,8.74" target="#b5">[6]</ref>, the terminological density of the QUAERO corpus is very high. As the same time, such density is obtained by a tagging methodology that nest several terms in a single polylexical term. An example of this situation is shown in Table <ref type="table" coords="11,213.99,235.42,3.87,8.74" target="#tab_4">5</ref>. Undoubtedly, the tagging is correct but it is not clear that such concrete sentence actually contains 5 terms instead of just 3 (Indications, radiothérapie and tumeurs digestives) as most term extractors will do.</p><p>Another minor issue is that text seems to include some kind of extra segmentation (see for example: l' enfant or d ' activation plaquettaire induite par l ' héparine among many others). The words by themselves are not important but such segmentation may cause errors in the POS tagging stage and this fact may be a real problem for TC delimitation ("l" and "d" will become a noun instead of a determiner and preposition respectively). Also, the generation of the final stand-off annotation becomes a bit more complicated.</p><p>Table <ref type="table" coords="11,178.75,355.86,4.98,8.74" target="#tab_5">6</ref> shows a detailed analysis of run 1 results. From one side, there are two classes (PHEN and GEOG) that does not produce any correct result and another class that only detects one valid term (OBJC). In these cases, the corresponding classifiers have a extremely low accuracy, probably due to the lack of training examples. So, acquiring additional examples for these cases should result on some improvement. From other side, there are some classes (DISO, PROC and ANAT) where the number of examples is much higher and therefore show a better result .</p><p>Table <ref type="table" coords="11,177.43,451.95,4.98,8.74" target="#tab_6">7</ref> shows the same analysis for run 2. There is an improvement in the performance for all the classes showing that: (i) the symbolic analysis partially solves the inaccuracies of the machine learning system and (ii) the combination of methods improves the global efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and further work</head><p>The organizers of CLEF eHealth 2016 divided the task 2 in two phases: entity recognition and entity normalization on French medical text ofthe Quaero corpus. Our approach results in two different systems for solving each task.</p><p>For the first task, we have presented a system that automatically detects and tags medical terms in medical documents using a tagset derived from UMLS taxonomy. The results of the system for entity recognition, as discussed in previous section are poor, far from the obtained in our previous system (performing on medical English wp pages and confirmed for other languages, including French, <ref type="bibr" coords="11,134.77,644.16,10.79,8.74" target="#b6">[7]</ref>) but much better than those obtained in our participationin CLEF2015. The improvement was specially high in our run 2 that includes some symbolic pro- cessing for improving the results. The working framework allowed us to experiment with several design parameters like the number of terms used for training, context width, features definition, etc. Undoubtedly, this is at the base of the improvement obtained for run 1. The use of some symbolic processing on the results of run 1 allow us to obtain some additional improvement.</p><p>It is interesting to observe that in all cases the improvement is higher in the inexact match than in the exact match. This fact may reveal some issues in the TC delimitation but also in the offset calculation. The latter issue is magnified by the tokenization of the training corpus that difficulties the linguistic analysis and the offset calculation.</p><p>The second task was solved using a totally different system. It is based in obtaining the normalization information from public resources after obtaining the English translation of each medical term. The results were a bit below of the other participants . Again, tokenization is an issue that affects the performance of the system.</p><p>Several research lines will be followed in the next future:</p><p>-The integration of both entity recognition and normalization in a single task may bring mutual benefits. -To enlarge the use of BioPortal for looking in the ontologies for the recognition and classification task seems to be a promising direction. -A combination and/or the specialization of the resources for learning more accurate classifiers. The application of the DBPedia based approach, to all the semantic classes merits a deeper investigation. -A careful combination of learning from the training dataset and from additional material, as WP should be experimented. -The features currently used for learning the classifiers are rather crude and need some revision. We foresee to do some experimentation weighting the features, separating the features according its position in relation to the TC and adding new features as: start/end characters, typed features, etc. -Moving from semantic tagging of medical entities to semantic tagging of relations between such entities is a highly exciting objective, in the line of recent challenges in the medical domain (and beyond). -Improving the selection of medical entities by using POS pattern learning, adapting our term extractor to the tagging policy of medical entities in Quaero corpus and improving adaptation of Freeling to French medical texts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,238.12,362.18,139.12,7.89;3,137.60,162.66,340.16,184.74"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Train and testing pipelines</figDesc><graphic coords="3,137.60,162.66,340.16,184.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,252.19,462.92,110.98,7.89;5,151.77,296.93,311.80,151.23"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Run 2 improvement</figDesc><graphic coords="5,151.77,296.93,311.80,151.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,220.69,428.56,170.90,7.89;6,194.29,293.77,226.77,120.02"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. French to English term translation</figDesc><graphic coords="6,194.29,293.77,226.77,120.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,176.80,311.97,261.75,7.89;8,194.29,223.13,226.77,74.07"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Example of SPARQL template for accessing to BioPortal</figDesc><graphic coords="8,194.29,223.13,226.77,74.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,138.15,246.36,351.40,117.98"><head>Table 1 .</head><label>1</label><figDesc>More frequent top super classes</figDesc><table coords="7,138.15,278.37,351.40,85.97"><row><cell cols="2">Semantic class Top super-classes</cell><cell>Example</cell></row><row><cell>ANAT</cell><cell cols="2">16 http://dbpedia.org/class/yago/BodyPart105220461</cell></row><row><cell>LIVB</cell><cell cols="2">27 http://dbpedia.org/class/yago/Animal100015388</cell></row><row><cell>CHEM</cell><cell cols="2">53 http://dbpedia.org/class/yago/Inhibitor114724436</cell></row><row><cell>PROC</cell><cell cols="2">21 http://dbpedia.org/class/yago/Treatment100658082</cell></row><row><cell>GEOG</cell><cell cols="2">31 http://dbpedia.org/ontology/PopulatedPlace</cell></row><row><cell>DISO</cell><cell cols="2">35 http://dbpedia.org/class/yago/Infection114174549</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,189.31,246.04,236.73,69.91"><head>Table 2 .</head><label>2</label><figDesc>Processing nested terms</figDesc><table coords="9,189.31,268.83,236.73,47.12"><row><cell>TC found</cell><cell>Additional terms to be processed</cell></row><row><cell>cancers digestifs</cell><cell>cancers, digestif</cell></row><row><cell>dose de fentanyl</cell><cell>dose, fentanyl</cell></row><row><cell cols="2">clip péri-cave d' Adams clip, péri-cave, clip péri-cave</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,136.16,309.56,356.29,130.93"><head>Table 3 .</head><label>3</label><figDesc>Results as reported by the organization of the CLEF2016's (phase I)</figDesc><table coords="10,136.16,341.56,356.29,98.92"><row><cell>-</cell><cell>entities exact match</cell><cell>entities inexact match</cell><cell></cell></row><row><cell>docs/run</cell><cell>TP FP FN Prec. Recall</cell><cell>F1 TP FP FN Prec. Recall</cell><cell>F1</cell></row><row><cell>EMEA/1</cell><cell cols="3">512 3463 1835 0,1288 0,2182 0,1620 962 3013 1653 0,2420 0,3679 0,2920</cell></row><row><cell>EMEA/2*</cell><cell cols="3">420 4025 1816 0,0945 0,1878 0,1257 864 3581 1613 0,1944 0,3488 0,2496</cell></row><row><cell>EMEA/3*</cell><cell cols="3">654 1550 3538 0,2967 0.1560 0.2045 903 1301 2976 0.4097 0.2328 0.2969</cell></row><row><cell cols="4">MEDLINE/1 736 5053 2369 0,1271 0,2370 0,1655 1446 4343 1988 0,2498 0,4199 0,3132</cell></row><row><cell cols="4">MEDLINE/2* 969 5050 2138 0,1610 0,3119 0,2124 1759 4260 1684 0,2922 0,5109 0,3718</cell></row><row><cell cols="4">MEDLINE/3* 1078 2025 4933 0.3474 0.1793 0.2366 1575 1528 4113 0.5076 0.2769 0.3583</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="10,145.58,496.40,321.12,70.40"><head>Table 4 .</head><label>4</label><figDesc>Results as reported by the organization of the CLEF2016's (phase II)</figDesc><table coords="10,150.27,519.68,314.82,47.12"><row><cell>-</cell><cell>entities exact match</cell><cell>entities inexact match</cell><cell></cell></row><row><cell>docs</cell><cell>TP FP FN Prec. Recall</cell><cell>F1 TP FP FN Prec. Recall</cell><cell>F1</cell></row><row><cell>EMEA</cell><cell cols="3">517 558 558 0,4809 0,4809 0,4809 517 558 558 0,4809 0,4809 0,4809</cell></row><row><cell cols="4">MEDLINE 673 745 748 0,4746 0,4736 0,4741 673 745 748 0,4746 0,4736 0,4741</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="11,147.05,116.41,321.26,44.50"><head>Table 5 .</head><label>5</label><figDesc>Medical entities as tagged in file 49922.txt (MEDLINE)</figDesc><table coords="11,147.05,139.70,321.26,21.21"><row><cell cols="2">Full sentence Indications de la radiothérapie pour les tumeurs digestives</cell></row><row><cell>Entities</cell><cell>Indications, radiothérapie, tumeurs digestives, tumeurs, digestives</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="12,147.86,115.91,319.65,186.47"><head>Table 6 .</head><label>6</label><figDesc>Error analysis run 1</figDesc><table coords="12,147.86,138.30,319.65,164.08"><row><cell>Right</cell><cell></cell><cell></cell><cell cols="5">Class proposed by the classifiers</cell><cell></cell><cell></cell><cell></cell></row><row><cell>class</cell><cell cols="10">DISO PHEN PROC PHYS ANAT LIVB CHEM DEVI OBJC GEOG</cell></row><row><cell>DISO</cell><cell>451</cell><cell>26</cell><cell>180</cell><cell>56</cell><cell>185</cell><cell>92</cell><cell>184</cell><cell>19</cell><cell>24</cell><cell>16</cell></row><row><cell>PHEN</cell><cell>21</cell><cell>0</cell><cell>5</cell><cell>1</cell><cell>6</cell><cell>2</cell><cell>3</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>PROC</cell><cell>136</cell><cell>10</cell><cell>215</cell><cell>31</cell><cell>62</cell><cell>48</cell><cell>107</cell><cell>14</cell><cell>9</cell><cell>8</cell></row><row><cell>PHYS</cell><cell>13</cell><cell>1</cell><cell>17</cell><cell>11</cell><cell>11</cell><cell>1</cell><cell>18</cell><cell>2</cell><cell>0</cell><cell>0</cell></row><row><cell>ANAT</cell><cell>59</cell><cell>2</cell><cell>32</cell><cell>12</cell><cell>68</cell><cell>4</cell><cell>19</cell><cell>2</cell><cell>2</cell><cell>0</cell></row><row><cell>LIVB</cell><cell>51</cell><cell>3</cell><cell>35</cell><cell>16</cell><cell cols="2">26 131</cell><cell>16</cell><cell>2</cell><cell>3</cell><cell>3</cell></row><row><cell>CHEM</cell><cell>31</cell><cell>7</cell><cell>37</cell><cell>15</cell><cell>18</cell><cell>20</cell><cell>131</cell><cell>8</cell><cell>10</cell><cell>1</cell></row><row><cell>DEVI</cell><cell>15</cell><cell>0</cell><cell>7</cell><cell>4</cell><cell>4</cell><cell>3</cell><cell>1</cell><cell>4</cell><cell>0</cell><cell>0</cell></row><row><cell>OBJC</cell><cell>2</cell><cell>0</cell><cell>3</cell><cell>4</cell><cell>0</cell><cell>1</cell><cell>9</cell><cell>0</cell><cell>1</cell><cell>1</cell></row><row><cell>GEOG</cell><cell>7</cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>6</cell><cell>4</cell><cell>3</cell><cell>1</cell><cell>0</cell><cell>0</cell></row><row><cell cols="10">Precision 57.38 0.00 40.41 7.28 17.62 42.81 26.68 7.69 2.04</cell><cell>0.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="12,147.86,335.00,319.65,186.47"><head>Table 7 .</head><label>7</label><figDesc>Error analysis run 2</figDesc><table coords="12,147.86,357.39,319.65,164.08"><row><cell>Right</cell><cell></cell><cell cols="8">Class improvement proposed by the symbolic process</cell><cell></cell></row><row><cell>class</cell><cell cols="10">DISO PHEN PROC PHYS ANAT LIVB CHEM DEVI OBJC GEOG</cell></row><row><cell>DISO</cell><cell>499</cell><cell>24</cell><cell>160</cell><cell>49</cell><cell>118</cell><cell>93</cell><cell>162</cell><cell>18</cell><cell>21</cell><cell>7</cell></row><row><cell>PHEN</cell><cell>16</cell><cell>0</cell><cell>5</cell><cell>1</cell><cell>4</cell><cell>2</cell><cell>3</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>PROC</cell><cell>114</cell><cell>9</cell><cell>270</cell><cell>22</cell><cell>47</cell><cell>48</cell><cell>96</cell><cell>13</cell><cell>8</cell><cell>4</cell></row><row><cell>PHYS</cell><cell>12</cell><cell>5</cell><cell>17</cell><cell>37</cell><cell>8</cell><cell>1</cell><cell>17</cell><cell>2</cell><cell>0</cell><cell>0</cell></row><row><cell>ANAT</cell><cell>52</cell><cell>1</cell><cell>23</cell><cell>10</cell><cell>163</cell><cell>4</cell><cell>25</cell><cell>4</cell><cell>3</cell><cell>0</cell></row><row><cell>LIVB</cell><cell>45</cell><cell>3</cell><cell>27</cell><cell>14</cell><cell cols="2">21 131</cell><cell>15</cell><cell>2</cell><cell>3</cell><cell>2</cell></row><row><cell>CHEM</cell><cell>27</cell><cell>7</cell><cell>23</cell><cell>11</cell><cell>11</cell><cell>20</cell><cell>160</cell><cell>8</cell><cell>12</cell><cell>1</cell></row><row><cell>DEVI</cell><cell>13</cell><cell>0</cell><cell>4</cell><cell>3</cell><cell>3</cell><cell>2</cell><cell>1</cell><cell>4</cell><cell>0</cell><cell>0</cell></row><row><cell>OBJC</cell><cell>1</cell><cell>0</cell><cell>1</cell><cell>3</cell><cell>0</cell><cell>1</cell><cell>9</cell><cell>0</cell><cell>1</cell><cell>0</cell></row><row><cell>GEOG</cell><cell>7</cell><cell>0</cell><cell>2</cell><cell>1</cell><cell>11</cell><cell>4</cell><cell>3</cell><cell>1</cell><cell>1</cell><cell>15</cell></row><row><cell cols="11">Precision 63.49 0.00 50.75 24.50 42.23 42.81 32.59 7.69 2.04 51.72</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="1,144.73,634.88,94.49,7.86"><p>http://en.wikipedia.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="1,144.73,645.84,185.81,7.86"><p>https://sites.google.com/site/clefehealth2016/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="1,144.73,656.80,210.18,7.86"><p>https://sites.google.com/site/clefehealth2016/task-2</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_3" coords="4,144.73,634.88,125.77,7.86"><p>http://nlp.lsi.upc.edu/freeling/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_4" coords="4,144.73,645.84,195.58,7.86"><p>In the experiments reported here n was set to 3.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_5" coords="4,144.73,656.80,100.12,7.86"><p>http://wiki.dbpedia.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_6" coords="8,144.73,645.84,335.87,7.86;8,144.73,656.80,185.36,7.86"><p>In our run 1, the process of extracting GEOG entities was performed by a Geographic NER, and, so only nine classifiers were learnt.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_7" coords="10,144.73,645.84,335.86,7.86;10,144.73,656.80,211.79,7.86"><p>Using a very similar methodology to classify medical WP pages (over six classes) we obtained accuracies of 74.76% (exact match). See<ref type="bibr" coords="10,346.79,656.80,9.73,7.86" target="#b6">[7]</ref> </p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7">Acknowledgements</head><p>This work was partially supported by the <rs type="funder">TUNER</rs> project (<rs type="funder">Spanish Ministerio de Economía y Competitividad</rs>, <rs type="grantNumber">TIN2015-65308-C5-5-R</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_mn5EpJQ">
					<idno type="grant-number">TIN2015-65308-C5-5-R</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="13,142.96,548.55,337.63,7.86;13,151.52,559.50,243.58,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,267.68,548.55,190.78,7.86">Medical entities tagging using distant learning</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vivaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Rodríguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,151.52,559.50,89.02,7.86">CICLing 2015, Part II</title>
		<imprint>
			<publisher>LNCS</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9042</biblScope>
			<biblScope unit="page" from="631" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,570.02,337.63,7.86;13,151.52,580.98,325.18,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,442.93,570.02,37.65,7.86;13,151.52,580.98,144.77,7.86">Overview of the CLEF eHealth evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,338.51,580.98,21.60,7.86">LNCS</title>
		<imprint>
			<date type="published" when="2016-09">2016. September 2016</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,591.49,337.64,7.86;13,151.52,602.45,329.07,7.86;13,151.52,613.41,329.07,7.86;13,151.52,624.37,259.74,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,383.78,602.45,96.81,7.86;13,151.52,613.41,178.09,7.86">Clinical information extraction at the CLEF eHealth evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lavergne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,370.46,613.41,110.13,7.86;13,151.52,624.37,133.89,7.86">CLEF Evaluation Labs and Workshop: Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2016-09">2016. September 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,634.88,337.64,7.86;13,151.52,645.84,329.07,7.86;13,151.52,656.80,261.80,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,193.70,645.84,286.89,7.86;13,151.52,656.80,22.38,7.86">CLEF eHealth evaluation lab 2015 task 1b: clinical named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,195.79,656.80,137.27,7.86">CLEF 2015 Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,119.67,337.63,7.86;14,151.52,130.63,329.07,7.86;14,151.52,141.59,275.46,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="14,204.41,130.63,188.75,7.86">Overview of the CLEF eHealth evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">H</forename><surname>Hanna Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,421.37,130.63,59.23,7.86;14,151.52,141.59,174.39,7.86">clef 2015 -6th conference and labs of the evaluation forum</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,152.55,337.63,7.86;14,151.52,163.51,329.07,7.86;14,151.52,174.47,117.39,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="14,304.15,152.55,176.44,7.86;14,151.52,163.51,85.67,7.86">Semantic tagging of French medical entities using distant learning</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Cotik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vivaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Rodríguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,258.66,163.51,221.93,7.86;14,151.52,174.47,84.32,7.86">Working Notes of CLEF 2015 -Conference and Labs of the Evaluation forum</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,185.43,337.64,7.86;14,151.52,196.39,196.14,7.86" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="14,301.84,185.43,178.76,7.86;14,151.52,196.39,145.59,7.86">Arabic medical entities tagging using distant learning in a multilingual framework</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Cotik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vivaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Rodríguez</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Submitted</note>
</biblStruct>

<biblStruct coords="14,142.96,207.34,110.54,7.86;14,271.04,207.34,209.56,7.86;14,151.52,218.30,329.07,7.86;14,151.52,229.26,297.30,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="14,271.04,207.34,209.56,7.86;14,151.52,218.30,85.94,7.86">Inducing domain-specific semantic class taggers from(almost) nothing</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,264.59,218.30,216.00,7.86;14,151.52,229.26,158.27,7.86">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="275" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,240.22,337.63,7.86;14,151.52,251.18,309.42,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="14,464.72,240.22,15.88,7.86;14,151.52,251.18,164.54,7.86">The WEKA data mining software: An update</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,338.58,251.18,89.57,7.86">SIGKDD Explorations</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,262.14,337.98,7.86;14,151.52,273.10,329.07,7.86;14,151.52,284.06,329.07,7.86;14,151.52,295.02,310.76,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="14,257.40,262.14,167.70,7.86">Freeling 3.0: Towards wider multilinguality</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Padró</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stanilovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,229.90,284.06,250.69,7.86;14,151.52,295.02,102.44,7.86">Proceedings of the 8th international conference on Language Resources and Evaluation</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Choukri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Declerck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">U</forename><surname>Dogan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Maegaard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mariani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Odijk</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Piperidis</surname></persName>
		</editor>
		<meeting>the 8th international conference on Language Resources and Evaluation</meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,305.98,337.97,7.86;14,151.52,316.93,294.01,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="14,268.99,305.98,188.70,7.86">Medical term extraction using EWN ontology</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vivaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Rodríguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,151.52,316.93,225.82,7.86">Proceedings of Terminology and Knowledge Engineering</title>
		<imprint>
			<biblScope unit="page" from="137" to="142" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,327.89,337.98,7.86;14,151.52,338.85,329.07,7.86;14,151.52,349.81,60.92,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="14,261.14,327.89,219.45,7.86;14,151.52,338.85,97.42,7.86">Using Wikipedia for term extraction in the biomedical domain: first experience</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vivaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Rodríguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,276.22,338.85,149.50,7.86">Procesamiento del Lenguaje Natural</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="251" to="254" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,360.77,337.98,7.86;14,151.52,371.73,329.07,7.86;14,151.52,382.69,310.37,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="14,328.62,360.77,151.98,7.86;14,151.52,371.73,204.28,7.86">Multilingual central repository version 3.0: upgrading a very large lexical knowledge base</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Laparra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rigau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,380.17,371.73,100.43,7.86;14,151.52,382.69,209.89,7.86">Proceedings of the Sixth International Global WordNet Conference (GWC&apos;12)</title>
		<meeting>the Sixth International Global WordNet Conference (GWC&apos;12)<address><addrLine>Matsue, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
