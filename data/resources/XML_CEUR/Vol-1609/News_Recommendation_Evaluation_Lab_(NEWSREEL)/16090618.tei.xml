<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,175.90,115.96,263.55,12.62;1,246.44,133.89,122.48,12.62">CLEF NewsREEL 2016: Image-based Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,218.64,171.56,76.68,8.74"><forename type="first">Francesco</forename><surname>Corsini</surname></persName>
							<email>corsinifrancesco0@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Delft University of Technology</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,322.49,171.56,65.28,8.74"><forename type="first">Martha</forename><surname>Larson</surname></persName>
							<email>m.a.larson@tudelft.nl</email>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Radboud University Nijmegen</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,175.90,115.96,263.55,12.62;1,246.44,133.89,122.48,12.62">CLEF NewsREEL 2016: Image-based Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BF0C71C8475C1B79E068C9945873729F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Recommender System</term>
					<term>News</term>
					<term>Image Analysis</term>
					<term>Face Detection</term>
					<term>Saliency Map</term>
					<term>Evaluation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our approach to the CLEF NewsREEL 2016 News Recommendation Evaluation Lab investigates the connection between images and users clicking behavior. Our goal is to gain a better understanding of the contribution of visual representations accompanying images (thumbnails) to the success of news recommendation algorithms as measured by standard metrics. We experiment with visual information, namely Face Detection and Saliency Map, extracted from the images that accompany news items to see if they can be used to chose news items that have a higher chance of being clicked by users. Initial results seems to suggest great CTR improvement in the Simulated Environment task, while some decrease in performance has been found in the Living Lab task. The latter result must be further validated in the future.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The CLEF NewsREEL <ref type="bibr" coords="1,242.16,464.84,10.52,8.74" target="#b4">[5]</ref> News Recommendation Evaluation Lab challenges participants to come up with an original and effective solution for providing recommendations for users in the news environment. Our participation is both for Task 1 (Living Lab Evaluation) and Task 2 (Evaluation in Simulated Environment). An overview of this year challenge results can be found at <ref type="bibr" coords="1,422.83,512.66,9.96,8.74" target="#b8">[9]</ref>.</p><p>Typical online news content providers publish images along with their news items. Our work is motivated by the conjecture that these images play a role in the effect of the recommendation, especially whether a user will click on the item. Content providers are well aware of the importance of images and are already taking advantage of them (e.g., both their informative potential, and their potential to act as clickbait). However, the effect of images for automatic recommendations is currently understudied and not well understood. Our research looks for the effect of such images, in order to determine if they can play a crucial role in the definition of a more refined recommendation. Our hypothesis is that people tend to click on news articles because they are curious about the image, as the image catches their eye, and some images depict things clearly making it very easy to see what the article is actually about. Specifically, in this work, we will focus on the usefulness of information about faces appearing and saliency in images. The Open Recommendation Platform (ORP) by plista provided a unique framework to test and benchmark our approach. Given the constraints of the online environment (100ms timeout response time, unpredictable load on the server), new and innovative architectures and algorithms were developed in order to deal with the heavy computational load caused by the image analysis. Our research also investigates whether features extracted from images can be used in a real-time recommendation pipeline.</p><p>The rest of the paper is organized as following: in section 2 we discuss the related work on how to trigger interest on images presented, plus the background needed to understand our approach to image classification. Section 3 describes our approach to solve the challenges presented in Task 1 and 2 and here our algorithm is presented. The outcome of our experiments and the results of the evaluations is presentend in section 4. The discussion 5 follows presenting future work and a wrap up for the conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work and Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Grabbing Attention</head><p>In this section, we discuss factors that trigger our eyes to land on an image. With content-based image retrieval on the rise, there is an increase in the study of cues that could help in ranking the retrieved images. A sound measure that would help to automatically rank is how interesting people find an image. Much research has been devoted to the study of interestingness on the Internet, especially with Flicker images, e.g., <ref type="bibr" coords="2,226.75,428.97,9.96,8.74" target="#b1">[2]</ref>. However, this sort of interestingness is different from what we investigate here. Specifically, it implies some sort of community and social behavior that goes beyond the effect of images merely catching the eye. The presence of this kind of behavior cannot be assumed to be present in news recommendation environment, where the images come from the news provider, rather than being contributed by community members. Flickr's interestingness is based on social parameters linked to the behavior, i.e., according to the uploader's score reputation and ratio between views, favorites and comments. As example, images with a positive connotation (smile, bright), tend to always have a higher level of interestingness in social media.</p><p>Other related research comes from the area of advertising. An accurate prediction of the probability that users click on ads is crucial for the online advertisement business. Even if with different methods, both our work and ads business share the same goal: predict (and increase) how many clicks an image(or an ad) receives. State-of-the-art click through rate prediction algorithms rely heavily on historical information collected for advertisers, users and publishers. However, recent work has seen the integration of multimedia features extracted from display ads into the click prediction models <ref type="bibr" coords="2,410.21,632.21,25.03,8.74">[1] [3]</ref>. The features related to an increase in CTR are numerous. In particular, Cheng et al. <ref type="bibr" coords="2,470.08,644.16,10.52,8.74" target="#b0">[1]</ref> present an extensive list of image features and their correlation with CTR. In this study, we focus on key features from <ref type="bibr" coords="3,322.52,118.99,9.96,8.74" target="#b0">[1]</ref>, chosen because of their promise and their feasibility in being deployed in an online environment. From a study of the literature, we found two of most interesting and investigation-worthy features: the presence of a person <ref type="bibr" coords="3,272.74,154.86,15.50,8.74" target="#b12">[13]</ref>  <ref type="bibr" coords="3,332.07,154.86,14.61,8.74" target="#b11">[12]</ref>, especially when having a face clearly visible facing the camera, and the analysis of the saliency map to detect aesthetics and simplicity <ref type="bibr" coords="3,249.77,178.77,10.52,8.74" target="#b0">[1]</ref> [3] [4] <ref type="bibr" coords="3,292.32,178.77,14.61,8.74" target="#b10">[11]</ref>. However, due to unexpected technical issues during the implementation of these features, only the presence of a person (face detection) was fully developed at the start of the Task 1 challenge. For this reason, it was the only one adopted for consistency throughout all the Task 1 evaluation window. However both features have been tested together in the Task 2 part of the challenge.</p><formula xml:id="formula_0" coords="3,291.31,154.86,37.69,8.74">[2] [3] [1]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Image Classification</head><p>Our approach is based on a straightforward binary image classifier, which classifies the image of the target item (thumbnail) as either "interesting" or "not interesting". The motivation behind this choice of binary classifiers is the lack of time resources and easy management of the results; a better and more refined approach to the classification (e.g. degrees of interestingness) is planned in future work 5.3. The classification process can be summarized simply as follows: According to our research an image is interesting if it either has:</p><p>-The presence of a person: A single central person (portrait) is preferred over multiple people all over the image -A single cluster in the middle of the image with a flat background. A single object is preferred over multiple objects</p><p>As for example, the Fig. <ref type="figure" coords="3,251.91,422.64,9.96,8.74">1a</ref> and 1b are considered "interesting", 1a for the presence of a face and 1b for satisfying the single object in the center. While 1c does not satisfy either of the two requirements. 3 Approach</p><p>Our approach was designed to validate our hypothesis that images impact user clicks on recommendations rather than to reach the maximum possible CTR.</p><p>The Living Lab Evaluation <ref type="bibr" coords="4,257.88,130.95,10.52,8.74" target="#b5">[6]</ref> (Task 1) was executed on the ORP, where part of plista's traffic is redirected. The ORP makes it possible to deploy and test algorithms in a real environment. The platform uses HTTP protocol supporting JSON format for data. Communication is handled by four types of messages: Recommendation requests, Impressions, Item Updates, Error Messages. The timeout for the waiting for the response is 100ms: if the system does not answer within this timeframe, the request is considered as an "error"</p><p>The Evaluation in Simulated Environment <ref type="bibr" coords="4,331.00,226.59,15.49,8.74" target="#b9">[10]</ref> (Task 2) officially makes use of a set of data provided by the NewsREEL organizers. The set includes item updates and event notification <ref type="bibr" coords="4,271.07,250.50,9.96,8.74" target="#b7">[8]</ref>. However, this official dataset did not have a crucial field which was required by our image-based algorithm: the img url. Although the field itself is present, the official data set was collected in June 2013 and the most part of the links have disappeared since the images are hosted by the publishers themselves. Domains tend to remove the items (especially images) after some time of inactivity, by cleaning their databases of old dated articles, as they take much space and do not generate any kind of traffic. Our participation in CLEFNewsREEL using the "official" dataset is, for this reason, compromised. However, this fact did not prevent us from testing our algorithms on another offline dataset. The data used are daily dumps from the plista ORP platform, just like the original dataset with a much more recent date (May 2016).</p><p>The algorithms developed and tested are the following:</p><p>-Task 1: Baseline1 -Task 1: Baseline1 + Faces -Task 2: Baseline1 -Task 2: Baseline1 + Faces -Task 2: Baseline1 + Faces + Salience -Task 2: Baseline2 -Task 2: Baseline2 + Faces + Salience</p><p>Baseline1 is a Popularity with a freshness windows of 100 items, while Base-line2 is Random with the same freshness windows. For the remaining part of the paper these two algorithms will be called Pop100 and Rand100. By looking at the difference between the image enhanced algorithm and the relative baseline we can understand the effectiveness of image-based recommendation in the news environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Algorithm</head><p>Although the algorithms deployed in the Living Lab Evaluation (Task 1) differed from the one deployed in the Evaluation in Simulated Environment (Task 2), the logic behind them is quite similar and can be summarized as follows:</p><p>A recency windows for each combination of category/domain is created, each window encompassing 100 items. Every time a new update comes in, it is processed by taking the url img field and scraping the corresponding image from the website. Features for the image are computed with our image processing algorithms, namely Viola-Jones <ref type="bibr" coords="5,274.96,166.81,15.50,8.74" target="#b13">[14]</ref> for face detection and spectral residuals <ref type="bibr" coords="5,470.07,166.81,10.52,8.74" target="#b6">[7]</ref> for the saliency map. The saliency map involves the extraction of several subfeatures (e.g., number of objects and their positions, background to foreground ratio) which are then used to detect if the image satiefies the requirement of being a single cluster in the middle of the image. This newly processed item is then added to the possible recommendations list, while the oldest item in the list is discarded (if full).</p><p>For the Pop100 algorithm: These items are sorted by a popularity score, which is an aggregation of how many impressions the item has received plus how many clicks it received in previous recommendations. Whenever a recommendation request arrives, the top N items are selected and only picked if they individually satisfy the "visual requirements" (see 2.2). If not enough items have been gathered before the top C elements have been considered, then standard popularity is used instead, without taking into consideration the "visual requirements" in order to fill the remaining spots. For the Rand100 algorithm, the logic is the same, however the ranking step is replaced by a random picking of items. The first C random times the item will be picked only if it satisfies the "visual requirements", after C times this restriction decays.</p><p>The constant C has been determined from empirical testing, and it can be interpreted as a tradeoff between "being interesting" and "following the baseline". In case of Pop100, the smaller C the most the items will be popular and less "visually interesting". As our intention here is to test if the visual component has an effect, C has been intentionally exaggerated in order to make the effect more notable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Living Lab Evaluation</head><p>The Online results show the data obtained from the scoreboard in the ORP during the evaluation window. Although the evaluation itself ran for around 40 days, not all the days have been taken in consideration due to issues which resulted in the recommender receiving a low volume of requests. As a result, only 24 days have been considered for the results. In order to answer our research question we decided to benchmark our image enhanced algorithm against its own baseline without image information. As for the Online, Pop100 is the baseline.</p><p>As can be seen from the Fig. <ref type="figure" coords="5,279.66,620.25,3.87,8.74">2</ref>: although the image enhanced recommender had more overall clicks, the baseline performed better in CTR value over long period of time. The Pop100+Faces sees a 28% decrease in CTR over the baseline Pop100. Our conclusion is that the lower result is actually due to a mixture Fig. <ref type="figure" coords="6,178.39,297.44,3.87,8.74">2</ref>: Online Pop100 vs Pop100+FacesDetection: Cumulative CTR of technical problems that most likely undermined the performance of the algorithm. A rundown of the problems can be found in the discussion in section 5.1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation in Simulated Environment</head><p>The Task 2 evaluation was done by using the dataset from ORP daily dumps. Three non-consecutive days have been used as a test set. We consider three days to be the minimum-sized data set large enough to provide a reliable comparison. Each day has an average of 68.000 requests. Since the algorithm running in the Task 1 environment accumulated a total of 175.000 requests over a month, we needed three days to reach approximately the same number of requests to have a comparable size for the dataset. Further testing is planned over a larger dataset in the future. The evaluation metric works as following: A recommendation is a successful hit if the user lands on the recommended page within 10 minutes of navigating the website. In this testing we conducted tests over two different baselines: Rand100 and Pop100. Rand100 was introduced in order to "weaken" the strength of the baseline algorithm in order to better show the effect of the Image features. The results can be seen in the Table <ref type="table" coords="6,366.40,603.88,4.98,8.74" target="#tab_0">1</ref> Introducing Image-based recommendation leads to a clicks increase of 51% with respect to the baseline Rand100, while the increase is 36% with respect to the Pop100 when considering only faces, 22% with both features. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>The results from the Task 1 and Task 2 evaluation differ: we think that this may be due to the inherent difference between the testing environments. We discuss this with more details in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Living Lab Evaluation</head><p>The results gathered during the evaluation window of a month suggest that the baseline (Pop100) performs better than the image-based algorithm. This can be partially attributed to the technical problems which the image-based algorithm faced when running online.</p><p>One of the problem encountered was to make the algorithm fast enough to keep up with the ORP rate of updates. While the requests sent by the platform do follow the performance of the algorithm (if the algorithm is struggling less requests are sent), this does not apply to the updates; therefore all the updates are sent at anytime. Updates are the "computationally intensive" part in our algorithm, as each update usually comes with an image that needs to be downloaded and analyzed. Updates tend to come in groups of 10 or more, making it necessary to queue them. Even when trying to solve the matter with various strategies, it sometimes happened that the next batch of updates came before the queue was all processed, making the queue longer and the processing time even longer, thus making the problem worse: if repeated enough times the server would crash and get rebooted, therefore going through a new cold start period. Longer queue and longer processing time meant longer delay to answer recommendation requests as well, thus failing due to the timeout time. The time resources available for this research were necessary limited and not all solutions to this problem have been explored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation in Simulated Environment</head><p>The Evaluation method used in this task does make the CTR quite worse than the one obtained in Task 1, as there is no actual user answering directly to the recommendation shown. Therefore no direct CTR comparison can be made.</p><p>However the difference between the baseline and the baseline+visual information can be used to infer the effect of such features.</p><p>For both baselines Rand100 and Pop100 we can see a significant improvement of the CTR when we make use of the Image information. As expected the increase is bigger in the "weaker" baseline, Rand100. However the most striking difference is the improved performance over the Pop100, especially when compared with the results of the similar experiment conducted Task 1. This strengthens our idea that the Task 1 implementations results were jeopardized by the poor technical performance rather than the Image-based recommendation model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Future Work</head><p>The algorithm and the approach developed during this challenge was intended to be an exploratory task. Much is still needed to indeed prove the real effect of images on the recommendation.</p><p>Both Task 1 and Task 2 testing needs to be continued on all the possible combinations of baselines and features used in this paper, in order to test both the single effect of the features independently and their strength against different baselines. This is especially needed in order to investigate further the difference between Task 1 and Task 2, especially in light of the results obtained in this paper. A larger dataset (including images) needs to be used for testing in Task 2. This is our aim in the forthcoming future. Improvement in efficiency and running times are needed in order to allow the algorithm to properly work in an Living Lab environment. The current implementation has many flaws that likely resulted in many delays and worse CTR. A possible approach could be to not compute images until they reach a minimum level of popularity: this would filter out many "socially uninteresting" images.</p><p>Although this paper has focused its attention on the exploitation of high level visual clues (people, saliency map), a more in depth analysis of other feature classes may reveal useful insights. Notable global features include colorfulness, brightness and saturation. Another interesting approach could be the inclusion of visual information of how and where the recommendation is displayed (website related features). All of this on top of a more refined approach to the classification, by introducing different degrees of interestingness in the process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Conclusion</head><p>Task 1 and Task 2 results seems to contradict each other at the first look. Task 2 shows an increase of the recommender performance while Task 1 shows a decrease. We can partially explain the difference by the fact that early Task 1 implementation ran in technical difficulties typical of the online environment, which partially jeopardized the final outcome.</p><p>By looking at the Task 2 results we can clearly see an improvement of the CTR when introducing image-based recommendations. This initial result seems to suggest a great improvement even when combined with already strong baselines (Popularity/Recency). More experiments with different baseline combinations and settings are required in the future to definitively prove the effectiveness of image-based recommendation in the news environment. We think that the results shown in this paper provide a good initial confirmation of its potential.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,295.85,571.36,23.66,8.74;3,255.80,485.04,103.75,57.86"><head></head><label></label><figDesc>Fig. 1</figDesc><graphic coords="3,255.80,485.04,103.75,57.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,211.45,127.36,192.46,85.95"><head>Table 1 :</head><label>1</label><figDesc>Task 2 Results    </figDesc><table coords="7,211.45,139.70,192.46,73.62"><row><cell>Algorithm</cell><cell>Clicks Requests CTR</cell></row><row><cell>Rand100</cell><cell>258 204456 0.13%</cell></row><row><cell cols="2">Rand100+Face+Salience 390 202254 0.19%</cell></row><row><cell>Pop100</cell><cell>630 204120 0.31%</cell></row><row><cell>Pop100+Face</cell><cell>857 203893 0.42%</cell></row><row><cell cols="2">Pop100+Face+Salience 771 203979 0.38%</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,142.96,243.28,337.64,7.86;9,151.52,254.24,329.07,7.86;9,151.52,265.20,329.07,7.86;9,151.52,276.16,254.92,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,313.63,254.24,166.97,7.86;9,151.52,265.20,133.76,7.86">Multimedia Features for Click Prediction of New Ads in Display Advertising</title>
		<author>
			<persName coords=""><forename type="first">Haibin</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roelof</forename><surname>Van Zwol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Javad</forename><surname>Azimi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eren</forename><surname>Manavoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ruofei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vidhya</forename><surname>Navalpakkam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,302.31,265.20,178.28,7.86;9,151.52,276.16,163.50,7.86">18th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="777" to="785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,286.79,337.63,7.86;9,151.52,297.75,329.07,7.86;9,151.52,308.71,329.07,7.86;9,151.52,319.67,178.51,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,175.49,297.75,301.27,7.86">High level describable attributes for predicting aesthetics and interestingness</title>
		<author>
			<persName coords=""><forename type="first">Sagnik</forename><surname>Dhar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tamara</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stony</forename><surname>Brook</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vicente</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tamara</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,151.52,308.71,329.07,7.86;9,151.52,319.67,78.16,7.86">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1657" to="1664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,330.30,337.64,7.86;9,151.52,341.26,329.07,7.86;9,151.52,352.22,131.56,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,201.50,330.30,279.09,7.86;9,151.52,341.26,44.88,7.86">The Impact of Visual Appearance on User Response in Online Display Advertising</title>
		<author>
			<persName coords=""><forename type="first">Fern</forename><surname>Xiaoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,204.05,341.26,276.54,7.86;9,151.52,352.22,39.41,7.86">Proceedings of the 21st international conference companion on World Wide Web</title>
		<meeting>the 21st international conference companion on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="457" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,362.85,337.63,7.86;9,151.52,373.81,329.07,7.86;9,151.52,384.77,101.01,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,428.07,362.85,52.52,7.86;9,151.52,373.81,67.33,7.86">The Interestingness of Images</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Gygli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Grabner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Riemenschneider</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Nater</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,226.34,373.81,254.25,7.86;9,151.52,384.77,8.29,7.86">Computer Vision (ICCV), 2013 IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1633" to="1640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,395.41,337.64,7.86;9,151.52,406.37,329.07,7.86;9,151.52,417.32,329.07,7.86;9,151.52,428.28,56.46,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,400.81,406.37,79.78,7.86;9,151.52,417.32,202.15,7.86">Benchmarking news recommendations: The CLEF NewsREEL use case</title>
		<author>
			<persName coords=""><forename type="first">Frank</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Torben</forename><surname>Brodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jonas</forename><surname>Seiler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><surname>Kille</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andreas</forename><surname>Lommatzsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martha</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roberto</forename><surname>Turrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">András</forename><surname>Serény</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,361.23,417.32,53.31,7.86">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="129" to="136" />
			<date type="published" when="2016-01">January 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,438.92,337.64,7.86;9,151.52,449.88,329.07,7.86;9,151.52,460.84,225.56,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="9,258.74,449.88,217.65,7.86">Benchmarking News Recommendations in a Living Lab</title>
		<author>
			<persName coords=""><forename type="first">Frank</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><surname>Kille</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andreas</forename><surname>Lommatzsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Till</forename><surname>Plumbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Torben</forename><surname>Brodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tobias</forename><surname>Heintz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="page" from="250" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,471.47,337.63,7.86;9,151.52,482.43,329.07,7.86;9,151.52,493.39,149.27,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,281.85,471.47,194.38,7.86">Saliency detection: A spectral residual approach</title>
		<author>
			<persName coords=""><forename type="first">Xiaodi</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liqing</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,151.52,482.43,329.07,7.86;9,151.52,493.39,78.16,7.86">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,504.02,337.63,7.86;9,151.52,514.98,329.07,7.86;9,151.52,525.94,100.67,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,439.60,504.02,40.99,7.86;9,151.52,514.98,29.50,7.86">The plista Dataset</title>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><surname>Kille</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Frank</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Torben</forename><surname>Brodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tobias</forename><surname>Heintz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,201.02,514.98,279.57,7.86;9,151.52,525.94,18.99,7.86">2013 International News Recommender Systems Workshop and Challenge</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="16" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,536.57,337.64,7.86;9,151.52,547.53,329.07,7.86;9,151.52,558.49,329.07,7.86;9,151.52,569.45,329.07,7.86;9,151.52,580.41,329.07,7.86;9,151.52,591.37,329.07,7.86;9,151.52,602.33,329.07,7.86;9,151.52,613.29,312.21,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,263.46,558.49,217.13,7.86;9,151.52,569.45,226.82,7.86">Overview of NewsREEL&apos;16: Multi-dimensional Evaluation of Real-Time Stream-Recommendation Algorithms</title>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><surname>Kille</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andreas</forename><surname>Lommatzsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gebrekirstos</forename><surname>Gebremeskel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Frank</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martha</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jonas</forename><surname>Seiler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Davide</forename><surname>Malagoli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andras</forename><surname>Sereny</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Torben</forename><surname>Brodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arjen</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vries</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,333.29,591.37,147.30,7.86;9,151.52,602.33,329.07,7.86;9,151.52,613.29,86.85,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction 7th International Conference of the CLEF Association, CLEF 2016</title>
		<editor>
			<persName><forename type="first">Norbert</forename><surname>Fuhr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Birger</forename><surname>Larsen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Teresa</forename><surname>Goncalves</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Linda</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Evora, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">September 5-8, 2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,623.92,337.98,7.86;9,151.52,634.88,329.07,7.86;9,151.52,645.84,329.07,7.86;9,151.52,656.80,124.61,7.86" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="9,394.15,634.88,86.44,7.86;9,151.52,645.84,224.07,7.86">Stream-Based Recommendations: Online and Offline Evaluation as a Service</title>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><surname>Kille</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andreas</forename><surname>Lommatzsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roberto</forename><surname>Turrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">András</forename><surname>Serény</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martha</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Torben</forename><surname>Brodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jonas</forename><surname>Seiler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Frank</forename><surname>Hopfgartner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="page" from="497" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,119.67,337.98,7.86;10,151.52,130.63,329.07,7.86;10,151.52,141.59,329.07,7.86;10,151.52,152.55,75.08,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,294.64,119.67,185.95,7.86;10,151.52,130.63,198.20,7.86">The Role of Visual Attention in the Aesthetic Appeal of Comsumer Images: a Preliminary Study</title>
		<author>
			<persName coords=""><forename type="first">Judith</forename><forename type="middle">A</forename><surname>Redi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Isabel</forename><surname>Povoa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,367.95,130.63,112.63,7.86;10,151.52,141.59,99.65,7.86">Visual Communications and Image Processing (VCIP)</title>
		<meeting><address><addrLine>The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>Intelligent Systems, Delft University of Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,163.51,337.97,7.86;10,151.52,174.47,329.07,7.86;10,151.52,185.43,294.29,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,191.71,174.47,288.89,7.86;10,151.52,185.43,94.80,7.86">Gaze direction and facial expressions exert combined but different effects on attentional resources</title>
		<author>
			<persName coords=""><forename type="first">Paola</forename><surname>Ricciardelli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cristina</forename><surname>Iani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luisa</forename><surname>Lugli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonello</forename><surname>Pellicano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roberto</forename><surname>Nicoletti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,254.31,185.43,92.18,7.86">Cognition and Emotion</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1134" to="1142" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,196.39,337.98,7.86;10,151.52,207.34,318.26,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,425.58,196.39,55.02,7.86;10,151.52,207.34,156.68,7.86">Evaluation of image appeal in consumer photography</title>
		<author>
			<persName coords=""><forename type="first">Andreas</forename><forename type="middle">E</forename><surname>Savakis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><forename type="middle">P</forename><surname>Etz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><forename type="middle">C P</forename><surname>Loui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,316.72,207.34,45.44,7.86">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">3959</biblScope>
			<biblScope unit="page" from="111" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,218.30,337.98,7.86;10,151.52,229.26,329.07,7.86;10,151.52,240.22,20.99,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,246.44,218.30,234.15,7.86;10,151.52,229.26,30.33,7.86">Rapid object detection using a boosted cascade of simple features</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,189.11,229.26,202.69,7.86">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="511" to="518" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
