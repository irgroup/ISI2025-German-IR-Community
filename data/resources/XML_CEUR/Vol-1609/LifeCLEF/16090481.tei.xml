<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,134.90,116.95,345.56,12.62;1,183.62,134.89,248.12,12.62">SeaCLEF 2016: Object proposal classification for fish detection in underwater videos</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,142.70,172.56,51.28,8.74"><forename type="first">Jonas</forename><surname>JÃ¤ger</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Information Technology</orgName>
								<orgName type="institution">Fulda University of Applied Sciences</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Computer Vision Group</orgName>
								<orgName type="institution">Friedrich Schiller University Jena</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,210.87,172.56,54.02,8.74"><forename type="first">Erik</forename><surname>Rodner</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Vision Group</orgName>
								<orgName type="institution">Friedrich Schiller University Jena</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,275.45,172.56,72.26,8.74"><forename type="first">Joachim</forename><surname>Denzler</surname></persName>
							<email>joachim.denzler@uni-jena.de</email>
							<affiliation key="aff1">
								<orgName type="department">Computer Vision Group</orgName>
								<orgName type="institution">Friedrich Schiller University Jena</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,358.26,172.56,59.50,8.74"><forename type="first">Viviane</forename><surname>Wolff</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Information Technology</orgName>
								<orgName type="institution">Fulda University of Applied Sciences</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,447.70,172.56,24.95,8.74;1,270.48,184.51,69.93,8.74"><forename type="first">Klaus</forename><surname>Fricke-Neuderth</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Information Technology</orgName>
								<orgName type="institution">Fulda University of Applied Sciences</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,257.93,239.59,52.12,7.47"><forename type="first">Klaus</forename><surname>Wolff</surname></persName>
						</author>
						<author>
							<persName coords="1,314.79,239.59,28.43,7.47"><surname>Fricke</surname></persName>
						</author>
						<title level="a" type="main" coord="1,134.90,116.95,345.56,12.62;1,183.62,134.89,248.12,12.62">SeaCLEF 2016: Object proposal classification for fish detection in underwater videos</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">114B307F2F66197D88F8B8899E941699</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Object proposals</term>
					<term>R-CNN</term>
					<term>CNN features</term>
					<term>Fine-grained classification</term>
					<term>Fish detection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This working note describes the results of CVG Jena Fulda team for the fish recognition task in SeaCLEF 2016. Our method is based on convolutional neural networks applied to object proposals for detection as well as species classification. We are using background subtraction proposals that are filtered by a binary SVM classifier for fish detection and a multiclass SVM for species classification. Both SVM's utilize CNN features extracted from AlexNet. With this pipeline we achieve a recognition precision of 66% and a normalized counting score of 58% on the provided test dataset. We also show that classification of background subtraction proposals works much better for fish detection than background subtraction on its own.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper presents the participation of the CVG Jena Fulda team in the SeaCLEF 2016 Task 1. This task deals with automatic fish recognition of coral reef species in low resolution videos. All fishes are presented in their natural unrestricted habitat. See Fig. <ref type="figure" coords="1,265.91,525.61,4.98,8.74" target="#fig_0">1</ref> for example frames.</p><p>This task is important to enhance computer vision methods for biodiversity applications. Many scientists in the field of ecology collect large amounts of video data to monitor biodiversity in their specific applications. But manual analysis of this data is time consuming and requires knowledge of rear human experts, which makes it impossible to evaluate data in a large scale. However, this large scale analysis is essential to obtain the knowledge to save ecosystems that have a large impact on the human population. Therefore, tools for automatic video analysis need to be developed to support the work of ecologists.</p><p>We have a special interest in this task because our team works on a closely related problem <ref type="bibr" coords="1,206.77,645.16,9.96,8.74" target="#b6">[7]</ref>. In our application we deal with high resolution underwater video analysis of fish species at the Adriatic sea in Croatia.</p><p>We noticed that detection is a crucial part in a fish classification and counting system. But we also experienced that fish detection is a difficult problem, due to lighting changes and the complex background in a natural environment. Therefore, we focus in the following paper on robust fish detection.</p><p>Last years participants <ref type="bibr" coords="2,257.36,170.43,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="2,269.54,170.43,7.75,8.74" target="#b2">3]</ref> in this task used median image background subtraction for fish detection. Boom et al. <ref type="bibr" coords="2,332.77,182.39,10.52,8.74" target="#b0">[1]</ref> also utilized background subtraction methods and post processed detection results with an objectness filter to remove bad detections. In contrast to that, we classify fish proposals by CNN features <ref type="bibr" coords="2,197.67,218.25,9.96,8.74" target="#b3">[4]</ref>.</p><p>In this work we propose the use of object proposal classification for fish detection. Object proposals are obtained by background subtraction and then classified into fish and background by a binary support vector machine (SVM). For fish recognition we utilize a multiclass SVM trained for the 15 considered species. Both SVM's are using the same CNN features, extracted from AlexNet <ref type="bibr" coords="2,134.77,292.60,9.96,8.74" target="#b7">[8]</ref>, for prediction.</p><p>Our detection approach is very similar to the idea of region-based convolutional neural networks (R-CNN) presented by Girshick et al. <ref type="bibr" coords="2,403.74,319.13,9.96,8.74" target="#b5">[6]</ref>. In contrast to <ref type="bibr" coords="2,134.77,331.09,10.52,8.74" target="#b5">[6]</ref> we are using the background subtraction method of Stauffer and Grimson <ref type="bibr" coords="2,134.77,343.04,15.50,8.74" target="#b12">[12]</ref> instead of selective search <ref type="bibr" coords="2,268.47,343.04,15.50,8.74" target="#b14">[14]</ref> for proposal generation, since we can exploit time information in the video data. Another difference is that we do not apply domain specific fine tuning to the CNN. The provided training set consists of 20 low resolution videos and more than 20000 sample images of 15 fish species. There are 5 videos with a resolution of 640 Ã 480 pixels and 15 videos with 320 Ã 240 pixels. All videos are annotated by two human experts with bounding boxes and species names.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Fish Dataset</head><p>The test set contains 73 videos with a resolution of 320 Ã 240 pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset preparation:</head><p>We split the given training videos into two parts with 10 videos each. One part will be used as validation set. The other 10 videos and all sample images will be used for training and will be called training set in the rest of this paper.</p><p>3 Method</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>Our main idea is to build a fish detector and to use detections for species classification. Since the application of background subtraction methods on its own leads to a large number of false detections, we use background subtraction to get fish proposals and classify each proposal as as fish or background. Then, all fish detections are classified as one of 15 species or rejected. Both classifieres, for detection and species recognition, are using the same features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Object proposal classification for fish detection</head><p>Our fish detection approach consists of three steps. (1.) Generation of bounding box proposals. (2.) Extraction of CNN features for each proposal. (3.) Classification of each bounding box proposal as fish or background. Please see Fig. <ref type="figure" coords="3,460.76,477.35,4.98,8.74" target="#fig_1">2</ref> for illustration of these steps.</p><p>In step (1.) we use the background subtraction algorithm of Stauffer and Grimson <ref type="bibr" coords="3,175.09,513.36,14.61,8.74" target="#b12">[12]</ref>, which uses a probabilistic background model that represents each pixel as a mixture of Gaussians. The result of this algorithm is a binary mask that indicates which pixels are background (see Fig. <ref type="figure" coords="3,369.62,537.27,8.30,8.74" target="#fig_1">2a</ref>). This mask is further used to obtain a second background mask (see Fig. <ref type="figure" coords="3,363.07,549.23,9.59,8.74" target="#fig_1">2b</ref>) by applying an erosion filter to it, which allows us to separate nearby fishes.</p><p>After that we apply the blob detection method of Suzuki and Abe <ref type="bibr" coords="3,452.10,573.28,15.50,8.74" target="#b13">[13]</ref> to both masks to get bounding box proposals (see Fig. <ref type="figure" coords="3,368.78,585.24,8.03,8.74" target="#fig_1">2c</ref>). Bounding boxes that have a smaller area than 100 pixels are removed, since these proposals are to small for species classification.</p><p>(2.) Now we use the generated proposals to extract CNN features from AlexNet <ref type="bibr" coords="3,173.69,633.20,9.96,8.74" target="#b7">[8]</ref>, that was pretrained on ILSVRC 2012 <ref type="bibr" coords="3,362.07,633.20,14.61,8.74" target="#b11">[11]</ref>. As features we choose the activations of the 7th hidden layer (relu7 ) in the convolutional network. Note that we did not fine tune the convolutional net by training it with fish images. (3.) Based on these features we utilize a binary SVM for classifying each bounding box proposal as fish or background (see Fig. <ref type="figure" coords="4,369.49,498.40,8.58,8.74" target="#fig_1">2d</ref>). Then we choose from all fish detections the boxes with a confidence level that is higher or equal to 0.5. In oder to obtain a probability measure from SVM scores we used Platt scaling <ref type="bibr" coords="4,134.77,534.26,15.50,8.74" target="#b10">[10]</ref> as implemented in scikit-learn <ref type="bibr" coords="4,287.67,534.26,9.96,8.74" target="#b9">[9]</ref>.</p><p>As a post processing step we apply non-maximum suppression to remove duplicate boxes for all fishes.</p><p>Detector training: To train our detector we extract CNN features (see step (2.)) and fit the SVM classifier to the classes background and fish. As training data we utilize the fish sample images of the training set (see section 2) and extract all annotated fishes from the 10 training videos. As background examples we generate object proposals from training set videos and extract those boxes that have no intersection with a ground truth fish box.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Species classification using CNN features</head><p>As in our previous work <ref type="bibr" coords="5,244.18,138.38,10.52,8.74" target="#b6">[7]</ref> we use CNN features <ref type="bibr" coords="5,354.08,138.38,10.52,8.74" target="#b3">[4]</ref> and a multiclass SVM for species prediction. We utilize the same CNN features that where extracted in detection step (2.) from AlexNet <ref type="bibr" coords="5,286.92,162.29,9.96,8.74" target="#b7">[8]</ref>, which was pretrained on ImageNet. As features we choose the activations of the 7th hidden layer (relu7) in the network.</p><p>When the confidence level for a classification is lower than 0.5 we consider it as an unknown fish and reject it. In order to get probabilities from SVM scores we use the method of Wu et al. <ref type="bibr" coords="5,275.12,210.11,14.61,8.74" target="#b15">[15]</ref>.</p><p>The SVM is trained with a one-vs-rest strategy for the 15 considered fish species. The training data are composed of the provided species sample images and all annotated fishes cropped from training set (see section 2) videos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Fish detection results</head><p>One of our main interest is how well object proposal classification (OPC) works for fish detection compared to background subtraction on its own. For that purpose we will first describe the methods listed in results Tab. 1 and then define our Pascal VOC <ref type="bibr" coords="5,241.09,352.93,10.52,8.74" target="#b4">[5]</ref> like evaluation process. Finally we will discuss our fish detection results presented in Fig. <ref type="figure" coords="5,304.54,364.89,4.98,8.74">3</ref> and Tab. 1. Methods: The first method, called BgsMedian in Tab. 1, computes a median background image for all frames in a video and subtracts the current frame from that background image. A specific pixel in the median image is calculated by using the median value of all pixels at same position in the video. This method was also used by last year participants <ref type="bibr" coords="5,306.12,597.34,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="5,318.30,597.34,7.01,8.74" target="#b1">2]</ref>.</p><p>The second method, referenced as BgsGMM, was developed by Stauffer and Grimson <ref type="bibr" coords="5,176.28,621.25,15.50,8.74" target="#b12">[12]</ref> and uses a probabilistic background model that represents each pixel as a mixture of Gaussians.</p><p>To obtain bounding boxes from these background subtraction methods we applied blob detection proposed by Suzuki and Abe <ref type="bibr" coords="5,363.99,657.11,14.61,8.74" target="#b13">[13]</ref>. Fig. <ref type="figure" coords="6,153.45,361.79,3.87,8.74">3</ref>: Precision-Recall graph for fish detection with OPC (object proposal classification) and background subtraction on its own. OPC (BgsMedian) and OPC (BgsGMM) are using the pipeline described in section 3.2 with the exception that BgsMedian is used for bounding box proposal generation in OPC (BgsMedian).</p><p>In our Experiments we fine tuned the parameter of the background subtraction methods for fish detection when used on its own. When we used these methods for proposal generation the parameter have been adjusted to get many fish proposals.</p><p>Evaluation process: As in Pascal VOC <ref type="bibr" coords="6,325.57,517.92,9.96,8.74" target="#b4">[5]</ref>, we consider a fish detection as correct (true positive) if the intersection over union ratio (iou) for a ground truth box with a predicted box is greater or equal to 0.5. If there is more than one predicted box that satisfies this condition for a specific ground truth box: Then one predicted box is considered as true positive and the remaining boxes are counted as false positives.</p><p>Discussion: Fig. <ref type="figure" coords="6,216.01,609.29,4.98,8.74">3</ref> and Tab. 1 present detection results for the above mentioned methods. The OPC (BgsGMM) approach works best in our setup. For detection by background subtraction BgsGMM has a higher average precision score than BgsMedain. Whereby average precision of BgsGMM is 36.35% lower than OPC (BgsGMM).</p><p>In general it can be observed that OPC detection approaches work better than background subtraction in our setup, although the CNN was not fine tuned to fish images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Species classification</head><p>For species classification we used the detections of OPC (BgsGMM) and extracted CNN features to classify each detection as one of the 15 considered fish species. If the confidence level for a classification was lower than 0.5 it was rejected.</p><p>With this pipeline we achieve a counting score (CS) of 83%, a precision of 66% and a normalized counting score (NCS) of 58% (see Fig. <ref type="figure" coords="7,411.05,259.73,3.87,8.74" target="#fig_2">4</ref>). CS and NCS are used as scoring functions in SeaCLEF 2016 and are defined as:</p><formula xml:id="formula_0" coords="7,280.73,292.58,199.86,13.80">CS = e -d N gt (1)</formula><p>with d as the difference between the number of ground truth occurrences N gt and the predicted occurrences per species.</p><formula xml:id="formula_1" coords="7,257.84,355.70,222.75,8.74">N CS = CS â¢ precision<label>(2)</label></formula><p>Fig. <ref type="figure" coords="7,170.46,379.32,4.98,8.74" target="#fig_2">4</ref> shows the results for SeaCLEF 2016. From this year participants we have achieved the best results in the fish species identification task. Compared to last years winner <ref type="bibr" coords="7,227.62,403.23,10.52,8.74" target="#b2">[3]</ref> who achieved a CS of 89%, a precision of 81% and a NCS of 72% there is still a little work to do. In future we plan to incorporate tracking, which will improve fish detection and classification results. We further plan to use larger CNN models and want to fine tune these models for fishes, since this worked really well for Choi <ref type="bibr" coords="7,299.34,451.05,9.96,8.74" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper described our participation in SeaCLEF 2016 fish species recognition task. We focused on robust fish detection, since the simple application of background subtraction methods leads to a large number of false detections. Therefore we compared traditional background subtraction methods, mainly used for fish detection so far, with object proposal classification (OPC) for detection. We show that OPC fish detection (Fig. <ref type="figure" coords="7,309.71,572.29,4.43,8.74" target="#fig_1">2</ref>) works much better than background subtraction (Fig. <ref type="figure" coords="7,211.64,584.25,4.43,8.74">3</ref>) in our setup.</p><p>For species recognition we use the same CNN features as for detection and classified each fish with a multiclass SVM. Using this pipeline we achieve a normalized counting score of 58% and a precision of 66% (see Fig. <ref type="figure" coords="7,438.75,620.68,4.43,8.74" target="#fig_2">4</ref>) on the provided test dataset.</p><p>For the future we plan to incorporate fish tracking. We also want to use larger CNN models and fine tune these models to fish data. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,136.43,653.53,342.49,8.74;2,134.77,469.08,345.84,172.92"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Example frames from six different videos of the SeaCLEF 2016 dataset.</figDesc><graphic coords="2,134.77,469.08,345.84,172.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,134.77,421.22,345.82,8.74;4,134.77,433.17,345.83,8.74;4,134.77,445.13,23.83,8.74;4,143.41,276.03,155.63,116.72"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Result images of different stages in our fish detection pipeline. Red boxes are predicted and blue boxes are ground truth. This figure is best viewed in color.</figDesc><graphic coords="4,143.41,276.03,155.63,116.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,134.77,311.71,345.83,8.74;8,134.77,323.66,21.03,8.74;8,134.77,116.83,345.82,183.35"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Results, published on the SeaCLEF 2016 website. Our team is shown in blue.</figDesc><graphic coords="8,134.77,116.83,345.82,183.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,152.06,116.83,311.24,233.43"><head></head><label></label><figDesc></figDesc><graphic coords="6,152.06,116.83,311.24,233.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,134.77,407.06,345.83,102.20"><head>Table 1 :</head><label>1</label><figDesc>Average precision for OPC (object proposal classification) detection and background substraction on our validation dataset. All values are in percent.</figDesc><table coords="5,205.32,443.77,204.71,65.50"><row><cell>Method</cell><cell>average precision</cell></row><row><cell>BgsMedian</cell><cell>0.34</cell></row><row><cell>BgsGMM</cell><cell>4.35</cell></row><row><cell>OPC (BgsMedian)</cell><cell>18.28</cell></row><row><cell>OPC (BgsGMM)</cell><cell>40.66</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,377.11,337.64,7.86;8,151.52,388.07,329.07,7.86;8,151.52,399.03,329.07,7.86;8,151.52,409.99,295.92,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,473.68,388.07,6.91,7.86;8,151.52,399.03,329.07,7.86;8,151.52,409.99,132.08,7.86">A research tool for long-term and continuous analysis of fish assemblage in coral-reefs using underwater camera footage</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bastiaan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiyin</forename><surname>Boom</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Simone</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Palazzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Phoenix</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cigdem</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hsiu-Mei</forename><surname>Beyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fang-Pang</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Concetto</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><forename type="middle">B</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,291.66,409.99,87.20,7.86">Ecological Informatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="83" to="97" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,420.24,337.63,7.86;8,151.52,431.20,329.07,7.86;8,151.52,442.16,329.07,7.86;8,151.52,453.12,329.07,7.86;8,151.52,464.07,183.09,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,425.40,431.20,55.19,7.86;8,151.52,442.16,206.17,7.86">Exploring the use of local descriptors for fish recognition in lifeclef</title>
		<author>
			<persName coords=""><forename type="first">Jorge</forename><surname>Cabrera-Gmez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Modesto</forename><forename type="middle">Castrilln</forename><surname>Santana</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>Domnguez-Brito</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Hernandez-Sosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Josep</forename><surname>Isern-Gonzlez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Javier</forename><surname>Lorenzo-Navarro</surname></persName>
		</author>
		<idno>nbn:de:0074-1391-8</idno>
	</analytic>
	<monogr>
		<title level="m" coord="8,395.64,442.16,84.94,7.86;8,151.52,453.12,212.29,7.86">Working Notes of the 6th International Conference of the CLEF Initiative</title>
		<title level="s" coord="8,371.07,453.12,109.52,7.86;8,151.52,464.07,14.79,7.86">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="volume">1391</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,474.33,337.63,7.86;8,151.52,485.28,329.07,7.86;8,151.52,496.24,329.07,7.86;8,151.52,507.20,161.54,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,217.36,474.33,263.23,7.86;8,151.52,485.28,188.60,7.86">Fish identification in underwater video with deep convolutional neural network: Snumedinfo at lifeclef fish task</title>
		<author>
			<persName coords=""><forename type="first">Sungbin</forename><surname>Choi</surname></persName>
		</author>
		<idno>nbn:de:0074-1391-8</idno>
	</analytic>
	<monogr>
		<title level="m" coord="8,379.19,485.28,101.40,7.86;8,151.52,496.24,196.51,7.86">Working Notes of the 6th International Conference of the CLEF Initiative</title>
		<title level="s" coord="8,355.41,496.24,120.96,7.86">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="volume">1391</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,517.45,337.64,7.86;8,151.52,528.41,329.07,7.86;8,151.52,539.37,165.57,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,229.94,528.41,250.65,7.86;8,151.52,539.37,43.20,7.86">Decaf: A deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName coords=""><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ning</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno>CoRR, abs/1310.1531</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,549.62,337.63,7.86;8,151.52,560.58,329.07,7.86;8,151.52,571.54,315.91,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,301.47,560.58,179.12,7.86;8,151.52,571.54,50.25,7.86">The pascal visual object classes challenge: A retrospective</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Mark Everingham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luc</forename><surname>Ali Eslami</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,209.72,571.54,168.11,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="98" to="136" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,581.79,337.63,7.86;8,151.52,592.75,329.07,7.86;8,151.52,603.71,84.01,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="8,443.51,581.79,37.08,7.86;8,151.52,592.75,292.95,7.86">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName coords=""><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<idno>CoRR, abs/1311.2524</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,613.96,337.63,7.86;8,151.52,624.92,329.07,7.86;8,151.52,635.88,329.07,7.86;8,151.52,646.84,329.07,7.86;8,151.52,657.79,307.74,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,294.75,624.92,185.84,7.86;8,151.52,635.88,174.41,7.86">Croatian fish dataset: Fine-grained classification of fish species in their natural habitat</title>
		<author>
			<persName coords=""><forename type="first">Jonas</forename><surname>JÃ¤ger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marcel</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joachim</forename><surname>Denzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Viviane</forename><surname>Wolff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Klaus</forename><surname>Fricke-Neuderth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Claudia</forename><surname>Kruschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,296.71,646.84,183.88,7.86;8,151.52,657.79,116.06,7.86">Proceedings of the Machine Vision of Animals and their Behaviour (MVAB)</title>
		<editor>
			<persName><forename type="first">T</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">Pltz</forename><forename type="middle">S</forename><surname>Mckenna</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Amaral</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Matthews</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fisher</surname></persName>
		</editor>
		<meeting>the Machine Vision of Animals and their Behaviour (MVAB)</meeting>
		<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="2015-09">September 2015</date>
			<biblScope unit="page" from="6" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,120.67,337.63,7.86;9,151.52,131.63,329.07,7.86;9,151.52,142.59,329.07,7.86;9,151.52,153.55,84.21,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,389.29,120.67,91.30,7.86;9,151.52,131.63,160.58,7.86">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,273.67,142.59,206.92,7.86">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,238.81,153.55,120.76,7.86" xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Curran Associates</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Inc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,164.51,337.64,7.86;9,151.52,175.46,329.07,7.86;9,151.52,186.42,329.07,7.86;9,151.52,197.38,323.35,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,395.25,186.42,85.34,7.86;9,151.52,197.38,73.64,7.86">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,233.83,197.38,153.92,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,208.34,337.98,7.86;9,151.52,219.30,329.07,7.86;9,151.52,230.26,189.60,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,219.02,208.34,261.57,7.86;9,151.52,219.30,159.14,7.86">Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods</title>
		<author>
			<persName coords=""><forename type="first">John</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,334.86,219.30,145.73,7.86;9,151.52,230.26,58.07,7.86">ADVANCES IN LARGE MARGIN CLASSIFIERS</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="61" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,241.22,337.98,7.86;9,151.52,252.18,329.07,7.86;9,151.52,263.14,329.07,7.86;9,151.52,274.09,294.95,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,267.64,263.14,208.75,7.86">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName coords=""><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,151.52,274.09,200.28,7.86">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,285.05,337.98,7.86;9,151.52,296.01,329.07,7.86;9,151.52,306.97,329.07,7.86;9,151.52,317.93,20.99,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,315.03,285.05,165.56,7.86;9,151.52,296.01,70.96,7.86">Adaptive background mixture models for real-time tracking</title>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Stauffer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><forename type="middle">L</forename><surname>Grimson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,244.40,296.01,236.19,7.86;9,151.52,306.97,77.46,7.86">1999 Conference on Computer Vision and Pattern Recognition (CVPR &apos;99)</title>
		<meeting><address><addrLine>Ft. Collins, CO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-06">June 1999. 1999</date>
			<biblScope unit="page" from="2246" to="2252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,328.89,337.98,7.86;9,151.52,339.85,329.07,7.86;9,151.52,350.81,73.21,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,282.92,328.89,197.67,7.86;9,151.52,339.85,109.27,7.86">Topological structural analysis of digitized binary images by border following</title>
		<author>
			<persName coords=""><forename type="first">Satoshi</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Keiichi</forename><surname>Abe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,270.88,339.85,205.69,7.86">Computer Vision, Graphics, and Image Processing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="46" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,361.77,337.97,7.86;9,151.52,372.73,317.47,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,445.77,361.77,34.82,7.86;9,151.52,372.73,113.18,7.86">Selective search for object recognition</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R R</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">E A</forename><surname>Van De Sande</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">W M</forename><surname>Smeulders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,272.72,372.73,168.11,7.86">International Journal of Computer Vision</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,383.68,337.98,7.86;9,151.52,394.64,329.07,7.86;9,151.52,405.60,70.65,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,353.45,383.68,127.14,7.86;9,151.52,394.64,158.88,7.86">Probability estimates for multiclass classification by pairwise coupling</title>
		<author>
			<persName coords=""><surname>Ting-Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chih-Jen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ruby</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Weng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,320.30,394.64,156.11,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="975" to="1005" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
