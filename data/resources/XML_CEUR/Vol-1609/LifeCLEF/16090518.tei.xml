<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,134.77,116.95,345.83,12.62;1,166.19,134.89,282.98,12.62">Open-set Plant Identification Using an Ensemble of Deep Convolutional Neural Networks</title>
				<funder ref="#_EPekHvX">
					<orgName type="full">Scientific and Technological Research Council of Turkey (TUBITAK)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,156.12,172.56,114.72,8.74"><forename type="first">Mostafa</forename><forename type="middle">Mehdipour</forename><surname>Ghazi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Engineering and Natural Sciences</orgName>
								<orgName type="institution">Sabanci University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,281.40,172.56,74.08,8.74"><forename type="first">Berrin</forename><surname>Yanikoglu</surname></persName>
							<email>berrin@sabanciuniv.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Engineering and Natural Sciences</orgName>
								<orgName type="institution">Sabanci University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,385.42,172.56,69.35,8.74"><forename type="first">Erchan</forename><surname>Aptoula</surname></persName>
							<email>eaptoula@gtu.edu.tr</email>
							<affiliation key="aff1">
								<orgName type="department">Institute of Information Technologies</orgName>
								<orgName type="institution">Gebze Technical University</orgName>
								<address>
									<settlement>Kocaeli</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,134.77,116.95,345.83,12.62;1,166.19,134.89,282.98,12.62">Open-set Plant Identification Using an Ensemble of Deep Convolutional Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1ACEDBF20E384370427A891C9F4B4FA4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>open-set recognition</term>
					<term>plant identification</term>
					<term>deep learning</term>
					<term>convolutional neural networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Open-set recognition, a challenging problem in computer vision, is concerned with identification or verification tasks where queries may belong to unknown classes. This work describes a fine-grained plant identification system consisting of an ensemble of deep convolutional neural networks within an open-set identification framework. Two wellknown deep learning architectures of VGGNet and GoogLeNet, pretrained on the object recognition dataset of ILSVRC 2012, are finetuned using the plant dataset of LifeCLEF 2015. Moreover, GoogLeNet is fine-tuned using plant and non-plant images for rejecting samples from non-plant classes. Our systems have been evaluated on the test dataset of PlantCLEF 2016 by the campaign organizers and our best proposed model has achieved an official score of 0.738 in terms of the mean average precision, while the best official score is 0.742.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automated plant identification is a fine-grained image classification problem concerned with small inter-class and large intra-class variations. As with many other problems, recent research in this area has concentrated on deep learning schemes in which significant improvements have been obtained compared to traditional methods <ref type="bibr" coords="1,226.06,525.61,10.96,8.74" target="#b0">[1,</ref><ref type="bibr" coords="1,237.01,525.61,7.31,8.74" target="#b1">2,</ref><ref type="bibr" coords="1,244.32,525.61,7.31,8.74" target="#b2">3,</ref><ref type="bibr" coords="1,251.63,525.61,7.31,8.74" target="#b3">4]</ref>. Raw data is fed into these networks in multiple levels, allowing the system to automatically discover high-level features for plant species recognition. However, due to their high computational complexity for training from scratch, the existing pre-trained deep networks are fine-tuned for plant identification purposes <ref type="bibr" coords="1,261.93,573.43,10.79,8.74" target="#b1">[2,</ref><ref type="bibr" coords="1,272.72,573.43,7.20,8.74" target="#b2">3,</ref><ref type="bibr" coords="1,279.92,573.43,7.20,8.74" target="#b4">5]</ref>.</p><p>The plant identification challenge of the Conference and Labs of the Evaluation Forum (CLEF) <ref type="bibr" coords="1,236.15,597.34,11.62,8.74" target="#b5">[6,</ref><ref type="bibr" coords="1,247.77,597.34,7.75,8.74" target="#b6">7,</ref><ref type="bibr" coords="1,255.52,597.34,7.75,8.74" target="#b7">8,</ref><ref type="bibr" coords="1,263.27,597.34,7.75,8.74" target="#b8">9,</ref><ref type="bibr" coords="1,271.02,597.34,11.62,8.74" target="#b9">10]</ref> is one of the most well-known annual events that benchmark content-based image retrieval from structured plant databases including photographs of leaves, branches, stems, flowers, and fruits. The latest annotated plant dataset is provided by the LifeCLEF 2015 campaign with over 100,000 pictures of herbs, trees, and ferns belonging to 1,000 species collected from Western Europe.</p><p>Open-set recognition is a challenging task in computer vision which deals with identification or verification problems where samples from unknown classes could be presented to the system as well <ref type="bibr" coords="2,319.97,143.90,15.50,8.74" target="#b10">[11,</ref><ref type="bibr" coords="2,335.47,143.90,11.62,8.74" target="#b11">12]</ref>. To create a similar scenario, the PlantCLEF 2016 campaign has provided a test image query which is very different from the previous years' CLEF datasets in nature <ref type="bibr" coords="2,392.45,167.81,15.50,8.74" target="#b12">[13,</ref><ref type="bibr" coords="2,407.95,167.81,11.62,8.74" target="#b13">14]</ref>. This dataset is composed of unknown plant species and non-plant objects to create an openworld plant dataset. Therefore, the task challenges are not limited to automatically recognizing the known plant species, but also rejecting unknown plants and objects as well.</p><p>Our team participated in the PlantCLEF 2016 challenge under the name of SabanciUGebzeTU achieved the second rank with a very small difference from the first-ranked team. In our proposed systems, we fine-tune the pre-trained deep convolutional neural networks of GoogLeNet <ref type="bibr" coords="2,338.20,263.68,15.50,8.74" target="#b14">[15]</ref> and VGGNet <ref type="bibr" coords="2,421.79,263.68,15.50,8.74" target="#b15">[16]</ref> for plant identification using the LifeCLEF 2015 plant task datasets. We augment this data using different image transforms such as rotation, translation, reflection, and scaling to overcome overfitting while training and to improve the performance during testing the system on highly noisy test data. The overall system is then composed of these two networks using score-level averaging. To enable rejections, we train another deep learning system to separate plants from nonplants. Specifically, we fine-tuned GoogLeNet using the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC) 2012 dataset as negative examples-after removing the potted plant category.</p><p>The rest of this paper is organized as follows. Section 2 describes the proposed methods based on fine-tuning of the GoogLeNet and VGGNet models for plant identification and open-set rejection, data augmentation, and classifier fusion. Section 3 is dedicated to the description of the utilized dataset and presentation of designed experiments and their results. The paper concludes in Section 4 with the summary and discussion of the utilized methods and obtained results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed Method</head><p>Our proposed method for automated plant identification is based on fine-tuning and fusing of two successful deep learning models, i.e. GoogLeNet <ref type="bibr" coords="2,443.87,513.21,15.50,8.74" target="#b14">[15]</ref> and VGGNet <ref type="bibr" coords="2,165.78,525.16,20.68,8.74" target="#b15">[16]</ref>. These models are, respectively, the first-ranked and second-ranked architectures of the ILSVRC 2014-both trained on the ILSVRC 2012 dataset with 1.2 million labeled images of 1,000 object classes.</p><p>GoogLeNet <ref type="bibr" coords="2,202.61,561.25,15.50,8.74" target="#b14">[15]</ref> contains 57 convolutional layers, 14 pooling layers, and one fully-connected layer while VGGNet <ref type="bibr" coords="2,299.63,573.20,15.50,8.74" target="#b15">[16]</ref> involves 16 convolutional layers, five pooling layers, and three fully-connected layers. Both networks take color image patches of size 224 × 224 pixels as the input and connect a linear layer with Softmax activation in the output.</p><p>We used the plant task datasets of LifeCLEF 2015 for fine-tuning the pretrained models. The training parameters consist of a weight decay of 0.0002, a base learning rate of 0.001, and a batch size of 20. Data augmentation is applied to decrease the chance of overfitting during training and to improve performance while testing. For this purpose, we randomly extract K square patches from each original image around its center. The original image is also rotated by ±R degrees and the largest square image is cropped from the center of each rotated image. All the extracted patches as well as the original image (K + 3 images) are then scaled to 256 × 256 pixels and the mean image is subtracted from them. Finally, five patches of size 224 × 224 pixels are extracted from four corners and the center of each image. These patches are then also reflected horizontally, resulting in 10 × (K + 3) patches per input image in total.</p><p>Score-level averaging is applied to combine the prediction scores assigned to each class for all the augmented patches within a single network. Finally, the obtained scores from every deep network classifier are combined using the same averaging rule. The observation id that indicates different images of the same unique plant is not used in our systems; hence the recognition results are based only on single images.</p><p>For the unknown-class rejection task within the unseen data, we separately fine-tuned the GoogLeNet model for a binary classification problem, i.e. plants vs. non-plants. The training samples for this purpose consist of plant images from LifeCLEF 2015 and non-plant images from ILSVRC 2012. Using the obtained results from the binary classifier, we reject those images that are classified as non-plant and receive a low confidence score in the main plant identification system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>To train and validate our systems, we used the plant dataset of LifeCLEF 2015 <ref type="bibr" coords="3,134.77,429.52,15.50,8.74" target="#b16">[17]</ref> consisting of 113,204 images of different plant organs belonging to 1,000 species of trees, herbs, and ferns. We randomly divided the training portion of the dataset into two subsets for training and validation, with 70,904 and 20,854 images, respectively. The test portion of the dataset consists of a separate set of 21,446 images; however the ground-truth for the test dataset was only recently released and thus used in a limited fashion in our system. In the remainder of this paper, we will call these three subsets train, validation, and test subsets, respectively.</p><p>The PlantCLEF 2016 test dataset includes 8,000 samples submitted by the users of the mobile application Pl@ntNet <ref type="bibr" coords="3,318.36,537.34,14.61,8.74" target="#b12">[13]</ref>. This dataset is highly noisy and essentially different from the plant task datasets of LifeCLEF 2015 since it contains pictures of unknown plants and objects. We use the data augmentation approach explained in Section 2 and set K = 5 and R = 10 to train and test 80 patches per input image. In some experiments, we set K = 9 and R = {10, 20} to train and test 140 patches per image.</p><p>To fine-tune GoogLeNet for the open-set unknown-class rejection task, K is set to zero and no rotation is applied so as to augment data with only 10 patches per image. The training data for this problem is obtained by combining the earlier training subset of LifeCLEF 2015 for the plant class samples and an equal number of non-plant object samples from ILSVRC 2012, giving about 140,000 samples in total. In addition, the validation set is obtained from combining the earlier validation subset of LifeCLEF 2015 and an equal number of non-plant object samples of ILSVRC 2012, resulting in about 40,000 samples in total. Images used in the training and validation subsets contained distinct samples.</p><p>We implemented the GoogLeNet and VGGNet deep models using the Caffe deep learning framework <ref type="bibr" coords="4,242.10,180.71,15.50,8.74" target="#b17">[18]</ref> with pre-trained weights obtained from Caffe Model Zoo provided by the Berkeley Vision and Learning Center (BVLC). In the rest of this section, we explain our conducted experiments, their validation results, and the prepared runs.</p><p>It is worth mentioning that we have not used additional plant images for training any of the systems. Furthermore, all systems are fully automatic except for Run 3 where we manually remove 90 images in order to measure our performance in the case of a closed set problem (no query from unknown classes).</p><p>Run 1. In this run, we first fine-tuned the pre-trained models of GoogLeNet and VGGNet using the train subset of LifeCLEF 2015 that we augmented with 140 and 80 patches per image till 600,000 and 500,000 iterations, respectively. Next, we fine-tuned the pre-trained GoogLeNet with almost all of the data (train+test+validation/2) augmented with 80 patches per image until 200,000 iterations. We fused all the obtained scores for augmented image patches from different networks' classifiers. With this system, we achieved an accuracy of 79.80% on the given validation set (validation/2).</p><p>To reject test samples of unknown classes, we fine-tuned the pre-trained GoogLeNet with the obtained plant/non-plant dataset until 100,000 iterations and achieved an accuracy of almost 100% on the given validation set. Next, we tested the combined deep model on the non-plant validation set; from the obtained plant identification prediction scores it was inferred that these scores have a uniform-like distribution. We set the rejection threshold to T = 0.4 based on the top-1 score for maximal rejection of non-plant samples and minimum rejection of plant data. In the test stage, we utilized our combined system for score prediction as well as rejection of samples whose top-1 score was less than 0.4. We rejected 480 images from the PlantCLEF 2016 test dataset in this manner and obtained our first run. Run 2. All the implemented steps for achieving this run were the same as those performed for Run 1. The only difference was that no image rejection was performed in obtaining this run. Run 3. All the steps utilized in preparing this run were common with Run 1 except for the rejection method. In this experiment, we manually reviewed the test images and set aside 90 non-plant images. This was done to measure the system performance with only known classes; however, as this score is later provided by campaign organizers, this system is not very relevant.</p><p>Test Results. We submitted the classification results of the aforementioned systems on the official test set of the PlantCLEF 2016. The utilized metric for evaluation was the mean average precision. In other words, all prediction scores were extracted for each class and sorted in the descending order to compute the average precision for that class. Finally, the mean was computed across all classes. The released results by the challenge organizers <ref type="bibr" coords="5,403.47,179.77,15.49,8.74" target="#b13">[14]</ref> are shown in Figure <ref type="figure" coords="5,166.82,191.72,3.87,8.74" target="#fig_0">1</ref>. As the officials results indicate, we obtained the second place in the open-set plant identification competition of PlantCLEF 2016. Moreover, the unofficial results indicate that we achieved the top score in the image-based plant identification.</p><p>From the official results, we can conclude that the automatic rejection method (Run 1) was the top performer among our three systems followed by the manual rejection scheme (Run 3) and the method with no rejection (Run 2).</p><p>Comparing automatic rejection (Run 1) and no rejection (Run 2) systems, we see that the error in automatic rejection is very small when considering only known classes (0.806 vs 0.807), while the gains in the open-set and invasive species problems are slightly more significant (0.738 vs 0.736 and 0.704 vs 0.683, respectively).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this paper, we reviewed the details of our proposed systems used in the openset plant identification problem of PlantCLEF 2016 campaign. We fused two powerful deep learning methods of VGGNet and GoogLeNet after fine-tuning them with the augmented plant task datasets of LifeCLEF 2015. Meanwhile, we used plant and non-plant images to fine-tune GoogLeNet for a binary classification to perform unknown-class rejection. Our systems were officially evaluated on the test dataset of PlantCLEF 2016 and our best proposed model achieved a mean average precision of 0.738.</p><p>Our main focus in PlantCLEF 2016 was to see how we could improve the competitive results obtained in LifeCLEF 2015 <ref type="bibr" coords="5,350.55,488.07,14.61,8.74" target="#b9">[10]</ref>. To this end, we studied the best ways to fine-tune deep learning models; in particular, we experimented with the iteration size, batch size, and data augmentation. We observed that the accuracy steadily improved with the increased number of iterations and with data augmentation. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,196.74,648.84,221.87,7.89;7,134.77,335.99,345.82,275.78"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The official released results of PlantCLEF 2016</figDesc><graphic coords="7,134.77,335.99,345.82,275.78" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This work is supported by the <rs type="funder">Scientific and Technological Research Council of Turkey (TUBITAK)</rs> under the grant number <rs type="grantNumber">113E499</rs>. <rs type="person">Dr. Aptoula</rs> was affiliated with <rs type="institution">Okan University</rs> when this work was conducted.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_EPekHvX">
					<idno type="grant-number">113E499</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,142.96,646.84,337.64,7.86;5,151.52,657.79,268.12,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,336.13,646.84,144.46,7.86;5,151.52,657.79,119.97,7.86">IBM research Australia at LifeCLEF 2014: Plant identification task</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Abedini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Garnavi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,293.51,657.79,93.33,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,120.67,337.63,7.86;6,151.52,131.63,318.68,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,188.52,120.67,292.07,7.86;6,151.52,131.63,170.18,7.86">Plant identification with deep convolutional neural network: SNUMedinfo at LifeCLEF plant identification task 2015</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,344.07,131.63,93.33,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,142.59,337.64,7.86;6,151.52,153.55,329.07,7.86;6,151.52,164.51,204.98,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,359.90,142.59,120.69,7.86;6,151.52,153.55,329.07,7.86;6,151.52,164.51,36.61,7.86">A comparative study of finegrained classification methods in the context of the LifeCLEF plant identification challenge</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Champ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lorieul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,230.36,164.51,93.33,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,175.46,337.64,7.86;6,151.52,186.42,329.07,7.86;6,151.52,197.38,57.65,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,425.05,175.46,55.55,7.86;6,151.52,186.42,236.81,7.86">Sabanci-Okan system in LifeCLEF 2015 plant identification competition</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Ghazi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Yanikoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Atoula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Muslu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">C</forename><surname>Ozdemir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,414.27,186.42,66.32,7.86;6,151.52,197.38,24.84,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,208.34,337.63,7.86;6,151.52,219.30,271.66,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,336.97,208.34,143.62,7.86;6,151.52,219.30,123.79,7.86">Content specific feature learning for fine-grained plant classification</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Mccool</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Corke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,297.03,219.30,93.34,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,230.26,337.64,7.86;6,151.52,241.22,329.07,7.86;6,151.52,252.18,241.50,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,305.01,241.22,175.58,7.86;6,151.52,252.18,15.40,7.86">The CLEF 2011 plant images classification task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Birnbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mouysset</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,188.93,252.18,166.13,7.86">CLEF (Notebook Papers/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,263.14,337.63,7.86;6,151.52,274.09,329.07,7.86;6,151.52,285.05,163.38,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,209.20,274.09,189.35,7.86">The ImageCLEF 2012 plant identification task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,422.20,274.09,58.39,7.86;6,151.52,285.05,125.42,7.86">CLEF (Online Working Notes/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,296.01,337.63,7.86;6,151.52,306.97,329.07,7.86;6,151.52,317.93,25.60,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,174.00,306.97,187.20,7.86">The ImageCLEF 2013 plant identification task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bakic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,383.16,306.97,93.29,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,328.89,337.63,7.86;6,151.52,339.85,323.53,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,167.64,339.85,139.05,7.86">LifeCLEF plant identification task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,348.92,339.85,93.33,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.62,350.81,337.97,7.86;6,151.52,361.77,98.37,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,279.33,350.81,156.08,7.86">LifeCLEF plant identification task 2015</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,455.89,350.81,24.70,7.86;6,151.52,361.77,65.56,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.62,372.73,337.97,7.86;6,151.52,383.66,329.07,7.89;6,151.52,394.64,41.47,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,306.90,372.73,169.76,7.86">Probability models for open set recognition</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Scheirer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">E</forename><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,151.52,383.68,268.73,7.86">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2317" to="2324" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.62,405.60,337.97,7.86;6,151.52,416.56,329.07,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,251.58,405.60,129.17,7.86">Towards open world recognition</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bendale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,405.04,405.60,75.55,7.86;6,151.52,416.56,252.43,7.86">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1893" to="1902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.62,427.52,337.97,7.86;6,151.52,438.48,329.07,7.86;6,151.52,449.44,286.17,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="6,352.43,438.48,128.16,7.86;6,151.52,449.44,125.04,7.86">LifeCLEF 2016: multimedia life species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Champ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Planqué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Palazzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,298.61,449.44,106.21,7.86">Proceedings of CLEF 2016</title>
		<meeting>CLEF 2016</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.62,460.40,337.98,7.86;6,151.52,471.36,168.88,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="6,284.87,460.40,195.72,7.86;6,151.52,471.36,20.48,7.86">Plant identification in an open-world (LifeCLEF 2016)</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,194.26,471.36,93.33,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.62,482.31,337.97,7.86;6,151.52,493.27,329.07,7.86;6,151.52,504.23,215.38,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="6,264.84,493.27,125.19,7.86">Going deeper with convolutions</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,411.39,493.27,69.21,7.86;6,151.52,504.23,182.52,7.86">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.62,515.19,337.98,7.86;6,151.52,526.15,329.07,7.86" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="6,272.24,515.19,208.35,7.86;6,151.52,526.15,58.86,7.86">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>CoRR)</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Computing Research Repository</note>
</biblStruct>

<biblStruct coords="6,142.62,537.11,337.97,7.86;6,151.52,548.07,329.07,7.86;6,151.52,559.03,329.07,7.86;6,151.52,569.99,176.13,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="6,351.20,548.07,129.39,7.86;6,151.52,559.03,125.12,7.86">LifeCLEF 2015: multimedia life species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Planqué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Palazzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,298.86,559.03,181.73,7.86;6,151.52,569.99,107.24,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="462" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.62,580.94,337.97,7.86;6,151.52,591.90,329.07,7.86;6,151.52,602.86,329.07,7.86;6,151.52,613.82,32.25,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="6,238.21,591.90,237.77,7.86">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,165.31,602.86,282.46,7.86">Proceedings of the 22nd ACM International Conference on Multimedia</title>
		<meeting>the 22nd ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="675" to="678" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
