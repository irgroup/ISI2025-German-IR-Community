<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.42,115.96,328.52,12.62;1,241.98,133.89,131.39,12.62">Floristic participation at LifeCLEF 2016 Plant Identification Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,196.04,171.56,61.02,8.74"><forename type="first">Julien</forename><surname>Champ</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Inria ZENITH team</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,273.95,171.56,56.56,8.74"><forename type="first">Hervé</forename><surname>Goëau</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">IRD</orgName>
								<orgName type="institution">UMR AMAP</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,360.44,171.56,48.07,8.74"><forename type="first">Alexis</forename><surname>Joly</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Inria ZENITH team</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.42,115.96,328.52,12.62;1,241.98,133.89,131.39,12.62">Floristic participation at LifeCLEF 2016 Plant Identification Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B29B712B0E2CD815258F3EEC1E52EBFA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>LifeCLEF</term>
					<term>plant</term>
					<term>leaves</term>
					<term>leaf</term>
					<term>flower</term>
					<term>fruit</term>
					<term>bark</term>
					<term>stem</term>
					<term>branch</term>
					<term>species</term>
					<term>retrieval</term>
					<term>images</term>
					<term>collection</term>
					<term>species identification</term>
					<term>citizen-science</term>
					<term>fine-grained classification</term>
					<term>evaluation</term>
					<term>benchmark</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of the Floristic consortium to the LifeCLEF 2016 plant identification challenge <ref type="bibr" coords="1,397.63,264.98,15.29,7.86" target="#b17">[18]</ref>. The aim of the task was to produce a list of relevant species for a large set of plant images related to 1000 species of trees, herbs and ferns living in Western Europe, knowing that some of these images belonged to unseen categories in the training set like plant species from other areas, horticultural plants or even off topic images (people, keyboards, animals, etc). To address this challenge, we first experimented as a baseline, without any rejection procedure, a Convolutional Neural Network (CNN) approach based on a slightly modified GoogLeNet model. In a second run, we applied a simple rejection criteria based on probability threshold estimation on the output of the CNN, one for each species, for removing automatically species propositions judged irrelevant. In the third run, rather than definitely eliminating some species predictions with the risk to remove false negative propositions, we applied various attenuation factors in order to revise the probability distributions given by the CNN as confident score expressing how much a query was related or not to the known species. More precisely, for this last run we used the geographical information and several cohesion measures in terms of observation, "organ" tags and taxonomy (genus and family levels) based on a knn similarity search results within the training set.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Content-based image retrieval and computer vision approaches are considered as one of the most promising solutions to help bridging the taxonomic gap, as discussed in <ref type="bibr" coords="1,189.80,596.34,11.84,8.74" target="#b4">[5,</ref><ref type="bibr" coords="1,201.64,596.34,7.90,8.74" target="#b1">2,</ref><ref type="bibr" coords="1,209.54,596.34,11.84,8.74" target="#b25">26,</ref><ref type="bibr" coords="1,221.38,596.34,11.84,8.74" target="#b23">24,</ref><ref type="bibr" coords="1,233.23,596.34,11.84,8.74" target="#b16">17]</ref>. We therefore see an increasing interest in this transdisciplinary challenge in the multimedia community (e.g. in <ref type="bibr" coords="1,403.66,608.30,16.20,8.74" target="#b22">[23,</ref><ref type="bibr" coords="1,419.85,608.30,12.15,8.74" target="#b9">10,</ref><ref type="bibr" coords="1,432.00,608.30,8.10,8.74" target="#b2">3,</ref><ref type="bibr" coords="1,440.10,608.30,12.15,8.74" target="#b21">22,</ref><ref type="bibr" coords="1,452.25,608.30,12.15,8.74" target="#b18">19,</ref><ref type="bibr" coords="1,464.39,608.30,12.15,8.74" target="#b11">12]</ref>. Beyond the raw identification performances achievable by state-of-the-art computer vision algorithms, recent visual search paradigms actually offer much more efficient and interactive ways of browsing large flora than standard field guides or online web catalogs ( <ref type="bibr" coords="1,226.02,656.12,10.52,8.74" target="#b3">[4]</ref>). Smartphone applications relying on such image-based identification services are particularly promising for setting-up massive ecological monitoring systems, involving thousands of contributors at a very low cost. A first step in this way has been achieved by the US consortium behind LeafSnap <ref type="foot" coords="2,150.82,153.28,3.97,6.12" target="#foot_0">4</ref> , an i-phone application allowing the identification of 184 common American plant species based on pictures of cut leaves on an uniform background (see <ref type="bibr" coords="2,155.36,178.77,15.50,8.74" target="#b20">[21]</ref> for more details). Then, the French consortium supporting Pl@ntNet ( <ref type="bibr" coords="2,138.64,190.72,15.50,8.74" target="#b16">[17]</ref>) went one step beyond by building an interactive image-based plant identification application that is continuously enriched by the members of a social network specialized in botany. Inspired by the principles of citizen sciences and participatory sensing, this project quickly met a large public with more than 1M downloads of the mobile applications ( <ref type="bibr" coords="2,318.35,238.55,10.79,8.74" target="#b7">[8,</ref><ref type="bibr" coords="2,329.14,238.55,7.20,8.74" target="#b6">7]</ref>). A related initiative is the plant identification evaluation task organized since 2011 in the context of the international evaluation forum CLEF <ref type="foot" coords="2,267.94,260.88,3.97,6.12" target="#foot_1">5</ref> and that is based on the data collected within Pl@ntNet.</p><p>Since few years, deep convolutional neural networks repeatedly demonstrated record breaking results in generic object recognition problems such as ImageNet <ref type="bibr" coords="2,134.77,324.72,15.50,8.74" target="#b19">[20]</ref> and do attract more and more interest in the computer and multimedia vision communities. The promising effectiveness of this kind of approaches on more specific and fine grained classification problems like plant identification was confirmed last year <ref type="bibr" coords="2,203.21,360.59,10.52,8.74" target="#b8">[9]</ref> with impressive results regarding the fineness of the classes (at species level) and the unbalanced data in terms of available images per species. Rather than extracting the features according to hand-tuned or psycho-vision oriented filters, such methods directly work on the image signal. The weights learned by the first convolutional layers allows to automatically build relevant image filters whereas the intermediate layers are in charge of pooling these raw responses into high-level visual patterns. The last fully connected layers work more traditionally as any discriminative classifier on the image representation resulting from the previous layers.</p><p>A known drawback of Deep Convolutional Neural Networks is that they require a lot of training data mainly because of the huge number of parameters to be learned. This is particularly true here where the training set is highly unbalanced and includes many classes with few instances. The possibility to efficiently fine tune an already learned model, to adapt the architecture and resume training from the already learned model weight, is one a the main strength of CNN. This is one key explaining such results obtained last year on the plant identification task.</p><p>However, this year the task introduce an additional challenge by considering an open set classification problem, i.e. where some of the queries of the test set do not belong to the known species <ref type="bibr" coords="2,271.98,592.71,11.73,8.74" target="#b5">[6]</ref>. More precisely, according to the description of the task, these unseen images came from the plantnet mobile application and reflect the diversity of the visual content which the users produce despite of the plantnet application is dedicated to wild plants from Western Europe. More precisely these pictures can be:</p><p>off topic pictures like peoples, keyboards, landscapes, etc, horticultural plants (house &amp; garden plants, vegetables &amp; fruits), and wild plants but observed from all around the world and outside from the list of known species in the training set.</p><p>Considering the off topic pictures, one can guess that it must be rather easy to build a system predicting low or scattered probabilities on the 1000 known species, since visual content should be very different from the training dataset. Indeed, strong lines and corners from a manufactured object will produce certainly visual features very different from textured and mostly green visual contents learned from the training dataset. The difficulty of the task is most probably concentrated on the queries related to horticultural and wild plants with images sharing with the training set more visual similarities. That said, CNN, like a vast majority of machine learning tools and recognition systems are designed for a static closed world, where the primary assumption is that all categories are known. We can admit that is a classification problem not so much explored in computer vision while it is a frequent usage case in the real world, even if some previous works are yet done in this direction with the CNNs <ref type="bibr" coords="3,164.15,363.24,9.96,8.74" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Floristic Run 1</head><p>To address this challenge, we used a CNN model without any rejection procedure in order to obtain a first run considered here as a baseline, with the expectation that a query related to a known species will obtain a probability distribution concentrated on one or few relevant species (for instance species related to a same genus). The opposite expectation is that a query related to a unseen class will obtain a probability distribution spread over many classes.</p><p>We have used Caffe <ref type="bibr" coords="3,242.68,512.54,14.61,8.74" target="#b13">[14]</ref>, a Deep Learning Framework, allowing us to use CNN architectures and models from the literature. We have chosen and slightly modified the "GoogLeNet GPU implementation" model in the Caffe model Zoo, based on the Google winning architecture in the ImageNet 2014 Challenge <ref type="bibr" coords="3,462.33,548.41,14.61,8.74" target="#b24">[25]</ref>. The GoogLeNet architecture consists of a 22 layers deep network with a softmax loss as the top classifier. It is composed of three "inception modules" stacked on top of each other. Each intermediate inception module is connected to an auxiliary classifier during training, so as to encourage discrimination in the lower stages of the classifier, increase the gradient signal that gets propagated back, and provide additional regularization. These auxiliary classifiers are only used during the training part, and then discarded.</p><p>We modified this model network by adding a batch normalisation at each level between the pooling and the Local Response Normalization layers in order to accelerate the learning phase <ref type="bibr" coords="4,278.42,118.99,14.61,8.74" target="#b12">[13]</ref>. As it is mentioned in this paper, we also removed the dropout layers. Combined with Parametric Rectified Linear Unit (PReLU) instead of ReLU layers, this model finally prevent the risk of overfitting <ref type="bibr" coords="4,134.77,154.86,14.61,8.74" target="#b10">[11]</ref>. Since we didn't find a such GoogleNet implementation, we learn this model on the ImageNet 2014 dataset (one week, 1,100,000 iterations with a batch size of 32, reaching a final train loss cost around 0.12).</p><p>Finally, we fine-tuned this model on the LifeCLEF Plant Task 2016 training dataset. For each image in the training and test sets, we therefore cropped the largest square in the center, and re-sized it to 256x256 pixels. As it was implemented within Caffe library, it makes also use of a simple data augmentation technique, consisting in cropping randomly a 224x224 pixels image, and mirroring it horizontally.</p><p>As a reminder, here are the most important parameters for Caffe to obtain our first submitted run "Floristic Run 1". The base learning rate parameter was set to 0.0075 which is rather high compared to usual learning rates applied to models without batch normalisation. The learning rate is divided by 10 every 42451 iterations with a batch size of 16 involving that each training images will pass 6 times during a step (113204 images x 6 / 16 gives the step size). We used only 2 steps and finally stopped the training after 90k iterations. For information, this fine-tuned model stopped with a top-1 loss accuracy on the training set itself of 0.9378.</p><p>To obtain the first run "Floristic Run 1", we directly used this fine-tuned model on the 8000 test images and limited the responses to the first 50 predicted species for each (when necessary).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Floristic Run 2: run 1 + rejection procedure</head><p>In a second run we added to the first approach a simple rejection procedure based on the estimation of probability thresholds, one for each species. The main idea was here to detect and remove some species predictions judged irrelevant. If the thresholds are correctly estimated, a query related to an unseen category should not be associated to any predictions and finally should not occur in the run file.</p><p>Given a species, for estimating its probability threshold, we computed the probability for each of its training image, and then selected the lowest value as a threshold. This threshold represents in a way the limit of the visual knowledge of the species according to the model and its available training images.</p><p>Finally, we produced the run file "Floristic Run 2" by applying the estimated thresholds on the predictions given by the run 1. This approach divided by two on average the number of species predictions of each query, with numerous queries associated to only one species prediction (1470 queries among 8000, while the run 1 contained only 83 queries with a response size of 1). But finally, none of the queries where entirely rejected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Floristic Run 3: run 1 + mitigating factors</head><p>The risk of the approach using rejection procedure like in the run 2 is to definitely remove false negative species propositions, notably if the thresholds are too high while the probability of a correct species on a query is too loo. Therefore, in the third run, we preferred to keep all the species predictions produced in run 1 and apply on it some various attenuation factors. Indeed, the metric of the task is the classification MAP, i.e. the Mean of the Average Precision of each class taken individually, so, given a class, all the queries are sorted by their probability associated to this class, and the Average Precision depends directly on the ranks of the queries which really belong to this class. The main idea here was to reorder the list of the queries by downscaling their initial probability value by several factors between [α, 1.0] (α fixed arbitrarily to 0.9) with the expectation that irrelevant queries will be finally pushed on the tail of the list while relevant queries will maintain their rank.</p><p>For each query, six distinct factors were applied, mixing some information available in the metadata provided in the dataset with some consistency measures computed on the response given by a visual similarity search approach. The similarity search is produced by a fast nearest neighbors indexing and search method applied to the 1024 dimensional high level feature vector extracted with the CNN model from the second to last layer "pool5/7x7 s1". Each image feature is compressed with RMMH <ref type="bibr" coords="5,266.96,366.96,24.28,8.74" target="#b14">[15]</ref> (Random Maximum Margin Hashing) and its approximate k-nearest neighbors are searched by probing multiple neighboring buckets in the consulted hash table (according to the a posteriori multi-probe algorithm described in <ref type="bibr" coords="5,235.10,402.83,14.76,8.74" target="#b15">[16]</ref>). In that way, the knn search gives a complementary views of the training dataset from which we re-examine the species predictions given by the softmax output in the CNN model. More precisely, we can compare the metadata of the knns returned by the system with the metadata of a query for computing several factors (five here) reporting various contextual information:</p><p>a factor S classes based on the classes returned by the knns, a factor S organs based on the "organ" tags, two "taxonomic" factors S genus and S f amily at the genus and family levels, and a geolocalisation factor S geoloc .</p><p>Factors are estimated individually for each query i, with values belonging to [0.9, 1.0] and are directly applied to the probability distribution P i in order to obtain some confident scores C i :</p><formula xml:id="formula_0" coords="5,191.20,585.93,232.45,9.65">C i = P i * S classes * S organs * S genus * S f amily * S geoloc</formula><p>For computing these factors, we choose to select arbitrarily the most visually similar images belonging to distinct observations. We didn't take directly the 5 most similar images because it can potentially be only near duplicate images belonging to a same observation and thus report poor contextual information.</p><p>Class distribution factor S classes : this factor represents the convergence of the knns to a same class or not: if the knns belong to the same class, the factor will be neutral (S c lasses = 1), while more the returned classes are distinct, more the factor will tend to α = 0.9. Based on the occurrences of the classes appearing in the knns, we can compute a probability distribution P and then compute the entropy H c defined by:</p><formula xml:id="formula_1" coords="6,259.66,189.58,95.53,30.32">H c = - k i=1 P i log 2 P i</formula><p>with k = 5 observations. The entropy H c will be equal to 0 when all the knns belong to a same same class, while it will be equal to its maximal value H cmax = log 2 (k) = log 2 (5) when each knn belong to a different class. Then an affine function gives directly the factor:</p><formula xml:id="formula_2" coords="6,249.16,278.35,115.83,23.22">S classes = 1 -0.1 * H c log 2 (5)</formula><p>Organ factor S organs : following the same previous approach, we count here the number of distinct tags organ reported by the knns among the available tags (flower, fruit, leaf, scan, stem, entire, branch), extract a probability distribution on these organs, compute the entropy H o and finally compute the factor:</p><formula xml:id="formula_3" coords="6,249.42,363.03,115.32,23.23">S organs = 1 -0.1 * H o log 2 (5)</formula><p>Taxonomic factors S genus and S f amily : following the same previous formulas, from the occurrences of the distinct genera (families) reported by the nns, we can extract a probability distributions on the genera (family), compute the entropy H g (and H f ) and compute finally the factors:</p><formula xml:id="formula_4" coords="6,249.05,448.62,116.06,54.64">S genus = 1 -0.1 * H g log 2 (5) S f amily = 1 -0.1 * H f log 2 (5)</formula><p>Geolocalisation factor S geoloc : here we didn't use a visual similarity knn search, but computed directly a factor based on the great circle distance dist between the GPS coordinates given by the metadata of a query and the coordinates representing more or less the center of France (latitude = 46.3, longitude = 2.3): S geoloc = 1-dist distancemax where distancemax = 20000 kms is more or less the farthest distance on earth from the center of France. By default dist = 500 kms if the metadata of a query doesn't contain some GPS coordinates, which is giving a factor of S geoloc = 0.975</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Official Results</head><p>Table <ref type="table" coords="6,162.62,644.16,4.98,8.74">1</ref> reports the scores of the 29 submitted runs, and figure <ref type="figure" coords="6,417.17,644.16,4.98,8.74" target="#fig_1">2</ref> gives a complementary graphical overview of all results obtained by the participants.  Floristic team submitted 3 runs: the first run Floristic Run 1 was based on the well-known GoogLeNet CNN architecture, but slightly modified with the use of Parametric Rectified Linear Units and the use of batch normalisation layers in order to accelerate and prevent from overfitting the learned model. This first approach obtained an intermediate MAP of 0.619 while the best system obtained a MAP of 0.742. Unfortunately, by adding the rejection criteria, we degraded slightly the MAP (down to 6.111 obtained by "Floristic Run 2"). This rejection criteria was certainly too strong, with estimated probability thresholds too high, and have probably removed too much correct species predictions. On another side, contextual information exploited in "Floristic Run 3" for revising the species predictions slightly improved the MAP (up to 0.627), but not enough for reaching the performances of the best systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,207.44,365.68,200.47,7.89;7,134.77,128.09,345.82,211.86"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. LifeCLEF 2016 Plant Task Official results</figDesc><graphic coords="7,134.77,128.09,345.82,211.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,207.44,642.77,200.47,7.89;7,134.77,406.06,345.84,210.98"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. LifeCLEF 2016 Plant Task Official results</figDesc><graphic coords="7,134.77,406.06,345.84,210.98" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="2,144.73,645.84,85.04,7.86"><p>http://leafsnap.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="2,144.73,656.80,120.33,7.86"><p>http://www.clef-initiative.eu/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,333.68,337.63,7.86;8,151.52,344.64,97.80,7.86" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bendale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Boult</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06233</idno>
		<title level="m" coord="8,262.87,333.68,144.43,7.86">Towards open set deep networks</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,142.96,354.97,337.64,7.86;8,151.52,365.93,329.07,7.86;8,151.52,376.89,329.07,7.86;8,151.52,387.85,43.91,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,333.77,354.97,146.82,7.86;8,151.52,365.93,141.77,7.86">Sensor network for the monitoring of ecosystem: Bird species recognition</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Roe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,315.16,365.93,165.44,7.86;8,151.52,376.89,46.01,7.86;8,231.50,376.89,191.14,7.86">Intelligent Sensors, Sensor Networks and Information</title>
		<imprint>
			<date type="published" when="2007-12">2007. Dec 2007</date>
			<biblScope unit="page" from="293" to="298" />
		</imprint>
	</monogr>
	<note>ISSNIP 2007. 3rd International Conference on</note>
</biblStruct>

<biblStruct coords="8,142.96,398.18,337.63,7.86;8,151.52,409.14,329.07,7.86;8,151.52,420.10,329.07,8.12;8,151.52,431.70,156.34,7.47" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,360.80,398.18,119.79,7.86;8,151.52,409.14,185.13,7.86">A Parametric Active Polygon for Leaf Segmentation and Shape Estimation</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cerutti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tougne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vacavant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Coquin</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-00622269" />
	</analytic>
	<monogr>
		<title level="m" coord="8,360.15,409.14,120.44,7.86;8,151.52,420.10,85.40,7.86">7th International Symposium on Visual Computing</title>
		<meeting><address><addrLine>Las Vegas, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09">Sep 2011</date>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,441.39,337.64,7.86;8,151.52,452.35,329.07,7.86;8,151.52,463.30,122.29,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,416.05,452.35,64.54,7.86;8,151.52,463.30,43.71,7.86">Next-generation field guides</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Ellison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">J</forename><surname>Farnsworth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Kress</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Neill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pickering</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">D</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Courtney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">K</forename><surname>Vandyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,202.26,463.30,42.88,7.86">BioScience</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,473.64,337.63,7.86;8,151.52,484.59,329.07,7.86;8,151.52,495.55,60.92,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,265.15,473.64,170.59,7.86">Automated species identification: why not?</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">J</forename><surname>Gaston</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>O'neill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,437.92,473.64,42.67,7.86;8,151.52,484.59,284.26,7.86">Philosophical Transactions of the Royal Society of London B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">359</biblScope>
			<biblScope unit="issue">1444</biblScope>
			<biblScope unit="page" from="655" to="667" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,505.88,337.63,7.86;8,151.52,516.84,147.90,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,277.55,505.88,198.94,7.86">Plant identification in an open-world (lifeclef 2016)</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,165.60,516.84,83.65,7.86">CLEF working notes</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">2016</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,527.17,337.64,7.86;8,151.52,538.13,329.07,7.86;8,151.52,549.09,329.07,7.86;8,151.52,560.05,80.63,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,315.77,538.13,164.82,7.86;8,151.52,549.09,48.56,7.86">Pl@ ntnet mobile 2014: Android port and new features</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Affouard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bakic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Barbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dufour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Vignau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,219.58,549.09,257.13,7.86">Proceedings of International Conference on Multimedia Retrieval</title>
		<meeting>International Conference on Multimedia Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page">527</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,570.38,337.64,7.86;8,151.52,581.34,329.07,7.86;8,151.52,592.30,328.53,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,316.02,581.34,85.32,7.86">Pl@ ntnet mobile app</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bakić</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Barbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carré</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthélémy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,422.30,581.34,58.29,7.86;8,151.52,592.30,216.84,7.86">Proceedings of the 21st ACM international conference on Multimedia</title>
		<meeting>the 21st ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="423" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,602.63,337.64,7.86;8,151.52,613.59,106.05,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,284.89,602.63,149.03,7.86">Lifeclef plant identification task 2015</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,455.89,602.63,24.70,7.86;8,151.52,613.59,55.88,7.86">CLEF working notes</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page">2015</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,623.92,337.98,7.86;8,151.52,634.88,329.07,7.86;8,151.52,645.84,329.07,8.12;8,151.52,657.44,71.10,7.47" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,429.55,623.92,51.05,7.86;8,151.52,634.88,202.02,7.86">Visual-based plant species identification from crowdsourced data</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mouysset</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Joyeux</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-00642236" />
	</analytic>
	<monogr>
		<title level="m" coord="8,373.50,634.88,107.09,7.86">MM&apos;11 -ACM Multimedia</title>
		<meeting><address><addrLine>Scottsdale, United States</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011-11">2011. Nov 2011</date>
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,119.67,337.98,7.86;9,151.52,130.63,329.07,8.11;9,151.52,142.24,122.39,7.47" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="9,293.02,119.67,187.57,7.86;9,151.52,130.63,175.25,7.86">Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno>CoRR abs/1502.01852</idno>
		<ptr target="http://arxiv.org/abs/1502.01852" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,151.95,337.97,7.86;9,151.52,162.91,329.07,8.11;9,151.52,174.51,81.52,7.47" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,290.05,151.95,186.25,7.86">An interactive flower image recognition system</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">H</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11042-010-0490-6</idno>
		<ptr target="http://dx.doi.org/10.1007/s11042-010-0490-6" />
	</analytic>
	<monogr>
		<title level="j" coord="9,151.52,162.91,97.05,7.86">Multimedia Tools Appl</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="73" />
			<date type="published" when="2011-05">May 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,184.22,337.98,7.86;9,151.52,195.18,329.07,8.11;9,151.52,206.78,84.73,7.47" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="9,244.89,184.22,235.70,7.86;9,151.52,195.18,138.66,7.86">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno>CoRR abs/1502.03167</idno>
		<ptr target="http://arxiv.org/abs/1502.03167" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,216.49,337.97,7.86;9,151.52,227.45,329.07,7.86;9,151.52,238.41,154.44,7.86" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="9,237.79,227.45,238.19,7.86">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5093</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,142.62,248.77,337.98,7.86;9,151.52,259.73,329.07,7.86;9,151.52,270.69,22.02,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,244.24,248.77,143.26,7.86">Random maximum margin hashing</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Buisson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,410.71,248.77,69.89,7.86;9,151.52,259.73,134.75,7.86;9,316.82,259.73,69.92,7.86">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2011-06">2011. June 2011</date>
			<biblScope unit="page" from="873" to="880" />
		</imprint>
	</monogr>
	<note>IEEE Conference</note>
</biblStruct>

<biblStruct coords="9,142.62,281.04,337.98,7.86;9,151.52,292.00,329.07,7.86;9,151.52,302.96,329.07,8.11;9,151.52,314.56,70.61,7.47" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,240.86,281.04,200.66,7.86">A posteriori multi-probe locality sensitive hashing</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Buisson</surname></persName>
		</author>
		<idno type="DOI">10.1145/1459359.1459388</idno>
		<ptr target="http://doi.acm.org/10.1145/1459359.1459388" />
	</analytic>
	<monogr>
		<title level="m" coord="9,463.04,281.04,17.56,7.86;9,151.52,292.00,283.51,7.86;9,170.92,302.96,30.66,7.86">Proceedings of the 16th ACM International Conference on Multimedia</title>
		<meeting>the 16th ACM International Conference on Multimedia<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="209" to="218" />
		</imprint>
	</monogr>
	<note>MM &apos;08</note>
</biblStruct>

<biblStruct coords="9,142.62,324.27,337.97,7.86;9,151.52,335.23,329.07,7.86;9,151.52,346.19,209.08,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,298.24,335.23,182.35,7.86;9,151.52,346.19,43.01,7.86">Interactive plant identification based on social image data</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bakić</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Barbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carré</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mouysset</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,201.70,346.19,89.28,7.86">Ecological Informatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="22" to="34" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,356.55,337.97,7.86;9,151.52,367.51,329.07,7.86;9,151.52,378.46,282.60,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,360.12,367.51,120.47,7.86;9,151.52,378.46,125.04,7.86">Lifeclef 2016: multimedia life species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Champ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Planqué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Palazzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,297.60,378.46,107.84,7.86">Proceedings of CLEF 2016</title>
		<meeting>CLEF 2016</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,388.82,337.98,7.86;9,151.52,399.78,329.07,8.11;9,151.52,411.38,98.85,7.47" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="9,304.35,388.82,176.24,7.86;9,151.52,399.78,63.18,7.86">Plant image retrieval using color, shape and texture features</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kebapci</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Yanikoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Unal</surname></persName>
		</author>
		<idno type="DOI">10.1093/comjnl/bxq037</idno>
		<ptr target="http://dx.doi.org/10.1093/comjnl/bxq037" />
	</analytic>
	<monogr>
		<title level="j" coord="9,222.38,399.78,46.50,7.86">Comput. J</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1475" to="1490" />
			<date type="published" when="2011-09">Sep 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,421.09,337.98,7.86;9,151.52,432.05,329.07,7.86;9,151.52,443.01,86.01,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="9,328.09,421.09,152.50,7.86;9,151.52,432.05,103.94,7.86">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,275.64,432.05,200.74,7.86">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,453.37,337.98,7.86;9,151.52,464.33,329.07,7.86;9,151.52,475.28,298.98,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="9,204.15,464.33,276.44,7.86;9,151.52,475.28,34.91,7.86">Leafsnap: A computer vision system for automatic plant species identification</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Kress</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">C</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">V</forename><surname>Soares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,207.07,475.28,119.90,7.86">Computer Vision-ECCV 2012</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="502" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,485.64,337.98,7.86;9,151.52,496.60,329.07,7.86;9,151.52,507.56,329.07,7.86;9,151.52,518.52,259.38,8.12" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="9,343.84,485.64,136.76,7.86;9,151.52,496.60,182.93,7.86">Advanced shape context for plant species identification using leaf image retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mouine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Verroust-Blondet</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-00726785" />
	</analytic>
	<monogr>
		<title level="m" coord="9,455.38,496.60,25.21,7.86;9,151.52,507.56,271.50,7.86">ICMR &apos;12 -2nd ACM International Conference on Multimedia Retrieval</title>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">H S</forename><surname>Ip</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Rui</surname></persName>
		</editor>
		<meeting><address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-06">Jun 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,528.87,337.97,7.86;9,151.52,539.83,329.07,7.86;9,151.52,550.79,211.09,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="9,275.31,528.87,205.28,7.86;9,151.52,539.83,36.57,7.86">Automated flower classification over a large number of classes</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Nilsback</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,210.55,539.83,185.38,7.86;9,428.86,539.83,51.72,7.86;9,151.52,550.79,97.56,7.86">Computer Vision, Graphics Image Processing</title>
		<imprint>
			<date type="published" when="2008-12">2008. Dec 2008</date>
			<biblScope unit="page" from="722" to="729" />
		</imprint>
	</monogr>
	<note>ICVGIP &apos;08. Sixth Indian Conference</note>
</biblStruct>

<biblStruct coords="9,142.62,561.15,337.98,7.86;9,151.52,572.10,329.07,7.86;9,151.52,583.06,113.40,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="9,357.33,561.15,123.27,7.86;9,151.52,572.10,32.39,7.86">Multimedia analysis for ecological data</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Mezaris</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Van Ossenbruggen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,203.36,572.10,272.79,7.86">Proceedings of the 20th ACM international conference on Multimedia</title>
		<meeting>the 20th ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1507" to="1508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,593.42,337.98,7.86;9,151.52,604.38,329.07,7.86;9,151.52,615.34,172.45,8.12" xml:id="b24">
	<monogr>
		<title level="m" type="main" coord="9,263.85,604.38,125.06,7.86">Going deeper with convolutions</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno>CoRR abs/1409.4842</idno>
		<ptr target="http://arxiv.org/abs/1409.4842" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,625.69,337.98,7.86;9,151.52,636.65,329.07,7.86;9,151.52,647.61,185.41,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="9,379.40,625.69,101.19,7.86;9,151.52,636.65,281.31,7.86">Automated species recognition of antbirds in a Mexican rainforest using hidden Markov models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">M</forename><surname>Trifa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N G</forename><surname>Kirschel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">E</forename><surname>Vallejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,440.01,636.65,40.58,7.86;9,151.52,647.61,139.85,7.86">Journal of The Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
