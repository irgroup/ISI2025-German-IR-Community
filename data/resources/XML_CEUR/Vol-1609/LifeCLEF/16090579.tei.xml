<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,150.79,116.95,313.78,12.62;1,183.33,134.89,248.71,12.62">Very Deep Residual Networks with MaxOut for Plant Identification in the Wild</title>
				<funder ref="#_FzENRxT">
					<orgName type="full">CTU</orgName>
				</funder>
				<funder ref="#_3HeKQSz">
					<orgName type="full">Czech Science Foundation</orgName>
				</funder>
				<funder ref="#_qSef8Du">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,210.18,170.77,45.39,11.26"><forename type="first">Milan</forename><surname>Šulc</surname></persName>
							<email>sulcmila@cmp.felk.cvut.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Machine Perception</orgName>
								<orgName type="institution" key="instit1">FEE</orgName>
								<orgName type="institution" key="instit2">CTU in</orgName>
								<address>
									<addrLine>Prague ; Technicka 2</addrLine>
									<postCode>166 27</postCode>
									<settlement>Prague 6</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,263.04,173.29,69.96,8.74"><forename type="first">Dmytro</forename><surname>Mishkin</surname></persName>
							<email>mishkdmy@cmp.felk.cvut.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Machine Perception</orgName>
								<orgName type="institution" key="instit1">FEE</orgName>
								<orgName type="institution" key="instit2">CTU in</orgName>
								<address>
									<addrLine>Prague ; Technicka 2</addrLine>
									<postCode>166 27</postCode>
									<settlement>Prague 6</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,360.40,173.29,44.77,8.74"><forename type="first">Jiří</forename><surname>Matas</surname></persName>
							<email>matas@cmp.felk.cvut.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Machine Perception</orgName>
								<orgName type="institution" key="instit1">FEE</orgName>
								<orgName type="institution" key="instit2">CTU in</orgName>
								<address>
									<addrLine>Prague ; Technicka 2</addrLine>
									<postCode>166 27</postCode>
									<settlement>Prague 6</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,150.79,116.95,313.78,12.62;1,183.33,134.89,248.71,12.62">Very Deep Residual Networks with MaxOut for Plant Identification in the Wild</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C75435420DA382547EA5417612F4FB46</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The paper presents our deep learning approach to automatic recognition of plant species from photos. We utilized a very deep 152layer residual network [15] model pre-trained on ImageNet, replaced the original fully connected layer with two randomly initialized fully connected layers connected with maxout [13], and fine-tuned the network on the PlantCLEF 2016 training data. Bagging of 3 networks was used to further improve accuracy. With the proposed approach we scored among the top 3 teams in the PlantCLEF 2016 plant identification challenge.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the past, automatic recognition of plants was usually solved by requiring a photo of a specific plant organ, such as leaf <ref type="bibr" coords="1,337.02,415.80,15.50,8.74" target="#b20">[21,</ref><ref type="bibr" coords="1,352.52,415.80,7.75,8.74" target="#b5">6,</ref><ref type="bibr" coords="1,360.27,415.80,11.62,8.74" target="#b27">28]</ref>, flower <ref type="bibr" coords="1,410.18,415.80,15.99,8.74" target="#b23">[24,</ref><ref type="bibr" coords="1,426.16,415.80,7.99,8.74" target="#b0">1,</ref><ref type="bibr" coords="1,434.16,415.80,11.99,8.74" target="#b22">23]</ref> or tree bark <ref type="bibr" coords="1,157.88,427.76,11.25,8.74" target="#b5">[6,</ref><ref type="bibr" coords="1,169.13,427.76,11.25,8.74" target="#b28">29,</ref><ref type="bibr" coords="1,180.39,427.76,7.50,8.74" target="#b2">3]</ref>. Moreover, a number of these systems and datasets placed further constraints on the input image, such as white background behind in a leaf image.</p><p>Recently, Deep Convolutional Neural Networks (CNNs) succeeded in a number of computer vision tasks, especially those related to complex recognition and detection of objects. This was also the case of plant recognition, where in PlantCLEF 2015 <ref type="bibr" coords="1,210.99,488.27,10.52,8.74" target="#b8">[9]</ref> the deep learning submissions <ref type="bibr" coords="1,356.16,488.27,11.62,8.74" target="#b4">[5,</ref><ref type="bibr" coords="1,367.78,488.27,7.75,8.74" target="#b6">7,</ref><ref type="bibr" coords="1,375.53,488.27,7.75,8.74" target="#b3">4,</ref><ref type="bibr" coords="1,383.28,488.27,11.62,8.74" target="#b25">26]</ref> outperformed combinations of hand-crafted methods significantly (see Fig. <ref type="figure" coords="1,383.66,500.23,3.87,8.74" target="#fig_0">1</ref>).</p><p>Our submission to this year's challenge also employs a deep CNN pretrained on ImageNet, namely the very recent ResNet architecture <ref type="bibr" coords="1,391.43,524.87,14.61,8.74" target="#b14">[15]</ref>, which allows to train very deep networks efficiently. The idea of ResNets is that each layer should not learn the whole feature space transformation, but only a residual correction to the previous layer. To bridge domain shift between a general-class network pretrained on ImageNet and a fine-grained task of plant classification, we added an additional maxout <ref type="bibr" coords="1,231.89,584.65,15.50,8.74" target="#b12">[13]</ref> layer on top of the pretrained network. This brought a noticeable improvement in accuracy in our validation experiments.</p><p>The rest of this paper is organized as follows: Section 2 gives a quick overview of the PlantCLEF 2016 plant identification task. The proposed method is described in Section 3 and the preliminary results and validation in Section 4. The results on the test set are discussed in Section 5. Finally, Section 6 contains the conclusions and the discussion for future work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The PlantCLEF 2016 Plant Identification Task</head><p>The goal in the PlantCLEF challenge is to automatically identify plant species from photos of different nature. This years challenge <ref type="bibr" coords="2,369.03,405.61,16.13,8.74" target="#b9">[10,</ref><ref type="bibr" coords="2,385.16,405.61,12.10,8.74" target="#b18">19]</ref> addresses the task as an open-set or open-world recognition problem <ref type="bibr" coords="2,355.58,417.56,14.87,8.74" target="#b26">[27,</ref><ref type="bibr" coords="2,370.44,417.56,7.43,8.74" target="#b1">2]</ref>: the test data contains distractors of unseen categories and the metric for the classification is the mean average precision (mAP), considering each class of the training set as a query. This poses a requirement on robustness to unseen categories.</p><p>The training data consist of the training and test set of PlantCLEF 2015, which were fully annotated with the correct taxonomic species as well as other meta-data such as type of view (Leaf, LeafScan, Flower, Fruit, Stem, Branch, Entire), date of acquisition, author ID or its GPS coordinates (if available). The training set consists of 113,205 pictures of herb, tree and fern specimen belonging to 1,000 species. The evaluated metric is the mean average precision -mAP. The test set contains 8000 images, including the above mentioned distractor images. The official results on the test (evaluated by the organizers) are discussed in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Proposed Approach: Very Deep Residual Maxout Networks</head><p>Recently, the very deep residual networks of He et al. <ref type="bibr" coords="2,379.36,633.20,15.50,8.74" target="#b14">[15]</ref> gained a lot of attention after achieving the best results in both the ILSVRC (ImageNet Large Scale Visual Recognition Challenge) 2015 and the COCO (Common Objects in Context) 2015 Detection Challenge. The residual learning framework allows to efficiently train networks that are substantially deeper than the previously used CNN architectures. We used the pre-trained models on ImageNet publicly available<ref type="foot" coords="3,172.40,154.28,3.97,6.12" target="#foot_0">1</ref> for Caffe <ref type="bibr" coords="3,221.18,155.86,14.61,8.74" target="#b17">[18]</ref>.</p><p>To further improve the classification accuracy, we made a small change in the network architecture: the additional fully-connected layer with 512 neurons was added on top of the network, right before the softmax classifier. The activation function in the new layer is maxout <ref type="bibr" coords="3,298.60,203.84,15.50,8.74" target="#b12">[13]</ref> with 4 linear pieces. Dropout with a ratio of 50% is applied after the maxout layer and before the classifier. The final layer is a 1000-way softmax classifier corresponding to the number plant species needed to be recognized. Glorot <ref type="bibr" coords="3,276.85,239.70,10.52,8.74" target="#b7">[8]</ref> initialization was used for these two layers.</p><p>Thereafter, we have finetuned the network for 150,000 iterations in submissions "CMP Run 1" and "CMP Run 2" and for 370,000 iterations in "CMP Run 3", all with the following parameters:</p><p>-The learning rate was set to 10 -3 and lowered by factor of 10 each 100 000 iterations. -The momentum was set to 0.9, weight decay to 2 • 10 -4 . r -The effective batch size was set to 28 (either computed at once on NVIDIA Titan X, or split into more batches using Caffe's iter size parameter when used on lower-memory GPUs). -A horizontal mirroring of input images was performed during training.</p><p>Beyond fine-tuning the network, we performed bagging, inspired by its impact on the PlantCLEF 2015 results, where an interesting margin was gained with bagging of 5 networks by Choi <ref type="bibr" coords="3,268.39,412.82,9.96,8.74" target="#b4">[5]</ref>. Due to computational limits at training time, we only used bagging of 3 networks, although we believe that using a higher number of more diverse networks would further improve the accuracy. The voting was done by taking species-wise maximum of output probabilities.</p><p>We have also experimented with training Support Vector Machines (SVMs) on L2 normalized outputs of the last pooling layer "kernelized" using an approximate χ 2 feature map <ref type="bibr" coords="3,252.66,484.71,14.61,8.74" target="#b29">[30]</ref>. Platt's probabilistic output was used <ref type="bibr" coords="3,439.90,484.71,16.13,8.74" target="#b21">[22,</ref><ref type="bibr" coords="3,456.03,484.71,12.10,8.74" target="#b24">25]</ref> to obtain comparable results with One-vs-All arrangement of the binary classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Preliminary Results and Validation</head><p>For our preliminary experiments and validation, we used the PlantCLEF 2016 training set, which is the union of previous year's <ref type="bibr" coords="3,360.08,566.01,82.10,8.74">(PlantCLEF 2015)</ref> training and test sets. Our validation process was threefold:</p><p>First, we validated networks trained on the PlantCLEF 2015 training set by evaluating them on the PlantCLEF 2015 test set using the previous year's score metric <ref type="bibr" coords="3,166.79,613.99,9.96,8.74" target="#b8">[9]</ref>. The goal of this phase was to validate that the ResNet-152 architecture is superior to the GoogleNet networks finetuned by the winners of the PlantCLEF 2015 challenge. While the best submission without bagging achieved a score of 59.4% on image observations in the PlantCLEF 2015 challenge, a finetuned ResNet-152 (without maxout) scored 62.1%. Applying SVMs on top of the last pooling layer pushed the score further to 62.5%, and training different SVMs for different groups of view types (always one for Leaf and LeafScan, second for Flower and Fruit, and third for Stem, Branch and Entire) gives another small improvement to 62.7%. Note that the meta information about view type is also available at test-time. While deploying the SVMs slightly improved the 2015 score, using the CNN SoftMax output worked better for the 2016 metric. This is probably due to better comparability of SoftMax outputs among different samples, which was not important for the 2015 score, but which is crucial for the mAP used in PlantCLEF 2016. Finetuning ResNet-152 for 150,000 iterations lead to 52.2% mAP, while finetuning for 130,000 iterations with maxout lead to 56.75% mAP, proving that using maxout improves the accuracy significantly. The training set size is big enough to finetune networks for a larger number of iterations without overfitting, which brings additional 0.5% of mAP points, see Table <ref type="table" coords="4,429.47,541.68,3.87,8.74" target="#tab_1">2</ref>. The testtime 10-view image augmentation <ref type="bibr" coords="4,290.61,553.63,15.50,8.74" target="#b19">[20]</ref> (4 corner-crops, center crop and their mirrored versions) added only 0.2% of mAP, unlike in the ImageNet competition. Evaluating the network in a fully convolutional style on images scaled to 448 pixels (in longer dimension) surprisingly decreased the accuracy.</p><p>Third and lastly, we performed bagging on the selected pipeline by dividing the 2016 training set into three folds and finetuning 3 networks, each using a different fold for validation and the remaining two folds for finetuning. The only goal of this validation was to check, that finetuning of all 3 networks converged to a meaningful solution.  <ref type="figure" coords="5,284.15,361.32,3.87,8.74" target="#fig_1">2</ref>.</p><p>The second submission (CMP Run 2), achieving mAP 64.4%, was generated using only one of the three residual networks utilized in CMP Run 1. The difference between the first two submissions is 6.6%, underlining the importance of bagging.</p><p>The third submission (CMP Run 3), achieving mAP 63.9%, was generated by a network pretrained only on the LifeCLEF 2015 training set, for a higher number of iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>Our results confirm the suitability of very deep convolutional networks for plant recognition in the wild, allowing to use a unified end-to-end pipeline for recognition of different plant organs as well as overall views in an uncontrolled environment. Significant improvements, compared to the most successful approaches from the previous year, were achieved by deploying a very deep (152-layer) residual network and placing a maxout layer in front of the classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Future Work</head><p>Very recent improvements to the ResNet architecture, such as deeper networks trained with stochastic depth <ref type="bibr" coords="5,268.41,633.20,15.50,8.74" target="#b16">[17]</ref> or the new residual unit proposed based on the latest study of identity mappings <ref type="bibr" coords="5,304.50,645.16,14.61,8.74" target="#b15">[16]</ref>, would be the next steps for future work in plant recognition using deep residual networks. The second open question is what is the best way of learning for domain adaptation. We believe that the results can be further significantly improved without any change in the CNN architecture.</p><p>One of the attractive applications of plant recognition are mobile apps with automatic field guides <ref type="bibr" coords="6,237.59,416.44,15.90,8.74" target="#b20">[21,</ref><ref type="bibr" coords="6,253.49,416.44,11.93,8.74" target="#b11">12,</ref><ref type="bibr" coords="6,265.42,416.44,11.93,8.74" target="#b10">11]</ref>. Compared to the standard automatic plant recognition approaches, deploying a CNN allows to process different types of images using exactly the same pipeline. However, since our networks are very deep and have a significant memory footprint (241MB), they should be optimized in terms of speed, memory and energy efficiency prior to utilization on mobile devices. The Deep Compression of Han et al. <ref type="bibr" coords="6,340.27,476.22,15.50,8.74" target="#b13">[14]</ref> is a promising direction for this optimization.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,134.77,323.00,345.83,7.89;2,134.77,333.99,217.46,7.86;2,143.41,116.83,328.54,191.40"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Results of the previous year's (PlantCLEF2015) main task. Source: The Life-CLEF 2015 Plant Identification Task [9] presentation.</figDesc><graphic coords="2,143.41,116.83,328.54,191.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,134.77,326.34,345.82,7.89;6,134.77,337.33,332.20,7.86;6,143.41,116.83,328.53,194.74"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. Results of the main task in PlantCLEF2016<ref type="bibr" coords="6,349.49,326.37,13.52,7.86" target="#b9">[10]</ref>. CMP results are in orange, our primary submission (CMP Run 1) scored among the 3 best performing teams.</figDesc><graphic coords="6,143.41,116.83,328.53,194.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.77,237.46,345.83,197.52"><head>Table 1 .</head><label>1</label><figDesc>Validation of the finetuned ResNet-152 using the PlantCLEF 2015 [9] score. LR denotes the learning rate, it. denotes the number of iterations, sepSVM is the set of SVM classifiers, each trained only on images of certain types (leaves, flowers &amp; fruits, stem &amp; branch &amp; entire). Second, we tested networks finetuned on PlantCLEF 2015 training data by evaluating them on the test set of PlantCLEF 2015 with the mAP metric chosen for PlantCLEF 2016. This step demonstrated the difference between the metrics used in PlantCLEF 2015 and PlantCLEF 2016.</figDesc><table coords="4,194.70,291.63,225.97,53.29"><row><cell>Method</cell><cell>Score</cell></row><row><cell>LR = 0.001, 70K it.</cell><cell>58.7%</cell></row><row><cell>LR = 0.001, step size 100K, 150K it.</cell><cell>62.1%</cell></row><row><cell>LR = 0.001, step size 100K, 150K it. + SVM</cell><cell>62.5%</cell></row><row><cell cols="2">LR = 0.001, step size 100K, 150K it. + sepSVM 62.7%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,134.77,117.41,345.83,252.65"><head>Table 2 .</head><label>2</label><figDesc>Validation of the finetuned ResNet-152 using the PlantCLEF 2016 [10] mAP score. LR denotes the learning rate, it. denotes the number of iterations, sepSVM is the set of SVM classifiers, each trained only on images of certain types (leaves, flowers &amp; fruits, stem &amp; branch &amp; entire).</figDesc><table coords="5,172.10,171.58,29.19,7.86"><row><cell>Method</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.73,658.44,241.07,7.47"><p>https://github.com/KaimingHe/deep-residual-networks</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>Milan Šulc and <rs type="person">Dmytro Mishkin</rs> were supported by the <rs type="funder">CTU</rs> student grant <rs type="grantNumber">SGS15/155/OHK3/2T/13</rs>, <rs type="person">Jiří Matas</rs> by the <rs type="funder">Czech Science Foundation</rs> Project <rs type="grantNumber">GA ČR P103/12/G084</rs>. Access to computing and storage facilities owned by parties and projects contributing to the <rs type="institution">National Grid Infrastructure MetaCentrum</rs>, provided under the programme "<rs type="projectName">Projects of Large Research, Development, and Innovations Infrastructures</rs>" (<rs type="grantNumber">CESNET LM2015042</rs>), is greatly appreciated.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_FzENRxT">
					<idno type="grant-number">SGS15/155/OHK3/2T/13</idno>
				</org>
				<org type="funded-project" xml:id="_3HeKQSz">
					<idno type="grant-number">GA ČR P103/12/G084</idno>
					<orgName type="project" subtype="full">Projects of Large Research, Development, and Innovations Infrastructures</orgName>
				</org>
				<org type="funding" xml:id="_qSef8Du">
					<idno type="grant-number">CESNET LM2015042</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,142.96,646.84,337.63,7.86;6,151.52,657.79,329.07,7.86;7,151.52,120.67,154.04,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,285.14,646.84,195.45,7.86;6,151.52,657.79,71.73,7.86">Image segmentation for large-scale subcategory flower recognition</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Angelova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,248.11,657.79,176.51,7.86;6,458.46,657.79,22.14,7.86;7,151.52,120.67,40.26,7.86">Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="39" to="45" />
		</imprint>
	</monogr>
	<note>IEEE Workshop</note>
</biblStruct>

<biblStruct coords="7,142.96,130.99,337.63,7.86;7,151.52,141.95,329.07,7.86;7,151.52,152.91,25.60,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,251.00,130.99,130.32,7.86">Towards open world recognition</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bendale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,404.28,130.99,76.31,7.86;7,151.52,141.95,262.39,7.86">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1893" to="1902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,163.23,337.63,7.86;7,151.52,174.19,329.07,7.86;7,151.52,185.15,182.97,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,311.24,163.23,169.35,7.86;7,151.52,174.19,166.40,7.86">A comparison of multi-scale local binary pattern variants for bark image retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Boudra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Behloul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,340.50,174.19,140.09,7.86;7,151.52,185.15,59.24,7.86">Advanced Concepts for Intelligent Vision Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="764" to="775" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,195.47,337.64,7.86;7,151.52,206.43,329.07,7.86;7,151.52,217.39,329.07,7.86;7,151.52,228.35,268.27,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,338.89,195.47,141.70,7.86;7,151.52,206.43,329.07,7.86">A comparative study of fine-grained classification methods in the context of the lifeclef plant identification challenge</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Champ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lorieul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<ptr target="CEUR-WS" />
	</analytic>
	<monogr>
		<title level="m" coord="7,190.39,217.39,290.21,7.86;7,151.52,228.35,21.99,7.86">Working Notes of CLEF 2015 -Conference and Labs of the Evaluation forum</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09-08">2015. September 8-11, 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,238.67,337.64,7.86;7,151.52,249.63,329.07,7.86;7,151.52,260.59,329.07,7.86;7,151.52,271.55,72.95,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,189.11,238.67,291.49,7.86;7,151.52,249.63,153.14,7.86">Plant identification with deep convolutional neural network: Snumedinfo at lifeclef plant identification task 2015</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<ptr target="CEUR-WS" />
	</analytic>
	<monogr>
		<title level="m" coord="7,324.92,249.63,155.67,7.86;7,151.52,260.59,157.27,7.86">Working Notes of CLEF 2015 -Conference and Labs of the Evaluation forum</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">September 8-11, 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,281.87,337.64,7.86;7,151.52,292.83,329.07,7.86;7,151.52,303.79,127.34,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,243.39,281.87,237.20,7.86;7,151.52,292.83,94.19,7.86">Automated identification of tree species from images of the bark, leaves and needles</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fiel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sablatnig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,265.87,292.83,194.55,7.86">Proc. of 16th Computer Vision Winter Workshop</title>
		<meeting>of 16th Computer Vision Winter Workshop<address><addrLine>Mitterberg, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,314.11,337.63,7.86;7,151.52,325.07,329.07,7.86;7,151.52,336.03,329.07,7.86;7,151.52,346.99,25.60,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,336.69,314.11,143.90,7.86;7,151.52,325.07,122.59,7.86">Content specific feature learning for fine-grained plant classification</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Mccool</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Corke</surname></persName>
		</author>
		<ptr target="CEUR-WS" />
	</analytic>
	<monogr>
		<title level="m" coord="7,293.62,325.07,186.98,7.86;7,151.52,336.03,114.79,7.86">Working Notes of CLEF 2015 -Conference and Labs of the Evaluation forum</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">September 8-11, 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,357.31,337.64,7.86;7,151.52,368.27,329.07,7.86;7,151.52,379.23,76.80,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,248.15,357.31,232.44,7.86;7,151.52,368.27,61.31,7.86">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,232.53,368.27,244.60,7.86">International conference on artificial intelligence and statistics</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,389.55,337.63,7.86;7,151.52,400.51,329.07,7.86;7,151.52,411.47,197.54,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,280.21,389.55,145.91,7.86">Lifeclef plant identification task 2015</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<ptr target="CEUR-WS" />
	</analytic>
	<monogr>
		<title level="m" coord="7,446.53,389.55,34.06,7.86;7,151.52,400.51,282.63,7.86">Working Notes of CLEF 2015 -Conference and Labs of the Evaluation forum</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">September 8-11, 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,421.79,337.97,7.86;7,151.52,432.75,147.90,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,277.55,421.79,198.94,7.86">Plant identification in an open-world (lifeclef 2016)</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,165.60,432.75,83.65,7.86">CLEF working notes</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">2016</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,443.07,337.98,7.86;7,151.52,454.03,329.07,7.86;7,151.52,464.99,329.07,7.86;7,151.52,475.95,80.63,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,315.77,454.03,164.82,7.86;7,151.52,464.99,49.39,7.86">Pl@ ntnet mobile 2014: Android port and new features</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Affouard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bakic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Barbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dufour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Vignau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,222.08,464.99,254.95,7.86">Proceedings of international conference on multimedia retrieval</title>
		<meeting>international conference on multimedia retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page">527</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,486.27,337.98,7.86;7,151.52,497.23,329.07,7.86;7,151.52,508.19,328.53,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,316.02,497.23,85.32,7.86">Pl@ ntnet mobile app</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bakić</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Barbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carré</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthélémy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,422.30,497.23,58.29,7.86;7,151.52,508.19,216.84,7.86">Proceedings of the 21st ACM international conference on Multimedia</title>
		<meeting>the 21st ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="423" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,518.51,337.97,7.86;7,151.52,529.47,195.73,7.86" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1302.4389</idno>
		<title level="m" coord="7,449.36,518.51,31.23,7.86;7,151.52,529.47,33.97,7.86">Maxout networks</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,142.61,539.79,337.97,7.86;7,151.52,550.75,329.07,7.86;7,151.52,561.71,43.51,7.86" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="7,276.09,539.79,204.50,7.86;7,151.52,550.75,261.84,7.86">Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015-10">Oct 2015</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct coords="7,142.61,572.03,337.98,7.86;7,151.52,582.99,159.05,7.86" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="7,299.05,572.03,177.61,7.86">Deep residual learning for image recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,142.61,593.31,337.98,7.86;7,151.52,604.27,159.05,7.86" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="7,298.94,593.31,177.41,7.86">Identity mappings in deep residual networks</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.05027</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,142.61,614.60,337.98,7.86;7,151.52,625.55,201.03,7.86" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sedra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.09382</idno>
		<title level="m" coord="7,368.05,614.60,112.54,7.86;7,151.52,625.55,34.64,7.86">Deep networks with stochastic depth</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,142.61,635.88,337.97,7.86;7,151.52,646.84,329.07,7.86;7,151.52,657.79,154.44,7.86" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="7,237.79,646.84,238.19,7.86">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5093</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,142.62,120.67,337.97,7.86;8,151.52,131.63,329.07,7.86;8,151.52,142.59,282.60,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="8,360.12,131.63,120.47,7.86;8,151.52,142.59,125.04,7.86">Lifeclef 2016: multimedia life species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Champ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Planqué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Palazzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,297.60,142.59,107.84,7.86">Proceedings of CLEF 2016</title>
		<meeting>CLEF 2016</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,153.55,337.98,7.86;8,151.52,164.51,329.07,7.86;8,151.52,175.46,86.01,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="8,328.09,153.55,152.50,7.86;8,151.52,164.51,103.94,7.86">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,275.64,164.51,200.74,7.86">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,186.42,337.98,7.86;8,151.52,197.38,329.07,7.86;8,151.52,208.34,298.98,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="8,204.15,197.38,276.44,7.86;8,151.52,208.34,34.91,7.86">Leafsnap: A computer vision system for automatic plant species identification</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Kress</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">C</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">V</forename><surname>Soares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,207.07,208.34,119.90,7.86">Computer Vision-ECCV 2012</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="502" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,219.30,337.97,7.86;8,151.52,230.26,191.84,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="8,283.09,219.30,197.50,7.86;8,151.52,230.26,62.53,7.86">A note on platt&apos;s probabilistic outputs for support vector machines</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">C</forename><surname>Weng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,221.48,230.26,69.14,7.86">Machine learning</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,241.22,337.98,7.86;8,151.52,252.18,329.07,7.86;8,151.52,263.14,171.92,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="8,398.67,241.22,81.93,7.86;8,151.52,252.18,128.59,7.86">Flower classification for a citizen science mobile app</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Mattos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">G</forename><surname>Herrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">K</forename><surname>Shigeno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>Feris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,303.25,252.18,177.35,7.86;8,151.52,263.14,84.33,7.86">Proceedings of International Conference on Multimedia Retrieval</title>
		<meeting>International Conference on Multimedia Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page">532</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,274.09,337.97,7.86;8,151.52,285.05,203.94,7.86" xml:id="b23">
	<monogr>
		<title level="m" type="main" coord="8,277.28,274.09,203.31,7.86;8,151.52,285.05,95.40,7.86">An automatic visual flora-segmentation and classification of flower images</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Nilsback</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<pubPlace>Oxford University</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,296.01,337.97,7.86;8,151.52,306.97,324.71,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="8,192.29,296.01,288.29,7.86;8,151.52,306.97,121.21,7.86">Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,280.39,306.97,143.11,7.86">Advances in large margin classifiers</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,317.93,337.97,7.86;8,151.52,328.89,329.07,7.86;8,151.52,339.85,329.07,7.86;8,151.52,350.81,43.26,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="8,333.89,317.93,146.70,7.86;8,151.52,328.89,109.67,7.86">Fine-tuning deep convolutional networks for plant recognition</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Caicedo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">E</forename><surname>Camargo</surname></persName>
		</author>
		<ptr target="CEUR-WS" />
	</analytic>
	<monogr>
		<title level="m" coord="8,283.85,328.89,196.74,7.86;8,151.52,339.85,120.62,7.86">Working Notes of CLEF 2015 -Conference and Labs of the Evaluation forum</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">September 8-11, 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,361.77,337.97,7.86;8,151.52,372.73,329.07,7.86;8,151.52,383.68,47.10,7.86" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="8,306.64,361.77,170.02,7.86">Probability models for open set recognition</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Scheirer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">E</forename><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,151.52,372.73,270.39,7.86">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2317" to="2324" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>IEEE Transactions on</note>
</biblStruct>

<biblStruct coords="8,142.62,394.64,337.98,7.86;8,151.52,405.60,187.29,7.86" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="8,233.52,394.64,128.21,7.86">Texture-based leaf identification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,382.24,394.64,98.35,7.86;8,151.52,405.60,63.31,7.86">Computer Vision-ECCV 2014 Workshops</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="185" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,416.56,337.97,7.86;8,151.52,427.52,329.07,7.86;8,151.52,438.48,211.10,7.86" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="8,236.97,416.56,243.62,7.86;8,151.52,427.52,43.20,7.86">Kernel-mapped histograms of multi-scale lbps for tree bark recognition</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,216.99,427.52,215.06,7.86;8,151.52,438.48,109.36,7.86">Image and Vision Computing New Zealand (IVCNZ)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="82" to="87" />
		</imprint>
	</monogr>
	<note>International Conference of</note>
</biblStruct>

<biblStruct coords="8,142.62,449.44,337.98,7.86;8,151.52,460.40,329.07,7.86;8,151.52,471.36,25.60,7.86" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="8,268.67,449.44,207.20,7.86">Efficient additive kernels via explicit feature maps</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,151.52,460.40,266.81,7.86">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="480" to="492" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>IEEE Transactions on</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
