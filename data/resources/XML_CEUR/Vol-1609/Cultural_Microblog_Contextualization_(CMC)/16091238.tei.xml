<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,156.88,115.96,301.59,12.62;1,151.03,133.89,313.29,12.62;1,235.85,151.82,143.65,12.62">Tweet Contextualization using Continuous Space Vectors: Automatic Summarization of Cultural Documents</title>
				<funder>
					<orgName type="full">GAFES of the Université d&apos;Avignon et des Pays de Vaucluse (France</orgName>
				</funder>
				<funder>
					<orgName type="full">French ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,135.81,189.52,96.91,8.74"><forename type="first">Elvys</forename><forename type="middle">Linhares</forename><surname>Pontes</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LIA</orgName>
								<orgName type="institution">Université d&apos;Avignon et des Pays de Vaucluse</orgName>
								<address>
									<settlement>Avignon</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,247.86,189.52,123.70,8.74"><forename type="first">Juan-Manuel</forename><surname>Torres-Moreno</surname></persName>
							<email>juan-manuel.torres@univ-avignon.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">LIA</orgName>
								<orgName type="institution">Université d&apos;Avignon et des Pays de Vaucluse</orgName>
								<address>
									<settlement>Avignon</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">École Polytechnique de Montréal</orgName>
								<address>
									<settlement>Montréal</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,388.46,189.52,64.49,8.74"><forename type="first">Stéphane</forename><surname>Huet</surname></persName>
							<email>stephane.huet@univ-avignon.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">LIA</orgName>
								<orgName type="institution">Université d&apos;Avignon et des Pays de Vaucluse</orgName>
								<address>
									<settlement>Avignon</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,248.70,201.48,113.49,8.74"><forename type="first">Andréa</forename><forename type="middle">Carneiro</forename><surname>Linhares</surname></persName>
							<email>andreaclinhares@gmail.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Universidade Federal do Ceará</orgName>
								<address>
									<settlement>Sobral-CE</settlement>
									<country key="BR">Brasil</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,156.88,115.96,301.59,12.62;1,151.03,133.89,313.29,12.62;1,235.85,151.82,143.65,12.62">Tweet Contextualization using Continuous Space Vectors: Automatic Summarization of Cultural Documents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">370908E61813D30631E6A67B73517432</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Text Contextualization</term>
					<term>Automatic Text Summarization</term>
					<term>Word Embedding</term>
					<term>Wikipedia</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe our participation in the INEX 2016 Tweet Contextualization track. The tweet contextualization process aims at generating a short summary from Wikipedia documents related to the tweet. In our approach, we analyzed tweets and created a query to retrieve the most relevant Wikipedia article. We combine Information Retrieval and Automatic Text Summarization methods to generate the tweet context.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Twitter 4 is a social network used to diffuse news quickly using a so-called "tweet". Many newspapers and magazines use Twitter to diffuse relevant events. A tweet is composed of hashtags, usernames, words and punctuation marks. These symbols make it possible to identify Twitter's user accounts, keywords and emotions. However, a tweet is limited to 140 characters and it is complicated to describe completely an event in a single tweet. A way to overcome this problem is to get more information from another source to better explain the tweet.</p><p>Several papers concerning the tweet summarization have been developed. For example, the work of Liu et al. introduces a graph-based multi-tweet summarization system <ref type="bibr" coords="1,204.58,603.55,9.96,8.74" target="#b6">[7]</ref>. This graph integrates the functionalities of social networks, solving partially the lack of information contained in tweets. <ref type="bibr" coords="1,407.62,615.50,72.97,8.74">Chakrabarti and</ref> Punera use a Hidden Markov Model in order to enable the temporal events of sets of tweets to be modeled <ref type="bibr" coords="2,261.40,130.95,9.96,8.74" target="#b2">[3]</ref>.</p><p>Inspired by the problem of tweet contextualization, the Cultural Microblog Contextualization based on Wikipedia track aims to generate short summaries which provide the background information of tweets to help users to understand them. The main idea of this task can also be forward in the French project Project "Galerie des festivals" (Gafes) (Gallery of Festivals), which is a collaboration between sociologists and computer scientists <ref type="foot" coords="2,352.54,201.69,3.97,6.12" target="#foot_0">5</ref> and is carried by the Université d'Avignon (Centre Norbert Elias and Laboratoire Informatique d'Avignon). Indeed, in this paper, we contextualize a set of tweets by constructing a summary by extraction <ref type="bibr" coords="2,195.95,239.13,15.50,8.74" target="#b12">[13]</ref> guided by the "festival" mentioned in the tweet.</p><p>The summary must contain some context information about the event in order to help answering questions such as "what is this tweet about?". The context should take the form of a readable summary, not exceeding 500 words, composed of passages from the provided Wikipedia corpus. This INEX task has been described in the paper <ref type="bibr" coords="2,258.13,299.48,14.61,8.74" target="#b10">[11]</ref>. The INEX's organizers selected a set of tweets to be contextualized by the participants using the English version of Wikipedia. These tweets are collected from a set of public micro-blogs posted on Twitter and are related to the keyword "festival".</p><p>This paper is organized as follows. In Section 2 we describe our approach to contextualize the tweet. Then, we present the process of document retrieval on Wikipedia and the summarization systems in Sections 3 and 4, respectively. Finally, the conclusions are described in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Architecture</head><p>Most studies to contextualize a tweet using the Wikipedia's corpus separates this task in two parts: Information Retrieval (IR) to get the Wikipedia's documents and Automatic Text Summarization (ATS) to generate a short summary about these documents <ref type="bibr" coords="2,212.38,481.21,9.96,8.74" target="#b0">[1]</ref>. Our system is also based on these two tasks to analyze and to create the summaries (Figure <ref type="figure" coords="2,298.18,493.17,3.87,8.74" target="#fig_0">1</ref>). The first part is responsible to get the Wikipedia's document that best describes the festival mentioned in the tweet (Section 3). Initially, our system normalizes and removes the punctuation marks from each tweet to create an Indri query. Then, the Lemur system retrieves the 50 Wikipedia's documents related to the query. Finally, the system scores these documents based on the tweets and selects the document with the highest score as best description of the tweet.</p><p>The second part analyzes the selected document and creates its summary using different ATS systems (Section 4). We use the framework word2vec 6 to create the Continuous Space Vector (CSV) representation using the corpus Gigaword. Then, we create a context vocabulary of the selected document using the CSV representation. Finally, we use Artex and Sasi systems to summarize the selected document using the original vocabulary and the context vocabulary. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Wikipedia's Document Retrieval</head><p>Using the list of tweets given by the INEX's organization, we attributed different scores for the hashtags, usernames and text in the tweet. We consider the hashtags as the tweet's keywords, because they normally are names or places of cultural events. The usernames represent links to other Twitter's accounts (sometimes the festival's account) and text have few relevant words about the cultural event. Although the punctuation marks are relevant to get the semantic of the tweet, they are irrelevant to identify the festival's name. So, we remove all the punctuation marks and the stopwords.</p><p>For each tweet, we created an Indry query composed of the hashtags, the usernames and the words. Then, we used the Lemur system to find the 50 Wikipedia's documents related to this query.</p><p>As the 50 documents can have different subjects, we analyze these documents to find the document most related to the tweet. For each Wikipedia's document, we analyze the title and the text in relation to the tweet's elements (hashtag, username and word). Normally, the title of the Wikipedia's document has few words and contains the main information, while the text of the Wikipedia's document is large and the relevance of words are small. So, we consider Equation 3 describing the score of the Wikipedia's document D based on the tweet T .</p><formula xml:id="formula_0" coords="4,145.01,166.10,335.59,54.20">score title = α 1 × occ(ht, title) + α 2 × occ(un, title) + α 3 × occ(nw, title) (1) score text = β 1 × occ(ht, text) + β 2 × occ(un, text) + β 3 × occ(nw, text) (2) score doc = score title + score text<label>(3)</label></formula><p>where ht are the hashtags of the tweet T , un are the usernames of the tweet T , nw are the normal words of the tweet T and occ(ht, title) is the sum of occurrences of the hashtags in the title.</p><p>We analyzed a subset of tweets and we set up empirically the parameters:</p><formula xml:id="formula_1" coords="4,134.77,278.54,231.60,9.65">α 1 = 120, α 2 = 80, α 3 = 80, β 1 = 2, β 2 = 2, β 3 = 1.</formula><p>For each tweet, we chose the Wikipedia's document with the biggest score to be analyzed by the ATS systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Automatic Text Summarization</head><p>The Automatic Text Summarization (ATS) systems analyze the sentences and create a short summary with the main information of the text. In order to better analyze the selected document (section above), we create two types of vocabulary (Subsection 4.1) and we use Artex (Sect. 4.2) and Sasi (Sect. 4.3) systems in order to summarize this document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Word Representation</head><p>The word representation is very important to analyze a text. The standard word representation is an one-hot vector using a Discrete Space Vector (DSV), where each word is represented by a vector composed of zeros and only one. In this representation, all the words are independent from one another, e.g. "car", "house", "bigger" and "biggest" have different representations. In this case, we can not analyze well the sentences because we consider similar words or words with the same context as independent words.</p><p>We developed a better representation to create a context vocabulary based on context of words <ref type="bibr" coords="4,220.87,560.48,9.96,8.74" target="#b4">[5]</ref>. We represent the words by the context using CSVs <ref type="bibr" coords="4,455.63,560.48,9.96,8.74" target="#b8">[9]</ref>. In this representation, two words with same context have similar representations. They devised the greedy algorithm 1 to find the similar words of word w in the texts among a pre-compiled list lcs of CSVs generated on a large corpus. If two words have a similar context, they are clustered in a same set and replaced by the most frequent word of this set. As the clusters can represent synonyms and/or words with the same idea, we can better calculate the similarity between the sentences and the metrics as Term Frequency-Inverse Document Frequency (TF-IDF). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Artex summarizer system</head><p>The Artex system <ref type="bibr" coords="5,214.76,347.23,15.50,8.74" target="#b11">[12]</ref> is an ATS system, which models a text with the sentences s 1 , s 2 , . . . , s P and vocabulary size N in a Vector Space Model (VSM) <ref type="foot" coords="5,443.79,357.61,3.97,6.12" target="#foot_2">7</ref> . Then, it calculates an average document vector that represents the average of all sentences vectors. Additionally, the system calculates the "lexical weight" for each sentence, i.e. the number of words in the sentence (Figure <ref type="figure" coords="5,390.30,395.05,3.87,8.74" target="#fig_1">2</ref>). The score of sentence s i is calculated using the proximity with the "global topic" and the "lexical weight" (Equation <ref type="formula" coords="5,320.32,634.01,3.87,8.74">4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>score(s</head><formula xml:id="formula_2" coords="6,286.22,130.92,194.37,9.68">i ) = (s i × b) × a (4)</formula><p>where s i is the vector of the sentence i, a is the average pseudo-word vector (i.e. the average number of occurrences of N words used in the sentence i) and b is the average pseudo-sentence vector (i.e. the average number of occurrences of each word j used trough the P sentences).</p><p>Finally, the summary is generated concatenating the sentences with the highest scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Sasi summarizer system</head><p>The Sasi system <ref type="bibr" coords="6,210.31,257.48,10.52,8.74" target="#b5">[6]</ref> is an ATS system that models the text as a graph of sentences G = (V, E), where V is associated with the sentences of document (set of vertices) and E represents the similarity between two sentences (set of edges). Two sentences, which are represented by the vectors A and B, are similar if the cosine similarity between them (Equation <ref type="formula" coords="6,318.80,305.31,4.43,8.74" target="#formula_3">5</ref>) is higher than the average value of the similarity between all the sentences of the document.</p><formula xml:id="formula_3" coords="6,252.64,337.02,227.95,22.31">sim(A, B) = A × B ||A|| × ||B||<label>(5)</label></formula><p>From the graph G, the system calculates the independent subset<ref type="foot" coords="6,427.62,366.32,3.97,6.12" target="#foot_3">8</ref> in order to find the most relevant non-redundant sentences. Therefore, this system creates an independent subset prioritizing the most relevant sentences based on the TF-IDF metric. Finally, the summary is composed of the most relevant sentences of the independent subset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Settings and Evaluation</head><p>The set of tweets collected by INEX's organizers mentions different festivals in the world. So, it is not possible to have neither the reference summaries nor the source document about each festival. In order to evaluate the quality of the summaries, the ROUGE system <ref type="bibr" coords="6,298.57,506.66,10.52,8.74" target="#b3">[4]</ref> needs a set of reference summaries to estimate the quality of a candidate summary. In order to avoid the references, we have chosen an approach without human references <ref type="bibr" coords="6,363.85,530.57,10.52,8.74" target="#b7">[8,</ref><ref type="bibr" coords="6,376.03,530.57,12.73,8.74" target="#b9">10,</ref><ref type="bibr" coords="6,390.43,530.57,7.75,8.74" target="#b1">2]</ref> that evaluates the relevance of a candidate summary in relation to the source. In our experiments we consider the first retrieved text by the Lemur system as a "source text" for each tweet.</p><p>We use the FRESA system <ref type="bibr" coords="6,269.05,578.39,15.50,8.74" target="#b9">[10,</ref><ref type="bibr" coords="6,286.21,578.39,12.73,8.74" target="#b13">14]</ref> to compute the relevance of the summary based on the intersection of the n-grams between the candidate summary and the "source text". For each tweet, we generated a summary (less than 500 words) using the following systems: Artex summarizer, Sasi with the original vocabulary (Sasi OV) and Sasi with the context vocabulary (Sasi CV). Table <ref type="table" coords="6,428.85,626.21,4.98,8.74" target="#tab_1">1</ref> shows the FRESA results about the quality of the summaries using 1-grams (FRESA-1), 2-grams (FRESA-2), skip 2-grams (FRESA-4) and their average values (FRESA-M). Results were computed using the Kullback-Leibler modified divergence <ref type="bibr" coords="7,462.33,142.90,14.61,8.74" target="#b12">[13]</ref>. From Table <ref type="table" coords="7,202.96,274.98,3.87,8.74" target="#tab_1">1</ref>, we can not distinguish the best system, because all scores are too close. Therefore, the FRESA evaluation without references is not yet sufficient to identify the quality of the best ATS system. In fact, the first document retrieved by the IR system of INDRI may not contain the most relevant information about the festival that was mentioned in the tweet. So, establishing what is the "correct" source to evaluate a system without human references, is not a simple task. A manual evaluation is required in order to analyze correctly the source and the summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Perspectives</head><p>In this paper, we presented our contributions to the INEX 2016 Tweet Contextualization Track. We considered different scores for each tweet's element to retrieve the most related Wikipedia's document with respect to a tweet. Then, we used two types of vocabularies to analyze the selected documents and to create their summary using different ATS systems. Finally, we created the summaries using two ATS systems.</p><p>In future work, summaries can be generated or can resort to a strategy to fusion multidocument sentences and preserve the grammaticality of each summary.</p><p>The evaluation using standard methods (ROUGE, FRESA,...) is probably not the most appropriate approach to measure the quality of this task of contextualization. It is possible to make a more interactive evaluation issue allowing visualization methods. We believe this evaluation, using human interaction, should correspond to a better evaluation of the results. We also want to investigate the improvement of this type of evaluation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,146.29,390.84,322.77,7.89"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Our system architecture to contextualize the tweet using the Wikipedia.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,264.10,587.33,87.15,7.89;5,137.10,428.52,164.41,129.60"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Artex system.</figDesc><graphic coords="5,137.10,428.52,164.41,129.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,134.77,118.71,324.15,175.04"><head></head><label></label><figDesc>Algorithm 1 Context vocabulary of text Input: n (neighborhood size), lcs (list of words inside continuous space), text for each word wt in text do if wt is in lcs then nset ← {wt} nlist ← [wt] while nlist is not empty do w l ← nlist.pop(0) nw ← the n nearest words of w l in lcs nlist.add((nw ∩ vocabulary of text) \ nset) nset ← nset ∪ (nw ∩ vocabulary of text) end while Replace in text each word of nset by the most frequent of nset</figDesc><table coords="5,143.98,263.95,52.35,29.81"><row><cell>end if</cell></row><row><cell>end for</cell></row><row><cell>Return text</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,202.88,174.95,209.59,70.75"><head>Table 1 .</head><label>1</label><figDesc>FRESA Evaluation Results.</figDesc><table coords="7,202.88,198.29,209.59,47.41"><row><cell cols="2">System FRESA-1 FRESA-2 FRESA-4 FRESA-M</cell></row><row><cell>Artex</cell><cell>0.14733 0.07701 0.07708 0.10047</cell></row><row><cell>Sasi OV</cell><cell>0.15056 0.07679 0.07667 0.10134</cell></row><row><cell>Sasi CV</cell><cell>0.14959 0.07665 0.07660 0.10095</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_0" coords="2,144.73,634.88,335.87,8.12;2,144.73,646.48,37.66,7.47"><p>A description for the GaFes Project is available on the website: https://mc2.talne. eu/gafes</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_1" coords="2,144.73,656.80,225.97,8.12"><p>Site: https://code.google.com/archive/p/word2vec/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_2" coords="5,144.73,656.80,219.68,7.86"><p>We used the DSVs but could be expanded with CSVs.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_3" coords="6,144.73,645.84,335.87,7.86;6,144.73,656.80,116.68,7.86"><p>An independent subset of a graph G is a subset of the vertices such that there is no edges between these vertices.</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>This work was partially financed by the <rs type="funder">French ANR</rs> project <rs type="funder">GAFES of the Université d'Avignon et des Pays de Vaucluse (France</rs>). 4 https://twitter.com/</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,142.59,337.63,7.86;8,151.52,153.55,213.10,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="8,344.98,142.59,135.61,7.86;8,151.52,153.55,139.43,7.86">A hybrid tweet contextualization system using ir and summarization</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>INEX</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,164.51,337.63,7.86;8,151.52,175.46,329.07,7.86;8,151.52,186.42,329.07,7.86;8,151.52,198.03,213.82,7.47" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,376.74,164.51,103.85,7.86;8,151.52,175.46,324.46,7.86">Evaluating Multiple Summaries Without Human Models: A First Experiment with a Trivergent Model</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Cabrera-Diego</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Torres-Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Durette</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-41754-7_8</idno>
		<ptr target="http://dx.doi.org/10.1007/978-3-319-41754-7_8" />
	</analytic>
	<monogr>
		<title level="m" coord="8,353.71,186.42,93.15,7.86">Proceedings in NLDB</title>
		<meeting>in NLDB</meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="91" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,208.34,337.64,7.86;8,151.52,219.30,329.07,7.86;8,151.52,230.26,181.02,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,274.22,208.34,143.54,7.86">Event Summarization using Tweets</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Punera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,440.89,208.34,39.70,7.86;8,151.52,219.30,329.07,7.86;8,151.52,230.26,152.34,7.86">5th International Conference on Weblogs and Social Media (ICWSM). Association for the Advancement of Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,241.22,337.63,7.86;8,151.52,252.18,329.07,7.86;8,151.52,263.14,135.92,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,199.54,241.22,260.00,7.86">ROUGE: A Package for Automatic Evaluation of Summaries</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,296.08,252.18,184.51,7.86;8,151.52,263.14,36.06,7.86">Workshop Text Summarization Branches Out (ACL&apos;04)</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Szpakowicz</surname></persName>
		</editor>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,274.09,337.64,7.86;8,151.52,285.05,329.07,7.86;8,151.52,296.01,329.07,7.86;8,151.52,307.62,218.53,7.47" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,437.85,274.09,42.75,7.86;8,151.52,285.05,329.07,7.86;8,151.52,296.01,14.39,7.86">Automatic Text Summarization with a Reduced Vocabulary Using Continuous Space Vectors</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Linhares Pontes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Huet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Torres-Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Linhares</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-41754-7_46</idno>
		<ptr target="http://dx.doi.org/10.1007/978-3-319-41754-7_46" />
	</analytic>
	<monogr>
		<title level="m" coord="8,363.10,296.01,86.88,7.86">Proceedings in NLDB</title>
		<meeting>in NLDB</meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="440" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,317.93,337.64,7.86;8,151.52,328.89,329.07,7.86;8,151.52,339.85,282.57,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,392.83,317.93,87.76,7.86;8,151.52,328.89,329.07,7.86;8,151.52,339.85,29.42,7.86">Sasi: sumarizador automático de documentos baseado no problema do subconjunto independente de vértices</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Linhares Pontes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Linhares</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Torres-Moreno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,201.77,339.85,203.66,7.86">XLVI Simpósio Brasileiro de Pesquisa Operacional</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,350.81,337.64,7.86;8,151.52,361.77,329.07,7.86;8,151.52,372.72,124.47,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,288.16,350.81,192.43,7.86;8,151.52,361.77,54.14,7.86">Graph-Based Multi-Tweet Summarization using Social Signals</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,227.35,361.77,253.25,7.86;8,151.52,372.72,30.96,7.86">International Conference on Computational Linguistics (COL-ING&apos;12)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1699" to="1714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,383.68,337.64,7.86;8,151.52,394.64,286.50,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,245.52,383.68,235.08,7.86;8,151.52,394.64,81.72,7.86">Automatically Assessing Machine Summary Content Without a Gold Standard</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,240.69,394.64,106.72,7.86">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="267" to="300" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,405.60,337.64,7.86;8,151.52,416.56,329.07,7.86;8,151.52,427.52,25.60,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,395.73,405.60,84.86,7.86;8,151.52,416.56,223.06,7.86">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,395.86,416.56,24.19,7.86">NIPS</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,438.48,337.97,7.86;8,151.52,449.44,329.07,7.86;8,151.52,460.40,329.07,7.86;8,151.52,471.35,25.60,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,408.07,438.48,72.52,7.86;8,151.52,449.44,184.11,7.86">Multilingual summarization evaluation without human models</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Saggion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Torres-Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Da Cunha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,358.54,449.44,122.05,7.86;8,151.52,460.40,175.96,7.86">23rd International Conference on Computational Linguistics (COLING&apos;10)</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1059" to="1067" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,482.31,337.97,7.86;8,151.52,493.27,329.07,7.86;8,151.52,504.23,99.31,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,414.36,482.31,66.23,7.86;8,151.52,493.27,176.35,7.86">Overview of the INEX 2012 Tweet Contextualization Track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Moriceau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mothe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,351.54,493.27,129.05,7.86;8,151.52,504.23,65.77,7.86">CLEF (Online Working Notes/ Labs/ Workshop</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,515.19,337.98,7.86;8,151.52,526.15,107.45,7.86" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="8,244.05,515.19,141.12,7.86">Artex is another text summarizer</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Torres-Moreno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>CoRR)</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Computing Research Repository</note>
</biblStruct>

<biblStruct coords="8,142.62,537.11,337.98,7.86" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="8,240.06,537.11,126.28,7.86">Automatic Text Summarization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Torres-Moreno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,548.07,337.97,7.86;8,151.52,559.03,329.07,7.86;8,151.52,569.98,228.45,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,396.22,548.07,84.37,7.86;8,151.52,559.03,117.82,7.86">Summary Evaluation With and Without References</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Torres-Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Saggion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Da Cunha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,275.86,559.03,204.73,7.86;8,151.52,569.98,158.81,7.86">Polibits: Research journal on Computer science and computer engineering with applications</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="13" to="19" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
