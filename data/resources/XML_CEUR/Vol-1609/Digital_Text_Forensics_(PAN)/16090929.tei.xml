<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,155.84,116.95,303.68,12.62;1,275.64,134.89,64.07,12.62">Derivative Approach for Plagiarism Source Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,269.28,172.56,76.80,8.74"><forename type="first">Rhulani</forename><surname>Maluleka</surname></persName>
							<email>rhumaluleka@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Peoples&apos; Friendship University of Russia</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,155.84,116.95,303.68,12.62;1,275.64,134.89,64.07,12.62">Derivative Approach for Plagiarism Source Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">718E32C0BD8CCCBA36C3E2CABB6C1573</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our approach to the PAN shared task of plagiarism source retrieval based on the strategy suggested by Williams et. al <ref type="bibr" coords="1,186.68,257.44,9.88,7.86" target="#b0">[1]</ref>. We also incorporate named entities queries similar to those of Elizalde <ref type="bibr" coords="1,197.58,268.40,9.88,7.86" target="#b1">[2]</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Algorithm</head><p>We attempt to improve on the current approaches to the source retrieval task. Based on the results of the 2015 competition <ref type="bibr" coords="1,346.17,328.94,10.52,8.74" target="#b2">[3]</ref> we chose to implement an algorithm that combines the approaches of Williams et. al <ref type="bibr" coords="1,395.20,340.89,10.52,8.74" target="#b0">[1]</ref> and Elizalde <ref type="bibr" coords="1,467.31,340.89,9.96,8.74" target="#b1">[2]</ref>. Williams' software was the best performing detector in the source retrieval task in 2013 and 2014. Even though they did not submit a new version in 2015, thier approach still went unmatched by the 2015 participants. We chose to work from their 2013 approach as the added complexity of their supervised result ranking strategy in 2014 achieved virtually the same results as its predicessor. Elizalde makes use of a novel idea of extracting named entities across each document in an attempt to detect highly obfuscated plagiarism.</p><p>Our approach consists of several stages, namely: chunking, key-phrase extraction, query formulation, and download filtering.</p><p>Chunking: We begin by segmenting the text of the suspicious document into paragraphs of 5 sentences each. We preprocess each paragraph, removing all non-alphabetic characters.</p><p>Keyphrase Extraction and Query Formulation: In forming keyphrases two distinct methods were employed. The first attempt to find the most important features of the entire document, while the other forms queries based on individual chunks.</p><p>Named entity queries: The Natural Language Toolkit (NLTK)<ref type="foot" coords="1,406.66,567.12,3.97,6.12" target="#foot_0">1</ref> is used to identify Named Entities over the whole text. These are then ranked in descending order of length. The 10 longest named entities are submitted as-is as queries to the search engine. As noted by Elizalde <ref type="bibr" coords="1,324.86,604.56,9.96,8.74" target="#b1">[2]</ref>, the rationale behind is that the named entities are unlikely to change even if paraphrasing has been used to obfuscate plagiarism. Additionally, the longer named entities are likely to contain more specific information, and thus be more likely to yield true positive results.</p><p>Chunk based queries: Each sentence in each paragraph is tokenized using NLTK's Punkt Sentence Tokenizer and the NLTK pre-trained part-of-speech tagger is used to tag all the tokens. All stopwords remove, and only verbs, nouns, and adjectives are retained. The WordNet lemmatizer is used to stem word. Stemming is done last as it may affect the identification of named entities. Queries are formed by concatenating sequences of tokens to form disjunct sequential 10-grams. The first three 10-grams from each paragraph are submitted to the ChatNoir search engine. The top three results are returned for each queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Download Filtering:</head><p>The ChatNoir search engine <ref type="bibr" coords="2,360.19,227.58,10.52,8.74" target="#b3">[4]</ref> allows one to request a snippet, of up to five hundred characters, of a specific document. The snippet is based around a query that is submitted along with the request. We use the original query that returned the result is used for requesting snippets; and request snippets of the maximum length. Documents are only downloaded if they are deemed similar to the suspicious document, based on their snippet. The similarity between the snippet of each document and the suspicious document is calculated based on an method suggested by Broder et. al [5] using word ngrams, also known as shingles. The 5-shingles, overlapping sequences of 5 tokens, are extracted from the document and each downloaded snippet. The similarity between a snippet s and a suspicious document d is then calculated as:</p><formula xml:id="formula_0" coords="2,255.69,369.03,103.97,8.74">Sim(s, d) = S(s) ∩ S(d)</formula><p>where S is a set of shingles. The results are then ranked by the similarity measure of their snippet.</p><p>The figure (see Algorithm 1) shows the algorithm for our source retrieval approach. The implementation of our algorithm is publicly available through PAN's online code repository. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,263.75,437.18,3.97,6.12"><head></head><label></label><figDesc>2 5. Broder, A. Z., Glassman, S. C., Manasse, M. S. &amp; Zweig, G. Syntactic clustering of the web. Computer Networks and ISDN Systems 29, 1157-1166 (1997).</figDesc><table coords="3,134.77,188.71,221.12,317.51"><row><cell cols="2">Algorithm 1 Source Retrieval Approach</cell></row><row><cell cols="2">1: procedure SourceRet(text)</cell></row><row><cell>2:</cell><cell>NEs ← getNamedEntities(text)</cell></row><row><cell>3:</cell><cell>for all result in NEs do</cell></row><row><cell>4:</cell><cell>snippet ← getSnippet(result)</cell></row><row><cell>5:</cell><cell>if similarity(snippet) ≥ min Sim then</cell></row><row><cell>6:</cell><cell>if (result ∈ sources) = False then</cell></row><row><cell>7:</cell><cell>sources ← Download(result)</cell></row><row><cell>8:</cell><cell>end if</cell></row><row><cell>9:</cell><cell>end if</cell></row><row><cell>10:</cell><cell>end for</cell></row><row><cell>11:</cell><cell>paragraphs ← splitText(text)</cell></row><row><cell>12:</cell><cell>for all p in paragraphs do</cell></row><row><cell>13:</cell><cell>p ← preprocess(p)</cell></row><row><cell>14:</cell><cell>queries ← extractTopQueries(p)</cell></row><row><cell>15:</cell><cell>for all q ∈ queries do</cell></row><row><cell>16:</cell><cell>results ← submitQueries(q)</cell></row><row><cell>17:</cell><cell>end for</cell></row><row><cell>18:</cell><cell>results ← rankResults(results)</cell></row><row><cell>19:</cell><cell>for all result in results do</cell></row><row><cell>20:</cell><cell>snippet ← getSnippet(result)</cell></row><row><cell>21:</cell><cell>if similarity(snippet) ≥ min Sim then</cell></row><row><cell>22:</cell><cell>if (result ∈ sources) = False then</cell></row><row><cell>23:</cell><cell>sources ← Download(result)</cell></row><row><cell>24:</cell><cell>end if</cell></row><row><cell>25:</cell><cell>end if</cell></row><row><cell>26:</cell><cell>end for</cell></row><row><cell>27:</cell><cell>end for</cell></row><row><cell cols="2">28: end procedure</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,657.79,128.78,7.86"><p>nltk 3.2.1 http://www.nltk.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,657.79,183.40,7.86"><p>https://github.com/pan-webis-de/maluleka16</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="2,138.64,494.53,341.95,8.74;2,152.48,506.48,328.11,8.74;2,152.48,518.44,30.44,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="2,422.06,494.53,58.53,8.74;2,152.48,506.48,174.81,8.74">Unsupervised Ranking for Plagiarism Source Retrieval</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H.-H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="2,334.93,506.48,121.62,8.74">Notebook for PAN at CLEF</title>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="2,138.64,530.39,341.95,8.74;2,152.48,542.35,243.01,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="2,208.96,530.39,271.63,8.74;2,152.48,542.35,26.64,8.74">Using statistic and semantic analysis to detect plagiarism in CLEF</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Elizalde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="2,187.41,542.35,168.88,8.74">Online Working Notes/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="2,138.64,554.31,341.95,8.74;2,152.48,566.26,328.11,8.74;2,152.48,578.22,139.87,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="2,313.91,554.31,166.68,8.74;2,152.48,566.26,220.68,8.74">Source Retrieval for Plagiarism Detection from Large Web Corpora: Recent Approaches</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="2,381.78,566.26,98.81,8.74;2,152.48,578.22,52.02,8.74">Working Notes Papers of the CLEF</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1613" to="0073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="2,138.64,590.17,341.95,8.74;2,152.48,602.13,328.12,8.74;2,152.48,614.08,328.11,8.74;2,152.48,626.04,328.11,8.74;2,152.48,637.99,179.69,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="2,281.47,602.13,199.12,8.74;2,152.48,614.08,31.71,8.74">A Search Engine for the ClueWeb09 Corpus in 35</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Graßegger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Welsch</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Chatnoir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="2,165.60,614.08,314.99,8.74;2,152.48,626.04,147.98,8.74">th International ACM Conference on Research and Development in Information Retrieval (SIGIR 12)</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Hersh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Callan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Maarek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-08">Aug. 2012</date>
			<biblScope unit="page">1004</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
