<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,127.58,152.67,339.81,12.64;1,198.29,170.67,198.69,12.64">Author obfuscation using WordNet and language models Notebook for PAN at CLEF 2016</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,125.18,210.18,104.25,8.96"><forename type="first">Muharram</forename><surname>Mansoorizadeh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer engineering</orgName>
								<orgName type="institution">Bu-Ali Sina University</orgName>
								<address>
									<settlement>Hamedan</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,236.55,210.18,59.49,8.96"><forename type="first">Taher</forename><surname>Rahgooy</surname></persName>
							<email>taher.rahgooy@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer engineering</orgName>
								<orgName type="institution">Bu-Ali Sina University</orgName>
								<address>
									<settlement>Hamedan</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,303.43,210.18,88.51,8.96"><forename type="first">Mohammad</forename><surname>Aminiyan</surname></persName>
							<email>m.aminiyan@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer engineering</orgName>
								<orgName type="institution">Bu-Ali Sina University</orgName>
								<address>
									<settlement>Hamedan</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,399.19,210.18,70.85,8.96"><forename type="first">Mahdy</forename><surname>Eskandari</surname></persName>
							<email>me16eskandari@hotmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer engineering</orgName>
								<orgName type="institution">Bu-Ali Sina University</orgName>
								<address>
									<settlement>Hamedan</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,127.58,152.67,339.81,12.64;1,198.29,170.67,198.69,12.64">Author obfuscation using WordNet and language models Notebook for PAN at CLEF 2016</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6FF01F1127D72743B9122C7173D0272D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>author obfuscation</term>
					<term>Brown corpus</term>
					<term>WordNet</term>
					<term>language model</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As almost all the successful author identification approaches are based on the word frequencies, the most obvious way to obfuscate a text is to distort those frequencies. In this paper we chose a subset of the most frequent words for an author and replace each one with one of their synonyms. In order to select the best synonym, we considered two measures: similarity of the original word and the synonym, the difference between the scores (probabilities) that are assigned to the original and distorted sentences by a language model. By using similarity, we aim to select words that are similar to the original word semantically, and by using a language model we try to favor word usages that are common.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The author masking task of PAN 2016 is to paraphrase a given document so that its writing style does not match that of its original author, anymore. The problem consist of a set of documents written by a specific author and another document of the same author named "original". The challenge is to use the information in the provided set of documents in order to obfuscate the "original" document. In order to response the challenge we use a five-stage iterative method which is described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed approach</head><p>In the following we describe the steps we took in order to generate an obfuscated text from the original one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Author word usage distribution</head><p>In the first stage, we used word frequencies of the training text for the author to estimate the word usage probability distribution by that author. For this purpose a maximum likelihood estimate of the word frequencies obtained using NLTK 3.0 toolkit <ref type="bibr" coords="1,439.71,658.34,10.66,8.96" target="#b0">[1]</ref>. We use this distribution to emphasis on words that used frequently by the author. We used top 200 most frequent words for this purpose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language Model</head><p>The understanding of natural languages is very complex. Words essentially combine in a non-random order but in some complex order. It is intuitively believed that the, language models can be learnt from the word and its neighboring words. Most language modeling tools use N-grams features to learn the probability for sequence of words (e.g. a sentence). We trained a 4-gram language model on Brown corpus <ref type="bibr" coords="2,409.87,218.22,11.69,8.96" target="#b1">[2]</ref> by KenLM toolkit <ref type="bibr" coords="2,153.82,230.22,11.69,8.96" target="#b2">[3]</ref> with default settings. KenLM uses modified Kneser-Ney smoothing <ref type="bibr" coords="2,447.83,230.22,11.83,8.96" target="#b3">[4]</ref> to adjust zero probabilities for non-presented words in the training data. We use this language model to score sentences generated by the obfuscation phase. Let S = (w1,w2,â€¦wk,â€¦, wn-1,wn) be a sentence where wk is a word that selected for replacement. Assume there is {v1, v2, â€¦, vm} candidates for replacement. So, in the second stage, we replace wk with each candidate and score them using the score of generated sentence ğ‘  ğ‘£ ğ‘˜ in the language model:</p><formula xml:id="formula_0" coords="2,124.70,321.40,346.00,14.31">ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ ğ¿ğ‘€ (ğ‘ , ğ‘£ ğ‘˜ ) = ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ ğ¿ğ‘€ (ğ‘  ğ‘£ ğ‘˜ ) = âˆ‘ ğ‘™ğ‘œğ‘”(ğ‘ƒ(ğ‘¤ ğ‘– |ğ‘¤ ğ‘–-1 ğ‘¤ ğ‘–-2 ğ‘¤ ğ‘–-3 )) ğ‘› ğ‘–=4<label>(1)</label></formula><p>By this approach we select words that are common in the corresponding context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Synonym generation</head><p>In the third stage, for each selected word we generate a subset of word synonyms from WordNet <ref type="bibr" coords="2,164.26,419.61,11.69,8.96" target="#b4">[5]</ref> using NLTK toolkit. Then we scored similarity of each synonym with the original word by Wu and Palmer similarity score <ref type="bibr" coords="2,328.32,431.63,10.83,8.96" target="#b5">[6]</ref>, which is a score denoting how similar two word senses are, based on the depth of the two senses in the taxonomy and that of their most specific ancestor node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Post processing</head><p>The WordNet synonyms are lemmas of the words, so we need to find the suitable form of the generated words. Hence, in the fourth stage, we used the POS tag of the original word to find the proper form of the synonyms. The Pattern package from CLiPS toolkit <ref type="bibr" coords="2,124.70,541.55,11.72,8.96" target="#b6">[7]</ref> used to make this adjustment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Word replacement</head><p>The state of the art authorship verification algorithms use word frequencies of the training set to determine if the "original" document is written by the corresponding author. Therefore we try to change the word frequencies of the "original" document in a way that they do not match with the training frequencies. The words that only used in the "original" document, but not in the training document, have no effect on the result of authorship verification, so we did not consider them for replacement.</p><p>So in the final stage, for each problem we concatenated all train documents and treated them as a single document. We obtained the word usage distribution of training document. Then iteratively a sentence from the "original" document selected for obfuscation. Firstly we tokenized the sentence and then part-of-speech tags of the sentence obtained using NLTK 3.0 toolkit. Then we generated a set of synonyms for each word that used at least once by the author in the training document, using aforementioned method. A subset of synonyms which were have high similarity scores to the original word is selected. From these candidates the word that has better language model score is selected. The final score for each word replacement in the sentence is:</p><formula xml:id="formula_1" coords="3,124.70,265.78,346.00,12.68">ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘ , ğ‘£, ğ‘˜) = ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ ğ¿ğ‘€ (ğ‘  ğ‘£ ğ‘˜ ) * ğ‘ƒ(ğ‘ [ğ‘˜])<label>(2)</label></formula><p>Where s is the original sentence, ğ‘  ğ‘£ ğ‘˜ is the original sentence that we replace its k-th word with v, and P(s[k]) is the probability of using k-th word of the sentence by the author.</p><p>Based on this score we select best replacement. The ties are broken by order of the words in the sentence (the first one is selected). For each sentence we made at most one replacement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>In order to evaluate our work, the software run on TIRA platform <ref type="bibr" coords="3,384.41,418.53,11.69,8.96" target="#b7">[8]</ref> then a peer review has been performed on the results based on three different evaluation measures including safety, soundness and sensibility <ref type="bibr" coords="3,272.93,442.55,10.69,8.96" target="#b8">[9]</ref>.</p><p>We call an obfuscation software ï‚· Safe, if a forensic analysis does not reveal the original author of its obfuscated texts, ï‚· Sound, if its obfuscated texts are textually entailed with their originals, and ï‚· Sensible, if its obfuscated texts are inconspicuous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Safety</head><p>To compare proposed algorithms effect on the state of the art author verification methods, we trained GLAD <ref type="bibr" coords="3,220.10,561.23,16.91,8.96" target="#b9">[10]</ref> tool on PAN2014 author verification dataset (The essays part). Then we run the trained model on results of each participant. Additionally we obtained the result for the original PAN 2016 author masking dataset. The GLAD accuracy on original dataset was 55.61 percent. Table <ref type="table" coords="3,337.02,597.26,4.98,8.96" target="#tab_0">1</ref> shows results obtained on each participant output. Where masking performance is the ratio of instances that classified incorrectly by the authorship verification algorithm and accuracy is the ratio of instances that classified correctly by the algorithm.</p><p>Results show that all approaches decrease the accuracy of the authorship verification algorithms, but not as much as expected. The B approach outperforms other two approaches while C approach almost have no effect on the accuracy.</p><p>To have a better understanding of the results we obtained four type of output for each approach:</p><p>ï‚· Positive-Masked: instances that classified correctly by GLAD and masked ï‚· Positive-Unmasked: instances that classified correctly by GLAD but unmasked ï‚· Negative-Masked: instances that classified incorrectly by GLAD and masked ï‚· Negative-Unmasked: instances that classified incorrectly by GLAD and unmasked</p><p>The "Negative-Unmasked" type is interesting, because this type of error means that the obfuscation results actually help the authorship verification algorithm to classify that instance correctly. On the positive instances, the participants A and C performed identically, while participant B performs a lot better than the other tw. In other hand, participants A and B worked the same on negative instances where the participant C performs worse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Soundness</head><p>Second measure which is evaluated by our human expert (in this case our team of authors) is soundness. For soundness, we take a representative random sample of text fragments and evaluate whether they are paraphrases of the original text. We choose a random number of problems and give them a score between 0-5. Score 5 refers to the method which is paraphrases the original text most accurately and the score 0 refer to the worst paraphrase. Soundness results in table <ref type="table" coords="5,231.14,174.18,4.98,8.96" target="#tab_2">3</ref> illustrates that, our proposed method (participant A) has a much better performance (the score equal to 4.86 in average) compared to the other participants, where the second place belong to participant C which has the score 3.93. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sensibility</head><p>The last evaluation measure is sensibility which is also measured by human expert (same as soundness). For sensibility, we take a representative random sample of text fragments and evaluate whether and how obvious it is that the text has been obfuscated. We choose random number of problems and give theme score between 0-5. Score 0 refer to method which generate the most obvious obfuscated text and the score 5 refer to the best result. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>Using the approach described above, we follow two major ideas: first, a document obfuscation should not made in a way that any human or non-human reader can easily figure out the changes and second, the method should remove high frequent words and phrases which is used by the author. In case of PAN 2016 task, based on given problem, we proposed simple but efficient method in order to change a document in a way that machine learning techniques cannot simply recognize the original author. Also, we thought smart and few exchanges in the document's words would not deform the document in form machine produced text do, so the human reviewer could be confused with original text. We changed at most one word from each sentence, this parameter can be tuned using parameter selection methods in order to reach to a good balance between text obfuscation and the amount of distortion in the text.</p><p>The evaluation results shows that while our approach have a competitive result for safety, it makes very small changes in the original text, which means it keeps the quality of the original text way better than other approaches. Thus it performs very better than the other two approaches from soundness and sensibility perspective.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,163.82,149.99,279.13,77.52"><head>Table 1 .</head><label>1</label><figDesc>Results obtained on each participant output.</figDesc><table coords="4,163.82,167.70,279.13,59.81"><row><cell>Accuracy</cell><cell></cell><cell>Masking Performance</cell></row><row><cell>Participant A</cell><cell>50.24</cell><cell>49.76</cell></row><row><cell>Participant B</cell><cell>39.51</cell><cell>60.49</cell></row><row><cell>Participant C</cell><cell>55.12</cell><cell>44.88</cell></row><row><cell>Original Data</cell><cell>55.61</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,171.14,463.72,270.57,85.68"><head>Table 2 .</head><label>2</label><figDesc>Fout types of results obtained on each participant output.</figDesc><table coords="4,171.14,480.64,270.57,68.76"><row><cell></cell><cell>Positive-</cell><cell>Positive-</cell><cell>Negative-</cell><cell>Negative-</cell></row><row><cell></cell><cell>masked</cell><cell>unmasked</cell><cell>masked</cell><cell>unmasked</cell></row><row><cell>Participant A</cell><cell>42</cell><cell>72</cell><cell>60</cell><cell>31</cell></row><row><cell>Participant B</cell><cell>64</cell><cell>50</cell><cell>60</cell><cell>31</cell></row><row><cell>Participant C</cell><cell>42</cell><cell>72</cell><cell>50</cell><cell>41</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,189.53,234.18,218.45,427.60"><head>Table 3 .</head><label>3</label><figDesc>Results of soundness evaluation</figDesc><table coords="5,189.53,258.69,218.45,403.09"><row><cell>problem number</cell><cell>A</cell><cell>B</cell><cell>C</cell></row><row><cell>7</cell><cell>5</cell><cell>2</cell><cell>3.5</cell></row><row><cell>9</cell><cell>5</cell><cell>2</cell><cell>3.5</cell></row><row><cell>18</cell><cell>5</cell><cell></cell><cell>4</cell></row><row><cell>25</cell><cell>5</cell><cell>1.5</cell><cell>5</cell></row><row><cell>35</cell><cell>4.5</cell><cell>1</cell><cell>4</cell></row><row><cell>42</cell><cell>3.5</cell><cell>3</cell><cell>3.5</cell></row><row><cell>58</cell><cell>4</cell><cell>2</cell><cell>4.5</cell></row><row><cell>60</cell><cell>5</cell><cell>3</cell><cell>4</cell></row><row><cell>63</cell><cell>4</cell><cell>2</cell><cell>4</cell></row><row><cell>70</cell><cell>5</cell><cell>4</cell><cell>4</cell></row><row><cell>81</cell><cell>5</cell><cell>2</cell><cell>4</cell></row><row><cell>89</cell><cell>5</cell><cell>1</cell><cell>4</cell></row><row><cell>90</cell><cell>5</cell><cell>2</cell><cell>4</cell></row><row><cell>105</cell><cell>5</cell><cell>3</cell><cell>4</cell></row><row><cell>106</cell><cell>5</cell><cell>1</cell><cell>5</cell></row><row><cell>108</cell><cell>5</cell><cell>2</cell><cell>4</cell></row><row><cell>109</cell><cell>5</cell><cell>3</cell><cell>3</cell></row><row><cell>113</cell><cell>5</cell><cell>3</cell><cell>4</cell></row><row><cell>116</cell><cell>5</cell><cell>3</cell><cell>2</cell></row><row><cell>128</cell><cell>5</cell><cell>2</cell><cell>3</cell></row><row><cell>141</cell><cell>5</cell><cell>1</cell><cell>5</cell></row><row><cell>144</cell><cell>5</cell><cell>1</cell><cell>3</cell></row><row><cell>152</cell><cell>5</cell><cell>1</cell><cell>3</cell></row><row><cell>157</cell><cell>5</cell><cell>2</cell><cell>3</cell></row><row><cell>167</cell><cell>5</cell><cell>2</cell><cell>5</cell></row><row><cell>173</cell><cell>5</cell><cell>1</cell><cell>5</cell></row><row><cell>182</cell><cell>5</cell><cell>4</cell><cell>4</cell></row><row><cell>193</cell><cell>5</cell><cell>2</cell><cell>4</cell></row><row><cell>201</cell><cell>5</cell><cell>2</cell><cell>4</cell></row><row><cell>203</cell><cell>5</cell><cell>3</cell><cell>5</cell></row><row><cell>Average</cell><cell>4.86</cell><cell>2.08</cell><cell>3.93</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,193.37,266.06,203.56,420.77"><head>Table 4 .</head><label>4</label><figDesc>Results of properness evaluationSensibility results in table 5 demonstrates that, our proposed method outperforms the other works (the score equal to 4.86 in average), where the second place belong to participants C which has the score 3.7 in average. It means our method generates phrases which are more similar to human generated texts. Note that you can find the complete evaluation in the task overview paper<ref type="bibr" coords="7,422.74,210.18,10.66,8.96" target="#b8">[9]</ref>.</figDesc><table coords="6,193.37,282.98,199.97,9.96"><row><cell>problem number</cell><cell>A</cell><cell>B</cell><cell>C</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,132.67,517.75,337.85,8.19;7,141.74,528.88,47.20,8.10" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="7,283.25,517.75,145.80,8.18">Natural language processing with Python</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>O&apos;Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,132.67,539.92,337.91,8.10;7,141.74,550.75,100.50,8.19" xml:id="b1">
	<monogr>
		<title level="m" coord="7,141.74,539.92,328.84,8.10">A Standard Corpus of Present-Day Edited American English, for use with Digital Computers</title>
		<imprint>
			<publisher>Brown</publisher>
			<date type="published" when="1964">1964. 1971. 1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,132.67,572.92,338.17,8.10;7,141.74,583.84,328.87,8.10;7,141.74,594.88,110.79,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,238.02,572.92,185.11,8.10">KenLM: Faster and smaller language model queries</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Heafield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,438.82,572.92,32.01,8.10;7,141.74,583.84,228.96,8.10">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011-07">2011, July</date>
			<biblScope unit="page" from="187" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,132.67,605.86,338.04,8.19;7,141.74,616.87,197.30,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,203.60,605.86,178.28,8.19">Modified kneser-ney smoothing of n-gram models</title>
		<author>
			<persName coords=""><forename type="first">Frankie</forename><surname>James</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,393.79,605.95,76.92,8.10;7,141.74,616.87,148.64,8.10">Research Institute for Advanced Computer Science, Tech. Rep</title>
		<imprint>
			<biblScope unit="volume">00</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,132.67,627.82,337.89,8.19;7,141.74,638.95,97.31,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,219.11,627.82,153.03,8.18">WordNet: a lexical database for English</title>
		<author>
			<persName coords=""><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,381.91,627.91,88.64,8.10;7,141.74,638.95,20.37,8.10">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,132.67,649.78,337.58,8.19;7,141.74,660.91,310.28,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,230.75,649.78,131.78,8.18">Verb semantics and lexical selection</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,381.96,649.78,88.29,8.18;7,141.74,660.91,238.33,8.10">Proceedings of the 32nd Annual meeting of the Associations for Computational Linguistics</title>
		<meeting>the 32nd Annual meeting of the Associations for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="133" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,132.67,671.95,337.78,8.10;7,141.74,682.87,144.00,8.10" xml:id="b6">
	<analytic>
		<ptr target="http://www.clips.ua.ac.be/pattern" />
	</analytic>
	<monogr>
		<title level="m" coord="7,141.74,671.95,50.76,8.10">CLiPS Pattern</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,149.99,337.56,8.10;8,141.74,160.94,328.69,8.19;8,141.74,172.07,328.45,8.10;8,141.74,182.99,328.58,8.10;8,141.74,194.03,328.94,8.10;8,141.74,205.07,202.58,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,403.80,149.99,66.42,8.10;8,141.74,160.94,328.69,8.19;8,141.74,172.07,48.09,8.10">Improving the Reproducibility of PAN&apos;s Shared Tasks: Plagiarism Detection, Author Identification, and Author Profiling</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,215.83,182.99,254.49,8.10;8,141.74,194.03,291.82,8.10">Information Access Evaluation meets Multilinguality, Multimodality, and Visualization. 5th International Conference of the CLEF Initiative (CLEF 14)</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Lupu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hall</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Toms</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014-09">Sep 2014</date>
			<biblScope unit="page" from="268" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,215.99,338.05,8.10;8,141.74,227.03,328.86,8.10;8,141.74,238.07,250.76,8.10" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,268.19,215.99,202.53,8.10;8,141.74,227.03,103.09,8.10">Author Obfuscation: Attacking State-of-the-Art Authorship Verification Approaches</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,262.49,227.03,204.17,8.10">Working Notes Papers of the CLEF 2016 Evaluation Labs</title>
		<title level="s" coord="8,141.74,238.07,173.92,8.10">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<imprint>
			<date type="published" when="2016-09">Sep 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.32,248.99,338.06,8.10;8,141.74,260.06,136.76,8.10" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,246.05,248.99,191.32,8.10">GLAD: Groningen Lightweight Authorship Detection</title>
		<author>
			<persName coords=""><forename type="first">Manuela</forename><surname>HÃ¼rlimann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,446.99,248.99,23.39,8.10;8,141.74,260.06,108.23,8.10">Working Notes Papers of the CLEF</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
