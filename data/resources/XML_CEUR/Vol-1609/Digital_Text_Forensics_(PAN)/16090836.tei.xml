<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,190.49,115.90,281.89,12.90;1,197.57,133.83,220.23,12.90;1,223.43,153.69,168.50,10.75">Profiling using Complementary Second Order Attributes and Stylometric Features Notebook for PAN at CLEF 2016</title>
				<funder>
					<orgName type="full">REVEAL</orgName>
				</funder>
				<funder ref="#_stfcPMh">
					<orgName type="full">European Union</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,209.06,190.09,103.44,8.64"><forename type="first">Konstantinos</forename><surname>Bougiatiotis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Informatics</orgName>
								<orgName type="department" key="dep2">Telecommunications National Center for Scientific Research (NCSR</orgName>
								<orgName type="institution">) &quot;Demokritos&quot;</orgName>
								<address>
									<settlement>Athens</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,331.87,190.09,74.42,8.64"><forename type="first">Anastasia</forename><surname>Krithara</surname></persName>
							<email>akrithara@iit.demokritos.gr</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Informatics</orgName>
								<orgName type="department" key="dep2">Telecommunications National Center for Scientific Research (NCSR</orgName>
								<orgName type="institution">) &quot;Demokritos&quot;</orgName>
								<address>
									<settlement>Athens</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,190.49,115.90,281.89,12.90;1,197.57,133.83,220.23,12.90;1,223.43,153.69,168.50,10.75">Profiling using Complementary Second Order Attributes and Stylometric Features Notebook for PAN at CLEF 2016</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">464E259D1E959847E125F1F604BA7F8B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we present an approach for the task of author profiling. We propose a modular framework, extracting two main group of features, combined with appropriate preprocessing, implementing Support Vector Machines for classification. The two main groups we used were stylometric and discriminative, featuring trigrams on one hand and complementary-weighted Second Order Attributes on the other. We address the problem as a profile based problem creating target profiles and also grouping each user's tweets in the same document.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>PAN, held as part of the CLEF conference is an evaluation lab on uncovering plagiarism, authorship, and social software misuse. In 2016, PAN featured 3 tasks, author obfuscation, author identification and author profiling.</p><p>The 2016 Author Profiling task challenged participants to predict gender and age in 3 languages (English, Spanish and Dutch). It featured quite a few novelties compared to previous years. The first one is a big spurt in the size of the training dataset. Comparing to the 2014 task, where there were 152 user-profiles, this year the dataset comprises of 436 users, that is three times bigger. Moreover, we have an added class in the age estimation task, that of '65-XX', increasing the difficulty of the task. Finally, this year's task is focused on cross-genre identification. This means that the training documents were created from one genre (specifically Twitter) and the evaluation will be on other genres such blogs, social media etc.</p><p>In this paper we present an approach for tackling the author profiling task. In the next section the different steps of our approach are presented in details, while in section 3 the evaluation of the method is discussed. In the final section, we draw conclusions and point out possible future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed Method</head><p>In order to tackle the author profiling task we propose a semantically meaningful grouping of the features. We wanted to create a modular, extensible and parameterizable framework for testing different preprocessing, feature and classifier combinations.</p><p>An overview of the methodology can be seen in Figure <ref type="figure" coords="2,372.94,119.31,3.74,8.64" target="#fig_0">1</ref>. The main steps involved in the architecture of the system are outlined as follows:</p><p>1. Preprocessing: Parsing, preprocessing and vectorization of the tweet, leading in a bag of words representation for each document-tweet. 2. Feature Extraction: Extracting discriminative and stylometry features from the processed text. 3. Classification: Train a Support Vector Machine classifier to distinguish between different age groups and genders using the extracted features from the collection These steps are explained in details in the following subsections. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preprocessing</head><p>We start by applying a set of preprocessing procedures on the texts in our collection.</p><p>In text mining, it is often assumed that words appear independently in a document and their order of occurrence is immaterial for the purposes of any information retrieval task at hand. Ultimately, this assumption leads to the bag of words representation of the document, according to which each document is represented as a multi-dimensional vector. This vector is populated with the counts of the different word appearances in each document, where each cell corresponds to a different word. The vector space is created by assigning a new dimension to each unique word in the document collection, that forms the vocabulary of the collection. Still, before acquiring this representation of the tweets, the text must be cleared of Twitter specific information such as @replies, hashtags and URLs. In order to do so, all tweets are pipelined through a series of filters which remove any HTML found, URLs, numbers and unwanted punctuation marks. Moreover, the hashtags are stripped of their hashtag character #, leaving only the corresponding tag.</p><p>Afterwards, the texts are tokenized, splitted into words, and case folded, all letters reduced to lowercase. Thus, the resulting form of each tweet is a list of lowercase words, contained in the original tweet, after preprocessing. We also experimented with lemmatization and stemming of the words <ref type="bibr" coords="3,277.59,286.69,10.58,8.64" target="#b2">[3]</ref>, in order to decrease the term space by unifying variations of the same word, but to no avail with regards to improvement in results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Feature Extraction</head><p>We focus on two different set of features, stylometric and discriminative. The stylometric set of features models the individual linguistic style of the users, that is existent in their corresponding written texts. These are ways of expressing oneself that can be mapped to user specific attributes such as age or gender. Features tested, as suggested by our previous work <ref type="bibr" coords="3,226.21,393.42,10.58,8.64" target="#b0">[1]</ref>, were tf-idf of n-grams, bag of n-grams, bag of words and tf-idf of words.</p><p>The selected stylometric features are the frequencies of trigrams found in the tweets. Specifically for the age prediction task, we are interested only in the top 3000 most frequent trigrams found in the whole collection, while for the gender prediction the stylometric features didn't improve the results so they are not used.</p><p>Let it be noted here that structural features like counts of hashtags, URLs and other text characteristics, were also tested, but didn't enhance the outcomes and were abandoned.</p><p>The idea for the discriminative set of features is based upon the Second Order Attributes (SOA) <ref type="bibr" coords="3,196.05,512.97,10.58,8.64" target="#b3">[4]</ref>. The main concept is, at first, to associate the different words found in our collection with the different profiles, driven by the sense that many words are distinct per target profile. For the gender task, an example is that men talk more about "games" and women more frequently about "shopping", while for the age task, "pension" and "marriage" should be terms related more to middle-age groups rather than younger ones. This is clearly depicted in Figure <ref type="figure" coords="3,287.34,584.71,3.74,8.64">2</ref>, where we can see terms like "dreamjob" that clearly denote a younger user, while others like "lol" that may denote a young agegroup but are not fully indicative of the age group. There also exist many discriminative terms regarding the gender subtask as shown in Figure <ref type="figure" coords="3,354.29,620.57,3.74,8.64">3</ref>.</p><p>After, having mapped the relations between each term and the target profiles for the task, we move on to create the document projections in the profile space. That is, we aim to create a vector for each document, where each cell would encompass the Specifically, our approach introduces a few novelties in the way the final documents' profile relations are generated. First of all, we need to compute a value for each term in the vocabulary V = [t 1 , t 2 , ..., t V ], indicating how relevant it is with each target profile P = [p 1 , p 2 , ..., p P ]. Let also D = [d 1 , d 2 , ..., d N ] denote the collection of the documents-tweets. For computing the relation t i,j , of term i with the profile j, one would normally take into account the documents containing the term i and at the same time belong in profile j. However, fueled by other studies <ref type="bibr" coords="4,363.22,536.41,11.02,8.64" target="#b1">[2]</ref>, <ref type="bibr" coords="4,377.92,536.41,11.02,8.64">[7]</ref> and in order to counter any bias in our system due to skewed data (i.e. more training examples for one profile than another) we create each term-profile relation based on the complementary profiles in the collection. That is, instead of using training data from the profile j, we estimate the profile parameters using data from all profiles except j. This generates more robust estimates, because each one uses a more even amount of training data per profile, which lessens the bias.</p><p>Nonetheless, we would like to exploit the knowledge about the prior distribution of documents into profiles, that is P (p j ). To do so, we incorporate a weighting term in the estimation procedure that is inversely proportional to the probability of the profile. The core idea, is that the rarer a profile, the more influence should the terms related to this profile exhibit, in order to make up for the sparsity of the documents related with this profile. Finally, the term-profile estimate is:</p><formula xml:id="formula_0" coords="5,232.32,423.40,150.72,27.94">t i,j = k:d k / ∈Pj log(1 + tf i,k len(d k ) * w k )</formula><p>where tf i,k is the term frequency in document k, len(d k ) the document's length and w k the weighting parameter of the class the document belongs to. We also apply a two-way normalization on the term parameters:</p><p>-Firstly, for each specific term over all the profiles, in order to emphasize the difference between the profiles related to the term and those who are not:</p><formula xml:id="formula_1" coords="5,280.58,539.16,69.37,26.56">t i,j = t i,j P j=1 t i , j</formula><p>-Secondly, for each profile over all the terms in the collection, so as to model the parameters per profile according to the value of the other terms also:</p><formula xml:id="formula_2" coords="5,281.02,607.97,68.49,26.56">t i,j = t i,j V i=1 t i , j</formula><p>Before moving on, let us clarify that using the complementary profiles as training data for each term-profile estimate, we get the opposite result of the previous depicted examples. That is, the profile most related to a term should be the one with the minimum value in the vector t = [t i,1 , t i,2 , ..., t i,P ] . That also stands for the document-profile vector d k = [d i,1 , d i,2 , ..., d i,P ], that will be created afterwards.</p><p>After projecting terms in the space of profiles, we build relationships between documents and profiles; these are the second-order attributes. Those are generated as shown in Figure <ref type="figure" coords="6,174.92,181.21,3.74,8.64" target="#fig_2">4</ref>, taking into consideration for each document only the terms present in it. This results in the document-profile vector d k where each cell is a real value representing the relationship of the document d k with a profile p j . Lastly, while summing the term vectors, they are firstly weighted by the relative frequency of the term t i in the current document. That is:</p><formula xml:id="formula_3" coords="6,252.53,257.07,109.80,27.55">d k,j = i:ti∈d k tf i,k len(d k ) × t i</formula><p>After the feature extraction procedure, we concatenate the features in a new feature vector containing all the generated features, as shown in Table <ref type="table" coords="6,388.35,312.34,3.74,8.64" target="#tab_0">1</ref>, and forward them in the classifier. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Classification</head><p>We used machine learning tools from the scikit-learn library <ref type="bibr" coords="6,374.40,520.69,10.58,8.64" target="#b5">[5]</ref>. For the age and gender subtask we decided, after experimentation with different algorithms, to use a Support Vector Machine (SVM) with an RBF kernel and a SVM with a linear kernel respectively. Moreover, we specify that the weights of the SVM kernel should be "balanced" according to the frequency distribution of the samples in the different profiles. This leads to higher weights for the less populated classes, resulting in smaller regularization parameters for these classes and a higher incentive for the SVM to classify it properly. The best parameters for each SVM classifier were chosen through parameter grid search, using stratified 5-fold cross validation schemes.</p><p>We also tried feature scaling and normalization before training the classifier with the concatenated data, for the age subtask, but the corresponding results didn't advocate in favor of this step.</p><p>3 Experimental Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset and Evaluation</head><p>As already mentioned, the core of this year's task is cross-genre identification for three different languages.The dataset distributions for both tasks, showcased for the English language in absolute counts of profiles, are illustrated in Figure <ref type="figure" coords="7,389.06,202.46,3.74,8.64" target="#fig_3">5</ref>. In the context of PAN 2016, systems were evaluated using accuracy for both the gender and age classification tasks. An overview of the approaches and results for the author profiling task can be found in [6].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>The evaluation of our system on the two held-out test datasets are shown in Table <ref type="table" coords="7,473.11,487.52,3.74,8.64" target="#tab_1">2</ref>. The best results have been obtained for the English part of the second test set for both subtasks, as highlighted in the table. We can also see that our system is not performing well regarding the age subtask, especially on the Spanish data. Finally, we can see that the results vary greatly per language, e.g. for the Dutch dataset we are consistently subpar on the gender task comparing to the other languages. However, we would need the overall results in order to evaluate our system in comparison with others.</p><p>In order to have some kind of comparison, we also evaluated our newly proposed system over the training dataset using a 4-fold cross validation. We pitched our results against our last year's submission which was the 3rd best overall and the best one, on average over all languages, for the gender subtask. The results are showcased in Figure <ref type="figure" coords="7,164.06,620.57,3.74,8.64" target="#fig_4">6</ref>. It can be seen that generally the new system outperforms, even marginally, the previous one with the difference being more prominent in the age subtask. Even for the gender subtask, where our previous system excelled in PAN15, we have achieved better results, except for the Dutch dataset.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>Although we would need the overall results in order to put ours into perspective, we have gained some initial insights:</p><p>-The age subtask is much more difficult than the gender one, as showcased by all evaluations, where both systems consistently perform worse than the gender subtask. -Regarding the comparison scheme, the results of both systems for the age subtask are far from satisfying with only 50% accuracy. The difference with last year's performance, approximately 66%, may be explained through the nature of the current dataset, as the same methodology achieved only 46% accuracy this year. The volume of the data, the distribution over classes and more importantly the added difficulty of the cross-genre task play an importart role. -The consistently worse results on the subtasks for the first test dataset, may indicate a genre bias in our model. That is, the data of the 2 nd test dataset could be more similar to the train data, than those of the 1 st test dataset. This reconfirms the increased complexity of the task when dealing with data from different domains.</p><p>-Our system performed better on the English test cases and that is to be expected, as training was mostly done on the English data.Noticing the fluctuations in the accu-racy results per language maybe a more sophisticated system should have different implementations tailored to the needs of each different language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Future Work</head><p>These initial results spur us on towards new research work on the Author Profiling task.</p><p>In the context of our approach we will further evaluate the features used for the age classification subtask specifically. We will utilize the test datasets, when they will be publicly available, in order to find which features deteriorate the performance on the test data. Moreover, using those data we can find which features are important in crossdomain knowledge transfer regarding author profiling traits. Finally, another approach would be to create target profiles modeling both the age and the gender at the same time, e.g. "male"∧"18-24". This would lead to an increase of the joint accuracy of the two task classifiers and would result in projecting both subtasks in one profile-space of the same nature. That would alleviate the systematic errors imposed through the assumption that age is independent of gender, in terms of linguistic style of texts. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,231.78,560.48,151.80,8.12;2,169.35,262.28,276.66,283.47"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. General Workflow of the system</figDesc><graphic coords="2,169.35,262.28,276.66,283.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,250.66,243.95,114.03,8.12;4,134.77,264.98,345.83,113.38"><head>Figure 2 .Figure 3 .</head><label>23</label><figDesc>Figure 2. Age descriptive terms</figDesc><graphic coords="4,134.77,264.98,345.83,113.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,158.93,357.35,297.49,8.12;5,134.77,115.83,345.82,226.78"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Documents' representations resulting from the aggregation of their terms</figDesc><graphic coords="5,134.77,115.83,345.82,226.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,194.66,361.20,226.03,8.12;7,342.26,236.86,138.33,113.39"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Age and Gender distributions for the English Dataset</figDesc><graphic coords="7,342.26,236.86,138.33,113.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="8,134.77,395.58,345.83,8.12;8,134.77,406.89,14.44,7.77;8,134.77,271.25,155.62,113.39"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Results of the current and last years' system on the current Age(left) and Gender(right) task</figDesc><graphic coords="8,134.77,271.25,155.62,113.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="10,134.77,119.96,345.41,7.77;10,146.47,130.92,329.36,7.77;10,146.47,141.88,280.49,7.77;10,146.47,152.84,96.22,7.77;10,134.77,163.80,339.24,7.77;10,146.47,174.76,318.68,7.77"><head></head><label></label><figDesc>6. Rangel, F., Rosso, P., Verhoeven, B., Daelemans, W., Potthast, M., Stein, B.: Overview of the 4th Author Profiling Task at PAN 2016: Cross-genre Evaluations. In: Working Notes Papers of the CLEF 2016 Evaluation Labs. CEUR Workshop Proceedings, CLEF and CEUR-WS.org (Sep 2016) 7. Rennie, J.D., Shih, L., Teevan, J., Karger, D.: Tackling the poor assumptions of naive bayes text classifiers. In: International Conference on Machine Learning. vol. 20, p. 616 (2003)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,236.75,357.79,141.87,71.89"><head>Table 1 .</head><label>1</label><figDesc>Features used for each subtask</figDesc><table coords="6,249.26,377.28,114.60,52.41"><row><cell>Subtask</cell><cell>Group</cell><cell>Feature</cell></row><row><cell>Age</cell><cell>Stylometry Discriminative</cell><cell>3000 5</cell></row><row><cell>Gender</cell><cell>Stylometry Discriminative</cell><cell>-2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,188.32,115.83,240.21,142.43"><head>Table 2 .</head><label>2</label><figDesc>Results for the test datasets</figDesc><table coords="8,188.32,134.96,240.21,123.29"><row><cell>Dataset</cell><cell>Language</cell><cell>Subtask</cell><cell>Accuracy</cell></row><row><cell></cell><cell>Dutch</cell><cell>Gender</cell><cell>44.00</cell></row><row><cell>Test-1</cell><cell>English</cell><cell>Age Gender</cell><cell>30.46 53.45</cell></row><row><cell></cell><cell>Spanish</cell><cell>Age Gender</cell><cell>29.69 60.94</cell></row><row><cell></cell><cell>Dutch</cell><cell>Gender</cell><cell>41.60</cell></row><row><cell>Test-2</cell><cell>English</cell><cell>Age Gender</cell><cell>55.13 69.23</cell></row><row><cell></cell><cell>Spanish</cell><cell>Age Gender</cell><cell>32.14 67.86</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5">Acknowledgments</head><p>This work was supported by <rs type="funder">REVEAL</rs> (http://revealproject.eu/) project, which has received funding by the <rs type="funder">European Union</rs>'s <rs type="programName">7th Framework Program for research, technology development and demonstration</rs> under the Grant Agreements No. <rs type="grantNumber">FP7-610928</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_stfcPMh">
					<idno type="grant-number">FP7-610928</idno>
					<orgName type="program" subtype="full">7th Framework Program for research, technology development and demonstration</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,138.13,448.74,315.63,7.77;9,146.47,459.70,327.91,7.77;9,146.47,470.65,316.61,7.77;9,146.47,481.61,274.80,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,311.78,448.74,141.97,7.77;9,146.47,459.70,232.23,7.77">Author Profiling Using Stylometric and Structural Feature Groupings-Notebook for PAN at CLEF 2015</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Grivas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Giannakopoulos</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="9,266.25,470.65,196.83,7.77;9,146.47,481.61,45.46,7.77">CLEF 2015 Evaluation Labs and Workshop -Working Notes Papers</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>San Juan</surname></persName>
		</editor>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09">8-11 September. Sep 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.13,492.60,341.91,7.77;9,146.47,503.56,328.23,7.77;9,146.47,514.52,334.12,7.77;9,146.47,525.48,269.25,7.77" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Vogel</surname></persName>
		</author>
		<title level="m" coord="9,209.82,492.60,270.21,7.77;9,146.47,503.56,41.14,7.77;9,407.21,503.56,67.50,7.77;9,146.47,514.52,334.12,7.77;9,146.47,525.48,33.17,7.77">Proceedings, chap. Improving Multiclass Text Classification with Error-Correcting Output Coding and Sub-class Partitions</title>
		<meeting>chap. Improving Multiclass Text Classification with Error-Correcting Output Coding and Sub-class Partitions<address><addrLine>Ottawa, Canada; Berlin Heidelberg, Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010-05-31">2010. May 31 -June 2,2010. 2010</date>
			<biblScope unit="page" from="4" to="15" />
		</imprint>
	</monogr>
	<note>Advances in Artificial Intelligence: 23rd Canadian Conference on Artificial Intelligence</note>
</biblStruct>

<biblStruct coords="9,138.13,536.47,315.69,7.77;9,146.47,547.43,331.04,7.77;9,146.47,558.39,312.41,7.77;9,146.47,569.35,207.06,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,216.59,536.47,121.07,7.77">Nltk: The natural language toolkit</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,355.31,536.47,98.51,7.77;9,146.47,547.43,331.04,7.77;9,146.47,558.39,115.82,7.77;9,343.82,558.39,54.23,7.77">Proceedings of the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics</title>
		<meeting>the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="63" to="70" />
		</imprint>
	</monogr>
	<note>ETMTNLP &apos;02</note>
</biblStruct>

<biblStruct coords="9,138.13,580.34,342.22,7.77;9,146.47,591.30,332.77,7.77" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="9,146.47,591.30,310.35,7.77">INAOE&apos;s participation at PAN&apos;13: Author Profiling task-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>López-Monroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Escalante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villaseñor-Pineda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Villatoro-Tello</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,146.47,602.26,314.03,7.77;9,146.47,613.22,248.06,7.77" xml:id="b4">
	<monogr>
		<title level="m" coord="9,297.07,602.26,163.43,7.77;9,146.47,613.22,78.86,7.77">CLEF 2013 Evaluation Labs and Workshop -Working Notes Papers</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Tufis</surname></persName>
		</editor>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-09">September. Sep 2013</date>
			<biblScope unit="page" from="23" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.13,624.21,339.05,7.77;9,146.47,635.17,333.55,7.77;9,146.47,646.13,332.63,7.77;9,146.47,657.08,149.66,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,258.45,646.13,144.73,7.77">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,409.37,646.13,69.72,7.77;9,146.47,657.08,67.47,7.77">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
