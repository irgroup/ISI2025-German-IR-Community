<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,157.08,115.90,301.20,12.90;1,243.72,133.83,127.92,12.90;1,223.43,154.12,168.50,10.75">Evaluating Safety, Soundness and Sensibleness of Obfuscation Systems Notebook for PAN at CLEF 2016</title>
				<funder ref="#_usvqnyR">
					<orgName type="full">German Federal Ministry of Economics and Technology</orgName>
				</funder>
				<funder ref="#_K7RhkDY">
					<orgName type="full">North Rhine-Westphalian</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,192.97,190.95,67.62,8.64"><forename type="first">Matthias</forename><surname>Liebeck</surname></persName>
							<email>liebeck@cs.uni-duesseldorf.de</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science</orgName>
								<orgName type="institution">Heinrich Heine University Düsseldorf</orgName>
								<address>
									<postCode>D-40225</postCode>
									<settlement>Düsseldorf</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,267.40,190.95,73.98,8.64"><forename type="first">Pashutan</forename><surname>Modaresi</surname></persName>
							<email>modaresi@cs.uni-duesseldorf.de</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science</orgName>
								<orgName type="institution">Heinrich Heine University Düsseldorf</orgName>
								<address>
									<postCode>D-40225</postCode>
									<settlement>Düsseldorf</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,365.21,190.95,57.17,8.64"><forename type="first">Stefan</forename><surname>Conrad</surname></persName>
							<email>conrad@cs.uni-duesseldorf.de</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science</orgName>
								<orgName type="institution">Heinrich Heine University Düsseldorf</orgName>
								<address>
									<postCode>D-40225</postCode>
									<settlement>Düsseldorf</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,157.08,115.90,301.20,12.90;1,243.72,133.83,127.92,12.90;1,223.43,154.12,168.50,10.75">Evaluating Safety, Soundness and Sensibleness of Obfuscation Systems Notebook for PAN at CLEF 2016</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7C9BA1C93C84B2FB7105689D51CF71A0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>masking is the task of paraphrasing a document so that its writing style no longer matches that of its original author. This task was introduced as part of the 2016 PAN Lab on Digital Text Forensics, for which a total of three research teams submitted their results. This work describes our methodology to evaluate the submitted obfuscation systems based on their safety, soundness and sensibleness. For the first two dimensions, we introduce automatic evaluation measures and for sensibleness we report our manual evaluation results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Author masking is the task of paraphrasing a document so that its writing style no longer matches that of its original author. Due to the advances in fields such as authorship attribution and author verification, it is not clear whether authors (particularly in the age of the Internet and social media) can assure their anonymity anymore <ref type="bibr" coords="1,434.26,452.32,15.27,8.64" target="#b19">[20]</ref>. While in some scenarios, such as verifying the authorship of disputed novels or revealing the author of harassing messages in social media <ref type="bibr" coords="1,318.78,476.23,15.27,8.64" target="#b18">[19]</ref>, author unmasking might be useful, there are situations where authors have the right to protect their privacy, among them the desire to avoid retribution from an employer or government agency <ref type="bibr" coords="1,419.44,500.14,15.27,8.64" target="#b9">[10]</ref>.</p><p>The task of author masking was introduced as part of the 2016 PAN Lab on Digital Text Forensics <ref type="bibr" coords="1,196.07,524.49,10.58,8.64" target="#b4">[5]</ref>, for which a total of three research teams, namely Mansourizade et al. <ref type="bibr" coords="1,146.99,536.45,15.27,8.64" target="#b12">[13]</ref>, Keswani et al. <ref type="bibr" coords="1,227.61,536.45,16.60,8.64" target="#b10">[11]</ref> and Mihalvoya et al. <ref type="bibr" coords="1,331.02,536.45,16.60,8.64" target="#b13">[14]</ref> (called Team A, B and C respectively in the rest of this work) submitted their results. The evaluation was completely anonymous and the identities of the teams were revealed after the submission of our evaluation results.</p><p>Together with the task of author masking, obfuscation evaluation has been introduced as another task to evaluate the performance of the author masking submissions. Three dimensions have been defined by the task organizers for the performance evaluation of the obfuscation systems: safety to ensure that a forensic analysis does not reveal the original author of an obfuscated text; soundness to evaluate if the obfuscated texts are textually entailed with their originals; and sensibleness to ensure that the obfuscated texts are inconspicuous <ref type="bibr" coords="1,230.08,656.44,15.27,8.64" target="#b17">[18]</ref>.</p><p>In this work, we describe our methodology to evaluate the performance of the submitted systems based on the aforementioned dimensions. In section 2 we define the problem of author masking more concretely and describe the provided training data. The evaluation results of the dimensions safety, soundness and sensibleness are reported in sections 3, 4 and 5, respectively. Finally, we conclude our work in section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Definition</head><p>Given a document, an author masking software has to paraphrase it so that its writing style no longer matches that of its original author. Although the organizers of the author masking task do not directly define this task as a supervised machine learning problem, a training set is provided so that the participant can evaluate their designed algorithms based on this dataset. The same dataset is also used as the test dataset for the final evaluation.</p><p>The provided dataset is a collection of 205 problems selected from author verification tasks from PAN2013 <ref type="bibr" coords="2,258.35,311.74,10.58,8.64" target="#b8">[9]</ref>, PAN2014 <ref type="bibr" coords="2,319.12,311.74,16.60,8.64" target="#b21">[22]</ref> and PAN2015 <ref type="bibr" coords="2,400.65,311.74,15.27,8.64" target="#b20">[21]</ref>. Each problem is a collection of at most five known documents (written by the same author) and a questioned document. Normally in author verification problems, the author of the questioned document is unknown and the task of an author verifier is to figure out whether the questioned document has the same author as the known documents or not. But in the training dataset of the author masking task, all problems are selected from positive instances, meaning all questioned documents have the same author as the known documents. The language of all provided problems is English.</p><p>The participants were asked to develop a software that outputs a detailed list, how each piece of the original text has been paraphrased. For a detailed description of the desired system output, the reader is referred to the official task page<ref type="foot" coords="2,404.55,430.09,3.49,6.05" target="#foot_0">1</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Safety</head><p>An obfuscation software is called safe, if a forensic analysis does not reveal the original author of the obfuscated texts. We evaluate the safety of the obfuscation software using an automatic author verifier called GLAD <ref type="bibr" coords="2,335.67,516.13,10.58,8.64" target="#b7">[8]</ref>. The idea behind this automatic evaluation measure is that if an obfuscation system successfully masks the authors of the questioned documents in the training set (remember that all problems in the training set belong to the positive class), the author verifier will classify the problems as negative (meaning that the obfuscated document no longer has the same author as the other documents).</p><p>The GLAD algorithm was one of the top ranked systems at PAN2015 and treats the author verification problem as an intrinsic binary classification machine learning task. GLAD uses SVM <ref type="bibr" coords="2,233.88,612.23,11.62,8.64" target="#b6">[7]</ref> as a learning algorithm and makes use of simple feature classes such as N-Grams, tokens, sentences, visual, compression, entropy and syntactic features <ref type="bibr" coords="2,168.79,636.14,10.58,8.64" target="#b7">[8]</ref>.</p><p>To train the GLAD algorithm we used the English problems from the training datasets from PAN2013 to PAN2015. The statistics of the training dataset used are shown in Table <ref type="table" coords="3,197.64,143.22,3.74,8.64" target="#tab_0">1</ref>. Notice that the training dataset from PAN2014 consisted of novels and essays and we took both categories to train our model.</p><p>Using the trained model, we measure the performance of the GLAD algorithm once using the original documents from the training set of the author masking problem (labels are all considered to be true), and once on the submissions of each team (labels are all considered to be true). As the evaluation measure we use c@1 <ref type="bibr" coords="3,406.04,333.30,15.27,8.64" target="#b16">[17]</ref>, as defined in Equation <ref type="formula" coords="3,174.05,345.25,3.74,8.64" target="#formula_0">1</ref>. The c@1 measure is a modified version of accuracy, where c@1 rewards approaches that maintain the same number of correct answers and decrease the number of incorrect answers by leaving some problems unanswered.</p><formula xml:id="formula_0" coords="3,255.87,388.21,224.73,22.31">c@1 = 1 n • n c + n u n c n<label>(1)</label></formula><p>In the definition of c@1 measure, n is the number of problems, n c is the number of correct answers and n u represents the number of unanswered problems.</p><p>Table <ref type="table" coords="3,174.40,438.83,4.98,8.64">2</ref> summarizes the evaluation results of the safety dimension. On the original dataset (the training dataset of author masking), the GLAD algorithm has a c@1 score of 0.656, meaning that the algorithm correctly classifies roughly 65% of the problems as positive. Notice that the gold standard labels are all set to be true and that teams having lower c@1 scores are more successful at the masking task than the other teams. It is also observable that none of the participants has a c@1 score below 0.5. This means that the portion of successful obfuscations for all submissions is below 50%. At the same time it can be seen that all submissions have a c@1 score below the baseline 0.656, meaning that all teams were partly successful at the author masking task.</p><p>Table <ref type="table" coords="3,239.64,565.06,3.36,8.06">2</ref>. Evaluation results of the safety dimension Team A Team B Team C Original C@1 0.585 0.532 0.522 0.656 Although in previous PAN competitions, AUC (Area Under the Curve) <ref type="bibr" coords="3,432.93,632.53,11.62,8.64" target="#b5">[6]</ref> was also used to evaluate the automatic verifiers, the use of this measure was not possible in our scenario as the test datasets contain either only positive or only negative instances.</p><p>Another interesting analysis is to investigate the relation between true positives and false negatives. The idea behind this analysis is to figure out the portion of documents classified as positive before obfuscation, and the ones classified as negative after obfuscation. For this we select true positives from the original dataset and count the ones that have been classified as negative by the GLAD algorithm. Table <ref type="table" coords="4,410.09,167.13,4.98,8.64">3</ref> summarizes the results.</p><p>Table <ref type="table" coords="4,239.64,212.48,3.36,8.06">3</ref>. Evaluation results of the safety dimension Team A Team B Team C FN / TP 0.159 0.254 0.290 Notice that higher values in Table 3 are preferred. Team C has the highest score among the teams and has managed to obfuscate roughly 30% of the true positive problems to false negative ones. These results are consistent with the results shown in Table <ref type="table" coords="4,134.77,322.72,3.74,8.64">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Soundness</head><p>We assume that the goal of author masking is to reword a text segment into a paraphrased one while retaining as much semantic similarity as possible. Therefore, we propose to quantify soundness by measuring the semantic textual similarity (STS) between the original text segment and its corresponding obfuscation.</p><p>The prediction of semantic textual similarity has been a recurring task in SemEval challenges since 2012 <ref type="bibr" coords="4,224.34,461.02,8.02,8.64" target="#b0">[1]</ref><ref type="bibr" coords="4,232.36,461.02,4.01,8.64" target="#b1">[2]</ref><ref type="bibr" coords="4,232.36,461.02,4.01,8.64" target="#b2">[3]</ref><ref type="bibr" coords="4,236.37,461.02,8.02,8.64" target="#b3">[4]</ref>. The aim of the STS task is to determine the semantic similarity of two sentences in the continuous interval [0, 5] where 0 represents a complete dissimilarity and 5 denotes a complete semantic equivalence between the sentences. The task organizers provide sentence pairs with gold standards from different categories. The task is evaluated by calculating the Pearson correlation between the predicted values and a crowdsourced gold standard.</p><p>In this paper, we use the unsupervised semantic similarity approach called Overlap <ref type="bibr" coords="4,134.77,546.77,16.60,8.64" target="#b11">[12]</ref> to automatically determine the semantic similarity between the original segment and its paraphrase. There are two advantages of using an unsupervised approach: (i) human annotators can only annotate a subset of the paraphrases within a reasonable amount of time. An automatic approach can evaluate all original-paraphrase pairs and (ii) we do not need labeled training data as compared to a supervised approach.</p><p>The idea of the Overlap method is simple since it measures the overlap between the tokens in the original segment s 1 and the tokens in the paraphrase s 2 by aligning tokens to the best match in the other text segment. The authors first define a similarity function for two tokens which uses synsets from WordNet <ref type="bibr" coords="4,372.03,644.48,16.60,8.64" target="#b15">[16]</ref> and word embeddings from word2vec <ref type="bibr" coords="4,198.15,656.44,15.27,8.64" target="#b14">[15]</ref>, as denoted in Equation <ref type="formula" coords="4,313.25,656.44,3.74,8.64">2</ref>. Afterwards, the similarity score between two text segments in [0, 5] is defined as follows:</p><formula xml:id="formula_1" coords="5,140.57,132.83,140.75,69.14">sim(t 1 , t 2 ) :=                1 if t 1 .</formula><formula xml:id="formula_2" coords="5,166.70,240.01,313.89,30.83">STS(s 1 , s 2 ) := 5 •   t1∈s1 max t2∈s2 sim(t 1 , t 2 ) 2 • |s 1 | + t2∈s2 max t1∈s1 sim(t 2 , t 1 ) 2 • |s 2 |  <label>(3)</label></formula><p>Since we assume the obfuscations to be semantically as close as possible to the originals, the STS score between both segments should be 5. We predict the semantic similarity for all pairs for each team. Afterwards, we average over the predicted scores for each team. Table <ref type="table" coords="5,218.34,320.17,4.98,8.64">4</ref> summarizes the results for the soundness dimension.</p><p>Table <ref type="table" coords="5,231.92,348.01,3.36,8.06">4</ref>. Evaluation results of the soundness dimension Team A Team B Team C Mean STS 4.87 4.04 4.48</p><p>For the soundness dimension, the best semantic paraphrases were created by team A with an average STS score of 4.87. This is not surprising since team A only substituted a few words and often kept the original segment as a paraphrase. Therefore, the paraphrases are semantically very close or even identical to the original. Team C achieved a mean STS score of 4.48 and team B had the lowest score with 4.04. Since the Overlap approach from <ref type="bibr" coords="5,196.72,474.79,16.60,8.64" target="#b11">[12]</ref> is independent of the word order, the results of team B cannot be explained by changing the word order of the phrases. One factor that definitely influenced the semantic similarity is the appearance of German words in the paraphrases, which cannot be matched to the English tokens in the original texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Sensibleness</head><p>The dimension sensibleness describes the language quality of the obfuscations and whether it allows us to understand them. An author masking software might mask the author of a text at the cost of its comprehension. Therefore, it is also crucial to evaluate the quality of the produced obfuscations.</p><p>We observed that teams A and C used dictionaries to perform simple substitutions and team B usually changed the order of phrases. It is surprising to see that the paraphrases by team B sometimes contain random German words, as in the following example: "it is difficult to across, Once the Mitbürgers unschön is faint, odor street, on the village so massed mold Verfalls and centuries."</p><p>Although there are approaches to automatically predict the grammatical quality of text, we chose to manually evaluate the sensibleness because portions of the text have a low language quality but still allow for a limited understanding of the content. For example, this can be compared to a non-native speaker who asks in an online forum a question that is poorly worded but still comprehensible.</p><p>After a manual inspection of a subset of the paraphrases from all three teams, we decided to annotate each pair with a score s ∈ {0, 1, 2} to measure the language quality. We then drew a small sample and discussed annotation guidelines. Our three labels and their definitions are described in Table <ref type="table" coords="6,290.02,214.95,3.74,8.64" target="#tab_2">5</ref>. The language quality of the paraphrase is too low to allow any understanding of the content.</p><p>Example: "I a In certain years in a bookstore can help , than English , French English. French"</p><p>In our evaluation, sensibleness is only evaluated by looking at the obfuscated text. This is due to the fact that only the paraphrased text after author masking is used in a real world scenario. Therefore, it is reasonable to only evaluate the output of the system. We ignore spacing and line breaks during the annotation process. Furthermore, we also ignore the substitutions of the words "oof " and "tto" from team C because they do not impact the understanding of the text.</p><p>We randomly drew a subset of 20 problems. For each team, we then drew three obfuscations per problem. All of these obfuscations were manually annotated by three annotators. In order to report a single value per team, we averaged all the scores from the annotators. Table <ref type="table" coords="6,220.29,526.75,4.98,8.64">6</ref> summarizes the results for the sensibleness dimension. Table <ref type="table" coords="6,228.18,554.08,3.36,8.06">6</ref>. Evaluation results of the sensibleness dimension Team A Team B Team C Average score 1.94 0.57 1.20</p><p>Team A achieved the best results in the sensibleness dimension with an average score close to 2. The paraphrases from team B allow for the lowest understanding of all three teams with an average score of 0.57 which is between partially comprehensible and incomprehensible.</p><p>We should note that there are at least two problems for the evaluation of the sensibleness dimension: (i) it is difficult to formalize language quality and understanding and (ii) the sensibleness dimension is subjective. Although we observed a high agreement on the category incomprehensible, we had a lower agreement on whether a paraphrase is fully or partially comprehensible. This is plausible since one annotator might perfectly understand a text segment while another annotator may have some troubles with it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we discussed our methodology to evaluate the performance of the obfuscation systems submitted to the PAN2016 Author Masking shared task. More concretely, submissions were evaluated based on their safety (Section 3), soundness (Section 4), and sensibleness (Section 5). The scripts for our evaluation are available on GitHub<ref type="foot" coords="7,467.22,281.37,3.49,6.05" target="#foot_1">2</ref> .</p><p>An automatic author verifier was used to measure the safety of the submissions. The ranking of the teams in terms of safety is as follows: team C, B, and A</p><p>We proposed to quantify soundness by automatically measuring the semantic text similarity between the original text fragments and their obfuscations. The best score was achieved by team A, followed by teams C and B.</p><p>Unlike the first two dimensions, the sensibleness of the submissions was evaluated manually. As sensibleness is subjective and difficult to formally define, we consider its measurement a nontrivial task. Regarding sensibleness, teams A, C and B were ranked first, second, and third, respectively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,154.90,171.76,305.56,72.69"><head>Table 1 .</head><label>1</label><figDesc>Statistics of the dataset used to train GLAD</figDesc><table coords="3,154.90,191.24,305.56,53.20"><row><cell></cell><cell cols="4">#Problems #Documents Avg. #Known Documents Avg. #Tokens</cell></row><row><cell>PAN2015</cell><cell>100</cell><cell>200</cell><cell>1.0</cell><cell>366</cell></row><row><cell>PAN2014 (Essays)</cell><cell>200</cell><cell>725</cell><cell>2.6</cell><cell>848</cell></row><row><cell>PAN2014 (Novels)</cell><cell>100</cell><cell>200</cell><cell>1.0</cell><cell>3137.8</cell></row><row><cell>PAN2013</cell><cell>10</cell><cell>42</cell><cell>3.2</cell><cell>1037</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,208.18,136.47,272.41,66.34"><head></head><label></label><figDesc>lemma == t 2 .lemma 1 if t 1 and t 2 have the same most common synset 0.5 if t 1 and t 2 share any other synset cos(t 1 , t 2 ) if t 1 and t 2 have word2vec embeddings</figDesc><table coords="5,208.18,165.10,272.41,37.71"><row><cell></cell><cell>(2)</cell></row><row><cell>0.15</cell><cell>otherwise</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,150.68,242.28,313.99,116.13"><head>Table 5 .</head><label>5</label><figDesc>Labels for the sensibleness dimension</figDesc><table coords="6,150.68,261.77,313.99,96.64"><row><cell>Score Name</cell><cell>Definition</cell></row><row><cell>2 comprehensible</cell><cell>The paraphrase can be understood immediately.</cell></row><row><cell></cell><cell>Example: "These things are deeply rooted in the</cell></row><row><cell></cell><cell>Swedish people."</cell></row><row><cell cols="2">1 partially comprehensible The paraphrase can be understood with some restric-</cell></row><row><cell></cell><cell>tions. It can contain smaller errors or some smaller parts</cell></row><row><cell></cell><cell>that are incomprehensible.</cell></row><row><cell></cell><cell>Example: "they him. But ignored"</cell></row><row><cell>0 incomprehensible</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,657.08,224.20,7.77"><p>http://pan.webis.de/clef16/pan16-web/author-obfuscation.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="7,144.73,657.08,139.88,7.77"><p>https://github.com/pasmod/obfuscation</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was partially funded by the <rs type="programName">PhD program Online Participation</rs>, supported by the <rs type="funder">North Rhine-Westphalian</rs> funding scheme Fortschrittskollegs and by the <rs type="funder">German Federal Ministry of Economics and Technology</rs> under the <rs type="programName">ZIM program</rs> (Grant No. <rs type="grantNumber">KF2846504</rs>). We would like to thank <rs type="person">Daniel Braun</rs> for his help in the evaluation of the sensibleness dimension.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_K7RhkDY">
					<orgName type="program" subtype="full">PhD program Online Participation</orgName>
				</org>
				<org type="funding" xml:id="_usvqnyR">
					<idno type="grant-number">KF2846504</idno>
					<orgName type="program" subtype="full">ZIM program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,142.61,550.47,337.98,7.77;7,150.95,561.43,329.64,7.77;7,150.95,572.39,329.64,7.77;7,150.95,583.35,329.64,7.77;7,150.95,594.31,178.83,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,408.51,561.43,72.08,7.77;7,150.95,572.39,269.14,7.77">SemEval-2015 Task 2: Semantic Textual Similarity, English, Spanish and Pilot on Interpretability</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Banea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Lopez-Gazpio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Maritxalar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rigau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,436.77,572.39,43.83,7.77;7,150.95,583.35,214.43,7.77">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
		<meeting>the 9th International Workshop on Semantic Evaluation<address><addrLine>SemEval</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="252" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,605.30,337.98,7.77;7,150.95,616.26,329.64,7.77;7,150.95,627.22,329.64,7.77;7,150.95,638.18,318.94,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,241.72,616.26,235.41,7.77">SemEval-2014 Task 10: Multilingual Semantic Textual Similarity</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Banea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rigau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,163.12,627.22,313.61,7.77">Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014)</title>
		<meeting>the 8th International Workshop on Semantic Evaluation (SemEval 2014)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics and Dublin City University</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="81" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,119.96,337.98,7.77;8,150.95,130.92,329.64,7.77;8,150.95,141.88,329.64,7.77;8,150.95,152.84,329.64,7.77;8,150.95,163.80,290.92,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,341.78,119.96,138.81,7.77;8,150.95,130.92,89.69,7.77">SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,264.30,130.92,216.30,7.77;8,150.95,141.88,82.47,7.77;8,276.04,141.88,201.22,7.77;8,208.81,152.84,271.79,7.77">SEM 2012: The First Joint Conference on Lexical and Computational Semantics</title>
		<meeting><address><addrLine>SemEval</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="385" to="393" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth International Workshop on Semantic Evaluation</note>
</biblStruct>

<biblStruct coords="8,142.61,174.12,337.98,7.77;8,150.95,185.08,329.64,7.77;8,150.95,196.04,329.64,7.77;8,150.95,207.00,287.82,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,370.87,174.12,109.72,7.77;8,150.95,185.08,73.82,7.77">SEM 2013 shared task: Semantic Textual Similarity</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,242.24,185.08,238.35,7.77;8,150.95,196.04,26.68,7.77;8,226.77,196.04,253.82,7.77;8,150.95,207.00,62.99,7.77">Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity</title>
		<meeting>the Main Conference and the Shared Task: Semantic Textual Similarity</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="32" to="43" />
		</imprint>
	</monogr>
	<note>Second Joint Conference on Lexical and Computational Semantics (*SEM)</note>
</biblStruct>

<biblStruct coords="8,142.61,217.32,337.98,7.77;8,150.95,228.28,324.29,7.77" xml:id="b4">
	<analytic>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,362.80,217.32,117.79,7.77;8,150.95,228.28,124.46,7.77">CLEF 2016 Evaluation Labs and Workshop -Working Notes Papers</title>
		<title level="s" coord="8,281.37,228.28,133.12,7.77">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,238.60,337.98,7.77;8,150.95,249.56,242.43,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,204.96,238.60,275.63,7.77;8,150.95,249.56,73.78,7.77">The Use of the Area Under the ROC Curve in the Evaluation of Machine Learning Algorithms</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Bradley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,230.90,249.56,57.14,7.77">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1145" to="1159" />
			<date type="published" when="1997-07">Jul 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,259.88,333.93,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,233.73,259.88,87.03,7.77">Support-vector networks</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,326.89,259.88,65.98,7.77">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,270.20,337.98,7.77;8,150.95,281.16,329.64,7.77;8,150.95,292.12,111.84,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,411.15,270.20,69.44,7.77;8,150.95,281.16,121.63,7.77">GLAD: Groningen Lightweight Authorship Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hürlimann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Weck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Suster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Nissim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,290.30,281.16,190.29,7.77;8,150.95,292.12,85.69,7.77">Working Notes of CLEF 2015 -Conference and Labs of the Evaluation forum</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,302.44,337.98,7.77;8,150.95,313.40,247.98,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,240.75,302.44,199.75,7.77">Overview of the Author Identification Task at PAN 2013</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,458.67,302.44,21.92,7.77;8,150.95,313.40,221.84,7.77">CLEF 2013 Evaluation Labs and Workshop -Working Notes Papers</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,323.72,338.35,7.77;8,150.95,334.68,329.64,7.77;8,150.95,345.64,287.79,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,267.77,323.72,212.82,7.77;8,150.95,334.68,38.66,7.77">Obfuscating Document Stylometry to Preserve Author Anonymity</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Kacmarcik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,208.34,334.68,255.13,7.77;8,186.82,345.64,67.31,7.77">Proceedings of the COLING/ACL on Main Conference Poster Sessions</title>
		<meeting>the COLING/ACL on Main Conference Poster Sessions</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="444" to="451" />
		</imprint>
	</monogr>
	<note>COLING-ACL &apos;06</note>
</biblStruct>

<biblStruct coords="8,142.24,355.96,338.35,7.77;8,150.95,366.92,329.64,7.77;8,150.95,377.88,131.94,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,337.73,355.96,142.86,7.77;8,150.95,366.92,99.05,7.77">Author Masking through Translation-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Keswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Majumder</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,285.93,366.92,194.66,7.77;8,150.95,377.88,45.46,7.77">CLEF 2016 Evaluation Labs and Workshop -Working Notes Papers</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,388.20,338.35,7.77;8,150.95,399.16,329.64,7.77;8,150.95,410.12,329.64,7.77;8,150.95,421.08,121.55,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,334.75,388.20,145.84,7.77;8,150.95,399.16,198.66,7.77">HHU at SemEval-2016 Task 1: Multiple Approaches to Measuring Semantic Textual Similarity</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Liebeck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pollack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Modaresi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Conrad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,369.55,399.16,111.05,7.77;8,150.95,410.12,157.26,7.77">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
		<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>SemEval-</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="607" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,431.40,338.35,7.77;8,150.95,442.36,329.64,7.77;8,150.95,453.32,265.98,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,385.76,431.40,94.83,7.77;8,150.95,442.36,224.37,7.77">Author Obfuscation using WordNet and Language Models-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mansourizade</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rahgooy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Aminiyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Eskandari</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,412.41,442.36,68.18,7.77;8,150.95,453.32,179.49,7.77">CLEF 2016 Evaluation Labs and Workshop -Working Notes Papers</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,463.64,338.35,7.77;8,150.95,474.60,329.64,7.77;8,150.95,485.56,286.67,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,150.95,474.60,247.69,7.77">SU@PAN&apos;2016: Author Obfuscation-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mihaylova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Karadjov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kiprov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Georgiev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Koychev</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,437.74,474.60,42.85,7.77;8,150.95,485.56,200.19,7.77">CLEF 2016 Evaluation Labs and Workshop -Working Notes Papers</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,495.88,338.35,7.77;8,150.95,506.84,146.21,7.77" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,316.64,495.88,163.95,7.77;8,150.95,506.84,54.57,7.77">Efficient Estimation of Word Representations in Vector Space</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,211.71,506.84,59.30,7.77">ICLR Workshop</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,517.17,338.35,7.77;8,150.95,528.12,76.95,7.77" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,203.23,517.17,157.77,7.77">WordNet: A Lexical Database for English</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,368.73,517.17,111.86,7.77">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,538.45,338.35,7.77;8,150.95,549.41,329.64,7.77;8,150.95,560.36,329.64,7.77;8,150.95,571.32,38.60,7.77" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="8,238.46,538.45,155.37,7.77">A Simple Measure to Assess Non-response</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rodrigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,413.06,538.45,67.53,7.77;8,150.95,549.41,329.64,7.77;8,150.95,560.36,52.79,7.77;8,302.66,560.36,29.39,7.77">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1415" to="1424" />
		</imprint>
	</monogr>
	<note>HLT &apos;11</note>
</biblStruct>

<biblStruct coords="8,142.24,581.65,338.35,7.77;8,150.95,592.60,329.64,7.77;8,150.95,603.56,222.76,7.77" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="8,275.75,581.65,204.84,7.77;8,150.95,592.60,72.56,7.77">Author Obfuscation: Attacking the State of the Art in Authorship Verification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,241.86,592.60,208.40,7.77">Working Notes Papers of the CLEF 2016 Evaluation Labs</title>
		<title level="s" coord="8,456.68,592.60,23.91,7.77;8,150.95,603.56,146.32,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<imprint>
			<date type="published" when="2016-09">Sep 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,613.89,338.35,7.77;8,150.95,624.84,329.64,7.77;8,150.95,635.80,165.34,7.77" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="8,420.09,613.89,60.50,7.77;8,150.95,624.84,123.49,7.77">Overview of the 3rd Author Profiling Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Celli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,313.26,624.84,167.33,7.77;8,150.95,635.80,78.86,7.77">CLEF 2015 Evaluation Labs and Workshop -Working Notes Papers</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,646.13,338.35,7.77;8,150.95,657.08,227.64,7.77" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="8,232.70,646.13,166.17,7.77">Can Pseudonymity Really Guarantee Privacy?</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rohatgi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,413.58,646.13,67.01,7.77;8,150.95,657.08,121.52,7.77">Proceedings of the 9th USENIX Security Symposium</title>
		<meeting>the 9th USENIX Security Symposium</meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="85" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,119.96,338.35,7.77;9,150.95,130.92,329.64,7.77;9,150.95,141.88,226.13,7.77" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="9,163.52,130.92,179.90,7.77">Overview of the Author Identification Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">D</forename><surname>Amd Ben Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>López-López</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="9,379.12,130.92,101.47,7.77;9,150.95,141.88,139.65,7.77">CLEF 2015 Evaluation Labs and Workshop -Working Notes Papers</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,152.84,338.35,7.77;9,150.95,163.80,329.64,7.77;9,150.95,174.76,329.64,7.77;9,150.95,185.71,20.92,7.77" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="9,263.29,163.80,182.67,7.77">Overview of the Author Identification Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanchez-Perez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="9,150.95,174.76,249.51,7.77">CLEF 2014 Evaluation Labs and Workshop -Working Notes Papers</title>
		<imprint>
			<date type="published" when="2014-09">2014. Sep 2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
