<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,168.79,115.99,277.77,12.60;1,183.60,133.92,163.78,12.60;1,139.74,153.75,335.88,10.50;1,166.39,167.70,282.58,10.50">CITlab ARGUS for Keyword Search in Historical Handwritten</title>
				<funder ref="#_2ZJAvs9">
					<orgName type="full">Bundesrepublik Deutschland (BMWi)</orgName>
				</funder>
				<funder ref="#_YM6cEDR">
					<orgName type="full">Zentrales Innovationsprogramm Mittelstand</orgName>
				</funder>
				<funder ref="#_t5ZyutP">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,155.87,203.65,59.37,8.80"><forename type="first">Tobias</forename><surname>Strauß</surname></persName>
							<email>tobias.strauss@uni-rostock.de</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CITlab</orgName>
								<orgName type="department" key="dep2">Institute of Mathematics</orgName>
								<orgName type="institution">University of Rostock</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,223.15,203.65,66.30,8.80"><forename type="first">Tobias</forename><surname>Grüning</surname></persName>
							<email>tobias.gruening@uni-rostock.de</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CITlab</orgName>
								<orgName type="department" key="dep2">Institute of Mathematics</orgName>
								<orgName type="institution">University of Rostock</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,297.69,203.65,72.87,8.80"><forename type="first">Gundram</forename><surname>Leifert</surname></persName>
							<email>gundram.leifert@uni-rostock.de</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CITlab</orgName>
								<orgName type="department" key="dep2">Institute of Mathematics</orgName>
								<orgName type="institution">University of Rostock</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,397.25,203.65,61.74,8.80"><forename type="first">Roger</forename><surname>Labahn</surname></persName>
							<email>roger.labahn@uni-rostock.de</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CITlab</orgName>
								<orgName type="department" key="dep2">Institute of Mathematics</orgName>
								<orgName type="institution">University of Rostock</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,168.79,115.99,277.77,12.60;1,183.60,133.92,163.78,12.60;1,139.74,153.75,335.88,10.50;1,166.39,167.70,282.58,10.50">CITlab ARGUS for Keyword Search in Historical Handwritten</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2579D7EA1ECA50A11D9DB2A726E26101</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>MDRNN</term>
					<term>LeakyLP cells</term>
					<term>CTC</term>
					<term>handwriting recognition</term>
					<term>neural network</term>
					<term>keyword spotting</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe CITlab's recognition system for the Handwritten Scanned Document Retrieval Task 2016 attached to the CLEF 2016 hold in the city of Évora in Portugal, 5-8 September 2016 (see <ref type="bibr" coords="1,397.55,297.46,9.52,7.92" target="#b8">[9]</ref>). The task is to locate positions that match a given query -consisting of possibly more than one keyword -in a number of historical handwritten documents. The core algorithms of our system are based on multi-dimensional recurrent neural networks (MDRNN) trained by connectionist temporal classification (CTC). The software modules behind that as well as the basic utility technologies are essentially powered by PLANET's ARGUS framework for intelligent text recognition and image processing.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Conference and Labs of the Evaluation Forum (CLEF) 2016 ( <ref type="bibr" coords="1,439.01,471.37,10.96,8.80" target="#b8">[9]</ref>) hosts a variety of competitions. Among others, the Handwritten Scanned Document Retrieval Task 2016 competition on the tranScriptorium Dataset (HTRtS) attracted our attention because we expected CITlab's handwriting recognition software to be able to successfully deal with the respective task.</p><p>Our neural networks have basically been used previously in the international handwriting competitions OpenHaRT 2013 attached to the ICDAR 2013 conference (see <ref type="bibr" coords="1,188.25,555.05,10.30,8.80" target="#b3">[4]</ref>), the HTRtS14 and ANWERSH14 attached to the ICFHR 2014 conference (see <ref type="bibr" coords="1,201.99,567.01,11.07,8.80" target="#b7">[8,</ref><ref type="bibr" coords="1,213.06,567.01,7.38,8.80" target="#b2">3]</ref>) as well as in KWS15 and HTRtS15 attached to the ICDAR 2015 conference (see <ref type="bibr" coords="1,226.44,578.96,10.30,8.80" target="#b5">[6]</ref>).</p><p>Affiliated with the Institute of Mathematics at the University of Rostock, CITlab 1 hosts joint projects of the Mathematical Optimization Group and PLANET intelligent systems GmbH 2 , a small/medium enterprise focusing on computational intelligence technology and applications. The work presented here is part of our ongoing text recognition projects and is extensively based upon PLANET's ARGUS software modules and the respective framework for development, testing and training.</p><p>Task The Handwritten Scanned Document Retrieval Task 2016 aims at an advanced keyword spotting. Besides ordinary keyword search, the competition comprises the detection of multiple word queries consisting of possibly hyphenated keywords within sections. The writings used for this task are unpublished manuscripts of Jeremy Bentham -an English philosopher and reformer of the 18th century.</p><p>The goal is to detect queries in a "segment" which is defined as six consecutive lines. A segment contains a query if all keywords appear in the correct order. Two consecutive segments overlap in 5 lines. This means, a match of a query possibly appears in up to 6 segments depending on the difference between the indices of the last and first index of matching lines. A detailed description of this task and their results can be found in <ref type="bibr" coords="2,321.84,304.10,14.61,8.80" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Basic Scheme</head><p>For the general approach, we may briefly refer to previous CITlab system descriptions <ref type="bibr" coords="2,179.66,391.34,11.25,8.80" target="#b3">[4,</ref><ref type="bibr" coords="2,190.91,391.34,7.50,8.80" target="#b2">3,</ref><ref type="bibr" coords="2,198.41,391.34,7.50,8.80" target="#b7">8,</ref><ref type="bibr" coords="2,205.92,391.34,7.50,8.80" target="#b5">6]</ref> because the overall scheme has essentially not been changed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">From Baseline to Polygon</head><p>This section briefly describes an algorithm to calculate polygons surrounding the text lines given its baselines. Given that for the test set (see Table <ref type="table" coords="2,449.54,452.82,4.43,8.80" target="#tab_0">1</ref>) only baselines are provided, such an algorithm is mandatory since the recognition system requires a cropped text line as input.</p><p>The baseline to polygon algorithm basically follows <ref type="bibr" coords="2,371.67,488.69,9.96,8.80" target="#b0">[1]</ref>. The idea is that given a medial seam (which is roughly spoken a polyline following the main body of the text line) separating seams are calculated by optimizing an appropriate cost function using dynamic programming (see <ref type="bibr" coords="2,316.12,524.55,10.30,8.80" target="#b0">[1]</ref>). Here, the cost function penalizes a separating seam for crossing regions with high Sobel values and for its distance to the medial seam. The Sobel values are calculated by convolving the input image with the Sobel operator. Using the given baseline directly as medial seam leads to insufficient results, e.g. in Fig. <ref type="figure" coords="2,166.04,584.33,9.96,8.80">1a</ref> the provided baseline even does not touch the text -as a consequence the calculated separating seams even do not contain the text at all. Hence, an optimal shift is calculated for each baseline such that the sum of Sobel values on the shifted baseline is maximal. Fig. <ref type="figure" coords="2,309.69,620.19,10.52,8.80">1b</ref> depicts the effect of this approach.</p><p>There are surrounding polygons given for the training and development set (Table <ref type="table" coords="2,166.64,644.10,3.87,8.80" target="#tab_0">1</ref>). Since they look quite different to the polygons calculated using the described algorithm, we did not train on the given surrounding polygons. These </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Preprocessing</head><p>Given the line polygon, we apply certain standard preprocessing routines, i.e.</p><p>image normalization: contrast enhancement (no binarization), size; writing normalization: line bends, line skew, script slant.</p><p>Then, images are further unified by CITlab's proprietary writing normalization: The writing's main body is placed in the center part of an image of fixed 96px height. While the length-height ratio of the main body stays untouched, the ascenders and descenders are squashed to focus the network's attention on the more informative main body. These images are the input for the feature generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Feature Generation</head><p>The feature generation works like a convolutional filter with complex coefficients. The input image is converted in a set of feature maps that contain local frequency information. Let X X X ∈ [0, 1] u×v be an image of width u and height v. Let ω ∈ R + be a frequency, θ ∈ [0, 2π) be an angle and r 0 ∈ R + be a window radius. The complex convolutional kernel is defined by</p><formula xml:id="formula_0" coords="3,153.83,601.07,295.51,59.08">f (r) = 1 2 1 + cos πr 2 if r &lt; 2 0 else g(x, y) := g(x, y) ω,θ,r0 = f x 2 + y 2 r 0 exp iω x cos (θ) + y sin (θ)</formula><p>around a centre (0, 0). The frequency feature b(x, y) at point (x, y) is then calculated by b (x, y)</p><formula xml:id="formula_1" coords="4,258.30,164.40,130.58,20.59">= (i,j)∈Z 2 X i,j g(i -x, j -y) .</formula><p>The advantage of this frequency features is the robustness against shifts and noise on the input image. In this applications we use parameters</p><formula xml:id="formula_2" coords="4,134.77,207.98,345.83,26.43">ω ∈ π 4 , π 2 , θ ∈ 0, π 4 , π 2 , 3π<label>4</label></formula><p>and r 0 ≈ 4. These 8 feature images (2 frequencies and 4 angles) are the input for the MDRNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Recurrent Neural Network</head><p>The resulting features were fed into so called Sequential Processing Recurrent Neural Network (SPRNN). The SPRNN has 3 hidden layers with 355210 trainable weights. The first and third layer are multidimensional and multidirectional recurrent layers. To reduce the computational complexity and increase the ability to generalize, these recurrent layers are connected through a feedforward layer. Instead of using LSTMs in the MDRNN the LeakyLP cells are used <ref type="bibr" coords="4,434.51,345.25,9.96,8.80" target="#b4">[5]</ref>.</p><p>The SPRNN's output then consists of a certain number of vectors. This number is related to the line length because every vector contains information about a particular image position. More precisely, the entries are understood as the estimate of the probabilities of every alphabet character at the position under consideration. Hence, the vector lengths all equal the alphabet size, and putting all vectors together leads to the so-called confidence matrix "ConfMat". This is the intrinsic recognition result which will subsequently be used for the decoding.</p><p>Note further that, for Handwritten Scanned Document Retrieval Task 2016 , we worked with an alphabet containing all digits, lowercase and uppercase letters of the ISO basic Latin alphabet special characters /&amp;£ §+-\_.,:;!?'"=[]() and ␣, whereby different types of quotation marks and hyphens were mapped to one of the respective symbols.</p><p>Finally, the above alphabet is augmented by an artificial, not-a-character symbol, CITlab's NaC <ref type="foot" coords="4,195.32,539.90,3.97,6.16" target="#foot_2">3</ref> . In particular, it may be used to detect character boundaries because, generally speaking, our SPRNNs emit high NaC confidences in uncertain situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Training Data</head><p>The composition of the data set provided by the competition organizers is summarized in Table <ref type="table" coords="4,211.45,628.08,3.87,8.80" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Network Training</head><p>The network is trained using an extension of Nesterov's Accelerated Gradient Descent with learning rate 5e -4 and momentum 0.9. For each training epoch, we choose a random subset of 10,000 lines from the training set. The first 19 epochs were trained using the original images with a fixed learning rate. For 3 epochs we added noise to the preprocess parameters and network activations.</p><p>For 19 additional epochs we set the learning rate to 5e-5 and added degradation (pixel noise, blur, cross outs,...) to the images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8">Decoding Schemes</head><p>Word Matchings The neural networks output, the ConfMat, consists of confidences y t,l for any label l and position t where the labels are the characters and the NaC. The confidences are positive and sum to 1 for fixed position t. Thus, they can be interpreted as conditional probability for label l at position t given input image X X X. The number of positions is typically greater than the length of the decoded words such that different label sequences decode the same word. Following the original notation of <ref type="bibr" coords="5,316.42,453.52,9.96,8.80" target="#b1">[2]</ref>, let F be the function mapping a sequence of labels to a sequence of characters by merging consecutive identical labels and deleting NaCs. Instead of calculating the probability 5 of a string s s s, we calculate the maximum probability P(π π π * (s s s)|X X X) <ref type="foot" coords="5,355.65,487.83,3.97,6.16" target="#foot_4">6</ref> of any path collapsing to s s s (this corresponds to the Viterbi approximation for HMMs):</p><formula xml:id="formula_3" coords="5,239.42,521.68,136.52,30.20">P(π π π * (s s s)|X X X) = max π π π∈F -1 (s s s) T t=1 y t,πt .</formula><p>In the following, z z z denotes a single keyword. Since the ConfMat could contain more than one word, the path probability of z z z must be calculated on a specific submatrix: 5 To get the (CTC) probability one replaces the maximum operator by the sum:</p><formula xml:id="formula_4" coords="5,234.01,592.52,147.33,30.03">P s:e (π π π * (z z z)|X X X) = max π π π∈F -1 (z z z) e t=s y t,πt ,</formula><formula xml:id="formula_5" coords="5,144.73,641.68,131.59,13.24">P(s s s|X X X) = π π π∈F -1 (z z z) T t=1 yt,π t .</formula><p>where s and e are the start and end position of the submatrix within the ConfMat. Since y t,l &lt; 1 for any t, l, the path probability typically decreases if e -s increases. Thus, we accept a keyword z z z ranging from position s to e of a certain ConfMat if path probability relative to the number of positions P s:e (π π π * (z z z)|X X X)/(e -s + 1) is higher than a certain threshold.</p><p>To ensure that the match is not only part of a larger word, the word has to be separated by spaces, parentheses, hyphens etc. if it does not appear at the beginning or the end of a line. This pattern can be described by a regular expression:</p><formula xml:id="formula_6" coords="6,184.84,214.58,143.75,9.08">(.*[␣(-])? keyword ([␣)-].*)?</formula><p>. This search is accomplished using the decoder described in <ref type="bibr" coords="6,246.40,226.53,9.96,8.80" target="#b6">[7]</ref>. The result is a path π π π of length T aligned to the ConfMat positions. The indices s and e are determined by the subpath π π π s:e corresponding to the keyword (i.e. F(π π π s:e ) = z z z). Because of F, s and e are still not well defined since e.g. NaCs will be deleted. To avoid ambiguity, we use the most greedy subpath. Again, if the probability of the separators does not exceed a certain threshold, the match is assumed to be part of a larger word and it is rejected.</p><p>Multiple word queries are treated by searching the keywords individually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Incorporating Hyphens</head><p>The strategy above obviously does not work for hyphens since the keyword is spread over two ConfMats. To treat also hyphens, we search for pairs of consecutive ConfMats where the first ConfMat likely ends on a hyphen symbol and extract the submatrices containing the last word of the first matrix and the first word of second matrix. Both submatrices will be combined and the new ConfMat is added to the list of all ConfMats such that we can use the above strategy to search for hyphenated words in those combined matrices.</p><p>To search for ConfMats containing hyphenations, we simply search for hyphens at the end again using the RegEx-Decoder from <ref type="bibr" coords="6,386.59,447.27,9.96,8.80" target="#b6">[7]</ref>. The used regular expression is (.*␣)?[A-Za-z]+␣?-␣? which extracts the first part of the hyphenation and the hyphen at once. Score Many of the word matches are false positives and will influence the result in a negative way. The four evaluation measures penalize false matches with a high score more than false positives with a relatively low score. Therefore, a "good" score is crucial for a good evaluation.</p><p>The path probability P s:e (π π π * (z z z)|X X X) is an obvious score. This probability reflects the maximum confidence that the input contains the word z z z.</p><p>To our experience, the ability to learn dependencies between characters depends highly on the training data. If many variations appear in the trained character sequences, the network's output will depend only weakly on character transitions. Thus, the network will not be able to predict word priors. It rather predicts the character sequence as accurate as possible. To incorporate also word priors, we borrow some basic ideas from domain adaptation. The source domain S is the domain learned by the neural network which includes those weak dependencies on character sequences. The target domain T reflects the correct word statistics. For sake of simplicity, assume for the moment that all input images X X X reflect single word snippets. The only assumption of the below derivation is that P S (X X X|z z z) = P T (X X X|z z z) which basically means that the fonts are the same. The beauty of this approach is that the word distribution of training and test data may differ. By Bayes law, we know P T (z z z|X X X) = P S (z z z|X X X) p S (X X X) P S (z z z)</p><formula xml:id="formula_7" coords="7,272.37,186.37,208.23,51.02">P T (z z z) p T (X X X) = 1 N P T (z z z) P S (z z z) P S (z z z|X X X)<label>(1)</label></formula><p>where</p><formula xml:id="formula_8" coords="7,260.51,271.14,114.59,27.07">N = z z z P T (z z z ) P S (z z z ) P S (z z z |X X X).</formula><p>In principle, P T (z z z) could be any language model. In this task, we simply use a word unigram. The source prior P S (z z z) is a character transition probability learned by the neural network. We estimate P S (z z z) in three different ways:</p><p>-P S (z z z) = P T (z z z) thus target posterior is equal to the source posterior times the normalization. We refer to this prior scheme as abs. -P S (z z z) ∝ 1, thus only the prior is used. <ref type="foot" coords="7,327.39,374.45,3.97,6.16" target="#foot_5">7</ref> We refer to this prior scheme as prior.</p><formula xml:id="formula_9" coords="7,140.99,396.17,112.62,18.10">-P S (z z z) ∝ |z z z| i=1 P(z i ) c</formula><p>where z i is the character prior and 0 &lt; c ≤ 1. <ref type="foot" coords="7,458.75,401.50,3.97,6.16" target="#foot_6">8</ref> We refer to this prior scheme as da.</p><p>In last both schemes, prior and da, the prior probabilities are estimated up to a constant factor 1/N which is basically the reciprocal of the sum of the estimates of P S (z z z) over the finite set of all words z z z. We integrate N into N for both schemes.</p><p>If the written characters of one word do not influence those of another, it is reasonable to reestimate the word probability P s:e (z z z|X X X) within the positions from s to e of the ConfMat according to eq. ( <ref type="formula" coords="7,341.53,508.62,3.87,8.80" target="#formula_7">1</ref>). Then, the normalization for prior and da consists of the finite set of all word and part of word sequences fitting in this submatrix. In the same way, we reestimate the path probability P s:e (π π π * (z z z)|X X X).</p><p>To sort a set of words according to their probability on a specific submatrix of a given ConfMat, there is no need to calculate the normalization 1/N . The normalization is only crucial for comparing probabilities of different submatrices. To analyze the impact of the normalization, we submitted results with (normed) and without (unnormed) normalization. Typically, the vocabulary only represents a small part of all words of the considered language. Thus, it is impossible to sum all these feasible words. Words not contained in the vocabulary are called outof-vocabulary words (OOV words). Usually, the normalization constant N has to be approximated. <ref type="foot" coords="8,210.90,153.24,3.97,6.16" target="#foot_7">9</ref>Typically, our posterior probabilities are calculated using the path probability. To investigate the impact of using the path probability as an approximation of CTC we submitted comparable systems for both source posterior probabilities. Using the CTC scheme, we only use the path probability to calculate s and e. All the above equations we substitute the path probability P(π π π * (z z z)|X X X) by the CTC probability P(z z z|X X X). We refer to these posterior scheme as path or ctc, respectively.</p><p>Combining Keywords for Multiple Word Queries For single word queries, we are already done. The matches can be saved for six consecutive segments. For multiple word queries, all keywords have to be detected in a certain segment and the order how they appear has to be the same as in the query.</p><p>There is one score for each query. So the scores of the matches of multiple word queries has to be merged to one score. We tested the minimum, the arithmetic and geometric mean of the scores of each match. In our tests, arithmetic and geometric yield almost the same error rate while the minimum of all scores yielded significantly higher error rates. We worked with the geometric mean.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>This section reports the results of the Handwritten Scanned Document Retrieval Task 2016 . The experiments are designed to combine the described decoding components of Sect. 2.8:</p><p>posterior probability (path and ctc) prior probability (abs, prior and da) normalization (normed and unnormed)</p><p>We were restricted to submit only 10 systems. Since we usually use the probability of the most likely path instead of CTC probabilities, we skipped two decoding schemes which use the CTC posterior and are not normalized at the same time.</p><p>We are especially interested in the scores at segment level. The scores at box level highly depend on the precise detection of a bounding box of a keyword. Since this is out of our scope we concentrate our investigations on the segment score. To get an impression of the differences, we refer to Table <ref type="table" coords="8,408.84,579.64,4.98,8.80" target="#tab_3">4</ref> in Appendix A showing the same results as Table <ref type="table" coords="8,283.46,591.59,4.98,8.80" target="#tab_1">2</ref> only on box level. Appendix A also contains the results of subsets of the keyword queries such as hyphenated or OOV words for both the development and the test set.</p><p>Additionally, we submitted search results obtained by a neural network trained with additional external data. Unfortunately, we accidentally also used data from the HTRtS15 training set with overlaps with the development data set. The resulting network yields improved results on the development set. Other additional training data seems to fit poorly to the test data and thus confused the network. Thus, the recognition rates on the test set decrease.  Normalization The Tables <ref type="table" coords="10,264.08,118.93,4.98,8.80" target="#tab_1">2</ref> and<ref type="table" coords="10,292.49,118.93,4.98,8.80" target="#tab_2">3</ref> show the impact of the normalization on the four different measures. Normalizing the probabilities typically improves the recognition score except for one configuration: If the source prior is equal to the target prior (i.e. abs). Then the normalization can be counterproductive if the data is different from the trained data. The network is trained to optimize the unnormalized CTC probability. So it is not surprising that the system works well if we use only the source posterior probability as score. If the network output gets blurry (because of e.g. untrained writing styles), alternative results become more likely compared to the proposed result. The normalization value will grow for keywords which have a small edit distance to many other vocabulary words. Thus, if the network is not able to make clear decisions, the normalization value will much more depend on the keyword position in the vocabulary. Even for the development set -where the data seems to fit the training data well -the gain from the normalization is not significant. Thus, the normalization can be omitted using the abs decoding scheme.</p><p>If source and target prior differ, the posterior scale changes depending on the word. Thus for different keywords, the scores are not comparable anymore. The normalization maps the scores into the same range. Therefore, normalization increases the recognition rate by around 7 gAP points for prior and da schemes at test set (Table <ref type="table" coords="10,213.20,346.94,3.87,8.80" target="#tab_2">3</ref>).</p><p>All other tables show the same behavior. Therefore, we omit the row with the unnormalized decoding schemes in Table <ref type="table" coords="10,332.77,371.70,4.98,8.80" target="#tab_3">4</ref> -8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Path vs. CTC Probability</head><p>The network is trained to optimize the CTC posterior likelihood. Thus, it is not surprising that the CTC probability is typically slightly better (less than 0.6 gAP points on the test set 3) than the path probability except for few experimental setups: The box level gAP on the development set (Table <ref type="table" coords="10,217.69,453.68,4.43,8.80" target="#tab_3">4</ref>) and the gAP on the development set restricted to broken words (Table <ref type="table" coords="10,194.91,465.63,3.87,8.80" target="#tab_4">5</ref>). A query match may contain additional false keyword matches although the query match on segment level is correct. These additional false matches are penalized by the gAP on box level. Since the CTC probability is typically higher than the path probability and the rejection thresholds stays constant, there are more additional false keyword matches within a query match. So the error increases for the CTC probability.</p><p>Finally, the gap between path and CTC posterior probability is small for all experiments. The path probability also preserves the relation between the source prior and normalization decoding schemes. Thus, the path probability is a good approximation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Priors</head><p>The evaluation is even less clear than the one above. The results do not only depend on different experimental setups (i.e. different tables) but also they highly depend on the measure. Considering the development set (Table <ref type="table" coords="10,451.53,632.15,3.87,8.80" target="#tab_1">2</ref>), the prior scheme works slightly better (less than 0.6 gAP points) than abs and da. The mAP measure puts more weight on the infrequent words. Thus, the abs decoding scheme works better than the prior decoding scheme which naturally favors frequent words.</p><p>Compared to the development set, the results on the test set gain more from including prior knowledge since the posterior probabilities are less reliable. Especially, if the gAP value is measured, the da scheme yields better results (greater than 3 gAP points) than the others. Measuring the mAP, the prior decoding scheme is slightly better (less than 0.2 mAP points compared to da).</p><p>In Table <ref type="table" coords="11,190.99,202.71,3.87,8.80" target="#tab_7">8</ref>, the da scheme yields the lowest error rates independent of the measure. This may indicate that the OOV prior could be improved. The current estimation of an OOV prior is constant for all OOV words. For future research, we plan to investigate a more sophisticated OOV prior such as a character ngram of small order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper we present the fundamental concepts of our systems submitted to the Handwritten Scanned Document Retrieval Task 2016 attached to the CLEF in 2016. We submitted 10 systems comparing different rescoring strategies.</p><p>Unfortunately, there is no winning rescoring strategy. Normalization almost always improves the score and typically the score is slightly better when using the CTC posterior probability compared to the probability of the most likely path. Nevertheless, the probability of the most likely path is a good approximation to the CTC probability. Using domain adaptation to switch from the learned source domain to the target domain, we scale the posterior probability by the target prior -source prior ratio. Fixing the target prior (as unigram probability), we vary the source prior. For all three tested source priors there are setups where the way of calculating this specific prior is preferable. This might indicate that the estimated prior does not fit the prior learned by the neural network. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Additional Tables</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,134.77,268.37,345.83,8.80"><head></head><label></label><figDesc>Fig. 1: Comparison of the baseline to polygon approach for different medial seams</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,148.07,127.30,319.22,78.44"><head>Table 1 :</head><label>1</label><figDesc>Composition of the data sets provided by the organizers</figDesc><table coords="5,148.07,152.60,319.22,53.15"><row><cell></cell><cell>#pages</cell><cell>#lines</cell><cell>#characters</cell><cell>polygons</cell><cell>baselines</cell></row><row><cell>training set</cell><cell>363</cell><cell>9645</cell><cell>65488</cell><cell>yes</cell><cell>no</cell></row><row><cell>development set</cell><cell>433</cell><cell>10589</cell><cell>80758</cell><cell>yes</cell><cell>no</cell></row><row><cell>test set</cell><cell>200</cell><cell>6355</cell><cell>-</cell><cell>no 4</cell><cell>yes</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,134.77,230.54,351.28,160.39"><head>Table 2 :</head><label>2</label><figDesc>Results on the development set on segment level for the MDRNN trained only on the training set</figDesc><table coords="9,142.74,268.78,343.31,122.14"><row><cell></cell><cell>source prior</cell><cell></cell><cell>abs</cell><cell cols="2">prior</cell><cell>da</cell><cell></cell></row><row><cell></cell><cell>source posterior</cell><cell>path</cell><cell>ctc</cell><cell>path</cell><cell>ctc</cell><cell>path</cell><cell>ctc</cell></row><row><cell>gAP</cell><cell>normed unnormed</cell><cell>94.81 94.77</cell><cell>94.89</cell><cell>95.36 91.73</cell><cell>95.42 91.87</cell><cell>94.99 92.58</cell><cell>95.04</cell></row><row><cell>mAP</cell><cell>normed unnormed</cell><cell>89.71 89.42</cell><cell>89.90</cell><cell>89.58 88.59</cell><cell>89.76 88.89</cell><cell>89.63 89.13</cell><cell>89.82</cell></row><row><cell>gNDCG</cell><cell>normed unnormed</cell><cell>96.72 96.69</cell><cell>96.78</cell><cell>96.78 96.34</cell><cell>96.83 96.41</cell><cell>96.73 96.46</cell><cell>96.77</cell></row><row><cell>mNDCG</cell><cell>normed unnormed</cell><cell>90.77 90.61</cell><cell>90.97</cell><cell>90.66 89.96</cell><cell>90.85 90.25</cell><cell>90.70 90.36</cell><cell>90.89</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,134.77,472.73,351.28,151.42"><head>Table 3 :</head><label>3</label><figDesc>Results on the test set on segment level for the MDRNN trained only on the training set</figDesc><table coords="9,142.74,510.97,343.31,113.17"><row><cell></cell><cell>source prior</cell><cell>abs</cell><cell></cell><cell cols="2">prior</cell><cell>da</cell><cell></cell></row><row><cell></cell><cell>source posterior</cell><cell>path</cell><cell>ctc</cell><cell>path</cell><cell>ctc</cell><cell>path</cell><cell>ctc</cell></row><row><cell>gAP</cell><cell>normed unnormed</cell><cell>33.89 42.21</cell><cell>33.98</cell><cell>43.20 36.17</cell><cell>43.72 36.30</cell><cell>46.74 39.65</cell><cell>47.13</cell></row><row><cell>mAP</cell><cell>normed unnormed</cell><cell>38.62 38.18</cell><cell>39.46</cell><cell>39.10 36.50</cell><cell>40.03 37.13</cell><cell>39.19 37.91</cell><cell>39.89</cell></row><row><cell>gNDCG</cell><cell>normed unnormed</cell><cell>59.39 61.14</cell><cell>60.03</cell><cell>61.40 59.70</cell><cell>62.14 60.37</cell><cell>61.98 60.62</cell><cell>62.70</cell></row><row><cell>mNDCG</cell><cell>normed unnormed</cell><cell>40.57 40.22</cell><cell>41.40</cell><cell>40.96 38.85</cell><cell>41.86 39.51</cell><cell>41.05 40.04</cell><cell>41.73</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="13,134.77,171.90,354.46,107.59"><head>Table 4 :</head><label>4</label><figDesc>Results on the development set on box level for the MDRNN trained only on the training set</figDesc><table coords="13,142.74,210.14,346.49,69.34"><row><cell></cell><cell>source prior</cell><cell></cell><cell>abs</cell><cell cols="2">prior</cell><cell>da</cell><cell></cell></row><row><cell></cell><cell>source posterior</cell><cell>path</cell><cell>ctc</cell><cell>path</cell><cell>ctc</cell><cell>path</cell><cell>ctc</cell></row><row><cell>gAP</cell><cell>normed</cell><cell>72.73</cell><cell>72.31</cell><cell>73.40</cell><cell>72.92</cell><cell>70.87</cell><cell>70.54</cell></row><row><cell>mAP</cell><cell>normed</cell><cell>72.88</cell><cell>72.94</cell><cell>72.92</cell><cell>72.87</cell><cell>72.42</cell><cell>72.25</cell></row><row><cell>gNDCG</cell><cell>normed</cell><cell>75.42</cell><cell>75.20</cell><cell>75.63</cell><cell>75.38</cell><cell>74.73</cell><cell>74.43</cell></row><row><cell>mNDCG</cell><cell>normed</cell><cell>75.93</cell><cell>76.00</cell><cell>75.99</cell><cell>76.02</cell><cell>75.72</cell><cell>75.65</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="13,134.77,347.96,354.45,107.59"><head>Table 5 :</head><label>5</label><figDesc>Results on the development set only for broken words on segment level for the MDRNN trained only on the training set</figDesc><table coords="13,142.74,386.21,346.48,69.34"><row><cell></cell><cell>source prior</cell><cell>abs</cell><cell></cell><cell cols="2">prior</cell><cell>da</cell><cell></cell></row><row><cell></cell><cell>source posterior</cell><cell>path</cell><cell>ctc</cell><cell>path</cell><cell>ctc</cell><cell>path</cell><cell>ctc</cell></row><row><cell>gAP</cell><cell>normed</cell><cell>60.86</cell><cell>60.47</cell><cell>60.60</cell><cell>60.09</cell><cell>59.35</cell><cell>59.35</cell></row><row><cell>mAP</cell><cell>normed</cell><cell>48.96</cell><cell>49.61</cell><cell>48.28</cell><cell>48.64</cell><cell>47.85</cell><cell>48.44</cell></row><row><cell>gNDCG</cell><cell>normed</cell><cell>75.10</cell><cell>75.03</cell><cell>76.55</cell><cell>76.43</cell><cell>75.98</cell><cell>75.98</cell></row><row><cell>mNDCG</cell><cell>normed</cell><cell>50.07</cell><cell>50.75</cell><cell>49.36</cell><cell>49.76</cell><cell>49.02</cell><cell>49.52</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="14,134.77,150.47,351.28,107.59"><head>Table 6 :</head><label>6</label><figDesc>Results on the development set only for OOV words on segment level for the MDRNN trained only on the training set</figDesc><table coords="14,142.74,188.72,343.31,69.34"><row><cell></cell><cell>source prior</cell><cell>abs</cell><cell></cell><cell cols="2">prior</cell><cell>da</cell><cell></cell></row><row><cell></cell><cell>source posterior</cell><cell>path</cell><cell>ctc</cell><cell>path</cell><cell>ctc</cell><cell>path</cell><cell>ctc</cell></row><row><cell>gAP</cell><cell>normed</cell><cell>88.57</cell><cell>88.98</cell><cell>89.31</cell><cell>89.66</cell><cell>89.01</cell><cell>89.28</cell></row><row><cell>mAP</cell><cell>normed</cell><cell>88.43</cell><cell>88.71</cell><cell>87.83</cell><cell>88.36</cell><cell>88.31</cell><cell>88.86</cell></row><row><cell>gNDCG</cell><cell>normed</cell><cell>92.08</cell><cell>92.42</cell><cell>92.19</cell><cell>92.52</cell><cell>92.16</cell><cell>92.47</cell></row><row><cell>mNDCG</cell><cell>normed</cell><cell>89.18</cell><cell>89.48</cell><cell>88.65</cell><cell>89.20</cell><cell>88.98</cell><cell>89.53</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="14,134.77,335.49,351.28,107.59"><head>Table 7 :</head><label>7</label><figDesc>Results on the test set only for broken words on segment level for the MDRNN trained only on the training set</figDesc><table coords="14,142.74,373.74,343.31,69.34"><row><cell></cell><cell>source prior</cell><cell>abs</cell><cell></cell><cell cols="2">prior</cell><cell>da</cell><cell></cell></row><row><cell></cell><cell>source posterior</cell><cell>path</cell><cell>ctc</cell><cell>path</cell><cell>ctc</cell><cell>path</cell><cell>ctc</cell></row><row><cell>gAP</cell><cell>normed</cell><cell>16.69</cell><cell>16.98</cell><cell>19.64</cell><cell>20.21</cell><cell>23.56</cell><cell>24.33</cell></row><row><cell>mAP</cell><cell>normed</cell><cell>22.65</cell><cell>23.63</cell><cell>22.9</cell><cell>23.83</cell><cell>22.81</cell><cell>23.73</cell></row><row><cell>gNDCG</cell><cell>normed</cell><cell>33.46</cell><cell>34.29</cell><cell>34.56</cell><cell>35.52</cell><cell>35.81</cell><cell>36.84</cell></row><row><cell>mNDCG</cell><cell>normed</cell><cell>23.35</cell><cell>24.4</cell><cell>23.53</cell><cell>24.51</cell><cell>23.47</cell><cell>24.45</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="14,134.77,520.51,348.10,107.59"><head>Table 8 :</head><label>8</label><figDesc>Results on the test set only for OOV words on segment level for the MDRNN trained only on the training set</figDesc><table coords="14,142.74,558.76,340.13,69.34"><row><cell></cell><cell>source prior</cell><cell>abs</cell><cell></cell><cell cols="2">prior</cell><cell>da</cell><cell></cell></row><row><cell></cell><cell>source posterior</cell><cell>path</cell><cell>ctc</cell><cell>path</cell><cell>ctc</cell><cell>path</cell><cell>ctc</cell></row><row><cell>gAP</cell><cell>normed</cell><cell>28.55</cell><cell>28.78</cell><cell>37.97</cell><cell>38.61</cell><cell>41.92</cell><cell>42.59</cell></row><row><cell>mAP</cell><cell>normed</cell><cell>38.21</cell><cell>38.89</cell><cell>38.7</cell><cell>39.31</cell><cell>38.9</cell><cell>39.53</cell></row><row><cell>gNDCG</cell><cell>normed</cell><cell>52.69</cell><cell>53.07</cell><cell>55.27</cell><cell>55.79</cell><cell>56.2</cell><cell>56.67</cell></row><row><cell>mNDCG</cell><cell>normed</cell><cell>39.89</cell><cell>40.52</cell><cell>40.38</cell><cell>40.95</cell><cell>40.54</cell><cell>41.12</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,646.58,151.14,7.37"><p>http://www.citlab.uni-rostock.de</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,144.73,657.54,94.15,7.37"><p>http://www.planet.de</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,144.73,645.79,235.82,7.92"><p>In the literature it is also called blank, no-symbol, no-label.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,144.73,656.74,262.64,7.92"><p>There exist polygons but they are not accurate enough for using.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4" coords="5,144.73,656.74,114.05,7.92;5,253.70,656.54,5.48,8.12;5,259.51,655.03,3.82,5.24;5,263.82,656.74,7.47,7.92;5,267.20,656.54,127.46,8.12"><p>In the following, we call P(π π π * (s s s)|X X X) the path probability of s s s.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5" coords="7,144.73,623.87,335.86,7.92;7,144.73,634.83,133.02,7.92;7,273.67,634.62,24.74,8.12;7,298.40,632.90,8.34,5.45;7,310.31,634.83,30.49,7.92;7,336.72,634.62,24.74,8.12;7,361.46,633.11,4.37,5.24"><p>It would be statistically more reasonable to model the character/label probability by some constant such that PS (z z z) = c |z z z| or PS (z z z) = c T</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6" coords="7,144.73,645.79,335.86,7.92;7,144.73,656.74,30.61,7.92"><p>In the submitted system, this character priors are estimated on the training set and c = 0.5.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_7" coords="8,144.73,634.83,143.15,7.92"><p>In our experiments, we sum up the</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_8" coords="8,303.88,634.83,176.70,7.92;8,144.73,645.79,335.86,7.92;8,144.73,656.74,35.12,7.92"><p>most likely vocabulary matches plus an additional OOV term if the best string (also raw output) is not contained in those matches.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>First of all, the CITlab team really wishes to express its great gratitude to our long-term technology &amp; development partner PLANET intelligent systems GmbH (<rs type="person">Raben Steinfeld</rs> <rs type="institution">&amp; Rostock, Germany</rs>) for the extremely valuable, ongoing support in every aspect of this work. Participating in Handwritten Scanned Document Retrieval Task 2016 would not have been possible without that! In particular, we continued using PLANET's software world which was developed and essentially improved in various common CITlab-PLANET projects over previous years.</p><p>From PLANET's side, our activities were essentially supported by <rs type="person">Jesper Kleinjohann</rs> and <rs type="person">Richard Schwark</rs>, whom we especially thank for ongoing very helpful discussions and his continuous development support.</p><p>Being part of our current research &amp; development collaboration project, the development work was funded by grant no. <rs type="grantNumber">KF2622304SS3</rs> (<rs type="grantNumber">Kooperationsprojekt</rs>) in <rs type="funder">Zentrales Innovationsprogramm Mittelstand</rs> (ZIM) by <rs type="funder">Bundesrepublik Deutschland (BMWi)</rs>. The contest application has been adapted while working in the <rs type="programName">EU Horizon 2020 project READ -Recognition and Enrichment</rs> <rs type="projectName">of Archival Documents</rs> (official no. <rs type="grantNumber">674943</rs>).</p><p>Finally, we are indebted to the competition organizers from the <rs type="institution">PRHLT group at UPV</rs> -in particular <rs type="person">Mauricio Villegas</rs> -for setting up this evaluation and the contest as well as the entire tranScriptorium project for providing all the data.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_t5ZyutP">
					<idno type="grant-number">KF2622304SS3</idno>
				</org>
				<org type="funding" xml:id="_YM6cEDR">
					<idno type="grant-number">Kooperationsprojekt</idno>
				</org>
				<org type="funded-project" xml:id="_2ZJAvs9">
					<idno type="grant-number">674943</idno>
					<orgName type="project" subtype="full">of Archival Documents</orgName>
					<orgName type="program" subtype="full">EU Horizon 2020 project READ -Recognition and Enrichment</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="12,142.96,231.81,337.63,7.92;12,151.52,242.77,329.07,7.92;12,151.52,253.73,307.61,7.92" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,293.87,231.81,186.72,7.92;12,151.52,242.77,148.93,7.92">Seam carving for text line extraction on color and grayscale historical manuscripts</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Arvanitopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Susstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,325.00,242.77,155.60,7.92;12,151.52,253.73,34.49,7.92;12,215.51,253.73,131.89,7.92">Frontiers in Handwriting Recognition (ICFHR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="726" to="731" />
		</imprint>
	</monogr>
	<note>14th International Conference on</note>
</biblStruct>

<biblStruct coords="12,142.96,264.42,337.64,7.92;12,151.52,275.38,329.07,7.92;12,151.52,286.34,329.07,7.92;12,151.52,297.30,69.88,7.92" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,385.21,264.42,95.38,7.92;12,151.52,275.38,324.83,7.92">Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,165.16,286.34,275.05,7.92">Proceedings of the 23rd international conference on Machine learning</title>
		<meeting>the 23rd international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="369" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,307.99,337.63,7.92;12,151.52,318.95,329.07,7.92;12,151.52,329.91,329.07,8.17;12,151.52,341.67,80.03,7.37" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="12,344.20,307.99,136.39,7.92;12,151.52,318.95,329.07,7.92;12,151.52,329.91,15.40,7.92">CITlab ARGUS for historical data tables: Description of CITlab&apos;s system for the ANWRESH-2014 Word Recognition task</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Leifert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Grüning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strauß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Labahn</surname></persName>
		</author>
		<idno>2014/1</idno>
		<ptr target="http://arXiv.org/abs/1412.6012" />
		<imprint>
			<date type="published" when="2014-04">Apr 2014</date>
		</imprint>
		<respStmt>
			<orgName>Universität Rostock</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="12,142.96,351.56,337.63,7.92;12,151.52,362.52,329.07,7.92;12,151.52,373.48,329.07,7.92;12,151.52,384.44,329.07,8.17;12,151.52,396.20,127.10,7.37" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,300.10,351.56,180.49,7.92;12,151.52,362.52,329.07,7.92;12,151.52,373.48,34.57,7.92">CITlab ARGUS for arabic handwriting: Description of CITlab&apos;s system for the OpenHaRT 2013 Document Image Recognition task</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Leifert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Labahn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strauß</surname></persName>
		</author>
		<ptr target="http://www.nist.gov/itl/iad/mig/hart2013_wrkshp.cfm" />
	</analytic>
	<monogr>
		<title level="m" coord="12,207.54,373.48,214.75,7.92">Proceedings of the NIST 2013 OpenHaRT Workshop</title>
		<meeting>the NIST 2013 OpenHaRT Workshop</meeting>
		<imprint>
			<date type="published" when="2013-08">Aug 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,406.09,337.64,7.92;12,151.52,417.05,329.07,7.92;12,151.52,428.01,121.70,7.92" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="12,351.49,406.09,129.10,7.92;12,151.52,417.05,80.29,7.92">Cells in multidimensional recurrent neural networks</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Leifert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strauß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Grüning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Labahn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.2620</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>submitted to Journal of Machine Learning Research</note>
</biblStruct>

<biblStruct coords="12,142.96,438.70,337.64,7.92;12,151.52,449.66,329.07,7.92;12,151.52,460.62,329.07,7.92;12,151.52,471.58,158.00,7.92" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="12,358.85,438.70,121.75,7.92;12,151.52,449.66,329.07,7.92;12,151.52,460.62,282.29,7.92">CITlab ARGUS for historical handwritten documents -Description of CITlab&apos;s System for the HTRtS 2015 Task : Handwritten Text Recognition on the tranScriptorium Dataset</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Leifert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strauß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Grüning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Labahn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015-04">Apr 2015</date>
		</imprint>
		<respStmt>
			<orgName>Universität Rostock</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="12,142.96,482.27,337.63,7.92;12,151.52,493.23,329.07,8.17;12,151.52,504.99,287.15,7.37" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,366.05,482.27,114.54,7.92;12,151.52,493.23,139.61,7.92">Regular expressions for decoding of neural network outputs</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strauß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Leifert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Grüning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Labahn</surname></persName>
		</author>
		<ptr target="http://www.sciencedirect.com/science/article/pii/S0893608016000447" />
	</analytic>
	<monogr>
		<title level="j" coord="12,300.18,493.23,69.23,7.92">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,514.89,337.64,7.92;12,151.52,525.85,329.07,7.92;12,151.52,536.80,329.07,7.92;12,151.52,547.76,168.87,8.17" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="12,358.85,514.89,121.75,7.92;12,151.52,525.85,329.07,7.92;12,151.52,536.80,118.13,7.92">CITlab ARGUS for historical handwritten documents: Description of CITlab&apos;s system for the HTRtS 2014 Handwritten Text Recognition task</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strauß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Grüning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Leifert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Labahn</surname></persName>
		</author>
		<idno>2014/2</idno>
		<ptr target="http://arXiv.org/abs/1412.3949" />
		<imprint>
			<date type="published" when="2014-04">Apr 2014</date>
		</imprint>
		<respStmt>
			<orgName>Universität Rostock</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="12,142.96,558.46,337.64,7.92;12,151.52,569.42,329.07,7.92;12,151.52,580.38,329.07,7.92;12,151.52,591.33,329.07,7.92;12,151.52,602.29,198.38,7.92" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,449.27,580.38,31.32,7.92;12,151.52,591.33,206.00,7.92">General Overview of ImageCLEF at the CLEF 2016 Labs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schaer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ramisa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Dellandrea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">H</forename><surname>Toselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="12,366.21,591.33,114.38,7.92;12,151.52,602.29,27.78,7.92">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,612.99,337.98,7.92;12,151.52,623.95,329.08,7.92;12,151.52,634.91,329.07,7.92;12,151.52,645.86,192.14,7.92" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,417.90,612.99,62.70,7.92;12,151.52,623.95,264.60,7.92">Overview of the ImageCLEF 2016 Handwritten Scanned Document Retrieval Task</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">H</forename><surname>Toselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Vidal</surname></persName>
		</author>
		<ptr target="org&lt;http://ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="m" coord="12,437.46,623.95,43.13,7.92;12,151.52,634.91,250.65,7.92">CLEF2016 Working Notes. CEUR Workshop Proceedings, CEUR-WS</title>
		<meeting><address><addrLine>Évora, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-08">September 5-8 2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
