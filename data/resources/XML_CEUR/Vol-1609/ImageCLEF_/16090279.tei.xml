<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,173.46,116.95,268.44,12.62;1,181.10,134.89,253.17,12.62">DUTh at the ImageCLEF 2016 Image Annotation Task: Content Selection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,204.07,172.56,67.15,8.74"><forename type="first">Georgios</forename><surname>Barlas</surname></persName>
							<email>gbarlas@ee.duth.gr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution" key="instit1">Democritus</orgName>
								<orgName type="institution" key="instit2">University of Thrace</orgName>
								<address>
									<postCode>67 100</postCode>
									<settlement>Xanthi</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,278.89,172.56,55.65,8.74"><forename type="first">Maria</forename><surname>Ntonti</surname></persName>
							<email>mntonti@ee.duth.gr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution" key="instit1">Democritus</orgName>
								<orgName type="institution" key="instit2">University of Thrace</orgName>
								<address>
									<postCode>67 100</postCode>
									<settlement>Xanthi</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,342.30,172.56,68.99,8.74"><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution" key="instit1">Democritus</orgName>
								<orgName type="institution" key="instit2">University of Thrace</orgName>
								<address>
									<postCode>67 100</postCode>
									<settlement>Xanthi</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,173.46,116.95,268.44,12.62;1,181.10,134.89,253.17,12.62">DUTh at the ImageCLEF 2016 Image Annotation Task: Content Selection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">411CAC7E65644A7738046D975D89200E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This report describes our experiments in the Content Selection subtask of the Image Annotation task of ImageClef 2016 <ref type="bibr" coords="1,405.63,266.43,12.07,7.86" target="#b6">[7,</ref><ref type="bibr" coords="1,419.23,266.43,10.75,7.86" target="#b12">13]</ref>. Our approach is based on the fact that the human visual system concentrates mostly on local features <ref type="bibr" coords="1,262.48,288.35,13.52,7.86" target="#b11">[12]</ref>. In this respect, we trained an SVM classifier with descriptors that are based on the local features of the image, such as edges and corners. For the experimentation process we used the set of 500 images provided for the task, divided into training and test set. This set was particularly created for this year's new subtask, Content Selection, although the concepts are the same as last year. Through experimentation we determine which descriptors give the best results for the given task. To conduct the main experiment the SVM classifier is trained with the aforementioned set of 500 images using a subset of the top-performing features. Consecutively, the SVM processes the new set of 450 images and selects the boxes that best describe them conceptually.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Content Selection is the intermediate step between identifying objects of an image and generating a natural language caption. The objective of this task is to identify which bounded objects of the image are important so as to be included in the annotator's caption. In addition, since each object is labeled, the result would be a conceptually accurate description of the image. As requested by the ImageCLEF competition we developed a system that receives as input labeled objects of an image and identifies the objects that are referred to in the corresponding image caption. Since participants of the content selection subtask have concentrated so far on using only text features or bounding box information, this paper may provide a novel contribution in exploring features based on visual keypoints only. We are not aware of another work with keypoints being used in our ways (e.g. ratio of keypoints in bounding boxes to keypoints in image).</p><p>Our approach relies on finding suitable descriptors, from the given data, in order to train an SVM classifier. In this work we followed an image-only approach without processing the textual information provided as groundtruth. Inspired by the fact that the human visual system concentrates mostly on local features, we incorporated several such descriptors using well known algorithms of image processing. Thereby we created a set of 17 descriptors and grouped them into several subsets referring to similar features. Then, after experimenting with descriptors standalone and as groups, we arrived to a set of 9 most-useful descriptors.</p><p>Complementary to testing for different feature subsets, experiments were also conducted using various SVM kernel functions. Linear, polynomial and Gaussian radial basis function kernels were tested. Polynomial and Gaussian kernels performed similarly, but the latter one was chosen as it produced slightly better results.</p><p>The rest of this report is organized as follows. In the next section we describe the dataset provided as well as the methodology we followed to tackle the problem. Specifically, we analyze the descriptors that were used during experimentation and describe the SVM classifier. Section 3 describes the evaluation methodology along with our the experimental results. Conclusion and directions for further research are summarized in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data and Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dataset</head><p>The dataset provided by the ImageCLEF competition consists of 500 images from various concepts, accompanied with a set of bounding boxes for each image and a label for each box. Furthermore, a set of textual descriptions is given for each image as ground-truth with a minimum of 5 and a mean of 9.5 sentences per image <ref type="bibr" coords="2,183.05,430.24,9.96,8.74" target="#b6">[7]</ref>. This set was initially split into a training and a validation set and was used for experimentation. After experimentally concluding to the best configuration the whole set was used to train the SVM classifier. A second set of 450 images was later released by ImageCLEF which was used as the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Feature Extraction</head><p>Initially, 17 descriptors were created. After experimentation we concluded to a subset of 9 that was found to have the maximum contribution. Correlation information between the descriptors and the purpose of each one was used to cluster them into categories. In the rest of this section, we will elaborate on each descriptor category.</p><p>Position Desctiptors For each bounding box, two points are given that define its position in the image. The coordinates of these points are used individually as four values x min , x max , y min , y max , divided by the corresponding dimension of the image, as follows:</p><formula xml:id="formula_0" coords="3,284.79,134.34,44.64,38.24">d 1 = x min w d 2 =</formula><p>x max w</p><formula xml:id="formula_1" coords="3,284.79,178.03,44.93,44.16">d 3 = y min h d 4 = y max h</formula><p>where w, h denote the width and the height of the image, respectively. Additionally, two more features are formed that correspond to the relative position of the center of the bounding box, abscissa and ordinate respectively:</p><formula xml:id="formula_2" coords="3,280.10,292.27,55.12,46.79">d 5 = d 1 + d 2 2 d 6 = d 3 + d 4<label>2</label></formula><p>The purpose of those descriptors is to investigate the correlation between the position of the bounding box and the importance of it <ref type="bibr" coords="3,374.50,368.25,9.96,8.74" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Size Descriptors</head><p>The descriptors of this group aim to calculate the portion of the image that is occupied by the bounding box, separately for the two dimensions and combined as well.</p><formula xml:id="formula_3" coords="3,287.38,451.49,41.75,60.06">d 7 = w b w d 8 = h b h d 9 = d 7 d 8</formula><p>where w b , h b denote the width and height of the bounding box, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Descriptors based on Local Features</head><p>For the calculation of the descriptors of this group we used several well-established algorithms for local feature detection (i.e. the Canny edge detector <ref type="bibr" coords="3,281.75,597.34,9.96,8.74" target="#b1">[2]</ref>, Harris and Stephens <ref type="bibr" coords="3,387.74,597.34,9.96,8.74" target="#b7">[8]</ref>, BRISK <ref type="bibr" coords="3,437.74,597.34,9.96,8.74" target="#b8">[9]</ref>, SURF <ref type="bibr" coords="3,134.77,609.29,10.52,8.74" target="#b0">[1]</ref> and FAST <ref type="bibr" coords="3,196.75,609.29,14.76,8.74" target="#b10">[11]</ref>). These algorithms imitate the way that human processes visual information. The calculated features are based on the hypothesis that an elevated number of the key-points or key-regions detected will be located in conceptually important boxes. Towards this direction we propose the calculation of the percentage of the image local features detected in each box. </p><formula xml:id="formula_4" coords="4,264.54,182.46,86.24,77.66">d 12 = BRISK box BRISK image d 13 = SU RF box SU RF image d 14 = F AST box F AST image</formula><p>Entropy Descriptors Image entropy is a quantity that is used to describe the amount of information that is contained in an image. In this regard, the motivation behind this feature group is to quantify the amount of information held by the content of a bounding box, proportionally to that of the image.</p><p>As a first step we produced three different versions of the image. The first two correspond to the edge maps generated by the Canny edge detector <ref type="bibr" coords="4,433.46,339.34,10.52,8.74" target="#b1">[2]</ref> and the Structured Forests edge detection method (ESF) <ref type="bibr" coords="4,352.33,351.29,9.96,8.74" target="#b4">[5]</ref>, respectively. The last one corresponds to the image reduced to gray-level pixel values. Consecutively, we calculate the entropy contained by a bounding box in all three images divided by the total entropy of the image.</p><formula xml:id="formula_5" coords="4,252.12,407.90,111.57,79.68">d 15 = E(Canny box ) E(Canny image ) d 16 = E(ESF box ) E ( ESF image ) d 17 = E(Grayscale box ) E(Grayscale image )</formula><p>where E(x) denotes the entropy of an image x, defined as</p><formula xml:id="formula_6" coords="4,250.37,516.94,114.62,30.32">E(x) = - N i=1 h(i) log 2 h(i)</formula><p>where h(i) is the count of pixels assigned to the ith bin of the image histogram and N the total number of bins.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Support Vector Machine (SVM) Classification</head><p>For the purpose of this task, we trained a binary SVM in order to classify each bounding box as 'important' or 'not important'. SVM tackles the problem of nonliner classification by determining a hyperplane that separates two classes in a space of higher dimensionality than the feature space using a kernel function <ref type="bibr" coords="4,470.08,657.11,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="5,134.77,119.99,7.01,8.74" target="#b3">4]</ref>. We used MATLAB's default function to train and use the SVM. For improved performance, we experimented with different kernel functions, such as the Linear, the Polynomial and the Gaussian radial basis kernel functions, concluding to the Gaussian kernel as the top performing.</p><p>During the experiments, the training dataset was divided into two subsets, the training and the validation subset, respectively. We experimented with training subsets of 100 and 250 images randomly selected. We investigated the performance of different sets of descriptors, concluding to a set of 9. Table <ref type="table" coords="5,436.95,203.68,4.98,8.74" target="#tab_0">1</ref> presents the results of the experiments with different configurations.</p><p>In the cases where the SVM classified a small number of the boxes as important, we used the SURF descriptor as criterion for the selection. Specifically, if the result contained less than two boxes, then the n 2 + 3 boxes with the biggest d 13 value were added to result set, where n is the number of boxes in the image. In case the image contained less than n 2 +3 boxes, then all of them were selected. The number n 2 + 3 was selected after experimentation. We initially started with number n 2 and then concluded to n 2 + 3.</p><p>3 Experimental Evaluation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluation Measures</head><p>According to the instructions, Subtask 3 is evaluated using the content selection metric, which is the F 1 score averaged across all test images. Each F 1 score is computed from the precision and recall metrics averaged over all gold standard descriptions for the image. The precision P Ii for test image I i is computed as:</p><formula xml:id="formula_7" coords="5,252.61,433.26,227.98,30.20">P Ii = 1 M M m=1 |G Ii m ∩ S Ii | |S Ii |<label>(1)</label></formula><p>The recall R ( I i ) for test image I i is computed as:</p><formula xml:id="formula_8" coords="5,252.68,491.31,227.91,30.20">R Ii = 1 M M m=1 |G Ii m ∪ S Ii | |G Ii m |<label>(2)</label></formula><p>where</p><formula xml:id="formula_9" coords="5,139.75,546.10,180.81,22.16">I = {I 1 , I 2 , . . . , I N } the set of test images G Ii = {G Ii 1 , G Ii 2 , .</formula><p>. . , G Ii M } the set of gold standard descriptions S Ii the resulting set of unique bounding box instances M the number of gold standard descriptions for image I i .</p><p>The content selection score F Ii for image I i , is computed as:</p><formula xml:id="formula_10" coords="5,268.88,614.33,211.71,23.89">F Ii = 2 P Ii R Ii P Ii + R Ii<label>(3)</label></formula><p>The final P , R and F scores are computed as the mean P , R and F scores across all test images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Results</head><p>For the experiments we used the 500 images from imageCLEF dataset. Firstly, the images are split randomly in two sets, the training set and the test set. As training set, 100 or 250 images are used, 20% of 50% of the set respectively. As expected, the bigger training dataset gave better results. for this reason, it was decided to use all the 500 provided images dataset as training set at the submission run. Experiments took place with various combination of descriptors.</p><p>As shown in Table <ref type="table" coords="6,219.47,211.79,3.87,8.74">2</ref>, descriptors are managed as groups. For decision criterion in the cases that the SVM classified a small number of boxes as important, we experimented with d 9 and d 13 descriptors. The SURF descriptor (d 13 ) produced better results, as it is a well-established and robust algorithm, in contrary to descriptor d 9 which is more abstract. Table <ref type="table" coords="6,315.79,259.61,4.98,8.74">2</ref> shows the setup of each experiment. For example, for experiment 1 descriptors d 1...4 , d 11 , d 13 and d 17 were used. SVMs kernel is radial basis function, 100 images of 500 were used as training set and as criterion d 9 were used. Before the experiments each group of descriptors were tested separately, so the behavior of each was known. That means that there was not need to include or exclumide all descriptors of the group in each experiment but the best representatives of the group. Furthermore, the correlation matrix was taken into account, that is why for example d 9 is not included in our experiments, as shown in Table <ref type="table" coords="6,307.22,355.25,3.87,8.74">2</ref>. Finally, as seen from Table <ref type="table" coords="6,441.64,355.25,3.87,8.74" target="#tab_0">1</ref>, the Fmeasure was not the only one taken under consideration for our final choice but also the balance of precision and recall.</p><p>Our approach using Gaussian kernel SVM classifier and 9 descriptors as experiment 14 achieves an overall F-measure of 54.59% ± 15.33, the best result of the two participating groups to the subtask. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This report describes the methodology, the experimentation, and the results acquired concerning DUTh's participation to the Subtask 3 of the Image Annotation task of ImageCLEF 2016. Our novelty is that we have tackled the task using only visual keypoints/features, in contrast to other participants so far using only text features or bounding box information. We investigated the performance of seventeen image descriptors combined with three SVM configurations corresponding to different SVM kernels. Experimental evaluation highlighted the significance of a feature subset in determining the conceptually important boxes. These features mostly relate to the edges and corners detected by wellestablished algorithms. Our approach using Gaussian kernel SVM classifier and nine descriptors achieves an overall F-measure of 54.59% ± 15.33, the best result of the two participating groups to the subtask. Taking a step further, we believe that the proposed methodology can be improved towards two directions. The first one concerns the improvement of the feature extraction methods. Motivated by the high performance of local feature detection demonstrated by this project, we would like to additionally incorporate the local feature descriptors that correspond to them. The statistical analysis and the comparison of these descriptors may provide useful information concerning the importance of each key-point. Room for improvement also exists in the exploitation of textual analysis of the proposed annotation terms. Textual features that are based on term and document frequencies can provide useful</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,264.54,134.77,24.14,9.65;4,297.74,128.03,41.90,9.65;4,292.65,141.60,52.07,9.65;4,264.54,161.99,24.14,9.65;4,297.74,155.25,43.96,9.65;4,292.65,168.82,54.13,9.65"><head>d 10 =</head><label>10</label><figDesc>Canny box Canny image d 11 = Harris box Harris image</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="7,169.35,116.83,276.66,229.09"><head></head><label></label><figDesc></figDesc><graphic coords="7,169.35,116.83,276.66,229.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,168.15,446.61,279.06,215.36"><head>Table 1 .</head><label>1</label><figDesc>Experimental results for various combinations of descriptor</figDesc><table coords="6,186.30,467.41,242.75,194.56"><row><cell>Experiment</cell><cell>F-score</cell><cell>Precession</cell><cell>Recall</cell></row><row><cell>1</cell><cell cols="3">0.5885 ± 0.2300 0.5972 ± 0.2451 0.6758 ± 0.2963</cell></row><row><cell>2</cell><cell cols="3">0.5873 ± 0.2297 0.5946 ± 0.2442 0.6783 ± 0.2946</cell></row><row><cell>3</cell><cell cols="3">0.5882 ± 0.2312 0.5991 ± 0.2465 0.6726 ± 0.2982</cell></row><row><cell>4</cell><cell cols="3">0.5888 ± 0.2294 0.5963 ± 0.2446 0.6761 ± 0.2978</cell></row><row><cell>5</cell><cell cols="3">0.5980 ± 0.2224 0.5994 ± 0.2390 0.6892 ± 0.2955</cell></row><row><cell>6</cell><cell cols="3">0.5976 ± 0.2235 0.5982 ± 0.2392 0.6893 ± 0.2962</cell></row><row><cell>7</cell><cell cols="3">0.5891 ± 0.2296 0.5969 ± 0.2446 0.6758 ± 0.2986</cell></row><row><cell>8</cell><cell cols="3">0.5889 ± 0.2301 0.5985 ± 0.2449 0.6746 ± 0.2973</cell></row><row><cell>9</cell><cell cols="3">0.5585 ± 0.2108 0.4939 ± 0.2081 0.7461 ± 0.2994</cell></row><row><cell>10</cell><cell cols="3">0.6380 ± 0.1899 0.5683 ± 0.2210 0.8203 ± 0.2253</cell></row><row><cell>11</cell><cell cols="3">0.5314 ± 0.1602 0.3865 ± 0.1620 0.9671 ± 0.0761</cell></row><row><cell>12</cell><cell cols="3">0.5709 ± 0.2175 0.5298 ± 0.2257 0.7235 ± 0.2850</cell></row><row><cell>13</cell><cell cols="3">0.5894 ± 0.2283 0.5950 ± 0.2430 0.6817 ± 0.2930</cell></row><row><cell>14</cell><cell cols="3">0.5888 ± 0.2322 0.6018 ± 0.2475 0.6663 ± 0.3042</cell></row><row><cell>15</cell><cell cols="3">0.5893 ± 0.2303 0.6001 ± 0.2457 0.6717 ± 0.3000</cell></row><row><cell>16</cell><cell cols="3">0.5893 ± 0.2312 0.6014 ± 0.2462 0.6688 ± 0.3030</cell></row><row><cell>17</cell><cell cols="3">0.5888 ± 0.2300 0.5973 ± 0.2450 0.6757 ± 0.2975</cell></row></table><note coords="7,169.08,360.69,277.20,7.89"><p>Fig. 1. Correlation calculation between every descriptor investigated</p></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>insight in order to determine the importance of every box label. Furthermore, textual features concerning term significance may be extracted exploiting word ontologies or semantic networks, such as WordNet <ref type="bibr" coords="8,356.79,355.34,14.61,8.74" target="#b9">[10]</ref>.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,408.28,337.64,7.86;8,151.52,419.24,267.14,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,342.23,408.28,134.70,7.86">Speeded-up robust features (surf)</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,151.52,419.24,171.92,7.86">Computer vision and image understanding</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="346" to="359" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,429.91,337.63,7.86;8,151.52,440.87,258.55,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,198.29,429.91,185.50,7.86">A computational approach to edge detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,392.24,429.91,88.35,7.86;8,151.52,440.87,177.14,7.86">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="679" to="698" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
	<note>IEEE Transactions on</note>
</biblStruct>

<biblStruct coords="8,142.96,451.55,337.63,7.86;8,151.52,462.51,25.60,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,246.27,451.55,96.97,7.86">Support-vector networks</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,350.30,451.55,68.87,7.86">Machine learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,473.18,337.63,7.86;8,151.52,484.14,290.19,7.86" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<title level="m" coord="8,286.49,473.18,194.10,7.86;8,151.52,484.14,144.33,7.86">An introduction to support vector machines and other kernel-based learning methods</title>
		<imprint>
			<publisher>Cambridge university press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,494.82,337.63,7.86;8,151.52,505.78,329.07,8.12;8,151.52,517.38,216.54,7.47" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,253.63,494.82,164.54,7.86">Structured forests for fast edge detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<ptr target="http://research.microsoft.com/apps/pubs/default.aspx?id=202540" />
	</analytic>
	<monogr>
		<title level="m" coord="8,439.68,494.82,40.91,7.86;8,151.52,505.78,176.42,7.86">ICCV. International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2013-12">December 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,527.41,337.64,7.86;8,151.52,538.37,203.52,7.86" xml:id="b5">
	<analytic>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,312.52,527.41,137.77,7.86">The elements of statistical learning</title>
		<title level="s" coord="8,151.52,538.37,107.85,7.86">Springer series in statistics</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,549.05,337.64,7.86;8,151.52,560.01,329.07,7.86;8,151.52,570.97,329.07,7.86;8,151.52,579.66,272.66,10.13" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,287.50,560.01,193.09,7.86;8,151.52,570.97,117.61,7.86">Overview of the ImageCLEF 2016 Scalable Concept Image Annotation Task</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ramisa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Dellandrea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,293.35,570.97,187.25,7.86;8,151.52,581.93,110.74,7.86">CLEF2016 Working Notes. CEUR Workshop Proceedings, CEUR-WS.org</title>
		<meeting><address><addrLine>Évora, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-08">September 5-8 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,592.60,337.64,7.86;8,151.52,603.56,166.25,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,256.83,592.60,151.92,7.86">A combined corner and edge detector</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Stephens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,430.70,592.60,49.90,7.86;8,151.52,603.56,40.29,7.86">Alvey vision conference</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">50</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,614.24,337.64,7.86;8,151.52,625.20,329.07,7.86;8,151.52,636.16,113.78,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,324.06,614.24,156.53,7.86;8,151.52,625.20,36.68,7.86">Brisk: Binary robust invariant scalable keypoints</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Leutenegger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">Y</forename><surname>Siegwart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,209.67,625.20,100.77,7.86;8,340.02,625.20,125.09,7.86">IEEE International Conference</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="page" from="2548" to="2555" />
		</imprint>
	</monogr>
	<note>Computer Vision (ICCV)</note>
</biblStruct>

<biblStruct coords="8,142.62,646.84,337.97,7.86;8,151.52,657.79,82.94,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,204.73,646.84,152.73,7.86">Wordnet: a lexical database for english</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,363.74,646.84,116.85,7.86">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,120.67,337.98,7.86;9,151.52,131.63,329.07,7.86;9,151.52,142.59,154.48,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,319.91,120.67,160.68,7.86;9,151.52,131.63,117.53,7.86">Faster and better: A machine learning approach to corner detection</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Rosten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Drummond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,277.02,131.63,203.57,7.86;9,151.52,142.59,63.86,7.86">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="119" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>IEEE Transactions on</note>
</biblStruct>

<biblStruct coords="9,142.62,153.55,337.97,7.86;9,151.52,164.51,98.05,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,258.63,153.55,127.15,7.86">Edge detectors in human vision</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Shapley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tolhurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,392.82,153.55,87.77,7.86;9,151.52,164.51,21.25,7.86">The Journal of physiology</title>
		<imprint>
			<biblScope unit="volume">229</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">165</biblScope>
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,175.46,337.98,7.86;9,151.52,186.42,329.07,7.86;9,151.52,197.38,329.07,7.86;9,151.52,208.34,329.07,7.86;9,151.52,219.30,126.65,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,398.74,197.38,81.85,7.86;9,151.52,208.34,142.90,7.86">General Overview of ImageCLEF at the CLEF 2016 Labs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schaer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ramisa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Dellandrea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">M J</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">H</forename><surname>Toselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Snchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="9,301.24,208.34,139.07,7.86">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
