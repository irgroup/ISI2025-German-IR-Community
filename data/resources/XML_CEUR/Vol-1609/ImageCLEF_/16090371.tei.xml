<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,380.72,116.95,84.83,12.62;1,140.32,134.89,334.72,12.62;1,159.14,152.82,297.07,12.62">ImageCLEF 2016 Scalable Concept Image Annotation Task: Overcoming the Scarcity of Training Data</title>
				<funder ref="#_bsj9mXc">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,274.12,190.49,67.11,8.74"><forename type="first">Hichem</forename><surname>Sahbi</surname></persName>
							<email>hichem.sahbi@telecom-paristech.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">CNRS TELECOM ParisTech at</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">CNRS TELECOM ParisTech</orgName>
								<orgName type="institution" key="instit2">Paris-Saclay University</orgName>
								<address>
									<addrLine>46 rue Barrault</addrLine>
									<postCode>75013</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,380.72,116.95,84.83,12.62;1,140.32,134.89,334.72,12.62;1,159.14,152.82,297.07,12.62">ImageCLEF 2016 Scalable Concept Image Annotation Task: Overcoming the Scarcity of Training Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">297C19BBD7DCA484258EA4A9B6C3C877</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>label enrichment</term>
					<term>SVMs</term>
					<term>deep learning</term>
					<term>image annotation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce our participation at the ImageCLEF 2016 scalable concept detection and localization task. As in ImageCLEF 2015, this edition focuses on generating not only annotations (concept detection) but also localizing concepts into a large image collection. In our runs, we focus mainly on concept detection; our solution is purely visual and based on deep features combined with standard linear support vector machines (SVMs) built on top of well enriched training sets. Starting from loosely labeled training sets, we propose an algorithm that learns the statistical dependencies between concepts and allows us to enrich the labels of these training sets, resulting into more effective SVMs for image annotation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic image annotation is one of the major challenges in computer vision and machine learning. It consists in learning intricate relationships between keywords (a.k.a concepts/labels/categories) and training images, in order to assign list of keywords to newly observed visual contents (see for instance <ref type="bibr" coords="1,425.06,495.44,7.75,8.74" target="#b0">[1]</ref><ref type="bibr" coords="1,432.80,495.44,3.87,8.74" target="#b1">[2]</ref><ref type="bibr" coords="1,432.80,495.44,3.87,8.74" target="#b2">[3]</ref><ref type="bibr" coords="1,432.80,495.44,3.87,8.74" target="#b3">[4]</ref><ref type="bibr" coords="1,436.68,495.44,7.75,8.74" target="#b4">[5]</ref>). These concepts may either correspond to well defined physical entities (pedestrians, cars, etc.) or to high level, fine-grained notions resulting from the interaction of many entities into scenes (parties, fights, etc.). In both cases, image annotation is challenging due to the perplexity when assigning concepts to scenes especially when the number of possible concepts is taken from a large vocabulary, when training data are scarce and also when analyzing highly semantic and variable content.</p><p>Early image annotation techniques are content-based (e.g. <ref type="bibr" coords="1,400.00,603.03,7.75,8.74" target="#b5">[6]</ref><ref type="bibr" coords="1,407.75,603.03,3.87,8.74" target="#b6">[7]</ref><ref type="bibr" coords="1,407.75,603.03,3.87,8.74" target="#b7">[8]</ref><ref type="bibr" coords="1,411.62,603.03,7.75,8.74" target="#b8">[9]</ref>). They model straightforward "concept-image" relationships and learn how to assign concepts to new images; they first describe image observations using visual features <ref type="foot" coords="1,473.35,625.37,3.97,6.12" target="#foot_0">1</ref> , treat each concept as an independent class, and then train the corresponding concept-specific classifier to identify (separately) images belonging to that concept using a variety of machine learning and inference techniques, either generative or discriminative <ref type="bibr" coords="2,236.43,143.90,111.33,8.74">[11-16, 9, 17-24, 10, 25-36]</ref>. Extensions of these methods achieve structured output predictions <ref type="bibr" coords="2,304.96,155.86,15.50,8.74" target="#b36">[37,</ref><ref type="bibr" coords="2,322.12,155.86,12.73,8.74" target="#b37">38]</ref> by modeling not only "conceptimage" relationships, but also "concept-concept" dependencies <ref type="bibr" coords="2,412.05,167.81,12.45,8.74" target="#b38">[39]</ref><ref type="bibr" coords="2,424.50,167.81,4.15,8.74" target="#b39">[40]</ref><ref type="bibr" coords="2,424.50,167.81,4.15,8.74" target="#b40">[41]</ref><ref type="bibr" coords="2,428.66,167.81,12.45,8.74" target="#b41">[42]</ref>. Indeed, concepts in image annotation are usually interdependent, i.e., the presence of one concept may tell us something about the presence of another one; for instance the presence of the concept "sea" usually implies the presence of other concepts such as "sky" or "sand". Hence modeling the statistical dependencies between concepts (both for training and inference) is crucial and this is usually achieved with graphical models and markov/conditional random fields <ref type="bibr" coords="2,443.97,239.54,14.61,8.74" target="#b15">[16]</ref>. Relationships between concepts can also be modeled by extracting (hand-crafted or learned) mid-level characteristics which are common to different concepts. This has recently received a particular attention in the context of deep networks and transfer learning <ref type="bibr" coords="2,228.35,287.36,15.50,8.74" target="#b42">[43,</ref><ref type="bibr" coords="2,245.51,287.36,12.73,8.74" target="#b9">10,</ref><ref type="bibr" coords="2,259.89,287.36,11.62,8.74" target="#b43">44]</ref>. However, the lack of labeled data may severely limit the usability of these methods and requires solutions in order to learn from few shots. Hence, learning from common data and characteristics is valuable in order to overcome the scarcity of training data especially when handling image annotation problems with a large number of concepts.</p><p>In this paper, we describe the participation of "CNRS-TELECOM Paris-Tech" at the ImageCLEF 2016 Scalable Concept Image Annotation Task <ref type="bibr" coords="2,465.10,371.29,15.50,8.74" target="#b44">[45,</ref><ref type="bibr" coords="2,134.77,383.24,11.62,8.74" target="#b45">46]</ref>. Our solution focuses mainly on concept detection; it combines effective deep features with SVM classifiers. As training data are scarce, we propose a solution that enriches the labels of these training data. This solution is based on measuring the statistical correlation between concepts in the training set and makes it possible to propagate labels to larger training sets. Note that our solution does not require the use of the meta-data associated to training and test data; indeed it is purely visual. In spite of this, the proposed runs are competitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Concept Prediction and Localization at a Glance</head><p>Our concept detection and localization results are obtained according to the two following steps: i) Holistic concept detection: this step is achieved using global (holistic) visual features. For that purpose, we train "one versus all" SVMs for each concept, in order to detect whether that concept exists in a given test image (see extra details in Section 4.2).</p><p>ii) Blind concept localization: concept localization is achieved blindly, i.e., without observing the content of a given test image. In contrast to our last year participation <ref type="bibr" coords="2,194.09,633.20,14.61,8.74" target="#b46">[47]</ref>, we did not investigate heuristics for concept localization and we use the whole image dimensions as bounding boxes; this turns out to be sufficient for many concepts as discussed in Section 4.2. So in this participation, (Bottom) Sample of external pictures collected from the web; the leftmost picture belongs to the category "beach", while the middle and rightmost pictures belong to the categories "anchor" and "apple" respectively. It is clear that these pictures can also be assigned to categories ("sea", "sand", "cloud"), ("boat"), ("tree"), etc. as these concepts are highly correlated with the concepts "beach", "anchor" and "apple" respectively. So these pictures can be reused to train the classifiers of these concepts.</p><p>we focus on the first step only (i.e., Holistic concept detection) and mainly issues about enriching training datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Training Datasets and Label Enrichment</head><p>Besides training data provided in ImageCLEF 2016, we collected automatically an external training set using the "googlebot-image" crawler. This external set consists in 42,272 images belonging to the 251 concepts of ImageCLEF. No post processing of these images was achieved (the whole content is used in order to train our SVM models and without localizing the concepts in images). Figs. <ref type="figure" coords="3,464.90,501.70,7.75,8.74" target="#fig_0">1,</ref><ref type="figure" coords="3,475.61,501.70,4.98,8.74" target="#fig_1">2</ref> show a sample of those images as well as the distribution of the number of images per concept. We also use the 2,000 images of the dev set provided by the Image-CLEF 2016 organizers as an internal training set in order to train and tune the parameters of our SVM models. All images are described using the coefficients of the FC7 layer of the pre-trained VGG network in <ref type="bibr" coords="3,364.84,561.47,14.61,8.74" target="#b47">[48]</ref>.</p><p>Label enrichment As some concepts are rare, we use the 2,000 images of the dev set in order to enrich the labels of all the training set. The idea is to transfer the knowledge about the co-occurrence of some labels using a simple principle: given two concepts c and c , if c, c are highly correlated, then the presence of one of these two concepts in a given training image implies the presence of the other concept. In order to implement this principle, we define the asymmetric co-occurrence between two concepts as follows</p><formula xml:id="formula_0" coords="4,212.66,331.59,267.93,29.67">C(c |c) = N i=1 Y ic Y ic N i=1 Y ic , c, c = 1 . . . K,<label>(1)</label></formula><p>here N is the size of the dev set and K is the number of concepts (N = 2, 000, Fig <ref type="bibr" coords="4,152.86,473.99,51.17,8.74">(1, bottom)</ref> shows an example of this label enrichment process, where the presence of concept "apple" implies the presence of the concept "tree". Note that this enrichment process could also be achieved as a post processing step (i.e., after image annotation), however due to shortage of time, this issue has not been investigated.</p><formula xml:id="formula_1" coords="4,134.77,376.77,345.82,23.18">K = 251 in practice) and Y ∈ R N ×K is a matrix whose entry Y ic = 1 iff the concept c is present into image I i</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ImageCLEF 2016 Evaluation</head><p>The targeted task is, again, concept detection and localization: given a picture, the goal is to predict which concepts (classes) are present into that picture and the coordinates of the bounding boxes surrounding these concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">ImageCLEF 2016 Collection</head><p>A very large amount of images was gathered by the organizers, and using associated web pages, tags and meta-data were also provided. This set includes more than 500k images with only 2k images with known ground truth (i.e., labels and bounding boxes are given). These images belong to 251 concepts (see example in Fig. <ref type="figure" coords="5,165.69,143.90,3.87,8.74" target="#fig_0">1</ref>). In our runs, each image is again described with a visual feature vector corresponding to the FC7 layer of the VGG pretrained network. Note that the parameters of this network are not fine-tuned on training data and concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Submitted Runs</head><p>All our submitted runs (discussed below) are based on SVM training. For each concept, we trained "one-versus-all" SVM classifiers; we use many random folds (taken from training data) for multiple SVM training and we use these SVMs in order to predict the concepts on the test set. We repeat this training process, for each concept, through different random folds from the training set and we take the average scores of the underlying SVM classifiers. This makes classification results less sensitive to the sampling of the training set. Given a test image x, a concept c is declared as present into x iff f c (x) &gt; τ , here f c (x) = 1 L 1 {g (x)&gt;0} and g () is an SVM classifier trained on a random fold of positive and negative data (in practice L = 10; see also Tab. 1 for the setting of τ ).</p><p>Our ten submitted runs correspond to the combination of five dataset enrichment strategies (see columns of Tab. 1 and section 3) and two datasets used for SVM training (external and ImageCLEF16/dev set). For all the submitted runs, performances are evaluated, by the organizers, using a variant of the Jaccard measure; the latter is defined as the intersection over union of bounding boxes provided in the submitted runs and those in the ground truth. Mean average precision (MAP) measures -based on different percentages of bounding box overlaps -are given for each concept and also averaged through different concepts (see our results in Tables 2, 3, 4, 5, 6). Details about these measures can be found in the ImageCLEF 2016 website <ref type="foot" coords="5,304.44,458.51,3.97,6.12" target="#foot_1">2</ref> . In contrast to our last year participation, we do not address the issue of bounding box (BB) generation; our bounding boxes cover the whole areas of the test images. We expect further improvement of performances if we consider the BB generation heuristics used last year (as already shown in <ref type="bibr" coords="5,211.78,507.91,14.76,8.74" target="#b46">[47]</ref>).</p><p>From all these tables, we observe the following issues:</p><p>-For all the runs shown in table 2, we observe that combining external data with the ImageCLEF16 dev set provides a clear gain compared to the use of external data only; this may be explained by the fact that the ImageCLEF16 dev set has (possibly) a similar distribution compared to ImageCLEF16 test set, and this makes it possible to adapt training parameters (mainly the SVM weights) to the conditions of the test data. In contrast, the use of external data only does not allow to adapt these SVM parameters appropriately. and "TAB.1.5.res" rely on the enrichment process. From all these tables we observe a clear gain in performance especially for concepts with a high correlation factor <ref type="foot" coords="6,213.05,349.95,3.97,6.12" target="#foot_2">3</ref> . This is predictable as concepts with high correlation factors (such as "arm", "shirt", "shoe" in tables 3, 4) co-occur with many other concepts and hence inherit larger training subsets. Some concepts even with small correlation factors (such as "apron", "cup") also benefit from the enrichment process, with a relatively smaller gain.</p><p>-The same behavior also occurs when considering the performance with 50% overlap (see tables <ref type="bibr" coords="6,233.75,434.82,7.75,8.74" target="#b4">5,</ref><ref type="bibr" coords="6,244.36,434.82,7.75,8.74" target="#b5">6)</ref>. We also notice that concepts which are usually centered in pictures (such as "motorcycle", "kitchen", "shirt") are relatively well localized using our simple blind localization. Other difficult concepts (such as "cat" in table <ref type="table" coords="6,226.70,470.69,4.43,8.74">6</ref>) get substantial improvement. It is also clear that better concept detection implies better localization results (see again tables 3, 4 vs. tables 5, 6).</p><p>-From all these results it is clear that the run "TAB.1.5.res" is better than the run "TAB.1.3.res" as the former is more conservative (i.e., threshold σ is relatively high) while the latter is less conservative and benefits from larger training sets. Finally, figures 3, 4 show the concepts for which we obtained the best results among different participants in ImageCLEF16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We discussed in this paper, our participation at the ImageCLEF 2016 Scalable Concept Image Annotation Task. In our runs, concept detection is based on deep   features combined with linear SVMs trained on well enriched datasets. The enrichment process is based on measuring the co-occurrence of concepts and this makes it possible to reuse training images across correlated concepts. Observed results show that i) the enrichment process has a positive impact on performances especially for concepts with high correlations with others, and ii) the use of both external and provided ImageCLEF16 dev set enhances performances compared to the use of external data only; indeed, in spite of being relatively small, the provided dev set makes it possible to adapt the parameters of our SVM models to the distribution of dev and test data.</p><p>A future possible extension, of this work, is to make the enrichment process label dependent, i.e., how to mix and select different enrichment strategies for different concepts. Another possible extension is to achieve late label enrichment, as a post processing step, by augmenting annotation results on the test set using the same label enrichment strategy.</p><p>Table <ref type="table" coords="9,165.24,238.02,4.13,7.89">3</ref>. This table shows for each concept, its correlation factor, the size of the initial training set, the size of the enriched set, the performance before enrichment (i.e., run "TAB.1.1.res") and after enrichment (i.e., run "TAB.1.3.res"). Again, for run "TAB.1.3.res", σ = 0.1 (see table <ref type="table" coords="9,269.66,270.92,3.58,7.86" target="#tab_0">1</ref>). All these performances correspond to 0% overlap. Table <ref type="table" coords="12,165.24,169.19,4.13,7.89">6</ref>. This table shows for each concept, its correlation factor, the size of the initial training set, the size of the enriched set, the performance before enrichment (i.e., run "TAB.1.1.res") and after enrichment (i.e., run "TAB.1.5.res"). Again, for run "TAB.1.5.res", σ = 0.75 (see table <ref type="table" coords="12,295.03,202.10,3.58,7.86" target="#tab_0">1</ref>). All these performances correspond to 50% overlap. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,134.77,291.40,345.83,7.89;3,134.77,302.38,345.83,7.86;3,134.77,313.34,345.83,7.86;3,134.77,324.30,345.82,7.86;3,134.77,335.26,345.82,7.86;3,134.77,346.22,345.83,7.86;3,134.77,357.18,335.16,7.86;3,365.52,202.78,110.42,73.67"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (Top) Sample of pictures taken from the ImageCLEF2016 database (dev set).(Bottom) Sample of external pictures collected from the web; the leftmost picture belongs to the category "beach", while the middle and rightmost pictures belong to the categories "anchor" and "apple" respectively. It is clear that these pictures can also be assigned to categories ("sea", "sand", "cloud"), ("boat"), ("tree"), etc. as these concepts are highly correlated with the concepts "beach", "anchor" and "apple" respectively. So these pictures can be reused to train the classifiers of these concepts.</figDesc><graphic coords="3,365.52,202.78,110.42,73.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,134.77,256.23,345.82,7.89;4,134.77,267.22,121.80,7.86"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Number of images per concept on the external training set (left) and on the ImageCLEF16 dev set (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,315.00,390.27,165.59,9.68;4,134.77,402.26,345.82,8.74;4,134.77,414.21,345.83,8.74;4,134.77,426.17,345.82,8.74;4,134.77,438.12,345.83,8.74;4,134.77,450.05,345.82,9.68;4,134.77,462.03,72.75,8.74"><head></head><label></label><figDesc>and Y ic = 0 otherwise. As external images are collected using "individual keywords" as queries, they have a single label per image and cannot be used to learn these co-occurrences. In contrast, dev set images have multiple labels and are used instead. Hence, labels in the external set are enriched as follows ∀c, c ∈ {1, . . . , K}, ∀i ∈ {N + 1, . . . , N + N } (N = 42, 272), if Y ic = 1 and C(c |c) ≥ σ then Y ic ← 1 (see Section 4 about the tuning of σ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,134.77,350.14,345.82,7.89;7,134.77,361.13,345.83,7.86;7,134.77,372.08,271.22,7.86"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. This figure shows the concepts for which we outperform other participants' runs (blue bars: our best performances, red bars: other participants' best performances on these concepts). These performances correspond to 0 % overlap.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="7,134.77,627.67,345.82,7.89;7,134.77,638.65,345.83,7.86;7,134.77,649.61,275.83,7.86"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.<ref type="bibr" coords="7,154.40,627.67,4.13,7.89" target="#b3">4</ref>. This figure shows the concepts for which we outperform other participants' runs (blue bars: our best performances, red bars: other participants' best performances on these concepts). These performances correspond to 50 % overlap.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,134.77,116.91,345.83,207.48"><head>Table 1 .</head><label>1</label><figDesc>Different runs as submitted to the ImageCLEF 2016 Challenge. RA stands for row adaptive, i.e., the threshold is set for each test image in order to guarantee that the maximum number of detections per image is ≤ 100. TAB.1.1.res TAB.1.4.res TAB.1.4.1.res TAB.1.3.res TAB.1.5.res -Tables3-6show a subset of concepts whose performances improve after the enrichment process w.r.t the baseline (i.e., "TAB.1.1.res" vs. "TAB.1.3.res"</figDesc><table coords="6,139.06,158.86,337.26,82.81"><row><cell>X Datasets X X X Enrichment X X X X X</cell><cell>No</cell><cell>Yes σ = 0.01</cell><cell>Yes σ = 0.01</cell><cell>Yes σ = 0.1</cell><cell>Yes σ = 0.75</cell></row><row><cell></cell><cell>τ = 0.00</cell><cell>τ (RA)</cell><cell>τ = 8.00</cell><cell>τ = 0.00</cell><cell>τ = 0.00</cell></row><row><cell>External</cell><cell cols="5">TAB.0.1.res TAB.0.4.res TAB.0.4.1.res TAB.0.3.res TAB.0.5.res</cell></row><row><cell>External</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>+ImageCLEF16 (dev)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note coords="6,151.70,291.74,328.89,8.74;6,151.70,303.70,328.89,8.74;6,151.70,315.65,328.89,8.74"><p><p><p>in table</p>3</p>and "TAB.1.1.res" vs. "TAB.1.5.res" in table 4); again, and as already described in table 1, "TAB.1.1.res" is a baseline run that uses external and ImageCLEF16 data without enrichment while runs "TAB.1.3.res"</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,134.77,117.41,345.83,169.34"><head>Table 2 .</head><label>2</label><figDesc>Performances (in %) of our different concept detection and localization results (taken from ImageCLEF 2016 results).</figDesc><table coords="8,138.77,149.46,337.84,137.29"><row><cell>P P Runs P P Overlap P P P External Only</cell><cell>0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100 %</cell></row><row><cell>CNRS/TAB.0.1.res</cell><cell>19.62 15.67 12.01 9.78 8.13 6.73 5.77 4.83 3.86 2.81 1.65</cell></row><row><cell>CNRS/TAB.0.5.res</cell><cell>19.39 15.89 12.38 10.08 8.39 6.88 5.90 4.95 3.90 2.75 1.64</cell></row><row><cell>CNRS/TAB.0.3.res</cell><cell>17.31 14.27 11.53 9.53 8.00 6.77 5.89 4.93 3.97 2.84 1.81</cell></row><row><cell>CNRS/TAB.0.4.res</cell><cell>10.59 7.43 5.71 4.64 3.73 3.05 2.67 2.25 1.87 1.37 0.91</cell></row><row><cell>CNRS/TAB.0.4.1.res</cell><cell>10.25 7.12 5.41 4.33 3.48 2.85 2.49 2.10 1.72 1.25 0.82</cell></row><row><cell>External + CLEF16 dev</cell><cell></cell></row><row><cell>CNRS/TAB.1.1.res</cell><cell>24.75 21.89 18.32 15.14 12.83 11.11 9.62 7.71 6.13 4.13 2.42</cell></row><row><cell>CNRS/TAB.1.5.res</cell><cell>21.53 19.44 16.48 13.66 11.56 9.96 8.66 6.85 5.41 3.38 2.06</cell></row><row><cell>CNRS/TAB.1.3.res</cell><cell>16.85 13.72 10.98 9.06 7.58 6.36 5.63 4.74 3.79 2.67 1.64</cell></row><row><cell>CNRS/TAB.1.4.res</cell><cell>10.29 7.03 5.06 3.99 3.30 2.70 2.35 2.01 1.67 1.29 0.83</cell></row><row><cell>CNRS/TAB.1.4.1.res</cell><cell>9.79 6.55 4.80 3.74 3.09 2.53 2.17 1.91 1.57 1.19 0.74</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,138.56,291.90,340.86,249.25"><head>Table 4 .</head><label>4</label><figDesc>This table shows for each concept, its correlation factor, the size of the initial training set, the size of the enriched set, the performance before enrichment (i.e., run "TAB.1.1.res") and after enrichment (i.e., run "TAB.1.5.res").</figDesc><table coords="9,138.56,291.90,340.86,249.25"><row><cell cols="6">concepts Fσ(.) # initial set # enriched set perfs % (before enrichment) perfs % (after enrichment)</cell></row><row><cell cols="2">butterfly 50</cell><cell>51</cell><cell>7398</cell><cell>0</cell><cell>2.17</cell></row><row><cell>barn</cell><cell>78</cell><cell>180</cell><cell>13007</cell><cell>0</cell><cell>0.18</cell></row><row><cell>bullet</cell><cell>19</cell><cell>112</cell><cell>2180</cell><cell>0</cell><cell>0.26</cell></row><row><cell>cup</cell><cell>6</cell><cell>80</cell><cell>306</cell><cell>0</cell><cell>0.33</cell></row><row><cell>fork</cell><cell>1</cell><cell>150</cell><cell>150</cell><cell>0</cell><cell>0.36</cell></row><row><cell cols="2">hospital 57</cell><cell>178</cell><cell>10894</cell><cell>0.43</cell><cell>0.57</cell></row><row><cell cols="2">keyboard 25</cell><cell>177</cell><cell>3515</cell><cell>3.70</cell><cell>3.82</cell></row><row><cell>mat</cell><cell>1</cell><cell>79</cell><cell>79</cell><cell>0</cell><cell>1.64</cell></row><row><cell>mirror</cell><cell>70</cell><cell>304</cell><cell>20072</cell><cell>2.04</cell><cell>6.67</cell></row><row><cell>pencil</cell><cell>4</cell><cell>194</cell><cell>519</cell><cell>0</cell><cell>1.79</cell></row><row><cell>shirt</cell><cell>36</cell><cell>188</cell><cell>5939</cell><cell>48.98</cell><cell>58.97</cell></row><row><cell>shoe</cell><cell>76</cell><cell>356</cell><cell>20377</cell><cell>20.00</cell><cell>23.40</cell></row><row><cell>sock</cell><cell>3</cell><cell>357</cell><cell>357</cell><cell>13.33</cell><cell>14.00</cell></row><row><cell>vase</cell><cell>22</cell><cell>171</cell><cell>3624</cell><cell>0</cell><cell>8.57</cell></row><row><cell>vest</cell><cell>1</cell><cell>75</cell><cell>75</cell><cell>3.70</cell><cell>6.06</cell></row><row><cell>tongue</cell><cell>43</cell><cell>181</cell><cell>6265</cell><cell>0</cell><cell>1.06</cell></row><row><cell>mouth</cell><cell>1</cell><cell>227</cell><cell>227</cell><cell>50.00</cell><cell>73.91</cell></row><row><cell>neck</cell><cell>1</cell><cell>72</cell><cell>72</cell><cell>64.29</cell><cell>72.16</cell></row><row><cell>foot</cell><cell>11</cell><cell>302</cell><cell>1541</cell><cell>12.50</cell><cell>18.69</cell></row><row><cell>arm</cell><cell>44</cell><cell>159</cell><cell>7199</cell><cell>61.11</cell><cell>81.94</cell></row><row><cell cols="2">magazine 19</cell><cell>184</cell><cell>2598</cell><cell>1.06</cell><cell>8.33</cell></row><row><cell>apple</cell><cell>16</cell><cell>246</cell><cell>2138</cell><cell>0</cell><cell>1.06</cell></row><row><cell>orange</cell><cell>95</cell><cell>379</cell><cell>17030</cell><cell>0</cell><cell>0.38</cell></row><row><cell>salad</cell><cell>64</cell><cell>199</cell><cell>11531</cell><cell>10.00</cell><cell>10.53</cell></row><row><cell>canal</cell><cell>50</cell><cell>125</cell><cell>7492</cell><cell>0.40</cell><cell>1.43</cell></row><row><cell>nut</cell><cell>30</cell><cell>85</cell><cell>4318</cell><cell>3.57</cell><cell>6.67</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="11,134.77,217.38,345.83,344.46"><head>Table 5 .</head><label>5</label><figDesc>This table shows for each concept, its correlation factor, the size of the initial training set, the size of the enriched set, the performance before enrichment (i.e., run "TAB.1.1.res") and after enrichment (i.e., run "TAB.1.3.res"). Again, for run "TAB.1.3.res", σ = 0.1 (see table1). All these performances correspond to 50% overlap.</figDesc><table coords="11,138.48,281.68,340.97,280.15"><row><cell cols="6">concepts Fσ(.) # initial set # enriched set perfs % (before enrichment) perfs % (after enrichment)</cell></row><row><cell>ball</cell><cell>56</cell><cell>241</cell><cell>9539</cell><cell>0</cell><cell>0.13</cell></row><row><cell>barn</cell><cell>78</cell><cell>180</cell><cell>13007</cell><cell>0</cell><cell>0.18</cell></row><row><cell>basket</cell><cell>1</cell><cell>310</cell><cell>310</cell><cell>0</cell><cell>0.40</cell></row><row><cell>bottle</cell><cell>76</cell><cell>115</cell><cell>12848</cell><cell>0</cell><cell>0.45</cell></row><row><cell>box</cell><cell>30</cell><cell>90</cell><cell>3371</cell><cell>0</cell><cell>0.68</cell></row><row><cell>bullet</cell><cell>19</cell><cell>112</cell><cell>2180</cell><cell>0</cell><cell>0.26</cell></row><row><cell>cap</cell><cell>82</cell><cell>251</cell><cell>22114</cell><cell>0</cell><cell>0.08</cell></row><row><cell>flag</cell><cell>27</cell><cell>155</cell><cell>4162</cell><cell>0</cell><cell>0.10</cell></row><row><cell>helmet</cell><cell>32</cell><cell>176</cell><cell>4923</cell><cell>0</cell><cell>0.28</cell></row><row><cell>ladder</cell><cell>4</cell><cell>330</cell><cell>786</cell><cell>0</cell><cell>0.19</cell></row><row><cell>mat</cell><cell>1</cell><cell>79</cell><cell>79</cell><cell>0</cell><cell>0.14</cell></row><row><cell cols="2">microphone 36</cell><cell>187</cell><cell>6117</cell><cell>0</cell><cell>0.24</cell></row><row><cell>necktie</cell><cell>94</cell><cell>485</cell><cell>24349</cell><cell>0</cell><cell>0.13</cell></row><row><cell>pillow</cell><cell>53</cell><cell>297</cell><cell>9049</cell><cell>0</cell><cell>2.38</cell></row><row><cell>scarf</cell><cell>16</cell><cell>151</cell><cell>2087</cell><cell>0.61</cell><cell>0.87</cell></row><row><cell>shirt</cell><cell>36</cell><cell>188</cell><cell>5939</cell><cell>12.24</cell><cell>16.24</cell></row><row><cell>shoe</cell><cell>76</cell><cell>356</cell><cell>20377</cell><cell>0</cell><cell>1.42</cell></row><row><cell>stick</cell><cell>122</cell><cell>232</cell><cell>21878</cell><cell>0</cell><cell>0.28</cell></row><row><cell>toilet</cell><cell>1</cell><cell>152</cell><cell>152</cell><cell>0</cell><cell>0.70</cell></row><row><cell>towel</cell><cell>39</cell><cell>148</cell><cell>6440</cell><cell>0</cell><cell>0.29</cell></row><row><cell>vest</cell><cell>1</cell><cell>75</cell><cell>75</cell><cell>0</cell><cell>0.76</cell></row><row><cell>wheel</cell><cell>45</cell><cell>169</cell><cell>8093</cell><cell>0</cell><cell>0.33</cell></row><row><cell>eye</cell><cell>33</cell><cell>192</cell><cell>4424</cell><cell>0</cell><cell>0.12</cell></row><row><cell>face</cell><cell>32</cell><cell>238</cell><cell>4769</cell><cell>2.78</cell><cell>3.95</cell></row><row><cell>radio</cell><cell>39</cell><cell>202</cell><cell>6649</cell><cell>0</cell><cell>0.20</cell></row><row><cell>book</cell><cell>8</cell><cell>126</cell><cell>742</cell><cell>0</cell><cell>0.12</cell></row><row><cell>letter</cell><cell>71</cell><cell>271</cell><cell>12167</cell><cell>0</cell><cell>3.23</cell></row><row><cell>wine</cell><cell>29</cell><cell>256</cell><cell>4209</cell><cell>0</cell><cell>0.35</cell></row><row><cell>canal</cell><cell>50</cell><cell>125</cell><cell>7492</cell><cell>0.40</cell><cell>1.43</cell></row><row><cell cols="2">femalechild 12</cell><cell>79</cell><cell>1232</cell><cell>2.30</cell><cell>2.48</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="12,138.44,233.48,341.00,376.55"><head></head><label></label><figDesc>concepts Fσ(.) # initial set # enriched set perfs % (before enrichment) perfs % (after enrichment)</figDesc><table coords="12,138.44,242.81,306.97,367.23"><row><cell>cat</cell><cell>8</cell><cell>173</cell><cell>679</cell><cell>13.64</cell><cell>22.22</cell></row><row><cell>deer</cell><cell>3</cell><cell>149</cell><cell>149</cell><cell>21.82</cell><cell>22.92</cell></row><row><cell>fish</cell><cell>10</cell><cell>148</cell><cell>1562</cell><cell>6.25</cell><cell>18.18</cell></row><row><cell>airplane</cell><cell>8</cell><cell>413</cell><cell>644</cell><cell>40.28</cell><cell>46.67</cell></row><row><cell>apron</cell><cell>9</cell><cell>173</cell><cell>318</cell><cell>4.00</cell><cell>12.50</cell></row><row><cell>basket</cell><cell>1</cell><cell>310</cell><cell>310</cell><cell>0</cell><cell>0.51</cell></row><row><cell>bathtub</cell><cell>13</cell><cell>172</cell><cell>2794</cell><cell>8.33</cell><cell>14.29</cell></row><row><cell>bottle</cell><cell>28</cell><cell>115</cell><cell>5489</cell><cell>0</cell><cell>0.45</cell></row><row><cell>box</cell><cell>30</cell><cell>90</cell><cell>338</cell><cell>0</cell><cell>3.12</cell></row><row><cell>computer</cell><cell>1</cell><cell>142</cell><cell>142</cell><cell>3.66</cell><cell>3.92</cell></row><row><cell>cup</cell><cell>6</cell><cell>80</cell><cell>80</cell><cell>0</cell><cell>0.39</cell></row><row><cell>drum</cell><cell>7</cell><cell>369</cell><cell>1405</cell><cell>4.26</cell><cell>6.98</cell></row><row><cell>farm</cell><cell>15</cell><cell>244</cell><cell>6557</cell><cell>0.57</cell><cell>0.74</cell></row><row><cell>flag</cell><cell>7</cell><cell>155</cell><cell>391</cell><cell>0</cell><cell>1.41</cell></row><row><cell>helmet</cell><cell>32</cell><cell>176</cell><cell>1156</cell><cell>0</cell><cell>0.85</cell></row><row><cell>kitchen</cell><cell>8</cell><cell>174</cell><cell>433</cell><cell>10.71</cell><cell>17.65</cell></row><row><cell cols="2">motorcycle 8</cell><cell>170</cell><cell>340</cell><cell>43.33</cell><cell>75.00</cell></row><row><cell>necktie</cell><cell>9</cell><cell>485</cell><cell>15719</cell><cell>0</cell><cell>0.31</cell></row><row><cell>picture</cell><cell>6</cell><cell>236</cell><cell>319</cell><cell>2.17</cell><cell>2.70</cell></row><row><cell>pillow</cell><cell>8</cell><cell>297</cell><cell>2023</cell><cell>0</cell><cell>0.90</cell></row><row><cell>ramp</cell><cell>17</cell><cell>308</cell><cell>4143</cell><cell>0.82</cell><cell>1.18</cell></row><row><cell>scarf</cell><cell>16</cell><cell>151</cell><cell>1018</cell><cell>0.61</cell><cell>1.32</cell></row><row><cell>shirt</cell><cell>10</cell><cell>188</cell><cell>1098</cell><cell>12.24</cell><cell>20.18</cell></row><row><cell>shoe</cell><cell>8</cell><cell>356</cell><cell>6901</cell><cell>0</cell><cell>0.40</cell></row><row><cell>stadium</cell><cell>1</cell><cell>68</cell><cell>68</cell><cell>26.00</cell><cell>35.29</cell></row><row><cell>stick</cell><cell>9</cell><cell>232</cell><cell>6042</cell><cell>0</cell><cell>0.27</cell></row><row><cell>sword</cell><cell>14</cell><cell>106</cell><cell>705</cell><cell>3.23</cell><cell>3.70</cell></row><row><cell>toilet</cell><cell>1</cell><cell>152</cell><cell>152</cell><cell>0</cell><cell>9.09</cell></row><row><cell>tractor</cell><cell>13</cell><cell>280</cell><cell>2219</cell><cell>3.23</cell><cell>3.85</cell></row><row><cell>train</cell><cell>3</cell><cell>102</cell><cell>102</cell><cell>9.09</cell><cell>9.30</cell></row><row><cell>tray</cell><cell>18</cell><cell>91</cell><cell>650</cell><cell>0</cell><cell>10.00</cell></row><row><cell>vest</cell><cell>1</cell><cell>75</cell><cell>75</cell><cell>0</cell><cell>1.57</cell></row><row><cell>wheel</cell><cell>9</cell><cell>169</cell><cell>753</cell><cell>0</cell><cell>0.56</cell></row><row><cell>ear</cell><cell>23</cell><cell>58</cell><cell>593</cell><cell>0</cell><cell>0.38</cell></row><row><cell>head</cell><cell>10</cell><cell>378</cell><cell>378</cell><cell>4.94</cell><cell>8.06</cell></row><row><cell>book</cell><cell>8</cell><cell>126</cell><cell>126</cell><cell>0</cell><cell>0.51</cell></row><row><cell>letter</cell><cell>20</cell><cell>271</cell><cell>4560</cell><cell>0</cell><cell>0.28</cell></row><row><cell>beach</cell><cell>17</cell><cell>70</cell><cell>239</cell><cell>4.00</cell><cell>4.17</cell></row><row><cell>valley</cell><cell>2</cell><cell>313</cell><cell>313</cell><cell>9.68</cell><cell>14.29</cell></row><row><cell cols="2">femalechild 12</cell><cell>79</cell><cell>79</cell><cell>2.30</cell><cell>3.85</cell></row><row><cell cols="2">male child 26</cell><cell>75</cell><cell>1152</cell><cell>2.17</cell><cell>5.00</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,657.79,332.45,7.86"><p>either handcrafted such as color, texture, etc. or learned such as deep features<ref type="bibr" coords="1,462.85,657.79,14.34,7.86" target="#b9">[10]</ref> </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,144.73,657.79,212.22,7.86"><p>http://www.imageclef.org/2016/annotation#Results</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="6,144.73,657.79,227.52,7.86;6,384.53,655.57,6.13,5.24;6,384.53,662.58,15.28,5.24;6,401.85,657.79,48.90,8.68"><p>The correlation factor of a concept is defined asFσ(c) = K c =1 1 {C(c |c)≥σ} .</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This work was supported in part by a grant from the <rs type="funder">Research Agency ANR (Agence Nationale de la Recherche)</rs> under the <rs type="projectName">MLVIS</rs> project <rs type="grantNumber">ANR-11-BS02-0017</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_bsj9mXc">
					<idno type="grant-number">ANR-11-BS02-0017</idno>
					<orgName type="project" subtype="full">MLVIS</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="13,142.96,145.99,337.64,7.86;13,151.52,156.95,329.07,7.86;13,151.52,167.91,223.50,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,352.19,145.99,128.40,7.86;13,151.52,156.95,153.65,7.86">Sharing visual features for multiclass and multiview object detection</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,318.42,156.95,162.16,7.86;13,151.52,167.91,135.95,7.86">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,179.35,337.63,7.86;13,151.52,190.31,329.07,7.86;13,151.52,201.26,302.55,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,308.33,179.35,172.25,7.86;13,151.52,190.31,109.18,7.86">Correlated label propagation with application to multi-label learning</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,284.52,190.31,169.64,7.86">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1719" to="1726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,212.70,337.64,7.86;13,151.52,223.66,329.07,7.86;13,151.52,234.62,45.05,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,243.24,212.70,191.86,7.86">Real-time computerized annotation of pictures</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,450.24,212.70,30.36,7.86;13,151.52,223.66,231.20,7.86">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="985" to="1002" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>IEEE Transactions on</note>
</biblStruct>

<biblStruct coords="13,142.96,246.06,337.64,7.86;13,151.52,257.02,141.40,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,328.99,246.06,151.61,7.86;13,151.52,257.02,31.19,7.86">A model for learning the semantics of pictures</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jeon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,209.43,257.02,54.56,7.86">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,268.46,337.63,7.86;13,151.52,279.42,329.07,7.86;13,151.52,290.38,100.34,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,270.24,268.46,210.35,7.86;13,151.52,279.42,42.24,7.86">A sparse kernel relevance model for automatic image annotation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,208.81,279.42,238.62,7.86">International Journal of Multimedia Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="209" to="229" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,301.82,337.64,7.86;13,151.52,312.78,329.07,7.86;13,151.52,323.74,253.32,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,436.94,301.82,43.65,7.86;13,151.52,312.78,225.51,7.86">Blobworld: A system for region-based image indexing and retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Carson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,402.08,312.78,78.51,7.86;13,151.52,323.74,171.17,7.86">Third International Conference on Visual Information Systems</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="509" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,335.18,337.63,7.86;13,151.52,346.14,329.07,7.86;13,151.52,357.09,329.07,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,375.40,335.18,105.19,7.86;13,151.52,346.14,304.42,7.86">Local features and kernels for classification of texture and object categories: A comprehensive study</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Marszalek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,151.52,357.09,173.14,7.86;13,341.79,357.09,110.45,7.86">Proceedings of the Beyond Patches workshop</title>
		<meeting>the Beyond Patches workshop</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>conjunction with CVPR2006</note>
</biblStruct>

<biblStruct coords="13,142.96,368.53,337.64,7.86;13,151.52,379.49,329.07,7.86;13,151.52,390.45,20.99,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,331.07,368.53,149.52,7.86;13,151.52,379.49,165.29,7.86">Automatic image annotation and retrieval using cross-media relevance models</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,342.54,379.49,81.76,7.86">Proc. of ACM SIGIR</title>
		<meeting>of ACM SIGIR</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="119" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,401.89,337.64,7.86;13,151.52,412.85,329.07,7.86;13,151.52,423.81,317.56,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,401.04,401.89,79.56,7.86;13,151.52,412.85,225.84,7.86">Supervised learning of semantic classes for image annotation and retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,392.87,412.85,87.72,7.86;13,151.52,423.81,177.75,7.86">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="394" to="410" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>IEEE Transactions on</note>
</biblStruct>

<biblStruct coords="13,142.61,435.25,337.98,7.86;13,151.52,446.21,329.06,7.86;13,151.52,457.17,134.29,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,344.49,435.25,136.10,7.86;13,151.52,446.21,121.56,7.86">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,301.54,446.21,179.04,7.86;13,151.52,457.17,31.99,7.86">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1106" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,468.61,337.98,7.86;13,151.52,479.57,261.97,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,416.37,468.61,64.22,7.86;13,151.52,479.57,49.10,7.86">Matching words and pictures</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Barnard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Duygululu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,212.51,479.57,172.74,7.86">The Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,491.01,337.98,7.86;13,151.52,501.96,329.07,7.86;13,151.52,512.92,165.66,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,207.40,491.01,273.19,7.86;13,151.52,501.96,89.94,7.86">Network-dependent image annotation based on explicit contextdependent kernel maps</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,264.95,501.96,215.64,7.86;13,151.52,512.92,55.93,7.86">Pattern Recognition (ICPR), 2014 22nd International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="625" to="630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,524.36,337.98,7.86;13,151.52,535.32,329.07,7.86;13,151.52,546.28,329.07,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,277.49,524.36,102.50,7.86">Modeling annotated data</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,406.89,524.36,73.70,7.86;13,151.52,535.32,329.07,7.86;13,151.52,546.28,92.59,7.86;13,359.63,546.28,38.76,7.86">Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval</title>
		<meeting>the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="127" to="134" />
		</imprint>
	</monogr>
	<note>SIGIR &apos;03</note>
</biblStruct>

<biblStruct coords="13,142.61,557.72,337.98,7.86;13,151.52,568.68,329.07,7.86;13,151.52,579.64,329.07,7.86;13,151.52,590.60,108.16,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,297.04,557.72,183.55,7.86;13,151.52,568.68,152.58,7.86">Annotating images and image objects using a hierarchical dirichlet process model</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Yakhnenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Honavar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,332.62,568.68,147.97,7.86;13,151.52,579.64,329.07,7.86;13,151.52,590.60,17.10,7.86">Proceedings of the 9th International Workshop on Multimedia Data Mining: held in conjunction with the ACM SIGKDD 2008</title>
		<meeting>the 9th International Workshop on Multimedia Data Mining: held in conjunction with the ACM SIGKDD 2008</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,602.04,337.97,7.86;13,151.52,613.00,326.98,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="13,250.54,602.04,230.05,7.86;13,151.52,613.00,74.71,7.86">Automatic linguistic indexing of pictures by a statistical modeling approach</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,239.08,613.00,89.19,7.86">IEEE Trans. on PAMI</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1075" to="1088" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,624.44,337.97,7.86;13,151.52,635.40,134.40,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="13,318.17,624.44,162.42,7.86;13,151.52,635.40,57.55,7.86">Multiscale conditional random fields for image labeling</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>Zimel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Carreira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,232.90,635.40,23.16,7.86">CVPR</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,646.84,337.98,7.86;13,151.52,657.79,329.07,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="13,287.44,646.84,193.15,7.86;13,151.52,657.79,61.80,7.86">Plsa-based image autoannotation: Constraining the latent space</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Monay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gaticaperez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,235.67,657.79,217.02,7.86">Proc. of ACM International Conference on Multimedia</title>
		<meeting>of ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,120.67,337.98,7.86;14,151.52,131.63,111.88,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="14,255.00,120.67,199.91,7.86">Translating topics to words for image annotation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,151.52,131.63,82.22,7.86">Proc. of ACM CIKM</title>
		<meeting>of ACM CIKM</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,142.60,337.97,7.86;14,151.52,153.56,329.07,7.86;14,151.52,164.51,309.86,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="14,334.57,142.60,146.02,7.86;14,151.52,153.56,232.32,7.86">Cbsa: content-based soft annotation for multimodal image retrieval using bayes point machines</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sychay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,396.27,153.56,84.33,7.86;14,151.52,164.51,179.26,7.86">Circuits and Systems for Video Technology, IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="38" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,175.48,337.97,7.86;14,151.52,186.44,329.07,7.86;14,151.52,197.40,329.07,7.86;14,151.52,208.36,87.55,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="14,348.79,175.48,131.79,7.86;14,151.52,186.44,216.04,7.86">Svm-knn: Discriminative nearest neighbor classification for visual category recognition</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,392.61,186.44,87.98,7.86;14,151.52,197.40,79.41,7.86">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2126" to="2136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,219.33,337.97,7.86;14,151.52,230.29,329.07,7.86;14,151.52,241.24,329.07,7.86;14,151.52,252.20,34.81,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="14,394.16,219.33,86.43,7.86;14,151.52,230.29,306.03,7.86">Tagprop: Discriminative metric learning in nearest neighbor models for image auto-annotation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Guillaumin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,151.52,241.24,67.95,7.86;14,249.42,241.24,158.66,7.86">IEEE 12th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="309" to="316" />
		</imprint>
	</monogr>
	<note>Computer Vision</note>
</biblStruct>

<biblStruct coords="14,142.62,263.17,337.98,7.86;14,151.52,274.13,252.73,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="14,326.02,263.17,146.13,7.86">A new baseline for image annotation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Makadia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pavlovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,162.27,274.13,120.42,7.86">Computer Vision-ECCV 2008</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="316" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,285.10,337.97,7.86;14,151.52,296.06,329.07,7.86;14,151.52,307.01,227.42,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="14,357.26,285.10,123.33,7.86;14,151.52,296.06,106.12,7.86">Coherent image annotation by learning semantic distance</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,281.63,296.06,169.70,7.86;14,151.52,307.01,136.11,7.86">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>CVPR 2008. IEEE Conference on</note>
</biblStruct>

<biblStruct coords="14,142.62,317.98,337.97,7.86;14,151.52,328.94,329.07,7.86;14,151.52,339.90,157.32,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="14,265.86,317.98,214.73,7.86;14,151.52,328.94,67.05,7.86">A discriminative kernel-based approach to rank images from text queries</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,229.44,328.94,251.15,7.86;14,151.52,339.90,8.29,7.86">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1371" to="1384" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>IEEE Transactions on</note>
</biblStruct>

<biblStruct coords="14,142.62,350.87,337.98,7.86;14,151.52,361.83,329.07,7.86;14,151.52,372.79,34.81,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="14,323.46,350.87,112.40,7.86">Image annotation using svm</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cusano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ciocca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schettini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,460.70,350.87,19.89,7.86;14,151.52,361.83,60.04,7.86">Electronic Imaging</title>
		<imprint>
			<publisher>International Society for Optics and Photonics</publisher>
			<date type="published" when="2003">2004. 2003</date>
			<biblScope unit="page" from="330" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,383.75,337.98,7.86;14,151.52,394.71,329.07,7.86;14,151.52,405.67,88.76,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="14,305.84,383.75,174.75,7.86;14,151.52,394.71,248.51,7.86">Automatic image annotation by incorporating feature hierarchy and boosting to scale up svm classifiers</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,423.51,394.71,57.07,7.86;14,151.52,405.67,58.81,7.86">Proc. of ACM MULTIMEDIA</title>
		<meeting>of ACM MULTIMEDIA</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,416.64,337.97,7.86;14,151.52,427.60,329.07,7.86;14,151.52,438.56,132.60,7.86" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="14,329.81,416.64,150.78,7.86;14,151.52,427.60,50.71,7.86">Context-dependent kernels for object classification</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Y</forename><surname>Audibert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Keriven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,215.99,427.60,260.95,7.86">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="699" to="708" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,449.52,337.97,7.86;14,151.52,460.48,329.07,7.86;14,151.52,471.44,94.29,7.86" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="14,199.83,449.52,280.75,7.86;14,151.52,460.48,271.62,7.86">Cnrs-telecom paristech at imageclef 2013 scalable concept image annotation task: Winning annotations with context dependent svms</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,455.98,460.48,24.61,7.86;14,151.52,471.44,66.10,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,482.41,337.98,7.86;14,151.52,493.37,186.63,7.86" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="14,247.93,482.41,232.67,7.86;14,151.52,493.37,68.86,7.86">Transductive kernel map learning and its application to image annotation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,243.67,493.37,24.39,7.86">BMVC</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,504.34,337.97,7.86;14,151.52,515.29,329.07,7.86;14,151.52,526.25,193.93,7.86" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="14,242.61,504.34,237.98,7.86;14,151.52,515.29,251.27,7.86">Context based support vector machines for interconnected image annotation (the saburo tsuji best regular paper award)</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,441.42,515.29,39.18,7.86;14,151.52,526.25,164.62,7.86">the Asian Conference on Computer Vision (ACCV)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,537.22,337.98,7.86;14,151.52,548.18,329.07,7.86;14,151.52,559.14,158.46,7.86" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="14,255.32,537.22,200.85,7.86">Deep kernel map networks for image annotation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,151.52,548.18,329.07,7.86;14,151.52,559.14,38.81,7.86">2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1571" to="1575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,570.11,337.98,7.86;14,151.52,581.06,329.07,7.86;14,151.52,592.02,158.46,7.86" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="14,247.54,570.11,211.67,7.86">Laplacian deep kernel learning for image annotation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,151.52,581.06,329.07,7.86;14,151.52,592.02,38.81,7.86">2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1551" to="1555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,602.99,337.98,7.86;14,151.52,613.95,329.07,7.86;14,151.52,624.91,20.99,7.86" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="14,197.35,602.99,246.47,7.86">Imageclef annotation with explicit context-aware kernel maps</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,457.40,602.99,23.19,7.86;14,151.52,613.95,216.32,7.86">International Journal of Multimedia Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="113" to="128" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,635.88,337.97,7.86;14,151.52,646.84,329.07,7.86;14,151.52,657.79,111.73,7.86" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="14,250.28,635.88,230.30,7.86;14,151.52,646.84,51.61,7.86">Transductive inference &amp; kernel design for object class segmentation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,225.83,646.84,250.75,7.86">2012 19th IEEE International Conference on Image Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2173" to="2176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,120.67,337.97,7.86;15,151.52,131.63,329.07,7.86;15,151.52,142.59,158.46,7.86" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="15,245.06,120.67,227.08,7.86">Semi supervised deep kernel design for image annotation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,161.62,131.63,318.97,7.86;15,151.52,142.59,38.81,7.86">2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1156" to="1160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,153.55,337.98,7.86;15,151.52,164.51,329.07,7.86;15,151.52,175.46,168.22,7.86" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="15,377.12,153.55,103.47,7.86;15,151.52,164.51,177.89,7.86">Context-dependent kernel design for object matching and recognition</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Y</forename><surname>Audibert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rabarisoa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Keriven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,356.81,164.51,123.78,7.86;15,151.52,175.46,75.27,7.86">Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,186.42,337.98,7.86;15,151.52,197.38,329.07,7.86;15,151.52,208.34,235.29,7.86" xml:id="b36">
	<analytic>
		<title level="a" type="main" coord="15,382.48,186.42,98.11,7.86;15,151.52,197.38,159.86,7.86">Learning structured prediction models: A large margin approach</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Chatalbashev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,333.26,197.38,147.33,7.86;15,151.52,208.34,126.22,7.86">Proceedings of the 22nd international conference on Machine learning</title>
		<meeting>the 22nd international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="896" to="903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,219.30,337.97,7.86;15,151.52,230.26,329.07,7.86;15,151.52,241.22,163.00,7.86" xml:id="b37">
	<analytic>
		<title level="a" type="main" coord="15,399.95,219.30,80.64,7.86;15,151.52,230.26,224.62,7.86">Large margin methods for structured and interdependent output variables</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tsochantaridis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Altun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,400.78,230.26,79.80,7.86;15,151.52,241.22,71.79,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="page" from="1453" to="1484" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,252.18,337.98,7.86;15,151.52,263.14,329.07,7.86;15,151.52,274.09,94.21,7.86" xml:id="b38">
	<analytic>
		<title level="a" type="main" coord="15,287.07,252.18,193.52,7.86;15,151.52,263.14,22.89,7.86">Structured learning and prediction in computer vision</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,186.60,263.14,246.40,7.86">Foundations and Trends R in Computer Graphics and Vision</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="185" to="365" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,285.05,337.98,7.86;15,151.52,296.01,329.07,7.86;15,151.52,306.97,262.59,7.86" xml:id="b39">
	<analytic>
		<title level="a" type="main" coord="15,338.67,285.05,141.92,7.86;15,151.52,296.01,137.82,7.86">Kernelized structural svm learning for supervised object segmentation</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bertelli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Gokturk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,311.92,296.01,168.67,7.86;15,151.52,306.97,31.49,7.86;15,213.66,306.97,81.50,7.86">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="page" from="2153" to="2160" />
		</imprint>
	</monogr>
	<note>IEEE Conference on</note>
</biblStruct>

<biblStruct coords="15,142.62,317.93,337.97,7.86;15,151.52,328.89,329.07,7.86;15,151.52,339.85,111.73,7.86" xml:id="b40">
	<analytic>
		<title level="a" type="main" coord="15,245.95,317.93,234.64,7.86;15,151.52,328.89,42.24,7.86">Modeling label dependencies in kernel learning for image annotation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,216.08,328.89,260.23,7.86">2014 IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="5886" to="5890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,350.81,337.98,7.86;15,151.52,361.77,329.07,7.86;15,151.52,372.72,59.90,7.86" xml:id="b41">
	<analytic>
		<title level="a" type="main" coord="15,241.03,350.81,219.23,7.86">Contextual kernel map learning for scene transduction</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,151.52,361.77,100.07,7.86;15,282.97,361.77,139.85,7.86">IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="3797" to="3801" />
		</imprint>
	</monogr>
	<note>Image Processing (ICIP)</note>
</biblStruct>

<biblStruct coords="15,142.62,383.68,337.98,7.86;15,151.52,394.64,329.07,7.86;15,151.52,405.60,329.07,7.86;15,151.52,416.56,140.62,7.86" xml:id="b42">
	<analytic>
		<title level="a" type="main" coord="15,394.81,383.68,85.78,7.86;15,151.52,394.64,270.58,7.86">Object recognition as machine translation: Learning a lexicon for a fixed image vocabulary</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Duygulu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Barnard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F G</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,342.85,405.60,75.52,7.86">ECCV 2002. LNCS</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Heyden</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Sparr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Johansen</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2353</biblScope>
			<biblScope unit="page" from="97" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.61,427.52,337.98,7.86;15,151.52,438.48,296.07,7.86" xml:id="b43">
	<analytic>
		<title level="a" type="main" coord="15,259.44,427.52,120.61,7.86">A survey on transfer learning</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,395.21,427.52,85.39,7.86;15,151.52,438.48,142.43,7.86">Knowledge and Data Engineering, IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.61,449.44,337.98,7.86;15,151.52,460.40,329.07,7.86;15,151.52,469.09,329.07,10.13;15,151.52,482.31,329.07,7.86;15,151.52,493.27,32.58,7.86" xml:id="b44">
	<analytic>
		<title level="a" type="main" coord="15,301.48,460.40,179.11,7.86;15,151.52,471.36,128.92,7.86">Overview of the ImageCLEF 2016 Scalable Concept Image Annotation Task</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ramisa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Dellandrea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<ptr target="-WS.org¡http://ceur-ws.org¿" />
	</analytic>
	<monogr>
		<title level="m" coord="15,302.98,471.36,104.52,7.86">CLEF2016 Working Notes</title>
		<title level="s" coord="15,237.87,482.31,149.76,7.86">CEUR Workshop Proceedings, CEUR</title>
		<meeting><address><addrLine>Évora, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-08">September 5-8 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.61,504.23,337.98,7.86;15,151.52,515.19,329.07,7.86;15,151.52,526.15,329.07,7.86;15,151.52,537.11,329.07,7.86;15,151.52,548.07,239.88,7.86" xml:id="b45">
	<analytic>
		<title level="a" type="main" coord="15,461.29,526.15,19.30,7.86;15,151.52,537.11,219.57,7.86">General Overview of ImageCLEF at the CLEF 2016 Labs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schaer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ramisa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Dellandrea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">H</forename><surname>Toselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Snchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="15,412.48,537.11,68.10,7.86;15,151.52,548.07,71.32,7.86">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.61,559.03,337.97,7.86;15,151.52,569.99,329.07,7.86;15,151.52,580.94,248.29,7.86" xml:id="b46">
	<analytic>
		<title level="a" type="main" coord="15,197.16,559.03,283.42,7.86;15,151.52,569.99,257.94,7.86">Cnrs telecom paristech at imageclef 2015 scalable concept image annotation task: Concept detection with blind localization proposals</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,433.61,569.99,46.99,7.86;15,151.52,580.94,123.37,7.86">CLEF 2015 Evaluation Labs and Workshop</title>
		<title level="s" coord="15,282.94,580.94,88.61,7.86">Online Working Notes</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.61,591.90,337.98,7.86;15,151.52,602.86,329.07,7.86;15,151.52,613.82,70.97,7.86" xml:id="b47">
	<analytic>
		<title level="a" type="main" coord="15,401.89,591.90,78.70,7.86;15,151.52,602.86,208.75,7.86">Return of the devil in the details: Delving deep into convolutional nets</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,385.19,602.86,95.40,7.86;15,151.52,613.82,42.64,7.86">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
