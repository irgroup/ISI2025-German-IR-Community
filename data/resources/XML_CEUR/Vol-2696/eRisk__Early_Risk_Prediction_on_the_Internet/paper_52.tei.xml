<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,146.13,115.96,323.11,12.62;1,136.95,133.89,341.45,12.62;1,272.01,151.82,71.34,12.62">Deep learning architectures and strategies for early detection of self-harm and depression level prediction</title>
				<funder ref="#_degRhdg">
					<orgName type="full">Generalitat Valenciana</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,223.60,189.49,77.49,8.74"><forename type="first">Ana-Sabina</forename><surname>Uban</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">PRHLT Research Center</orgName>
								<orgName type="institution">Universitat Politècnica de València</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Human Language Technologies Research Center</orgName>
								<orgName type="institution">University of Bucharest</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,334.59,189.49,52.69,8.74"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
							<email>prosso@dsic.upv.es</email>
							<affiliation key="aff0">
								<orgName type="department">PRHLT Research Center</orgName>
								<orgName type="institution">Universitat Politècnica de València</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,146.13,115.96,323.11,12.62;1,136.95,133.89,341.45,12.62;1,272.01,151.82,71.34,12.62">Deep learning architectures and strategies for early detection of self-harm and depression level prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1331D8F1F56AFB5680F6577B34FEFE29</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>deep learning</term>
					<term>mental disorders</term>
					<term>BERT</term>
					<term>hierarchical attention network</term>
					<term>self-harm</term>
					<term>depression</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper summarizes the contributions of the PRHLT-UPV team as a participant in the eRisk 2020 tasks on self-harm detection and prediction of depression levels from social media. Computational methods based on machine learning and natural language processing have a great potential to assist with early detection of mental disorders of social media users, based on their online activity. We use multi-dimensional representations of language, and compare various deep learning models' performance, exploring rarely approached avenues in previous research, including hierarchical deep learning architectures and pre-trained transformers and language models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Mental health disorders affect hundreds of millions of people worldwide; <ref type="bibr" coords="1,448.83,461.30,15.50,8.74" target="#b16">[17]</ref> depression alone is a major factor for suicide, and is usually underdiagnosed and undertreated. People affected by mental disorders often turn to social media to talk about their problems. There is an important opportunity for automatic processing of social media data in order to identify changes in mental health status that may otherwise go undetected before they develop more serious health consequences. Identifying people who start to develop signs of a mental illness early on is very important to managing its evolution, and in certain cases it can be life-saving. Recently, the recent COVID-19 pandemic is expected to exacerbate this problem, affecting mental health as well as physical health <ref type="bibr" coords="1,412.59,568.90,9.96,8.74" target="#b8">[9]</ref>.</p><p>The CLEF eRisk Lab 3 , organized every year since 2017, is dedicated specifically to identifying early signs of mental disorders from a user's social media posts, before the user was diagnosed with the disorder, for disorders including depression, anorexia and thoughts of self-harm <ref type="bibr" coords="2,346.61,118.99,12.45,8.74" target="#b9">[10]</ref><ref type="bibr" coords="2,359.06,118.99,4.15,8.74" target="#b10">[11]</ref><ref type="bibr" coords="2,363.21,118.99,12.45,8.74" target="#b11">[12]</ref>. Each year a new task is organized around predicting a specific disorder: in 2017 and 2018 the shared tasks focused on depression detection, in 2019 a new task for anorexia prediction was organized, as well as a second task around predicting self-harm tendencies without any training data; in 2020 self-harm detection was again the topic, this time in a supervised setting. Datasets are collected from Reddit posts and comments selected from specific relevant sub-reddits, annotated by automatically detecting self-stated diagnoses of users. Healthy users are selected from participants in the same sub-reddits, thus making sure the gap between healthy and diagnosed users is not trivially detectable. For the self-harm task, the dataset includes only posts published before any involvement in the self-harm related communities, which conditions any model trained on this data to be capable of very early prediction, and at the same time adds difficulty to the task.</p><p>The language used by a speaker has been shown to contain strong indicators of an altered mental state. These can manifest both explicitly, at the level of the topics approached, or implicitly, at the level of the emotional charge of the text (greater negative emotion <ref type="bibr" coords="2,268.70,329.92,10.30,8.74" target="#b4">[5]</ref>), or even more subtle stylistic indicators (such as the increased use of first-person pronouns <ref type="bibr" coords="2,342.21,341.87,14.76,8.74" target="#b24">[25]</ref>). Textual data from social media, as a very rich and relatively easy to obtain type of data, as well as continuously growing source of real-time information, can thus be leveraged to gain many valuable insights into an individual's behavior and mental state and its evolution.</p><p>Most previous research related to automatic mental disorder detection from social media data have focused the study of depression <ref type="bibr" coords="2,378.69,433.24,10.52,8.74" target="#b5">[6,</ref><ref type="bibr" coords="2,390.86,433.24,7.75,8.74" target="#b7">8,</ref><ref type="bibr" coords="2,400.28,433.24,7.01,8.74" target="#b0">1]</ref>, but other mental illnesses have also been studied, including generalized anxiety disorder <ref type="bibr" coords="2,462.33,445.20,14.60,8.74" target="#b22">[23]</ref>, schizophrenia <ref type="bibr" coords="2,198.51,457.15,14.61,8.74" target="#b12">[13]</ref>, post-traumatic stress disorder <ref type="bibr" coords="2,361.37,457.15,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="2,373.54,457.15,7.01,8.74" target="#b3">4]</ref>, risks of suicide <ref type="bibr" coords="2,462.32,457.15,14.61,8.74" target="#b15">[16]</ref>, anorexia <ref type="bibr" coords="2,176.26,469.11,15.50,8.74" target="#b10">[11]</ref> and self-harm <ref type="bibr" coords="2,262.01,469.11,14.61,8.74" target="#b10">[11]</ref>. The majority of studies on mental disorder detection use simple machine learning models (such as support vector machines (SVMs) and logistic regression) <ref type="bibr" coords="2,273.60,493.02,10.52,8.74" target="#b5">[6,</ref><ref type="bibr" coords="2,285.79,493.02,7.01,8.74" target="#b4">5]</ref>. Few studies have used more complex deep learning methods <ref type="bibr" coords="2,214.73,504.97,15.50,8.74" target="#b20">[21,</ref><ref type="bibr" coords="2,231.89,504.97,12.73,8.74" target="#b24">25,</ref><ref type="bibr" coords="2,246.28,504.97,12.73,8.74" target="#b25">26,</ref><ref type="bibr" coords="2,260.67,504.97,11.62,8.74" target="#b21">22]</ref>. At the level of features, most previous works have used traditional bag of words n-grams <ref type="bibr" coords="2,335.87,516.93,9.96,8.74" target="#b2">[3]</ref>, as well as hand-crafted lexicons <ref type="bibr" coords="2,156.51,528.88,14.61,8.74" target="#b23">[24]</ref>, LIWC features <ref type="bibr" coords="2,244.48,528.88,9.96,8.74" target="#b4">[5]</ref>, or Latent Semantic Analysis <ref type="bibr" coords="2,385.86,528.88,15.50,8.74" target="#b19">[20,</ref><ref type="bibr" coords="2,403.02,528.88,11.62,8.74" target="#b23">24]</ref>. There are few studies which jointly consider several aspects of the language <ref type="bibr" coords="2,404.14,540.84,15.50,8.74" target="#b21">[22,</ref><ref type="bibr" coords="2,421.30,540.84,11.62,8.74" target="#b22">23]</ref>.</p><p>This study summarizes our contributions as participants to the eRisk shared tasks on self-harm detection and assessment of depression levels <ref type="bibr" coords="2,411.64,584.39,14.60,8.74" target="#b11">[12]</ref>. We explore the use of deep learning for detecting mental disorders from text data, and compare various architectures, including hierarchical attention networks and transformers. We model our text data using a multi-aspect representation, through using features that reflect various complementary levels of the language, including content, style and emotion. For predicting the level of depression, we use traditional machine learning models including SVMs and Logistic Regression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task 1. Self-harm detection</head><p>The first task in eRisk 2020 consists of detecting whether a user is at risk of developing self-harm tendencies. Training data collected from Reddit was available, consisting of 340 users (of which 41 were labelled as positive) and their Reddit post history. Test data was provided as a stream of user posts, and candidate systems were asked to provide a decision (a binary number: a user is at risk or not), as well as a risk score (a real number), at each time step in the stream.</p><p>We participated in the task with five different models. We implement several neural network architectures, as well as experiment with pre-trained models and strategies for sampling training data in order to improve results. Details of the architectures used and the experimental setup are described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Features</head><p>Content features. We include a general representation of text content by transforming each text into word sequences. Preprocessing of texts includes lowercasing and tokenizing, removing punctuation and numbers; function words are not excluded. Most frequent 20,000 words were selected to form the vocabulary, and words not in the vocabulary were represented as a special "unknown" token. When passed as input to the neural networks, words within a sequence were encoded as embeddings of dimension 100. In order to initialize the weights of the embedding layers, we started from GloVe embeddings pre-trained on Twitter data. The choice of pre-trained embeddings was justified by their dimension, which is smaller than for other GloVe embeddings pre-trained on large corpora, leading to fewer mode parameters overall (in view of avoiding overfitting problems). Nevertheless, even though the data for this task is also sampled from social media, the two platforms (Reddit and Twitter) have significant differences as well; exploring the use of other embedding initializations (especially using embeddings pre-trained on longer texts) would be interesting in future experiments.</p><p>Style features. We aim at representing the stylistic level of texts through including function word and pronoun features. Function words have traditionally been used as stylistic markers, whereas increased use of pronouns, especially first person pronouns, has been shown to correlate with mental disorder risk <ref type="bibr" coords="3,134.77,541.34,14.61,8.74" target="#b23">[24]</ref>. We include two separate stylistic features: firstly, we extract from each text a numerical vector representing function words frequencies as bag-of-words. Separately, we include a simple scalar feature meant to capture the first person personal pronoun usage, by measuring the proportion of first person pronouns relative to the total number of words used in a text. We complement these with features extracted from the LIWC lexicon, as described below.</p><p>LIWC features. The LIWC<ref type="foot" coords="3,280.77,611.61,3.97,6.12" target="#foot_0">4</ref>  <ref type="bibr" coords="3,289.38,613.18,15.50,8.74" target="#b17">[18]</ref> is a lexicon mapping words in the English vocabulary to lexico-syntactic features of different kinds. It has been widely used in computational studies for analysing how suffering from mental disorders manifests in an author's writings. LIWC categories have the capacity to capture different levels of language: including style (through syntactic categories), emotions (through affect categories) and topics (through content-oriented categories such as words referring to cognitive or analytical processes, or words referring to topics such as money, health or religion). We include in our analysis all 64 categories in the lexicon, and represent them as numerical vectors by computing for each category the ratio of words in a text that are related to the category, according to the lexicon.</p><p>Emotions and sentiment. We dedicate a few features to represent emotional content in our texts, since the emotional state of a user is known to be highly correlated with his/her mental health. Several of the LIWC categories aim to capture sentiment polarity and emotion content (negative emotion, positive emotion, affect, sadness, anxiety). We additionally include a second lexicon: the NRC emotion lexicon <ref type="bibr" coords="4,249.10,275.06,14.61,8.74" target="#b13">[14]</ref>, which is dedicated exclusively to emotion representation, containing 9 different emotion categories: anger, anticipation, disgust, fear, joy, negative,positive, sadness, surprise, trust. We represent NRC features similarly to LIWC features, by computing for each category the proportion of words in the text which are associated with that category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Experimental setup</head><p>During the training phase as well as for testing, we do not consider social media posts individually as datapoints, since they are too short to be sufficiently predictive. Instead, we generate our datapoints by grouping sequences of 50 chronologically consecutive posts into larger chunks, to obtain more consistent samples of text as our datapoints. Features are computed at chunk-level.</p><p>As a consequence, prediction is always done on chunks of 50 posts. When analyzing the input stream of test data, we form new chunks of the last 50 posts received periodically (after every 20 new posts), and feed them to the networks to generate predictions.</p><p>As we will describe in the following section, we use two types of architectures for modelling the input: sequential and hierarchical. We adopt a special strategy for predictions on the first 50 posts in the stream: we pad the input data up to the size used during training (512 words in the case of the sequential setup and 50 posts of length 256 in the case of the hierarchical setup), but only submit the output score provided by the network, and as decisions (user is at risk or not) we submit zeros regardless of the output score, so as not to send premature alerts (since once a user is declared at risk, the decision can not be reverted).</p><p>Sequence sampling. For one of our runs, we employ a special strategy during the training phase. We attempt to augment the training data through generating "artificial" chunks of user posts, aside from the ones formed naturally through chunking the user's post history in chronological order. We do this by sampling from the post history randomly, following an exponential distribution so as to sample with higher probability from recent posts (which are more likely to contain signs of the disorder). The chronological order of posts is maintained.</p><p>Rolling average of predictions. As previously mentioned, for most runs predictions are generated using the last 50 posts seen in the test data stream. For one of our runs, we use a different strategy, by computing a rolling average of the most recent 3 network outputs: in this way, we hope to obtain more robust results that are not dependent only on the last batch of 50 user posts, but take into account a larger window of context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Architectures</head><p>BiLSTM with attention. The first model we consider is a bidirectional LSTM network, with attention. Input word sequences are truncated at maximum 512 words, with words encoded as embeddings, and passed as input to the BiLSTM layer with 256 units, which is then fed to an attention layer. The bagof-words features representing function word distribution are passed through a dense layer of 20 units; and the remaining extracted features (including pronoun, emotion and LIWC category usage) are concatenated into one vector. The output of the BiLSTM is concatenated along with the other features and the final representation passed through an output layer that generates the final prediction. Hierarchical Attention Network. Hierarchical attention networks (HAN) were introduced in <ref type="bibr" coords="5,220.98,572.43,15.50,8.74" target="#b26">[27]</ref> where they were used for review classification, by representing a text as a hierarchical structure where a document is comprised of sentences and a sentence is comprised of words. We propose that social media data in our setup is very well suited to such a hierarchical representation; in our case the hierarchy consists of user post histories, which are composed of social media posts, which are in turn composed of word sequences. Especially since the evolution of the mental state of a user is in itself a relevant indicator for the development of a disorder, as shown in <ref type="bibr" coords="5,330.56,656.12,14.61,8.74" target="#b18">[19]</ref>, user-level representations are expected to be natural and useful for modelling this problem. One other study has included post-level and user-level attention on their classifier's architecture, obtaining top results in the anorexia detection shared task <ref type="bibr" coords="6,393.55,142.90,14.61,8.74" target="#b14">[15]</ref>.</p><p>In the hierarchical setup, posts within a chunk (datapoint) are stacked to form a hierarchical structure: word sequences (truncated at 256 words), as well as the rest of vectorial numerical and bag-of-words features, are stacked to form bi-dimensional vectors. Bag-of-words and numerical features also follow a hierarchical structure, with a set of features extracted for each post in the group, and stacked together into bi-dimensional vectors. The hierarchical network is composed of two components: a post-level encoder, which produces a representation of a post, and a user-level encoder, which generates a representation of a user's post history. For encoding the word sequence at post-level, we use a convolutional layer with 100 filters of length 3. Each of the posts in the input datapoint is encoded with the post-level encoder, and then they are stacked to form a bi-dimensional representation, which is then concatenated with the other features, and passed to the user-level encoder. We choose to model the user-level encoder as an LSTM layer with attention, with 32 units. The output of the user encoder is connected to the output layer which generates the final prediction. A depiction of the hierarchical architecture is shown in Figure <ref type="figure" coords="6,398.33,334.19,3.87,8.74" target="#fig_0">1</ref>.</p><p>Transformers. We experiment with state-of-the-art language models based on transformer architectures, which have been shown to obtain high performances on a wide range of NLP tasks, with minimal task-specific training. We use pre-trained BERT <ref type="bibr" coords="6,232.97,382.01,10.52,8.74" target="#b6">[7]</ref> models for English (the "base" versions of the models) with one trainable output layer and fine-tune them for our task.</p><p>Ensemble. Finally, we use a simple ensemble model for one of our runs: predictions are generated through averaging the outputs of several other models on the received input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Models submitted</head><p>The models and setups used for each of the five runs submitted by our team are described below.</p><p>Run 0. BERT + sequence sampling. For our first run we used the pretrained and fine-tuned BERT model. During fine-tuning, the sequence sampling strategy for data augmentation was used.</p><p>Run 1. BiLSTM. Run 1 consists of the BiLSTM model described in the previous section.</p><p>Run 2. Hierarchical CNN + LSTM. For run 2 we used the hierarchical attention network with CNN and LSTM layers. Due to memory limitations, we only generated predictions for the first 50 posts in the stream: all subsequent predictions (for all datapoints in the stream) were based on these outputs.</p><p>Run 3. Ensemble. For this run, we used an ensemble of the first three models: BERT, the BiLSTM and the hierarchical attention network. To obtain prediction scores, we averaged the outputs of the three networks for each input datapoint. A user is considered at risk if the obtained output exceeds the 0.5 threshold.</p><p>Run 4. Rolling average of BiLSTM. For our last run, we used the rolling average strategy described in the previous section, to obtain a smoothed version of the model's outputs. For each timestep, we averaged the output of the BiLSTM model for the most recent three inputs (chunks of 50 posts).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Results</head><p>Table <ref type="table" coords="7,162.24,207.32,4.98,8.74" target="#tab_0">1</ref> show the official results obtained for each of our runs. Evaluation measures included the traditional precision, recall and F1-scores computed at userlevel, as well as some metrics specifically designed for measuring how early risk was detected: latency-weighted F1, which is the F1-score weighted by a penalizing factor for late predictions, and ERDE <ref type="bibr" coords="7,318.17,255.14,14.61,8.74" target="#b11">[12]</ref>, a measure of error that increases when predictions are delayed. For comparison, we include the systems that obtained best scores for each metric. The best F1-scores were obtained with the BERT model using sequence sampling training, showing that pre-trained transformers are powerful for external tasks including detection of self-harm, and also that the sequence sampling strategy might be an effective method for data augmentation. The second best results were obtained with the last model -the rolling average of outputs strategy brings significant improvement to predictions compared to the base model (simple BiL-STM). We attribute the poorer performance of the HAN and ensemble models to the small size of test data used for predictions (first 50 posts in the stream).</p><p>A second evaluation approach treats the task as a ranking task, by using the system's continuous risk scores and ranking users in order of risk according to these scores. Metrics specific to ranking tasks are used to measure performance, including precision @ k (P@10), and Normalized Discounted Cumulative Gain @ k (NDCG@10, NDCG@100). In Table <ref type="table" coords="8,304.90,238.59,4.98,8.74" target="#tab_1">2</ref> we show the evaluation results for our systems using the ranking metrics, measured on the first 500 posts in the input stream. Our models perform well on these metrics, the first system obtaining perfect scores for both metrics measured @ 10. For comparison, we include the system that obtained best scores in terms of all ranking metrics @ 500 writings, submitted by the iLab team.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task 2. Predicting levels of depression</head><p>The second task consisted of predicting the level of depression of social media users, by predicting answers to a 21-question questionnaire for assessing depression, where each question can have one of four to six answers. Training data consisting of 20 labelled users was available beforehand. The test data consisted of 70 users' social media posts, and the participating systems had to predict their answers to each of the questions.</p><p>Several evaluation metrics were used, measuring how well the predictions match the true labels, from more fine-grained to more general levels, including: average hit rate (AHR), average closeness rate (ACR), average difference between overall depression levels (ADODL), depression category hit rate (DCHR).</p><p>We participated with three different models in this task. The details of the models and features used are described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Features</head><p>For the first two models, we used a few of the same features described in the previous sections. We included the lower-dimensionality numerical features: LIWC and emotion categories, represented as continuous vectors. For obtaining userlevel representations, we averaged the values of these vectors computed for each of the user's posts. Since it has been shown that the evolution of certain behaviors and linguistic markers is in itself predictive of developing a disorder or not, we choose to capture the variation of the features extracted, by including in our feature vectors the standard variations (aside from the averages) seen in the distribution of each feature across a user's history of posts.</p><p>For our final model, we tried to leverage pre-trained language models in order to obtain semantic representations of the user's social media posts. To this effect, we extracted sentence representations from Universal Sentence Encoder (USE) <ref type="bibr" coords="9,134.77,130.95,10.52,8.74" target="#b1">[2]</ref> for each of the posts in a user's history, obtaining a continuous vectorial representation for each post. A user's representation was obtained by averaging the representations of each of his/her posts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Models</head><p>We chose to use simpler traditional machine learning models for this task with fewer parameters than the neural networks used in task 1, to suit the small size of the training data: we experimented with SVM and logistic regression models, using the features previously described.</p><p>All models were trained on the available training data, and the trained models were used to make predictions on the new data in the testing phase. For each of the models, we modelled the task as a multi-label multi-class classification problem, by training one model for each of the 21 questions, where each question can be assigned one of 4-6 labels (depending on the question).</p><p>LogReg-features The first model used was a logistic regression model with the lexicon-based features represented as numerical vectors.</p><p>SVM-features For the second run, we used an SVM with RBF kernel, with the same features as for the previous run.</p><p>SVM-USE Our last model was an SVM with RBF kernel, and USE features. Table <ref type="table" coords="9,178.15,560.48,4.98,8.74" target="#tab_2">3</ref> shows official results results for task 2, for all evaluation metrics. Our best models in terms of DCHR were the models using lexicon-based features, which obtained the maximum score of all participating teams on this metric. The model using USE features has better performance than the other two for the rest of the metrics. The good scores obtained with simple models and features suggest the problem may not be well suited to complex representations and architectures, possibly due to the small size of the training data. For comparison, we include in the table results of the systems that obtained best scores in terms of the other metrics (aside from DCHR). Overall, scores for this task were modest for all participating teams, suggesting predicting the level of depression is a difficult task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper we presented the contributions of the PRHLT-UPV team in the eRisk 2020 shared tasks: self-harm detection and the prediction of depression levels, based on social media text data. We used multi-dimensional features to represent various levels of the language, including content, style and emotion. In the first task, where more training data was available, we experimented with different deep learning architectures, including hierarchical attention networks and transformers, as well as with different strategies concerning the experimental setup: such as sequence sampling for data augmentation, and rolling average for smoothing model outputs. For the second task we used traditional models such as SVM and logistical regression, with features including style and emotion features, as well as semantic sentence representations from pre-trained language models. We obtained best scores in terms of detecting the general depression category in the second task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,203.95,527.42,207.46,7.89;5,169.35,363.97,276.66,148.67"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Hierarchical attention network architecture.</figDesc><graphic coords="5,169.35,363.97,276.66,148.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,139.49,310.58,333.31,277.54"><head>Table 1 .</head><label>1</label><figDesc>Official results for task 1</figDesc><table coords="7,139.49,310.58,333.31,277.54"><row><cell>Run</cell><cell cols="5">Precision Recall F1 ERDE5 ERDE50 latencyw-F1</cell></row><row><cell>BERT+seq-sampling</cell><cell>.469</cell><cell cols="2">.654 .546 .291</cell><cell>.154</cell><cell>.462</cell></row><row><cell>BiLSTM</cell><cell>.710</cell><cell cols="2">.212 .326 .251</cell><cell>.235</cell><cell>.172</cell></row><row><cell>HAN</cell><cell>.271</cell><cell cols="2">.577 .369 .339</cell><cell>.269</cell><cell>.298</cell></row><row><cell>Ensemble</cell><cell>.846</cell><cell cols="2">.212 .338 .248</cell><cell>.232</cell><cell>.178</cell></row><row><cell>BiLSTM+rolling</cell><cell>.765</cell><cell cols="2">.375 .503 .253</cell><cell>.194</cell><cell>.423</cell></row><row><cell>iLab/run 1</cell><cell>.913</cell><cell cols="2">.404 .560 .248</cell><cell>.149</cell><cell>.540</cell></row><row><cell>SSN NLP/run 1</cell><cell>.283</cell><cell>1</cell><cell>.442 .205</cell><cell>.158</cell><cell>.442</cell></row><row><cell>iLab/run 4</cell><cell>.828</cell><cell cols="2">.692 .754 .255</cell><cell>.255</cell><cell>.476</cell></row><row><cell>iLab/run 2</cell><cell>.544</cell><cell cols="2">.654 .594 .134</cell><cell>.118</cell><cell>.592</cell></row><row><cell>iLab/run 3</cell><cell>.564</cell><cell cols="2">.885 .689 .287</cell><cell>.071</cell><cell>.572</cell></row><row><cell>iLab/run 0</cell><cell>.833</cell><cell cols="2">.577 .682 .252</cell><cell>.111</cell><cell>.658</cell></row><row><cell>Run</cell><cell></cell><cell cols="3">P@10 NDCG@10 NDCG@100</cell><cell></cell></row><row><cell cols="3">BERT+seq-sampling 1</cell><cell>1</cell><cell>.68</cell><cell></cell></row><row><cell>BiLSTM</cell><cell></cell><cell>.9</cell><cell>.81</cell><cell>.75</cell><cell></cell></row><row><cell>HAN</cell><cell></cell><cell>.6</cell><cell>.69</cell><cell>.48</cell><cell></cell></row><row><cell>Ensemble</cell><cell></cell><cell>.9</cell><cell>.81</cell><cell>.75</cell><cell></cell></row><row><cell cols="2">BiLSTM+rolling</cell><cell>.9</cell><cell>.90</cell><cell>.69</cell><cell></cell></row><row><cell>iLab/run 3</cell><cell></cell><cell>1</cell><cell>1</cell><cell>.84</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,233.80,597.95,147.75,7.89"><head>Table 2 .</head><label>2</label><figDesc>Ranking metrics for task 1</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,194.06,432.03,224.16,92.15"><head>Table 3 .</head><label>3</label><figDesc>Official results task 2</figDesc><table coords="9,194.06,432.03,224.16,74.44"><row><cell></cell><cell>AHR ACR ADODL DCHR</cell></row><row><cell cols="2">LogReg-features 34.01% 67.07% 80.05% 35.71%</cell></row><row><cell>SVM-features</cell><cell>34.56% 67.44% 80.63% 35.71%</cell></row><row><cell>SVM-USE</cell><cell>36.94% 69.02% 81.72% 31.53%</cell></row><row><cell cols="2">BioInfo@UAVR 38.30% 69.21% 76.01% 30.00%</cell></row><row><cell>iLab run2</cell><cell>37.07% 69.41% 81.70% 27.14%</cell></row><row><cell>relai lda user</cell><cell>36.39% 68.32% 83.15% 34.29%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="3,144.73,656.80,87.04,7.86"><p>http://www.liwc.net/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The work of <rs type="person">Paolo Rosso</rs> was in the framework of the research project <rs type="grantNumber">PROM-ETEO/2019/121</rs> (DeepPattern) by the <rs type="funder">Generalitat Valenciana</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_degRhdg">
					<idno type="grant-number">PROM-ETEO/2019/121</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.96,468.49,337.64,7.86;10,151.52,479.45,329.07,7.86;10,151.52,490.41,329.07,7.86;10,151.52,501.36,25.60,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,300.75,468.49,179.85,7.86;10,151.52,479.45,132.75,7.86">Analysing the causes of depressed mood from depression vulnerable individuals</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">F</forename><surname>Abd Yusof</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Guerin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,306.02,479.45,174.57,7.86;10,151.52,490.41,198.25,7.86">Proceedings of the International Workshop on Digital Disease Detection using Social Media</title>
		<meeting>the International Workshop on Digital Disease Detection using Social Media</meeting>
		<imprint>
			<publisher>DDDSM</publisher>
			<date type="published" when="2017">2017. 2017. 2017</date>
			<biblScope unit="page" from="9" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,512.83,337.63,7.86;10,151.52,523.78,329.07,7.86;10,151.52,534.74,133.43,7.86" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">Y</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Limtiaco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Guajardo-Cespedes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.11175</idno>
		<title level="m" coord="10,346.27,523.78,105.27,7.86">Universal sentence encoder</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,142.96,546.20,337.63,7.86;10,151.52,557.16,329.08,7.86;10,151.52,568.12,279.86,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,331.31,546.20,149.28,7.86;10,151.52,557.16,26.22,7.86">Quantifying mental health signals in twitter</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Coppersmith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,198.75,557.16,281.85,7.86;10,151.52,568.12,205.78,7.86">Proceedings of the workshop on computational linguistics and clinical psychology: From linguistic signal to clinical reality</title>
		<meeting>the workshop on computational linguistics and clinical psychology: From linguistic signal to clinical reality</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="51" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,579.58,337.64,7.86;10,151.52,590.54,329.07,7.86;10,151.52,601.50,329.07,7.86;10,151.52,612.46,146.29,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,448.80,579.58,31.80,7.86;10,151.52,590.54,192.16,7.86">Clpsych 2015 shared task: Depression and ptsd on twitter</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Coppersmith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hollingshead</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,363.15,590.54,117.44,7.86;10,151.52,601.50,329.07,7.86;10,151.52,612.46,71.82,7.86">Proceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality</title>
		<meeting>the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="31" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,623.92,337.64,7.86;10,151.52,634.88,329.07,7.86;10,151.52,645.84,329.07,7.86;10,151.52,656.80,76.80,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,370.43,623.92,110.16,7.86;10,151.52,634.88,213.96,7.86">Characterizing and predicting postpartum depression from shared facebook data</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Choudhury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Counts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">J</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,386.10,634.88,94.49,7.86;10,151.52,645.84,324.56,7.86">Proceedings of the 17th ACM conference on Computer supported cooperative work &amp; social computing</title>
		<meeting>the 17th ACM conference on Computer supported cooperative work &amp; social computing</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="626" to="638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,119.67,337.63,7.86;11,151.52,130.63,329.07,7.86;11,151.52,141.59,52.73,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,379.62,119.67,100.97,7.86;11,151.52,130.63,48.75,7.86">Predicting depression via social media</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Choudhury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Counts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,224.19,130.63,256.40,7.86;11,151.52,141.59,24.07,7.86">Seventh international AAAI conference on weblogs and social media</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,153.29,337.63,7.86;11,151.52,164.25,329.07,7.86;11,151.52,175.21,25.60,7.86" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="11,346.99,153.29,133.60,7.86;11,151.52,164.25,189.89,7.86">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,142.96,186.91,337.63,7.86;11,151.52,197.87,329.07,7.86;11,151.52,208.82,329.07,7.86;11,151.52,219.76,117.29,7.89" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,352.88,197.87,127.71,7.86;11,151.52,208.82,112.22,7.86">Facebook language predicts depression in medical records</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Merchant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Crutchley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Preot ¸iuc-Pietro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Asch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,272.33,208.82,208.27,7.86">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">44</biblScope>
			<biblScope unit="page" from="11203" to="11208" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,231.48,337.64,7.86;11,151.52,242.44,329.07,7.86;11,151.52,253.40,176.57,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,379.92,231.48,100.67,7.86;11,151.52,242.44,329.07,7.86;11,151.52,253.40,17.96,7.86">Clinically significant fear and anxiety of covid-19: A psychometric examination of the coronavirus anxiety scale</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A</forename><surname>Mathis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">C</forename><surname>Jobe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Pappalardo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,176.15,253.40,81.80,7.86">Psychiatry Research</title>
		<imprint>
			<biblScope unit="page">113112</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,265.10,337.98,7.86;11,151.52,276.06,329.07,7.86;11,151.52,287.02,220.04,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,312.57,265.10,168.02,7.86;11,151.52,276.06,45.43,7.86">Overview of erisk: early risk prediction on the internet</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,216.41,276.06,264.18,7.86;11,151.52,287.02,96.22,7.86">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="343" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,298.72,337.98,7.86;11,151.52,309.67,329.07,7.86;11,151.52,320.63,249.36,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,309.50,298.72,171.09,7.86;11,151.52,309.67,61.16,7.86">Overview of erisk 2019 early risk prediction on the internet</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,235.82,309.67,244.78,7.86;11,151.52,320.63,125.55,7.86">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="340" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,332.33,337.97,7.86;11,151.52,343.29,329.07,7.86;11,151.52,354.25,329.07,7.86;11,151.52,365.21,329.07,7.86;11,151.52,376.17,329.07,7.86;11,151.52,387.13,71.34,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,340.63,332.33,139.96,7.86;11,151.52,343.29,154.73,7.86">Overview of eRisk 2020: Early Risk Prediction on the Internet</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,334.50,354.25,146.10,7.86;11,151.52,365.21,329.07,7.86;11,151.52,376.17,197.90,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction Proceedings of the Eleventh International Conference of the CLEF Association (CLEF</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">T S V H J C L C E A N L C N F</forename></persName>
		</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,398.82,337.97,7.86;11,151.52,409.78,329.07,7.86;11,151.52,420.74,329.07,7.86;11,151.52,431.70,67.58,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,362.69,398.82,117.90,7.86;11,151.52,409.78,116.12,7.86">Quantifying the language of schizophrenia in social media</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hollingshead</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Coppersmith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,289.64,409.78,190.96,7.86;11,151.52,420.74,325.65,7.86">Proceedings of the 2nd workshop on Computational linguistics and clinical psychology: From linguistic signal to clinical reality</title>
		<meeting>the 2nd workshop on Computational linguistics and clinical psychology: From linguistic signal to clinical reality</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,443.40,337.97,7.86;11,151.52,454.33,67.77,7.89" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="11,285.34,443.40,79.24,7.86">Nrc emotion lexicon</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">D</forename><surname>Turney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>National Research Council</publisher>
			<biblScope unit="volume">2</biblScope>
			<pubPlace>Canada</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,466.06,337.97,7.86;11,151.52,477.02,275.05,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,317.59,466.06,163.00,7.86;11,151.52,477.02,130.42,7.86">Quick and (maybe not so) easy detection of anorexia in social media posts</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mohammadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kosseim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,302.99,477.02,94.91,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,488.72,337.98,7.86;11,151.52,499.65,306.40,7.89" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,151.52,499.67,124.96,7.86">Detecting suicidality on twitter</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>O'dea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Batterham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">L</forename><surname>Calear</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,283.31,499.67,87.91,7.86">Internet Interventions</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="188" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,511.37,337.98,7.86;11,151.52,522.33,297.13,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,236.25,511.37,105.28,7.86">Depression: A global crisis</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">H</forename><surname>Organization</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,347.71,511.37,95.68,7.86">world mental health day</title>
		<meeting><address><addrLine>Occoquan, Va, USA</addrLine></address></meeting>
		<imprint>
			<publisher>World Federation for Mental Health</publisher>
			<date type="published" when="2012-10-10">october 10 2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,534.03,337.97,7.86;11,151.52,544.96,300.72,7.89" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="11,340.83,534.03,139.76,7.86;11,151.52,544.99,18.81,7.86">Linguistic inquiry and word count: Liwc</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">J</forename><surname>Booth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001. 2001. 2001</date>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page">2001</biblScope>
			<pubPlace>Mahway</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,556.69,337.97,7.86;11,151.52,567.65,329.07,7.86;11,151.52,578.61,95.81,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="11,346.74,556.69,133.85,7.86;11,151.52,567.65,282.32,7.86">Attentive multi-stage learning for early risk detection of signs of anorexia and self-harm on social media</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ragheb</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Azé</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bringay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,455.90,567.65,24.69,7.86;11,151.52,578.61,67.14,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,590.30,337.98,7.86;11,151.52,601.26,329.07,7.86;11,151.52,612.22,329.07,7.86;11,151.52,623.18,25.60,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="11,300.57,590.30,180.02,7.86;11,151.52,601.26,204.45,7.86">Using topic modeling to improve prediction of neuroticism and depression in college students</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Resnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Garron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,380.14,601.26,100.45,7.86;11,151.52,612.22,262.76,7.86">Proceedings of the 2013 conference on empirical methods in natural language processing</title>
		<meeting>the 2013 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1348" to="1353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,634.88,337.98,7.86;11,151.52,645.84,329.07,7.86;11,151.52,656.80,167.18,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="11,288.46,634.88,192.13,7.86;11,151.52,645.84,204.21,7.86">Uarizona at the clef erisk 2017 pilot task: linear and recurrent models for early depression detection</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sadeque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="11,376.32,645.84,104.27,7.86;11,151.52,656.80,14.79,7.86">CEUR workshop proceedings</title>
		<imprint>
			<biblScope unit="volume">1866</biblScope>
			<date type="published" when="2017">2017</date>
			<publisher>NIH Public Access</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,119.67,337.98,7.86;12,151.52,130.63,329.07,7.86;12,151.52,141.59,168.09,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="12,151.52,130.63,329.07,7.86;12,151.52,141.59,30.54,7.86">Depression detection via harvesting social media: A multimodal dictionary learning solution</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,203.02,141.59,27.51,7.86">IJCAI</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3838" to="3844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,152.55,337.97,7.86;12,151.52,163.51,329.07,7.86;12,151.52,174.47,216.61,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="12,251.60,152.55,132.71,7.86">Detecting anxiety through reddit</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rudzicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,405.70,152.55,74.89,7.86;12,151.52,163.51,329.07,7.86;12,151.52,174.47,142.14,7.86">Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology-From Linguistic Signal to Clinical Reality</title>
		<meeting>the Fourth Workshop on Computational Linguistics and Clinical Psychology-From Linguistic Signal to Clinical Reality</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="58" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,185.43,337.98,7.86;12,151.52,196.39,329.07,7.86;12,151.52,207.34,25.60,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="12,314.23,185.43,166.36,7.86;12,151.52,196.39,212.85,7.86">Linguistic metadata augmented classifiers at the clef 2017 task for early detection of depression</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Trotzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Koitka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,385.61,196.39,94.98,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,218.30,337.98,7.86;12,151.52,229.26,329.07,7.86;12,151.52,240.22,95.81,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="12,313.02,218.30,167.58,7.86;12,151.52,229.26,281.30,7.86">Word embeddings and linguistic metadata at the clef 2018 tasks for early detection of depression and anorexia</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Trotzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Koitka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,455.89,229.26,24.70,7.86;12,151.52,240.22,67.14,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,251.18,337.98,7.86;12,151.52,262.14,329.07,7.86;12,151.52,273.10,55.09,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="12,315.59,251.18,165.00,7.86;12,151.52,262.14,239.40,7.86">A neural network approach to early risk detection of depression and anorexia on social media text</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,414.05,262.14,66.54,7.86;12,151.52,273.10,26.42,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,284.06,337.98,7.86;12,151.52,295.02,329.07,7.86;12,151.52,305.98,329.07,7.86;12,151.52,316.93,178.48,7.86" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="12,392.53,284.06,88.06,7.86;12,151.52,295.02,144.05,7.86">Hierarchical attention networks for document classification</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,315.57,295.02,165.02,7.86;12,151.52,305.98,329.07,7.86;12,151.52,316.93,85.48,7.86">Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies</title>
		<meeting>the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1480" to="1489" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
