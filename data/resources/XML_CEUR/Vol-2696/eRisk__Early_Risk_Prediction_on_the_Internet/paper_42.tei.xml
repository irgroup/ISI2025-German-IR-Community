<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,163.65,115.96,288.05,12.62;1,173.57,133.89,268.21,12.62;1,229.99,151.82,155.37,12.62">Using Surface and Semantic Features for Detecting Early Signs of Self-Harm in Social Media Postings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,161.92,190.05,60.88,8.74"><forename type="first">Linda</forename><surname>Achilles</surname></persName>
							<email>achilles@uni-hildesheim.de</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Information Science and Natural Language Processing</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<settlement>Hildesheim</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,230.19,190.05,58.21,8.74"><forename type="first">Max</forename><surname>Kisselew</surname></persName>
							<email>kisselew@uni-hildesheim.de</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Information Science and Natural Language Processing</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<settlement>Hildesheim</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,296.17,190.05,73.41,8.74"><forename type="first">Johannes</forename><surname>Sch√§fer</surname></persName>
							<email>johannes.schaefer@uni-hildesheim.de</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Information Science and Natural Language Processing</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<settlement>Hildesheim</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,396.57,190.05,56.87,8.74"><forename type="first">Ralph</forename><surname>Koelle</surname></persName>
							<email>koelle@uni-hildesheim.de</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Information Science and Natural Language Processing</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<settlement>Hildesheim</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,163.65,115.96,288.05,12.62;1,173.57,133.89,268.21,12.62;1,229.99,151.82,155.37,12.62">Using Surface and Semantic Features for Detecting Early Signs of Self-Harm in Social Media Postings</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A25FDE07091B7861F8661CD7A822A491</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Self-harm detection</term>
					<term>Risk detection</term>
					<term>Natural language processing</term>
					<term>Word vectors</term>
					<term>Contextualized word embeddings</term>
					<term>Deep learning</term>
					<term>Ensemble system</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the University of Hildesheim submission to the CLEF eRisk 2020 shared task on detecting early signs of self-harm in social media posts. We introduce four systems that apply different methods trying to address this task and a fifth ensemble system that combines the four other systems. The first four systems make use of features of different types, such as time intervals between posts, the sentiment and semantics of the writings by using bag-of-words vectors and contextualized word embeddings in a neural network approach. The results show that while all our systems achieve a high recall, the focus of future work should be further improvement of the precision. All systems and the ensemble model achieve a comparable performance of F latency values in the range of 0.367 to 0.424.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Since the advent of Social Media networks, they revolutionized the way people interact with each other and so attracted academic and industry researchers in different fields of expertise <ref type="bibr" coords="1,267.71,529.71,9.96,8.74" target="#b2">[3]</ref>. This way the content of those networks also became popular in the field of natural language processing (NLP). Text and meta information of posts have been used, for instance, to predict the Big Five personality traits of microblog users <ref type="bibr" coords="1,290.77,565.58,9.96,8.74" target="#b0">[1]</ref>. Later, different kinds of mental disorders came into focus of the research community. Facebook language was analyzed to predict a depression in a medical record <ref type="bibr" coords="1,309.07,589.49,9.96,8.74" target="#b6">[7]</ref>, as well as postpartum depression <ref type="bibr" coords="1,470.08,589.49,10.52,8.74" target="#b3">[4]</ref> and Twitter data were evaluated to detect depressed users. The significance of this research led to the emergence of initiatives such as the CLEF eRisk group.</p><p>The Early Risk Prediction On The Internet (eRisk) lab<ref type="foot" coords="2,404.50,117.42,3.97,6.12" target="#foot_0">1</ref> , as part of the CLEF initiative <ref type="foot" coords="2,204.73,129.37,3.97,6.12" target="#foot_1">2</ref> , was first organized in 2017. The lab's main objective is to evaluate metrics, systems and data collections regarding Social Media users' safety and health on the internet. During the first workshop there was a pilot task on depression detection and a corresponding data collection was released <ref type="bibr" coords="2,134.77,178.77,14.61,8.74" target="#b11">[12]</ref>. During the following years more tasks, such as the early prediction of signs of self-harm or anorexia have been conducted.</p><p>In 2020 there were two tasks:</p><p>1. Early detection of signs of self-harm 2. Measuring the severity of the signs of depression</p><p>The data for the first task is released in rounds. In each round participating teams receive one social media post for each social media author in the collection. The task is to analyze these posts and return a binary decision [0, 1] for each author if he or she is at risk for self-harm in addition to estimating the level of self-harm represented by a score <ref type="bibr" coords="2,235.46,304.28,10.52,8.74">[0,</ref><ref type="bibr" coords="2,249.45,304.28,11.62,8.74" target="#b9">10]</ref>. A round ends when a team submits their results starting the next round.</p><p>In the second task the data is released as entire collection for each social media author at once. After processing these writings, the team's system has to fill in a standard depression questionnaire, the Beck Depression Inventory (BDI) <ref type="bibr" coords="2,156.60,364.27,13.10,8.74" target="#b1">[2]</ref>, for each social media author.</p><p>This paper describes the approach of the hildesheim team in the first task of CLEF eRisk 2020, the early detection of signs of self-harm in social media posts. Section 2 and 3 give more insight into the data collection and the necessary preprocessing as well as an overview of the evaluation metrics in eRisk. Furthermore, we deployed five different systems, two of them making use of surface-based features (see Sections 4.1 and 4.2), two systems making use of semantic features (see Sections 4.3 and 4.4) and the fifth system being an ensemble system (see Section 4.5) combining the decisions and scores from the other four systems. Each system is evaluated separately in the shared task as runs 0 to 4 of our team. Since the shared task limited the maximum number of allowed runs per team to 5, we were not able to test different configurations of these systems. In Section 4 we present each system in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data and Pre-processing</head><p>In 2019 the shared tasks' chunk-based data processing approach was changed to an item-by-item option to analyse the data. In 2017 and 2018 participating teams received a chunk of data, a sub-collection of the writings limited by a specific time period, for each social media author. From 2019 on they would receive the data post by post. This second way of processing the social media data would give the participating teams the possibility to make a decision about the state of a specific social media author at any point in time and it was continued in 2020 <ref type="bibr" coords="3,158.01,130.95,14.61,8.74" target="#b13">[14]</ref>.</p><p>The data collection process is described in <ref type="bibr" coords="3,338.26,145.28,14.61,8.74" target="#b11">[12]</ref>, the training data set in <ref type="bibr" coords="3,465.09,145.28,15.50,8.74" target="#b12">[13]</ref> and the test data set is described in <ref type="bibr" coords="3,292.96,157.23,14.61,8.74" target="#b14">[15]</ref>. For 2020 the training data set is a collection of XML files, one for each subject (social media author). Each individual XML file comprises a collection of an author's writings in chronological order. Each writing consists of title, text, info and date elements. The title and text elements represent the title and the content of each social media post, the date element the timestamp. The info tag gives information on the social network the data was retrieved from: The social network Reddit<ref type="foot" coords="3,385.13,227.39,3.97,6.12" target="#foot_2">3</ref> . Both title and text elements can be empty if the other element contains text. Sometimes title as well as text are both filled with content.</p><p>The training data provided XML files for 340 subjects, 41 of which belonging to the self-harm group, 299 to the control group. The total number of writings in the self-harm group is 6,927 posts in contrast to 163,506 in the control group. The difference between the groups is also very significant in the average number of writings per subject: 169.0 in the self-harm group and 546.8 in the control group. According to the shared task organizers the average number of words per writing is in the self-harm group a slightly higher (24.8) than in the control group <ref type="bibr" coords="3,134.77,350.89,24.20,8.74">(18.8)</ref>. The self-harm test data of the 2019 was reused for the 2020 challenge as training data <ref type="bibr" coords="3,195.12,362.84,14.61,8.74" target="#b13">[14]</ref>. Table <ref type="table" coords="3,244.11,362.84,4.98,8.74" target="#tab_0">1</ref> summarizes the details about the training data. During manual inspection of the training data, a few problems were identified. For example, some posts contained many URLs or Hashtags while others only consisted of HTML codes. The latter were partially identified as posts written in Cyrillic script, thus probably in a language different from English. These inconsistencies, typical for social media, required some pre-processing before the training data could be processed with the systems.</p><p>In a first step the posts were tokenized 4 splitting them into sentences and tokens. At the same time a post ID was generated from the subject ID and timestamp to keep the post structure also on sentence level. In a second step language-detection<ref type="foot" coords="4,216.13,129.37,3.97,6.12" target="#foot_4">5</ref> was applied to the sentences.</p><p>We removed sentences in cases where the language detection algorithm raised an error. This way URLs were sorted out of the data. Additionally, hashtags and posts consisting only of HTML escape characters were also removed from the training data set. The remaining sentences were used for training of the semantic features. Some sentences contained urban slang words (e.g. dawg) and were consequently misclassified during language detection. Therefore, we decided to include all the posts where the language detection did not fail, even though not all sentences were classified to be English.</p><p>An additional pre-processing step of the training data was necessary for the time analysis system (see Section 4.1). The posts were sorted by subject and timestamp and the time difference between two posts was calculated. For both groups (self-harm and control group) mean and standard deviation were calculated. For the self-harm group the mean was approximately 71 hours (2 days 23 hours), meaning that each subject approximately posted every three days on average. The standard deviation was approximately 563 hours (23 days 11 hours). For the control group the mean was approximately 35 hours (1 day 11 hours) and the standard deviation was approximately 333 hours (13 days 22 hours).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Metrics</head><p>Precision, recall and the F-measure, calculated referring to the self-harm positive group of social media authors <ref type="bibr" coords="4,262.45,451.41,14.61,8.74" target="#b13">[14]</ref>, were used as evaluation metrics for eRisk since its advent in 2017. Besides these standard Information Retrieval metrics the organizers of eRisk also introduced a new metric, ERDE (Early Risk Detection Error), that involves the time that a system took to make a decision, based on the number of writings that were needed to come to this decision. ERDE allows to penalize late decisions made by the system, meaning that a late decision needs to process more writings than an early alert. The metric's range is [0, 1] meaning a low value corresponds to a good result of the system. However, ERDE comes with several limitations <ref type="bibr" coords="4,358.04,550.18,14.61,8.74" target="#b12">[13]</ref>, so that F latency , as proposed by Sadeque and colleagues <ref type="bibr" coords="4,278.94,562.13,14.61,8.74" target="#b15">[16]</ref>, was added to the set of evaluation metrics for eRisk. An optimal system's value is 1.</p><p>In addition to the decision-based evaluation metrics described above, the organizers introduced also ranking-based evaluation methodologies. The standard Information Retrieval measures P@10, NDCG@10 and NDCG@100 are also applied in eRisk.</p><p>This section describes the four individual systems and the fifth ensemble system which we developed for the submissions for the eRisk 2020 shared task. Each system (1 -5) was submitted as in separate runs (0 -4).</p><p>Our systems had a run time of 72d 20h describing the time passed from the first to the last response to the server providing new Social Media posts. Technical problems within our systems led to this high number, however, no manual offline processing was involved. The systems work entirely automatically.</p><p>The systems 1, 2 and 4 were originally implemented returning a decision = 1 when there were no more posts of an author in the current round, interpreting the last score and decision as final for this user. After the test stage of the shared task this understanding of the evaluation metrics turned out to not fully comply with the actual application of these measures of the share task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">System 1 -Time Analysis</head><p>One of our hypotheses is that social media users at risk for self-harm post less regularly than those in the control group. For the first run (run 0) a rather simple time analysis algorithm was deployed. The first step was to retrieve the timestamp from the round before the current round to calculate the time that passed between the two posts for each subject. For the calculation of the score that represents the estimation of the level of self-harm the standard deviation that was calculated during the training phase was used. The range from &lt;0 days to 13 days 21:44:23 was mapped to the score range of 0 to 5 (lower half of being at risk ). The second half was mapped from the first half's upper border to 23 days 10:51:57. Everything above this value was set to the highest possible score <ref type="bibr" coords="5,134.77,441.82,16.38,8.74" target="#b9">(10)</ref>.</p><p>The mapping was done with the following functions for the groups:</p><formula xml:id="formula_0" coords="5,257.02,472.28,223.57,23.23">f cg (x) = min(x ‚Ä¢ 5 b cg , 5)<label>(1)</label></formula><formula xml:id="formula_1" coords="5,253.80,507.54,226.79,23.22">f sh (x) = min(x ‚Ä¢ 10 b sh , 10)<label>(2)</label></formula><p>While b cg refers to the control group's upper time border (13 days 21:44:23), b sh contains the self-harm group's value (23 days 10:51:57), both being converted to seconds. The variable x refers to the time difference in seconds between two posts. Thereby, f expresses the score of the level of self-harm risk in the range of 0 to 10.</p><p>For the calculation of the decision, the current round's score f was compared to the mean score of the previous rounds. If the difference between the current score and the mean score is greater than ¬±3 the system returns decision = 1.</p><p>There were cases were the algorithm caused an error: During the first round, since we need at least two writings for calculating a time difference between two posts, and at least one more case, where the timestamp of two successive posts of the same author were identical. To prevent the system from causing an error we caught these cases by setting the default time difference to ten seconds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">System 2 -Sentiment Analysis</head><p>For the second run (run 1) we developed a method based on sentiment analysis. We used VADER (Valence Aware Dictionary and sEntiment Reasoner) <ref type="bibr" coords="6,453.46,192.90,14.61,8.74" target="#b9">[10]</ref>, a lexicon-based sentiment algorithm due to its ability to process elements that are special for Social Media posts, such as emoticons as an expression of mood or words written in capital letters as a sign of emphasis.</p><p>VADER comes with a compound score which is described by the authors as a normalized and weighted composite score <ref type="foot" coords="6,343.28,251.12,3.97,6.12" target="#foot_5">6</ref> . The compound score ranges between -1 (extreme negative sentiment) and +1 (extreme positive sentiment). Posts with sentiment values in the range from -0.05 to +0.05 are considered to be of neutral sentiment. The sentiment algorithm was applied on post level on the pre-processed training data. A histogram of the distribution of posts with specific sentiment values is shown in Figure <ref type="figure" coords="6,363.59,312.47,3.87,8.74" target="#fig_0">1</ref>. Both groups (self-harm and control group) are visualized separately. At first glance both groups have a similar distribution of sentiment compound values such as for instance the most posts are located in the neutral segment. However, the shapes of the histograms differ at the margins. The control group appears to have a decreasing number of extreme positive and extreme negative posts compared to the self-harm group. Therefore, we hypothesize a correlation between extreme sentiment values and the author's susceptibility to self-harm.</p><p>For the test stage, the sentiment method therefore functions as follows: VADER is applied on post level to calculate the compound sentiment value. In a next step, the compound sentiment value is mapped to the score for the estimation of the level of self-harm by multiplying the compound value by 10. A negative compound value is first transformed into a positive number by multiplying it by -1.</p><p>For the binary decision a mean score of the previous rounds is calculated. The algorithm then compares the mean score of the previous rounds with the score of the current round. If the difference between the current score and the mean score is greater than ¬±3 the system returns decision = 1, because we assume the author to be prone to self-harm, becoming apparent through a less stable sentiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">System 3 -Distributional Semantics</head><p>For our third system (run 2) we implemented a system based on distributional semantics to decide as early as possible whether a post indicates signs of selfharm. To this end, our method computes the semantic similarity between vector representations of previously unseen Reddit posts and an abstract vector representation exhibiting the semantics of a typical post showing signs self-harm behavior. If the semantic similarity exceeds a predefined threshold, the system raises an alarm for the subject who wrote the corresponding post.</p><p>Our system employs an approach based on the framework of distributional semantics <ref type="bibr" coords="7,180.20,385.21,14.61,8.74" target="#b18">[19]</ref>. This framework is based on the distributional hypothesis which states that words occurring in similar contexts tend to have similar meanings <ref type="bibr" coords="7,134.77,409.12,10.79,8.74" target="#b8">[9,</ref><ref type="bibr" coords="7,145.56,409.12,7.20,8.74" target="#b7">8,</ref><ref type="bibr" coords="7,152.75,409.12,7.20,8.74" target="#b4">5]</ref>. This hypothesis is operationalized by representing the meaning of target words as multidimensional vectors, also referred to as word vectors or semantic vectors. In this work we use the bag-of-words model where each vector dimension stands for a particular context word and the numerical value in that dimension signifies how often that context word co-occurs within a window of n words around the target word in a specific text corpus.</p><p>Data. As described in Section 2 the training data contains a history of posts for 41 subjects for whom self-harm alarm has been raised and 299 healthy subjects. To develop our model on data balanced in terms of the distribution of self-harm and healthy subjects' histories of writings, we randomly selected 41 subjects from the set of healthy subjects. Together with the 41 subjects prone to self-harm this results in a total of 82 histories of posts.</p><p>Vector representation of Reddit posts. Our word vectors are built on a concatenation of the lemmatized British National Corpus (BNC) <ref type="foot" coords="7,420.32,563.72,3.97,6.12" target="#foot_6">7</ref> and ukWaC corpora <ref type="foot" coords="7,167.75,575.68,3.97,6.12" target="#foot_7">8</ref> . These corpora are used in many related works to build vector space models as they contain a wide range of text genres from different domains. The corpus contains in total around 2.36 billion tokens. We create 10000-dimensional bag-of-words vectors for the 28,000 most frequent content words in the corpus and set the window size for counting co-occurring context words around each target word to 5 words to either side of the target word. The vector dimensions are the 10,000 most frequent content words from the corpus. For each Reddit post that is used for the development of our system and during the test stage of the shared task, we compute an average semantic vector as follows: Assuming that W p is the set of all words appearing in post p, we compute the vector -‚Üí p representing the meaning of post p as the centroid of all word vectors -‚Üí w for words w from W p :</p><formula xml:id="formula_2" coords="8,266.94,201.59,213.65,26.80">- ‚Üí p = 1 |W p | w‚ààWp - ‚Üí w<label>(3)</label></formula><p>Vector representation of susceptibility to self-harm. A manual inspection of writings from the 41 subjects who are prone to self-harm according to the golden truth revealed that in many cases the last post written by these subjects is particularly characteristic for the expression of self-harm behavior. Thus, we compute a special self-harm vector -‚Üí s indicating actions or thoughts of self-harm by averaging post vectors representing the last post from each of the 41 subjects prone to self-harm. To tune our system, we computed the cosine similarities between the first five posts of each subject in our balanced data set consisting of 82 histories of posts and the self-harm vector -‚Üí s . We found 0.985 to be a good threshold to distinguish posts from persons prone to self-harm and those who are not. Therefore we use this threshold for the test stage in the CLEF eRisk 2020 shared task.</p><p>During the test stage we compute a post vector for each incoming post as we did during the training phase. Then we compute the cosine similarity between each of these post vectors and the pre-computed self-harm vector -‚Üí s . If the cosine similarity exceeds the threshold of 0.985, an alarm for that post is raised and the label 1 is assigned to the subject who wrote that post. The score expressing susceptibility to self-harm expressed in post p is computed using the following linear function:</p><formula xml:id="formula_3" coords="8,252.52,461.74,228.07,13.03">score(p) = cos( - ‚Üí p , - ‚Üí s ) ‚Ä¢ 10 (4)</formula><p>where -‚Üí p is the post vector and -‚Üí s the pre-computed self-harm vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">System 4 -Neural Network</head><p>Automatically learning to estimate a person's risk of self-harm solely based on their social media postings is a complex task. Therefore, an automatic system has to be able to consider a variety of textual features. Manually defining a feature set which incorporates a comprehensive amount of indicators transpired to be a tedious task (cf. Systems 1-3 utilizing diverse feature categories). Thus, we decided to use a neural network to automatically learn such features. In this section we describe the structure of our deep learning model, how we train it on the available data set and how we predict scores for new instances. The overall architecture of our neural network system is shown in Figure <ref type="figure" coords="8,403.73,632.01,3.87,8.74" target="#fig_1">2</ref>.</p><p>In the context of the shared task, we formulate the classification task as follows: an instance (input data point) consists of a sequence of posts of a single author (where each post is represented as a string) and should be classified as a binary decision, expressing if the author tends toward self-harm (yes/no). Model architecture. As numerical representation of the posts' text, we used BERT <ref type="bibr" coords="9,190.23,430.17,10.52,8.74" target="#b5">[6]</ref> embeddings which has in recent years proven to be an efficient method of represent meaning in contextualized word embeddings. We used the pre-trained embedding model BERT-Base ('BERT uncased L-12 H-768 A-12')<ref type="foot" coords="9,476.12,452.51,3.97,6.12" target="#foot_8">9</ref>  <ref type="bibr" coords="9,134.77,466.04,14.61,8.74" target="#b17">[18]</ref>. As dimensionality of the embeddings we selected 50 features. To keep the size of our instances computationally feasible, we limited the post history to the 100 most recent postings and the length of each post to the first 50 words (using pre-padding in both cases when fewer postings/words are available). Thus, an instance consists of 5,000 BERT word embeddings of size 50. These values are also shown in the input layer of the network in Figure <ref type="figure" coords="9,373.92,525.81,3.87,8.74" target="#fig_1">2</ref>.</p><p>Subsequently, we apply a convolutional neural network (CNN) to automatically select features which can be indicative of self-harm from the post history. Our CNN sub-network consists of four parallel branches, each being a sequence of a convolutional layer, a max pooling layer and a dropout layer. CNNs are efficient feature selectors which can be applied to learn complex features based on semantic representations, cf. <ref type="bibr" coords="9,261.73,598.37,14.60,8.74" target="#b16">[17]</ref>. We decided to use four different convolutions (see the branches in Figure <ref type="figure" coords="9,253.48,610.33,4.43,8.74" target="#fig_1">2</ref>) to detect 8 features (by using 8 filters in the layer) from word n-grams of different sizes n from 1 to 4. Thus, the first convolution learns unigram features from the embedding of the post history of the subject, the second convolution learns bigram features, etc. In each branch, the subsequent max pooling layer is applied to retain only the maximum feature values for each post, resulting in a 100x8 matrix (8 features for each of the 100 most recent postings) in each branch. A dropout layer (with a probability of 0.25) then introduces regularization to the model during training which improves its ability to generalize to new data instances. Finally, the output of the branches is simply concatenated resulting in 32 features for each of the 100 most recent postings as shown in the layer named Concatenate in Figure <ref type="figure" coords="10,401.94,202.68,3.87,8.74" target="#fig_1">2</ref>.</p><p>To compute an assessment of the overall self-harm risk of a subject based on these high-level features of their most recent history, we process the output of the Concatenate layer using a recurrent neural network (RNN) with long-short term memory (LSTM) cells (see LSTM layer in Figure <ref type="figure" coords="10,377.83,257.50,3.87,8.74" target="#fig_1">2</ref>). This neural network component reads the features of these posts as a sequence while updating an internal status (which here should model the risk of self-harm) after each step (post). Finally after processing the entire sequence, the RNN returns an overall assessment for the given post history; here, we set the dimensionality of the output space to 8.</p><p>As final layer we use a densely connected layer with a sigmoid activation function to predict an output between 0 and 1 which can be interpreted as the probability of the subject being prone to self-harm. With this configuration, the model has a total of 5,353 trainable parameters.</p><p>Training. We used the data available in the eRisk 2019 Text Research Collection <ref type="bibr" coords="10,167.78,403.01,15.50,8.74" target="#b11">[12]</ref> to construct training instances as follows. As our model expects a chronological list of posts per subject as input and the data set consists of the entire post history of only 340 subjects, we decided to use multiple random samples of subsets of this data. We constrain the samples to be between 10 and 100 posts in length while we consider both titles and text comments as individual posts. With this method we extract 3,705 samples from the data set and select 90% of those as our training data and the remaining 10% as validation data.</p><p>To cope with the class imbalance (in the original data set, only 41 of 340 subjects are prone to self-harm), we use class weights during training based on their inverse frequency in out training set. Thus, errors on classifying positive instances are valued approximately 21 times higher than errors on classifying negative instances. Additionally, to avoid over-fitting, we apply early stopping using the validation set which stops training when the monitored binary crossentropy score for the validation set does not improve for several epochs. Finally, we optimize the network with a training batch size of 64 and a binary crossentropy loss using the Adam optimizer <ref type="bibr" coords="10,306.67,589.34,15.50,8.74" target="#b10">[11]</ref> in 12 epochs over the training data.</p><p>Prediction. Our neural network model returns a probabilistic prediction p(s) for each unseen instance expressing the likelihood of the subject s being prone to self-harm. To conform to the format of the shared task, we reformat this score for each subject into a decision using Equation 5 and a self-harm score sh(s) = 10 ‚Ä¢ p(s).</p><formula xml:id="formula_4" coords="11,221.16,130.63,259.44,23.08">decision(s) = 0 if 0.1 &lt; p(s) &lt; 0.8 1 otherwise<label>(5)</label></formula><p>Using this method, we set the decision value to 1 only in cases when the model is extremely confident for a negative prediction (values below 0.1)<ref type="foot" coords="11,459.18,172.66,7.94,6.12" target="#foot_9">10</ref> or highly confident for a positive prediction (values above 0.8)<ref type="foot" coords="11,393.68,184.62,7.94,6.12" target="#foot_10">11</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">System 5 -Ensemble System</head><p>Our ensemble system uses the individual predictions of the above-mentioned four systems (System 1-4) in each run to compute a single combined decision. For each subject this system predicts a decision value of 1 if at least two of the individual systems assigned a 1. If only one or none of the systems predicted 1, the ensemble system returns 0. The self-harm risk score for each subject is always computed as an average of the scores of all four systems in each run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Table <ref type="table" coords="11,162.94,343.64,4.98,8.74" target="#tab_1">2</ref> shows the overall decision-based results of team hildesheim in all five runs on the eRisk 2020 test data. The run ID corresponds to our systems as described in Section 4.</p><p>Our systems rank high in terms of recall. Two systems achieve R = 1, but also the other three runs are highly ranked. Corresponding to these results the precision of all five runs is comparably low. Our best system achieves a precision of P = 0.297 which shows that approximately every third decision is correct. In such a sensitive domain we consider this to be an acceptable result, but we aim for a higher precision in future eRisk participation of our team.</p><p>For ERDE 5 one of our systems (System 3) performs well with a low value of ERDE 5 = 0.237. After processing 50 posts all our systems improve, e.g. our best system achieves an ERDE 50 result of 0.185.</p><p>Regarding the latency-weighed F measure F latency our systems show average performance. Our third system performs best with a value of F latency = 0.424, close to the results of our other proposed systems.</p><p>The ranking-based evaluation results are listed in Table <ref type="table" coords="11,398.16,522.97,3.87,8.74" target="#tab_2">3</ref>. We did not consider the results after the first writing to be meaningful for our approaches, because some systems are based on a history of writings and especially for the time algorithm at least two writings are necessary to make a decision. For that reason, we think that the results for 100 writings and 500 writings are more interpretable. However, the ranking-based results remain rather constant for 100 and 500 writings with only slight changes. The complete list of the evaluation results of all participating teams is published in <ref type="bibr" coords="12,174.68,428.11,14.61,8.74" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>This paper describes the University of Hildesheim submission to the CLEF eRisk 2020 shared task on detecting early signs of self-harm in social media posts. We presented four systems that apply different methods trying to solve this task and a fifth ensemble system that combines the decisions of the four former systems. The first four systems analyze social media posts taking into account different types of features, such as time intervals between posts, sentiment values and semantic representations. While all our systems achieve a high recall, they struggle to yield a comparable precision.</p><p>We expected our ensemble system to perform better than the other systems since it raises an alarm only if several other systems do so as well. However, as the results show, the ensemble system is more likely to balance out the predictions of the other four systems which becomes apparent by being ranked among the other four systems. Therefore as future work we intend to implement a more sophisticated ensemble model that is able to incorporate the strengths of the other four systems, in particular when those are very confident in their decisions. This could be accomplished by weighting the contributions of the single systems in the ensemble system. Investigating different settings for the ensemble system is a promising avenue towards a solution to the early detection of self-harm risk in social media postings.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,135.04,314.48,345.28,7.89;7,134.77,115.84,345.80,183.87"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Distribution of posts in conjunction with VADER sentiment compound value.</figDesc><graphic coords="7,134.77,115.84,345.80,183.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,134.77,338.90,345.83,7.89;9,134.77,349.88,345.83,7.86;9,134.77,360.84,345.83,7.86;9,134.77,371.80,193.19,7.86;9,134.77,115.84,345.82,208.29"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Architecture of our neural network system. Each box corresponds to a neural network layer while the values on the right side of each box display the dimensions of the input (values at the top) and output (values at the bottom) tensor of each layer (' ?' is a placeholder for the variable batch size).</figDesc><graphic coords="9,134.77,115.84,345.82,208.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,134.77,400.14,345.83,96.75"><head>Table 1 .</head><label>1</label><figDesc>Summary of the training data set for eRisk 2020 task 1 (Early detection of signs of self-harm).</figDesc><table coords="3,360.68,435.58,81.12,7.86"><row><cell>Self-harm Control</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="12,134.77,115.91,345.82,118.37"><head>Table 2 .</head><label>2</label><figDesc>Our decision-based results of task 1: Early detection of signs of self-harm, in comparison to the best results achieved in the shared task for each metric.</figDesc><table coords="12,165.22,150.86,281.34,83.42"><row><cell>System</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>ERDE5</cell><cell>ERDE50</cell><cell>F latency</cell></row><row><cell>1</cell><cell>0.248</cell><cell>1.000</cell><cell>0.397</cell><cell>0.292</cell><cell>0.196</cell><cell>0.397</cell></row><row><cell>2</cell><cell>0.246</cell><cell>1.000</cell><cell>0.395</cell><cell>0.304</cell><cell>0.185</cell><cell>0.389</cell></row><row><cell>3</cell><cell>0.297</cell><cell>0.740</cell><cell>0.424</cell><cell>0.237</cell><cell>0.226</cell><cell>0.424</cell></row><row><cell>4</cell><cell>0.270</cell><cell>0.942</cell><cell>0.420</cell><cell>0.400</cell><cell>0.251</cell><cell>0.367</cell></row><row><cell>5</cell><cell>0.256</cell><cell>0.990</cell><cell>0.406</cell><cell>0.409</cell><cell>0.210</cell><cell>0.389</cell></row><row><cell>Best</cell><cell>0.913</cell><cell>1.000</cell><cell>0.754</cell><cell>0.134</cell><cell>0.071</cell><cell>0.658</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="12,134.77,251.25,345.83,134.13"><head>Table 3 .</head><label>3</label><figDesc>Our ranking-based results of task 1: Early detection of signs of self-harm, in comparison to the best results achieved in the shared task for each metric.</figDesc><table coords="12,146.07,286.19,320.15,99.18"><row><cell></cell><cell></cell><cell>100 writings</cell><cell></cell><cell></cell><cell>500 writings</cell><cell></cell></row><row><cell cols="7">System P@10 NDCG@10 NDCG@100 P@10 NDCG@10 NDCG@100</cell></row><row><cell>1</cell><cell>0.4</cell><cell>0.43</cell><cell>0.42</cell><cell>0.5</cell><cell>0.53</cell><cell>0.42</cell></row><row><cell>2</cell><cell>0.5</cell><cell>0.48</cell><cell>0.49</cell><cell>0.5</cell><cell>0.54</cell><cell>0.57</cell></row><row><cell>3</cell><cell>1.0</cell><cell>1.00</cell><cell>0.69</cell><cell>1.0</cell><cell>1.00</cell><cell>0.68</cell></row><row><cell>4</cell><cell>0.1</cell><cell>0.07</cell><cell>0.13</cell><cell>0.1</cell><cell>0.06</cell><cell>0.11</cell></row><row><cell>5</cell><cell>1.0</cell><cell>1.00</cell><cell>0.62</cell><cell>1.0</cell><cell>1.00</cell><cell>0.69</cell></row><row><cell>Best</cell><cell>1.0</cell><cell>1.00</cell><cell>0.83</cell><cell>1.0</cell><cell>1.00</cell><cell>0.84</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,645.84,196.49,7.86"><p>Website of the eRisk lab: https://erisk.irlab.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,656.80,251.31,7.86"><p>Website of the CLEF initiative: http://www.clef-initiative.eu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,144.73,645.84,284.49,7.86"><p>Website of the social media network Reddit: https://www.reddit.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="3,144.73,656.80,331.85,7.86"><p>Using the standard NLTK tokenizer: https://www.nltk.org/api/nltk.tokenize.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,144.73,656.80,335.87,7.86"><p>Python language-detection library langdetect: https://pypi.org/project/langdetect/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="6,144.73,656.80,260.51,7.86"><p>VADER on Pypi.org: https://pypi.org/project/vader-sentiment/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="7,144.73,645.84,250.77,7.86"><p>British National Corpus (BNC): http://www.natcorp.ox.ac.uk</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="7,144.73,656.80,186.24,7.86"><p>UKWaC corpora: http://wacky.sslmit.unibo.it</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="9,144.73,656.80,320.64,7.86"><p>The used BERT model is available on https://github.com/google-research/bert</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9" coords="11,144.73,612.96,335.87,7.86;11,144.73,623.90,175.74,7.89"><p>We chose this very strict threshold to only exclude subjects which have shown several clear signs of not being prone to self harm.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10" coords="11,144.73,634.88,335.86,7.86;11,144.73,645.84,335.87,7.86;11,144.73,656.80,168.93,7.86"><p>Here we chose a weaker threshold (in comparison to the threshold for negative cases) to catch subjects which only have shown signs of being prone to self harm at some point, though those still being clear signs.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="13,142.96,204.12,337.64,7.86;13,151.52,215.08,329.07,7.86;13,151.52,226.04,329.07,7.86;13,151.52,237.00,329.07,7.86;13,151.52,247.95,224.73,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,355.57,204.12,125.02,7.86;13,151.52,215.08,101.37,7.86">Predicting Big Five Personality Traits of Microblog Users</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,421.93,215.08,58.67,7.86;13,151.52,226.04,329.07,7.86;13,151.52,237.00,189.88,7.86">Proceedings of the 2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Raghavan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">L J T</forename></persName>
		</editor>
		<meeting>the 2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)<address><addrLine>Washington D.C., USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2013-11">November 2013</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="501" to="508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,258.22,337.63,7.86;13,151.52,269.16,302.37,7.89" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,412.71,258.22,67.88,7.86;13,151.52,269.18,86.76,7.86">An Inventory for Measuring Depression</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mendelson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mock</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Erbaugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,245.54,269.18,121.51,7.86">Archives of general psychiatry</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="561" to="571" />
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,279.45,337.64,7.86;13,151.52,290.38,302.66,7.89" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,261.51,279.45,219.09,7.86;13,151.52,290.41,15.20,7.86">Social Network Sites: Definition, History, and Scholarship</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">B</forename><surname>Ellison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,173.59,290.41,188.58,7.86">Journal of computer-mediated Communication</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="210" to="230" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,300.68,337.63,7.86;13,151.52,311.64,329.07,7.86;13,151.52,322.60,329.07,7.86;13,151.52,333.55,329.07,7.86;13,151.52,344.51,291.54,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,369.49,300.68,111.10,7.86;13,151.52,311.64,228.06,7.86">Characterizing and Predicting Postpartum Depression from Shared Facebook Data</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Choudhury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Counts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">J</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,251.96,322.60,228.64,7.86;13,151.52,333.55,191.04,7.86;13,403.78,333.55,47.73,7.86">Proceedings of the 17th ACM conference on Computer supported cooperative work &amp; social computing</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Fussell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Lutters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">R M M R</forename></persName>
		</editor>
		<meeting>the 17th ACM conference on Computer supported cooperative work &amp; social computing<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2014-02">February 2014</date>
			<biblScope unit="page" from="626" to="638" />
		</imprint>
	</monogr>
	<note>CSCW 2014</note>
</biblStruct>

<biblStruct coords="13,142.96,354.78,337.63,7.86;13,151.52,365.74,329.07,7.86;13,151.52,376.67,121.20,7.89" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,469.07,354.78,11.52,7.86;13,151.52,365.74,146.80,7.86">Indexing by Latent Semantic Analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Harshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,306.17,365.74,174.42,7.86;13,151.52,376.70,29.19,7.86">Journal of the Association for Information Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="391" to="407" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,386.97,337.64,7.86;13,151.52,397.93,329.07,7.86;13,151.52,408.89,329.07,7.86;13,151.52,419.84,329.07,7.86;13,151.52,430.80,329.07,7.86;13,151.52,441.76,250.09,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,363.52,386.97,117.07,7.86;13,151.52,397.93,228.38,7.86">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
		<ptr target="https://doi.org/10.18653/v1/N19-1423" />
	</analytic>
	<monogr>
		<title level="m" coord="13,403.80,397.93,76.79,7.86;13,151.52,408.89,329.07,7.86;13,151.52,419.84,209.93,7.86">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">Jun 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="13,142.96,452.03,337.63,7.86;13,151.52,462.99,329.07,7.86;13,151.52,473.95,329.07,7.86;13,151.52,484.88,152.74,7.89" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,348.70,462.99,131.89,7.86;13,151.52,473.95,114.57,7.86">Facebook Language Predicts Depression in Medical Records</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Merchant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Crutchley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Preot ¬∏iuc-Pietro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Asch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,274.69,473.95,205.90,7.86;13,151.52,484.91,32.38,7.86">Proceedings of the National Academy of Sciences (PNAS)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">44</biblScope>
			<biblScope unit="page" from="11203" to="11208" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,495.18,337.64,7.86;13,151.52,506.14,62.97,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,189.42,495.18,167.30,7.86">A Synopsis of Linguistic Theory 1930-1955</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Firth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,363.28,495.18,117.31,7.86">Studies in Linguistic Analysis</title>
		<imprint>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="1957">1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,516.38,274.49,7.89" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,195.90,516.40,95.77,7.86">Distributional Structure</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,298.79,516.40,22.03,7.86">Word</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="146" to="162" />
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,526.67,337.97,7.86;13,151.52,537.63,329.07,7.86;13,151.52,548.59,329.07,7.86;13,151.52,559.55,329.07,7.86;13,151.52,570.51,37.37,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,253.16,526.67,227.43,7.86;13,151.52,537.63,116.88,7.86">Vader: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Hutto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,237.39,548.59,243.20,7.86;13,151.52,559.55,157.33,7.86">Proceedings of the 8th International AAAI Conference on Weblogs and Social Media. AAAI 2014</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Adar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Resnick</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Choudhury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Hogan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Oh</surname></persName>
		</editor>
		<meeting>the 8th International AAAI Conference on Weblogs and Social Media. AAAI 2014<address><addrLine>Palo Alto, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2014-04">June 1-4 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,580.78,337.97,7.86;13,151.52,591.73,329.07,7.86;13,151.52,602.69,314.49,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,243.07,580.78,185.41,7.86">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6980" />
	</analytic>
	<monogr>
		<title level="m" coord="13,236.65,591.73,243.94,7.86;13,151.52,602.69,117.29,7.86">Proceedings of the 3rd International Conference on Learning Representationss. ICLR 2015</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</editor>
		<meeting>the 3rd International Conference on Learning Representationss. ICLR 2015</meeting>
		<imprint>
			<date type="published" when="2015-09">May 7-9 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,612.96,337.98,7.86;13,151.52,623.92,329.07,7.86;13,151.52,634.88,329.07,7.86;13,151.52,645.84,329.07,7.86;13,151.52,656.80,250.59,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,255.61,612.96,224.98,7.86;13,151.52,623.92,39.82,7.86">A Test Collection for Research on Depression and Language Use</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,384.71,623.92,95.89,7.86;13,151.52,634.88,329.07,7.86;13,151.52,645.84,171.36,7.86;13,373.97,645.84,44.38,7.86">Proceedings of the 7th International Conference of the CLEF Association</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">F C M</forename></persName>
		</editor>
		<meeting>the 7th International Conference of the CLEF Association<address><addrLine>Cham, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Intrnational Publishing</publisher>
			<date type="published" when="2016-08">September 5-8 2016</date>
			<biblScope unit="page" from="28" to="39" />
		</imprint>
	</monogr>
	<note>CLEF 2016</note>
</biblStruct>

<biblStruct coords="14,142.62,119.67,337.98,7.86;14,151.52,130.63,329.07,7.86;14,151.52,141.59,329.07,7.86;14,151.52,152.55,329.07,7.86;14,151.52,163.51,329.07,7.86;14,151.52,174.47,203.07,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="14,317.94,119.67,162.65,7.86;14,151.52,130.63,207.29,7.86">Overview of eRisk at CLEF 2019 Early Risk Prediction on the Internet (extended overview)</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2380/paper248.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="14,277.25,141.59,203.34,7.86;14,151.52,152.55,329.07,7.86;14,151.52,163.51,98.24,7.86">Information Access Evaluation meets Multilinguality, Multimodality, and Visualization</title>
		<title level="s" coord="14,308.92,163.51,122.03,7.86">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>M√ºller</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019">2380. September 2019</date>
		</imprint>
	</monogr>
	<note>Proceedings of the 10th Conference and Labs of the Evaluation Forum</note>
</biblStruct>

<biblStruct coords="14,142.62,185.43,337.98,7.86;14,151.52,196.39,329.07,7.86;14,151.52,207.35,329.07,7.86;14,151.52,218.30,329.07,7.86;14,151.52,229.26,257.51,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="14,322.59,185.43,158.01,7.86;14,151.52,196.39,41.48,7.86">eRisk 2020: Self-harm and Depression Challenges</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,254.68,207.35,225.91,7.86;14,151.52,218.30,177.92,7.86;14,394.16,218.30,44.12,7.86">Advances in Information Retrieval. Proceedings of the 42nd European Conference on IR Research</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Jose</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Magalh√£es</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Castells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Martins</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">April 14-17 2020</date>
			<biblScope unit="page" from="557" to="563" />
		</imprint>
	</monogr>
	<note>ECIR 2020</note>
</biblStruct>

<biblStruct coords="14,142.62,240.22,337.97,7.86;14,151.52,251.18,329.07,7.86;14,151.52,262.14,329.07,7.86;14,151.52,273.10,329.07,7.86;14,151.52,284.06,329.07,7.86;14,151.52,295.02,279.28,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="14,315.66,240.22,164.92,7.86;14,151.52,251.18,89.52,7.86">Overview of eRisk 2020: Early Risk Prediction on the Internet</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,453.25,262.14,27.33,7.86;14,151.52,273.10,329.07,7.86;14,151.52,284.06,288.18,7.86">Proceedings of the 11th International Conference of the CLEF Association. CLEF 2020</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lioma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>N√©v√©ol</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the 11th International Conference of the CLEF Association. CLEF 2020<address><addrLine>Cham, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">September 22-25 2020</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="14,142.62,305.98,337.98,7.86;14,151.52,316.93,329.07,7.86;14,151.52,327.89,329.07,7.86;14,151.52,338.85,199.11,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="14,288.82,305.98,191.77,7.86;14,151.52,316.93,58.81,7.86">Measuring the Latency of Depression Detection in Social Media</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sadeque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,230.40,316.93,250.19,7.86;14,151.52,327.89,98.45,7.86;14,312.84,327.89,50.47,7.86">Proceedings of the 11th ACM International Conference on Web Search and Data Mining</title>
		<meeting>the 11th ACM International Conference on Web Search and Data Mining<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2018-02">February 2018</date>
			<biblScope unit="page" from="495" to="503" />
		</imprint>
	</monogr>
	<note>WSDM 2018</note>
</biblStruct>

<biblStruct coords="14,142.62,349.81,337.98,7.86;14,151.52,360.77,329.07,7.86;14,151.52,371.73,329.07,7.86;14,151.52,382.69,329.07,7.86;14,151.52,393.65,285.77,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="14,273.69,349.81,186.87,7.86">Offence in Dialogues: A Corpus-Based Study</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sch√§fer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Burtenshaw</surname></persName>
		</author>
		<idno type="DOI">10.26615/978-954-452-056-4_125</idno>
		<ptr target="https://doi.org/10.26615/978-954-452-056-4125" />
	</analytic>
	<monogr>
		<title level="m" coord="14,247.27,360.77,233.32,7.86;14,151.52,371.73,329.07,7.86;14,151.52,382.69,62.12,7.86;14,287.05,382.69,53.44,7.86">Proceedings of the International Conference Recent Advances in Natural Language Processing: Natural Language Processing in a Deep Learning World</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Mitkov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">A</forename></persName>
		</editor>
		<meeting>the International Conference Recent Advances in Natural Language Processing: Natural Language Processing in a Deep Learning World<address><addrLine>Varna, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>INCOMA Ltd</publisher>
			<date type="published" when="2019-04">September 2-4 2019</date>
			<biblScope unit="page" from="1085" to="1093" />
		</imprint>
	</monogr>
	<note>RANLP 2019</note>
</biblStruct>

<biblStruct coords="14,142.62,404.61,337.98,7.86;14,151.52,415.56,329.07,7.86;14,151.52,426.52,139.33,7.86" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Turc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.08962v2</idno>
		<title level="m" coord="14,368.82,404.61,111.78,7.86;14,151.52,415.56,258.20,7.86">Well-Read Students Learn Better: On the Importance of Pre-training Compact Models</title>
		<imprint>
			<date type="published" when="2019-08">August 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="14,142.62,437.48,337.97,7.86;14,151.52,448.41,304.92,7.89" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="14,258.07,437.48,222.52,7.86;14,151.52,448.44,38.52,7.86">From Frequency to Meaning: Vector Space Models of Semantics</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">D</forename><surname>Turney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,197.40,448.44,167.03,7.86">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="141" to="188" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
