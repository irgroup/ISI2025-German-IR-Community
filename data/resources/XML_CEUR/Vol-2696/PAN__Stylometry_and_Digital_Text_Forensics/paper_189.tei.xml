<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,160.42,150.55,286.01,14.30;1,147.78,168.07,299.93,14.30;1,219.99,185.35,155.50,14.30;1,210.05,205.60,175.34,10.67">An Ensemble Model Using N-grams and Statistical Features to Identify Fake News Spreaders on Twitter Notebook for PAN at CLEF 2020</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,247.58,242.45,44.17,9.19"><forename type="first">Jakab</forename><surname>Buda</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Eötvös Loránd University</orgName>
								<address>
									<settlement>Budapest</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,298.95,242.45,60.29,9.19"><forename type="first">Flora</forename><surname>Bolonyai</surname></persName>
							<email>f.bolonyai@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Eötvös Loránd University</orgName>
								<address>
									<settlement>Budapest</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,160.42,150.55,286.01,14.30;1,147.78,168.07,299.93,14.30;1,219.99,185.35,155.50,14.30;1,210.05,205.60,175.34,10.67">An Ensemble Model Using N-grams and Statistical Features to Identify Fake News Spreaders on Twitter Notebook for PAN at CLEF 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9CA8E44454E859AD81125F41C95F802B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this notebook, we summarize our work process of preparing a software for the PAN 2020 Profiling Fake News Spreaders on Twitter task. Our final software was a stacking ensemble classifier of five different machine learning models; four of them use word n-grams as features, while the fifth one was based on statistical features extracted from the Twitter feeds. Our software uploaded to the TIRA platform achieved an accuracy of 75% in English and 80.5% in Spanish. Our overall accuracy of 77.75% turned out to be a tie for the first place in the competition.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The aim of the PAN 2020 Profiling Fake News Spreaders on Twitter task <ref type="bibr" coords="1,435.69,458.21,16.69,9.19" target="#b11">[12]</ref> was to investigate whether the author of a given Twitter feed is likely to spread fake news. The training and test sets of the task consisted of English and Spanish Twitter feeds <ref type="bibr" coords="1,124.80,492.77,15.34,9.19" target="#b12">[13]</ref>.</p><p>We used an ensemble of different machine learning models to provide a prediction for each user. All of our sub-models handle the Twitter feed of a user as a unit and determine a probability for each user how likely they are to be fake news spreaders. For the final predictions, these sub-models are combined using a logistic regression.</p><p>In Section 2 we present some related works on profiling fake news spreaders. In Section 3 we describe our approach in detail together with the extracted features and models. In Section 4 we present our results. In Section 5 we discuss some potential future work and in Section 6 we conclude our notebook.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>Using word n-gram variables for author profiling has been shown to be effective <ref type="bibr" coords="1,124.80,662.21,10.85,9.19" target="#b2">[3,</ref><ref type="bibr" coords="1,139.40,662.21,7.52,9.19" target="#b4">5,</ref><ref type="bibr" coords="1,150.66,662.21,7.52,9.19" target="#b8">9,</ref><ref type="bibr" coords="1,161.93,662.21,12.52,9.19" target="#b13">14,</ref><ref type="bibr" coords="1,178.20,662.21,12.52,9.19" target="#b14">15,</ref><ref type="bibr" coords="1,194.47,662.21,11.89,9.19" target="#b17">18]</ref>, especially with TF-IDF weighting <ref type="bibr" coords="1,358.00,662.21,15.35,9.19" target="#b19">[20]</ref>. Identifying fake news based on such features has been tested earlier <ref type="bibr" coords="1,322.67,673.73,10.63,9.19" target="#b0">[1]</ref>. Statistical features, such as the number of punctuation marks <ref type="bibr" coords="1,259.43,685.25,15.87,9.19" target="#b14">[15,</ref><ref type="bibr" coords="1,281.30,685.25,11.89,9.19" target="#b18">19]</ref>, medium-specific symbols (for example hashtags, and at signs in tweets, links in digital texts) <ref type="bibr" coords="2,341.74,149.81,10.83,9.19" target="#b6">[7,</ref><ref type="bibr" coords="2,355.24,149.81,7.52,9.19" target="#b7">8,</ref><ref type="bibr" coords="2,365.44,149.81,12.52,9.19" target="#b13">14,</ref><ref type="bibr" coords="2,380.63,149.81,12.52,9.19" target="#b14">15,</ref><ref type="bibr" coords="2,395.83,149.81,12.52,9.19" target="#b16">17,</ref><ref type="bibr" coords="2,411.02,149.81,11.89,9.19" target="#b18">19]</ref>, emoticons <ref type="bibr" coords="2,124.80,161.33,10.85,9.19" target="#b6">[7,</ref><ref type="bibr" coords="2,138.14,161.33,7.52,9.19" target="#b7">8,</ref><ref type="bibr" coords="2,148.14,161.33,12.52,9.19" target="#b13">14,</ref><ref type="bibr" coords="2,163.15,161.33,12.52,9.19" target="#b15">16,</ref><ref type="bibr" coords="2,178.16,161.33,13.36,9.19" target="#b18">19]</ref> or stylistic features <ref type="bibr" coords="2,272.61,161.33,11.69,9.19" target="#b7">[8]</ref> are also commonly used for text classification purposes.</p><p>SVMs <ref type="bibr" coords="2,165.01,184.61,10.85,9.19" target="#b2">[3,</ref><ref type="bibr" coords="2,179.14,184.61,7.52,9.19" target="#b4">5,</ref><ref type="bibr" coords="2,189.94,184.61,7.52,9.19" target="#b8">9,</ref><ref type="bibr" coords="2,200.74,184.61,12.52,9.19" target="#b13">14,</ref><ref type="bibr" coords="2,216.54,184.61,11.89,9.19" target="#b14">15]</ref>, XGBoost <ref type="bibr" coords="2,276.74,184.61,15.35,9.19" target="#b20">[21]</ref>, logistic regression <ref type="bibr" coords="2,376.37,184.61,16.66,9.19" target="#b18">[19]</ref> and random forest <ref type="bibr" coords="2,124.80,196.13,11.69,9.19" target="#b1">[2]</ref> models are commonly used for author profiling and text classification purposes. Although the state-of-the-art results for many text classification tasks are achieved with transformer-based language models <ref type="bibr" coords="2,301.71,219.17,10.85,9.19" target="#b3">[4,</ref><ref type="bibr" coords="2,317.90,219.17,11.89,9.19" target="#b10">11]</ref>, these are computationally very expensive solutions and perform better on tasks where text semantics is more important. Ghanem et al. proposed an emotionally infused LSTM model to detect false information in social media and news articles. Their model yielded state-of-theart results on three datasets, but it is also computationally expensive <ref type="bibr" coords="2,441.27,265.25,10.64,9.19" target="#b5">[6]</ref>, so experimenting with lighter approaches still has practical benefits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The corpus and the environment setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">The corpus</head><p>The corpus for the PAN 2020 Profiling Fake News Spreaders on Twitter task <ref type="bibr" coords="2,454.00,395.33,16.68,9.19" target="#b11">[12]</ref> consists of one English and one Spanish corpus, each containing 300 XML files. Each of these files contains 100 tweets from an author. Because of the moderate size of the corpus, we wanted to avoid splitting the corpus into a training and a development set. Therefore, we used cross-validation techniques to prevent overfitting. As opposed to earlier editions of the PAN competition, the dataset this year came pre-cleaned: all urls, hashtags and user mentions in the tweets were changed to standardized tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Environment setup</head><p>We developed our software using the Python language (version 3.7). To build our models we mainly used the following packages: scikit-learn<ref type="foot" coords="2,387.60,516.83,3.00,5.47" target="#foot_0">1</ref> , xgboost<ref type="foot" coords="2,430.80,516.83,3.00,5.47" target="#foot_1">2</ref> , emoji <ref type="foot" coords="2,465.12,516.83,3.00,5.47" target="#foot_2">3</ref> , lexical-diversity <ref type="foot" coords="2,189.84,528.35,3.00,5.47" target="#foot_3">4</ref> , pandas <ref type="foot" coords="2,225.60,528.35,3.00,5.47" target="#foot_4">5</ref> and numpy <ref type="foot" coords="2,276.00,528.35,3.00,5.47" target="#foot_5">6</ref> . Our codes are available on GitHub<ref type="foot" coords="2,423.12,528.35,3.00,5.47" target="#foot_6">7</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Our models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">N-gram models</head><p>We experimented with a number of machine learning models based on word ngrams extracted from the text. Precisely, we investigated the performance of regularized logistic regressions (LR), random forests (RF), XGBoost classifiers (XGB) and linear support vector machines (SVM). For all four models, we ran an extensive grid search combined with five-fold cross-validation to find the optimal text preparation method, vectorization technique and modeling parameters. We tested the same parameters for the English and Spanish data. We investigated two types of text cleaning methods for all models. The first method (M1) removed all non alphanumeric characters (except #) from the text, while the second method (M2) removed most non alphanumeric characters (except #) but kept emoticons and emojis. Both methods transformed the text to lower case. Regarding the vectorization of the corpus, we experimented with a number of parameters. We tested different word ngram ranges (unigrams, bigrams, unigrams and bigrams) and also looked at different scenarios regarding the minimum overall document frequency of the word n-grams <ref type="bibr" coords="3,124.80,364.61,10.85,9.19" target="#b2">(3,</ref><ref type="bibr" coords="3,140.27,364.61,7.52,9.19" target="#b3">4,</ref><ref type="bibr" coords="3,152.41,364.61,7.52,9.19" target="#b4">5,</ref><ref type="bibr" coords="3,164.56,364.61,7.52,9.19" target="#b5">6,</ref><ref type="bibr" coords="3,176.70,364.61,7.52,9.19" target="#b6">7,</ref><ref type="bibr" coords="3,188.84,364.61,7.52,9.19" target="#b7">8,</ref><ref type="bibr" coords="3,200.98,364.61,7.52,9.19" target="#b8">9,</ref><ref type="bibr" coords="3,213.12,364.61,13.36,9.19" target="#b9">10)</ref> included as features. Table <ref type="table" coords="3,349.34,364.61,5.04,9.19" target="#tab_0">1</ref> describes the tested model hyperparameter values during the training phase of our models. For the early bird testing phase conducted through TIRA <ref type="bibr" coords="3,367.07,646.37,15.34,9.19" target="#b9">[10]</ref>, we simply chose the model and parameter combination in each language that had the highest accuracy during the cross-validation and fitted these models on the entire training set. However, the accuracy of our model was approximately 5% lower on the test set compared to the cross-validation results (79% vs. 83% for the Spanish dataset and 69% vs. 76% for the English dataset), so we used a different approach during the final testing phase.</p><p>The ensemble method we used for the final version of our software (described in detail in Section 3.2.3) required the best text cleaning and vectorization parameters and hyperparameters for each model. These hyperparameters are summarized in Table <ref type="table" coords="4,124.80,219.17,3.76,9.19" target="#tab_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">User-wise statistical model</head><p>Apart from the n-gram based models, we constructed a model based on statistical variables describing all hundred tweets of each author, thus giving one more prediction per author. The variables used in this model are as follows:</p><p>• the mean length of the 100 tweets of the authors both in words and in characters; • the minimum length of the 100 tweets of the authors both in words and in characters; • the maximum length of the 100 tweets of the authors both in words and in characters; • the standard deviations of the length of the 100 tweets of the authors both in words and in characters; • the range of the length of the 100 tweets of the authors both in words and in characters; • the number of retweets in the dataset by each author;</p><p>• the number of URL links in the dataset by each author;</p><p>• the number of hashtags in the dataset by each author;</p><p>• the number of mentions in the dataset by each author;</p><p>• the number of emojis in the dataset by each author;</p><p>• the number of ellipses used at the end of the tweets in the 100 tweets of the authors; • a stylistic feature, the type-token ratio to measure the lexical diversity of the authors (in the dataset each author has 100 tweets thus the number of tokens per author does not differ as much that it would cause a great diversity in the TTRs). This gives a total of 17 statistical variables. Since we used an XGBoost classifier, we did not normalize the variables and the linear correlation between the variables posed no problem.</p><p>To find the best hyperparameter set, we used a five-fold cross-validated grid search and finally refitted the best model on the whole data. The cross-validated accuracies achieved this way are 70% and 74% for the English and Spanish data respectively. Table <ref type="table" coords="5,150.06,525.89,5.04,9.19" target="#tab_2">3</ref> contains the best hyperparameters found. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Stacking ensemble</head><p>After identifying the best hyperparameters for the five mentioned models with cross-validation, we had to find a reliable ensemble method. To avoid overfitting this ensemble model to the training set, we did not train it using the predictions of the five final trained models. Instead, we wanted to create a dataset that represents the predictions that are produced by our models. To do this, we refitted the five submodels with the cross-validated hyperparameters five times on different chunks of the original training data (each consisting of tweets from 240 users). The predictions given by these five models to the 60 remaining users were appended to the training data of the ensemble model, thus this training set consisted of predictions given to all 300 users in the training data, but these predictions were given by five different models in case of each model type. The sample created this way can be interpreted as an approximation of a sample from the distribution of the predictions of the final five models on the test set. We created a test set with the same method but with a different split of the training data.</p><p>We then used these constructed training and test sets to find the best ensemble from the following three methods: majority voting, linear regression of predicted probabilities (this includes the simple mean), and a logistic regression model. The best and most reliable results were given by the logistic model; therefore, we used this model as our final ensemble method. Table <ref type="table" coords="6,316.09,622.85,5.04,9.19" target="#tab_3">4</ref> summarizes the logistic regression coefficients for the probabilistic predictions of each model for both languages. The validity of this method is backed by the fact that our results on the training sets (an accuracy of 75% and 81% for the English and Spanish set respectively) were only slightly better than the final test results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>As mentioned in Section 3, we tested two versions of our software. For the early bird testing, we used the single best n-gram models based on our cross-validated grid search (a random forest classifier for the English set and a support vector machines classifier for the Spanish set). Using these models, we experienced a significant decrease in the accuracy of the models compared to their cross-validated performance, so this was one of the reasons why we decided to incorporate a number of different models for our final software. As Table <ref type="table" coords="7,338.13,484.61,5.04,9.19" target="#tab_4">5</ref> shows, relying on a number of different models and a statistically based ensemble method proved to be a good solution. First, the cross-validated accuracies of our final models were almost the same as their accuracies on the test set, and second, our final software was able to reach a higher accuracy in both languages than our early bird solution. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Future Work</head><p>One of the unanswered questions that emerged during this project is concerning the reasons behind the fact that our models are better at identifying fake news spreaders that tweet in Spanish. This is true about all of our individual models regardless of the features they used, and about the final ensemble model as well. We assume that it would be beneficial to conduct some qualitative research about the tweets in the dataset to better understand why fake news spreaders that tweet in Spanish are more distinguishable from regular users than those that tweet in English.</p><p>Another promising direction for achieving higher accuracy in profiling fake news spreaders is to develop a software that is able to determine whether a single tweet should be considered as fake news. It is reasonable to assume that even those that are labelled as fake news spreaders only post some tweets that can be considered as fake news, while some of their posts are just regular tweets. Therefore, from the perspective of our approach, the current dataset is likely to contain a lot of noise. If we were able to identify fake news on the level of tweets, we could build a model relying on this information that would allow us to give predictions for each tweet. This approach was unfortunately not executable with the PAN20 Fake News Spreaders dataset <ref type="bibr" coords="8,200.94,373.97,15.34,9.19" target="#b12">[13]</ref>, as it did not provide information about single tweets, and additionally, all URL links, hashtags and user mentions, which could have provided valuable clues about the credibility of the tweet, were replaced by standardized tokens in the text. Moreover, even if we had access to these tweets in their original form, manual labeling would be a tedious process even for the "small" dataset of 300 users. However, it would be interesting to investigate how a software that is able to decide whether a single tweet is fake news would perform in this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this notebook, we summarized our work process of preparing a software for the PAN 2020 Profiling Fake News Spreaders on Twitter task <ref type="bibr" coords="8,361.14,520.37,15.34,9.19" target="#b11">[12]</ref>. Originally, we looked at a number of machine learning models using n-grams as features. To find the best parameters for the models, we conducted an extensive grid search combined with cross-validation. After finding the models achieving the highest accuracy during the cross-validation, we fitted these on the entire training set. However, we realized during the early bird testing phase that this approach results in a significantly lower accuracy on the test set compared to its cross-validation results. Therefore, for our final software, we decided to create a combined model which was a stacking ensemble of five sub-models. Four of these sub-models (a logistic regression, a support vector machine classifier, a random forest classifier and an XGBoost classifier) used word n-grams as features, while the fifth model (another XGBoost model) used statistical features extracted from the Twitter feed. For each sub-model, we used grid search and cross-validation to find the best performing parameters and fitted the models on the entire training data with these parameters. To get a final prediction for each user, we trained a logistic regression that used the probabilistic predictions of the sub-models as features. Using the ensemble model, we were able to achieve the same accuracy on the test set as during the cross-validation process. Overall, our final software was able to identify fake news spreaders with a 75% accuracy among users that tweet in English, and with an 80.5% accuracy among users that tweet in Spanish. Our overall accuracy of 77.75% was tied as the highest performance in the competition.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,145.37,399.19,312.08,229.97"><head>Table 1 :</head><label>1</label><figDesc>Grid-searched hyperparameters for the used machine learning models</figDesc><table coords="3,145.37,419.43,312.08,209.73"><row><cell>Model</cell><cell cols="2">Model hyperparameters Name (Python parameter name)</cell><cell>Values</cell></row><row><cell>LR</cell><cell>Regularization coefficient (C)</cell><cell cols="2">{0.1,1,10,100,1000}</cell></row><row><cell></cell><cell>Number of boosting rounds (B)</cell><cell cols="2">{100,300,400}</cell></row><row><cell>RF</cell><cell>Minimum number of cases on each leaf (min_samples_leaf)</cell><cell cols="2">{5,6,7,8,9,10}</cell></row><row><cell>SVM</cell><cell>Regularization coefficient (C)</cell><cell cols="2">{1,10,100,1000}</cell></row><row><cell></cell><cell>Learning rate (eta):</cell><cell cols="2">{0.01,0.1,0.3}</cell></row><row><cell></cell><cell>Number of estimators (n_estimators)</cell><cell></cell><cell>{200,300}</cell></row><row><cell>XGB</cell><cell>Maximum depth of a tree (max_depth)</cell><cell></cell><cell>{3,4,5,6}</cell></row><row><cell></cell><cell>Subsample ratio (subsample)</cell><cell></cell><cell>{0.6,0.7,0.8}</cell></row><row><cell></cell><cell>Subsample ratio of columns (colsample_bytree)</cell><cell></cell><cell>{0.5,0.6,0.7}</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,124.80,242.23,341.97,452.45"><head>Table 2 :</head><label>2</label><figDesc>The best performing text cleaning methods, vectorization parameters and model hyperparameters for the n-gram based machine learning models Parameter names in the relevant Python package/function. Detailed description in Table1.</figDesc><table coords="4,124.80,272.79,341.97,417.99"><row><cell cols="2">Language Model</cell><cell>Text cleaning</cell><cell cols="2">Vectorization Min. global N-grams occurrence</cell><cell>Model hyperparameters 8</cell></row><row><cell></cell><cell>LR</cell><cell>M1</cell><cell>uni-and bigrams</cell><cell>6</cell><cell>C=1000</cell></row><row><cell></cell><cell>RF</cell><cell>M2</cell><cell>uni-and bigrams</cell><cell>9</cell><cell>B=300 min_samples_leaf=9</cell></row><row><cell>EN</cell><cell>SVM</cell><cell>M1</cell><cell>uni-and bigrams</cell><cell>5</cell><cell>C=100</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>eta= 0.01</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>max_depth=6</cell></row><row><cell></cell><cell>XGB</cell><cell>M1</cell><cell>uni-and bigrams</cell><cell>8</cell><cell>colsample_bytree=0.6</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>subsample=0.8</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>n_estimators=300</cell></row><row><cell></cell><cell>LR</cell><cell>M1</cell><cell>bigrams</cell><cell>9</cell><cell>C=100</cell></row><row><cell></cell><cell>RF</cell><cell>M1</cell><cell>uni-and bigrams</cell><cell>3</cell><cell>B=100 min_samples_leaf=8</cell></row><row><cell></cell><cell>SVM</cell><cell>M1</cell><cell>bigrams</cell><cell>8</cell><cell>C=10</cell></row><row><cell>ES</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>eta= 0.3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>max_depth=6</cell></row><row><cell></cell><cell>XGB</cell><cell>M1</cell><cell>uni-and bigrams</cell><cell>8</cell><cell>colsample_bytree=0.7</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>subsample=0.6</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>n_estimators=200</cell></row><row><cell>8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,139.69,161.35,327.46,206.93"><head>Table 3 :</head><label>3</label><figDesc>The best model hyperparameters for the XGBoost model using statistical features</figDesc><table coords="6,183.66,181.35,227.04,186.93"><row><cell>Parameter name</cell><cell cols="2">Parameter values EN ES</cell></row><row><cell>Column sample by node</cell><cell>1</cell><cell>0.8</cell></row><row><cell>Column sample by tree</cell><cell>0.9</cell><cell>0.8</cell></row><row><cell>gamma</cell><cell>2</cell><cell>4</cell></row><row><cell>Learning rate</cell><cell>0.2</cell><cell>0.3</cell></row><row><cell>Max depth</cell><cell>2</cell><cell>3</cell></row><row><cell>Min child weight</cell><cell>4</cell><cell>5</cell></row><row><cell>Number of estimators</cell><cell>200</cell><cell>100</cell></row><row><cell>alpha</cell><cell>0.1</cell><cell>0.3</cell></row><row><cell>Subsample</cell><cell>0.8</cell><cell>0.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,140.57,155.35,325.70,141.89"><head>Table 4 :</head><label>4</label><figDesc>Logistic regression coefficients for the predicted probabilities by each sub-model</figDesc><table coords="7,203.42,175.83,177.90,121.42"><row><cell></cell><cell cols="2">Coefficient values</cell></row><row><cell>Model</cell><cell>EN</cell><cell>ES</cell></row><row><cell>LR</cell><cell>0.8</cell><cell>1.31</cell></row><row><cell>SVM</cell><cell>0.48</cell><cell>1.16</cell></row><row><cell>RF</cell><cell>0</cell><cell>0</cell></row><row><cell>XGB</cell><cell>1.07</cell><cell>0.54</cell></row><row><cell>Statistical XGB</cell><cell>0.2</cell><cell>0.12</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,128.33,553.75,325.44,93.17"><head>Table 5 :</head><label>5</label><figDesc>Accuracies achieved by the two versions of our software during the crossvalidation process and on the test set</figDesc><table coords="7,128.33,584.31,321.72,62.62"><row><cell>Language</cell><cell cols="2">Early bird software</cell><cell cols="2">Final software</cell></row><row><cell></cell><cell>CV (training set)</cell><cell>Test set</cell><cell>CV (training set)</cell><cell>Test set</cell></row><row><cell>EN</cell><cell>83%</cell><cell>79%</cell><cell>81%</cell><cell>80.5%</cell></row><row><cell>ES</cell><cell>75%</cell><cell>69%</cell><cell>75%</cell><cell>75%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,130.17,622.28,82.26,8.32"><p>https://scikit-learn.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,130.17,632.84,110.55,8.32"><p>https://xgboost.readthedocs.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,130.17,643.64,108.30,8.32"><p>https://pypi.org/project/emoji/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,130.17,654.20,146.25,8.32"><p>https://pypi.org/project/lexical-diversity/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="2,130.17,665.00,93.04,8.32"><p>https://pandas.pydata.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="2,130.17,675.56,66.79,8.32"><p>https://numpy.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="2,130.17,686.36,159.79,8.32"><p>https://github.com/pan-webis-de/bolonyai20</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,128.56,203.81,342.15,9.19;10,142.65,215.33,328.18,9.19;10,142.65,226.85,327.96,9.19;10,142.65,238.37,327.98,9.19;10,142.65,249.89,92.49,9.19" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,276.97,203.81,193.75,9.19;10,142.65,215.33,179.47,9.19">Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Traore</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Saad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,179.94,226.85,290.66,9.19;10,142.65,238.37,115.81,9.19">Intelligent, Secure, and Dependable Systems in Distributed and Cloud Environments</title>
		<title level="s" coord="10,267.54,238.37,149.42,9.19">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Traore</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Woungang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Awad</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10618</biblScope>
		</imprint>
	</monogr>
	<note>ISDDC 2017</note>
</biblStruct>

<biblStruct coords="10,128.56,267.41,342.24,9.19;10,142.65,278.93,328.02,9.19;10,142.65,290.45,315.22,9.19" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,441.34,267.41,29.46,9.19;10,142.65,278.93,309.74,9.19">Gender Classification of Web Authors Using Feature Selection and Language Models</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Aravantinou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Simaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Mporas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Megalooikonomou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="10,142.65,290.45,231.85,9.19">Speech and Computer Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="page" from="226" to="233" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.56,308.21,342.16,9.19;10,142.65,319.73,328.00,9.19;10,142.65,331.25,328.05,9.19;10,142.65,342.77,252.77,9.19" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,252.26,308.21,218.46,9.19;10,142.65,319.73,140.47,9.19">A quantitative analysis of lexical differences between genders in telephone conversations</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Boulis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ostendorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,304.57,319.73,166.09,9.19;10,142.65,331.25,228.88,9.19">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics -ACL &apos;05</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics -ACL &apos;05<address><addrLine>Morristown, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="435" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.56,360.29,342.13,9.19;10,142.65,371.81,319.96,9.19" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="10,349.81,360.29,120.88,9.19;10,142.65,371.81,224.13,9.19">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>NAACL-HLT</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.56,389.33,342.18,9.19;10,142.65,400.85,328.03,9.19;10,142.65,412.37,219.45,9.19" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,277.37,389.33,193.37,9.19;10,142.65,400.85,90.16,9.19">Modeling Latent Biographic Attributes in Conversational Genres</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Garera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,254.67,400.85,216.01,9.19;10,142.65,412.37,136.27,9.19">Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP</title>
		<meeting>the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="710" to="718" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.56,430.13,342.15,9.19;10,142.80,441.65,327.92,9.19;10,142.80,453.17,199.98,9.19" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,288.87,430.13,181.85,9.19;10,142.80,441.65,161.95,9.19">An Emotional Analysis of False Information in Social Media and News Articles</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,334.05,441.65,136.66,9.19;10,142.80,453.17,79.70,9.19">ACM Transactions on Internet Technology (TOIT)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.56,470.69,342.11,9.19;10,142.65,482.21,328.03,9.19;10,142.65,493.73,328.04,9.19;10,142.65,505.25,328.12,9.19;10,142.65,516.77,303.56,9.19" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,142.65,482.21,328.03,9.19;10,142.65,493.73,122.61,9.19">Efficient social network multilingual classification using character, POS n-grams and Dynamic Normalization</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Gonzalez-Gallardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Torres-Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Rendon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sierra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,296.23,493.73,174.45,9.19;10,142.65,505.25,328.12,9.19;10,142.65,516.77,166.63,9.19">IC3K 2016 -Proceedings of the 8th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management</title>
		<imprint>
			<publisher>SciTePress</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="307" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.56,534.29,342.15,9.19;10,142.65,546.05,328.05,9.19;10,142.65,557.57,151.95,9.19" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,216.97,546.05,184.18,9.19">Age and gender identification in social media</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Marquardt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Farnadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Davalos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Teredesai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Cock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,423.04,546.05,47.66,9.19;10,142.65,557.57,55.54,9.19">CLEF 2014 working notes</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1129" to="1136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.56,575.09,342.11,9.19;10,142.65,586.61,328.03,9.19;10,142.65,598.13,328.10,9.19;10,142.65,609.65,179.99,9.19" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,360.10,575.09,110.58,9.19;10,142.65,586.61,104.96,9.19">Predicting Age and Gender in Online Social Networks</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Peersman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Van Vaerenbergh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,268.78,586.61,201.90,9.19;10,142.65,598.13,180.11,9.19">Proceedings of the 3rd International Workshop on Search and Mining User-Generated Contents</title>
		<meeting>the 3rd International Workshop on Search and Mining User-Generated Contents<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="37" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,133.15,627.17,337.57,9.19;10,142.65,638.69,328.15,9.19;10,142.65,650.45,311.85,9.19" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,361.72,627.17,109.00,9.19;10,142.65,638.69,48.46,9.19">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,320.05,638.69,150.75,9.19;10,142.65,650.45,237.86,9.19">Information Retrieval Evaluation in a Changing World -Lessons Learned from 20 Years of CLEF</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,133.15,149.81,337.53,9.19;11,142.65,161.33,328.01,9.19;11,142.65,172.85,26.70,9.19" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="11,431.22,149.81,39.45,9.19;11,142.65,161.33,192.62,9.19">Language Models are Unsupervised Multitask Learners</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>OpenAI</publisher>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,133.15,190.61,337.47,9.19;11,142.65,202.13,328.01,9.19;11,142.65,213.65,327.96,9.19;11,142.65,225.17,328.04,9.19;11,142.65,236.69,26.70,9.19" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,351.37,190.61,119.24,9.19;11,142.65,202.13,296.95,9.19">Overview of the 8th Author Profiling Task at PAN 2020: Profiling Fake News Spreaders on Twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="11,380.34,213.65,90.28,9.19;11,142.65,225.17,43.29,9.19">CLEF 2020 Labs and Workshops</title>
		<title level="s" coord="11,196.89,225.17,239.66,9.19">Notebook Papers. CEUR Workshop Proceedings.CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,133.15,254.21,337.56,9.19;11,142.65,265.73,310.26,9.19" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,343.00,254.21,127.70,9.19;11,142.65,265.73,41.96,9.19">Profiling Fake News Spreaders on Twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.3692319</idno>
		<ptr target="http://doi.org/10.5281/zenodo.3692319" />
	</analytic>
	<monogr>
		<title level="j" coord="11,191.53,265.73,30.43,9.19">Data set</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,133.15,283.25,337.53,9.19;11,142.65,294.77,328.03,9.19;11,142.65,306.53,302.17,9.19" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,373.80,283.25,96.88,9.19;11,142.65,294.77,85.36,9.19">Classifying latent user attributes in Twitter</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Shreevats</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,255.52,294.77,215.16,9.19;11,142.65,306.53,225.14,9.19">SMUC &apos;10: Proceedings of the 2nd international workshop on Search and mining user-generated contents</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="37" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,133.15,324.05,337.53,9.19;11,142.65,335.57,328.06,9.19;11,142.65,347.09,167.28,9.19" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,354.65,324.05,116.03,9.19;11,142.65,335.57,268.54,9.19">Author Profiling: Predicting Age and Gender from Blogs Notebook for PAN at CLEF 2013</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Santosh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,435.12,335.57,35.60,9.19;11,142.65,347.09,133.68,9.19">Working Notes for CLEF 2013 Conference</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,133.15,364.61,337.52,9.19;11,142.65,376.13,328.04,9.19;11,142.65,387.65,328.01,9.19;11,142.65,399.17,328.00,9.19;11,142.65,410.69,257.99,9.19" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,449.54,364.61,21.13,9.19;11,142.65,376.13,328.04,9.19;11,142.65,387.65,107.53,9.19">Deep Learning Network Models to Categorize Texts According to Author&apos;s Gender and to Identify Text Sentiment</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sboev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Litvinova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Voronina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gudovskikh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Rybka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,272.92,387.65,197.74,9.19;11,142.65,399.17,275.38,9.19">Proceedings -2016 International Conference on Computational Science and Computational Intelligence, CSCI 2016</title>
		<meeting>-2016 International Conference on Computational Science and Computational Intelligence, CSCI 2016</meeting>
		<imprint>
			<publisher>Institute of Electrical and Electronics Engineers Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1101" to="1106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,133.15,428.45,337.51,9.19;11,142.65,439.97,328.07,9.19;11,142.65,451.49,328.02,9.19;11,142.65,463.01,82.51,9.19" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,360.47,428.45,110.19,9.19;11,142.65,439.97,51.59,9.19">Effects of Age and Gender on Blogging</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pennebaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,222.23,439.97,248.49,9.19;11,142.65,451.49,323.13,9.19">AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="199" to="205" />
		</imprint>
	</monogr>
	<note>American Association for Artificial Intelligence (AAAI)</note>
</biblStruct>

<biblStruct coords="11,133.15,480.53,337.53,9.19;11,142.65,492.05,328.03,9.19;11,142.65,503.57,217.14,9.19" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="11,284.43,480.53,186.24,9.19;11,142.65,492.05,128.37,9.19">Author Profiling based on Text and Images Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Stout</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Musters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Pool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,323.74,492.05,146.94,9.19;11,142.65,503.57,183.13,9.19">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,133.15,521.09,337.49,9.19;11,142.65,532.85,328.02,9.19;11,142.65,544.37,328.00,9.19;11,142.65,555.89,170.26,9.19" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="11,253.25,521.09,217.38,9.19;11,142.65,532.85,328.02,9.19;11,142.65,544.37,41.18,9.19">On Predicting Sociodemographic Traits and Emotions from Communications in Social Networks and Their Implications to Online Self Disclosure</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bachrach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,206.53,544.37,214.42,9.19">Cyberpsychology, Behavior, and Social Networking</title>
		<imprint>
			<publisher>Mary Ann Liebert Inc</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="726" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,133.15,573.41,337.55,9.19;11,142.65,584.93,328.02,9.19;11,142.65,596.45,26.70,9.19" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="11,191.87,573.41,222.54,9.19">A comparative study of author gender identification</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Yildiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,439.55,573.41,31.15,9.19;11,142.65,584.93,241.69,9.19">Turkish Journal of Electrical Engineering and Computer Science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1052" to="1064" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,133.15,613.97,337.47,9.19;11,142.65,625.49,328.07,9.19;11,142.65,637.01,223.90,9.19" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="11,231.13,613.97,239.48,9.19;11,142.65,625.49,38.14,9.19">Hotel reviews sentiment analysis based on word vector clustering</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,201.81,625.49,268.91,9.19;11,142.65,637.01,102.39,9.19">2nd IEEE International Conference on Computational Intelligence and Applications (ICCIA)</title>
		<meeting><address><addrLine>Beijing</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="260" to="264" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
