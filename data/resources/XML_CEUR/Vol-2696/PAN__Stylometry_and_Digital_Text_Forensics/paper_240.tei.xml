<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,154.53,115.90,306.29,12.90;1,191.67,133.83,232.02,12.90;1,223.43,153.68,168.50,10.75">Authorship Verification with Prediction by Partial Matching and Context-free Grammar Notebook for PAN at CLEF 2020</title>
				<funder ref="#_wgYuZ3x">
					<orgName type="full">Cusanuswerk Academic Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,277.97,190.08,59.43,8.64"><forename type="first">Łukasz</forename><forename type="middle">G</forename><surname>Ągała</surname></persName>
							<email>lukasz.gagala@stud.uni-goettingen.de</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Göttingen</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,154.53,115.90,306.29,12.90;1,191.67,133.83,232.02,12.90;1,223.43,153.68,168.50,10.75">Authorship Verification with Prediction by Partial Matching and Context-free Grammar Notebook for PAN at CLEF 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7F113CF588E24E03752A3231958D9BB2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In our approach to authorship verification (AV) we proposed a data compression method based on the widespread Prediction by Partial Matching (PPM) algorithm extended with Context-free Grammar character preprocessing. The most frequent in-word bigrams in each text are replaced by special symbols and accepted by a modified version of PPM algorithm. For similarity measure between text samples we chose Compression-Based Cosine (CBC) that in previous research had been proven to perform slightly better than alternative measures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Authorship verification is an active research area of computational linguistics that can be expressed as a fundamental question of stylometry, namely whether or not two texts are written by one and the same author <ref type="bibr" coords="1,302.01,424.72,15.27,8.64" target="#b12">[13]</ref>. It has a wide range of applications in forensic linguistics and fraud and plagiarism detection. Among notable examples, we can name blackmail messages, false insurance claims or online reviews and opinion statements, where authorship analysis may turn out to be instrumental in answering forensic questions.</p><p>For 2020 edition of PAN challenge a large dataset in twofold version was prepared <ref type="bibr" coords="1,134.77,496.45,10.58,8.64" target="#b1">[2]</ref>. The dataset consists of pairs of text fragments of English language fanfiction being written either by one or two authors. For PAN 2020, similarly as in 2018 and 2019 editions, fanfiction literature was chosen as a source of the task corpus. Fanfiction literature is written by members of particular fandom, i.e. a subculture of fans concentrated around specific films, TV series, books, like Harry Potter and Star Wars, who re-enact a so-called universe of their interest by organising fan events, drawing comic books, creating multimedia content or writing new novels. The particular literary genre of literary fanfiction aims to emulate the original world of a respective fiction, but they very often enhance its plot and add new figures, places and events <ref type="bibr" coords="1,392.24,592.09,25.87,8.64">[3] [9]</ref>. In this regard fanfiction of different fandoms written by one person may display a lot of stylistic divergence coming from attempts to stick to a particular style that is regarded as typical for a given fandom. Authorship verification for that type of texts can, therefore, be seen as cross-domain verification similarly to cross-domain attribution <ref type="bibr" coords="2,397.58,131.27,15.27,8.64" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>For PAN 2020 Authorship Verification challenge we tried to enrich data-compressionbased methods for authorship attribution/verification (AA/AV) with text pre-processing. Our starting point were publications on the subject by Halvani et al. <ref type="bibr" coords="2,421.54,208.02,26.93,8.64">[8] [7]</ref> exploring different types of compression algorithms and metrics. Furthermore, we applied character-based context-free grammar rules as a feature engineering step as described by Aljehane <ref type="bibr" coords="2,187.48,243.89,10.58,8.64" target="#b0">[1]</ref>. The final verification decision was made by as proposed in <ref type="bibr" coords="2,450.06,243.89,10.58,8.64" target="#b7">[8]</ref>. We describe carefully our approach in the subsequent section Method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Compression Methods</head><p>Data compression algorithms are used in a variety of domains (bioinformatics, social sciences, image processing) for classification and clustering tasks. The theoretical foundation of those methods lies in information theory, more precisely, in Kolmogorov complexity <ref type="bibr" coords="2,164.89,363.00,15.27,8.64" target="#b13">[14]</ref>. The length of the shortest code (description) that can produce an object is called the Kolmogorov complexity of that object.</p><p>(1)</p><formula xml:id="formula_0" coords="2,278.67,406.67,58.02,8.74">K(s) = |d(s)|</formula><p>Kolmogorov complexity can be used to define an information distance between two objects and has the following formula:</p><p>(2)</p><p>N ID(x, y) = max{K(x|y), K(y|x)} max{K(x), K(y)} ,</p><p>where K(x|y) is a conditional complexity of x given y. Normalised Information Distance (NID) has been proven to satisfy the requirements for metric distance measure, however it remains incomputable <ref type="bibr" coords="2,291.83,524.13,50.03,8.64">[14, pp. 660]</ref>. For practical applications we can approximate NID by compression algorithms, such like Huffman coding, Lempel-Ziv compression (LZ77 and LZ78) or Prediction by Partial Matching (PPM) that are available in popular data compression libraries and programs, for example WINZIP or 7-ZIP <ref type="bibr" coords="2,134.77,571.95,15.27,8.64" target="#b14">[15]</ref>. Such an approximation of NID is called Normalised Compression Distance (NCD). In this case C value is the length of the compressed objects expressed in the number of bits.</p><p>(3)</p><formula xml:id="formula_1" coords="2,229.23,612.23,155.71,22.31">N CD(x, y) = max{C(x|y), C(y|x)} max{C(x), C(y)}</formula><p>A couple of alternative variations of that metric measure were proposed for the task of authorship verification:</p><p>• Compression-based Cosine (CBC) introduced by Sculley and Brodley <ref type="bibr" coords="3,430.78,119.31,15.27,8.64" target="#b15">[16]</ref>.</p><formula xml:id="formula_2" coords="3,151.70,134.92,249.57,23.70">(4) CBC(x, y) = 1 - C(x) + C(y) -C(xy) C(x)C(y)</formula><p>• Chen-Li Metric (CLM) credited by Sculley and Brodley <ref type="bibr" coords="3,374.36,165.36,16.60,8.64" target="#b15">[16]</ref> to Li et al. <ref type="bibr" coords="3,436.89,165.36,10.58,8.64" target="#b3">[4]</ref>.</p><p>(</p><formula xml:id="formula_3" coords="3,141.74,180.96,332.71,66.42">) CLM (x, y) = 1 - C(x) -C(x|y) C(xy) • Compression-based Dissimilarity Measure (CDM) proposed by Keogh et al. [10]. (6) CDM (x, y) = C(xy) C(x) + Cy<label>5</label></formula><p>Drawing on the research by Halvani et al. <ref type="bibr" coords="3,316.99,253.58,10.20,8.64" target="#b7">[8]</ref>, we decided to proceed with CBC and our own Python implementation of PPM in PPMC variant <ref type="bibr" coords="3,362.27,265.53,10.58,8.64" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Prediction by Partial Matching</head><p>Compression Method algorithms (CM) are widely used across many fields of scientific research (not only in computer sciences but also in genetics or social sciences). They have gained momentum in like manner in the domain of computational linguistics. Particularly in the text classification task, the Prediction by Partial Matching (PPM) algorithm seems to be a preferred CM, however it is not the most compelling approach for data compression itself <ref type="bibr" coords="3,247.72,367.66,10.58,8.64" target="#b7">[8]</ref>. PPM is used in different variances (therefore we can rather speak of a family of algorithms) in many compression programs, where it is very often combined with other computational techniques <ref type="bibr" coords="3,352.73,391.57,47.47,8.64">[15, pp.292</ref>]. The fundamental principle of PPM is a context-dependent prediction of each subsequent character in a text string. The context is given by a window of preceding characters with a predefined length (there exists also a PPM version with a so-called unbound context <ref type="bibr" coords="3,425.17,427.44,10.45,8.64" target="#b4">[5]</ref>). The PPM algorithm with context size = n can be also seen as a Hidden Markov Model of order n. The context size can be freely defined, yet most applications choose a range between 3 and 12, since longer context do not appear to be of practical use. Figure <ref type="figure" coords="3,433.33,463.31,4.98,8.64" target="#fig_1">1</ref> shows the way, in which the PPM algorithm proceeds through a text taking the context of a given length and each subsequent character. Figure <ref type="figure" coords="3,162.44,609.01,3.88,8.64" target="#fig_1">1</ref>: The PPM algorithm running through a text consists primary of two components: a context and a symbol-to-predict (context : symbol). Here the context size is 3 and an encoded white space is represented by underscore sign _.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Feature Engineering</head><p>The bulk of development research into PPM has been done in the domain of data compression for obvious reasons. Much less seems to be done in regard to CM for different text classification tasks -the main objective of PPM is data compression as such, and merely by the fact that similar objects (texts) tend to let themselves be compressed together more efficiently than dissimilar objects do. A superior compression rate of a particular approach does not necessarily lead to better classification results, so that CM may be an attractive starting point for AA/AV but they require some dedicated amendments. One of the recently proposed improvements is a context-free grammar preprocessing for PPM (Grammar-based preprocessing for PPM, GB-PPM), which focuses on a more dense representation of character strings <ref type="bibr" coords="4,324.71,243.30,10.58,8.64" target="#b0">[1]</ref>. The GB-PPM algorithm preprocessing replaces in subsequent runs n most frequent bigrams or trigrams of characters with special symbols reducing the overall length of a text and simplifying the distribution of characters for different contexts. First, GB-PPM identifies frequent n-grams (in our case bigrams, in this toy example the status of being frequent is assigned arbitrarily):</p><p>(7) Every word has a meaning.</p><p>Then the frequent n-grams are replaced with special symbols (e.g. ABC...), which are not a part of the set of characters in the text from Eq. 7:</p><p>(8) Aery Brd has a mCnDg.</p><p>The algorithm can be run once again, identifying the next set of frequent n-grams, this time together with special symbols standing for frequent n-grams from the last run in Eq. 8:</p><p>(9) Aery Brd has a mCnDg.</p><p>Also, those frequent n-grams can be replaced further with special symbols covering both original characters and other special symbols. After n runs (in our example n = 2) the algorithm can yield a new version of the text string in Eq. 10 and a corresponding character context-free grammar in Figure <ref type="figure" coords="4,301.43,479.81,3.88,8.64" target="#fig_0">2</ref>: <ref type="bibr" coords="4,134.77,497.31,16.60,8.64" target="#b9">(10)</ref> AEy Fd hG a HnDg. The generic code for GB-PPM is given in Algorithm 1. The procedure is being applied directly before the compression of each text sample, but one can easily imagine an alternative implementation, where a single run is performed over the whole text corpus D, so that the most frequent n-grams B are derived rather from D, B ← D, than a particular text t, t ∈ D. return C(T )</p><formula xml:id="formula_4" coords="4,290.18,534.95,34.50,84.77">A → Ev B → wo C → ea D → in E → er F → Br G → as H → mC</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Verification</head><p>To verify the authorship of a pair of texts ρ = (T x , T y ) , we need to find a decision threshold θ, for which our data compression dissimilarity measure M gives us the score s ρ = M(T x , T y ), so that:</p><formula xml:id="formula_5" coords="5,229.14,440.00,155.89,23.30">decision(ρ) = Y (Y es), if s ρ &lt; θ N (N o), otherwise</formula><p>Identically as in <ref type="bibr" coords="5,217.59,473.46,10.58,8.64" target="#b7">[8]</ref>, we find θ by using the Equal Error Rate (EER) algorithm on n text pairs with the equal number of positive (Y) and negative (N) authorship cases. In this way we can determine such θ, that the rates of false positives and false negatives are equal. Sort Y and N in ascending order;</p><formula xml:id="formula_6" coords="6,149.71,248.12,207.63,263.06">l ← length(Y); i ← 0; j ← l -1 ; for k ← 0 to l -1 do if Y i &lt; N j then i ← i + 1; j ← j -1; continue; if Y i = N j then θ ← Y i ; break; if Y i &gt; N j then if i = 0 then θ ← 1 2 (Y i + N j ) ; else θ ← 1 2 (min(Y i , N j ) + min(Y i-1 , N j ) ; break; if i = l then θ ← 1 2 (Y i-1 + N j+1 ) ; return θ ;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Implementation Details and Submission</head><p>The development dataset provided by the PAN 2020 organisers consists of two versions: a smaller one that is supposed for data-sparse machine learning methods (52,601 text snippet pairs) and a bigger one that should be more applicable for data-hungry approaches (275,565 text snippet pairs) <ref type="bibr" coords="6,288.56,596.66,15.27,8.64" target="#b10">[11]</ref>. Both subcorpora were drawn from even a bigger text collection consisting of 5.8 million stories written by 1.4 million authors in 44 different languages and in 10,328 different topical domains. The data is a set of problems being pairs of English language text fragments by the same or two different authors. Moreover, the texts in the pair come from different fanfics, however there are no fanfiction crossovers, i.e. literary texts that encompass multiple fiction universes, e.g. Batman and Star Wars, Harry Potter and Spider-Man. The overall distribution of authors across all the problems resembles the "long-tail" distribution of the original text corpus, from which the development set was composed.</p><p>To establish the verification decision threshold we used 2000 text pairs. Larger amounts of text pairs did not improve our calibration parameter. For GB-PPM algorithm we decided to process only bigrams in a single run, since additional executions of that preprocessing step gave no improvement. As a dissimilarity measure we chose CBC as described in Section Method.</p><p>As we can see in Table <ref type="table" coords="7,247.65,214.95,4.98,8.64" target="#tab_1">1</ref> our approach yielded better results as baseline methods suggested by the organisers, but could not break a "glass ceiling" of around 0.8 overall score -only two approaches by Boenninghoff and by Weerasinghe achieved the level of around 0.9 overall score. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,134.77,632.92,345.82,8.64"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A character free-context grammar resulting from transformation in Eq. 7 -10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,142.24,182.54,300.05,9.03;5,149.71,196.34,27.13,8.96;5,149.71,208.37,56.09,8.96;5,149.71,220.47,83.56,8.81;5,149.71,232.43,244.58,8.81;5,149.71,244.16,193.64,9.03;5,149.71,256.19,180.70,8.96;5,149.71,268.07,70.67,8.96;5,165.05,280.10,276.60,8.96;5,165.05,291.98,136.91,8.96;5,180.39,303.94,138.02,8.96;5,195.74,315.96,179.40,8.96"><head>Algorithm 1 :</head><label>1</label><figDesc>Non-finite symbol preprocessing with the GR-PPM algorithm Input: T (sequence), i (number of passes), n (number of most frequent bigrams in the current sequence), Output: sequence T with non-terminal symbols C ← PREDICTION BY PARTIAL MATCHING for k ← 0 to i do B ← Find the n most frequent in-word bigraphs in the current text T ; foreach frequent bigram b ∈ B do foreach frequent bigram b ∈ T do non-terminal symbol s ← frequent bigram b;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,142.24,146.73,177.85,9.03;6,149.71,160.53,292.94,9.03;6,179.33,172.88,101.71,8.64;6,149.71,184.44,81.34,9.03;6,149.71,196.40,119.80,9.03;6,165.05,208.42,229.21,8.96;6,165.05,220.31,70.83,9.03"><head>Algorithm 2 :</head><label>2</label><figDesc>Determine θ threshold by EER Input: Y (the dissimilarity scores of the Y problems), N (the dissimilarity scores of the N problems) Output: θ threshold if length(Y) = length(N) then Exception ← "Number of Y and N problems mismatch!"; throw Exception;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,168.96,282.64,273.67,152.94"><head>Table 1 :</head><label>1</label><figDesc>Comparison of performance for different approaches.</figDesc><table coords="7,168.96,282.64,273.67,131.18"><row><cell>Rank</cell><cell>Team</cell><cell>Training</cell><cell>AUC</cell><cell>c@1</cell><cell>F0.5u</cell><cell cols="2">F1-score Overall</cell></row><row><cell></cell><cell></cell><cell>dataset</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>boenninghoff20</cell><cell>large</cell><cell>0.969</cell><cell>0.928</cell><cell>0.907</cell><cell>0.936</cell><cell>0.935</cell></row><row><cell>2</cell><cell>weerasinghe20</cell><cell>large</cell><cell>0.953</cell><cell>0.880</cell><cell>0.882</cell><cell>0.891</cell><cell>0.902</cell></row><row><cell>3</cell><cell>boenninghoff20</cell><cell>small</cell><cell>0.940</cell><cell>0.889</cell><cell>0.853</cell><cell>0.906</cell><cell>0.897</cell></row><row><cell>4</cell><cell>weerasinghe20</cell><cell>small</cell><cell>0.939</cell><cell>0.833</cell><cell>0.817</cell><cell>0.860</cell><cell>0.862</cell></row><row><cell>5</cell><cell>halvani20b</cell><cell>small</cell><cell>0.878</cell><cell>0.796</cell><cell>0.819</cell><cell>0.807</cell><cell>0.825</cell></row><row><cell>6</cell><cell>kipnis20</cell><cell>small</cell><cell>0.866</cell><cell>0.801</cell><cell>0.815</cell><cell>0.809</cell><cell>0.823</cell></row><row><cell>7</cell><cell>araujo20</cell><cell>small</cell><cell>0.874</cell><cell>0.770</cell><cell>0.762</cell><cell>0.811</cell><cell>0.804</cell></row><row><cell>8</cell><cell>niven20</cell><cell>small</cell><cell>0.795</cell><cell>0.786</cell><cell>0.842</cell><cell>0.778</cell><cell>0.800</cell></row><row><cell>9</cell><cell>gagala20</cell><cell>small</cell><cell>0.786</cell><cell>0.786</cell><cell>0.809</cell><cell>0.800</cell><cell>0.796</cell></row><row><cell>10</cell><cell>araujo20</cell><cell>large</cell><cell>0.859</cell><cell>0.751</cell><cell>0.745</cell><cell>0.800</cell><cell>0.789</cell></row><row><cell>11</cell><cell>baseline (naive)</cell><cell>small</cell><cell>0.780</cell><cell>0.723</cell><cell>0.716</cell><cell>0.767</cell><cell>0.747</cell></row><row><cell cols="2">12 baseline (compression)</cell><cell>small</cell><cell>0.778</cell><cell>0.719</cell><cell>0.703</cell><cell>0.770</cell><cell>0.742</cell></row><row><cell>13</cell><cell>ordonez20</cell><cell>large</cell><cell>0.696</cell><cell>0.640</cell><cell>0.655</cell><cell>0.748</cell><cell>0.685</cell></row><row><cell>14</cell><cell>faber20</cell><cell>small</cell><cell>0.293</cell><cell>0.331</cell><cell>0.314</cell><cell>0.262</cell><cell>0.300</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The research for the author's work has been funded with a <rs type="grantName">PhD bursary</rs> for years <rs type="grantNumber">2016-2019</rs> by the <rs type="funder">Cusanuswerk Academic Foundation</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_wgYuZ3x">
					<idno type="grant-number">2016-2019</idno>
					<orgName type="grant-name">PhD bursary</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,142.61,578.39,334.13,7.77;7,150.95,589.34,139.86,7.77" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="7,220.18,578.39,253.29,7.77">Grammar-based preprocessing for PPM compression and classification</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">O M</forename><surname>Aljehane</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
		<respStmt>
			<orgName>Bangor University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct coords="7,142.61,600.30,320.84,7.77;7,150.95,611.26,325.28,7.77;7,150.95,622.22,278.50,7.77" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,199.28,611.26,248.55,7.77">The Importance of Suppressing Domain Style in Authorship Analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bischoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Deckers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schliebs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thies</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<idno>CoRR abs/2005.14714</idno>
		<ptr target="https://arxiv.org/abs/2005.14714" />
		<imprint>
			<date type="published" when="2020-05">May 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,633.18,331.61,7.77;7,150.95,644.14,118.05,7.77;7,150.95,655.94,242.09,6.31" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Booth</surname></persName>
		</author>
		<ptr target="https://books.google.de/books?id=yDJKDwAAQBAJ" />
		<title level="m" coord="7,188.33,633.18,285.89,7.77;7,150.95,644.14,62.61,7.77">A Companion to Media Fandom and Fan Studies. Wiley Blackwell companions in cultural studies</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,119.96,298.38,7.77;8,150.95,130.92,193.75,7.77" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,257.46,119.96,183.53,7.77;8,150.95,130.92,125.49,7.77">A compression algorithm for dna sequences and its applications in genome comparison</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kwong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="52" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,141.88,297.01,7.77;8,150.95,152.84,257.50,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,295.81,141.88,127.06,7.77">Unbounded length contexts for ppm</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Cleary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Teahan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,150.95,152.84,189.28,7.77">Proceedings DCC &apos;95 Data Compression Conference</title>
		<meeting>DCC &apos;95 Data Compression Conference</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="52" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,163.80,227.37,7.77;8,150.95,174.76,214.94,7.77" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gagala</surname></persName>
		</author>
		<ptr target="https://github.com/Lukasz-G/PAN2020" />
		<title level="m" coord="8,193.23,163.80,173.41,7.77">Code for PAN 2020 Authorship Verification task</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,185.71,336.28,7.77;8,150.95,196.67,327.19,7.77;8,150.95,207.63,302.89,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,273.22,185.71,205.67,7.77;8,150.95,196.67,50.74,7.77">Authorship verification in the absence of explicit features and thresholds</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Halvani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Graner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,433.80,196.67,44.35,7.77;8,150.95,207.63,76.27,7.77">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Pasi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Piwowarski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="454" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,218.59,337.98,7.77;8,150.95,229.55,291.00,7.77;8,150.95,240.51,328.20,7.77;8,150.95,251.47,258.38,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,279.17,218.59,201.42,7.77;8,150.95,229.55,39.65,7.77">On the usefulness of compression models for authorship verification</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Halvani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Graner</surname></persName>
		</author>
		<idno type="DOI">10.1145/3098954.3104050</idno>
		<ptr target="https://doi.org/10.1145/3098954.3104050" />
	</analytic>
	<monogr>
		<title level="m" coord="8,208.35,229.55,233.61,7.77;8,150.95,240.51,124.89,7.77">Proceedings of the 12th International Conference on Availability, Reliability and Security. ARES &apos;17</title>
		<meeting>the 12th International Conference on Availability, Reliability and Security. ARES &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,262.43,335.77,7.77;8,150.95,274.23,215.19,6.31" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hellekson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Busse</surname></persName>
		</author>
		<ptr target="http://www.jstor.org/stable/j.ctt20p58d6" />
		<title level="m" coord="8,244.34,262.43,111.30,7.77">The Fan Fiction Studies Reader</title>
		<imprint>
			<publisher>University of Iowa Press</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,284.34,323.52,7.77;8,150.95,295.30,293.87,7.77;8,150.95,306.26,327.38,7.77;8,150.95,317.22,315.52,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,321.31,284.34,128.30,7.77">Towards parameter-free data mining</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lonardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">A</forename><surname>Ratanamahatana</surname></persName>
		</author>
		<idno type="DOI">10.1145/1014052.1014077</idno>
		<ptr target="https://doi.org/10.1145/1014052.1014077" />
	</analytic>
	<monogr>
		<title level="m" coord="8,150.95,295.30,293.87,7.77;8,150.95,306.26,97.74,7.77;8,299.86,306.26,32.31,7.77">Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="206" to="215" />
		</imprint>
	</monogr>
	<note>KDD &apos;04</note>
</biblStruct>

<biblStruct coords="8,142.24,328.18,334.17,7.77;8,150.95,339.14,329.64,7.77;8,150.95,350.10,316.30,7.77;8,150.95,361.06,206.68,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,234.75,339.14,245.84,7.77;8,150.95,350.10,16.14,7.77">Overview of the Cross-Domain Authorship Verification Task at PAN 2020</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,390.29,350.10,76.96,7.77;8,150.95,361.06,38.13,7.77">CLEF 2020 Labs and Workshops</title>
		<title level="s" coord="8,195.56,361.06,85.63,7.77">Notebook Papers. CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020-09">Sep 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,372.02,320.22,7.77;8,150.95,382.97,306.92,7.77;8,150.95,393.93,327.16,7.77;8,150.95,404.89,318.20,7.77;8,150.95,415.85,151.29,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,199.28,382.97,258.59,7.77;8,150.95,393.93,183.40,7.77">Overview of the Author Identification Task at PAN-2018: Cross-domain Authorship Attribution and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,213.35,404.89,255.80,7.77;8,150.95,415.85,72.47,7.77">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum (CLEF 2018)</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018-09">Sep 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,426.81,317.48,7.77;8,150.95,437.77,327.34,7.77;8,150.95,449.57,306.65,6.31" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,237.17,426.81,219.02,7.77">Determining if two documents are written by the same author</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Winter</surname></persName>
		</author>
		<idno type="DOI">10.1002/asi.22954</idno>
		<ptr target="https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.22954" />
	</analytic>
	<monogr>
		<title level="j" coord="8,150.95,437.77,241.42,7.77">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="178" to="187" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,459.69,319.30,7.77;8,150.95,470.65,210.72,7.77" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="8,226.01,459.69,231.83,7.77">An Introduction to Kolmogorov Complexity and Its Applications</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">M</forename><surname>Vitnyi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer Publishing Company, Incorporated</publisher>
		</imprint>
	</monogr>
	<note>3 edn.</note>
</biblStruct>

<biblStruct coords="8,142.24,481.60,328.04,7.77;8,150.95,492.56,105.33,7.77" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="8,239.87,481.60,113.91,7.77">Handbook of Data Compression</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Salomon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Motta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer Publishing Company, Incorporated</publisher>
		</imprint>
	</monogr>
	<note>5th edn.</note>
</biblStruct>

<biblStruct coords="8,142.24,503.52,334.17,7.77;8,150.95,514.48,136.83,7.77" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="8,240.43,503.52,235.98,7.77;8,150.95,514.48,46.66,7.77">Compression and machine learning: A new perspective on feature space vectors</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Brodley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006-04">04 2006</date>
			<biblScope unit="page" from="332" to="341" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
