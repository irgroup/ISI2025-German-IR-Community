<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,179.33,179.91,236.79,12.22;1,216.56,202.78,162.32,10.54">Profiling Fake News Spreaders on Twitter Notebook for PAN at CLEF 2020</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,242.31,245.33,57.17,8.85"><forename type="first">Catherine</forename><surname>Ikae</surname></persName>
							<email>catherine.ikae@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,305.90,245.33,58.63,8.85"><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
							<email>jacques.savoy@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,179.33,179.91,236.79,12.22;1,216.56,202.78,162.32,10.54">Profiling Fake News Spreaders on Twitter Notebook for PAN at CLEF 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5C15B4AD9BF9F515EE9014F57CFBDFAE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In our participation of the "Profiling Fake News Spreaders on Twitter" task (both in English and Spanish), our main objective is to be able to detect Twitter user accounts used to spread disinformation, fake news, as well as conspiracy theories. To automatically solve these questions based only on the tweets' contents, we suggest to reduce the number of features (isolated words) to a few hundred. This suggested approach is based on a two-stage method ignoring infrequent terms and ranking the others according to their occurrence differences between the two categories. Finally, a classifier is implemented combining decision tree, random forest, and boosting. Our first evaluation experiments indicate an overall accuracy around 70%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1 Introduction 1   Since 2013, CLEF-PAN has been generating test collections on author profiling with datasets extracted from social networks (e.g., blogs, tweets) <ref type="bibr" coords="1,365.91,490.13,10.64,8.85" target="#b0">[1]</ref>. During the last years, UniNE has participated in these text categorization tasks to identify some of the author's demographics (e.g., gender, age range, psychological traits, geographical origin) or to know if a set of tweets was created by bots or humans.</p><p>For this year, the participants need to implement a system identifying whether or not a set of 100 tweets was sent by a user spreading fake news (or junk news, pseudo-news, hoaxes, or in general disinformation). More precisely, the target task could be rephrased as knowing whether a set of tweets contains fake news (or misleading content). In fact, the available information is just the tweet contents, and the tweet context (e.g., number of likes, retweets, etc.) with the author source details (e.g., information about the Twitter account) not provided. Moreover, the multimedia elements are not included.</p><p>The first step to solve this question is to define precisely what we mean by fake news. This is not an easy task, mainly because different variants of fake news can be encountered <ref type="bibr" coords="2,178.09,173.09,10.64,8.85" target="#b1">[2]</ref>. For example, satire or parody with its irony and sarcasm could represent the less harmful form of fake news (e.g., Ig (ignoble) Nobel Prize). For others, humor cannot be viewed as fake news because it is evident that the underlying information is not true. At a higher level, one can see a sentence extracted from its context (or embraced in the wrong context) while in its most sophisticated form the news is entirely fabricated (with additional multimedia elements).</p><p>Usually fake news <ref type="bibr" coords="2,212.35,243.89,11.69,8.85" target="#b2">[3]</ref> is rendered as normal customer reviews, political or financial news as well as advertising but with the objective to favor or undermine the image of a product or the reputation of a candidate. Their presence could be limited to a few seconds (e.g., flash ads), to the period of an electoral or advertising campaign, or can even stay visible longer (to support a conspiracy theory, even an extreme one such as "Hitler is alive on a Nazi moon base" <ref type="bibr" coords="2,276.97,301.49,10.51,8.85" target="#b3">[4]</ref>).</p><p>The identification of fake news is still a complex problem. One can take account of four main sources of evidence, namely a) the news content, b) the news creator or spreader, c) the post or social context, d) the target audience (e.g., users or news platforms).</p><p>The content of fake information tends to present more emotional words, usually to evoke anger and fear in the readers <ref type="bibr" coords="2,269.76,374.45,10.64,8.85" target="#b4">[5]</ref>. They employ more negative forms (e.g., not, never), usually with more uppercase letters or words, more spelling errors, more specific punctuation symbols (e.g., !, ?, as well as !!!), hashtags, mentions or hyperlinks. According to Pennebaker's studies <ref type="bibr" coords="2,265.37,409.01,10.64,8.85" target="#b5">[6]</ref>, lying writers tend to use less Self words (I, me, my, mine), but more nouns, and some discrepancy verbs (would, should, could, ought). When telling the truth, the sentences are longer and more complex, containing more numbers, more details and more longer words.</p><p>The author's name and the URL of the source could also be pertinent during the identification. The user credibility could be estimated by his geolocation, the fact that the account was verified or not, or by the presence of weird tokens in the URL (as well as uncommon domains). Usually, creators of fake news (humans, bots or cyborgs) will send many posts during a short time interval. They also tend to have more friends and followers, and reply more often.</p><p>The social or post context can also provide some information indicating a fake news spreader such as a larger number of likes, a high intensity of retweets and more shares and comments than one would expect from a normal user. When monitoring the temporal activity, some patterns can identify a bot or cyborg activity.</p><p>The spreading of fake news presents several advantages for the sender. When receiving the same fake news many times (echo chamber effect) and particularly when received by friends, the misinformation is finally accepted as true. For example, analyzing Trump's tweets, the probability to see the word fake (of faker) just before (or after) CNN is high (more precisely, one can count 266 occurrences of CNN in which 88 times the term fake news appears in the short context). The same observation is valid for the New York Times or the Washington Post. After repeating this misinformation, only 9% of Republicans consider the New York Times as trustworthy <ref type="bibr" coords="2,124.80,667.97,10.64,8.85" target="#b6">[7]</ref>. Therefore, it is not surprising to observe that Conservatives tend to share fake news more often than Democrats and older persons <ref type="bibr" coords="2,327.61,679.49,10.64,8.85" target="#b7">[8]</ref>. And this trend continues to undermine US politics. Now accepting (or spreading) conspiracy theories could be considered mandatory for a Republican candidate to win a primary election for the Congress or the Senate <ref type="bibr" coords="3,219.22,173.09,10.64,8.85" target="#b8">[9]</ref>.</p><p>The rest of this paper is organized as follows. Section 2 describes the text datasets while Section 3 describes our feature selection procedure. Section 4 exposes our classifier and shows some of our evaluation results. A conclusion draws the main findings of our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Corpus</head><p>When limited to spreading action, one can focus only on the tweet contents. In our point of view, the problem is therefore to identify a set of tweets containing disinformation, leading to consider that the user generates and/or spreads fake news <ref type="bibr" coords="3,124.80,318.77,15.34,8.85" target="#b9">[10]</ref>, <ref type="bibr" coords="3,143.97,318.77,15.34,8.85" target="#b10">[11]</ref>. This task will be performed both in English and Spanish.</p><p>When faced with a new dataset, a first analysis extracts an overall picture of the data, the relationship, and detects and explores some simple patterns related to the different categories. In the current study, two categories are provided (Category = 0 or 1), without further information about the precise meaning of the two values. When observing some examples of tweets reported in Tables 1, one can assume that Category = 1 means fake news.  As one can see in Tables 1, tweets in Category #0 describe facts without expressing many emotions. In tweets appearing under the second label, the terms belong to swear expressions (e.g., shyster rats) or tend to cause fear (or anger) (e.g., invasion, destroy).</p><p>The available tweets are included in a training corpus available in English and Spanish. As depicted in Table <ref type="table" coords="3,260.54,670.85,3.76,8.85" target="#tab_1">2</ref>, the training data contains the same number of documents in the two categories and in the two languages.</p><p>As each document corresponds to 100 tweets, the mean number of tokens (composed only by letters) per document is around 1,260 for the English language. For the Spanish language, the mean length is around 1,508, with a significant difference between the two categories (Category #0: 1,655; Category #1: 1,361).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>English Spanish</head><p>Cat. #0 Cat. #1 As shown in Table <ref type="table" coords="4,219.07,306.05,3.76,8.85" target="#tab_1">2</ref>, one can observe that the number of hashtags is larger in Category #0 than in the second one with a difference between them close to 20%. In addition, the number of URLs (hyperlinks) is higher in Category #1 than in Category #0. For the English language, the difference is small, but clearly larger for the Spanish corpus.</p><p>As text categorization problems are known for having a large and sparse feature set <ref type="bibr" coords="4,124.80,377.09,15.34,8.85" target="#b11">[12]</ref>, Table 2 also indicates the number of distinct terms per category (or the vocabulary size denoted under the label |Voc|) which is 20,509 for the English Category #0. Fusing the two categories, the English corpus counts 29,521 distinct words (or 40,867 wordtypes for the Spanish collection).</p><p>For both languages, the vocabulary size is larger for Category #0 than for Category #1 (English: 20,509 vs. 19,851; Spanish: 29,137 vs. 24,825). The texts sent when spreading fake news are composed with a smaller lexis implying that the same or similar expressions are often repeated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Feature Selection</head><p>To achieve a good understanding of the distinction between normal tweets and tweets containing fake news, a feature selection function must be applied. As a simple strategy, the term frequency (tf) or the document frequency (df) have been suggested, under the assumption that a higher frequency could indicate a more useful feature. Both functions return similar results and have been shown to be effective approaches for solving the authorship attribution problem <ref type="bibr" coords="4,295.35,580.37,15.34,8.85">[13]</ref>. For example, the Delta method <ref type="bibr" coords="4,444.98,580.37,16.69,8.85" target="#b14">[14]</ref> is based on the 50 to 200 most frequent words to determine the true author of a text. Identifying disinformation (lies) and authorship identification are however not the same question.</p><p>Moreover, when considering the most frequent words employed, very similar sets of terms appear in both categories (e.g., "URL", "HASHTAG", "the", "to", and some punctuations symbols (' , : ...)). Thus, a simple feature selection based on the tf information is not fully effective and the distinction between features associated with each category is not guaranteed. However, it is always useful to ignore features having a low occurrence frequency. According to the Zipf's law, a large number of word-types appear just once or twice. According to statistics reported in Table <ref type="table" coords="5,286.75,173.09,3.76,8.85" target="#tab_2">3</ref>, when removing words appearing only once, the vocabulary size of the English corpus (Category #0) decreases from 20,509 to 10,474 (a reduction of 48.9%). For the Spanish language (Category #0), the reduction is larger, from 29,137 to 12,882 (a decrease of 55.8%).</p><p>On the other hand, one can encounter terms having a relatively high occurrence frequency but appearing only in a few documents (one document = a set of 100 tweets). Thus, we also suggest to remove terms having a low document frequency (df), for example, with a df &gt; 3. The effect on the vocabulary size is shown in the next to last row of Table <ref type="table" coords="5,181.09,267.17,3.76,8.85" target="#tab_2">3</ref>. For example, for the English corpus (Category #0), the vocabulary decreases from 20,509 to 4,636, showing a reduction of 77.4%. Similar decreases can be observed for the other sub-collections. In this study, we have considered both frequency counts by ignoring terms having a tf &lt; 6 and a df &lt; 4 as indicated in the last row of Table <ref type="table" coords="5,178.95,313.01,3.76,8.85" target="#tab_2">3</ref> After removing infrequent terms, we propose a feature selection method that works in two stages. In the first, the term frequency (tf) information is taken into account. For each term, the discriminative power is computed by estimating the occurrence probability difference in both categories as indicated in Equation <ref type="formula" coords="5,393.36,468.05,3.76,8.85" target="#formula_0">1</ref>. In this case, tfi0 indicates the absolute frequency of the ith term in class c0 (or Category #0), and n0 the text length (in tokens) of all tweets belonging in class c0 (and similarly with class c1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>𝑝𝑟𝑜𝑏𝐷(𝑡</head><formula xml:id="formula_0" coords="5,183.54,507.76,275.98,18.21">! , 𝑐 " ) = 𝑝𝑟𝑜𝑏(𝑡 ! , 𝑐 " ) -𝑝𝑟𝑜𝑏(𝑡 ! , 𝑐 # ) = $% !" &amp; " - $% !# &amp; #<label>(1)</label></formula><p>To determine terms able to describe the Category #0, only terms having a positive probD value are extracted. Of course, one can impose a stricter constraint by selecting terms having a probD larger than a threshold. Similarly, only words with a negative probD value are chosen to represent Category #1. This step generates two term clusters, one per class.</p><p>After this procedure, one can identify some terms more strongly associated to each category. For example, Table <ref type="table" coords="5,248.74,604.13,5.04,8.85" target="#tab_3">4</ref> reports the top fifteen words having the largest value for each language and category (the negative scores for Category #1 have been multiplied by -1). For both languages, tweets containing true information have more hashtags, retweets (rt) and user mentions. Tweets spreading fake news have more URL, "video" meaning that they tend to refer more often to other websites containing supporting information (in the form of text, video, etc.).</p><p>For the English language, the names of political leaders ("trump", "obama", "clinton"), or the adjective "new" are more recurrent in tweets spreading disinformation. This is also an indication that political news is more frequently spread than other domains. It is interesting to see the verb "says" as a feature indicating fake news (e.g., reporting a sentence spoken by a well-known person). Some punctuation symbols (, ... ! : ? or ¿) appear more recurrently in normal tweets than in fake news (e.g., in the sequence RT #USER#:). The comma is more associated with longer sentences, usually indicating a real story <ref type="bibr" coords="6,337.24,232.61,11.69,8.85" target="#b5">[6]</ref> as well as the pronoun I. After this step, one can stop the feature selection by considering the k terms (with k = 100 to 250) having the highest and smallest probD scores. To go further in this space reduction, the second step applies an additional feature selection procedure. In this perspective, previous studies have shown that the chi-square, odds ratio, or mutual information tend to produce effective reduced term sets for different text categorization tasks <ref type="bibr" coords="6,147.11,525.65,15.34,8.85" target="#b11">[12]</ref>, <ref type="bibr" coords="6,168.57,525.65,15.34,8.85">[13]</ref>. In this study, the chi-square method was selected to reduce the feature space to a few hundred terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>To define the different machine learning models, the scikit-learn library (Python) was applied <ref type="bibr" coords="6,212.53,612.77,15.34,8.85" target="#b15">[15]</ref>. The default setting defined in the library was chosen. The decision tree approach was applied to define our first model (with Gini function to measure the node impurity) <ref type="bibr" coords="6,237.41,635.81,15.34,8.85" target="#b16">[16]</ref>. As more complex classifiers, the random forest with 200 trees was applied and the final decision was acquired by majority voting. As another approach belonging to the ensemble learning, the bagging model forms one of our selected approaches. With boosting, represented by our last model, a set of weak learners is combined to produce a more effective assignment. More precisely, we chose the extreme gradient boosting (XGB) <ref type="bibr" coords="7,280.91,150.05,15.34,8.85" target="#b17">[17]</ref>, <ref type="bibr" coords="7,303.42,150.05,16.68,8.85" target="#b18">[18]</ref> based on a set of 100 decision trees (maximum depth was set to 2).</p><p>When computing the decision for a new set of tweets, the three classifiers determine a proposed attribution based on the same set of chosen features. To combine the three resulting decisions, a simple majority vote could be applied, giving the same importance to each of the three individual classifiers. This solution corresponds to a democratic vote.</p><p>However, each classifier returns not only the proposed decision but an estimated probability that the input set of tweets belongs to that category. Thus, our second approach, called soft vote, adds these three probabilities to determine the final assignment (this merging strategy was used in our early bird submission).</p><p>To compute the accuracy rates shown in Tables 5, only the training subset is used to select the feature sets and to generate the document surrogates (the same number of documents appears in both categories and languages). To achieve a fair evaluation, we randomly extracted 50 documents from each category to generate the test set.</p><p>From the results depicted in Tables 5, one can see that after reducing the feature set to a few hundred words one can still achieve a good overall effectiveness. Moreover, having more features does not imply obtaining a higher effectiveness level. For example, using in total only 150 features, our model achieves an accuracy rate of 0.81 (English corpus, majority vote) or 0.78 for the Spanish language (majority vote). Doubling the number of features does not always improve the overall effectiveness (English corpus: 0.81 vs. 0.75, Spanish: 0.788 vs. 0.79). It is interesting to know that even if, in mean, combining different classifiers provides a higher effectiveness, the best solutions for the Spanish corpus are often a single boosting model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,124.80,416.12,322.94,8.01;3,124.80,426.68,56.30,8.01;3,124.80,437.00,325.54,8.01;3,124.80,447.32,169.56,8.01;3,124.80,464.12,220.25,8.01;3,124.80,474.68,255.99,8.01;3,200.37,497.00,194.77,8.01;3,124.80,519.32,319.22,8.01;3,124.80,529.88,337.93,8.01;3,124.80,540.20,335.03,8.01;3,124.80,550.52,160.50,8.01;3,124.80,567.32,280.50,8.01;3,124.80,577.88,269.02,8.01"><head></head><label></label><figDesc>England ease to World Cup win over France #HASHTAG# #HASHTAG# #HASHTAG# #URL# #URL# Spain rescues 276 migrants crossing perilous Mediterranean #HASHTAG# #HASHTAG# #HASHTAG# #HASHTAG# #HASHTAG#… Italy's Uffizi demands return of Nazi-looted painting #URL# Trump invites congressional leaders to border security briefing #URL# Table 1a: Examples of four tweets in the Category #0 #USER# Merkel is using her IMMIGRATION INVASION as a demographic weapon to destroy Germany. #HASHTAG# #HASHTAG# #HASHTAG# #HASHTAG# #HASHTAG# #USER# #USER# Trump is 1/2 Scottish and 1/2 German. Trump will smash the shyster rats. #HASHTAG# #HASHTAG# #HASHTAG# With Obama's Approval, Russia Selling 130 Tons of Uranium to Iran #URL# FBI admits illegal wiretapping of President Trump, issues apology #URL#</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,200.12,600.20,195.28,8.01"><head>Table 1b :</head><label>1b</label><figDesc>Examples of four tweets in the Category #1</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,131.21,211.16,333.28,80.25"><head>Table 2 :</head><label>2</label><figDesc>Overall statistics about the training data in both languages</figDesc><table coords="4,296.69,211.16,163.15,8.94"><row><cell>Test</cell><cell>Cat. #0</cell><cell>Cat. #1</cell><cell>Test</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,171.16,313.01,254.02,105.84"><head>Table 3 :</head><label>3</label><figDesc>. Vocabulary size with different feature selection strategies</figDesc><table coords="5,171.16,330.44,254.02,71.85"><row><cell></cell><cell cols="2">English</cell><cell>Spanish</cell><cell></cell></row><row><cell></cell><cell>Cat. #0</cell><cell>Cat. #1</cell><cell>Cat. #0</cell><cell>Cat. #1</cell></row><row><cell>|Voc|</cell><cell>20,509</cell><cell>19,851</cell><cell>29,137</cell><cell>24,825</cell></row><row><cell>tf &gt; 1</cell><cell>10,474</cell><cell>10,672</cell><cell>12,882</cell><cell>11,514</cell></row><row><cell>tf &gt; 3</cell><cell>5,797</cell><cell>6,184</cell><cell>6,573</cell><cell>6,001</cell></row><row><cell>tf &gt; 5</cell><cell>4,136</cell><cell>4,431</cell><cell>4,463</cell><cell>4,150</cell></row><row><cell>df &gt; 3</cell><cell>4,636</cell><cell>5,247</cell><cell>5,838</cell><cell>5,386</cell></row><row><cell>tf &gt;5 and df &gt; 3</cell><cell>2,433</cell><cell>3,720</cell><cell>3,800</cell><cell>3,590</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,143.48,250.04,306.92,203.37"><head>Table 4 :</head><label>4</label><figDesc>The top fifteen terms having the largest probD values</figDesc><table coords="6,143.48,250.04,306.92,186.57"><row><cell></cell><cell cols="2">English</cell><cell></cell><cell></cell><cell cols="2">Spanish</cell><cell></cell></row><row><cell cols="2">Category #0</cell><cell cols="2">Category #1</cell><cell cols="2">Category #0</cell><cell cols="2">Category #1</cell></row><row><cell>0.0144</cell><cell>USER</cell><cell>0.0054</cell><cell>'</cell><cell>0.0140</cell><cell>USER</cell><cell>0.0232</cell><cell>URL</cell></row><row><cell>0.0080</cell><cell>HASHTAG</cell><cell>0.0041</cell><cell>URL</cell><cell>0.0112</cell><cell>HASHTAG</cell><cell>0.0069</cell><cell>unete</cell></row><row><cell>0.0057</cell><cell>:</cell><cell>0.0037</cell><cell>trump</cell><cell>0.0097</cell><cell>.</cell><cell>0.0066</cell><cell>-</cell></row><row><cell>0.0051</cell><cell>rt</cell><cell>0.0024</cell><cell>-</cell><cell>0.0063</cell><cell>rt</cell><cell>0.0041</cell><cell>video</cell></row><row><cell>0.0043</cell><cell>.</cell><cell>0.0021</cell><cell>s</cell><cell>0.0061</cell><cell>:</cell><cell>0.0028</cell><cell>(</cell></row><row><cell>0.0026</cell><cell>the</cell><cell>0.0016</cell><cell>after</cell><cell>0.0059</cell><cell>,</cell><cell>0.0028</cell><cell>-</cell></row><row><cell>0.0025</cell><cell>,</cell><cell>0.0010</cell><cell>her</cell><cell>0.0036</cell><cell>...</cell><cell>0.0023</cell><cell>)</cell></row><row><cell>0.0017</cell><cell>...</cell><cell>0.0009</cell><cell>to</cell><cell>0.0034</cell><cell>que</cell><cell>0.0013</cell><cell>"</cell></row><row><cell>0.0016</cell><cell>i</cell><cell>0.0009</cell><cell>video</cell><cell>0.0027</cell><cell>no</cell><cell>0.0013</cell><cell>su</cell></row><row><cell>0.0016</cell><cell>this</cell><cell>0.0008</cell><cell>new</cell><cell>0.0015</cell><cell>es</cell><cell>0.0010</cell><cell>el</cell></row><row><cell>0.0016</cell><cell>!</cell><cell>0.0008</cell><cell>donald</cell><cell>0.0015</cell><cell>?</cell><cell>0.0010</cell><cell>vida</cell></row><row><cell>0.0013</cell><cell>and</cell><cell>0.0008</cell><cell>post</cell><cell>0.0014</cell><cell>¿</cell><cell>0.0009</cell><cell>fuerte</cell></row><row><cell>0.0012</cell><cell>your</cell><cell>0.0007</cell><cell>obama</cell><cell>0.0014</cell><cell>las</cell><cell>0.0009</cell><cell>para</cell></row><row><cell>0.0012</cell><cell>a</cell><cell>0.0007</cell><cell>says</cell><cell>0.0011</cell><cell>ha</cell><cell>0.0008</cell><cell>a</cell></row><row><cell>0.0011</cell><cell>read</cell><cell>0.0007</cell><cell>clinton</cell><cell>0.0009</cell><cell>qué</cell><cell>0.0008</cell><cell>tu</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Table <ref type="table" coords="7,161.41,639.65,5.04,8.85">6</ref> reports our official results achieved with the TIRA system <ref type="bibr" coords="7,411.42,639.65,16.69,8.85" target="#b19">[19]</ref> and using the official test subset of the data. Our first results called early bird results have been obtained under the soft vote scheme. They appear in the second row in Table <ref type="table" coords="7,441.96,662.69,3.76,8.85">6</ref>. Our official performance was achieved with the majority scheme depicted in the last row in Table <ref type="table" coords="7,150.06,685.49,3.76,8.85">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TIRA test set Fusion</head><p>English Spanish Soft vote 0.675 0.700 Majority vote 0.725 0.725 In both cases, the infrequent terms have been ignored (tf &gt; 5 and df &gt; 3). Then the top 150 terms having the highest chi-square values have been selected to define the feature set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In our participation to the "Profiling Fake News Spreaders on Twitter" (CLEF PAN 2020) we have worked with tweets written in English and Spanish. Overall, we achieve the following main findings. First, we suggested a feature selection approach able to extract a reduced set of features (precisely 150). Based on such a reduced set, it is possible to identify those features more associated to normal tweets (e.g., I, this, film, review, episode, etc.). In addition, the conjunction and and the comma appears more often in normal posts, indicating the presence of longer sentences. In tweets spreading fake news, one can count more names of political leaders, as well as the terms says, post, president, she, he, democrat, etc. This is an indication of the presence of posts reporting opinions and words uttered by other persons.</p><p>Second, our analysis indicates that tweets containing fake news tend to include more references (URL) (see Table <ref type="table" coords="8,241.44,454.85,4.18,8.85">2</ref>) to other webpages than normal tweets, references used to support the misinformation or to justify some conspiracy theory. On the other hand, normal tweets present more retweets and hashtags as shown in Table <ref type="table" coords="8,402.77,477.89,3.76,8.85">2</ref>.</p><p>Third, our attribution approach is based on a model combining three individual attributions computed by a decision tree, a boosting, and a random forest classifier. It was a surprise to see that a simple majority scheme achieved a higher accuracy rate than a merging approach based on the probability estimates computed by each individual classifier.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="8,138.60,613.64,332.16,8.01;8,136.15,623.96,334.25,8.01" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,360.19,613.64,110.57,8.01;8,136.15,623.96,106.71,8.01">A Decade of Shared Tasks in Digital Text Forensics at PAN</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,252.39,623.96,67.31,8.01">Proceedings ECIR</title>
		<title level="s" coord="8,344.37,623.96,63.05,8.01">Springer LNCS #</title>
		<meeting>ECIR</meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="volume">11437</biblScope>
			<biblScope unit="page" from="291" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,139.08,637.40,331.63,8.01;8,136.15,647.72,204.95,8.01" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,217.44,637.40,110.22,8.01">Fake News. It&apos;s Complicated</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wardle</surname></persName>
		</author>
		<ptr target="https://firstdraftnews.org/latest/fake-news-complicated/" />
		<imprint>
			<date type="published" when="2017-02-16">2017. February, 16</date>
		</imprint>
	</monogr>
	<note>First Draft</note>
</biblStruct>

<biblStruct coords="8,137.72,661.16,332.98,8.01;8,136.15,671.48,302.51,8.01" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,275.48,661.16,195.22,8.01;8,136.15,671.48,92.73,8.01">An Overview of Online Fake News: Characterization, Detection, and Discussion</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A</forename><surname>Ghorbani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,237.13,671.48,141.53,8.01">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">102025</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,137.54,684.92,322.87,8.01" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,215.29,684.92,138.67,8.01">Hitler isn&apos;t Alive on a Nazi Moon Base</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Selk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,362.38,684.92,59.85,8.01">Washington Post</title>
		<imprint>
			<date type="published" when="1920">2018. May, 20</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,139.22,149.72,331.47,8.01;9,136.15,160.04,61.53,8.01" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">P</forename><surname>Hart</surname></persName>
		</author>
		<title level="m" coord="9,214.94,149.72,204.42,8.01">Trump and Us. What he Says and Why People Listen</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,137.54,173.48,313.98,8.01" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<title level="m" coord="9,233.52,173.48,99.13,8.01">The Secret Life of Pronouns</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Bloomsbury Press</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,137.50,186.92,333.12,8.01;9,136.15,197.24,334.53,8.01;9,136.15,207.56,98.54,8.01" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,216.79,186.92,219.30,8.01">Going Public in the Age of Twitter and Mistrust of the Media</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">L</forename><surname>Francia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,271.04,197.24,195.23,8.01">The Internet and the 2016 Presidential Campaign</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Baumgartnet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Towned</surname></persName>
		</editor>
		<meeting><address><addrLine>Lanham</addrLine></address></meeting>
		<imprint>
			<publisher>Lexington Books</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,137.66,221.00,333.06,8.01;9,136.15,231.32,277.45,8.01" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,295.66,221.00,175.06,8.01;9,136.15,231.32,150.87,8.01">Less than you Think: Prevalence and Predictors of Fake News Dissemination on Facebook</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Guess</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nagler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,295.62,231.32,65.91,8.01">Sciences Avdances</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">4586</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,140.69,244.52,329.97,8.01;9,136.15,254.84,105.01,8.01" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,224.54,244.52,242.45,8.01">Why QAnon Supporters are Winning Congressional Primaries</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Philips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,136.15,254.84,59.85,8.01">Washington Post</title>
		<imprint>
			<date type="published" when="2020-06-13">2020. June, 13th</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.58,268.28,328.13,8.01;9,136.15,278.60,334.54,8.01;9,136.15,288.92,124.77,8.01" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,368.51,268.28,102.20,8.01;9,136.15,278.60,262.20,8.01">Overview of the 8th Author Profiling Task at PAN 2020: Profiling Fake News Spreaders on Twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,407.53,278.60,63.16,8.01;9,136.15,288.92,53.81,8.01">CLEF 2020 Labs and Workshops</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Notebook Papers</note>
</biblStruct>

<biblStruct coords="9,142.20,302.36,328.52,8.01;9,136.15,312.68,331.97,8.01" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,309.12,302.36,161.60,8.01;9,136.15,312.68,124.58,8.01">An Emotional Analysis of False Information in Social Media and News Articles</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,266.37,312.68,152.74,8.01">ACM Transactions on Internet Technology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,145.11,326.12,325.64,8.01;9,136.15,336.44,115.51,8.01" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,233.79,326.12,203.62,8.01">Machine Learning in Automatic Text Categorization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,451.65,326.12,19.09,8.01;9,136.15,336.44,65.19,8.01">ACM Computing Survey</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.66,349.64,328.01,8.01;9,136.15,359.96,215.25,8.01" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,219.39,349.64,251.29,8.01;9,136.15,359.96,46.43,8.01">An Extensive Empirical Study of Feature Selection Metrics for Text classification</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Forman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,190.38,359.96,104.59,8.01">Journal of Machine Learning</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1289" to="1305" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,143.59,373.40,327.18,8.01;9,136.15,383.72,246.02,8.01" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,211.70,373.40,259.07,8.01;9,136.15,383.72,38.79,8.01">Comparative Evaluation of Term Selection Functions for Authorship Attribution</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,182.90,383.72,135.30,8.01">Digital Scholarship in the Humanities</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="246" to="261" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,143.40,397.16,327.37,8.01;9,136.15,407.48,228.78,8.01" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,230.29,397.16,240.47,8.01;9,136.15,407.48,38.91,8.01">Delta: A Measure of Stylistic Difference and a Guide to Likely Authorship</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Burrows</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,183.40,407.48,117.31,8.01">Literary &amp; Linguistic Computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="267" to="287" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.69,420.92,327.98,8.01;9,136.15,431.24,334.58,8.01;9,136.15,441.56,334.52,8.01;9,136.15,451.88,198.74,8.01" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,287.31,441.56,147.35,8.01">Scikit-learn: Machine Learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Venderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Courapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Duchernay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,442.65,441.56,28.02,8.01;9,136.15,451.88,110.03,8.01">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.43,465.32,328.29,8.01;9,136.15,475.64,103.76,8.01" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="9,361.88,465.32,108.83,8.01;9,136.15,475.64,18.57,8.01">Classification and Regression Trees</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Olshen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Stone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<pubPlace>Wadsworth, Belmont</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.64,488.84,328.04,8.01;9,136.15,499.16,42.26,8.01" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="9,280.31,488.84,143.08,8.01">Boosting. Foundations and Algorithms</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Shapire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.19,512.60,328.50,8.01;9,136.15,522.92,65.77,8.01" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="9,258.46,512.60,125.82,8.01">Computer Age Statistical Inference</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,143.77,536.36,326.95,8.01;9,136.15,546.68,334.62,8.01;9,136.15,557.00,246.02,8.01" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="9,372.24,536.36,98.48,8.01;9,136.15,546.68,43.63,8.01">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,294.20,546.68,176.57,8.01;9,136.15,557.00,176.44,8.01">Information Retrieval Evaluation in a Changing World -Lessons Learned from 20 Years of CLEF</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
