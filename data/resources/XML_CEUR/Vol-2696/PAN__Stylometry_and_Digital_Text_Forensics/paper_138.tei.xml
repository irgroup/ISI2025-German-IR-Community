<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,169.36,115.96,276.65,12.62;1,159.69,133.89,295.97,12.62;1,280.40,151.82,54.56,12.62">Approaches to the Profiling Fake News Spreaders on Twitter Task in English and Spanish</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,174.22,189.49,107.27,8.74"><forename type="first">Jacobo</forename><surname>López Fernández</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universitat Politècnica de València</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,308.64,189.49,128.02,8.74"><forename type="first">Juan</forename><surname>Antonio López Ramírez</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universitat Politècnica de València</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,169.36,115.96,276.65,12.62;1,159.69,133.89,295.97,12.62;1,280.40,151.82,54.56,12.62">Approaches to the Profiling Fake News Spreaders on Twitter Task in English and Spanish</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B468FBA60EA8CF43D30D6D545A7CD030</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>author profiling</term>
					<term>fake news</term>
					<term>multilingual</term>
					<term>social media</term>
					<term>spreaders</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper discusses the decisions made approaching PANs Profiling Fake News Spreaders on Twitter Task at CLEF 2020. We briefly describe how we combined author tweets to create samples that do or do not represent a Fake News Spreader. We decided to handle both languages proposed for this task: Spanish and English; and the methodologies that we suggested were Linear Support Vector Machines (SVMs) and Gradient Boosting, respectively. Other approaches such as Long Short-Term Memory (LSTM) were taken into account in the process of finding a model with the best accuracy results and these were also reported in this paper. We made use of the cross-validation scenario to obtain accuracy results due to the reduced amount of data. We have managed to achieve average accuracy scores of 0.735 for the Spanish language identification task and 0.685 for the English language identification task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The trust in information read through social media has steadily increased in the last few years. However, allow their accounts to publish and propagate misinformation with severe consequences for our society. First of all, we should make it clear that there are different types of misinformation and disinformation, such as fake news, satire or rumours that go viral in online social networks <ref type="bibr" coords="1,453.93,531.45,9.96,8.74" target="#b4">[5]</ref>. In addition, psycho-linguistic information as emotion, sentiment or informal language should be previously analised. Exploiting information extracted from user profiles and user interactions, we should be able to classify them depending on the information obtained.</p><p>A great amount of fake news and rumors are propagated in online social networks with the aim, usually, to deceive users and formulate specific opinions <ref type="bibr" coords="1,134.77,615.13,14.61,8.74" target="#b14">[15]</ref>. Users play a critical role in the creation and propagation of fake news online by consuming and sharing articles with inaccurate information either intentionally or unintentionally.</p><p>To prevent dissemination of misinformation and disinformation we may profile fake news spreaders automatically. Author profiling is based on the detection of certain characteristics in profiles making use of linguistic pattern recognition techniques.</p><p>This paper discusses the decisions made approaching PANs' Profiling Fake News Spreaders on Twitter Task at CLEF 2020 <ref type="bibr" coords="2,344.51,202.68,14.61,8.74" target="#b10">[11]</ref>. The task consists in, given a Twitter feed, determine whether its author is keen to be a fake news spreader. So, it focuses on identifying possible fake news spreaders on social media as a first step towards preventing fake news from being propagated among online users. The task has a multilingual perspective, so that includes tweets in English and Spanish. It is defined as a binary classification task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Fake news detection has attracted a lot of research attention in the last years. Guess et al. <ref type="bibr" coords="2,192.63,325.05,10.52,8.74" target="#b6">[7]</ref> made an approach to this field by doing research during the elections, in particular the 2016 US election procedure. In that paper, they propose a system that obtained features from polls published on Facebook. Popat et al. <ref type="bibr" coords="2,159.01,360.92,10.52,8.74" target="#b8">[9]</ref> suggested an end-to-end model to evaluate trust on random texts, without human supervision. Subsequently, they presented a biLSTM neural network model which aggregates signals from external evidence articles, the language of these articles and the trustworthiness of their sources.</p><p>Shu et al. <ref type="bibr" coords="2,194.99,408.74,15.50,8.74" target="#b13">[14]</ref> pointed that fake news spreaders cannot be profiled precisely based only on text content, but we should understand the correlation between user profiles on social media and fake news. They state that social engagements should be used as auxiliary information to improve fake news detection systems. In addition, Sliva et al. <ref type="bibr" coords="2,235.71,456.56,14.61,8.74" target="#b12">[13]</ref>, distinguished that, approaching content from a data mining perspective, we could identify patterns that could mark a text as fake. These patterns, such as clearness which make the text more readable and could convince the receiver even when it is fake. Collecting this kind of information produces a huge, unestructured, incomplete and noisy data; difficult and expensive to manage. Giachanou et al. <ref type="bibr" coords="2,301.47,516.33,10.52,8.74" target="#b5">[6]</ref> proposed EmoCred that incorporates emotions that are expressed in the claims into an LSTM network to differentiate between fake and real claims.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Fake News Spreaders Detection Systems</head><p>First, we apply the same type of preprocessing for both, the English and Spanish tasks data, following the next steps:</p><p>-Load tweets from XML files.</p><p>-Concatenate tweets forming a chain for every author. All tweets in this chain are separated by a blank space. We apply this technique on the English dataset and the Spanish dataset.</p><p>With the concatenated data, we vectorized our samples. The vectorizers used to perform this task were CountVectorizer and TfidfVectorizer <ref type="bibr" coords="3,413.15,130.95,14.61,8.74" target="#b11">[12]</ref>. CountVectorizer creates valuable data from counting words in samples while TfidfVectorizer takes into consideration more common words in detriment of those which are less common.</p><p>Concurrently, the tokenizer selected was casual tokenize, an implementation of TweetTokenizer from NLTK, due to its suitability to manage characters and expressions commonly used on the Twitter social network.</p><p>After all these transformations, we ended up getting a feature matrix for each of the languages proposed, English and Spanish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">First approaches</head><p>The first method applied to classify our samples employed Recurrent Neural Networks (RNN), making use of pretrained word embeddings in order to help representing words as real-valued vectors and lead to better performance of our neural network system.</p><p>For the Spanish language task, the embeddings loaded by our system were the Spanish Billion Words Corpus and Embeddings <ref type="bibr" coords="3,341.16,342.42,10.52,8.74" target="#b0">[1]</ref> which had been trained using word2vec and consists of near 1 million words where each of them is represented as a vector with a size of 300.</p><p>For the English language task, the embeddings loaded by our system had been trained using GloVe from Stanford <ref type="bibr" coords="3,311.44,390.72,10.52,8.74" target="#b7">[8]</ref> and collected by Laurence Moroney, composed of near 6000 billion words where each of them is represented as a vector with a size of 100.</p><p>Once the embeddings were loaded, we trained our RNN model with LSTM and the following topology: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Final systems</head><p>Despite the fact that the results obtained making use of RNN were close to those reported in the state of the art for this kind of tasks, we did not reach promising results as we will explain later in this paper. At that point, we made use of classifiers provided by the framework scikit-learn and chose the Gradient Boosting algorithm and the linear SVM algorithm for the English and Spanish tasks, respectively.</p><p>The main core of Gradient Boosting <ref type="bibr" coords="4,310.76,211.57,10.51,8.74" target="#b3">[4]</ref> consists of a predictive model based on decision trees, built step-by-step allowing the optimization of a differentiable loss function. For this function we made use of linear regression or 'sigmoid', called 'deviance' in the scikit-learn framework, whose mathematical expression is represented as the following:</p><formula xml:id="formula_0" coords="4,274.10,279.37,206.49,22.31">σ(z) = 1 1 + e -z<label>(1)</label></formula><p>We also experimented using the AdaBoost <ref type="bibr" coords="4,338.82,308.83,10.52,8.74" target="#b2">[3]</ref> algorithm along with the loss function, called 'exponential' in the scikit-learn framework. This algorithm focuses on classification problems and aims to convert a set of weak classifiers into a strong one. The final equation for classification can be represented as:</p><formula xml:id="formula_1" coords="4,248.48,366.06,232.12,30.20">F (x) = sign( M m=1 θ m f m (x))<label>(2)</label></formula><p>where f m stands for the m th weak classifier and θ m is the corresponding weight. It is exactly the weighted combination of M weak classifiers. The function which gives the weight for the m th weak classifier is the following:</p><formula xml:id="formula_2" coords="4,267.20,447.50,209.15,23.23">θ m = 1 2 ln( 1 -m m ) (<label>3</label></formula><formula xml:id="formula_3" coords="4,476.34,454.24,4.24,8.74">)</formula><p>where m is the lowest weighted classification error.</p><p>From another point of view, the main core of SVM <ref type="bibr" coords="4,368.36,489.18,10.52,8.74" target="#b1">[2]</ref> is based on the concept of separating a group of points (samples) into two different categories. As a consequence, our model had to be able to classify the sample correctly into its category. SVM looks for a hyperplane which optimally separates the points belonging the two classes. Subsequently, we look for the hyperplane with the longest distance (margin) to the closest points to it.</p><p>The equation of the hyperplane in the 'M' dimension can be given as:</p><formula xml:id="formula_4" coords="4,272.43,582.43,208.16,30.32">y = b + M i=1 w i x i<label>(4)</label></formula><p>where w i are vectors, b is biased term and x i are input variables. Furthermore, given a group of points S = (x 1 , c 1 ), ..., (x N , c N ) and a constant C&gt;0, we should obtain weights θ ∈ d , θ 0 ∈ and the tolerance parameter ς ∈ N to minimize the following expression:</p><formula xml:id="formula_5" coords="5,274.79,128.21,205.80,30.20">1 2 θ t θ + C N n=1 ς n<label>(5)</label></formula><p>Dependant of the following two expressions:</p><formula xml:id="formula_6" coords="5,233.22,188.10,247.37,11.72">c n (θ t x n + θ 0 ) ≥ 1 -ς n , 1 ≤ n ≤ N<label>(6)</label></formula><formula xml:id="formula_7" coords="5,268.50,221.03,212.09,9.65">ς n ≥ 0, 1 ≤ n ≤ N<label>(7)</label></formula><p>At last, the loss function employed was the hinge function, represented as:</p><formula xml:id="formula_8" coords="5,256.12,263.99,220.22,8.74">L(y) = max(0, 1 -t • y) (<label>8</label></formula><formula xml:id="formula_9" coords="5,476.34,263.99,4.24,8.74">)</formula><p>where y is the prediction and t is the intended output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>In this section we discuss about the dataset provided and the experimental adjustments we made.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>The given dataset is composed of two folders, a folder for the Spanish language and a folder for the English language, which contain:</p><p>-A XML file by author or Twitter user profile. There are 100 tweets in each XML file.</p><p>-A text file with the list of authors and the ground truth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Settings</head><p>The submission of our system was made from the TIRA platform <ref type="bibr" coords="5,445.64,512.66,14.61,8.74" target="#b9">[10]</ref>. As the participants were only provided with the training data, we applied crossvalidation into 10 folds in order to test our system. Different classifiers were tested such as Support Vector Machine, Gaussian Naive-Bayes, Gradient Boosting, Stochastic Gradient Descent, K-nearest Neigbours and two Neural Network approaches (Multilayer Perceptron and Convolutional Recurrent Neural Networks with LSTM). Regarding the English task we obtained the best results with a Gradient Boosting model and regarding the Spanish task we obtained the best results with a linear SVM model. Concerning SVM, we set the penalty parameter 'C' to 100 and the tolerance parameter to 0.01, with the maximum number of stages set to 100. In our SVM implementation we operated with the hinge loss function whereas in our Gradient Boosting implementation we operated with the deviance function. Learning rate was set to 0.01 for Gradient Boosting and the number of boosting stages to perform was 250. To implement our system we made use of the scikit-learn framework <ref type="foot" coords="6,372.82,129.37,3.97,6.12" target="#foot_0">1</ref> .</p><p>For the Spanish language task we used a language model based on bigrams and trigrams where punctuation marks are processed and a vocabulary is built considering the top 1000 features, ordered by frequency from the whole corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Table <ref type="table" coords="6,162.96,229.27,4.98,8.74" target="#tab_0">1</ref> shows the results achieved by our system in the Spanish and English tasks in terms of precision over the training data. As we mentioned earlier in this article, we are using a 10 fold cross-validation where the average precision of the 10 folds gives the final precision result for each classifier. The best results in terms of precision were those given by the linear SVM model for the Spanish language task and the Gradient Boosting model for the English language task. We should mention that the results shown in this table were obtained without modifying any hyperparameter of the two classifiers. Table <ref type="table" coords="6,176.78,491.05,4.98,8.74" target="#tab_1">2</ref> shows the results obtained by modifying parameters with the Gradient Boosting algorithm for the English language. The results display the positive influence that reducing the learning rate to 0.01 and increasing the number of stages to 250 has on the system. As far as we are concerned, alterating the loss function did not report any change in the system results and was left as its default value: logistic regression. We should indicate that hyperparameters were as well adjusted in the linear SVM model for the Spanish language, but the disparity with the original precision results was considered trivial, achieving results close to 0.84.</p><p>Table <ref type="table" coords="6,178.10,599.25,4.98,8.74">3</ref> shows the results achieved by our Fake News Spreaders detection system in English and Spanish in terms of accuracy on the training set in TIRA. We observe that our system performs better for the Spanish tweets compared to English.  <ref type="table" coords="7,166.03,336.41,4.13,7.89">3</ref>. Accuracy scores of our system on the official training set using crossvalidation.</p><p>Table <ref type="table" coords="7,178.10,390.05,4.98,8.74">4</ref> shows the results achieved by our Fake News Spreaders detection system in English and Spanish in terms of accuracy on the official test set. As we observed with the training data, our system performs better for the Spanish tweets compared to English. Accuracy English 0.685 Spanish 0.735 Table <ref type="table" coords="7,209.27,492.81,4.13,7.89">4</ref>. Accuracy scores of our system on the official test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper we described our system for PANs Profiling Fake News Spreaders on Twitter Task at CLEF 2020. Regarding the English language task we proposed a system trained with Gradient Boosting algorithm while for the Spanish language task we proposed a system based on linear SVM. The state of the art tells us that Neural Networks are currently the best solution for this kind of classification tasks, but the results that we achieved do not match with this statement. We can consider that some tasks are not suitable to be addressed with this kind of systems so far, as we saw with our implementation of Convolutional Recurrent Neural Network with LSTM. Eventually, a traditional machine learning algorithm performed better.</p><p>Our results showed that the input data processing considerably conditions performance in our system. In addition, from our results we can observe that our Spanish language solution performs better compared to our English language solution, as we managed to achieve 0.735 and 0.685 accuracy respectively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,203.50,655.03,208.35,7.89;3,134.77,471.40,345.83,168.85"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Topology of convolutional RNN and LSTM.</figDesc><graphic coords="3,134.77,471.40,345.83,168.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,150.56,347.54,314.24,106.44"><head>Table 1 .</head><label>1</label><figDesc>Accuracy scores obtained from Cross-Validation on the training set.</figDesc><table coords="6,196.72,347.54,221.91,95.53"><row><cell></cell><cell cols="2">Accuracy-English Accuracy-Spanish</cell></row><row><cell>SVM</cell><cell>0.63</cell><cell>0.74</cell></row><row><cell>linear SVM</cell><cell>0.64</cell><cell>0.83</cell></row><row><cell>Naive Bayes</cell><cell>0.64</cell><cell>0.70</cell></row><row><cell>Gradient Boosting</cell><cell>0.71</cell><cell>0.76</cell></row><row><cell>SGD</cell><cell>0.67</cell><cell>0.78</cell></row><row><cell>Nearest Neighbors</cell><cell>0.59</cell><cell>0.74</cell></row><row><cell>MLP</cell><cell>0.65</cell><cell>0.82</cell></row><row><cell>RNN with LSTM</cell><cell>0.60</cell><cell>0.66</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,134.77,117.78,345.83,226.52"><head>Table 2 .</head><label>2</label><figDesc>Accuracy scores obtained by modifying hyperparameters of Gradient Boosting Classifier.</figDesc><table coords="7,134.77,117.78,259.01,226.52"><row><cell>Loss</cell><cell cols="3">Learning rate Stages Accuracy</cell></row><row><cell>deviance</cell><cell>0.1</cell><cell>100</cell><cell>0.71</cell></row><row><cell>deviance</cell><cell>0.1</cell><cell>250</cell><cell>0.71</cell></row><row><cell>deviance</cell><cell>0.01</cell><cell>100</cell><cell>0.70</cell></row><row><cell>deviance</cell><cell>0.01</cell><cell>250</cell><cell>0.73</cell></row><row><cell>deviance</cell><cell>0.001</cell><cell>100</cell><cell>0.65</cell></row><row><cell>deviance</cell><cell>0.001</cell><cell>250</cell><cell>0.68</cell></row><row><cell>exponential</cell><cell>0.1</cell><cell>100</cell><cell>0.72</cell></row><row><cell>exponential</cell><cell>0.1</cell><cell>250</cell><cell>0.71</cell></row><row><cell>exponential</cell><cell>0.01</cell><cell>100</cell><cell>0.70</cell></row><row><cell>exponential</cell><cell>0.01</cell><cell>250</cell><cell>0.73</cell></row><row><cell>exponential</cell><cell>0.001</cell><cell>100</cell><cell>0.65</cell></row><row><cell>exponential</cell><cell>0.001</cell><cell>250</cell><cell>0.68</cell></row><row><cell></cell><cell cols="2">Accuracy</cell><cell></cell></row><row><cell></cell><cell>English</cell><cell>0.98</cell><cell></cell></row><row><cell></cell><cell cols="2">Spanish 0.9967</cell><cell></cell></row><row><cell>Table</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="6,144.73,657.44,113.47,7.47"><p>https://scikit-learn.org</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,253.89,277.94,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="8,235.06,253.89,181.31,7.86">Spanish billion words corpus and embeddings</title>
		<author>
			<persName coords=""><forename type="first">Cristian</forename><surname>Cardellino</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,265.55,337.63,7.86;8,151.52,276.51,224.85,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,344.74,265.55,135.85,7.86;8,151.52,276.51,64.75,7.86">Support vector machines: Theory and applications</title>
		<author>
			<persName coords=""><forename type="first">Theodoros</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Massimiliano</forename><surname>Pontil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2049. 01 2001</date>
			<biblScope unit="page" from="249" to="257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,288.16,337.63,7.86;8,151.52,299.12,222.29,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,309.62,288.16,131.44,7.86">A short introduction to boosting</title>
		<author>
			<persName coords=""><forename type="first">Yoav</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,450.00,288.16,30.59,7.86;8,151.52,299.12,179.67,7.86">Journal of Japanese Society for Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,310.78,337.63,7.86;8,151.52,321.74,191.23,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,244.66,310.78,235.92,7.86;8,151.52,321.74,19.41,7.86">Greedy function approximation: A gradient boosting machine</title>
		<author>
			<persName coords=""><forename type="first">Jerome</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,178.90,321.74,77.36,7.86">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1189" to="1232" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,333.40,337.64,7.86;8,151.52,344.36,329.07,7.86;8,151.52,355.32,152.59,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,355.63,333.40,124.96,7.86;8,151.52,344.36,192.43,7.86">An Emotional Analysis of False Information in Social Media and News Articles</title>
		<author>
			<persName coords=""><forename type="first">Bilal</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,353.77,344.36,126.81,7.86;8,151.52,355.32,76.07,7.86">ACM Transactions on Internet Technology (TOIT)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,366.97,337.63,7.86;8,151.52,377.93,329.07,7.86;8,151.52,388.89,329.07,7.86;8,151.52,399.85,307.08,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,378.07,366.97,102.52,7.86;8,151.52,377.93,110.18,7.86">Leveraging emotional signals for credibility detection</title>
		<author>
			<persName coords=""><forename type="first">Anastasia</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,279.55,377.93,201.04,7.86;8,151.52,388.89,304.10,7.86">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR&apos;19</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR&apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="877" to="880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,411.51,337.63,7.86;8,151.52,422.47,329.07,7.86;8,151.52,433.43,82.94,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,369.22,411.51,111.37,7.86;8,151.52,422.47,245.86,7.86">Less than you think: Prevalence and predictors of fake news dissemination on facebook</title>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Guess</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jonathan</forename><surname>Nagler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joshua</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,407.57,422.47,68.64,7.86">Science Advances</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,445.08,337.63,7.86;8,151.52,456.04,329.07,7.86;8,151.52,467.00,329.07,7.86;8,151.52,477.96,261.50,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,423.96,445.08,56.63,7.86;8,151.52,456.04,123.66,7.86">Glove: Global vectors for word representation</title>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,294.49,456.04,186.10,7.86;8,151.52,467.00,223.39,7.86">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-10">October 2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,489.62,337.63,7.86;8,151.52,500.58,329.07,7.86;8,151.52,511.54,118.97,7.86" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="8,151.52,500.58,325.20,7.86">Declare: Debunking fake news and false claims using evidence-aware deep learning</title>
		<author>
			<persName coords=""><forename type="first">Kashyap</forename><surname>Popat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Subhabrata</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<idno>CoRR, abs/1809.06416</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,523.19,337.98,7.86;8,151.52,534.15,329.07,7.86;8,151.52,545.11,301.08,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,433.99,523.19,46.60,7.86;8,151.52,534.15,115.95,7.86">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tim</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matti</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,444.93,534.15,35.66,7.86;8,151.52,545.11,187.39,7.86">Information Retrieval Evaluation in a Changing World</title>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09">September 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,556.77,337.98,7.86;8,151.52,567.73,329.07,7.86;8,151.52,578.69,329.07,7.86;8,151.52,589.65,329.07,7.86;8,151.52,600.61,102.19,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,442.93,556.77,37.66,7.86;8,151.52,567.73,329.07,7.86;8,151.52,578.69,43.36,7.86">Overview of the 8th Author Profiling Task at PAN 2020: Profiling Fake News Spreaders on Twitter</title>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anastasia</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bilal</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,222.55,589.65,140.97,7.86">CLEF 2020 Labs and Workshops</title>
		<title level="s" coord="8,373.95,589.65,100.70,7.86">Notebook Papers. CEUR</title>
		<editor>
			<persName><forename type="first">Linda</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Carsten</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Aurélie</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020-09">September 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,612.26,337.97,7.86;8,151.52,623.22,295.29,7.86" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="8,407.60,612.26,72.99,7.86;8,151.52,623.22,168.21,7.86">Text similarity in vector space models: A comparative study</title>
		<author>
			<persName coords=""><forename type="first">Omid</forename><surname>Shahmirzadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Lugowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenneth</forename><surname>Younge</surname></persName>
		</author>
		<idno>CoRR, abs/1810.00664</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,634.88,337.97,7.86;8,151.52,645.84,329.07,7.86;8,151.52,656.80,95.53,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,423.10,634.88,57.48,7.86;8,151.52,645.84,205.35,7.86">Fake news detection on social media: A data mining perspective</title>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amy</forename><surname>Sliva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,365.50,645.84,115.09,7.86;8,151.52,656.80,40.30,7.86">ACM SIGKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">8</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,119.67,337.98,7.86;9,151.52,130.63,329.07,7.86;9,151.52,141.59,329.07,7.86;9,151.52,152.55,329.07,7.86;9,151.52,163.51,329.07,7.86;9,151.52,174.47,129.55,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,308.36,119.67,172.23,7.86;9,151.52,130.63,95.27,7.86">Understanding user profiles on social media for fake news detection</title>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,271.52,130.63,209.08,7.86;9,151.52,141.59,152.92,7.86;9,379.52,152.55,101.08,7.86;9,151.52,163.51,230.97,7.86">Proceedings -IEEE 1st Conference on Multimedia Information Processing and Retrieval</title>
		<meeting>-IEEE 1st Conference on Multimedia Information Processing and Retrieval</meeting>
		<imprint>
			<date type="published" when="2018-06">2018. June 2018. 2018</date>
			<biblScope unit="page" from="10" to="14" />
		</imprint>
		<respStmt>
			<orgName>Institute of Electrical and Electronics Engineers Inc.</orgName>
		</respStmt>
	</monogr>
	<note>1st IEEE Conference on Multimedia Information Processing and Retrieval, MIPR</note>
</biblStruct>

<biblStruct coords="9,142.62,185.43,337.98,7.86;9,151.52,196.39,191.09,7.86" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="9,289.57,185.43,191.02,7.86;9,151.52,196.39,72.02,7.86">A survey of fake news: Fundamental theories, detection methods</title>
		<author>
			<persName coords=""><forename type="first">Xinyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Reza</forename><surname>Zafarani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
