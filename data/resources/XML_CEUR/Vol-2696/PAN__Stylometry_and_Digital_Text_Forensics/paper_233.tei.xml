<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,161.15,115.90,293.05,12.90;1,242.99,133.83,129.37,12.90;1,223.43,154.07,168.50,10.75">RMIT at PAN-CLEF 2020: Profiling Fake News Spreaders on Twitter Notebook for PAN at CLEF 2020</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,165.32,190.86,56.06,8.64"><forename type="first">Xinhuan</forename><surname>Duan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">RMIT University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,228.69,190.86,69.08,8.64"><forename type="first">Elham</forename><surname>Naghizade</surname></persName>
							<email>e.naghizade@rmit.edu.au</email>
							<affiliation key="aff0">
								<orgName type="institution">RMIT University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,304.77,190.86,60.00,8.64"><forename type="first">Damiano</forename><surname>Spina</surname></persName>
							<email>damiano.spina@rmit.edu.au</email>
							<affiliation key="aff0">
								<orgName type="institution">RMIT University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,388.34,190.86,61.70,8.64"><forename type="first">Xiuzhen</forename><surname>Zhang</surname></persName>
							<email>xiuzhen.zhang@rmit.edu.au</email>
							<affiliation key="aff0">
								<orgName type="institution">RMIT University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,161.15,115.90,293.05,12.90;1,242.99,133.83,129.37,12.90;1,223.43,154.07,168.50,10.75">RMIT at PAN-CLEF 2020: Profiling Fake News Spreaders on Twitter Notebook for PAN at CLEF 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8BBA307A19CA38D000A0CDD1C18BB327</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automatic detection of fake news in social media has become a prominent research topic due to its widespread, adverse effect on not only the society and public health but also on economy and democracy. The computational approaches towards automatic detection of fake news span from analyzing the source credibility, user credibility, as well as social network structure and the news content. However, the studies on user credibility in this context have largely focused on the frequency and times of engaging in a fake news propagation rather than profiling users based on the content of their tweets. In this paper, we approach this challenge through extracting linguistic and sentiment features from users' tweet feed as well as retrieving the presence of emojis, hashtags and political bias in their tweets. These features are then used to classify users into spreaders or non-spreaders of fake news. Our proposed approach achieves 72% accuracy, being among the top-4 results obtained by systems for the task in the English language.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper describes our participation to the Profiling Fake News Spreaders on Twitter task at PAN-CLEF 2020 <ref type="bibr" coords="1,234.91,482.27,15.27,8.64" target="#b11">[12]</ref>. Given a Twitter feed, the aim is to determine whether or not its author is a spreader of fake news. Although the task includes both English and Spanish languages, we only addressed the problem for the English language.</p><p>Fake news has been proven to be both harmful and misleading to people. In the 2016 US election, most of the users in Twitter have encountered at least one fake news each day <ref type="bibr" coords="1,151.25,542.44,10.58,8.64" target="#b0">[1]</ref>. To prevent people from being misled by fake news, one of the main problems to address consists of identifying fake news spreaders. We tackle this problem by proposing a two-step learning approach that (i) aims to model sentiment, political presence, and use of language of fake news spreaders at tweet level, and (ii) generates a profilelevel representation to feed a binary classifier used to classify profiles into spreaders or non-spreaders of fake news. Our model achieves a 70% accuracy in a 10-fold cross validation using the training set provided by the organizers.</p><p>The rest of the paper is organized as follows. Section 2 describes our proposed approach. Section 3 reports the implementation details needed to reproduce our approach. Section 4 discusses the results. Finally, Section 5 concludes the work and discusses future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed Approach</head><p>Several recent studies have focused on the role of users in social networks on the spread of fake news. These studies have largely focused on the information provided by users in their profile <ref type="bibr" coords="2,195.36,232.39,11.62,8.64" target="#b8">[9]</ref> or the number of times that users engage in fake news propagation, e.g., through retweeting them <ref type="bibr" coords="2,254.58,244.34,15.27,8.64" target="#b12">[13]</ref>.</p><p>However, in this task, the focus is not on detecting the veracity of a piece of news but rather if a user is a fake news spreader given the content of their tweet feed. We proposed profiling fake news spreader as a supervised learning task. Figure <ref type="figure" coords="2,434.20,280.21,4.98,8.64" target="#fig_0">1</ref> shows the main components of our proposed model for this task. As can be seen, the model carries two major steps, denoted as tweet-level and profile-level representation.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Tweet-Level Representation</head><p>The feature extracted in the tweet-level representation phase are listed in Table <ref type="table" coords="2,455.80,600.52,3.74,8.64" target="#tab_1">1</ref>, and the justifications for the features are listed as below:</p><p>-Sentiment: Recent studies suggest that the sentiment of tweets can help detect the credibility of a piece of news or its spreader <ref type="bibr" coords="2,326.08,644.48,10.79,8.64" target="#b4">[5,</ref><ref type="bibr" coords="2,336.87,644.48,7.19,8.64" target="#b5">6]</ref>. As a result, we include sentiment polarity as one of our extracted features. -Emojis and hashtags: To help strengthen the sentiment signal, we include the number of emojis and hashtags in the tweets as additional features. -Political presence: Recent studies suggest that fake news spreaders and non spreaders have different political presence <ref type="bibr" coords="3,297.85,319.03,15.27,8.64" target="#b13">[14]</ref>, hence we proposed to study the relation between political preferences and the behavior of spreading fake news. -Content: It has been proved that spreading fake news on social media is a very rare behavior <ref type="bibr" coords="3,189.41,355.37,10.58,8.64" target="#b6">[7]</ref>. Only features based on user profiles may not be sufficient. We train a language model (a fine-tuned BERT model) using the tweet content to extract relevant language features that can distinguish the desired two classes of users. Figure <ref type="figure" coords="3,182.69,391.23,4.98,8.64" target="#fig_1">2</ref> illustrates this process.</p><p>The mapping of training data is based on the following rule: all tweets belonging to a profile labeled in the training set as a fake news spreader will be labeled as spreader; analogously, tweets that belong to a non-spreader profile in the training set will be labeled as non-spreader.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Profile-Level Representation</head><p>After extracting the features at the tweet-level representation phase, we build the profilelevel representation (as shown in Figure <ref type="figure" coords="3,299.17,517.36,3.60,8.64" target="#fig_0">1</ref>). Given the tweets for a Twitter profile, the values for each feature are aggregated using three functions: mean, media, and standard deviation. The result of this process is a profile-level vector that includes these three aggregated scores for each of the feature in the tweet-level representation, which can be used to train a profile-level fake news spreader classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Implementation</head><p>The implementation of our submission to the evaluation campaign is publicly available <ref type="foot" coords="3,476.61,624.00,3.49,6.05" target="#foot_0">1</ref>and the details are described below.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Preprocessing</head><p>The training data provided by the organizers contain tweets in two languages: English and Spanish <ref type="bibr" coords="4,186.44,412.99,15.27,8.64" target="#b11">[12]</ref>. Each language consists of 300 Twitter profiles, and each profile has 100 tweets. Due to time constraints, we only addressed the task for the English language. The training dataset is balanced, i.e., half of the Twitter profiles are fake-news spreaders, while the other half are labeled as non-spreaders. Only the content of tweets is provided. In our experiments, the tweet content is preprocessed using the tokenizer provided by the library used to implement the TLSP model, described in Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Tweet-Level Spreader Prediction</head><p>The TLSP has been instantiated as a fine-tuned BERT binary classifier. BERT stands for Bidirectional Encoder Representations Transformers, and is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers <ref type="bibr" coords="4,270.77,556.99,10.58,8.64" target="#b3">[4]</ref>. The pre-trained BERT model are used to get the word embedding of the text and the embeddings are then fed into a Gated Recurrent Units (GRU) <ref type="bibr" coords="4,189.28,580.90,11.62,8.64" target="#b2">[3]</ref> to produce a prediction of the probability of the tweet belonging to a fake-news spreader.</p><p>We used the BERT implementation in the Transformers library<ref type="foot" coords="4,421.07,603.14,3.49,6.05" target="#foot_1">2</ref> and the GRU implementation in the torch.nn library<ref type="foot" coords="4,300.63,615.10,3.49,6.05" target="#foot_2">3</ref> . The parameters used to fine-tune the model are listed in Table <ref type="table" coords="4,208.12,628.72,3.74,8.64">2</ref>.</p><p>Table <ref type="table" coords="5,158.94,115.83,3.36,8.06">2</ref>. Parameters used to fine-tune BERT using Gated Recurrent Units (GRU) <ref type="bibr" coords="5,437.08,116.18,10.45,7.77" target="#b2">[3]</ref> with the torch.nn.GRU library. For the pre-trained BERT model in the Transformers library, we instantiated a configuration with the defaults, which is a similar configuration to that of the BERT bert-base-uncased architecture. The TLSP model is trained with the all the training data available. The model is then applied to the tweets in the validation set. The predicted probability of being a fake-news spreader tweet is then used as the TLSP feature in the tweet-level representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Tweet-Level Feature Representation</head><p>Besides the TLSP score, we computed the rest of the tweet-level features as follows:</p><p>-Sentiment: We used the VADER sentiment analysis system to compute the sentiment intensity of each tweet <ref type="bibr" coords="5,263.61,438.32,10.58,8.64" target="#b7">[8]</ref>, using the implementation provided by the authors. <ref type="foot" coords="5,476.61,436.65,3.49,6.05" target="#foot_3">4</ref>Given a tweet, the sentiment polarity is represented as a numeric score between -1 (negative) and 1 (positive). -Emojis and hashtags: For each tweet, the frequency of emojis and hashtags is computed. To extract emojis, We used the spacymoji library.<ref type="foot" coords="5,388.21,484.35,3.49,6.05" target="#foot_4">5</ref> -Political Presence: We aimed to model a political profile of the Twitter users. However -due to time limitations-the current version only indicates the presence of the term trump.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Profile-Level Classification</head><p>As it is shown in the Figure <ref type="figure" coords="5,245.44,570.62,3.74,8.64" target="#fig_0">1</ref>, the final model building firstly transforms the tweet-level representation to the user profile-level representation. After aggregating the features that are retrieved at the tweet-level to retrieve the profile-level features, this vector is fed to an SVM classifier <ref type="foot" coords="5,231.61,604.82,3.49,6.05" target="#foot_5">6</ref> to create the final model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Preliminary Results Using the Training Data</head><p>In order to define the run used to make the official submission, we tried different combinations of features for the tweet-level representation, as well as different machine learning algorithms as the fake news spreader classifier. Table <ref type="table" coords="6,391.11,182.60,4.98,8.64" target="#tab_4">3</ref> shows the effectiveness in terms of Accuracy, Precision, and Recall for different runs, using 10-fold crossvalidation over the training data. <ref type="foot" coords="6,264.41,204.84,3.49,6.05" target="#foot_6">7</ref> Using all features and SVM as the profile-level clas- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Official Results</head><p>Table <ref type="table" coords="6,159.92,446.73,4.98,8.64">4</ref> reports the best performing systems according to the accuracy results for the English language released by the organizers. The 0.72 accuracy obtained by our system (duan20) is among the top-4 accuracy scores obtained by the submissions for the English language, and 4% less accurate than the best system -which achieved a 0.75 accuracy, followed by the baseline SYMANTO (LDSE) <ref type="bibr" coords="6,168.80,506.50,15.27,8.64" target="#b10">[11]</ref>. <ref type="foot" coords="6,187.89,504.83,3.49,6.05" target="#foot_7">8</ref>Our official accuracy result is higher than the scores we obtained in our crossvalidation settings using the training data. This suggests that our approach would benefit from using larger datasets for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>We have described our participation in the Profiling Fake News Spreaders on Twitter task at PAN-CLEF 2020 <ref type="bibr" coords="6,235.43,605.66,15.49,8.64" target="#b11">[12]</ref>: given a Twitter feed, the aim is to determine whether or Table <ref type="table" coords="7,159.23,115.83,3.36,8.06">4</ref>. Best performing systems according to the accuracy results for the English language released by the organizers for the Profiling Fake News Spreaders on Twitter task at PAN-CLEF 2020. Our system is in boldface and baselines are indicated with a -position. not its author is a spreader of fake news. Our approach consists of two steps: (i) we first model sentiment, political presence, and language features of fake news spreaders at tweet level; (ii) we then generate a profile-level representation to feed to a binary classifier to distinguish user profiles into spreaders or non-spreaders of fake news. Our model achieves a 70% accuracy in a 10-fold cross validation using the training set provided by the organizers. We have a number of improvements planned for our future work:</p><p>Modeling emotions in addition to sentiment. Instead of only analyzing the sentiment intensity of tweets, we plan to incorporate emotions (e.g. fear, disgust, joy, sadness, and anger) and follow up recent work that studies the relation between emotions and fake news spreading behaviors <ref type="bibr" coords="7,292.98,525.50,10.79,8.64" target="#b5">[6,</ref><ref type="bibr" coords="7,303.77,525.50,7.19,8.64" target="#b4">5]</ref>.</p><p>Modeling political presence. We believe extracting entities from tweets and characterizing those entities to create a political profile for tweets (e.g., by performing entity linking with a knowledge base) may lead to a better identification of fake news spreaders.</p><p>Understanding the impact of TLSP. Although the fine-tuned BERT model obtained promising results, we would like to explore other embedding transforms such as GPT-3 <ref type="bibr" coords="7,181.76,616.78,11.62,8.64" target="#b1">[2]</ref> to better understand the impact of the TLSP component w.r.t. to the overall performance of our approach.</p><p>Incorporate multilingual inputs. We plan to instantiate our proposed approach to other languages such as Spanish.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,219.74,531.67,175.88,8.12"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Architecture of the proposed approach.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,167.86,348.28,279.65,8.12"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Architecture of the Tweet-Level Spreader Prediction (TLSP) model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,147.70,115.83,319.96,135.91"><head>Table 1 .</head><label>1</label><figDesc>Features used to in the tweet-level representation.</figDesc><table coords="3,147.70,140.33,319.96,111.40"><row><cell>Feature</cell><cell>Description</cell></row><row><cell>Sentiment</cell><cell>Sentiment intensity of the tweet, represented as</cell></row><row><cell></cell><cell>a numeric value between -1 (negative) and 1</cell></row><row><cell></cell><cell>(positive).</cell></row><row><cell>Hashtags</cell><cell>Number of hashstags in the tweet.</cell></row><row><cell>Emojis</cell><cell>Number of emojis in the tweet.</cell></row><row><cell>Political Presence</cell><cell>Number of political entities (e.g., "Trump")</cell></row><row><cell></cell><cell>mentioned in the tweet.</cell></row><row><cell cols="2">Tweet-Level Spreader Prediction (TLSP) Content-based fake-news spreader prediction at</cell></row><row><cell></cell><cell>tweet-level.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,134.77,236.71,345.82,173.30"><head>Table 3 .</head><label>3</label><figDesc>Results using 10-fold cross-validation over the training data. Submitted run in boldface.</figDesc><table coords="6,134.77,261.21,345.82,148.79"><row><cell>Tweet-Level Representation</cell><cell>Fake-News</cell><cell>Accuracy Precision Recall</cell></row><row><cell></cell><cell>Spreader Classifier</cell><cell></cell></row><row><cell>TLSP + Sentiment</cell><cell>Logistic Regression Random Forest</cell><cell>0.6567 0.6707 0.6469 0.6300 0.6392 0.6518</cell></row><row><cell>TLSP + Sentiment</cell><cell></cell><cell>0.6667 0.6837 0.6514</cell></row><row><cell>TLSP + Sentiment + Emojis</cell><cell>SVM</cell><cell>0.6633 0.6799 0.6431</cell></row><row><cell>TLSP + Sentiment + Emojis + Hashtags</cell><cell></cell><cell>0.6700 0.6775 0.6608</cell></row><row><cell>All Features</cell><cell>SVM</cell><cell>0.7000 0.7140 0.6917</cell></row><row><cell cols="3">sifier obtained the best results, and this is the run we submitted via the TIRA Integrated</cell></row><row><cell>Research Architecture [10].</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.73,657.08,139.87,7.77"><p>http://github.com/rmit-ir/pan2020-rmit</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,144.73,645.94,205.12,7.77"><p>https://huggingface.co/transformers/model_doc/bert.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,144.73,657.08,220.55,7.77"><p>https://pytorch.org/docs/master/generated/torch.nn.GRU.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,144.73,623.83,151.11,7.77"><p>https://github.com/cjhutto/vaderSentiment</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,144.73,634.98,152.96,7.77"><p>https://spacy.io/universe/project/spacymoji</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="5,144.73,646.13,335.86,7.77;5,144.73,657.08,180.21,7.77"><p>We used the scikit-learn implementation of C-Support Vector Classification (sklearn.SVM.SVC) with default paramenters.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="6,144.73,624.02,335.86,7.77;6,144.73,634.98,124.66,7.77"><p>In order to avoid overfitting, the same training-test split is used to build both tweet-level (i.e., TLSP) and profile-level classifiers.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="6,144.73,646.13,335.86,7.77;6,144.73,657.08,25.65,7.77"><p>All the results are available at https://pan.webis.de/clef20/pan20-web/author-profiling.html# results.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.61,142.87,319.82,7.77;8,150.95,153.48,162.25,8.12" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,248.93,142.87,171.75,7.77">Social media and fake news in the 2016 election</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Allcott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gentzkow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,426.33,142.87,36.11,7.77;8,150.95,153.83,83.06,7.77">Journal of Economic Perspectives</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="236" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,164.79,332.00,7.77;8,150.95,175.75,308.12,7.77;8,150.95,186.71,122.05,7.77" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,293.70,175.75,139.54,7.77">Language models are few-shot learners</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14165</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,142.61,197.67,318.77,7.77;8,150.95,208.63,312.35,7.77;8,150.95,219.59,309.30,7.77;8,150.95,230.55,240.56,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,193.63,208.63,269.67,7.77;8,150.95,219.59,69.38,7.77">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,238.12,219.59,222.13,7.77;8,150.95,230.55,153.78,7.77">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;14)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;14)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,241.50,335.90,7.77;8,150.95,252.46,323.39,7.77;8,150.95,263.42,298.11,7.77;8,150.95,274.38,239.67,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,328.63,241.50,149.88,7.77;8,150.95,252.46,151.63,7.77">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,320.96,252.46,153.39,7.77;8,150.95,263.42,298.11,7.77;8,150.95,274.38,152.82,7.77">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT&apos;19)</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT&apos;19)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,285.34,328.04,7.77;8,150.95,295.95,321.78,8.12;8,150.95,307.26,23.90,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,276.77,285.34,193.88,7.77;8,150.95,296.30,90.00,7.77">An Emotional Analysis of False Information in Social Media and News Articles</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,246.60,296.30,182.06,7.77">ACM Transactions on Internet Technology (TOIT)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,318.22,305.13,7.77;8,150.95,329.18,322.37,7.77;8,150.95,340.14,271.13,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,290.21,318.22,157.53,7.77;8,150.95,329.18,31.60,7.77">Leveraging emotional signals for credibility detection</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,200.51,329.18,272.81,7.77;8,150.95,340.14,193.95,7.77">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR&apos;19)</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR&apos;19)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="877" to="880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,351.09,320.75,7.77;8,150.95,361.70,270.34,8.12" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,268.77,351.09,194.60,7.77;8,150.95,362.05,116.57,7.77">Less than you think: Prevalence and predictors of fake news dissemination on Facebook</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Guess</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nagler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,273.87,362.05,65.26,7.77">Science Advances</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4586</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,373.01,330.64,7.77;8,150.95,383.97,311.18,7.77;8,150.95,394.93,148.92,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,236.63,373.01,236.62,7.77;8,150.95,383.97,69.47,7.77">VADER: A parsimonious rule-based model for sentiment analysis of social media text</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Hutto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,237.98,383.97,224.15,7.77;8,150.95,394.93,71.11,7.77">Eighth international AAAI Conference on Weblogs and Social Media (ICWSM-14)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="216" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,405.89,334.88,7.77;8,150.95,416.85,293.97,7.77;8,150.95,427.81,207.19,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,223.94,405.89,253.54,7.77;8,150.95,416.85,199.19,7.77">Early detection of fake news on social media through propagation path classification with recurrent and convolutional networks</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">F B</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,368.48,416.85,76.45,7.77;8,150.95,427.81,130.54,7.77">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="354" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,438.77,335.40,7.77;8,150.95,449.72,306.17,7.77;8,150.95,460.68,72.72,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,333.86,438.77,140.16,7.77">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,259.53,449.72,193.52,7.77">Information Retrieval Evaluation in a Changing World</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09">Sep 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,471.64,316.51,7.77;8,150.95,482.60,328.94,7.77;8,150.95,493.56,221.42,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,307.56,471.64,151.19,7.77;8,150.95,482.60,112.45,7.77">A Low Dimensionality Representation for Language Variety Identification</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,281.19,482.60,198.70,7.77;8,150.95,493.56,109.32,7.77">International Conference on Intelligent Text Processing and Computational Linguistics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="156" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,504.52,323.93,7.77;8,150.95,515.48,325.30,7.77;8,150.95,526.44,300.97,7.77;8,150.95,537.40,96.22,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,333.29,504.52,132.88,7.77;8,150.95,515.48,218.44,7.77">Overview of the 8th Author Profiling Task at PAN 2020: Profiling Fake News Spreaders on Twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,264.50,526.44,117.33,7.77">CLEF 2020 Labs and Workshops</title>
		<title level="s" coord="8,388.31,526.44,63.62,7.77;8,150.95,537.40,19.77,7.77">Notebook Papers. CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020-09">Sep 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,548.35,317.19,7.77;8,150.95,559.31,327.87,7.77;8,150.95,570.27,116.80,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,266.63,548.35,177.08,7.77">Csi: A hybrid deep model for fake news detection</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ruchansky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,150.95,559.31,327.87,7.77;8,150.95,570.27,39.22,7.77">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management (CIKM&apos;17)</title>
		<meeting>the 2017 ACM on Conference on Information and Knowledge Management (CIKM&apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="797" to="806" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,581.23,335.37,7.77;8,150.95,591.84,292.42,8.12" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,317.93,581.23,159.67,7.77;8,150.95,592.19,66.81,7.77">Fake news detection on social media: A data mining perspective</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sliva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,223.56,592.19,145.10,7.77">ACM SIGKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="36" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
