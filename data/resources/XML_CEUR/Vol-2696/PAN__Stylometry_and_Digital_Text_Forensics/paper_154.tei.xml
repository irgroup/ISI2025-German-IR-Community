<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,142.99,115.90,329.37,12.90;1,179.81,133.83,255.73,12.90;1,223.43,153.89,168.50,10.75">A Multi-Aspect Classification Ensemble Approach for Profiling Fake News Spreaders on Twitter Notebook for PAN at CLEF 2020</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,223.97,190.49,94.90,8.64"><forename type="first">Clemens</forename><surname>Hörtenhuemer</surname></persName>
							<email>clemens.hoertenhuemer@student.uibk.ac.ateva.zangerle@uibk.ac.at</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Innsbruck</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,338.24,190.49,53.14,8.64"><forename type="first">Eva</forename><surname>Zangerle</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Innsbruck</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,142.99,115.90,329.37,12.90;1,179.81,133.83,255.73,12.90;1,223.43,153.89,168.50,10.75">A Multi-Aspect Classification Ensemble Approach for Profiling Fake News Spreaders on Twitter Notebook for PAN at CLEF 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5A35B6D56CABB372A2F1EDF934C3B367</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Stacking ensemble</term>
					<term>natural language processing</term>
					<term>ensemble pruning</term>
					<term>fake news detection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this work, we attempt to differentiate authors of fake news and real news as part of the Profiling Fake News Spreaders on Twitter task at PAN. We propose a set of eight different language features to represent tweets. These representations are subsequently used in an ensemble classification model to identify fake news spreaders on Twitter. The approach is confined to the English language.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Threats like public deceit or deep fakes, i.e., the artificially created, realistic imitation of an individual reasonably concern politicians, journalists, and sociologists <ref type="bibr" coords="1,424.33,435.16,15.27,8.64" target="#b13">[14]</ref>. In online social networks, fake messages and rumors are usually spread with the intention of deceiving users and manifesting certain opinions. Fake news is not new, but social media platforms have enabled the phenomenon to grow exponentially in recent years <ref type="bibr" coords="1,448.61,471.03,15.27,8.64" target="#b16">[17]</ref>.</p><p>Therefore, technologies to detect intentionally spread fake messages are sought after. At the CLEF 2020 conference, the Profiling Fake News Spreaders on Twitter task at PAN addresses this matter <ref type="bibr" coords="1,255.90,507.10,15.27,8.64" target="#b16">[17]</ref>. The objective of the task is to study whether it is possible to distinguish authors who have disseminated fake news from those who, in their good faith, have never done so. For this task, a collection of sample messages from known fake news spreaders and truth-tellers was gathered from the Twitter microblogging platform and provided to participants. By using the same data and publishing the different approaches, the various teams can mutually inspire each other. Consequently, this should foster mutual improvements to teams' models and jointly advance approaches for detecting fake news spreaders.</p><p>According to <ref type="bibr" coords="1,205.37,602.95,15.27,8.64" target="#b14">[15]</ref>, there are three different approaches to automatically determine the credibility of a certain post, tweet, or article:</p><p>-Truth finding refers to the extraction of structured claims from a certain post, tweet, or article and the comparison of those claims with trustworthy sources. -Analysis of community behavior in social media aims to determine the credibility of a text based on probabilistic graph models and social media analysis. -Natural language claims try to determine the credibility of a text by recognizing characterizing patterns in the writing style of fake news spreaders.</p><p>The goal of this work is to contribute to the systematic detection of fake news in social media networks. By applying the concepts of natural language claims, the approach offers an executable decision model for computing the probability that the author is a fake news spreader. The choice of which text properties are used to determine whether a message is fake or not plays a crucial role. Hence, a central part of this work is investigating which text features are suitable as indicators for fake news. In this context, Ghanem et al. <ref type="bibr" coords="2,193.90,273.91,11.62,8.64" target="#b4">[5]</ref> showed that the decomposition of a tweet, article, or post into manifold emotional features can help to detect fake news. Similarly, <ref type="bibr" coords="2,396.70,285.86,16.60,8.64" target="#b22">[23]</ref> found that positively associated words are relevant to identify sarcasm and negative words to identify irony. Hence, besides conventional text features such as TF-IDF or POS-tags, we also incorporate mood-related aspects for the detection of fake news. Given a set of eight text features, we propose to utilize an ensemble classification approach for the task of differentiating fake news spreaders and truth-tellers. The models of this approach are constrained to the English language.</p><p>The remainder of this paper is structured as follows. In Chapter 2, we describe the used dataset, our approach for feature extraction, and the employed classification model. In Chapter 3, we present the results obtained by applying the developed classification model to the dataset and we conclude our work in Chapter 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>In this section, we present the proposed features as well as the supervised learning model employed to detect fake news spreaders. The objective of the machine learning model is to assign tweets either to the class of tweets written by fake news spreaders or to the class of tweets written by truth-tellers. Based on this classification of tweets, we assign authors of these tweets either to the class of fake news spreaders or the class of truth-tellers.</p><p>In the following, we firstly introduce the dataset underlying our experiments, before we describe the employed data preprocessing and the features used to characterize tweets, before we elaborate on the ensemble classification approach utilized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dataset</head><p>The dataset used was provided by the PAN task committee of the "Profiling Fake News Spreaders on Twitter" task <ref type="bibr" coords="2,249.58,632.53,15.27,8.64" target="#b16">[17]</ref>. This dataset contains tweets of 300 Twitter users, whereby users are labeled as either fake news spreaders or truth-tellers. For each user, a rich collection of tweets was provided. Table <ref type="table" coords="2,322.69,656.44,4.98,8.64" target="#tab_0">1</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Preprocessing</head><p>Each tweet belongs to either an author who belongs to the class of fake news spreaders or the class of truth-tellers. In a first step, we group tweets of fake news spreaders and tweets of truth-tellers as we aim to generalize patterns that allow to distinguish these two classes. Each tweet is then labeled with the respective class.</p><p>Combining multiple tweets into a combined message taking into account the labels provides a more comprehensive information base for pattern recognition. In preliminary experiments, we observed that this concatenation has a positive effect on the accuracy of the classification system. Therefore, for further processing, groups of four tweets of the same author and annotated with the same label are joined together into one message, which is then used as input for all further steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Text Features</head><p>Based on the input tweets (or rather, the concatenation of four tweets), we aim to extract meaningful features for the classification of tweets and hence, authors. Our choice of appropriate text features was motivated by multiple prior works regarding both general text classification, as well as specifically existing work regarding the detection of fake messages.</p><p>The Bag of Words model (BOW) serves as a first initial basis for the representation of tweets <ref type="bibr" coords="3,174.84,536.89,15.27,8.64" target="#b23">[24]</ref>. Furthermore, we add the features proposed by the winner of the 2018 PAN-Task for Style Change Detection <ref type="bibr" coords="3,294.49,548.84,15.49,8.64" target="#b25">[26]</ref>: N-Grams, Term Frequency-Inverse Frequency, POS-Tags, Readability using Textstat and Named Entities (NER) using SpaCy 5 . Ghanem et al. <ref type="bibr" coords="3,194.84,572.75,11.62,8.64" target="#b4">[5]</ref> showed that incorporating emotions can be crucial for the recognition of fake news. Therefore, we also leverage the NRC emotional dictionary <ref type="bibr" coords="3,452.99,584.71,16.60,8.64" target="#b12">[13]</ref> to incorporate emotional features in our approach. Furthermore, we used Vader (Valence Aware Dictionary and sEntiment Reasoner) <ref type="bibr" coords="3,309.91,608.62,11.62,8.64" target="#b7">[8]</ref> to reflect the mood of a text (positive or negative). The average word length of each tweet was also added as a further feature. Moreover, we also utilized sentence embedding vectors for for each tweet to incorporate semantic properties of the tweets. Figure <ref type="figure" coords="3,317.49,644.48,4.98,8.64" target="#fig_0">1</ref> illustrates the features extracted from a tweet in multiple strands. We detail the individual features in the following. Term Frequency-Inverse Document Frequency (TF-IDF): In this strand, we extract basic text features: TF-IDF features and trigrams. Therefore, the texts are separated into tokens (words) using spaces and punctuation marks. We then remove stop words and transform words to their word stem. Based on this preprocessing, we extract word trigrams. We compute TF-IDF scores to reflect their relevance in relation to the entire text corpus for the individual word or trigram, respectively.</p><p>Average Word Length (AWL): In this strand, the average word length of a text is determined. The texts are separated into words using spaces. To determine the average word length of a text, the total number of characters in the text excluding spaces is divided by the total number of words in the text (also including stop words).</p><p>Word/Sentence Embeddings (WE): Here, we compute a sentence embedding for each text. The resulting numeric vectors allow to semantically compare texts. The NLPlibrary SpaCy<ref type="foot" coords="5,190.39,141.55,3.49,6.05" target="#foot_0">1</ref> is used for the conversion into sentence vectors.</p><p>POS-Tags (POS): Part of Speech Tagging (POS-Tagging) is the classification of words into their part of speech. The words get classified with one of the following word types: Pronouns, prepositions, coordinating conjunctions, adjectives, adverbs, determinants, interjections, modals, nouns, personal pronouns, or verbs. For our approach, the number of occurrences of the different word types per text is added to the tweet representation. The NLP-libraries SpaCy 5 and NLTK<ref type="foot" coords="5,287.95,229.80,3.49,6.05" target="#foot_1">2</ref> were tested for POS-tagging. Our preliminary experiments showed that NLTK contributes better to the accuracy of the overall system and is therefore used for this approach.</p><p>Named Entity Recognition (NER): Here, each proper name in the text is assigned to a specific category, such as person, company name or currency. We add the number of occurrences of each category as features to the tweet representation. The NLP-library SpaCy 5 is used for the extraction of the named entities.</p><p>Sentiment Analysis (SA): Using sentiment analysis, we aim to determine the sentiment of the text, whereby sentiment is measured by three dimensions:</p><p>-Positive (between 0 and 1) -Negative (between 0 and 1) -Neutral (between 0 and 1)</p><p>The positive, negative, and neutral scores represent the proportion of the text that falls into these three sentiment categories. Therefore, all these scores together should add up to 1. Additionally, there is the variable compound which expresses the three values in one dimension. We use the scores of the three dimensions and the compound value as a feature to describe the text. The sentiment analysis library Vader<ref type="foot" coords="5,405.21,466.17,3.49,6.05" target="#foot_2">3</ref> , which combines a sentiment-lexicon-approach and rule-based context consideration <ref type="bibr" coords="5,406.28,479.79,10.58,8.64" target="#b7">[8]</ref>, is used for the extraction of the sentiments.</p><p>Emotional Analysis (EA): While sentiment analysis resolves the mood rather objectively between a positive or negative score, emotional analysis attempts to assess the text in terms of a multifaceted human perception of feelings. Since Ghanem et al. <ref type="bibr" coords="5,468.97,544.13,11.62,8.64" target="#b4">[5]</ref> state how important the consideration of human emotions is for the recognition of fake messages, this strand attempts to extract emotions from the given text. To achieve this, an analysis at token level is performed to check a text for the involvement of ten different types of emotions and their degree of expression.</p><p>We use the NRC emotion dictionary <ref type="bibr" coords="5,303.96,603.91,16.60,8.64" target="#b12">[13]</ref> to determine emotions. A word in the dictionary may have markers for the emotion types anger, anticipation, disgust, fear, joy, negative, positive, sadness, surprise, and trust. A word can also have more than one marker if it is associated with more than one emotion. Each word in the text is looked up in the emotion dictionary, matching emotional markers are grouped within their type and counted across the entire text. The count of each type is normalized by dividing it by the total number of words with any emotional marker in the text. The normalized values for each emotion type is used as emotional features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Readability (READ):</head><p>How easy it is to read a text can also be a crucial feature describing a text. Zlatkova et al. <ref type="bibr" coords="6,239.67,224.02,16.60,8.64" target="#b25">[26]</ref> have promoted the consideration of readability in their work on style change detection. There are various static analysis methods for this purpose, for example, the Flesch Reading Ease-Test (FRE) <ref type="bibr" coords="6,360.99,247.93,15.27,8.64" target="#b17">[18]</ref>, which calculates a score from the total number of sentences, words, and syllables. The score indicates how easy it is for the reader to understand the text. It is calculated as follows: FRE = 206.835 -1.015 total words total sentences -84.6 total syllables total words</p><p>Along the lines of Zlatkova et al. <ref type="bibr" coords="6,281.58,324.19,15.27,8.64" target="#b25">[26]</ref>, we also incorporate the following readability scores:</p><p>-Smog Grade <ref type="bibr" coords="6,200.19,358.54,18.19,8.64" target="#b11">[12]</ref> -Flesch Kincaid Grade <ref type="bibr" coords="6,241.07,371.11,16.60,8.64" target="#b17">[18]</ref> -Coleman Liau Index <ref type="bibr" coords="6,235.94,383.69,16.60,8.64" target="#b21">[22]</ref> -Automated Readability Index <ref type="bibr" coords="6,271.92,396.26,16.60,8.64" target="#b9">[10]</ref> -Dale Chall Readability Score <ref type="bibr" coords="6,270.68,408.83,11.62,8.64" target="#b0">[1]</ref> -Difficult Words <ref type="bibr" coords="6,215.96,421.40,11.62,8.64" target="#b6">[7]</ref> -Linsear Write Formula [3] -Gunning Fog Index <ref type="bibr" coords="6,231.93,446.55,11.62,8.64" target="#b5">[6]</ref> Each score is considered separately as a feature for the text. The library Textstat 4 was used for the calculation of the scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Classification</head><p>Based on the set of extracted features, the classifier aims to predict authors as fake or as real. When applied to a collection of tweets of an author, the probability of the author being a fake news spreader can be estimated.</p><p>In our approach, we evaluated multiple classification algorithms with the eight different feature types proposed in the previous section to obtain suitable combinations of classification algorithms and representations. In particular, we evaluated Support Vector Machines (SVM) <ref type="bibr" coords="6,237.25,608.62,15.27,8.64" target="#b19">[20]</ref>, Random Forests (RF) <ref type="bibr" coords="6,350.26,608.62,15.27,8.64" target="#b10">[11]</ref>, Artificial Neural Networks (ANN) <ref type="bibr" coords="6,165.56,620.57,10.58,8.64" target="#b8">[9]</ref>, Adaptive Boosting (AdaBoost) <ref type="bibr" coords="6,308.59,620.57,15.27,8.64" target="#b18">[19]</ref>, and Extreme Gradient Boosting (XG-Boost) <ref type="bibr" coords="6,163.46,632.53,11.62,8.64" target="#b1">[2]</ref> approaches. For each of these classification approaches, we performed crossvalidation with five folds <ref type="bibr" coords="6,238.55,644.48,11.62,8.64" target="#b3">[4]</ref> on the provided training data and with hyper parameters set according to Table <ref type="table" coords="6,224.72,656.44,3.74,8.64" target="#tab_1">2</ref> Table <ref type="table" coords="7,174.61,537.41,4.98,8.64" target="#tab_2">3</ref> shows the accuracy values for each feature in combination with each proposed classification algorithm for the provided training data set. The best accuracy scores for each representation are highlighted in bold.</p><p>Given that we found that different features work differently well when combined with different classification algorithms, we propose to use an ensemble of classifiers for our approach. The primary assumption of ensemble methods is that if weak models are combined appropriately, more accurate and robust models can be achieved <ref type="bibr" coords="7,461.50,610.02,15.27,8.64" target="#b24">[25]</ref>. More precisely, we have chosen a stacking ensemble approach that deliberately combines various weak models of different types. Accuracy values were determined for all combinations of algorithms and representations (see Table <ref type="table" coords="8,373.58,119.31,3.60,8.64" target="#tab_2">3</ref>). However, only the best combinations of each representation and a classification method (marked in bold in the table) were used in the ensemble. This reduction to the essence is known as ensemble pruning <ref type="bibr" coords="8,184.42,155.18,15.27,8.64" target="#b20">[21]</ref>. It is a method to increase efficiency and prediction performance by reducing the ensemble of model components. The results of the eight classifiers are aggregated using logistic regression as meta classifier. Thereby the classifiers are weighted according to the accuracy scores they achieved on the training dataset (cf Table <ref type="table" coords="8,451.85,191.04,3.60,8.64" target="#tab_2">3</ref>). The hyper parameters are set as specified in Table <ref type="table" coords="8,317.62,203.00,4.98,8.64" target="#tab_1">2</ref>    tweets of an author have been classified, the probability of being fake news spreader is used to classify the author itself. It is equal to the ratio of tweets classified as fake news to tweets classified as not fake news of an author, as represented by Equation <ref type="formula" coords="9,473.11,143.22,3.74,8.64" target="#formula_1">2</ref>. T a denotes the set of tweets of an author a, F is the class of tweets containing fake news, and A f is the class of fake news spreaders (i.e., authors of fake news).</p><formula xml:id="formula_1" coords="9,248.50,186.73,232.09,26.80">P (a ∈ A f ) = 1 T t∈Ta |t ∈ F |<label>(2)</label></formula><p>An author is considered to be a fake news spreader if the calculated probability is above 0.5. If the probability is lower, the author is assigned to the class of truth-tellers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results and Discussion</head><p>In Table <ref type="table" coords="9,171.44,290.00,4.98,8.64" target="#tab_2">3</ref> we depict the accuracy scores of the individual representations. Here, TF-IDF stands out as the superior representation with an average accuracy of 79.056%, which was determined by applying a variety of classification algorithms. However, utilizing the proposed ensemble approach, we were able to increase the accuracy score by 6.144%. The pruned stacking classifier, which utilizes the best performing classifiers of each representation, was evaluated by a seven-fold cross-validation of all labeled tweets of the training data. Thereby the following result was obtained: Accuracy: 85.2002 Precision: 85.2329</p><p>The model was used for the classification of the test set of the according PAN task <ref type="bibr" coords="9,463.99,437.96,16.60,8.64" target="#b16">[17]</ref> in the TIRA <ref type="bibr" coords="9,184.09,449.92,16.60,8.64" target="#b15">[16]</ref> evaluation platform. Thereby a classification of authors was conducted based on authors' tweets according to Equation 2 and a score of 0.72 was obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, we aimed to identify suitable text features for the detection of fake news. An increase in accuracy was not achieved by unification at the representation level, but by combining multiple classification results based on the different representations independently of each other using different classification algorithms. Based on these findings, a pruned stacking classifier was developed which incorporates Support Vector Machines, Random Forests, Artificial Neural Networks, and Extreme Gradient Boosting Machines and considers eight different text representations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,239.65,481.36,136.06,8.12;4,116.63,115.84,380.41,350.79"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Feature Extraction Pipeline.</figDesc><graphic coords="4,116.63,115.84,380.41,350.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="8,149.71,365.82,330.88,8.64;8,136.16,400.54,311.26,239.52"><head>Figure 2</head><label>2</label><figDesc>Figure 2 shows the model architecture of the pruned stacking classifier. Once the</figDesc><graphic coords="8,136.16,400.54,311.26,239.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,241.38,654.79,132.59,8.12"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Pruned Stacking Classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,330.16,656.44,137.23,8.64"><head>Table 1 .</head><label>1</label><figDesc>depicts an overview of the dataset. Overview of the dataset.</figDesc><table coords="3,136.41,118.05,342.55,74.54"><row><cell></cell><cell cols="3">Fake News Spreaders Truth-tellers Total</cell></row><row><cell>Number of authors</cell><cell>150</cell><cell>150</cell><cell>300</cell></row><row><cell>Number of tweets per author</cell><cell>100</cell><cell>100</cell><cell>100</cell></row><row><cell>Total number of tweets</cell><cell>15,000</cell><cell>15,000</cell><cell>30,000</cell></row><row><cell>Average word length in characters</cell><cell>5.51</cell><cell>5.40</cell><cell>5.4589</cell></row><row><cell>Average tweet length in words</cell><cell>14.20</cell><cell>14.50</cell><cell>14.3479</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,228.45,656.44,3.74,8.64"><head>Table 2 .</head><label>2</label><figDesc>. Classifier Hyper-Parameters.</figDesc><table coords="7,132.70,117.72,343.11,371.39"><row><cell cols="2">Classifier</cell><cell>Hyper Parameter</cell><cell>Value</cell></row><row><cell></cell><cell></cell><cell>penalty C</cell><cell>1</cell></row><row><cell cols="3">Support Vector Machine kernel</cell><cell>linear</cell></row><row><cell></cell><cell></cell><cell>maximum iterations</cell><cell>20000</cell></row><row><cell></cell><cell></cell><cell>maximum depth</cell><cell>none</cell></row><row><cell cols="2">Random Forest</cell><cell>number of estimators</cell><cell>300</cell></row><row><cell></cell><cell></cell><cell>random state</cell><cell>4</cell></row><row><cell></cell><cell></cell><cell>hidden layers</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell>hidden layer size</cell><cell>100</cell></row><row><cell></cell><cell></cell><cell>output layer size</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell>alpha</cell><cell>0.001</cell></row><row><cell></cell><cell></cell><cell>tolerance</cell><cell>0.001</cell></row><row><cell cols="3">Artificial Neural Network activation</cell><cell>Hyperbolic Tan</cell></row><row><cell></cell><cell></cell><cell>maximum iterations</cell><cell>10000</cell></row><row><cell></cell><cell></cell><cell>learning rate</cell><cell>0.001</cell></row><row><cell></cell><cell></cell><cell>fitting algorithm</cell><cell>Backpropagation</cell></row><row><cell></cell><cell></cell><cell>optimization</cell><cell>Adam</cell></row><row><cell></cell><cell></cell><cell>regularization</cell><cell>L2</cell></row><row><cell></cell><cell></cell><cell>booster</cell><cell>Gbtree</cell></row><row><cell>XGBoost</cell><cell></cell><cell>number of estimators</cell><cell>300</cell></row><row><cell></cell><cell></cell><cell>maximum depth</cell><cell>8</cell></row><row><cell></cell><cell></cell><cell>base estimator</cell><cell>Decision Tree</cell></row><row><cell>AdaBoost</cell><cell></cell><cell cols="2">base estimator maximum depth 7</cell></row><row><cell></cell><cell></cell><cell>number of estimators</cell><cell>300</cell></row><row><cell>Classifier</cell><cell cols="2">TF-IDF AWL WE POS NER SA</cell><cell>EA READ Average</cell></row><row><cell cols="4">Support Vector Machine 84.360 53.920 66.333 63.520 58.853 57.533 56.68 60.240 62.679</cell></row><row><cell>Random Forest</cell><cell cols="3">79.520 52.279 72.480 70.330 57.973 55.106 55.040 60.907 62.954</cell></row><row><cell cols="4">Artificial Neural Network 84.800 53.373 72.187 64.547 60.080 57.653 57.440 60.267 63.793</cell></row><row><cell>XGBoost</cell><cell cols="3">73.600 52.134 73.747 69.667 56.720 54.013 53.787 58.667 61.544</cell></row><row><cell>AdaBoost</cell><cell cols="3">73.000 51.920 70.813 67.760 55.400 52.960 53.653 58.080 60.448</cell></row><row><cell>Average</cell><cell cols="3">79.056 52.725 71.112 67.164 57.805 55.453 55.320 59.632</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,146.78,491.41,321.80,8.12"><head>Table 3 .</head><label>3</label><figDesc>Accuracy of individual features and classifiers, computed on the training dataset.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,230.96,203.00,153.44,121.75"><head>Table 4 .</head><label>4</label><figDesc>and Table 4. Meta Classifier Hyper Parameters</figDesc><table coords="8,234.12,239.61,147.11,74.27"><row><cell>Parameter</cell><cell>Value</cell></row><row><cell>Classifier</cell><cell>Logistic Regression</cell></row><row><cell>Penalty C</cell><cell>1</cell></row><row><cell>Optimization</cell><cell>lbfgs</cell></row><row><cell cols="2">Maximum iterations 50,000</cell></row><row><cell>Regularization</cell><cell>L2</cell></row><row><cell>Tolerance</cell><cell>0.0001</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,144.73,634.79,56.33,7.77"><p>https://spacy.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,144.73,645.94,76.47,7.77"><p>https://www.nltk.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,144.73,657.08,144.55,7.77"><p>https://pypi.org/project/vader-sentiment/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="7,144.73,657.08,112.95,7.77"><p>https://pypi.org/project/textstat/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,142.61,646.13,308.48,7.77;9,150.95,657.08,87.17,7.77" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Chall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Dale</surname></persName>
		</author>
		<title level="m" coord="9,226.17,646.13,221.09,7.77">Readability revisited: The new Dale-Chall readability formula</title>
		<imprint>
			<publisher>Brookline Books</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,119.96,323.71,7.77;10,150.95,130.92,326.61,7.77;10,150.95,141.88,70.98,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,234.22,119.96,147.04,7.77">Xgboost: A scalable tree boosting system</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,399.59,119.96,66.74,7.77;10,150.95,130.92,322.52,7.77">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,152.27,328.00,7.77;10,150.95,163.23,318.56,7.77;10,150.95,174.19,76.95,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,173.12,163.23,171.51,7.77">Readability of invasive procedure consent forms</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">E</forename><surname>Eltorai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">S</forename><surname>Naqvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ghanian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">P</forename><surname>Eberson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P C</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">T</forename><surname>Born</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">H</forename><surname>Daniels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,350.73,163.23,118.79,7.77">Clinical and translational science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="830" to="833" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,184.58,326.74,7.77;10,150.95,195.53,124.03,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,194.13,184.58,221.92,7.77">Estimation of prediction error by using k-fold cross-validation</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Fushiki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,421.78,184.58,47.58,7.77;10,150.95,195.53,40.36,7.77">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="146" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,205.92,320.10,7.77;10,150.95,216.88,264.42,7.77;10,150.95,227.84,115.92,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,276.77,205.92,185.95,7.77;10,150.95,216.88,84.80,7.77">An emotional analysis of false information in social media and news articles</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<idno type="DOI">10.1145/3381750</idno>
		<ptr target="https://doi.org/10.1145/3381750" />
	</analytic>
	<monogr>
		<title level="j" coord="10,241.12,216.88,108.02,7.77">ACM Trans. Internet Technol</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020-04">Apr 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,238.23,327.97,7.77;10,150.95,249.19,44.08,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,199.78,238.23,115.35,7.77">The fog index after twenty years</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gunning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,320.90,238.23,130.26,7.77">Journal of Business Communication</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="3" to="13" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,259.58,306.82,7.77;10,150.95,270.54,124.91,7.77" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="10,243.36,259.58,116.17,7.77">Textstat simple text analysis tool</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hüning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hüning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>Berlin</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Free University of Berlin</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Dutch Linguistics</note>
</biblStruct>

<biblStruct coords="10,142.61,280.93,331.59,7.77;10,150.95,291.89,327.11,7.77;10,150.95,302.84,23.90,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,236.63,280.93,237.57,7.77;10,150.95,291.89,59.76,7.77">Vader: A parsimonious rule-based model for sentiment analysis of social media text</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Hutto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,228.27,291.89,249.80,7.77">Eighth International AAAI Conference on Weblogs and Social Media</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,313.23,320.06,7.77;10,150.95,324.19,72.47,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,290.92,313.23,130.52,7.77">Artificial neural networks: A tutorial</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">M</forename><surname>Mohiuddin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,426.81,313.23,35.87,7.77">Computer</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="31" to="44" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,334.58,337.02,7.77;10,150.95,345.54,326.64,7.77;10,150.95,356.50,329.64,7.77;10,150.95,367.46,52.04,7.77" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="10,374.10,334.58,105.16,7.77;10,150.95,345.54,326.64,7.77;10,150.95,356.50,63.52,7.77">Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Kincaid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">P</forename><surname>Fishburne</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">S</forename><surname>Chissom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
		</imprint>
		<respStmt>
			<orgName>Naval Technical Training Command Millington TN Research Branch</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct coords="10,142.24,377.85,325.67,7.77;10,150.95,388.81,48.56,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,253.35,377.85,162.62,7.77">Classification and regression by randomforest</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,422.07,377.85,26.42,7.77">R news</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="18" to="22" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,399.20,321.26,7.77;10,150.95,410.16,57.53,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,224.17,399.20,144.12,7.77">Smog grading-a new readability formula</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">H</forename><surname>Mc Laughlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,374.36,399.20,65.24,7.77">Journal of reading</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="639" to="646" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,420.55,338.35,7.77;10,150.95,431.50,23.90,7.77" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">D</forename><surname>Turney</surname></persName>
		</author>
		<title level="m" coord="10,269.59,420.55,77.23,7.77">NRC emotion lexicon</title>
		<meeting><address><addrLine>Canada</addrLine></address></meeting>
		<imprint>
			<publisher>National Research Council</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,441.89,325.36,7.77;10,150.95,452.85,284.96,7.77;10,150.95,463.81,183.53,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,192.80,441.89,271.41,7.77">Constitutional democracy and technology in the age of artificial intelligence</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nemitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,150.95,452.85,284.96,7.77;10,150.95,463.81,77.44,7.77">Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</title>
		<imprint>
			<biblScope unit="volume">376</biblScope>
			<biblScope unit="page">20180089</biblScope>
			<date type="published" when="2018">2133. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,474.20,335.13,7.77;10,150.95,485.16,312.30,7.77;10,150.95,496.12,285.89,7.77;10,150.95,507.08,227.51,7.77;10,150.95,518.04,162.18,7.77" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,329.39,474.20,147.98,7.77;10,150.95,485.16,152.65,7.77">DeClarE: Debunking fake news and false claims using evidence-aware deep learning</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Popat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D18-1003" />
	</analytic>
	<monogr>
		<title level="m" coord="10,321.57,485.16,141.69,7.77;10,150.95,496.12,184.53,7.77">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11">Oct-Nov 2018</date>
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,528.43,335.40,7.77;10,150.95,539.38,306.17,7.77;10,150.95,550.34,72.72,7.77" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,333.86,528.43,140.16,7.77">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,259.53,539.38,193.52,7.77">Information Retrieval Evaluation in a Changing World</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09">Sep 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,560.73,323.93,7.77;10,150.95,571.69,325.30,7.77;10,150.95,582.65,300.97,7.77;10,150.95,593.61,96.22,7.77" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,333.29,560.73,132.88,7.77;10,150.95,571.69,218.44,7.77">Overview of the 8th Author Profiling Task at PAN 2020: Profiling Fake News Spreaders on Twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="10,264.50,582.65,117.33,7.77">CLEF 2020 Labs and Workshops</title>
		<title level="s" coord="10,388.31,582.65,63.62,7.77;10,150.95,593.61,19.77,7.77">Notebook Papers. CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020-09">Sep 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,604.00,265.00,7.77" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rudolf</surname></persName>
		</author>
		<title level="m" coord="10,191.59,604.00,94.13,7.77">How to write plain english</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
		<respStmt>
			<orgName>University of Canterbury</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,614.39,328.22,7.77" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,207.48,614.39,71.92,7.77">Explaining adaboost</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,297.64,614.39,69.64,7.77">Empirical inference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="37" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,624.78,338.16,7.77;10,150.95,635.74,213.15,7.77" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="10,307.31,624.78,173.10,7.77;10,150.95,635.74,143.59,7.77">Learning with kernels: support vector machines, regularization, optimization, and beyond</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.24,646.13,332.17,7.77;10,150.95,657.08,187.52,7.77;10,363.13,657.08,57.03,7.77" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="10,299.33,646.13,101.43,7.77">An ensemble pruning primer</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Tsoumakas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Vlahavas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,418.87,646.13,55.54,7.77;10,150.95,657.08,170.00,7.77">Applications of supervised and unsupervised ensemble methods</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,119.96,316.24,7.77;11,150.95,130.92,312.34,7.77;11,150.95,141.88,323.10,7.77;11,150.95,152.84,66.00,7.77" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="11,239.85,119.96,218.63,7.77;11,150.95,130.92,149.70,7.77">On improving the accuracy of readability classification using insights from second language acquisition</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vajjala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Meurers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,318.56,130.92,144.74,7.77;11,150.95,141.88,156.42,7.77">Proceedings of the seventh workshop on building educational applications using NLP</title>
		<meeting>the seventh workshop on building educational applications using NLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="163" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,163.80,338.35,7.77;11,150.95,174.76,287.23,7.77;11,150.95,185.71,172.41,7.77" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="11,203.24,163.80,262.07,7.77"># irony or# sarcasm-a quantitative and qualitative study based on twitter</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">Y A</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,150.95,174.76,287.23,7.77;11,150.95,185.71,46.83,7.77">Proceedings of the 27th Pacific Asia Conference on Language, Information, and Computation</title>
		<meeting>the 27th Pacific Asia Conference on Language, Information, and Computation</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="349" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,196.67,336.62,7.77;11,150.95,207.63,152.39,7.77;11,320.78,207.63,120.53,7.77" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="11,262.62,196.67,212.12,7.77">Understanding bag-of-words model: a statistical framework</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,150.95,207.63,152.39,7.77;11,320.78,207.63,42.83,7.77">International Journal of Machine Learning Cybernetics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="43" to="52" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,218.59,291.98,7.77" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="11,195.53,218.59,65.72,7.77">Ensemble learning</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,267.00,218.59,98.48,7.77">Encyclopedia of biometrics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="270" to="273" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,229.55,334.68,7.77;11,150.95,240.51,298.15,7.77;11,150.95,251.47,110.36,7.77" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="11,465.97,229.55,10.96,7.77;11,150.95,240.51,250.30,7.77">An ensemble-rich multi-aspect approach for robust style change detection</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zlatkova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kopev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mitov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Atanasov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hardalov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Koychev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,407.01,240.51,42.10,7.77;11,150.95,251.47,84.21,7.77">CLEF 2018 Working Nots of CLEF</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
