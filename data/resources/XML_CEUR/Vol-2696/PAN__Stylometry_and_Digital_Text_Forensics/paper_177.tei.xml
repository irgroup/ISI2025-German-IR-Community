<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,136.22,148.76,334.41,15.96;1,238.13,166.16,119.17,15.96;1,211.37,186.64,172.60,12.00">A BERT based Two-stage Fake News Spreaders Profiling System Notebook for PAN at CLEF 2020</title>
				<funder ref="#_rWhYV2d">
					<orgName type="full">Ministry of Science and Technology</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,227.81,224.75,60.74,9.05"><forename type="first">Shih-Hung</forename><surname>Wu</surname></persName>
							<email>shwu@cyut.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Chaoyang University of Technology Taichung</orgName>
								<address>
									<country>Taiwan (R.O</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,307.97,224.75,70.98,9.05"><forename type="first">Sheng-Lun</forename><surname>Chien</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Chaoyang University of Technology Taichung</orgName>
								<address>
									<country>Taiwan (R.O</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,136.22,148.76,334.41,15.96;1,238.13,166.16,119.17,15.96;1,211.37,186.64,172.60,12.00">A BERT based Two-stage Fake News Spreaders Profiling System Notebook for PAN at CLEF 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C70EBF0D3293912F80F9405F63C62E92</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our two-stage classification approach to the CLEF 2020 lab: Profiling Fake News Spreaders on Twitter. The task can be briefly defined as: Given a Twitter feed, determine whether its author is keen to be a spreader of fake news. Our approach is to adopt the pretrained model BERT as a tweet classifier and to spot potential spreaders whose tweets are strongly suspected as fake news. The performance of our approach can reach 0.71 on the English data set during developing the system. However, the performance drop to 0.56 in the final PAN at CLEF 2020 shared task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A great amount of fake news and rumors are propagated in online social networks. According to the experience on developing anti-spam techniques, it is a good approach to spot the source instead of trying to check the content one-by-one. The aim of profiling fake news spreaders task at PAN-2020 is to know if it is possible to discriminate authors who have posted some fake news in the past from those who have never done it before <ref type="bibr" coords="1,229.01,517.93,10.69,9.05" target="#b0">[1]</ref>.</p><p>The organizers propose the task from a multilingual perspective, and provide data set in English and Spanish, and recommend the participants to take part in both languages. The uncompressed dataset consists in a folder per language (en, es). Each folder contains an XML file per author (Twitter user) with 100 tweets and the filename of these XML files corresponding to the unique author IDs. There are also a separate truth.txt file with the list of authors and the ground truth of whether they are fake news spreaders or not. The performance of a system will be ranked by accuracy in discriminating between the two classes.</p><p>However, due to the limitation of time and resource, we just build a system only for tweets in English based on the content analysis and skip the tweets in Spanish. The decision process of our system is a two-stage classification approach to the</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Profiling Fake News Spreaders on Twitter task. Our system adopted the pre-trained bidirectional transformer language model, known as BERT <ref type="bibr" coords="2,372.67,161.00,11.72,9.05" target="#b1">[2]</ref> as our NLP tool for content analysis. During the training phrase, we fine-tune of the pretrained model BERT as a tweet classifier and use it to classify each tweet as potential fake news or not. Then our system spot a spreader by checking the percentage of each author's tweets that is classified as fake news. If the percentage is higher than a threshold, then we consider the author is a fake news spreader.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The BERT Pre-trained Model</head><p>The system flow is shown in the following figures. Figure <ref type="figure" coords="2,389.91,283.79,4.98,9.05" target="#fig_0">1</ref> shows the BERT model and classifier architecture. The core of our system is the pretrained language model "BERT". The BERT model is a bidirectional transformer pre-trained using a combination of masked language modeling (MLM) objective and next sentence prediction on a large corpus comprising the Toronto Book Corpus and Wikipedia. BERT stands for Bidirectional Encoder Representations from Transformers. BERT is designed to pre-train deep bidirectional representations from unlabeled text. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create models for new tasks. The implementation of BERT that we use is BERT for sequence classification from Hugging face library 1 . The pretrained model is "bert-base-uncased", that required all English text to be in lower case. The hyperparameter in the training phrase: Hidden size = 768, Learning r= 6.0e-5, and Vocab = 30522. We train the model 10 epochs in each experiment setting. Figure <ref type="figure" coords="2,166.06,615.76,4.98,9.05" target="#fig_1">2</ref> shows how our system do the training. In the training phrase, we have done some our training data preprocessing. We extracted every tweet and added the truth data for each XML file. Each XML file contains 100 tweets, and will be associated with the same label. All the non-English characters are filtered, only 1 https://huggingface.co/transformers/model_doc/bert.html</p><formula xml:id="formula_0" coords="2,144.86,527.95,273.77,49.65">BERT [CLS] W1 W2 W3 â€¦ Wn</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Linear Classifier</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class</head><p>English characters are kept for training data. Then we combine all data into a training dataset for the model to let it learn which tweet may be telling the fake news or not. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System Development</head><p>There are 300 authors and each has 100 tweets in the training set. We find that half of them are spreaders however we do not know whether each tweet is a fake news or not. However, we assume that all tweets belong to the spreaders are potential fake news and all tweets belong to the non-spreaders are real news. Thus, we trained a classifier that can classify the news into potential fake ones and real ones.</p><p>We know this assumption is imprecise, the classifier cannot spot the fake news well. So when we need to use it to spot a spreader, we set a threshold mechanism to prevent overly identify too many authors as spreaders. Only if the percentage of an author's tweets passed the threshold he/she will be labelled as spreader. An author with only a few tweets that are classified as fake news will not be labelled as a spreader. The decision is made by an empirical threshold. We divide the training set into two parts and use this developing set to find the best threshold, where 70% of the data used as training set and 30% of the data used as test set. Figure <ref type="figure" coords="3,420.39,592.96,4.98,9.05" target="#fig_2">3</ref> shows the accuracy vs. threshold result, where the threshold range from 60% to 90%. The system can get a 0.71 accuracy value with a threshold 74%. The threshold is selected manually and used in our system.  To know how the system might perform, we conduct several similar experiments on the training set. Table <ref type="table" coords="4,230.19,359.87,4.98,9.05" target="#tab_1">1</ref> shows the test results. The accuracy value is around 0.65 to 0.71 given enough training data, i.e. 60% to 80% of the data in training set. We expect that our system can get similar result in formal test. Figure <ref type="figure" coords="4,165.14,491.17,4.98,9.05" target="#fig_3">4</ref> shows how our system do the test. Before testing the data, we also do the data preprocessing first. We extracted every tweet for the one Author file (XML file) and used the model to predict every tweet. After all tweets of one author were labeled 1 or 0, we have a threshold mechanism to make decisions on whether the author is a spreader or not by checking the percentage of 1 exceeded 74% or not. Then our system will put the final answer with author id to a XML file and finish the task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Test Result and Discussion</head><p>The test part is taken on the virtual machine provided by the organizers, we met some technical error. In the training phrase, all the non-English characters are filtered, only English characters are kept for training data, but we omitted this part during the test phrase. This is one of the reasons that our system performance decreased. Table <ref type="table" coords="5,465.75,450.73,4.98,9.05">2</ref> shows our system official final test result vs. some benchmarks. The accuracy value of our system is 0.560, which is equal to the LSTM benchmark but lower than our best result on the development set.</p><p>Table 2: Our system performance of the final result vs. benchmarks.</p><p>Test runs Accuracy SYMANTO (LDSE) <ref type="bibr" coords="5,279.96,529.75,10.49,8.18" target="#b4">[5]</ref> 0.745 EIN <ref type="bibr" coords="5,249.88,540.58,10.45,8.18" target="#b5">[6]</ref> 0.640 LSTM 0.560 Pan20-author-profiling-test-dataset-2020-02-23 0.560 RANDOM 0.510</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper describes our two-stage classification approach to Profiling Fake News Spreaders on Twitter task. The performance of our approach can reach 0.7 on the development set. However, the performance drop to 0.56 in the final PAN evaluation at CLEF 2020 shared task. As future work, we intend to investigate what are the other information that might help to detect fake news spreaders <ref type="bibr" coords="6,268.37,161.00,10.60,9.05" target="#b2">[3]</ref>. For example, in addition to news content and labels, fake news articles in some datasets also provide information on social network of Twitter which contains Twitter users and their following relationships, i.e., useruser relationships, and how the news has propagated (tweeted/re-tweeted) by users, i.e., news-user relationships <ref type="bibr" coords="6,238.61,206.96,10.69,9.05" target="#b3">[4]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,235.97,594.94,134.87,8.18"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: BERT model and classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,249.89,390.67,106.79,8.18"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: system architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,205.25,327.53,196.32,8.18;4,136.30,147.35,322.80,178.20"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Threshold vs. accuracy result on training set.</figDesc><graphic coords="4,136.30,147.35,322.80,178.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,254.81,351.89,97.13,8.18"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Our system flow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,125.54,405.67,343.94,71.18"><head>Table 1 :</head><label>1</label><figDesc>System performance during develop, we divide the English training set as training part and test part with the threshold 74% Training data to test data ratio</figDesc><table coords="4,349.99,426.91,34.47,8.18"><row><cell>Accuracy</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This study was supported by the <rs type="funder">Ministry of Science and Technology</rs> under the grant number <rs type="grantNumber">MOST 109-2221-E-324-024</rs></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_rWhYV2d">
					<idno type="grant-number">MOST 109-2221-E-324-024</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,128.23,348.89,341.78,8.18;6,142.82,359.21,329.91,8.18;6,142.82,369.89,315.93,8.18;6,142.82,381.31,140.82,8.18" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,316.20,348.89,153.81,8.18;6,142.82,359.21,202.98,8.18">Overview of the 8th Author Profiling Task at PAN 2020: Profiling Fake News Spreaders on Twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="6,243.76,369.89,118.33,8.18">CLEF 2020 Labs and Workshops</title>
		<title level="s" coord="6,368.68,369.89,90.07,8.18;6,142.82,381.31,110.05,8.18">Notebook Papers. CEUR Workshop Proceedings.CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>NÃ©vÃ©ol</surname></persName>
		</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,128.23,391.63,297.74,8.18;6,142.82,401.95,312.11,8.18;6,142.82,412.27,24.09,8.18" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="6,351.71,391.63,74.25,8.18;6,142.82,401.95,201.68,8.18">Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805v2[cs.CL]</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,128.23,422.59,335.32,8.18;6,142.82,433.03,289.94,8.18;6,142.82,443.35,157.75,8.18" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,268.99,422.59,190.81,8.18">CSI: A Hybrid Deep Model for Fake News Detection</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ruchansky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,152.53,433.03,280.22,8.18;6,142.82,443.35,44.65,8.18">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management</title>
		<meeting>the 2017 ACM on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="797" to="806" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,128.23,453.67,323.50,8.18;6,142.82,463.99,146.02,8.18" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,251.01,453.67,200.72,8.18;6,142.82,463.99,75.99,8.18">Beyond News Contents: The Role of Social Context for Fake News Detection</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,232.36,463.99,24.14,8.18">WSDM</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,128.23,474.31,316.85,8.18;6,142.82,484.63,323.21,8.18;6,142.82,495.07,312.32,8.18;6,142.82,505.39,196.40,8.18" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,293.17,474.31,151.90,8.18;6,142.82,484.63,114.30,8.18">A Low Dimensionality Representation for Language Variety Identification</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10754</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,274.92,484.63,191.11,8.18;6,142.82,495.07,152.68,8.18;6,364.96,495.07,90.18,8.18;6,142.82,505.39,22.32,8.18">Postproc. 17th Int. Conf. on Comput. Linguistics and Intelligent Text Processing, CICLing-2016</title>
		<imprint>
			<publisher>LNCS</publisher>
			<date type="published" when="9624">9624</date>
			<biblScope unit="page" from="156" to="169" />
		</imprint>
	</monogr>
	<note>Revised Selected Papers, Part II</note>
</biblStruct>

<biblStruct coords="6,128.23,515.71,298.91,8.18;6,142.82,526.03,285.60,8.18;6,142.82,536.38,132.60,8.18" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,311.87,515.71,115.26,8.18;6,142.82,526.03,169.61,8.18">An Emotional Analysis of False Information in Social Media and News Articles</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,318.24,526.03,110.18,8.18;6,142.82,536.38,69.73,8.18">ACM Transactions on Internet Technology (TOIT)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
