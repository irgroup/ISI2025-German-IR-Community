<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,148.43,115.90,318.50,12.90;1,223.43,136.45,168.50,10.75">Siamese Network applied to Authorship Verification Notebook for PAN at CLEF 2020</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,159.31,173.56,71.67,8.64"><forename type="first">Emir</forename><surname>Araujo-Pino</surname></persName>
							<email>emiraraujoing@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Posgrado en Ciencia e Ingeniería de la Computación</orgName>
								<orgName type="institution">Universidad Nacional Autónoma de México</orgName>
								<address>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,240.43,173.56,93.23,8.64"><forename type="first">Helena</forename><surname>Gómez-Adorno</surname></persName>
							<email>helena.gomez@iimas.unam.mx</email>
							<affiliation key="aff1">
								<orgName type="department">Instituto de Investigaciones en Matemáticas Aplicadas y en Sistemas</orgName>
								<orgName type="institution">Universidad Nacional Autónoma de México</orgName>
								<address>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,359.99,173.56,91.59,8.64"><forename type="first">Gibran</forename><surname>Fuentes-Pineda</surname></persName>
							<email>gibranfp@unam.mx</email>
							<affiliation key="aff1">
								<orgName type="department">Instituto de Investigaciones en Matemáticas Aplicadas y en Sistemas</orgName>
								<orgName type="institution">Universidad Nacional Autónoma de México</orgName>
								<address>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,148.43,115.90,318.50,12.90;1,223.43,136.45,168.50,10.75">Siamese Network applied to Authorship Verification Notebook for PAN at CLEF 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B3AA125938357481F14AE49324D8E1C6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present our approach to the Authorship task at PAN 2020. The task consists in comparing two documents and automatically determine if they are written by the same author. To solve this task, we introduce a Siamese network architecture that is trained on character n-grams of the document pairs to be compared. We experimented with different hyperparameters when training the model on a large and a small dataset. Our best model achieved an overall evaluation of 0.804, which is the average of AUC, c@1, f_05_u, and F1 scores.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>PAN 3 is a CLEF 4 Lab on uncovering plagiarism, authorship, and social software misuse. PAN <ref type="bibr" coords="1,176.04,470.35,11.62,8.64" target="#b0">[1]</ref> has a series of shared tasks of text forensics and stylometry, this year's campaign focuses on authorship verification, celebrity profiling, profiling fake news Spreaders on Twitter, and Style Change Detection. In this paper, we describe our approach to the authorship verification task, which aims to identify if both texts belong to the same author or not. From the machine learning perspective, this task can be seen as a binary classification problem.</p><p>Nowadays, there are many unknown authorship letters such as email Fraud <ref type="bibr" coords="1,461.50,542.78,15.27,8.64" target="#b22">[24]</ref>, suicide <ref type="bibr" coords="1,166.41,554.74,10.58,8.64" target="#b6">[8]</ref>, and terrorism <ref type="bibr" coords="1,241.69,554.74,11.62,8.64" target="#b1">[3]</ref> for which it is necessary to verify the authorship. Currently, to solve authorship verification problems there are different approaches such as distance based <ref type="bibr" coords="1,194.16,578.65,15.27,8.64" target="#b21">[23]</ref>, machine learning based <ref type="bibr" coords="1,310.46,578.65,15.27,8.64" target="#b16">[18]</ref>, and impostors <ref type="bibr" coords="1,389.33,578.65,16.60,8.64" target="#b11">[13]</ref> which have shown great results in previous PAN tasks. Besides, there are four different approaches to solve these problems and can be separated by instance or profile based and intrinsic or extrinsic based <ref type="bibr" coords="2,173.04,131.27,15.27,8.64" target="#b18">[20]</ref>. This year's shared task consists of closed set problems, which we solved by an instance-intrinsic based approach.</p><p>As far as we know, there are few implementations of deep learning based methods to solve this problem. Lopez-Velazco 2016 <ref type="bibr" coords="2,310.60,167.44,16.60,8.64" target="#b15">[17]</ref> introduced a siamese architecture <ref type="bibr" coords="2,468.97,167.44,11.62,8.64" target="#b2">[4]</ref> with character embeddings as input, to the authorship verification problem. Exploring architectures and methods we finally train a deep learning siamese network on character 3-grams to solve the PAN 2020 authorship verification shared task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Previous Work</head><p>Authorship identification related problems still have challenges to overcome, there are many methods to solve specific problems <ref type="bibr" coords="2,307.83,274.15,10.58,8.64" target="#b7">[9]</ref>. Last year, PAN 2019 shared the cross domain authorship attribution task <ref type="bibr" coords="2,276.11,286.10,16.60,8.64" target="#b9">[11]</ref> which consisted of identifying the author of a given document among a closed set of authors. Most of the submitted solutions of PAN 2019 were SVM variations and no even one participant used a deep learning based approach. The main differences between a traditional machine learning and a deep learning application from the development perspective are the hardware requirements, the amount of data to handle, and the ability to handle raw data as input <ref type="bibr" coords="2,406.00,345.88,15.27,8.64" target="#b12">[14]</ref>. Conventional machine learning techniques need extensive feature engineering to transform the raw data in order to use it for training and testing a model.</p><p>Deep learning algorithms were used in PAN 18 authorship attribution shared task <ref type="bibr" coords="2,468.48,382.05,15.27,8.64" target="#b10">[12]</ref>, but as far as we know there is no much research on Siamese networks to solve these problems. In <ref type="bibr" coords="2,189.17,405.96,15.27,8.64" target="#b15">[17]</ref>, a Siamese architecture composed of a character embeddings input layer, a convolution <ref type="bibr" coords="2,215.96,417.92,15.27,8.64" target="#b13">[15]</ref>, and LSTM <ref type="bibr" coords="2,283.77,417.92,11.62,8.64" target="#b5">[7]</ref> networks was tested on an English books corpus. This architecture achieved good performance on a Gutenberg [2] project corpus specifically designed to test authorship verification methods. The main differences with our architecture are the input which consists of n-grams, the way of extracting the embedded vector from each input, and the compare method which originally uses euclidean distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Datasets</head><p>The PAN 2020 authorship verification organization provided two datasets: large and small. The purpose of these two corpus was to train two models, one for each dataset, to compare a hungry data method as a deep learning model with a symbolic machine learning approach. As it is known, one of the main problems for training a neural network is to get enough data to achieve good performance. So, we decided to train two models with the aim to compare how much the amount of data affects the performance of our method.</p><p>Table <ref type="table" coords="2,174.56,620.57,4.98,8.64" target="#tab_0">1</ref> shows the results of a basic data analysis over both datasets. The Samples column shows the number of documents pairs, the Different Texts column shows the number of different documents in the corpus, and the last three columns show the characters statistics of the documents. The small dataset corresponds to 19% of the size </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methodology</head><p>In the machine learning literature, there is a wide variety of deep learning architectures, as far as we know, conventionally most of these receive as input raw data. In other words, deep learning models learn to extract relevant features from raw data to reach good performance. Despite this, our neural architecture approach receives character n-grams as inputs. So in order to train our network, the first step is to transform the texts dataset into character n-grams (with n varying from 1 to 3) frequency vectors (the dimensions of the vectors correspond to the frequency of each n-gram).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Features Extraction</head><p>In order to obtain the n-grams of the documents pairs, we use the Scikit Learn Python module <ref type="bibr" coords="3,167.54,405.44,15.27,8.64" target="#b17">[19]</ref>. It extracts all the n-grams (with n varying from 1 to 3) within the documents and produces a vector representation with the frequency of such n-grams. With the purpose of optimizing time and memory resources and without compromising the classifier performance we performed basic hyperparameters tuning during the n-gram features extraction process. The hyperparameters we tune are the minimum document frequency and the maximum document frequency. To archive this we train the same Siamese architecture on different n-grams sets. Due to time restriction, we were not able to perform a complete grid search over all hyperparameters. Our best model on the training dataset receives as input n-grams (with n varying from 1 to 3) that appear at least in the 1% of all documents (min document frequency) and with no restriction on the maximum document frequency. Finally, 1 normalization was performed over the n-grams vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Network Architecture and Training</head><p>A siamese network can be seen generally as a comparison network, its main components are a set of identical subnetworks and a final layer to contrast the subnetworks outputs <ref type="bibr" coords="3,167.15,608.62,10.58,8.64" target="#b2">[4]</ref>. The main idea behind this architecture is to extract a set of features from each input using a subnetwork and in the same way train another network with the aim to compare the two outputs of the subnetworks.</p><p>Figure <ref type="figure" coords="3,178.76,644.48,4.98,8.64" target="#fig_0">1</ref> shows the network architecture. The architecture has only one extracting subnetwork which receives each input n-gram vector separately from each document to compare. The first layers of the extracting subnetwork are Batch normalization (BN), Gaussian Noise (GN), and Dropout (DP). These layers were set at the input with the aim to speed up the training and achieve a better validation score.</p><p>Then, a residual network converts the input into a feature space of 512 dimensions. The first dense layer inside the residual network acts as an adapter, it allows to connect the input to the residual network. This residual network has a depth of 8 and all the internal layers have a feature space of 512. Some differences from the ResNet <ref type="bibr" coords="4,453.82,191.98,11.62,8.64" target="#b4">[6]</ref> are the connections inside the residual network which perform a subtraction instead of an addition, and the use of dense layers instead of convolutional layers. Finally, the classifier network (Dense network with binary output) takes the absolute difference of both subnetworks outputs and performs a binary classification with a 3 layers dense network. In order to speed up training, we also use BN between the dense layers of the classifier network. We use the elu <ref type="bibr" coords="4,253.54,263.71,11.62,8.64" target="#b3">[5]</ref> activation, and Radam <ref type="bibr" coords="4,362.24,263.71,16.60,8.64" target="#b14">[16]</ref> optimization to train the complete Siamese network. We trained two models, one with the small dataset and the other with the large one. In order to speed up the n-gram extraction process, we only used the first 10000 (ten thousand) characters from each document. Both datasets were split on training and validation with 70 and 30 percent of samples respectively. To train the network we used the default value of the alpha learning rate which is 10 -3 and the n-grams range was set from 1 to 3. Table <ref type="table" coords="4,208.19,561.03,4.98,8.64">2</ref> shows the examined hyperparameters of the complete architecture. For our final submission, we used the parameters that achieved the best classification performance in terms of AUC on 30% of both large and small training datasets. The final hyperparameters are shown in Table <ref type="table" coords="4,301.33,596.90,4.98,8.64">2</ref> in bold.</p><p>Both models were trained on a 2070super GPU with 32bits configuration, 64GB RAM. The training time was around 6 and 14 hours on the small and large datasets respectively. We used the pipelines of TensorFlow 0.9</p><p>Table 2: Examined system configurations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We trained a model for each dataset (large and small). Figure <ref type="figure" coords="5,379.10,255.52,4.98,8.64">2</ref> shows the loss and validation loss obtained by training. We set the same hyperparameters for training, preprocessing, and architecture in both models. Table <ref type="table" coords="5,175.02,536.89,4.98,8.64" target="#tab_2">3</ref> shows the validation scores of the models trained on the small and large datasets. Both datasets were split in Training and Validation following a 70%-30% proportion. In this way, we evaluated two times each model, first on the same dataset but with different examples ( 30% validation set extracted from the same dataset), second, with a different dataset (30% validation set comes from the other dataset). In this sense, we obtain four validation scores from the two models and the two validation sets. It can be observed that the AUC score is 1.0 when the Training and Validation sets come from the same dataset. On the other hand, the small dataset model achieves only 0.823 AUC on the validation set that comes from the large training set. We believe that the reason for this behavior is that the same document can appear in both training and validation sets because we only divided the document pairs samples. Finally, Table <ref type="table" coords="6,209.45,232.62,4.98,8.64" target="#tab_3">4</ref> shows the final results of the PAN 2020 authorship verification task evaluated on the TIRA platform <ref type="bibr" coords="6,289.69,244.58,15.27,8.64" target="#b19">[21]</ref>. It can be observed, that the overall score shows that the small dataset model achieves better results than the large dataset model, even though the performance of both models are very similar, for example, the AUC difference between both results is 0.015. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we presented a siamese network approach to solve the PAN 2020 authorship verification problem. The network receives document pairs as character n-grams (with n varying from 1 to 3) as input and learns to identify if these documents are written by the same author. The network hyperparameters were adjusted on the two datasets provided by the task organizers. The final configuration submitted to the conference achieved the best performance during training time on both, large and small datasets. Our experiments showed that both models achieve similar results when training on different data and amount of examples.</p><p>Even while using as few as 19% of the size of the large dataset, the model trained on the small dataset achieved similar results on the validation set. On the other hand, the AUC score reached 1.0 at validation if the training and validation sets come from the same dataset. In the case of PAN 2020 test dataset, the small dataset model outperformed the large dataset model but only by 0.015 of AUC score. The validation of the small dataset model on the large validation set achieves a score near to the score obtained on the PAN 2020 test dataset.</p><p>We demonstrated that this architecture can achieve good results at the PAN 2020 verification task, even when trained on a small dataset and using only 10000 characters per document. Besides, our approach does not implement score corrections and we only tune our models with the AUC score as reference. As future research directions, we plan to perform a better tuning of the described hyperparameters using a genetic-based parameter tuning <ref type="bibr" coords="7,205.04,143.22,15.27,8.64" target="#b20">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aknowledgements</head><p>This work has been partially supported by PAPIIT-UNAM projects TA100520.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,134.77,451.37,345.82,8.64;4,134.77,463.32,306.40,8.64;4,137.60,308.86,340.16,130.66"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Final architecture trained. "BN" means batch normalization, "GN" refers to Gaussian noise, "Dense" means dense layer, and "abs" means absolute value.</figDesc><graphic coords="4,137.60,308.86,340.16,130.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,134.77,488.75,345.82,8.64;5,134.77,500.70,243.84,8.64;5,134.77,344.74,172.91,117.22"><head></head><label></label><figDesc>Figure 2: Both figures show the number of epochs in the horizontal axis. Training loss is shown as a blue line. Validation loss is shown as a red line.</figDesc><graphic coords="5,134.77,344.74,172.91,117.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,134.77,118.07,345.82,110.83"><head>Table 1 :</head><label>1</label><figDesc>Statistics measures of PAN 2020 datasets.of the large dataset. Most of the documents are around 21000 characters and there are almost no duplicated documents. The details of the datasets are available in<ref type="bibr" coords="3,437.30,220.26,15.27,8.64" target="#b8">[10]</ref>.</figDesc><table coords="3,142.39,118.07,326.78,41.45"><row><cell>Dataset</cell><cell>Samples</cell><cell>Positive Samples</cell><cell>Different Texts</cell><cell>Max Characters</cell><cell>Min Characters</cell><cell>Mean Characters</cell></row><row><cell>Large</cell><cell>275565</cell><cell>147778</cell><cell>494257</cell><cell>943947</cell><cell>20355</cell><cell>21426.08</cell></row><row><cell>Small</cell><cell>52601</cell><cell>27834</cell><cell>93667</cell><cell>296887</cell><cell>20670</cell><cell>21424.93</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,334.24,632.03,6.48,10.31"><head></head><label></label><figDesc>5 .</figDesc><table coords="5,201.19,118.07,208.50,63.09"><row><cell>Gaussian Noise</cell><cell>Dropout</cell><cell>Activation</cell><cell>Min Document Frecuency</cell></row><row><cell>0</cell><cell>0.1</cell><cell>relu</cell><cell>0.05</cell></row><row><cell>10 -3</cell><cell>0.3</cell><cell>elu</cell><cell>0.01</cell></row><row><cell>10 -4</cell><cell>0.7</cell><cell></cell><cell></cell></row><row><cell>10 -5</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,150.79,118.07,309.32,76.43"><head>Table 3 :</head><label>3</label><figDesc>Validations exchanging datasets.</figDesc><table coords="6,150.79,118.07,309.32,64.16"><row><cell>Training Dataset</cell><cell>Validation Dataset</cell><cell>AUC</cell><cell>c@1</cell><cell>f_05_u</cell><cell>F1</cell><cell>overall</cell></row><row><cell>Large (70%)</cell><cell>Small (30%)</cell><cell>0.964</cell><cell>0.882</cell><cell>0.858</cell><cell>0.894</cell><cell>0.899</cell></row><row><cell>Large (70%)</cell><cell>Large (30%)</cell><cell>1.000</cell><cell>0.993</cell><cell>0.990</cell><cell>0.993</cell><cell>0.994</cell></row><row><cell>Small (70%)</cell><cell>Small (30%)</cell><cell>1.000</cell><cell>0.987</cell><cell>0.981</cell><cell>0.988</cell><cell>0.989</cell></row><row><cell>Small (70%)</cell><cell>Large (30%)</cell><cell>0.823</cell><cell>0.748</cell><cell>0.773</cell><cell>0.745</cell><cell>0.772</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,181.87,312.50,251.62,53.72"><head>Table 4 :</head><label>4</label><figDesc>Final results of PAN 2020 authorship verification task.</figDesc><table coords="6,190.04,312.50,230.80,41.45"><row><cell>Training Dataset</cell><cell>AUC</cell><cell>c@1</cell><cell>f_05_u</cell><cell>F1</cell><cell>overall</cell></row><row><cell>Large</cell><cell>0.859</cell><cell>0.751</cell><cell>0.745</cell><cell>0.800</cell><cell>0.789</cell></row><row><cell>Small</cell><cell>0.874</cell><cell>0.770</cell><cell>0.762</cell><cell>0.811</cell><cell>0.804</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_0" coords="4,144.73,657.08,97.08,7.77"><p>https://www.tensorflow.org</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,142.61,264.76,159.80,7.77" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Organization</surname></persName>
		</author>
		<ptr target="https://pan.webis.de/" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,287.71,303.32,7.77;7,150.95,298.67,146.18,7.77" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,230.89,287.71,215.04,7.77;7,150.95,298.67,32.10,7.77">Applying authorship analysis to extremist-group web forum messages</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Abbasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Homeland Security</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,310.14,324.51,7.77;7,150.95,321.10,313.23,7.77;7,150.95,332.06,49.55,7.77" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,361.91,310.14,105.21,7.77;7,150.95,321.10,130.03,7.77">Signature verification using a &quot;siamese&quot; time delay neural network</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sickinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Shah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>American Telephone and Telegraph Company papers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,343.54,316.64,7.77;7,150.95,354.50,132.85,7.77" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="7,314.81,343.54,144.44,7.77;7,150.95,354.50,84.04,7.77">Fast and accurate deep network learning exponential linear units</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Clevert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,365.97,323.86,7.77" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="7,279.21,365.97,161.11,7.77">Deep residual learning for image recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,377.44,241.72,7.77" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="7,267.53,377.44,90.65,7.77">Long short-term memory</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,388.92,334.27,7.77;7,150.95,399.88,127.52,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,214.05,388.92,247.36,7.77">Author attribution in suicide notes: Evidence from applied linguistics</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jasim-Basim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,150.95,399.88,101.37,7.77">Comparative Legilinguistics</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,411.35,220.15,7.77" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<title level="m" coord="7,185.34,411.35,151.28,7.77">Especial Problems of Linguistic Forensics</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.24,422.83,334.17,7.77;7,150.95,433.78,329.64,7.77;7,150.95,444.74,316.30,7.77;7,150.95,455.70,206.68,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,234.75,433.78,245.84,7.77;7,150.95,444.74,16.14,7.77">Overview of the Cross-Domain Authorship Verification Task at PAN 2020</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="7,390.29,444.74,76.96,7.77;7,150.95,455.70,38.13,7.77">CLEF 2020 Labs and Workshops</title>
		<title level="s" coord="7,195.56,455.70,85.63,7.77">Notebook Papers. CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020-09">Sep 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.24,467.18,322.06,7.77;7,150.95,478.14,274.89,7.77" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="7,150.95,478.14,228.57,7.77">Overview of the cross-domain authorship attribution task at pan</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.24,489.61,320.22,7.77;7,150.95,500.57,302.43,7.77;7,150.95,511.53,200.54,7.77" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<title level="m" coord="7,199.28,500.57,254.10,7.77;7,150.95,511.53,174.40,7.77">Overview of the Author Identification Task at PAN-2018 cross-domain authorship attribution and style change detection</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.24,523.00,329.68,7.77;7,150.95,533.96,283.88,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,237.17,523.00,219.02,7.77">Determining if two documents are written by the same author</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Winter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,150.95,533.96,257.73,7.77">Journal of the American society for information science and technology</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.24,545.43,211.60,7.77" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m" coord="7,277.15,545.43,50.54,7.77">Deep learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.24,556.91,333.48,7.77;7,150.95,567.87,307.75,7.77;7,150.95,578.83,23.90,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,150.95,567.87,218.25,7.77">Backpropagation applied to handwritten zip code recognition</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">D</forename><surname>Jackel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,387.24,567.87,71.47,7.77">Neural computation</title>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.24,590.30,336.38,7.77;7,150.95,601.26,147.17,7.77" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="7,399.17,590.30,79.45,7.77;7,150.95,601.26,121.02,7.77">On the variance of the adaptive learning rate and beyond</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">C</forename><surname>Pengcheng He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Xiaodong Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.24,612.73,290.48,7.77;7,150.95,623.69,132.68,7.77" xml:id="b15">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Lopez-Velasco</surname></persName>
		</author>
		<title level="m" coord="7,219.95,612.73,212.76,7.77;7,150.95,623.69,106.53,7.77">Verificacíon de autoría en textos mediante redes neuronales convolucionales y recurrentes</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.24,635.17,329.01,7.77;7,150.95,646.13,318.50,7.77;7,150.95,657.08,77.11,7.77" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,446.34,635.17,24.91,7.77;7,150.95,646.13,282.92,7.77">Cic-gil approach to cross-domain authorship attribution: Notebook for pan at clef 2018</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Martín-Del-Campo-Rodríguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Gómez-Adorno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Batyrshin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,452.35,646.13,17.11,7.77;7,150.95,657.08,50.96,7.77">PAN working notes</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,119.96,338.35,7.77;8,150.95,130.92,300.54,7.77;8,150.95,141.88,322.31,7.77;8,150.95,152.84,192.98,7.77" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="8,295.94,141.88,144.73,7.77">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,446.86,141.88,26.40,7.77;8,150.95,152.84,110.80,7.77">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,163.80,325.23,7.77" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Potha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<title level="m" coord="8,245.35,163.80,195.98,7.77">Improving author verification based on topic modeling</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,174.76,335.40,7.77;8,150.95,185.71,306.17,7.77;8,150.95,196.67,72.72,7.77" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="8,333.86,174.76,140.16,7.77">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,259.53,185.71,193.52,7.77">Information Retrieval Evaluation in a Changing World</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09">Sep 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,207.63,330.80,7.77;8,150.95,218.59,308.16,7.77;8,150.95,229.55,165.11,7.77" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="8,399.57,207.63,73.47,7.77;8,150.95,218.59,129.38,7.77">Plagiarism detection with genetic-based parameter tuning</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Sanchez-Perez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Gómez-Adorno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,286.17,218.59,172.94,7.77;8,150.95,229.55,76.95,7.77">International Journal of Pattern Recognition and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page">1860006</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,240.51,290.64,7.77;8,150.95,251.47,76.81,7.77" xml:id="b21">
	<monogr>
		<title level="m" type="main" coord="8,249.48,240.51,183.40,7.77;8,150.95,251.47,50.66,7.77">Using compression-based language models for text categorization</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Teahan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">J</forename><surname>Harper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,262.43,336.48,7.77;8,150.95,273.39,26.15,7.77;8,150.95,284.34,301.68,7.77" xml:id="b22">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zaharia</surname></persName>
		</author>
		<ptr target="https://www.comparitech.com/vpn/cybersecurity-cyber-crime-statistics-facts-trends/" />
		<title level="m" coord="8,196.27,262.43,229.15,7.77">300+ terrifying cybercrime and cybersecurity statistics &amp; trends</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note>edition</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
