<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,150.07,148.82,306.48,16.08;1,175.03,166.34,245.57,16.08;1,210.10,186.79,175.37,12.00">Detecting Fake News Spreaders on Twitter Using Universal Sentence Encoder Notebook for PAN at CLEF 2020</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,213.22,224.68,117.65,9.16"><forename type="first">Soumayan</forename><forename type="middle">Bandhu</forename><surname>Majumder</surname></persName>
							<email>soumayanmajumder@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">Jadavpur University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,338.54,224.68,55.25,9.16"><forename type="first">Dipankar</forename><surname>Das</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">Jadavpur University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,150.07,148.82,306.48,16.08;1,175.03,166.34,245.57,16.08;1,210.10,186.79,175.37,12.00">Detecting Fake News Spreaders on Twitter Using Universal Sentence Encoder Notebook for PAN at CLEF 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B6FAEA3C2EC026DEB0F1DE0AA6CABA86</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the present attempt, we have developed a framework to detect the fake news spreaders on twitter by utilizing their tweets. Here, we have employed the pre-trained sentence embedding of Google and fed this embedding to a Long Short Term Memory (LSTM) based deep learning framework. Finally, the embedding is passed through an attention layer and predicts whether an author is prone to spread fake news or not. We have built models for two languages -English and Spanish. We have achieved 72% accuracy in this fake news spreader detection task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.44" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.44" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.44" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.44" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.44" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.44" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.44" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the present work, we have developed techniques to detect profiles of fake news spreaders. Fake news detection is becoming one of the challenging tasks of recent years. However, in this present task, instead of detecting fake news, we are concentrating on detecting it at user level. Thus, in order to accomplish our goals, we handle tweets at chunk level instead of handling each tweet, because here we have to detect the author of fake news, not the news type.</p><p>We participated in the profiling fake news spreader shared task <ref type="bibr" coords="1,427.85,474.22,16.80,9.07" target="#b13">[14]</ref> under PAN workshop and the organizers provided us the dataset. We have used a pretrained word embedding and fed it into the LSTM with attention based deep learning framework to achieve the desired output. The systems were hosted and evaluated on TIRA <ref type="bibr" coords="1,151.03,520.06,15.46,9.07" target="#b14">[15]</ref>, a web service that aims to facilitate software submissions and evaluations for shared tasks. Here we first use the universal sentence encoder of Google for converting texts to embedding then pass each authors tweet one by one into the LSTM network, here we will send tweets of each author in different time stamps one by one. After that send this output to attention layer to know the importance of each tweet and at last pass it through the sigmoid activation layer.</p><p>The rest of the paper is organized as follows. Related work on this particular topic is discussed in Section 2 whereas Section 3 briefly shows the insights of the datasets. Section 4 describes the method we used to detect the fake author and also describes our models and proposed architecture in depth. Section 5 is dedicated to experiments and results. Finally, in Section 6, we present the conclusions and briefly discuss about future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Fake news is currently one of the hottest topics of last four to five years and many researches are being conducted in this field. Some of the researchers suggest solving the fake news detection problem using the content of the news and some suggest detecting it based on the social context. Therefore, we can detect fake news in two waysa) news content model, and b) social context model. In case of news content model, we can detect fake news in two waysa) knowledge based detection, and b) style based detection. In knowledge based detection, we generally check the news content or extract the knowledge from the news or other repositories and compare it with the authentic news sites whereas in case of style based detection, we focus on the writing styles instead of the news content or knowledge. Here, we mainly focus on the linguistic features and readability features of the news. In social content model, we can detect fake news also in two waysa) propagation based techniques, and b) credibility based techniques. In propagation based techniques, we find various news propagated on the social media and track the original news based on such propagated news. In credibility based technique, we have to find the relationship between news article and users, publishers, posts, comments etc.</p><p>George et. al. <ref type="bibr" coords="2,217.06,361.38,11.52,9.07" target="#b0">[1]</ref> analyse the influence of linguistic properties and contextual features in detecting fake news by using different type of techniques like Naïve Bayes, SVM, KNN etc. Perez-Rosas et. al. <ref type="bibr" coords="2,309.00,384.20,11.75,9.07" target="#b1">[2]</ref> here cover seven different types of news domains and analyse linguistic differences in fake and real news and also compare different domain characteristics. Bedi et. al. <ref type="bibr" coords="2,364.86,407.24,11.52,9.07" target="#b3">[4]</ref> use authorized news database to verify fake news and real news. Dey et. al. <ref type="bibr" coords="2,353.79,418.76,11.75,9.07" target="#b4">[5]</ref> do feature extraction and analyse the linguistic patterns and then apply KNN algorithm to classify news. Uppal et. al. <ref type="bibr" coords="2,149.53,441.80,11.52,9.07" target="#b6">[7]</ref> propose discourse level analysis for deception detection of news documents.</p><p>However, one problem with these above mentioned techniques is that they detect the fake news after it spreads on social media. But, if we can detect it from the source, this problem can be avoided. So, one of our aims should be to detect the author of the fake news. Already, there are some works on fake news spreader detection <ref type="bibr" coords="2,165.19,499.42,15.26,9.07" target="#b9">[10]</ref>. But, it is applied only in English language. So, in this paper, we are going to implement it in both English and Spanish languages and we have used some different embedding techniques instead of GLOVE embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset</head><p>We participated in the profiling fake news spreader shared task of the PAN workshop at the CLEF (Conference and Labs of the Evaluation Forum) 2020 conference. In this task, the dataset was provided by the shared task organizers. We are given with hundred tweets of each author and a total of 300 authors tweets have been given to us for training. For each English and Spanish language, we are given 300 authors tweet (100 tweets for each author) to train the model. For evaluation, we have to submit our software to the TIRA infrastructure and after that we have to execute it on the test dataset. We have given snapshots of some tweets of both English and Spanish language from my training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spanish tweets of an author</head><p>English tweets of an author</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methods</head><p>Pre-processing: Here, we first tried to conduct some text pre-processing techniques on the tweets by removing everything except letters from 'a'-'z' and 'A' -'Z'. We have also removed all the urls and html tags or elements present in the tweets. Finally, we removed all types of emoji or emoticons present in the tweets. We send this preprocessed data to a universal-sentence-encoder. But, we observed that the universalsentence-encoder performs better if we send those tweets in raw form rather than preprocessed form. Thus, we choose to use those tweets without pre-processing.</p><p>LSTM Framework: Here, we have implemented embedding of our tweets and then passed it through the LSTM layer and then attention layer and predicted the output lastly through the sigmoid activation function. Here, we have used sentence embedding, instead of word embedding. We have employed universal-sentenceencoder-xling_en_es_1 (This is a cross lingual module and an extension of the normal universal sentence encoder). We also tried with universal-sentence-encodermultilingual-large-v3, but as this shared task is specifically for English and Spanish language, we choose universal-sentence-encoder-xling_en_es_1 (which is specifically trained for English and Spanish language) which can handle 16 languages including English and Spanish. We named it as Universal Sentence Encoder or U.S.E., interchangeably.</p><p>One feature of this universal sentence encoder is that it always gives output of a 512 dimension vector whatever be the input is. Here, we are given with the tweets of an author as the input to the U.S.E. and it produces 512 dimension vector. Thus, for each of the authors, we are getting an output of (100 x 512) dimensional vector output, as we have 100 tweets of each author. As we have 300 such authors in both English and Spanish languages for training our model, we developed a LSTM network with 128 units. The overall framework takes 512 features at a time and contains 100 such timestamps. In order to avoid over fitting, we have also used dropout of 0.3 and recurrent dropout of 0.2. We tried with different hyper-parameters but these two gives the best result. We also tried with different batch-sizes such as 16, 32 and 64 but we choose 64 among these. In the present framework, we tried to train both the languages differently and then used to train both the language jointly. At first, we used any of these two sentence embedding -1) U.S.E. multilingual large-v3 (version 3) and 2) U.S.E. xling_en_es-1. After that, we feed those outputs to the LSTM network. Because, we aimed to capture long term dependency through LSTM. However, in some cases, it is forgetful and does not know which input should be given more or less importance.</p><p>For example (from twitter) -"Breaking News: Tom Hanks and his wife Rita Wilson announced Wednesday that they have tested positive for the coronavirus". Here, to predict the word "coronavirus", we should give more emphasis to "tested" and "positive" instead of "Tom Hanks" or "Rita Wilson". So, here we have to give relative importance to each of the words instead of giving them same importance. Therefore, we have applied the attention model which is presented in the Bahdanu's paper <ref type="bibr" coords="4,151.75,442.28,10.53,9.07" target="#b7">[8]</ref>. But here we are applying this in sentence level instead of word level. Because here some news or tweets of an author are fake and some are real. Finally, we feed that output of the attention layer to the sigmoid activation unit. We then compile our model using adam optimizer and used binary_crossentropy as loss function. As both the classes are balanced, we considered accuracy as our evaluation metric to measure the performances of our models. We implemented the above mentioned models with universal sentence encoder multilingual large and universal sentence encoder-xling-en_es-1. We also tried to train both the languages separately and jointly with different batch sizes. But, as we mentioned earlier, we don't have access of test set and we have to submit our model to TIRA infrastructure. Then it will automatically do evaluation of our model on blinded test set. The performance of our system is measured by accuracy as the two classes are balanced. Here, we have to measure individual accuracies of each language and then finally average the accuracy values of each language to obtain the final accuracy. On the other hand, if we do average of the above two validation accuracies, we achieved around 71% accuracy. Thus, finally, we choose universal sentence encoder xling-en_es-1 trained on both the languages with batch size of 64 over the other models as its validation accuracy is 81.50%. When we submit our final model which uses Universal Sentence Encoder xling-en_es-1 and trained on both the languages jointly with the batch size of 64 to TIRA for evaluation on hidden test set, we get an accuracy of 64% in English language and 80% accuracy on Spanish language, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Encoder</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We achieved 64% accuracy in English language fake author detection task, which says that there is a scope of lot to improve and there is some issue of overfitting too though we used dropout and recurrent dropout at the time of training the model. Thus, in future, we should take this note to improve this model. If we want to use this software in real life then how will it perform much depends on how the test dataset of shared task of reflects the real world dataset. We achieve 80% accuracy in Spanish language author detection task, which is quite satisfactory, but again if we want to implement this software in real world, then its performance totally depends on how much test dataset of PAN shared task reflects the real world dataset. We can also use different types of embedding in future for this task like BERT, but main disadvantage of BERT is that it can take maximum 512 words at a time, so there is a constraint. However, we will plan some reliable frameworks to handle the issues.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,222.82,285.54,149.41,7.13;4,124.80,204.95,345.60,69.60"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: How we send data to LSTM network</figDesc><graphic coords="4,124.80,204.95,345.60,69.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,172.39,656.94,250.33,7.13;4,124.80,520.55,303.10,134.40"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Architecture of our model, Here each Si is a 512 dimensional vector.</figDesc><graphic coords="4,124.80,520.55,303.10,134.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,124.85,320.82,346.02,313.24"><head>Table 1 :</head><label>1</label><figDesc>Accuracy of each model with different encoder and different batch size trained on both languages Therefore, for experimenting with different models or architecture, we split our dataset into training set and evaluation set. It was observed that when we train both the language jointly, we split data in the ratio of 8:2. So, 480 authors feeds (each author has 100 tweets) were used for training and 120 authors data were used for validation (check the above mentioned table). From the above table we are getting maximum 81.50% accuracy. In case we train each language differently, we have used 270 authors data for training and 30 authors data for validation (check the below mentioned table).</figDesc><table coords="5,124.85,320.82,338.22,313.24"><row><cell></cell><cell></cell><cell cols="2">Batch</cell><cell cols="2">Number</cell><cell>Number</cell><cell>Accuracy</cell></row><row><cell></cell><cell></cell><cell>size</cell><cell></cell><cell cols="2">of Train</cell><cell>of</cell><cell>(in %)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">data</cell><cell>validation</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>data</cell></row><row><cell cols="2">U.S.E. multilingual</cell><cell>16</cell><cell></cell><cell cols="2">480</cell><cell>120</cell><cell>77.50</cell></row><row><cell cols="2">U.S.E. multilingual</cell><cell>32</cell><cell></cell><cell cols="2">480</cell><cell>120</cell><cell>74.90</cell></row><row><cell cols="2">U.S.E. multilingual</cell><cell>64</cell><cell></cell><cell cols="2">480</cell><cell>120</cell><cell>74.75</cell></row><row><cell cols="2">U.S.E. xling en_es-1</cell><cell>16</cell><cell></cell><cell cols="2">480</cell><cell>120</cell><cell>80.83</cell></row><row><cell cols="2">U.S.E. xling en_es-1</cell><cell>32</cell><cell></cell><cell cols="2">480</cell><cell>120</cell><cell>77.50</cell></row><row><cell cols="2">U.S.E. xling en_es-1</cell><cell>64</cell><cell></cell><cell cols="2">480</cell><cell>120</cell><cell>81.50</cell></row><row><cell>Encoder</cell><cell cols="2">Language</cell><cell cols="2">Batch</cell><cell cols="2">Number</cell><cell>Number</cell><cell>Accuracy</cell></row><row><cell></cell><cell></cell><cell></cell><cell>size</cell><cell></cell><cell cols="2">of train</cell><cell>of</cell><cell>(in %)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>data</cell><cell>validation</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>data</cell></row><row><cell>U.S.E. multilingual</cell><cell>English</cell><cell></cell><cell>16</cell><cell></cell><cell>270</cell><cell>30</cell><cell>63.33</cell></row><row><cell>U.S.E. multilingual</cell><cell>Spanish</cell><cell></cell><cell>16</cell><cell></cell><cell>270</cell><cell>30</cell><cell>80.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,186.31,636.78,222.87,7.13"><head>Table 2 :</head><label>2</label><figDesc>Accuracy of each model trained on two languages separately</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,139.97,428.12,330.79,9.07;6,124.85,439.40,345.94,9.07;6,124.85,450.92,342.92,9.07" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,356.28,428.12,114.49,9.07;6,124.85,439.40,148.02,9.07">Role of Contextual Features in Fake News Detection: A Review</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Skariah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Xavier</surname></persName>
		</author>
		<idno type="DOI">10.1109/icitiit49094.2020.9071524</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,304.91,439.40,165.88,9.07;6,124.85,450.92,176.90,9.07">International Conference On Innovative Trends In Information Technology (ICITIIT)</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,140.21,473.98,330.72,9.07;6,124.85,485.50,345.94,9.07;6,124.85,497.02,345.54,9.07;6,124.85,508.54,173.27,9.07" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,428.81,473.98,42.12,9.07;6,124.85,485.50,99.90,9.07">Automatic Detection of Fake News</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>P´erez-Rosas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lefevre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,247.54,485.50,223.25,9.07;6,124.85,497.02,113.05,9.07">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3391" to="3401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,139.25,533.98,57.89,9.07;6,226.27,533.98,241.04,9.07;6,124.85,545.29,340.98,9.07;6,124.85,556.81,192.17,9.07" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,338.26,533.98,129.05,9.07;6,124.85,545.29,148.75,9.07">Exploiting Multi-domain Visual Information for Fake News Detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename></persName>
		</author>
		<idno type="DOI">10.1109/icdm.2019.00062</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,303.00,545.29,162.83,9.07;6,124.85,556.81,61.21,9.07">IEEE International Conference On Data Mining (ICDM)</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,139.24,579.85,331.30,9.07;6,124.85,591.37,345.80,9.07;6,124.85,602.89,345.88,9.07;6,124.85,614.41,141.56,9.07" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,310.43,579.85,160.11,9.07;6,124.85,591.37,240.15,9.07">A Framework to Identify and secure the Issues of Fake News and Rumours in Social Networking</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bedi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Khatri</surname></persName>
		</author>
		<idno type="DOI">10.1109/peeic47157.2019.8976800</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,396.84,591.37,73.81,9.07;6,124.85,602.89,321.47,9.07">2Nd International Conference On Power Energy, Environment And Intelligent Control (PEEIC)</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,140.68,637.47,330.27,9.07;6,124.85,648.99,346.00,9.07;6,124.85,660.51,345.79,9.07;6,124.85,671.79,345.88,9.07;6,124.85,683.31,114.97,9.07" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,451.60,637.47,19.34,9.07;6,124.85,648.99,217.29,9.07">Fake News Pattern Recognition using Linguistic Analysis</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Rafi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hasan Parash</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Arko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chakrabarty</surname></persName>
		</author>
		<idno type="DOI">10.1109/iciev.2018.8641018</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,373.80,648.99,97.05,9.07;6,124.85,660.51,345.79,9.07;6,124.85,671.79,322.26,9.07">Joint 7Th International Conference On Informatics, Electronics &amp; Vision (ICIEV) And 2018 2Nd International Conference On Imaging, Vision &amp; Pattern Recognition (Icivpr)</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,141.16,161.17,329.47,9.07;7,124.85,172.69,345.98,9.07;7,124.85,184.21,241.62,9.07" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,330.81,161.17,139.81,9.07;7,124.85,172.69,131.34,9.07">Fraudulent News Detection using Machine Learning Approaches</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Rajesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kadu</surname></persName>
		</author>
		<idno type="DOI">10.1109/gcat47503.2019.8978436</idno>
	</analytic>
	<monogr>
		<title level="m" coord="7,290.73,172.69,180.10,9.07;7,124.85,184.21,78.97,9.07">Global Conference For Advancement In Technology (GCAT)</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.12,207.27,328.83,9.07;7,124.85,218.79,346.00,9.07;7,124.85,230.07,47.15,9.07;7,192.28,230.07,19.91,9.07;7,232.33,230.07,30.37,9.07;7,282.94,230.07,7.84,9.07;7,310.78,230.07,49.39,9.07;7,380.32,230.07,54.85,9.07;7,455.44,230.07,15.51,9.07;7,124.85,241.59,164.35,9.07" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,356.26,207.27,114.68,9.07;7,124.85,218.79,146.67,9.07">Fake news detection using discourse segment structure analysis</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Uppal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sachdeva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<idno type="DOI">10.1109/confluence47617.2020.9058106</idno>
	</analytic>
	<monogr>
		<title level="m" coord="7,301.54,218.79,169.30,9.07;7,124.85,230.07,42.44,9.07">10Th International Conference On Cloud Computing</title>
		<meeting><address><addrLine>Confluence</addrLine></address></meeting>
		<imprint>
			<publisher>Data Science &amp; Engineering</publisher>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,141.16,264.63,329.73,9.07;7,124.85,276.15,160.53,9.07" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="7,340.20,264.63,130.69,9.07;7,124.85,276.15,156.56,9.07">Neural Machine Translation by Jointly Learning to Align and Translate</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,139.25,301.62,331.65,9.07;7,124.85,312.90,345.93,9.07;7,124.85,324.42,345.54,9.07;7,124.85,335.94,172.78,9.07" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,367.41,301.62,103.49,9.07;7,124.85,312.90,91.65,9.07">Multi-Source Multi-Class Fake News Detection</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Saba-Sadiya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,237.70,312.90,233.08,9.07;7,124.85,324.42,113.11,9.07">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1546" to="1557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,144.29,358.98,326.25,9.07;7,124.85,370.52,345.79,9.07;7,124.85,382.04,346.04,9.07;7,124.85,393.56,345.55,9.07;7,124.85,405.08,346.06,9.07;7,124.85,416.60,315.36,9.07" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,454.79,358.98,15.75,9.07;7,124.85,370.52,345.79,9.07;7,124.85,382.04,129.59,9.07">The Role of Personality and Linguistic Patterns in Discriminating Between Fake News Spreaders and Fact Checkers</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Ríssola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-51310-8_17</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-51310-8_17" />
	</analytic>
	<monogr>
		<title level="m" coord="7,261.70,382.04,209.19,9.07;7,124.85,393.56,345.55,9.07;7,124.85,405.08,145.56,9.07">Natural Language Processing and Information Systems: 25th International Conference on Applications of Natural Language to Information Systems, NLDB 2020</title>
		<meeting><address><addrLine>Saarbrücken, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-06-24">2020. June 24-26, 2020</date>
			<biblScope unit="volume">12089</biblScope>
			<biblScope unit="page" from="181" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,145.96,439.40,324.79,9.07;7,124.85,450.92,345.97,9.07;7,124.85,462.46,26.71,9.07;7,172.59,462.46,61.66,9.07;7,255.19,462.46,31.27,9.07;7,307.24,462.46,60.22,9.07;7,388.45,462.46,45.76,9.07;7,455.18,462.46,15.51,9.07;7,124.85,473.98,111.57,9.07" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,157.00,450.92,313.83,9.07;7,124.85,462.46,26.71,9.07;7,172.59,462.46,32.63,9.07">Classification of Hand Movements From EEG Using a Deep Attention-Based LSTM Network</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Davoodnia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sepas-Moghaddam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Etemad</surname></persName>
		</author>
		<idno type="DOI">10.1109/jsen.2019.2956998</idno>
	</analytic>
	<monogr>
		<title level="j" coord="7,212.74,462.46,21.51,9.07;7,255.19,462.46,31.27,9.07;7,307.24,462.46,29.38,9.07">IEEE Sensors Journal</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3113" to="3122" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,146.44,497.02,324.31,9.07;7,124.85,508.54,345.58,9.07" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,302.04,497.02,168.71,9.07;7,124.85,508.54,52.70,9.07">Twitter User Profiling: Bot and Gender Identification</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kosmajac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Keselj</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="7,194.71,508.54,131.00,9.07">CLEF 2019 Labs and Workshops</title>
		<title level="s" coord="7,332.89,508.54,95.55,9.07">Notebook Papers. CEUR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,145.01,531.47,325.86,9.17;7,124.85,543.13,345.59,9.07" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,230.02,531.58,240.85,9.07;7,124.85,543.13,52.48,9.07">Detecting Bot Accounts on Twitter by Measuring Message Predictability</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Przybyła</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="7,194.71,543.13,131.00,9.07">CLEF 2019 Labs and Workshops</title>
		<title level="s" coord="7,333.12,543.13,95.33,9.07">Notebook Papers. CEUR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,146.45,566.17,324.47,9.07;7,124.85,577.45,345.86,9.07;7,124.85,588.97,346.10,9.07;7,124.85,600.49,311.75,9.07" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,401.93,566.17,68.99,9.07;7,124.85,577.45,341.88,9.07">Overview of the 8th Author Profiling Task at PAN 2020: Profiling Fake News Spreaders on Twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="7,381.96,588.97,88.99,9.07;7,124.85,600.49,42.22,9.07">CLEF 2020 Labs and Workshops</title>
		<title level="s" coord="7,174.50,600.49,223.88,9.07">Notebook Papers. CEUR Workshop Proceedings.CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,145.49,623.55,325.28,9.07;7,124.85,635.07,346.02,9.07;7,124.85,646.59,345.56,9.07" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,403.13,623.55,67.64,9.07;7,124.85,635.07,92.50,9.07">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,379.10,635.07,91.77,9.07;7,124.85,646.59,300.62,9.07">Information Retrieval Evaluation in a Changing World -Lessons Learned from 20 Years of CLEF</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
