<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,195.99,115.90,223.38,12.90;1,223.43,135.96,168.50,10.75">Style Change Detection Using BERT Notebook for PAN at CLEF 2020</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,239.15,172.57,45.09,8.64"><forename type="first">Aarish</forename><surname>Iyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Dartmouth College</orgName>
								<address>
									<postCode>03755</postCode>
									<settlement>Hanover</settlement>
									<region>NH</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,303.60,172.57,72.61,8.64"><forename type="first">Soroush</forename><surname>Vosoughi</surname></persName>
							<email>soroush.vosoughi@dartmouth.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Dartmouth College</orgName>
								<address>
									<postCode>03755</postCode>
									<settlement>Hanover</settlement>
									<region>NH</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,195.99,115.90,223.38,12.90;1,223.43,135.96,168.50,10.75">Style Change Detection Using BERT Notebook for PAN at CLEF 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">ACA4A06C0B5BADE0957781479723BE4D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Style Change Detection</term>
					<term>BERT</term>
					<term>Transfomer-based Models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Style Change Detection task is very important in the area of authorship profiling, having one of its main applications in plagiarism detection. Specifically, the goal of the task is to detect where (if any) stylistic changes happen in a document which can be used to estimate the number of authors of a given document. In this paper, we present a method for Style Change Detection. We use Google AI's open source BERT pretrained bidirectional models to tokenize and generate embeddings for the sentences in each document in our dataset and use those to train a random forest classifier. We achieved an F1 score of 0.86 for detecting style changes and an F1 score of 0.64 for detecting multi-author documents on the test set, placing us at the top of the competition for both tasks. The code for this project has been made open source so that it can be used for further research: https://github.com/aarish407/ Style-Change-Detection-Using-BERT</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Detecting the number of authors involved in writing document by analyzing the writing style is an important task that has been a focus of research for centuries. This area of research has traditionally been called Stylometry and is defined by the Oxford dictionary as, "the statistical analysis of variations in literary style between one writer or genre and another". It is a centuries-old practice, dating back to the early Renaissance. Its applications include plagiarism detection and forensics (e.g., Vosoughi et al. <ref type="bibr" coords="1,447.53,530.97,16.60,8.64" target="#b11">[12]</ref> use computational stylometry techniques to link social media accounts operated by the same user). The main principles of stylometry were compiled and laid out by the philosopher Wincenty Lutosawski in 1890 in his work "Principes de stylomtrie" <ref type="bibr" coords="1,406.60,566.83,10.58,8.64" target="#b5">[6]</ref>.</p><p>Unsurprisingly, style understanding has become one of the core areas of research in natural language understanding, leading to the proposal of various computational methods for understanding and detecting style in written text (e.g., see <ref type="bibr" coords="1,405.24,602.91,11.62,8.64" target="#b6">[7]</ref> for a review of the field of authorship attribution). Accordingly, this has become of one of the staple tasks at PAN. The work presented in this paper was developed as a solution to the Style Change Detection task for the competition PAN @ CLEF 2020 <ref type="bibr" coords="2,395.59,131.27,10.79,8.64" target="#b1">[2,</ref><ref type="bibr" coords="2,406.38,131.27,7.19,8.64" target="#b8">9]</ref>. The task is described as follows: Given a document, determine whether it has been written by more than one author (task 1). Furthermore, for a multi-author document, identify the positions in the document where the style change occurred (task 2). It is assumed that each paragraph is written by only one author, thus style change can only occur between two paragraphs. All the documents are in English and each document is written by one to three authors and can contain from zero to ten style changes. This is more complicated than the recent editions of the Style Change Detection tasks as those were either binary detection of single-/multi-authored documents <ref type="bibr" coords="2,324.50,226.91,16.60,8.64" target="#b9">[10,</ref><ref type="bibr" coords="2,341.10,226.91,12.45,8.64" target="#b10">11]</ref> or detecting the actual number of authors in a document <ref type="bibr" coords="2,236.31,238.86,15.27,8.64" target="#b12">[13]</ref>.</p><p>In this paper, we present a solution for this task using a Random Forest classifier in conjunction with embeddings generated by BERT, an open source large-scale pretrained language model developed by Google AI. The remaining of the paper is organized as follows. First, we introduce the dataset, next we describe our approach, including all data cleaning and pre-processing steps. Next, we describe our experiments and results. Finally, we wrap up by discussing future work and summarizing our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset</head><p>There were two types of datasets <ref type="bibr" coords="2,268.41,364.67,11.62,8.64" target="#b2">[3]</ref> that were provided for this task -a narrow dataset and wide dataset. The narrow dataset comprised of documents from similar domains, while the wide dataset did not have any restriction on its contents. For each document in each dataset there was an appropriate truth file given that had a label for task 1 (whether the document was written by more than one author) and a changes array for the task 2 (a list of 1s and 0s indicating if style change occurred between consecutive paragraphs). The F1 metric was used to calculate the score for task 1, and the micro-averaged F1 metric was used to calculate the score for task 2. Both the metrics will be referred to as accuracy hereafter. The results of both datasets were evaluated independently, and were then averaged to produce a final score for each task. The final score was calculated on the test dataset. Both the narrow and wide datasets were mined from the Stack family of websites.</p><p>Here is some information about the dataset:</p><p>1. Table <ref type="table" coords="2,175.69,528.76,4.98,8.64" target="#tab_0">1</ref> shows the number of documents in the narrow and wide train and validation sets. For each document, there was an appropriate truth file. 2. Table <ref type="table" coords="2,176.75,552.45,4.98,8.64" target="#tab_1">2</ref> shows the statistics of number of sentences and number of paragraphs in each document for the train narrow and wide datasets. 3. The truth files had the following data: number of authors, order of authors, source site and the results for task 1 and 2. For our solution, we did not make use of the first three keys. 4. Figures <ref type="figure" coords="2,184.92,611.80,9.40,8.64" target="#fig_1">1a</ref> and<ref type="figure" coords="2,215.35,611.80,9.96,8.64" target="#fig_1">1b</ref> show the distribution of number of style changes for the train narrow and wide datasets. 5. All datasets were balanced for task 1, i.e., detecting if a document is written by more than one author.    3 Approach</p><p>The general approach to both tasks was to generate embeddings of the words in each document at the sentence level and then use these embeddings for the classification. This is highlighted in Fig. <ref type="figure" coords="3,242.99,567.36,3.74,8.64">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Paragraph split</head><p>The first step was to split each document into paragraphs, since paragraphs are guaranteed to be atomic (i.e., only a single author has written a paragraph). This is important as the second task involves identifying style change between consecutive paragraphs.</p><p>Figure <ref type="figure" coords="4,162.44,262.97,3.88,8.64">2</ref>: Our approach for generating feature vectors for the two tasks using pretrained BERT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sentence Split</head><p>On first thought, the idea of splitting the paragraphs into sentences seems fairly straightforward -split on characters such as '.', '?' and '!'. However, a lot of sentences would be generated that weren't sentences originally. For example, the prefixes 'Dr.' or 'Mr.' would have their own sentences. Thus, it was important to ensure that the sentences were split in a manner that is robust to the variations in usage of the aforementioned punctuation marks. A regular expression approach was used, for which each occurrence of "." which was not meant as a sentence delimiter is identified and replaced with a special token. The following structures were identified and replaced accordingly:</p><p>-Prefixes (Mr., Mrs., Dr., Ms., Prof., Capt., Cpt., Lt., Mt.) -Website domains (.com, .net, .org, .io, .gov, .me, .edu) -Acronyms (U.S.A., etc.) -Suffixes (Inc., Ltd., Jr., Sr., Co.) -Abbreviations (e.g., i.e., ...) -Any digits separated by a period</p><p>The above approach doesn't take into consideration the different usage of '.', ',', '?' and '!' written in code, which is likely to come up in a dataset mined from the Stack family of websites. This can be added in the future to further improve this solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Embeddings</head><p>Before generating the embeddings, the sentence had to first be tokenized, which was done by using Google AI's BERT <ref type="bibr" coords="4,275.15,608.47,11.62,8.64" target="#b0">[1]</ref> tokenizer (the type of tokenizer depends on the BERT model used, which is described below). Note that BERT can only process sentences of length &lt;= 512 tokens.</p><p>In order to generate embeddings for the tokenized sentences, Google AI's BERT <ref type="bibr" coords="4,134.77,656.44,11.62,8.64" target="#b0">[1]</ref> pretrained deep bidirectional models were used. BERT offers various models, and for this task, the BERT Base Cased model was used (layers=12, hidden size=768, selfattention heads=12, total parameters=110M). The authors of BERT recommend that the BERT Base Uncased model should be used for most situations, unless it is certain that having a case-sensitive model would aid the task. We were able to report a 0.94% increase in the accuracy for the first task for the Wide dataset between the Cased and Uncased models, and thus the Cased model was used for the other tasks as well. The BERT Large model (layers=24, hidden size=1024, self-attention heads=16, total parameters=340M) was not explored for this work due to its computationally intensive nature. Furthermore, the BERT Large model in most cases only reported a 1-2% increase in accuracy over the BERT Base model on other NLP benchmarks <ref type="bibr" coords="5,436.40,226.91,10.58,8.64" target="#b0">[1]</ref>.</p><p>Although BERT is used to capture context rather than style, the authors of this work found out that the information captured by these embeddings works well for the style change detection task as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Processing of the Dataset</head><p>Although BERT was used to generate the embeddings, they had to be combined in a specific way to fit both the tasks. The following is the method followed:</p><p>1. Each individual sentence was processed by the BERT Tokenizer, and truncated to 512 tokens if needed. 2. The tokenized sentence was then processed by BERT, which generated embeddings for each layer. This generated a tensor of dimensions 12 × l × 768, where l is the length of the sentence. 3. The authors of BERT found out that the best results were obtained when the embeddings of the last 4 layers were combined, either by summing them, producing a tensor of dimensions l × 768, or by concatenating them and producing a tensor of dimensions l × 3072. We chose to sum the embeddings of the last 4 layers in order to prevent the dimensions of the tensor from becoming too big. Thus the final dimensions of the tensor at this step are l × 768. 4. The first dimension of the current tensor is the length of the sentence, and can thus change from sentence to sentence. In order to prevent this, the embeddings of the sentence are summed over the first dimension, thus producing a final vector of length 768. Summing the embeddings over the first dimension as opposed to averaging them can lead to large difference in embedding values between sentences that are long and short. However, the length of a sentence is an important factor in detecting style change, and thus it is important to capture that information.</p><p>At this stage, we change our approach of combining embeddings for the two tasks.</p><p>Detecting style change at the document-level (Task 1) To produce a final tensor for the whole document, all the sentence vectors of the document were averaged. At the document-level, the following approaches were tested:</p><p>1. Generate the sentence vectors by summing the embeddings over the length dimension + summing all the sentence vectors of the document to produce a documentlevel tensor 2. Generate the sentence vectors by summing the embeddings over the length dimension + averaging all the sentence vectors of the document to produce a documentlevel tensor 3. Generate the sentence vectors by averaging the embeddings over the length dimension + summing all the sentence vectors of the document to produce a documentlevel tensor 4. Generate the sentence vectors by averaging the embeddings over the length dimension + averaging all the sentence vectors of the document to produce a documentlevel tensor</p><p>The second approach produced the best results for the style change detection task at the document-level. We have described why summing the embeddings over the length dimension as opposed to averaging them works better. While producing the documentlevel tensor, averaging all the sentence vectors seems to work better. This can be attributed to the fact that the length of the document doesn't really factor into determining whether or not style change occurred in the document, as all style changes occur between paragraphs. Thus, it makes no difference if the document is relatively short or long, as long as it has at least two paragraphs. Thus, there is no need to capture this information. It must be noted that the difference in accuracy for all four approaches was within 2% for the validation wide dataset.</p><p>Detecting style change at the paragraph-level (Task 2) Since style change had to be determined between paragraphs, the paragraph-level data points were calculated by averaging the embeddings of two consecutive paragraphs. Thus, the data point was generated by adding the embeddings of all sentences in both paragraphs and then dividing it by the sum of both paragraph lengths (in sentences). The labels were the entries in the changes array of the truth file. It is important to note that the labels of the paragraphlevel data points are now imbalanced, as a document with no style change will have all paragraph-level labels as 0, while a document with style-change may still have some consecutive paragraphs that were written by the same author, and thus the labels for those data points would also be 0.</p><p>After this step, we essentially have two datasets -one with data points at the documentlevel and the other with data points at the paragraph-level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Classifier</head><p>Using Python's off-the-shelf ML library Scikit-learn <ref type="bibr" coords="6,354.33,548.84,10.58,8.64" target="#b7">[8]</ref>, various supervised models were tested for binary classification, such as Logistic Regression, Decision Trees, Random Forest, Support Vector Machines and Naive Baye's (Multinomial and Gaussian). The Random Forest classifier produced the best results by far for both tasks and on both data sets. Furthermore, once the Random Forest classifier was decided upon, a grid search on the hyperparameters was performed (for both tasks and both datasets) which increased the accuracy by almost 3%. However, the number of estimators for the grid-searched classifier was significantly larger than the default number of estimators, which in turn increased the time the classifier took to generate predictions on the validation set.</p><p>Finally, we had 4 classifiers:</p><p>1. Document-level classifier for the wide dataset. 2. Document-level classifier for the narrow dataset.  4 Results</p><p>Here we show the performance of our model on the validation and test sets. The validation set was made available during the development of the model, while the test results show the performance of our model in the competition. Table <ref type="table" coords="7,173.71,418.06,4.98,8.64">4</ref> shows the performance of our model on the validation set and Table <ref type="table" coords="7,448.85,418.06,4.98,8.64" target="#tab_3">5</ref> shows the performance of our model on the test set. Note that for the test set, we only have cumulative information of the two datasets for the two tasks Table <ref type="table" coords="7,160.51,493.99,3.88,8.64">4</ref>: F1 scores calculated on the validation set for Document-level (task 1) and Paragraph-level (task 2) predictions.</p><p>Narrow Wide Document-level 0.7661 0.7575 Paragraph-level 0.8805 0.8306 As can be observed, there is a discrepancy between the results reported on the test set and the validation set. This is because of the difference between the environments in which both the tests were carried out. During the development of this project, the BERT model was run using a GPU, which greatly increased the speed of computation. However, since the virtual machine offered by TIRA did not provide a GPU, all computations were significantly slower. The authors of this paper decide to clip the computations after a certain time in order to prevent the session from crashing and not being able to submit our solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Other Approaches &amp; Future Work</head><p>During the course of this project, a number of different approaches were tried. For those approaches, a unique dataset was generated, where each data point was a combination of two sentences from consecutive paragraphs of a document. Thus, if the sentences were from the same paragraph, then the corresponding label would be 0, while two sentences from different paragraphs would have a label of 1 if there was a style change between the two paragraphs. This approach is also susceptible to producing an imbalanced dataset, and hence the dataset was balanced before moving on with the classification task. The dataset produced had nearly 3 million data points by just using the wide dataset. A couple of the approaches have been described below:</p><p>Fine-Tuning BERT In this method, the goal was to fine tune BERT using the training data so that it could produce results that were at par or better than the submitted solution. However, it was empirically observed that accuracy plateaued after a point, and was thus not explored further.</p><p>Convolutional Neural Network This method is inspired by prior work on sentence classification using convolutional neural networks <ref type="bibr" coords="8,338.52,524.93,10.58,8.64" target="#b4">[5]</ref>. In this method, each data point had dimensions (l1 + l2) × 768 where l1 and l2 are the lengths of the two sentences. Note is that the data points were allowed to have variable lengths (as long as their individual lengths were &lt;= 512). The tensors were then passed through a set of parallel convolutional filters, with Kernel sizes of (2, 768), (3, 768), ..., <ref type="bibr" coords="8,393.52,572.43,11.62,8.74" target="#b4">(5,</ref><ref type="bibr" coords="8,406.81,572.43,18.82,8.74">768)</ref> . These were meant to capture n-gram stylistic features (i.e., bigrams, trigrams, etc). The results after applying all convolution filters were globally pooled and then combined to form a vector of length n where n is the number of convolutional filters. At the end, a Fully Connected Layer is used to generate the final label. Due to a lack of time, this approach could not be explored fully. However, the authors of this paper believe that there is merit to this approach, and intend to study it further in the future.</p><p>In this paper, we have shown how BERT can be used for the Style Change Detection task. Although BERT is used to capture context, this project shows that the information captured by its embeddings can be used for other NLP tasks as well. We intend to work on this project further by expanding on the other methods mentioned in Section 5. The code for the project can be found at <ref type="bibr" coords="9,278.62,187.48,10.58,8.64" target="#b3">[4]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,167.89,260.00,279.58,8.64"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Distribution of number of style changes in different datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,139.25,166.25,196.16,8.64;7,139.25,178.37,204.76,8.64;7,149.71,200.92,282.61,8.64"><head>3 .</head><label>3</label><figDesc>Paragraph-level classifier for the wide dataset. 4. Paragraph-level classifier for the narrow dataset.The final set of hyperparameters for each classifier are given in Table3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,215.25,296.94,184.86,51.11"><head>Table 1 :</head><label>1</label><figDesc>Number of documents in each dataset</figDesc><table coords="3,218.15,309.39,179.06,38.66"><row><cell cols="2">Number of Documents Narrow Wide</cell></row><row><cell>Train</cell><cell>3,442 8,138</cell></row><row><cell>Validation</cell><cell>1,722 4,078</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,134.77,376.92,345.82,104.11"><head>Table 2 :</head><label>2</label><figDesc>Statistics of number of sentences and paragraphs in each document for the two train datasets.</figDesc><table coords="3,201.78,400.93,209.00,80.10"><row><cell></cell><cell>Sentences</cell><cell></cell><cell>Paragraphs</cell><cell></cell></row><row><cell></cell><cell cols="3">Narrow Wide Narrow</cell><cell>Wide</cell></row><row><cell>Min</cell><cell>18</cell><cell>17</cell><cell>3</cell><cell>2</cell></row><row><cell cols="2">Max 276</cell><cell>375</cell><cell>82</cell><cell>74</cell></row><row><cell cols="4">Mean 110.19 106.98 25.28</cell><cell>18.03</cell></row><row><cell cols="2">Median 108</cell><cell>103</cell><cell>24</cell><cell>16</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,136.56,244.40,342.25,64.31"><head>Table 3 :</head><label>3</label><figDesc>Hyperparameters for all four classifiers.</figDesc><table coords="7,136.56,256.70,342.25,52.01"><row><cell></cell><cell cols="4">Document Wide Document Narrow Paragraph Wide Paragraph Narrow</cell></row><row><cell>Criterion</cell><cell>entropy</cell><cell>gini</cell><cell>gini</cell><cell>gini</cell></row><row><cell>Min Samples Per Leaf</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Min Samples Per Split</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell></row><row><cell>Estimators</cell><cell>400</cell><cell>1800</cell><cell>400</cell><cell>250</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,134.77,127.68,345.82,63.07"><head>Table 5 :</head><label>5</label><figDesc>Average F1 scores calculated on the test set for Document-level (task 1) and Paragraph-level (task 2) predictions.</figDesc><table coords="8,207.09,152.09,201.18,38.66"><row><cell></cell><cell>Average for both datasets</cell></row><row><cell>Document-level</cell><cell>0.6401</cell></row><row><cell>Paragraph-level</cell><cell>0.8566</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,142.61,234.89,337.98,7.77;9,150.95,245.85,294.64,7.77" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="9,336.97,234.89,143.62,7.77;9,150.95,245.85,144.12,7.77">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,142.61,255.92,337.98,7.77;9,150.95,266.87,329.64,7.77;9,150.95,277.83,241.55,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,332.79,255.92,147.80,7.77;9,150.95,266.87,63.39,7.77">Overview of the Style Change Detection Task at PAN 2020</title>
		<author>
			<persName coords=""><forename type="first">Eva</forename><surname>Zangerle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maximilian</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S M P B S</forename></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="9,438.42,266.87,42.18,7.77;9,150.95,277.83,72.99,7.77">CLEF 2020 Labs and Workshops</title>
		<title level="s" coord="9,230.42,277.83,85.63,7.77">Notebook Papers. CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020-09">Sep 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,287.90,337.98,7.77;9,150.95,299.70,145.26,6.31" xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Eva</forename><surname>Zangerle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maximilian</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T G S M P B S</forename></persName>
		</author>
		<ptr target="https://zenodo.org/record/3660984#.XxLhEihKhPY" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,308.93,337.98,7.77;9,150.95,320.73,179.52,6.31" xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vosoughi</surname></persName>
		</author>
		<ptr target="https://github.com/aarish407/Style-Change-Detection-Using-BERT" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,329.95,337.98,7.77;9,150.95,340.91,329.64,7.77;9,150.95,351.87,329.64,7.77;9,150.95,362.83,329.64,7.77;9,150.95,374.63,97.34,6.31" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,193.23,329.95,228.21,7.77">Convolutional neural networks for sentence classification</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1181</idno>
		<ptr target="https://www.aclweb.org/anthology/D14-1181" />
	</analytic>
	<monogr>
		<title level="m" coord="9,448.72,329.95,31.87,7.77;9,150.95,340.91,329.64,7.77;9,150.95,351.87,65.29,7.77">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-10">Oct 2014</date>
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,383.85,183.95,7.77" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lutosławski</surname></persName>
		</author>
		<title level="m" coord="9,213.75,383.85,86.67,7.77">Principes de stylométrie</title>
		<imprint>
			<date type="published" when="1890">1890</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,393.92,337.98,7.77;9,150.95,404.88,211.11,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,211.84,393.92,141.64,7.77">Authorship attribution of texts: A review</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">B</forename><surname>Malyutov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,370.67,393.92,109.92,7.77;9,150.95,404.88,98.60,7.77">General Theory of Information Transfer and Combinatorics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="362" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,414.95,337.98,7.77;9,150.95,425.91,329.64,7.77;9,150.95,436.52,217.63,8.12" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,319.15,425.91,144.34,7.77">Scikit-learn: Machine learning in python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,469.64,425.91,10.96,7.77;9,150.95,436.86,135.45,7.77">the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,446.93,337.98,7.77;9,150.95,457.89,329.64,7.77;9,150.95,468.85,72.72,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,345.61,446.93,134.98,7.77;9,150.95,457.89,12.95,7.77">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,280.67,457.89,195.85,7.77">Information Retrieval Evaluation in a Changing World</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09">Sep 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,478.92,338.35,7.77;9,150.95,489.88,329.64,7.77;9,150.95,500.83,329.64,7.77;9,150.95,511.79,329.64,7.77;9,150.95,522.75,329.64,7.77;9,150.95,533.71,120.14,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,166.50,489.88,314.09,7.77;9,150.95,500.83,12.95,7.77">Overview of PAN 2018: Author Identification, Author Profiling, and Author Obfuscation</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,251.95,511.79,228.64,7.77;9,150.95,522.75,266.64,7.77">Experimental IR Meets Multilinguality, Multimodality, and Interaction. 9th International Conference of the CLEF Initiative (CLEF 2018)</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Bellot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Trabelsi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mothe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Murtagh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017-09">Sep 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,543.78,338.35,7.77;9,150.95,554.74,329.64,7.77;9,150.95,565.70,329.64,7.77;9,150.95,576.65,329.64,7.77;9,150.95,587.61,252.33,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,187.72,554.74,292.88,7.77;9,150.95,565.70,78.96,7.77">Overview of the Author Identification Task at PAN 2017: Style Breach Detection and Author Clustering</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1866/" />
	</analytic>
	<monogr>
		<title level="m" coord="9,449.44,565.70,31.16,7.77;9,150.95,576.65,173.70,7.77">Working Notes Papers of the CLEF 2017 Evaluation Labs</title>
		<title level="s" coord="9,330.93,576.65,107.45,7.77">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Mandl</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2017-09">Sep 2017</date>
			<biblScope unit="volume">1866</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,597.68,338.35,7.77;9,150.95,608.64,291.86,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,268.71,597.68,207.98,7.77">Digital stylometry: Linking profiles across social networks</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,163.16,608.64,167.44,7.77">International Conference on Social Informatics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="164" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,618.71,338.35,7.77;9,150.95,629.66,329.64,7.77;9,150.95,640.62,329.64,7.77;9,150.95,652.43,151.63,6.31" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,399.02,618.71,81.57,7.77;9,150.95,629.66,137.10,7.77">Overview of the Style Change Detection Task at PAN 2019</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2380/" />
	</analytic>
	<monogr>
		<title level="m" coord="9,185.80,640.62,120.30,7.77">CLEF 2019 Labs and Workshops</title>
		<title level="s" coord="9,313.31,640.62,87.12,7.77">Notebook Papers. CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Losada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019-09">Sep 2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
