<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,134.84,115.90,345.69,12.90;1,223.43,135.75,168.50,10.75">Will Longformers PAN Out for Authorship Verification? Notebook for PAN at CLEF 2020</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,190.96,172.15,65.02,8.64"><forename type="first">Juanita</forename><surname>Ordoñez</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Lawrence Livermore National Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,265.54,172.15,75.32,8.64"><forename type="first">Rafael</forename><forename type="middle">Rivera</forename><surname>Soto</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Lawrence Livermore National Laboratory</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,367.30,172.15,57.10,8.64"><forename type="first">Barry</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
							<email>chen52@llnl.gov</email>
							<affiliation key="aff0">
								<orgName type="institution">Lawrence Livermore National Laboratory</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,134.84,115.90,345.69,12.90;1,223.43,135.75,168.50,10.75">Will Longformers PAN Out for Authorship Verification? Notebook for PAN at CLEF 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">12944EF8505F09F291B39E71C2F0D235</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Authorship verification, the task of identifying if two text excerpts are from the same author, is an important part of evaluating the veracity and authenticity of writings and is one of the challenges for this year's PAN @ CLEF 2020 event. In this paper, we describe our PAN authorship verification submission system, a neural network that learns useful features for authorship verification from fanfiction texts and their corresponding fandoms. Our system uses the Longformer, a variant of state-of-the-art transformer models, that is pre-trained on large amounts of text. This model combines global self-attention and local self-attention to enable efficient processing of long text inputs (like the fanfiction data used for PAN @ CLEF 2020), and we augment the pre-trained Longformer model with additional fully-connected layers and fine-tune it to learn features that are useful for author verification. Finally, our model incorporates fandom information via the use of a multi-task loss function that optimizes for both authorship verification and topic correspondence, allowing it to learn useful fandom features for author verification indirectly. On a held-out subset of the PAN-provided "large training" set, our Longformer-based system attained a 0.963 overall verification score, outperforming the PAN text compression baseline by 32.8% relative. However, on the official PAN test set, our system attained a 0.685 overall score, underperforming the PAN text compression baseline by 7.6% relative.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As more of us rely on online sources for our news and information, it becomes increasingly important to vet their veracity and authenticity. One key component of this vetting process is identifying the authorship of the information. Knowing the author of the information can help us better ascertain its trustworthiness which is critical in light of the growing amount of online misinformation propagated by so-called trolls, bots, and other online agitators. There has been a lot of prior work on computational and statistical methods for determining the authorship of text writings based on writing style: word choice, punctuation usage, idiosyncratic grammatical errors, and in more recent digital texts the use of emoticons. One vibrant community in which these computational approaches to authorship identification are developed and evaluated is PAN <ref type="bibr" coords="1,466.48,605.00,10.58,8.64" target="#b0">[1]</ref>.</p><p>PAN hosts scientific evaluations for digital text forensics and stylometry, and one of this year's tasks in PAN @ CLEF 2020 is that of authorship verification <ref type="bibr" coords="2,420.36,131.27,15.27,8.64" target="#b11">[12]</ref>, where the goal is to determine whether two separate text excerpts come from the same author or not. This notebook paper describes our team's final submission system and some of the experiments and alternative systems that we developed for the authorship verification challenge.</p><p>PAN @ CLEF 2020 builds off of earlier evaluations in Authorship Identification tasks <ref type="bibr" coords="2,158.49,208.66,16.60,8.64" target="#b12">[13]</ref> that used fanfiction <ref type="bibr" coords="2,261.58,208.66,11.62,8.64" target="#b4">[5]</ref> as the source material for the challenge. Milli, et al. <ref type="bibr" coords="2,146.90,220.61,16.60,8.64" target="#b17">[18]</ref> describes fanfiction as "fan-created fiction based on a previously existing, original work of literature." Fanfiction is derived from the original work but extends or changes certain aspects of the fiction like providing more development of minor characters, adding additional characters, modifying the relationships between characters, altering endings, etc. While fans may strive to write in the style of the original work's author, it is interesting to see if subtle writing style differences still make it possible to distinguish between the original and fan authors as well as between different fan authors. Our goal is to develop a system that can take two excerpts of fanfiction and determine whether they come from the same fan or not. In addition to the text in these excerpts, we are also given the fandom from which these excerpts derive.</p><p>Our approach is to use neural networks to learn text and fandom embeddings that are useful for authorship verification. Our final submission system is built using a variant of state-of-the-art transformer models <ref type="bibr" coords="2,303.44,369.74,16.60,8.64" target="#b25">[26]</ref> that have recently been setting the pace on a wide variety of natural language processing tasks such as translation, questionanswering, cloze tasks, and language modeling <ref type="bibr" coords="2,326.49,393.65,10.58,8.64" target="#b7">[8]</ref>. We use the Longformer model <ref type="bibr" coords="2,468.97,393.65,11.62,8.64" target="#b2">[3]</ref> pre-trained on about 6.5 billion tokens of text from multiple online sources including English Wikipedia, real news outlets, book versions of movies, and a subset of Com-monCrawl dataset. The Longformer is a computationally efficient transformer model for long text excerpts like the ones found in fanfiction. Our system augments the Longformer with additional fully-connected layers for the authorship verification task as well as a complementary fandom correspondence task.</p><p>The key contributions that we will cover in our PAN Notebook paper are the following:</p><p>1. We train our neural network models to incorporate auxiliary fandom information using a multi-task loss function that combines both authorship and fandom correspondence classification losses.</p><p>Authorship verification and authorship attribution are related subfields within the larger field of Forensic Authorship Analysis. Authorship verification seeks to determine if two different writings are from the same author, while authorship attribution's goal is to identify who wrote a given writing. Both of these fields rely on the extraction of useful text features for discriminating between different authors. Traditionally, researchers have relied on linguistic style or stylometric features, such as the counts and frequency of function words, average length of sentences, part-of-speech, characters, punctuation, whitespace usage, and other low-level features <ref type="bibr" coords="3,322.52,226.05,15.27,8.64" target="#b24">[25]</ref>.</p><p>More recently, with the advent of many successful end-to-end deep learning systems in computer vision, speech recognition, and natural language processing, researchers have begun exploring the idea of learning what features are most useful for both verification and attribution. Many researchers have explored using convolutional neural networks (CNNs) and have successfully used them to extract text features <ref type="bibr" coords="3,445.25,285.83,16.60,8.64" target="#b14">[15]</ref> that are helpful for attribution <ref type="bibr" coords="3,238.75,297.78,15.84,8.64" target="#b9">[10,</ref><ref type="bibr" coords="3,254.59,297.78,11.88,8.64" target="#b22">23,</ref><ref type="bibr" coords="3,266.47,297.78,11.88,8.64" target="#b23">24,</ref><ref type="bibr" coords="3,278.34,297.78,7.92,8.64" target="#b1">2]</ref>, where the CNNs learn author discriminative ngrams of words and characters. In <ref type="bibr" coords="3,276.13,309.74,15.27,8.64" target="#b9">[10]</ref>, researchers learn embeddings for both words and parts-of-speech (POS) tags and show improved generalization performance. Word level features are good at capturing an author's word usage style and oft used phrases, but they ignore other writing nuances such as punctuation, whitespaces, abreviations, and emoticons. Character-based CNNs excel at modeling these aspects; <ref type="bibr" coords="3,419.91,357.56,16.60,8.64" target="#b22">[23]</ref> shows that character based CNN perform especially well for large scale authorship attribution as the number of authors increase. One of the systems that we explored for PAN, our Character-based Convolutional Neural Network (CN) 2 , extends the work on characterlevel CNNs by combining CNNs with self-attention <ref type="bibr" coords="3,345.12,405.38,16.60,8.64" target="#b25">[26]</ref> layers to hone in on the most discriminative combinations of character-level n-grams.</p><p>Computational and neural network-based approaches for Natural Language Processing (NLP) have seen a spike in the growth of their popularity mostly due to the effectiveness of their usefulness across a wide-range of NLP tasks. Simple word-embedding techniques like Word2Vec <ref type="bibr" coords="3,241.46,465.15,16.60,8.64" target="#b16">[17]</ref> and GloVe <ref type="bibr" coords="3,305.34,465.15,15.27,8.64" target="#b19">[20]</ref>, learn to "embed" or project words into continuous feature vector spaces such that related words are proximal in feature space. Subsequent classifiers can then use these pre-trained embeddings for NLP tasks such as sentiment analysis, syntax parsing, semantic role labeling, etc. More recently, sophisticated language models, some built using recurrent neural networks, like ELMO <ref type="bibr" coords="3,461.50,512.97,15.27,8.64" target="#b20">[21]</ref>, and others derived from the self-attention based Transformer models <ref type="bibr" coords="3,409.42,524.93,16.60,8.64" target="#b25">[26]</ref> making them well-suited for efficient training on massive amounts of data, have attained state-ofthe-art performance on diverse sets of NLP tasks <ref type="bibr" coords="3,334.74,548.84,11.32,8.64" target="#b8">[9,</ref><ref type="bibr" coords="3,346.06,548.84,7.55,8.64" target="#b7">8,</ref><ref type="bibr" coords="3,353.61,548.84,11.32,8.64" target="#b15">16,</ref><ref type="bibr" coords="3,364.93,548.84,7.55,8.64" target="#b2">3]</ref>. These models, trained on increasingly large "Internet Scale" data (as in the case of <ref type="bibr" coords="3,357.34,560.80,10.45,8.64" target="#b7">[8]</ref>), learn features that can represent long sequences of text, and these features are then used in downstream NLP tasks. For PAN, we wanted to see if these state-of-the-art language models pre-trained on large amounts of data could be used for the authorship verification task. In section 3.4, we describe our word-based system that uses the Transformer variant specifically developed to efficiently model long text excerpts like fanfics called the Longformer <ref type="bibr" coords="3,431.91,620.57,11.62,8.64" target="#b2">[3]</ref> which is available through the Hugging Face's excellent Transformer repository <ref type="bibr" coords="3,419.21,632.53,15.27,8.64" target="#b26">[27]</ref>.</p><p>Many authorship verification systems have explored architectures other than CNNs and Transformers. Some have sought to learn features using autoencoder-inspired ar-chitectures from a variety of word and character n-grams and POS <ref type="bibr" coords="4,397.95,119.31,15.27,8.64" target="#b10">[11]</ref>. Recurrent Neural Networks (RNN) have also been successfully used. One particularly promising approach is the work of Boenninghoff, et al. <ref type="bibr" coords="4,308.99,143.22,10.58,8.64" target="#b6">[7]</ref>, who use a Siamese Network setup for transforming pairs of text excerpts to extract authorship features that can be compared for determining whether the two excerpts are from the same author. Their Hierarchical Recurrent Siamese Neural Network uses two Long Short-Term Memory (LSTM) layers trained using a modified contrastive loss function that seeks to project text from the same author to nearby locations in feature space.</p><p>Finally, this year's PAN baseline systems are two simple, yet effective approaches. The "TFIDF" baseline computes the term frequency-inverse document frequency normalized counts of character tetragrams of the pair of text excerpts, and then uses the cosine similarities between them as an authorship verification score. The "Compress" baseline is an adaptation of <ref type="bibr" coords="4,244.42,263.14,11.62,8.64" target="#b5">[6]</ref> to the verification task and uses a text compression technique based on Prediction by Partial Matching to compute cross-entropies between the text pair for attributing authorship. According to PAN <ref type="bibr" coords="4,350.83,287.05,10.58,8.64" target="#b0">[1]</ref>, "The mean and absolute difference of the two cross-entropies are used by a logistic regression model to estimate a verification score in [0,1]". This technique follows similar work using text compression for building authorship profiles in <ref type="bibr" coords="4,271.55,322.92,15.27,8.64" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodologies</head><p>Our work explores neural networks as a means for extracting discriminative features directly from the text without any explicit feature engineering. Towards this end, we explore two models: Character Convolutional Neural Network (CN) 2 , and Longformer. More detail about each model will be given in Section 3.3 and Section 3.4.</p><p>At a high level, there are three components to our approach: text feature extraction, topic embedding, and final classification. Of these three, only the text feature extraction changes depending on which of the two models is being used. To embed the fandoms <ref type="foot" coords="4,474.12,452.82,3.49,6.05" target="#foot_2">1</ref> , we apply an embedding layer E topic that maps each fandom identifier to a 512 dimensional vector. Then, the topic embeddings are combined with the text features and passed to two multi-layer perceptrons M author and M topic for authorship verification and topic correspondence respectively. The whole process is outlined in Figure <ref type="figure" coords="4,460.66,502.31,4.98,8.64" target="#fig_0">2</ref> for the (CN) 2 model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Tokenization</head><p>Depending on which model is being used for text feature extraction, our tokenization differs:</p><p>1. (CN) 2 -This model looks at the text from the standpoint of characters, including all punctuation and white-space as tokens. This model can thus focus more on the syntactic quirks of each author rather than the semantic meaning. The size of the Figure 1. This is an example of how we prepared the input for each network. In (CN) 2 , we take 5 random windows from each pair, map each character to its corresponding index, and stack all windows on top of each other. In Longformer, we take one random window from each document, map each word to its corresponding index, concatenate both windows side by side separating it with the &lt;SEP&gt; token and prepend the &lt;CLS&gt; token.</p><p>character vocabulary is 2, 500 and 4, 800 for the small and large version respectively. In the case where a character in the validation set in unseen, we use an "unknown" token. 2. Longformer -This model looks at the text from the standpoint of words and can be thought of as placing more emphasis on the semantic meaning and particular word combinations. Here, we tokenize our document using RoBERTa's tokenizer which has a vocabulary of size 50,265 tokens. More detail about this tokenizer can be found in <ref type="bibr" coords="5,199.57,451.55,15.27,8.64" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model Input</head><p>Because the average length of the fanfiction excerpts is about 20,000 characters long making it difficult for our models and their intermediate feature representations fit in GPU memory, we chose to use multiple random windows from each excerpt as input.</p><p>The number and length of random windows varies depending on the model being used:</p><p>1. (CN) 2 -Uses 10 random windows, 5 from each pair, each composed of 1000 characters. 2. Longformer -Uses 511 words from each pair, these are then separated using the special &lt;SEP&gt; token, and the classification token &lt;CLS&gt; is prepended to learn the document features that are most beneficial for authorship verification. See Figure <ref type="figure" coords="5,475.62,609.88,4.98,8.64">3</ref> and Section 3.4 for more information.</p><p>Figure <ref type="figure" coords="5,178.02,644.48,4.98,8.64">1</ref> shows an example of how we prepare the fanfiction documents for input to our authorship verification systems. As mentioned previously, the (CN) 2 model looks at the document from the standpoint of characters. For input, we take in a set of 10 random windows, 5 from each document. When each random window is embedded, we stack them on top of each other along the channel dimension. Then, 1-D convolutions are applied over n-grams of size one through five after which we maxpool over the length dimension. For each n-gram, there are 512 different convolutional filters, and these filters essentially learn the character n-grams that are most useful for authorship verification. Letting the output of each 1-D convolution and maxpool be called C 1 , C 2 , • • • , C 5 , where C 1 is the output of the 1-D convolution and maxpool that looks at unigrams and C 2 , • • • , C 5 are the ones from higher order n-grams, we define an operation we call Recursive Self Attention:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Character Convolutional Neural Network + Recursive Self Attention</head><formula xml:id="formula_0" coords="6,196.22,541.99,284.37,9.65">out = SA(C 5 ⊕ SA(C 4 ⊕ SA(C3 ⊕ SA(C 2 ⊕ C 1 ))))<label>(1)</label></formula><p>Where ⊕ is the concatenation operation, and SA is the Self-Attention operation. This allows the network to learn features in a hierarchical manner starting from the smallest n-grams to the highest. Finally, the output of this process is passed through a fully connected layer to generate the final documents' feature vector of size 512. The documents' features are then concatenated with the fandom embeddings forming a composite feature vector F , which is then sent to two separate two-layer multilayer perceptrons: one for learning the probability that the two documents are from the same author and the other for the probability that they come from the same topic (i.e., the fandom of the fanfic excerpt). The system architecture is shown on Figure <ref type="figure" coords="6,431.60,656.44,3.74,8.64" target="#fig_0">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Longformer</head><p>Figure <ref type="figure" coords="7,161.50,337.97,3.36,8.06">3</ref>. Architecture diagram for the Longformer system. Two sets of random 511-word windows are sampled from each input text, concatenated together with a separator token and prepended with a classification token. These are sent into the Longformer network. We embed the topic information and fuse it with our text feature representations embodied by the classification token output by the Longformer network. Finally, the multilayer perceptrons, M author and Mtopic predict author verification scores and topic correspondence scores respectively.</p><p>The Longformer <ref type="bibr" coords="7,220.40,428.60,11.62,8.64" target="#b2">[3]</ref> is an extension of the Transformer <ref type="bibr" coords="7,380.76,428.60,16.60,8.64" target="#b25">[26]</ref> which has achieved state-of-the-art results in many natural language tasks. The Longformer has the advantage of being pre-trained on approximately 6.5 billion word tokens and sets stateof-the-art results on Wiki-Hot and Trivia-QA <ref type="bibr" coords="7,324.20,464.47,10.58,8.64" target="#b2">[3]</ref>. Whereas the original Transformer architecture computed self-attention in O(n 2 ) time, where n is the length of the input sequence, the Longformer architecture introduces sliding window self-attention which scales linearly instead of quadratically. The main insight is to compute the self-attention locally instead of globally. Given a fixed window size of w, each token attends to 1  2 w on each side thus resulting in an operation that can be computed in O(nw). Both the global self-attention mechanism and the sliding window self-attention can be combined so as to integrate both global and local context into the computation. This allows the Longformer to take inputs that are much larger than those previously possible. See Figure <ref type="figure" coords="7,475.61,560.11,4.98,8.64">3</ref> for a diagram of the architecture.</p><p>We continue training from the weights of the RoBERTa model released by Beltagy, et al. <ref type="bibr" coords="7,157.45,596.66,10.58,8.64" target="#b2">[3]</ref>. The weights of the embedding layer and the weights of the first ten encoder stacks are frozen, only leaving the last two Encoder stacks for fine-tuning. We use a local attention pattern with w = 512 for every token except the CLS token for which we use a global attention pattern as in the original Transformer architecture. We take a random window consisting of 511 words from each author, these words are then tokenized and the input to the model is "&lt;CLS&gt; &lt;Excerpt 1 Tokens&gt; &lt;SEP&gt; &lt;Excerpt 2 Tokens&gt;". Where CLS is the classification token and SEP is the separator token found in the original BERT <ref type="bibr" coords="8,221.35,131.27,11.62,8.64" target="#b8">[9]</ref> architecture. Finally, the embedding of the CLS token of size N × 768 is taken as our documents' features, and the rest of the model flow follows as in the (CN) 2 approach. Our Longformer system is shown in Figure <ref type="figure" coords="8,403.03,155.18,3.74,8.64">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Multi-Task Loss Function</head><p>During training, our models optimize two objectives: authorship verification and topic correspondence. The joint loss function may be written as follows:</p><formula xml:id="formula_1" coords="8,148.91,245.97,331.68,30.32">L(F, a, t) = 1 N N i=1 BCE(σ(M author (F i )), a i ) + BCE(σ(M topic (F i )), t i ) (2)</formula><p>Where N is the number of samples, F ∈ R N x3D are the features extracted from the model, a ∈ {0, 1} are the author labels, and t ∈ {0, 1} are the topic labels. The label a i is 1 if the text pair is written by the same author and 0 otherwise; t is analogous to a but for topic correspondence. Given the features F , we map them to authorship verification scores and topic correspondence scores using separate two-layer multilayer perceptrons M author and M topic respectively. These scores are then bounded between zero and one through the use of the sigmoid function σ.</p><p>BCE is the binary cross-entropy loss function here defined for one sample:</p><formula xml:id="formula_2" coords="8,213.36,395.54,267.23,8.96">BCE(x, y) = -y log(x) -(1 -y) log(1 -x)<label>(3)</label></formula><p>Where x is a probability, and y ∈ {0, 1} is the label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Scoring</head><p>After training, the output of the neural networks M author and M topic approximate the posterior probabilities of the two excerpts being from the same author and being from the same topic respectively. We use the same-author posterior probability, the output of M author , as our authorship verification score and can be thresholded at 0.5 to decide whether the pair of fanfic excerpts are from the same author or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Metrics</head><p>To evaluate our model, we used the script provided by the PAN organizers. This script implements four metrics: AUC, F1-Score, C@1, and F_0.5u. C@1 <ref type="bibr" coords="8,402.75,596.66,16.60,8.64" target="#b18">[19]</ref> and F_0.5u <ref type="bibr" coords="8,468.97,596.66,11.62,8.64" target="#b3">[4]</ref> are relatively new and have different properties. C@1 is a version of F1-score that rewards the system for leaving difficult problems unanswered, i.e., when the verification probability to be exactly 0.5. In the case where there is a balance between correct answers and non-decisions this metric approximates the traditional accuracy computation. If the model is unsure about too many samples, the score tends towards zero.</p><p>F_0.5u places more importance on documents that come from the same author (i.e., true positives). This is in contrast to C@1 which treats both positive and negative examples with equal importance. Because of this, in F_0.5u the unanswered samples are treated as false negatives resulting in worse performance for models that leave a lot of samples unanswered. Finally, F_0.5u weights true positives higher compared to false positives and false negatives. Although both C@1 and F_0.5u interact with unanswered samples differently, we didn't map any scores to 0.5 and simply used the raw sameauthor posterior probability as our verification score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Dataset</head><p>The PAN Authorship Verification 2020 datasets come in two flavors: small and large. Each dataset was built by scraping fanfiction writings from fanfiction.net. Pairs of fanfictions along with their respective topic (fandom) were provided for training with the classification of positive (same author) or negative (different authors) as ground truth.</p><p>For training our models, we used both the small and large versions of the dataset with our final submission being based upon a model that was calibrated on the large dataset.</p><p>The differences between both datasets is highlighted in Table <ref type="table" coords="9,399.62,325.65,3.74,8.64" target="#tab_0">1</ref>. There are 52, 655 samples in the small dataset and 278, 169 in the large dataset, thus the large dataset contains about 5.28 times more samples. In terms of document length, the average number of characters is approximately 21,400 and the split between negative and positive samples is close to 50% on both datasets. Finally, both the small and the large dataset share the same 1, 600 fandoms.</p><p>To validate our approaches, we split both the small and large dataset into training and validation splits. To construct these splits, we performed the following steps:</p><p>1. Separate the positive and negative samples from each set. 2. Randomly choose 70% of the negative samples for the training set, and the remaining 30% for the validation set. 3. We pick 15% of the authors randomly and use their positive samples in our validation set. If two or more positive pairs existed, we used half for our training set and the rest for the validation set. 4. The positive samples of the remaining 85% of authors are used in the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>Tables <ref type="table" coords="9,163.69,560.80,4.98,8.64" target="#tab_1">2</ref> and<ref type="table" coords="9,189.38,560.80,4.98,8.64" target="#tab_2">3</ref> show our evaluation results of the baseline systems, (CN) 2 and Longformer, on the validation set for the small and large datasets respectively. Comparing (CN) 2 and Longformer against the Compress Baseline on the small dataset (Table <ref type="table" coords="9,469.80,584.71,3.60,8.64" target="#tab_1">2</ref>), both models see an improvement on every metric except (CN) 2 on AUC. Overall, (CN) 2 outperforms the baseline by 5% absolute, while the Longformer model outperforms it by 14.5%. On the large dataset (Table <ref type="table" coords="9,291.36,620.57,3.60,8.64" target="#tab_2">3</ref>), the improvement is even more pronounced. (CN) 2 achieves an improvement of 12.7% while Longformer achieves an improvement of 23.8%. Both (CN) 2 and Longformer benefit from having more data available which highlights the possibility of further improving results by the addition of more data. Given these results, we chose the Longformer system trained on the large dataset as our submission for the TIRA evaluation system <ref type="bibr" coords="10,329.17,373.11,15.27,8.64" target="#b21">[22]</ref>. Unfortunately, as can be seen in Table <ref type="table" coords="10,159.14,385.07,3.74,8.64" target="#tab_3">4</ref>, the model didn't generalize well to the test dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>From the results we see that Longformer clearly outperforms both (CN) 2 and the PAN baselines on our own held-out validation set. We surmise that there are three reasons why the Longformer architecture won out over (CN) 2 on this held-out validation set:</p><p>1. It was pre-trained on about 6.5 billion tokens from multiple online sources. 2. Its deep architecture allows the model to learn more distant relationships of elements in the text than just n-grams. In contrast, (CN) 2 is limited to exploiting relationships of n-grams of size 1 through 5. 3. Because the grammar of fanfictions are relatively clean, the word-based Longformer is more suited to the task as it exploits semantic relationships between the words and the structure of the sentences. On the other hand, (CN) 2 , focuses more on the syntactic features, thus we hypothesize that character-level features would be better in a dataset with shorter, more informal excerpts where words aren't necessarily written correctly.</p><p>As of the writing of this paper, we're still unsure as to why the Longformer model didn't generalize on the test set as can be seen in Table <ref type="table" coords="10,370.35,632.53,3.74,8.64" target="#tab_3">4</ref>. We conjectured that our validation set may not have sufficiently exhibited "the significant shift in the relation between authors and fandoms" in the test set from those seen during training. To test this hypothesis, we created a new dataset split such that the (author, fandom) pairs seen in the validation set are unseen in the training set. For example, if an author wrote in 5 fandoms, we used his/her writings from 4 fandoms in the train set and reserved the last for the validation set. This new validation set allowed us to test the most extreme form of (author, fandom) shifts where there is no overlap between (author, fandom) pairs between training and validation sets. Using this new train/validation data split, the Longformer model achieved an overall score of 93.6% on the validation set. While this score is less than that achieved in our previous validation set, it is still high, and thus fandom shift does not fully explain our Longformer model's failure to generalize on the official test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we described our approach to the authorship verification task in the PAN @ CLEF 2020 challenge based on using neural networks for learning discriminative features from the text as well as the fandom from which the text derives. We compared two different neural network architectures. The first architecture, (CN) 2 , uses a convolutional stack followed by a recursive self-attention stack to simultaneously learn useful character n-grams and their combinations that are most useful for determining whether the excerpt pair is from the same author. The second architecture leverages the state-ofthe-art text features learned by the Longformer model, pre-trained on text with about 6.5 billion words, and we fine-tune the last two encoder stacks to learn useful features for authorship verification. By leveraging a powerful text modeling architecture like the Longformer, we sought to investigate the effectiveness of a transfer learning approach that has shown great results for other NLP tasks. Both systems learn a separate set of embeddings for the fandoms of both fanfic excerpts. The text based features and the fandom features are concatenated and used to predict authorship and fandom correspondences. We used a multi-task loss function to simultaneously optimize for both authorship verification and topic correspondence, allowing it to learn useful fandom features for author verification indirectly.</p><p>For our validation testing, we partitioned each of the PAN provided "small" and "large" training sets into our own training and validation sets. We evaluated our (CN) 2   and Longformer systems along with the two simple PAN baseline systems. Both of our systems outperformed each baseline, but our Longformer system was the winner by a wide margin, attaining a 0.963 overall verification score which is a 32.8% relative improvement over the best baseline system. Thus, we chose to submit our Longformer model trained on the "large" training set as our submission system for PAN. Unfortunately, this system failed to generalize on the official PAN test set, only attaining a 0.685 overall score and failing to outperform the baseline systems. Without access to the PAN test set, we have started to diagnose the source of the generalization failure. An initial experiment on a new train/validation split where (author, fandom) pairs do not overlap between train and validation sets has shown that an extreme shift in (author, fandom) pairs may not be the most significant cause of performance degradation. Our future work will further investigate this issue and seek to improve the Longformer system's generalization performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgment</head><p>This work was performed under the auspices of the U.S. Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344. This document may contain research results that are experimental in nature, and neither the United States Government, any agency thereof, Lawrence Livermore National Security, LLC, nor any of their respective employees makes any warranty, express or implied, or assumes any legal liability or responsibility for the accuracy, completeness, or usefulness of any information, apparatus, product, or process disclosed, or represents that its use would not infringe privately owned rights. Reference to any specific commercial product, process, or service by trade name, trademark, manufacturer, or otherwise does not constitute or imply an endorsement or recommendation by the U.S. Government or Lawrence Livermore National Security, LLC. The views and opinions of authors expressed herein do not necessarily reflect those of the U.S. Government or Lawrence Livermore National Security, LLC and will not be used for advertising or product endorsement purposes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,134.77,329.97,161.49,8.12;6,296.26,328.46,2.99,5.18;6,302.54,330.32,178.05,7.77;6,134.77,341.28,253.70,7.77;6,388.46,339.42,2.99,5.18;6,394.58,341.28,86.01,7.77;6,134.77,352.24,345.82,7.77;6,134.77,363.20,18.43,7.77;6,153.19,361.33,2.99,5.18;6,158.93,362.91,321.66,8.35;6,134.77,374.16,203.98,7.77;6,163.68,157.40,288.00,157.84"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Architecture diagram for the (CN) 2 system. Five sets of random 1000-character windows are sampled from each input text excerpt and sent into the (CN) 2 network. We embed the topic (i.e., fandom) information and fuse it with our text feature representations learned by the (CN) 2 network. Finally, the multilayer perceptrons, M author and Mtopic predict author verification scores and topic correspondence scores respectively.</figDesc><graphic coords="6,163.68,157.40,288.00,157.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="10,176.84,115.83,261.68,127.72"><head>Table 1 .</head><label>1</label><figDesc>PAN's authorship verification statistics: small and large version.</figDesc><table coords="10,203.07,137.15,206.97,106.40"><row><cell>Dataset Version</cell><cell cols="2">Small Large</cell></row><row><cell cols="3">Average Size of Document (Character) 21,441 21,428</cell></row><row><cell>Size of Character Vocabulary</cell><cell>2,542</cell><cell>4,811</cell></row><row><cell>Number of Negative Examples</cell><cell cols="2">24,767 127,787</cell></row><row><cell>Number of Positive Examples</cell><cell cols="2">27,834 147,778</cell></row><row><cell>Number of Pair Train Split</cell><cell cols="2">37,147 196,951</cell></row><row><cell>Number of Pair Validation Split</cell><cell cols="2">15,454 78,614</cell></row><row><cell>Total Number of Pairs</cell><cell cols="2">52,601 275,565</cell></row><row><cell>Number of Topics</cell><cell>1,600</cell><cell>1,600</cell></row><row><cell>Number of Authors</cell><cell cols="2">52,655 278,169</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="10,190.58,257.66,231.95,75.17"><head>Table 2 .</head><label>2</label><figDesc>Small dataset validation results (%).</figDesc><table coords="10,190.58,280.64,231.95,52.20"><row><cell>Model</cell><cell>AUC C@1 F0.5u F1 Score</cell><cell>Overall</cell></row><row><cell>TFIDF Baseline</cell><cell>0.789 0.731 0.699 0.7441</cell><cell>0.747</cell></row><row><cell cols="2">Compress Baseline 0.806 0.74 0.701 0.782</cell><cell>0.757</cell></row><row><cell>(CN) 2</cell><cell cols="2">0.803 0.804 0.809 0.812 0.807 (+ 0.05)</cell></row><row><cell>Longformer</cell><cell cols="2">0.898 0.897 0.914 0.898 0.902 (+ 0.145)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="11,190.58,120.61,231.95,75.51"><head>Table 3 .</head><label>3</label><figDesc>Large dataset validation results (%).</figDesc><table coords="11,190.58,143.92,231.95,52.20"><row><cell>Model</cell><cell>AUC C@1 F0.5u F1 Score</cell><cell>Overall</cell></row><row><cell>TFIDF Baseline</cell><cell>0.779 0.723 0.691 0.759</cell><cell>0.738</cell></row><row><cell cols="2">Compress Baseline 0.766 0.707 0.674 0.753</cell><cell>0.725</cell></row><row><cell>(CN) 2</cell><cell cols="2">0.851 0.852 0.849 0.858 0.852 (+ 0.127)</cell></row><row><cell>Longformer</cell><cell cols="2">0.964 0.964 0.96 0.965 0.963 (+ 0.238)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="11,218.69,213.63,175.72,42.11"><head>Table 4 .</head><label>4</label><figDesc>Test dataset results (%).</figDesc><table coords="11,218.69,236.61,175.72,19.13"><row><cell>Model</cell><cell>AUC C@1 F0.5u F1 Score Overall</cell></row><row><cell cols="2">Longformer 0.696 0.64 0.655 0.748 0.685</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,151.70,579.05,328.90,8.64;2,151.70,591.00,328.89,8.64;2,151.70,602.96,328.90,8.64;2,151.70,614.91,251.07,8.64"><p>We investigate the effectiveness of large-scale text pre-training for authorship verification by building a system using the state-of-the-art Longformer model<ref type="bibr" coords="2,458.73,591.00,10.58,8.64" target="#b2">[3]</ref>, a transformer-based model<ref type="bibr" coords="2,253.79,602.96,16.60,8.64" target="#b25">[26]</ref> that efficiently models long text excerpts such as the fanfiction data in the PAN 2020 Author Verification Challenge.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="2,139.25,632.53,341.34,8.64;2,151.70,644.48,229.02,8.64;2,380.72,642.81,3.49,6.05;2,384.70,644.48,95.89,8.64;2,151.70,656.44,17.43,8.64"><p>3. We compare our word-based Longformer system with two PAN-provided baselines and a character-based convolutional neural network ((CN) 2 ) with self-attention system.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_2" coords="4,144.73,646.13,335.86,7.77;4,144.73,657.08,175.57,7.77"><p>In this paper we refer to fandoms as "topics" interchangeably since the fandom of a piece of writing can roughly be considered to be its topic.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="12,142.61,526.45,333.42,7.77;12,150.95,537.41,156.64,7.77" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="12,150.96,526.45,321.44,7.77">PAN: A series of scientific events and shared tasks on digital text forensics and stylometry</title>
		<ptr target="https://pan.webis.de/" />
		<imprint>
			<date type="published" when="2020-07-03">2020-07-03</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,548.20,330.29,7.77;12,150.95,558.81,84.19,8.12" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="12,245.62,548.20,198.92,7.77">Learning invariant representations of social media users</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bishop</surname></persName>
		</author>
		<idno>ArXiv abs/1910.04979</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,569.94,329.28,7.77;12,150.95,580.55,84.19,8.12" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="12,282.61,569.94,160.72,7.77">Longformer: The long-document transformer</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<idno>ArXiv abs/2004.05150</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,591.68,331.88,7.77;12,150.95,602.64,324.47,7.77;12,150.95,613.60,302.21,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,332.43,591.68,138.89,7.77">Generalizing unmasking for short texts</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,163.16,602.64,312.26,7.77;12,150.95,613.60,225.15,7.77">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="654" to="659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,624.38,320.84,7.77;12,150.95,635.34,325.28,7.77;12,150.95,645.95,223.44,8.12" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="12,199.28,635.34,248.55,7.77">The Importance of Suppressing Domain Style in Authorship Analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bischoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Deckers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schliebs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thies</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<idno>CoRR abs/2005.14714</idno>
		<ptr target="https://arxiv.org/abs/2005.14714" />
		<imprint>
			<date type="published" when="2020-05">May 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,657.08,314.88,7.77" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="12,196.81,657.08,234.53,7.77">Authorship detection with PPM notebook for PAN at CLEF 2013</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bobicev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,119.96,330.38,7.77;13,150.95,130.92,309.91,7.77;13,150.95,141.88,294.12,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,352.69,119.96,120.29,7.77;13,150.95,130.92,95.46,7.77">Similarity learning for authorship verification in social media</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Boenninghoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kolossa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,264.88,130.92,195.99,7.77;13,150.95,141.88,183.74,7.77">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2457" to="2461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,152.12,337.98,7.77;13,150.95,163.07,323.70,7.77;13,150.95,174.03,323.50,7.77;13,150.95,184.99,295.94,7.77;13,150.95,195.60,323.72,8.12;13,150.95,206.91,23.90,7.77" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="13,246.53,195.95,139.54,7.77">Language models are few-shot learners</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">P</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Krüger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">J</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<idno>ArXiv abs/2005.14165</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,217.15,325.47,7.77;13,150.95,227.76,259.26,8.12" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="13,328.63,217.15,139.45,7.77;13,150.95,228.11,144.12,7.77">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>ArXiv abs/1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,238.34,337.99,7.77;13,150.95,249.30,310.51,7.77;13,150.95,260.26,135.72,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,306.60,238.34,173.63,7.77;13,150.95,249.30,92.91,7.77">Authorship attribution with convolutional neural networks and POS-eliding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hitschler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Rehbein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,262.19,249.30,182.31,7.77">Proceedings of the Workshop on Stylistic Variation</title>
		<meeting>the Workshop on Stylistic Variation<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="53" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,270.50,332.94,7.77;13,150.95,281.11,194.40,8.12" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="13,262.27,270.50,212.91,7.77;13,150.95,281.46,79.74,7.77">Experiments with neural networks for small and large scale authorship verification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hosseinia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
		<idno>ArXiv abs/1803.06456</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,291.70,334.17,7.77;13,150.95,302.66,329.64,7.77;13,150.95,313.61,316.30,7.77;13,150.95,324.57,206.68,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,234.75,302.66,245.84,7.77;13,150.95,313.61,16.14,7.77">Overview of the Cross-Domain Authorship Verification Task at PAN 2020</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="13,390.29,313.61,76.96,7.77;13,150.95,324.57,38.13,7.77">CLEF 2020 Labs and Workshops</title>
		<title level="s" coord="13,195.56,324.57,85.63,7.77">Notebook Papers. CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020-09">Sep 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,334.81,320.22,7.77;13,150.95,345.77,299.67,7.77;13,150.95,356.73,309.13,7.77;13,150.95,367.69,318.20,7.77;13,150.95,378.65,23.90,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,199.28,345.77,251.34,7.77;13,150.95,356.73,173.13,7.77">Overview of the author identification task at PAN-2018: cross-domain authorship attribution and style change detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,213.35,367.69,255.80,7.77">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,388.88,338.35,7.77;13,150.95,399.84,239.20,7.77;13,150.95,410.80,140.58,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,245.55,388.88,235.04,7.77;13,150.95,399.84,77.63,7.77">A repetition based measure for verification of text collections and for text categorization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Khmelev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Teahan</surname></persName>
		</author>
		<idno type="DOI">10.1145/860435.860456</idno>
		<ptr target="https://doi.org/10.1145/860435.860456" />
	</analytic>
	<monogr>
		<title level="m" coord="13,246.55,399.84,64.10,7.77">ACM SIGIR 2003</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="104" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,420.69,329.72,8.12;13,150.95,432.00,23.90,7.77" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="13,183.67,421.04,204.29,7.77">Convolutional neural networks for sentence classification</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<idno>ArXiv abs/1408.5882</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,442.24,329.50,7.77;13,150.95,453.19,291.25,7.77;13,150.95,463.80,84.19,8.12" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="13,213.00,453.19,200.37,7.77">Roberta: A robustly optimized bert pretraining approach</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>ArXiv abs/1907.11692</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,474.39,334.74,7.77;13,150.95,485.35,321.23,7.77;13,150.95,496.31,305.81,7.77;13,150.95,507.27,125.53,7.77" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="13,370.57,474.39,106.40,7.77;13,150.95,485.35,160.55,7.77">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,299.61,496.31,157.15,7.77;13,150.95,507.27,29.89,7.77">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,517.50,333.13,7.77;13,150.95,528.46,288.86,7.77;13,150.95,539.42,176.81,7.77" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="13,235.39,517.50,224.45,7.77">Beyond canonical texts: A computational analysis of fanfiction</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Milli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bamman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,150.95,528.46,288.86,7.77;13,150.95,539.42,37.36,7.77">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2048" to="2053" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,549.66,326.23,7.77;13,150.95,560.62,323.27,7.77;13,150.95,571.58,73.83,7.77" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="13,236.87,549.66,146.56,7.77">A simple measure to assess non-response</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rodrigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,401.73,549.66,66.74,7.77;13,150.95,560.62,323.27,7.77;13,150.95,571.58,47.68,7.77">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,581.82,337.61,7.77;13,150.95,592.77,329.64,7.77;13,150.95,603.73,120.79,7.77" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="13,298.04,581.82,166.06,7.77">GloVe: Global vectors for word representation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,150.95,592.77,329.64,7.77;13,150.95,603.73,33.78,7.77">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,613.97,323.81,7.77;13,150.95,624.93,254.09,7.77" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="13,150.95,624.93,149.13,7.77">Deep contextualized word representations</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,318.06,624.93,60.84,7.77">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,635.17,335.40,7.77;13,150.95,646.13,306.17,7.77;13,150.95,657.08,72.72,7.77" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="13,333.86,635.17,140.16,7.77">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,259.53,646.13,193.52,7.77">Information Retrieval Evaluation in a Changing World</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09">Sep 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.24,119.96,338.35,7.77;14,150.95,130.57,279.51,8.12" xml:id="b22">
	<monogr>
		<title level="m" type="main" coord="14,283.19,119.96,197.40,7.77;14,150.95,130.92,164.87,7.77">Character-level and multi-channel convolutional neural networks for large-scale authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ghaffari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Breslin</surname></persName>
		</author>
		<idno>ArXiv abs/1609.06686</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.24,141.88,290.02,7.77;14,150.95,152.84,317.48,7.77" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="14,150.95,152.84,250.66,7.77">Convolutional neural networks for authorship attribution of short texts</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Shrestha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sierra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">A</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Solorio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,419.24,152.84,23.05,7.77">EACL</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.24,163.80,302.64,7.77;14,150.95,174.41,295.21,8.12" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="14,207.24,163.80,182.01,7.77">A survey of modern authorship attribution methods</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,395.57,163.80,49.31,7.77;14,150.95,174.76,211.53,7.77">Journal of the American Society for information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="538" to="556" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.24,185.71,321.33,7.77;14,150.95,196.32,256.56,8.12" xml:id="b25">
	<monogr>
		<title level="m" type="main" coord="14,205.76,196.67,86.57,7.77">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno>ArXiv abs/1706.03762</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.24,207.63,324.37,7.77;14,150.95,218.59,311.40,7.77;14,150.95,229.20,186.55,8.12" xml:id="b26">
	<monogr>
		<title level="m" type="main" coord="14,275.95,218.59,186.41,7.77;14,150.95,229.55,71.51,7.77">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Brew</surname></persName>
		</author>
		<idno>ArXiv abs/1910.03771</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
