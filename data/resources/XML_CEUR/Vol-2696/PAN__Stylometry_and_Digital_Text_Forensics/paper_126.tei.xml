<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,174.36,141.47,273.05,13.30;1,275.64,157.91,59.95,13.30;1,223.32,176.70,164.71,10.00">ULMFiT for Twitter Fake News Spreader Profiling Notebook for PAN at CLEF 2020</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,246.48,211.37,65.94,8.20"><forename type="first">H</forename><forename type="middle">L</forename><surname>Shashirekha</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Mangalore University</orgName>
								<address>
									<postCode>574199</postCode>
									<settlement>Mangalore</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,322.08,211.37,56.65,8.20"><forename type="first">F</forename><surname>Balouchzahi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Mangalore University</orgName>
								<address>
									<postCode>574199</postCode>
									<settlement>Mangalore</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,174.36,141.47,273.05,13.30;1,275.64,157.91,59.95,13.30;1,223.32,176.70,164.71,10.00">ULMFiT for Twitter Fake News Spreader Profiling Notebook for PAN at CLEF 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F030FBF53CFFB33D5E5E052326B9E8B1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>st century is named as the age of information technologies. Social applications such as Facebook, Twitter, Instagram, etc. have become a quick and huge media for spreading news over the internet. At the same time, the ability for the wide spread of news that is of low quality with intentionally false information is creating havocs causing damage to the extent of losing lives in the society. Such news is termed as fake news and detecting the fake news spreader is drawing more attention these days as fake news can manipulate communities' minds and also social trust. Until date, many studies have been done in this area and most of them are based on Machine Learning and Deep Learning approaches. In this paper, we have proposed a Universal Language Model Fine-Tuning model based on Transfer Learning to detect potential fake news spreaders on Twitter. The proposed model collects wiki text data to train the Language Model to capture general features of the language and this knowledge is transferred to build a classifier using fake news spreaders dataset provided by PAN 2020 to identify the fake news spreader. The results obtained on PAN 2020 fake news dataset are encouraging.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this era, social media is overwhelming the lives of people and people are sharing various information using different platforms of social media such as Google+, Facebook, WhatsApp and Twitter <ref type="bibr" coords="1,276.33,503.33,10.16,8.20" target="#b0">[1]</ref>. The velocity of news spreading on internet is highly increasing due to the availability of various social media platforms and pocket friendly mobile data packs. Social media has become more attractive especially for the younger generation mainly because of the inherent benefits of fast dissemination of information and easy access to the information <ref type="bibr" coords="1,332.22,546.53,10.09,8.20" target="#b1">[2]</ref>. At the same time, the ability for the wide spread of news that is of low quality with intentionally false information is creating havocs causing damage to the extent of losing lives in the society <ref type="bibr" coords="1,423.56,568.25,10.16,8.20" target="#b2">[3]</ref>.</p><p>Two major concepts of fake news are veracity and intention. Veracity is about the news that includes some information and the authenticity of that content is possible to be verified as they are. For example, in case of a news about earthquake in Japan, the probability of this news being true is higher but it is a challenge to prove that it is fake or not. Intention refers to the goal of spreader to use false information intentionally to mislead the reader. Fake news is not a new challenge as people have been exposed to propaganda, tabloid news, and satirical reporting since ages. But nowadays, the heavy dependence on the internet, trending stories on social media, new methods of monetizing content, etc., have been found to rely on information without using trustworthy traditional media outlets <ref type="bibr" coords="2,198.34,184.01,10.09,8.20" target="#b3">[4]</ref>. Fake news is hazardous since it is spread to manipulate readers' opinions and beliefs <ref type="bibr" coords="2,223.71,194.69,10.16,8.20" target="#b4">[5]</ref>. Hence, detecting fake news spreaders becomes very much important in today's scenario and is gaining popularity day by day as users play a key role in creating and sharing incorrect or false information intentionally or accidently <ref type="bibr" coords="2,143.28,227.21,10.02,8.20" target="#b5">[6]</ref>. In spite of many systems including automatic detection systems and human based systems, detection of fake news spreaders is still a challenging task <ref type="bibr" coords="2,397.68,238.01,10.16,8.20" target="#b6">[7]</ref>.</p><p>Detecting fake news spreaders in Twitter can be modeled as a typical binary Text Classification (TC) problem that labels a given news spreader as fake or genuine. TC is a Supervised Machine Learning (ML) technique that automatically assigns a label from the predefined set of labels to a given unlabelled input. It has wide applications in various domains, such as target marketing, medical diagnosis, news classification, and document organization <ref type="bibr" coords="2,255.04,302.93,10.16,8.20" target="#b7">[8]</ref>. There are several popular approaches for TC in general and for fake news spreader profiling in particular. In this paper, we propose a Universal Language Model Fine-Tuning (ULMFiT) model for fake news spreader detection based on Transfer Learning (TL).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Transfer Learning</head><p>TL is generally known as one of the novel inventions in the field of Deep Learning and Computer Vision. Conventionally, in ML every model is built from the scratch using a specific dataset. However, a model based on TL approach uses the knowledge obtained from building one model called as a source model in building another model called as target model. The former model is called as source task and later the target task. While the source task uses one dataset called as source dataset to build/learn the source learning system or source model, target task uses the knowledge obtained in building the source model along with the target dataset used for fine tuning the target model. For example, the source model can be a Language model (LM) that represents the general features of a language, target model can be TC, source dataset can be Wikipedia text and the target dataset can be fake news <ref type="bibr" coords="2,371.21,481.25,10.02,8.20" target="#b8">[9]</ref>. LM is a probability distribution over word sequences in a language and introduces a useful hypothesis space for many other NLP tasks <ref type="bibr" coords="2,276.12,502.73,14.50,8.20" target="#b9">[10]</ref>. As the knowledge obtained in building the source model is transferred to build the target model, learning is named as Transfer Learning. Figure <ref type="figure" coords="2,212.02,524.45,4.67,8.20" target="#fig_0">1</ref> illustrates the difference between conventional ML and TL. After the introduction of TL, LM has drawn more attention as it acts as an informative knowledge of a language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">ULMFiT</head><p>ULMFiT is a model based on TL and can be used for many NLP tasks such as TC and NER <ref type="bibr" coords="2,181.84,594.65,10.16,8.20" target="#b8">[9]</ref>. It uses the knowledge of LM as source model and then fine tunes the target model using the task-specific data or target dataset. Figure <ref type="figure" coords="2,420.04,605.57,4.67,8.20" target="#fig_1">2</ref> represents architecture of ULMFiT. It includes 3 steps i) pre-training LM using large corpus like Wikipedia to capture the high-level language features and the resultant model is called as pre-trained LM ii) fine-tune the target model using pre-trained LM and task-specific or target dataset iii) final model which accepts the test/unlabelled data to assign a label.  The advantage of TL is, when a given dataset is too small to train a learning model the knowledge obtained in a pre-trained LM on a source dataset can be transferred to the target task, resulting in the improvement of the target model even when the source and target datasets have different distributions or features <ref type="bibr" coords="3,361.27,426.05,10.96,8.20" target="#b8">[9]</ref> [11] <ref type="bibr" coords="3,389.62,426.05,14.99,8.20" target="#b11">[12]</ref>.</p><p>The rest of the paper is organized as follows. Section 2 gives the related work followed by the proposed methodology in section 3. While section 4 describes the experiments and results, section 5 gives the conclusion of the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>In spite of the availability of many automated tools and techniques for the detection of fake news spreaders, it is still a challenging task. Some of the relevant works are mentioned below:</p><p>An Artificial Neural Network model for Language Identification task for Indian native Languages namely Tamil, Hindi, Kannada, Malayalam, Bengali and Telugu written in Roman script has been explored by Hamada et. al. <ref type="bibr" coords="3,373.92,573.89,10.02,8.20" target="#b0">[1]</ref>. The data sets used in task are collection of comments from different regional newspapers and Facebook pages. They obtained an accuracy score of 35.30 %. The same authors also obtained accuracies of 47.60% and 47.30% respectively in another work using ensemble classifier made of multinomial Bayes, SVM and random forest tree <ref type="bibr" coords="3,399.46,617.09,14.50,8.20" target="#b12">[13]</ref>. Francisco et. al. <ref type="bibr" coords="3,156.59,628.01,15.63,8.20" target="#b13">[14]</ref> proposed Low Dimensionality Representation (LDR) for language variety identification and has applied LDR to the age and gender identification task at the PAN Lab at CLEF. The results they obtained are competitive with the best performing teams in the author profiling task.</p><p>Shu et. al. <ref type="bibr" coords="4,199.00,162.29,10.87,8.20" target="#b1">[2]</ref> constructs a real-world dataset by measuring users trust level of "experienced<ref type="foot" coords="4,192.48,172.79,2.81,4.94" target="#foot_0">1</ref> " and "native<ref type="foot" coords="4,244.92,172.79,2.81,4.94" target="#foot_1">2</ref> " users on fake news. They have performed a comparative analysis of explicit and implicit profile features between these user groups, which reveals their potential to differentiate fake news. Shu et. al. <ref type="bibr" coords="4,368.87,194.69,10.96,8.20" target="#b2">[3]</ref> have explored the fake news problem from a data mining perspective, including feature extraction and model construction and have reviewed different approaches for fake news detection. Bilal et al. <ref type="bibr" coords="4,155.74,227.21,10.96,8.20" target="#b4">[5]</ref> presents an approach based on a combination of emotional information from documents using a deep learning network. The authors used one dataset including trusted news (real news) created from English Gig word corpus and another dataset is a collection of news from seven different unreliable news sites as false news and have reported an F1 score of 96%. A Bot detection approach using behavioral and other informal cues is proposed by Andrew et. al. <ref type="bibr" coords="4,324.62,281.21,14.50,8.20" target="#b14">[15]</ref>. They have used random forest classifier and a gradient boosting classifier and also applied a hyper parameter optimization on over 476 million revisions that has been collected from Wikipedia articles. They have reported the model performance as 88% precision and 60% recall.</p><p>EmoCred model based on LSTM neural network proposed by Anastasia et. al. <ref type="bibr" coords="4,452.47,324.41,15.54,8.20" target="#b15">[16]</ref> incorporates emotional signals to differentiate between credible and non-credible claims. It accepts word embeddings as input from claims and a vector of emotional signals. The authors used Politifact<ref type="foot" coords="4,279.12,356.51,2.81,4.94" target="#foot_2">3</ref> that contain the text of the claims, the speaker, and the credit rating of each claim. Six different credibility ratings: true, mostly true, half true, mostly false, false, and pants-on-fire has been combined into two classes as true and false and obtained 61.7% F1 score for generating the emotional signals. "DeClarE" is an automated end-to-end neural network model proposed by Kashyap et. al. <ref type="bibr" coords="4,170.14,410.93,14.58,8.20" target="#b16">[17]</ref>. They capture signals from external evidence articles and model joint interactions between various factors like the context of a claim, the language of reporting articles, and the trustworthiness of their sources. Their model was evaluated on Snopes<ref type="foot" coords="4,182.64,442.91,2.81,4.94" target="#foot_3">4</ref> , Politifact <ref type="foot" coords="4,227.15,442.91,2.81,4.94" target="#foot_4">5</ref> , and a SemEval Twitter rumor dataset and obtained F1 scores of 79% and 68% for Snopes and Politifact respectively and a macro accuracy score of 57% for SemEval dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>An overview of the proposed fake news spreader detection model is described in Figure <ref type="figure" coords="4,172.82,537.17,3.41,8.20" target="#fig_2">3</ref>. The model constructed using the state-of-the-art ULMFiT architecture developed by Howard et. al. <ref type="bibr" coords="4,252.68,547.97,15.63,8.20" target="#b9">[10]</ref> consists of pre-training the LM and then fine-tuning the fake news spreader detection model by using the pre-trained LM and fake news spreader dataset provided by PAN2020. Two separate models are constructed to detect the fake news given in English and Spanish. Inspired by Stephen et. al. <ref type="bibr" coords="4,449.99,580.37,14.50,8.20" target="#b17">[18]</ref>, LM and Target classifier are created using text.models module from fastai library. This module implements the encoder for an ASGD Weight-Dropped LSTM (AWD-LSTM) which can be plugged in with a decoder to create an LM and also with some classifying layers to create a text classifier.</p><p>AWD-LSTM is a regular LSTM to which several regularization and optimization techniques are applied and built layer by layer by grabbing a PyTorch neural network model <ref type="bibr" coords="5,168.96,205.49,10.09,8.20" target="#b8">[9]</ref>. Its architecture as described by Howard and Ruder <ref type="bibr" coords="5,377.27,205.49,15.54,8.20" target="#b9">[10]</ref> consists of a word embedding of size 400, 3 layers and 1150 hidden activations per layer. The AWD-LSTM has been dominating the state-of-the-art language modeling and many studies on word-level models incorporate AWD-LSTMs. It also has shown noticeable results on character-level models <ref type="bibr" coords="5,242.57,248.81,14.38,8.20" target="#b17">[18]</ref>. LM also called as source learning model is trained on the source data collected from English/Spanish Wikipedia. Source data set usually is an unannotated data set that contains general domain texts to train LM to obtain general features like grammar of the language. A sufficiently large English/Spanish text data are collected from Wikipedia to create a source dataset of English/Spanish language respectively and LM is trained to learn the general features of the language. Wikipedia articles that were available in the month of January 2020 are collected in xml format and then the sentences are extracted from the raw text using WikiExtractor<ref type="foot" coords="5,391.08,481.31,2.81,4.94" target="#foot_5">6</ref> module. Once the source model completes its learning the knowledge thus learned is used to build the target task of fake news spreader detection. The knowledge can also be saved for future use for other English/Spanish NLP applications. Details of source dataset for both the languages are given in Table <ref type="table" coords="5,286.32,524.93,3.50,8.20" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Target Model</head><p>The target model is created using the knowledge obtained from LM followed by fine-tuning the model using the target dataset. The pre-trained LM is used to train target task data for various cycles to fine-tune the knowledge based on target task. Target dataset is the labeled data used for classification tasks which is provided by PAN for registered users only. The dataset consists of 300 XML files in a folder per language (English, Spanish) <ref type="bibr" coords="5,251.26,620.09,14.38,8.20" target="#b18">[19]</ref>. Each folder contains:  An XML file per author (Twitter user) consisting of 100 tweets each and the name of the XML file corresponds to the unique author id.  A truth.txt file with the list of authors and ground truth. The details of the dataset provided by PAN are given in Table <ref type="table" coords="6,401.74,174.53,3.50,8.20" target="#tab_1">2</ref>. Target data is preprocessed and then used for fine-tuning the classification task. Preprocessing involves tokenization, removing punctuations and stop words, lemmatization and removing other unwanted characters. Emojis are small images used to express emotion and are useful in text analysis <ref type="bibr" coords="6,295.16,217.73,14.43,8.20" target="#b12">[13]</ref>. Hence, they are converted to respective words or phrases and those words or phrases are treated similar to content bearing words. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper presents ULMFiT model for profiling fake tweet spreaders based on Transfer Learning approach. The proposed model is initially trained on a general domain English/Spanish data collected from Wikipedia to build an LM model, and then the acquired knowledge is transferred to build the fake news spreader detection task as the target model. The model resulted with 64% accuracy for Spanish and 62% for English language data. Further, the data collected from Wikipedia and LM can be used for any other English/Spanish NLP task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,195.24,278.09,231.41,7.41;3,187.80,171.00,235.92,99.36"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Conventional Machine Learning versus Transfer Learning</figDesc><graphic coords="3,187.80,171.00,235.92,99.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,251.52,378.17,118.93,7.41;3,218.16,302.16,186.12,68.28"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Architecture of ULMFiT</figDesc><graphic coords="3,218.16,302.16,186.12,68.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,187.08,360.29,247.78,7.41;5,216.48,268.20,189.24,84.36"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Overview of ULMFiT for Twitter fake news spreader profiling</figDesc><graphic coords="5,216.48,268.20,189.24,84.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,194.28,266.45,226.20,47.09"><head>Table 1 .</head><label>1</label><figDesc>Details of source dataset</figDesc><table coords="6,194.28,282.65,226.20,30.88"><row><cell>Language</cell><cell>No. Articles</cell><cell cols="2">No. Sentences No. Words</cell></row><row><cell>English</cell><cell>63341</cell><cell>2050239</cell><cell>68011619</cell></row><row><cell>Spanish</cell><cell>68490</cell><cell>1531438</cell><cell>64530355</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,159.24,342.89,240.02,24.29"><head>Table 2 .</head><label>2</label><figDesc>Details of target datasets provided by PAN</figDesc><table coords="6,159.24,358.97,91.01,8.20"><row><cell>Language</cell><cell>No. of</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,234.84,140.57,152.26,50.21"><head>Table 3 .</head><label>3</label><figDesc>Performance of the proposed model</figDesc><table coords="7,236.40,156.77,123.65,34.00"><row><cell>Language</cell><cell>Accuracy (%)</cell></row><row><cell>English</cell><cell>62 %</cell></row><row><cell>Spanish</cell><cell>64 %</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,148.36,605.57,197.79,7.41"><p>Users who are able to recognize fake news items like false</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,148.36,615.53,160.61,7.41"><p>Users who are more likely to believe fake news</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,148.36,625.37,284.19,7.41"><p>It is a fact-checking website where the credibility of different claims is investigated.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,148.36,635.33,59.99,7.41"><p>www.snopes.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,148.36,645.17,67.58,7.41"><p>www.politifact.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="5,148.36,645.17,133.08,7.41"><p>https://github.com/attardi/wikiextractor</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="6,148.36,645.17,115.95,7.41"><p>https://colab.research.google.com/</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental results</head><p>As per PAN 2020 rules for submitting software in Virtual Machine (VM), learning model has to be first constructed locally and saved followed by loading the model in PAN VM and finally submitting the model through TIRA Integrated Research Architecture submission system <ref type="bibr" coords="6,265.84,486.41,14.58,8.20" target="#b19">[20]</ref>. ULMFiT model is created using Google Colab 7 as it requires GPU and higher RAM size in learning cycles.</p><p>The proposed model was evaluated through PAN submission system and the performance of model was made available by the task moderator. Model's runtime reported by PAN is 00:35:48 (hh:mm:ss). Almost half of this time is spent on loading the model using fastai library and rest for predictions. Details of results obtained by the proposed model are given in Table <ref type="table" coords="6,301.34,551.33,3.46,8.20">3</ref>. The proposed model resulted with 64% accuracy for Spanish and 62% for English language data.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="7,146.74,353.81,321.21,8.20;7,160.20,364.61,307.81,8.20;7,160.20,375.41,162.29,8.20" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,349.06,353.81,118.89,8.20;7,160.20,364.61,288.65,8.20">Mangalore University INLI@ FIRE2018: Artificial Neural Network and Ensemble based Models for INLI</title>
		<author>
			<persName coords=""><forename type="first">Nayel</forename><surname>Hamada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">L</forename><surname>Shashirekha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,160.20,375.41,84.98,8.20">FIRE (Working Notes)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="110" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,146.74,386.21,321.45,8.20;7,160.20,397.13,307.90,8.20;7,160.20,407.93,248.05,8.20" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,319.97,386.21,148.22,8.20;7,160.20,397.13,128.56,8.20">Understanding User Profiles on Social Media for Fake News Detection</title>
		<author>
			<persName coords=""><forename type="first">Shu</forename><surname>Kai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,313.86,397.13,154.25,8.20;7,160.20,407.93,169.92,8.20">2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="430" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,146.74,418.61,321.40,8.20;7,160.20,429.41,307.75,8.20;7,160.20,440.33,194.64,8.20" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,425.07,418.61,43.06,8.20;7,160.20,429.41,231.61,8.20">Fake News Detection on Social Media: A Data Mining Perspective</title>
		<author>
			<persName coords=""><forename type="first">Shu</forename><surname>Kai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amy</forename><surname>Sliva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,405.29,429.41,62.66,8.20;7,160.20,440.33,90.91,8.20">ACM SIGKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="36" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,146.74,451.13,321.26,8.20;7,160.20,461.93,59.34,8.20" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,223.42,451.13,117.71,8.20">The Real Risks of Fake News</title>
		<author>
			<persName coords=""><forename type="first">Haber</forename><surname>Morey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,354.68,451.13,70.32,8.20">Risk Management</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="10" to="12" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,146.74,472.61,321.22,8.20;7,160.20,483.53,307.87,8.20;7,160.20,494.33,203.38,8.20" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,367.35,472.61,100.61,8.20;7,160.20,483.53,210.23,8.20">An Emotional Analysis of False Information in Social Media and News Articles</title>
		<author>
			<persName coords=""><forename type="first">Ghanem</forename><surname>Bilal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,381.69,483.53,86.38,8.20;7,160.20,494.33,106.29,8.20">ACM Transactions on Internet Technology (TOIT)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,146.74,505.13,321.46,8.20;7,160.20,515.93,308.00,8.20;7,160.20,526.85,307.95,8.20;7,160.20,537.53,307.92,8.20;7,160.20,548.33,71.02,8.20" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,217.30,515.93,250.90,8.20;7,160.20,526.85,191.16,8.20">The Role of Personality and Linguistic Patterns in Discriminating Between Fake News Spreaders and Fact Checkers</title>
		<author>
			<persName coords=""><forename type="first">Giachanou</forename><surname>Anastasia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Esteban</forename><forename type="middle">A</forename><surname>Ríssola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bilal</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,373.83,526.85,94.31,8.20;7,160.20,537.53,236.99,8.20">International Conference on Applications of Natural Language to Information Systems</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="181" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,146.74,559.13,321.49,8.20;7,160.20,570.05,251.40,8.20;7,411.72,568.86,6.14,5.34;7,420.48,570.05,47.82,8.20;7,160.20,580.85,307.97,8.20;7,160.20,591.65,71.02,8.20" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,294.36,559.13,173.87,8.20;7,160.20,570.05,145.13,8.20">Learning from Fact-checkers: Analysis and Generation of Fact-checking Language</title>
		<author>
			<persName coords=""><forename type="first">Kyumin</forename><surname>Vo Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,329.44,570.05,82.17,8.20;7,411.72,568.86,6.14,5.34;7,420.48,570.05,47.82,8.20;7,160.20,580.85,304.29,8.20">Proceedings of the 42 nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42 nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="335" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,146.74,602.33,321.17,8.20;7,160.20,613.25,290.84,8.20" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,344.01,602.33,123.90,8.20;7,160.20,613.25,40.94,8.20">A Survey of Text Classification Algorithms</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Aggarwal Charu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cheng</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhai</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,217.85,613.25,65.78,8.20">Mining Text Data</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="163" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,146.74,624.05,321.22,8.20;7,160.20,634.85,285.62,8.20" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,401.15,624.05,66.80,8.20;7,160.20,634.85,93.17,8.20">Ulmfit: State-Of-The-Art in Text Analysis</title>
		<author>
			<persName coords=""><forename type="first">Faltl</forename><surname>Sandra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Schimpke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Constantin</forename><surname>Hackober</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,263.65,634.85,112.25,8.20">Seminar Information Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,151.00,140.69,317.13,8.20;8,160.20,151.49,245.77,8.20" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="8,313.84,140.69,154.29,8.20;8,160.20,151.49,83.63,8.20">Universal Language Model Fine-Tuning for Text Classification</title>
		<author>
			<persName coords=""><forename type="first">Howard</forename><surname>Jeremy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.06146</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,151.00,162.29,317.10,8.20;8,160.20,173.21,308.01,8.20;8,160.20,184.01,307.85,8.20;8,160.20,194.69,307.85,8.20;8,160.20,205.49,57.00,8.20" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,165.65,173.21,302.57,8.20;8,160.20,184.01,112.04,8.20">A Practitioners Guide to Transfer Learning for Text Classification Using Convolution Neural Networks</title>
		<author>
			<persName coords=""><forename type="first">Semwal</forename><surname>Tushar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Promod</forename><surname>Yenigalla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gaurav</forename><surname>Mathur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shivashankar</forename><forename type="middle">B</forename><surname>Nair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,293.79,184.01,174.26,8.20;8,160.20,194.69,288.91,8.20">Proceedings of the 2018 Society for Industrial and Applied Mathematics (SIAM) International Conference on Data Mining</title>
		<meeting>the 2018 Society for Industrial and Applied Mathematics (SIAM) International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="513" to="521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,151.00,216.41,317.10,8.20;8,160.20,227.21,243.30,8.20" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,381.22,216.41,86.88,8.20;8,160.20,227.21,97.05,8.20">Transfer Learning via Dimensionality Reduction</title>
		<author>
			<persName coords=""><forename type="first">Pan</forename><surname>Sinno Jialin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,278.14,227.21,20.57,8.20">AAAI</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="677" to="682" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,151.00,238.01,316.91,8.20;8,160.20,248.81,307.91,8.20;8,160.20,259.61,255.25,8.20" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,328.30,238.01,139.62,8.20;8,160.20,248.81,307.91,8.20;8,160.20,259.61,72.03,8.20">Mangalore-University@ INLI-FIRE-2017: Indian Native Language Identification using Support Vector Machines and Ensemble approach</title>
		<author>
			<persName coords=""><forename type="first">Hamada</forename><forename type="middle">A</forename><surname>Nayel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">L</forename><surname>Shashirekha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,253.02,259.61,84.96,8.20">FIRE (Working Notes)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="106" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,151.00,270.41,317.07,8.20;8,160.20,281.21,307.87,8.20;8,160.20,292.01,307.96,8.20;8,160.20,302.93,181.53,8.20" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,436.71,270.41,31.37,8.20;8,160.20,281.21,284.17,8.20">A Low Dimensionality Representation for Language Variety Identification</title>
		<author>
			<persName coords=""><forename type="first">Rangel</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marc</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,160.20,292.01,307.96,8.20;8,160.20,302.93,40.32,8.20">International Conference on Intelligent Text Processing and Computational Linguistics</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="156" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,151.00,313.73,317.01,8.20;8,160.20,324.41,307.86,8.20;8,160.20,335.21,297.32,8.20" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,364.40,313.73,103.62,8.20;8,160.20,324.41,175.88,8.20">Bot Detection on Wikidata Using Behavioral and Other Informal Cues</title>
		<author>
			<persName coords=""><forename type="first">Hall</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Loren</forename><surname>Terveen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aaron</forename><surname>Halfaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,350.09,324.41,117.97,8.20;8,160.20,335.21,109.88,8.20">Proceedings of the ACM on Human-Computer Interaction</title>
		<meeting>the ACM on Human-Computer Interaction</meeting>
		<imprint>
			<date type="published" when="2018-11">November 2018</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,151.00,346.13,317.14,8.20;8,160.20,355.86,308.00,9.28;8,160.20,367.73,307.85,8.20;8,160.20,378.41,57.00,8.20" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,382.90,346.13,85.25,8.20;8,160.20,356.93,122.65,8.20">Leveraging Emotional Signals for Credibility Detection</title>
		<author>
			<persName coords=""><forename type="first">Giachanou</forename><surname>Anastasia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,304.04,355.86,164.16,9.28;8,160.20,367.73,288.94,8.20">Proceedings of the 42 nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42 nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="877" to="880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,151.00,389.33,316.92,8.20;8,160.20,400.13,307.83,8.20;8,160.20,410.93,195.25,8.20" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="8,164.59,400.13,303.44,8.20;8,160.20,410.93,32.23,8.20">DeClarE: Debunking Fake News and False Claims Using Evidence-Aware Deep Learning</title>
		<author>
			<persName coords=""><forename type="first">Popat</forename><surname>Kashyap</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Subhabrata</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.06416</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,151.00,421.73,317.19,8.20;8,160.20,432.65,301.34,8.20" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="8,402.41,421.73,65.79,8.20;8,160.20,432.65,137.81,8.20">Regularizing and Optimizing LSTM Language Models</title>
		<author>
			<persName coords=""><forename type="first">Merity</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nitish</forename><surname>Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02182</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,151.00,442.26,317.23,9.28;8,160.20,454.13,307.80,8.20;8,160.20,464.93,307.91,8.20;8,160.20,475.85,257.15,8.20" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="8,365.25,442.26,102.98,9.28;8,160.20,454.13,275.56,8.20">Overview of the 8 th Author Profiling Task at PAN 2020: Profiling Fake News Spreaders on Twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,383.41,464.93,84.70,8.20;8,160.20,475.85,229.58,8.20">CLEF 2020 Labs and Workshops, Notebook Papers, CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,151.00,486.65,316.96,8.20;8,160.20,497.45,307.91,8.20;8,160.20,508.13,205.25,8.20" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="8,447.16,486.65,20.80,8.20;8,160.20,497.45,128.95,8.20">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">Potthast</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tim</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matti</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,315.32,497.45,152.80,8.20;8,160.20,508.13,60.71,8.20">Information Retrieval Evaluation in a Changing World</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="123" to="160" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
