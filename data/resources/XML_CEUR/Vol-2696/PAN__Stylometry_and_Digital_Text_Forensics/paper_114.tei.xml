<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,189.73,115.90,235.89,12.90;1,204.64,133.83,206.08,12.90">Cross-Domain Authorship Verification Based on Topic Agnostic Features</title>
				<funder>
					<orgName type="full">German Federal Ministry of Education and Research</orgName>
				</funder>
				<funder>
					<orgName type="full">National Research Center for Applied Cybersecurity ATHENE</orgName>
				</funder>
				<funder>
					<orgName type="full">Hessen State Ministry for Higher Education, Research and the Arts</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,212.41,178.05,53.70,8.64"><forename type="first">Oren</forename><surname>Halvani</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Fraunhofer Institute for Secure Information Technology SIT</orgName>
								<address>
									<addrLine>Rheinstrasse 75</addrLine>
									<postCode>64295</postCode>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,278.16,178.05,52.68,8.64"><forename type="first">Lukas</forename><surname>Graner</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Fraunhofer Institute for Secure Information Technology SIT</orgName>
								<address>
									<addrLine>Rheinstrasse 75</addrLine>
									<postCode>64295</postCode>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,354.52,178.05,48.43,8.64"><forename type="first">Roey</forename><surname>Regev</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Fraunhofer Institute for Secure Information Technology SIT</orgName>
								<address>
									<addrLine>Rheinstrasse 75</addrLine>
									<postCode>64295</postCode>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,189.73,115.90,235.89,12.90;1,204.64,133.83,206.08,12.90">Cross-Domain Authorship Verification Based on Topic Agnostic Features</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0F1E644B3B9D3B61F7F52FC64708554B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Authorship verification (AV) is a research branch in digital text forensics that deals with the problem to determine whether two documents were written by the same author. Research activities in the context of AV have steadily increased in recent years, which have led to a variety of approaches trying to solve this problem. Many of these approaches, however, make use of features that are related to or influenced by the topic of the documents. Therefore, it may accidentally happen that their verification results are based not on the writing style alone (the actual focus of AV), but on the topic of the documents. To address this problem, we propose in the context of the AV shared task at the PAN 2020 workshop an alternative approach, which considers only topic-agnostic features in its classification decision. On the official test set, our approach was ranked third out of all submitted approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the constant increase of documents worldwide, more and more possibilities of identity misuse are becoming established. One example of such identity abuse is "CEO Fraud" -a sophisticated email scam -in which an attacker sends an email to an employee on behalf of a CEO to perform a specific action (e. g., transferring money or sending confidential company information). Another form of identity abuse occurs in the context of compromised accounts, where the attacker distributes messages in the name of the victim. In addition, identity abuse can occur in fake reviews in which, for example, an attempt is made on behalf of an alleged person to positively advertise a product or service provider. A countermeasure regarding these scenarios is to compare the writing style of the questioned documents with the writing style of those documents for which the true author A is known. By this, the question can be answered (with a certain degree of probability) whether the unknown document was also written by A. The comparison of documents based on their writing style is particularly relevant if no other metadata are available to clarify the identity of the unknown author. Authorship verification (AV), which is a branch of digital text forensics, has been dealing with this question for over two decades. Technically, AV represents a similarity detection problem, where for an unknown document D U and a known document D A it has to be determined whether both were written by the same author A. The focus of the similarity determination in the context of AV is on the writing style and not on other factors such as the topic or genre. Therefore, if D U and D A share the same topic but were written by different authors, a naive AV method might erroneously assume a high degree of similarity, resulting in a clear failure to achieve its intended goal.</p><p>A large number of existing AV methods including <ref type="bibr" coords="2,337.67,197.47,12.16,8.64" target="#b3">[4,</ref><ref type="bibr" coords="2,349.83,197.47,8.11,8.64" target="#b5">6,</ref><ref type="bibr" coords="2,357.94,197.47,12.16,8.64" target="#b20">21,</ref><ref type="bibr" coords="2,370.10,197.47,12.16,8.64" target="#b21">22,</ref><ref type="bibr" coords="2,382.26,197.47,12.16,8.64" target="#b24">25,</ref><ref type="bibr" coords="2,394.42,197.47,8.11,8.64" target="#b25">26</ref>] make use of character n-grams (overlapping character sequences), which are known to be closely associated to particular content words and, therefore, can be problematic when dealing with authorship <ref type="bibr" coords="2,202.01,233.34,15.27,8.64" target="#b19">[20]</ref>. Style analysis, however, must abstract from content and focus on content-independent formal properties of linguistic expressions in a text <ref type="bibr" coords="2,440.21,245.29,10.58,8.64" target="#b8">[9]</ref>. In the light of this conclusion, we propose an alternative approach which, by design, considers only such text units that reflect valid stylistic markers. Our contribution in this paper is twofold: First, we propose a number of topic-agnostic feature categories that effectively quantify the writing style of documents. Second, we propose a transparent AV method that can be applied to challenging AV tasks. These include cases, where D U and D A consist of only a few sentences or cases where both differ thematically.</p><p>The rest of the paper<ref type="foot" coords="2,221.27,333.74,3.49,6.05" target="#foot_0">1</ref> is organized as follows. Section 2 discusses previous work in the context of AV. In Section 3, we propose a number of feature categories, which will be used by our AV method introduced in Section 4. Afterwards, we present our experimental evaluation in Section 5 and, finally, in Section 6 we conclude the work and provide ideas for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Previous Work</head><p>The core of every AV method is a classification model that aims to decide whether a questioned document D U was written by a certain author A, for which a set D A = {D 1 , D 2 , . . .} of reference documents is given. With regard to their classification models, we have identified three categories of AV methods in our previous research work <ref type="bibr" coords="2,134.77,488.65,15.27,8.64" target="#b12">[13]</ref>, which are summarized below.</p><p>The first category are unary AV methods that determine their classification model solely on the basis of D A . A unary AV method assumes D U to be written by A, if it is stylistically similar to the documents in D A . The second category are binaryintrinsic AV methods that determine their classification model on the basis of a given training corpus. This corpus consists of a number of verification cases with a ground truth regarding the classes Y (same-author) and N (different-author). A binary-intrinsic AV method treats the unknown and known documents as a single unit X (for example, a feature vector). If X is more similar to the Y-cases, the method accepts A as the author of D U . If, on the other hand, X is more similar to the N-cases, D U is assumed to be written by another author. In any case, the decision is made solely on the basis of X and the learned model (hence, intrinsic). The third category are binary-extrinsic AV methods that determine their classification model on the basis of external (so-called impostor <ref type="bibr" coords="3,173.39,143.22,15.93,8.64" target="#b20">[21]</ref>) documents which, for example, are gathered by using a search engine. In this context, the documents in D A represent samples of the true author A, while the impostor documents act as samples of an author different than A. Binary-extrinsic AV methods assume D U to be written by A, if it is stylistically similar to the documents in D A . However, if D U is more similar to the impostor documents, it is assumed to have been written by an author other than A.</p><p>Over the last two decades, numerous AV approaches have been proposed that can be assigned to one of the above categories. An approach that we refer to as AVIF and that belongs to the category of unary AV methods was developed by Neal et al. <ref type="bibr" coords="3,435.08,250.53,16.60,8.64" target="#b21">[22]</ref> for the purpose of continuous verification. Their method is based on an isolation forest classifier, which, like many other AV methods, considers character n-grams as underlying features. AVIF achieved a high recognition accuracy using very small training samples of 50 and 100-character blocks. However, in their study the authors explain that the method was only evaluated on positive samples (in other words, instances of the Y-class). Therefore, it is not clear how well AVIF performs under realistic conditions where both cases (Y and N) are present.</p><p>A well-known binary-intrinsic AV approach, which we denote by the name ProfAV, was proposed by Potha and Stamatatos <ref type="bibr" coords="3,297.60,369.80,15.27,8.64" target="#b23">[24]</ref>. Their method considers two documents D U and D A as character n-gram profiles and measures their relative differences using a predefined dissimilarity function. If the resulting dissimilarity score exceeds a certain threshold (derived from the distribution of Y/N-samples in a given training corpus), D U is assumed to be written by A. Potha and Stamatatos <ref type="bibr" coords="3,354.77,417.62,16.60,8.64" target="#b23">[24]</ref> demonstrated that ProfAV was able to outperform every single AV method submitted to the first AV-competition as a part of the PAN shared tasks <ref type="bibr" coords="3,268.31,441.53,15.27,8.64" target="#b15">[16]</ref>.</p><p>One of the most influential and successful binary-extrinsic AV approach is the Impostors Method (IM) proposed by Koppel and Winter <ref type="bibr" coords="3,337.65,477.11,15.27,8.64" target="#b20">[21]</ref>, which laid the foundations for many subsequent AV approaches including <ref type="bibr" coords="3,312.23,489.06,16.21,8.64" target="#b27">[28,</ref><ref type="bibr" coords="3,328.44,489.06,12.16,8.64" target="#b16">17,</ref><ref type="bibr" coords="3,340.60,489.06,12.16,8.64" target="#b17">18,</ref><ref type="bibr" coords="3,352.76,489.06,12.16,8.64" target="#b18">19,</ref><ref type="bibr" coords="3,364.92,489.06,12.16,8.64" target="#b24">25]</ref>. IM can be broken down into two steps. First, appropriate impostor documents have to be collected according to a predefined strategy (for example, using a search engine). In the second step, a feature selection technique based on character n-grams is applied iteratively to measure the similarity between pairs of documents. If, given this measure, a suspect is picked out from among the impostor set with sufficient salience, then the suspect is assumed to be the author of D U <ref type="bibr" coords="3,233.92,560.80,15.27,8.64" target="#b20">[21]</ref>. The IM variants of Khonji and Iraqi <ref type="bibr" coords="3,407.80,560.80,16.60,8.64" target="#b16">[17]</ref> and Seidman <ref type="bibr" coords="3,134.77,572.75,16.60,8.64" target="#b27">[28]</ref> were the best-performing approaches in the first and second PAN-AV competitions <ref type="bibr" coords="3,134.77,584.71,15.77,8.64" target="#b15">[16,</ref><ref type="bibr" coords="3,150.54,584.71,11.83,8.64" target="#b28">29]</ref>. Another strong approach that belongs to the category of binary-extrinsic AV methods is the so-called NNCD method proposed by Veenman and Li <ref type="bibr" coords="3,428.31,596.66,15.27,8.64" target="#b31">[32]</ref>. In contrast to IM, their method delegates the entire feature engineering procedure to a state of the art compression-algorithm. Here, D U is assumed to be written by A if the compressed representation of D U is dissimilar to those of the impostor documents. Both NNCD <ref type="bibr" coords="3,165.97,644.48,16.60,8.64" target="#b31">[32]</ref> and GenIM <ref type="bibr" coords="3,234.13,644.48,16.60,8.64" target="#b27">[28]</ref> were the best-performing approaches in the first PAN AV competition <ref type="bibr" coords="3,184.86,656.44,15.27,8.64" target="#b15">[16]</ref>.</p><p>In this section, we propose a number of feature categories that are used by our AV approach to capture the writing style of documents. A part of these are derived from certain feature categories used in previous studies. The remaining feature categories, however, have been not considered so far in the context of AV, at least to our best knowledge. All feature categories are summarized in Table <ref type="table" coords="4,376.93,193.06,4.98,8.64">1</ref> along with a number of examples. In the following subsections, we first introduce all feature categories in detail. Afterwards, we explain which design decisions we made in regard to their hyperparameters. Finally, we describe the scope from where all proposed features are extracted and how we normalized them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ID</head><p>Feature category Sample output Range</p><formula xml:id="formula_0" coords="4,135.71,285.41,338.07,12.73">F1-3 Punctuation n-grams {(,.)} n ∈ {1, 2, 3}<label>F4</label></formula><p>TA sentence and clause starters {(however) , (, there)} -F5</p><p>TA sentence endings {(this)} -F6-9 TA token n-grams {(however , there) , (, there is) , (there is an) , (to this .)} n ∈ {1, 2, 3, 4} F10-11 TA masked token n-grams {(is an #) , (# to this)} n ∈ {3, 4}</p><p>Table <ref type="table" coords="4,158.53,324.31,3.36,8.06">1</ref>. All 11 feature categories considered by TAVeer (feature categories with the TA-prefix are proposed by us). The third column shows the output for the sample sentence: "However, there is an opposing view to this." Note that for the n-gram-based feature categories, each setting of n results in an individual feature category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Topic-Agnostic Words and Phrases</head><p>Function words can be seen as the most common choice in the field of authorship analysis, when it comes to select topic-agnostic features. However, in the literature it often remains unclear what is exactly understood and represented under the term "function words". In many existing studies (for example, <ref type="bibr" coords="4,331.74,482.08,11.95,8.64" target="#b6">[7,</ref><ref type="bibr" coords="4,343.69,482.08,11.95,8.64" target="#b14">15,</ref><ref type="bibr" coords="4,355.64,482.08,11.95,8.64" target="#b33">34]</ref>) no detailed explanation is provided regarding the question, which specific function word categories (or at least which specific words) were taken into account. Another peculiarity that can be seen in the literature, is the varying number of considered function words. For example, Chandrasekaran <ref type="bibr" coords="4,180.94,529.90,10.58,8.64" target="#b6">[7]</ref>, Binongo <ref type="bibr" coords="4,235.42,529.90,10.58,8.64" target="#b2">[3]</ref>, Srinivasa <ref type="bibr" coords="4,292.16,529.90,16.60,8.64" target="#b26">[27]</ref> and Zhao and Zobel <ref type="bibr" coords="4,396.37,529.90,16.60,8.64" target="#b32">[33]</ref> make use of 24, 50, 150 and 365 function words, respectively. In view of these different numbers, the question arises why only individual subsets are considered rather than using the entire spectrum of function words. Instead of making use of non-structured and incomplete lists, Varela et al. <ref type="bibr" coords="4,205.05,577.72,16.60,8.64" target="#b30">[31]</ref> and Pavelec et al. <ref type="bibr" coords="4,295.16,577.72,16.60,8.64" target="#b22">[23]</ref> follow a different approach, in which they consider subcategories of function words such as pronouns, conjunctions, subclasses of adverbs and other word forms. By this, a better insight can be gained regarding the question which specific types of function words were actually taken into account.</p><p>Motivated by this idea, we opted for a similar but more systematic approach, in which we consider all existing categories of function words along with other carefully selected topic-agnostic (hereafter, abbreviated as TA) categories. First, we assemble a comprehensive list L TA consisting of words and phrases that belong to these categories (cf. Table <ref type="table" coords="5,207.21,131.27,3.60,8.64" target="#tab_0">2</ref>). Based on L TA , we then derive different TA feature categories (described below) that can be used to model the writing style of documents across different linguistic layers. For the construction of L TA , we use a variety of words and phrases classified into 20 categories including function words, empty verbs, contractions, generic adverbs as well as transitional words and phrases. All considered words and phrases, which are known in the literature <ref type="bibr" coords="5,330.17,191.04,16.23,8.64" target="#b22">[23,</ref><ref type="bibr" coords="5,346.40,191.04,8.12,8.64" target="#b2">3,</ref><ref type="bibr" coords="5,354.52,191.04,12.17,8.64" target="#b29">30]</ref> to be content and topic independent, have been collected from different sources, in particular, linguistic books and stylometry papers. The transitional phrases cover a number of categories including causation, contrast, similarity, clarification, conclusion, purpose and summary. With regard to the verbs, we also take the respective tenses<ref type="foot" coords="5,344.24,237.20,3.49,6.05" target="#foot_1">2</ref> into account (for example, give → {gives, giving, gave, given}) in order to enrich L TA . All categories of words and phrases contained in L TA are summarized in Table <ref type="table" coords="5,380.49,262.77,4.98,8.64" target="#tab_0">2</ref> along with a number of examples. Note that due to the ambiguities occurring in the English language, a num- ber of function words appear in multiple categories. For example, "but" and "for" are both prepositions and conjunctions, whereas "few" represents a pronoun and a quantifier. However, regarding the features in L TA , we do not differentiate between the different meanings of these homographs <ref type="foot" coords="5,296.90,605.58,3.49,6.05" target="#foot_2">3</ref> . Based on L TA , we derive additional feature categories which are described in the following.</p><p>Punctuation n-Grams (F 1-3 ) Punctuation marks represent syntactic features that quantify the grammatical structures an author uses and, thus, are content and topic independent <ref type="bibr" coords="6,178.60,143.22,15.27,8.64" target="#b29">[30]</ref>. As punctuation n-grams we define a sequence of consecutive punctuation marks where letters, digits and other non-punctuation characters are skipped (cf. Table <ref type="table" coords="6,160.15,167.13,3.60,8.64">1</ref>). Among others, punctuation n-grams capture specific symbols that occur at word-internal level such as hyphens or apostrophes used in contractions (e. g., we've or they're). Furthermore, they allow to recognize unusual punctuation habits reflecting the individual writing style of an author such as combinations of question and exclamation marks (e. g., ?!? or !?!), which occur in informal documents. In total, we consider three punctuation n-gram feature categories (F 1-3 ) that are not dependent on the list L TA . However, the feature categories F 6-11 make use of F 1 (punctuation unigram).</p><p>TA Sentence and Clause Starters (F 4 ) Words or phrases that appear at the beginning of sentences or clauses can reflect one aspect of an author's writing style. We therefore consider such sentences and clause starters as a distinct feature category. However, since our focus lies on TA-based features, we make sure that a word or phrase appearing at the beginning of a sentence or a clause is included in L TA . Note that in case of clauses, we consider the preceding punctuation mark (comma or semicolon) together with the subsequent word or phrase as a whole feature (cf. Table <ref type="table" coords="6,358.78,351.96,3.60,8.64">1</ref>).</p><p>TA Sentence Endings (F 5 ) Words or phrases that appear at the end of sentences might also reflect a stylistic habit of authors. We therefore consider such features as a distinct feature category and make sure (analogous to F 4 ) that they are included in L TA .</p><p>TA Token n-Grams (F 6-9 ) These feature categories are a form of standard token ngrams with the restriction that each token t i in a token n-gram (t 1 , t 2 , . . . , t n ) represents either a punctuation or a word appearing in L TA (cf. Table <ref type="table" coords="6,370.47,458.61,3.60,8.64">1</ref>). Note that for n = 1, the respective feature category F 6 is essentially the list L TA , which is obtained by merging all categories listed in Table <ref type="table" coords="6,248.65,482.52,3.74,8.64" target="#tab_0">2</ref>.</p><p>TA Masked Token n-Grams (F 10-11 ) These feature categories also represent a form of token n-grams with the restriction that n-1 tokens in a token n-gram (t 1 , t 2 , . . . , t n ) are either punctuation marks or words appearing in L TA . The remaining n -2 tokens, on the other hand, represent topic-related words, which are then masked by the nonpunctuation character #. The intention here is to enable the detection of contexts surrounding or adjacent to topic-agnostic words (cf. Table <ref type="table" coords="6,356.04,571.71,3.60,8.64">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Feature Category Ranges</head><p>In previous AV works (e. g., <ref type="bibr" coords="6,258.04,620.57,15.94,8.64" target="#b23">[24,</ref><ref type="bibr" coords="6,273.98,620.57,11.95,8.64" target="#b13">14,</ref><ref type="bibr" coords="6,285.93,620.57,7.97,8.64" target="#b3">4]</ref>) n-gram-based feature categories have been treated as a single concept, where the most suitable n was chosen on the basis of a hyperparameter optimization procedure. In contrast to this, we treat n-gram-based feature categories independently so that, for example, punctuation 2and 3-grams represent two individual feature categories. There is a simple justification for this decision: If we would restrict ourselves to a specific n optimized on a training corpus, we might miss important features occurring in the unseen data (test corpus) that can only be captured with an alternative setting of n. Allowing multiple settings of n for the same feature category can therefore help counteract a mismatch of existing features between training and test data.</p><p>In the following, we explain the considerations behind the ranges of the n-gram-based feature categories listed in Table <ref type="table" coords="7,270.76,216.77,3.74,8.64">1</ref>. For the punctuation n-grams, we set n = 1 as a lower limit which is useful in cases where sentences comprise only a single punctuation (e. g., full-stop, question or exclamation mark). As an upper limit, we set n = 3, as it can be expected that longer punctuation sequences between the unknown and known documents will be scarce (more on this in the next subsection). Regarding TA token n-grams, we set n = 1 and n = 4 as a lower and upper limit, respectively. For the former, we aim to capture at least single words in the documents. Here, we expect that a part of these features will be present in both documents, in most of the cases. With regard to longer sequences, we aim to capture specific phrases that can be relevant for individual authors. However, sequences with more than four tokens are less likely to appear, especially between short documents so that n = 4 can be seen as a good compromise. For the TA masked token n-grams, we set n = 3 as a lower limit, as one of our intentions is to capture (masked) topic words surrounded by topic-agnostic words, so that n = 3 is a minimum limit. As an upper limit, we set n = 4 for the same reason mentioned for TA token n-grams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Scope of Feature Extraction</head><p>In existing AV studies it is often not mentioned which scope is considered to extract n-gram-based features. Here, the scope might be the entire text, paragraphs, sentences, clauses, phrases or tokens. Depending on the considered scope, the dimension of the generated feature space may vary which, in turn, may affect the verification results. For example, extracting token n-grams from single sentences would result in a smaller number of features, in contrast to the extraction from the whole text. This is because token n-grams cross sentence boundaries, so that respective cross-sentence features are not taken into account. Despite the smaller number of available features, we have decided, with regard to our AV approach, to extract all n-gram-based features exclusively from the sentence-level of the documents. The reason for this is that in practice short text fragments (e. g., social media posts or email text bodies) are often concatenated to obtain a sufficient document length, so that one sentence might not always have a connection to a subsequent sentence. Hence, if we extract n-gram-based features from the entire text, we would erroneously create artificial cross-sentence features that may not occur in texts of a particular author. Note that for feature extraction, we only consider lower case in order to capture all possible case variants (for example, "The", "the" or "THE"), which can occur especially in informal texts.</p><p>In this section, we present our AV approach TAVeer<ref type="foot" coords="8,341.45,140.84,3.49,6.05" target="#foot_3">4</ref> , which is inspired by the methodology of biometric recognition systems. These aim to recognize individuals, based on a variety of physiological characteristics and behavioral features obtained from the hand, vein, fingerprint, face, eye, ear or voice. Here, the "Equal Error Rate" (EER) represents a statistic used to show biometric performance in the context of a verification task. Essentially, EER corresponds to a point on a ROC curve where the false acceptance rate is equal to the false rejection rate. Given a questioned document D U and a document D A from a known author A, the goal of our method is to determine whether D U was also written by A. To achieve this goal, TAVeer employs an ensemble of m distance-based classifiers, where each one aims to accept or reject the questioned authorship of D U . Each classifier is provided with a category of stylistic features extracted from an individual linguistic layer (in each document). In this context, EER serves as a thresholding mechanism, where erroneous verification predictions in either direction are treated equally. This is different from other AV methods as, for example, the approach of Bevendorff et al. <ref type="bibr" coords="8,244.22,309.89,11.62,8.64" target="#b1">[2]</ref> that heavily prioritize precision over recall.</p><p>TAVeer can essentially be divided into the two phases training and inference. In the training stage, a model M has to be "learned" on the basis of a given training corpus C = (c 1 , c 2 , . . . , c n ). Here, each c denotes a verification case, for which the ground truth (Y or N) is known. In the inference stage, the generated model M is applied to an unseen verification case in order to accept or reject the questioned authorship. In the following we first describe the preliminaries for TAVeer and then the two phases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Preliminaries</head><p>Before describing our approach in detail, we first explain what exactly is considered as an input, how this input is represented and on which basic functionality it depends in order to measure the (de)similarity between the documents. Document Input TAVeer follows the profile-based paradigm that, to our best knowledge, was first described by Potha and Stamatatos <ref type="bibr" coords="8,333.29,501.03,16.60,8.64" target="#b23">[24]</ref> in the context of AV. In case that for a known author A a set of reference documents D A = {D 1 , D 2 , . . .} is provided, the idea behind the profile-based approach is to concatenate all documents in D A into a single document D A . Thus, a verification case c is transformed from (D U , D A ) to (D U , D A ), which represents the document input for TAVeer. Document Representation As a document representation technique, we consider a bag-of-features model, in which all involved features are treated independently from each other. Let F = {F 1 , F 2 , . . . F m } be the m proposed feature categories (cf. Table <ref type="table" coords="8,150.56,613.90,3.60,8.64">1</ref>). We define a function f : D × D × F → k∈N R k × R k , which transforms D U and D A according to a given feature category F to two real valued vectors, where k denotes the dimension of the feature space spanned by F . Consider for example F 1 as a feature category, which describes a set of punctuation marks {"-", ";", "?", ...}. Applying f to D U and D A yields all punctuation marks, that exist in at least one of the documents and adds them to a list V = (v 1 , v 2 , . . . , v k ). Then, two vectors X = (x 1 , x 2 , . . . , x k ) and Y = (y 1 , y 2 , . . . , y k ) are created, where each x j and y j represents the absolute frequency of the corresponding punctuation mark v j ∈ V in each document, respectively. As a final step, we normalize each vector by its Manhattan norm • 1 , so that all contained features are scaled into the (real) interval [0, 1] and sum up to one. This procedure holds for all m feature categories.</p><p>Distance Function To measure the (dis)similarity between two generated feature vectors X and Y , we use a distance function dist(X, Y ). For this, we have chosen the well-known Manhattan metric, defined by:</p><formula xml:id="formula_1" coords="9,222.74,281.12,257.86,30.20">dist(X, Y ) = X -Y 1 = k r=1 |X r -Y r |<label>(1)</label></formula><p>which has been used in a number of previous stylometry studies (for example, <ref type="bibr" coords="9,455.69,323.42,10.67,8.64" target="#b0">[1,</ref><ref type="bibr" coords="9,466.36,323.42,7.11,8.64" target="#b4">5]</ref>).</p><p>The Manhattan metric benefits from its simplicity and also from the fact that it allows easy interpretation <ref type="foot" coords="9,208.10,345.66,3.49,6.05" target="#foot_4">5</ref> of which specific features have contributed to the prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Model Learning</head><p>Given the training corpus C and the set of the m feature categories F = {F 1 , F 2 , . . . F m }, the objective of this step is to construct a model M, which represents the optimal combination of feature categories obtained on C. In the following, we describe the necessary sub-steps to create M.</p><p>Computing Thresholds In this sub-step, we have to compute the individual thresholds Θ = (θ F1 , θ F2 , . . . , θ Fm ) for the m feature categories. Using Equation 1, we calculate for each verification case c j = (D A,j , D U ,j ) ∈ C and each feature category F i the respective distance d i,j = dist(f (D A,j , D U ,j , F i )). As a thresholding technique, we select the equal error rate (EER), which describes the point, where the false positives rate is equal to the false negatives rate. Since all corpora used in our experimental setting are balanced, a threshold, which will result in an EER, can be obtained by calculating the median of the distances over all cases in the corpus. Consequently, for all m feature categories, we obtain the corresponding thresholds as follows:</p><formula xml:id="formula_2" coords="9,176.92,588.65,303.67,9.65">Θ = (θ F1 , θ F2 , . . . , θ Fm ), with θ Fi = median(d i,1 , d i,2 , . . . , d i,n )<label>(2)</label></formula><p>Note that in case where an exact EER is not feasible (for example, when multiple distance values are equal) the median provides the closest approximation of the EER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Similarity Function</head><p>The introduced distance function (cf. Equation <ref type="formula" coords="10,419.58,119.31,4.15,8.64" target="#formula_1">1</ref>) allows us to compute distances between a pair of two feature vectors X and Y . However, the resulting distances are not calibrated with respect to the individual thresholds from the previous sub-step. Therefore, we designed a similarity function sim(•) that considers as an input a distance d, a threshold θ F and the upper bound d max of the provided distance function (in our case, the Manhattan metric). Recall that in the context of our approach, all feature vectors are normalized using the Manhattan norm • 1 . Consequently, all features in each vector sum up to 1. Based on this fact, the lower and upper bound of dist(X, Y ) can be calculated by</p><formula xml:id="formula_3" coords="10,231.17,236.41,153.02,9.68">0 ≤ X -Y 1 ≤ X 1 + Y 1 = 2</formula><p>such that d max = 2 holds. An important requirement regarding our similarity function is that the resulting score s is calibrated in a way that 0.5 represents the decision boundary.</p><p>One possible definition for a function sim(•) that transforms a distance d into the range [0, 1] and simultaneously calibrates the resulting similarity score s with respect to this "natural" decision boundary is: easily substitute the Manhattan metric with any other distance function, as long as its respective upper bound d max is known. Furthermore, it should be noticed that any other definition for sim(•) that also fulfills the same requirement can be used instead.</p><formula xml:id="formula_4" coords="10,206.25,327.32,274.34,28.57">sim(d, d max , θ F ) = 1 -d 2θ F , if d ≤ θ F , 1 2 -d-θ F 2(dmax-θ F ) , otherwise<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification Function</head><p>The similarity function sim(•) from the previous sub-step can already calculate a calibrated similarity value for a given distance d and a threshold for a single feature category. However, the idea behind TAVeer is to determine whether a questioned authorship between two documents holds based on multiple feature categories. Let F Θ = {(F i , θ Fi )|i ∈ {1, 2, . . . , m}} denote a set, which comprises pairs of feature categories and their associated thresholds and P(F Θ ) the power set (without the empty set) holding all possible combinations of these pairs. We denote a single E ∈ P(F Θ ) by the term ensemble. Furthermore, we denote an ensemble comprising a single pair {(F, θ F )} ⊆ E as an atomic ensemble. To compute a similarity value with respect to E, we define an aggregated similarity function sim E (•) as follows:</p><formula xml:id="formula_5" coords="11,196.08,222.87,284.52,24.59">sim E (D U , D A , d max , E) = median (S) , with S = {sim(dist(f (D U , D A , F )), d max , θ F )|(F, θ F ) ∈ E}<label>(4)</label></formula><p>To obtain a binary prediction (Y/N) for a single verification case c based on sim E (•), we further define a classification function:</p><formula xml:id="formula_6" coords="11,176.85,290.21,303.74,23.30">clf(D U , D A , d max , E) = Y, if sim E (D U , D A , d max , E) &gt; 0.5 N, otherwise<label>(5)</label></formula><p>Selecting Optimal Ensemble In this last sub-step, the goal is to determine the optimal ensemble on the basis of the training corpus C, which will serve as the model M for the inference stage. To achieve this goal, we use Equation <ref type="formula" coords="11,370.79,358.18,4.98,8.64" target="#formula_6">5</ref>to classify all verification cases c 1 , c 2 , . . . , c n in C for each possible ensemble E ∈ P(F Θ ). As a result, we obtain |P(F Θ )| predictions for each c i . Based on the predictions and the ground truth provided for C, we can now calculate the accuracies for each ensemble to find the optimal one that will represent M. One way to obtain an optimal ensemble would be to select the one that leads to a maximum accuracy on C. In practice, however, this approach is not always reasonable as several ensembles can share the maximum accuracy. For this reason, we decided to consider additional criteria to obtain an optimal ensemble. Based on the power set P(F Θ ), we sort all the resulting ensembles one by one according to the following three criteria (each in descending order):</p><p>1. Accuracy of an ensemble E (calculated for C)</p><p>2. Number of feature categories an ensemble E contains 3. Median accuracy regarding all atomic ensembles in E (calculated for C)</p><p>From here, it is unlikely that multiple ensembles share the same ranking regarding these criteria. Finally, we select the first ensemble from the sorted list, which will serve as the final model M.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Inference</head><p>In contrast to the training phase, the inference phase is much more compact. Here, TAVeer consumes the resulting model M from the training phase and performs the following steps to classify an unseen verification case c ? = (D U , D A ). Using Equation <ref type="formula" coords="11,473.12,632.53,3.74,8.64" target="#formula_0">4</ref>, TAVeer first computes the similarity value s ? between the unknown and known documents D U and D A . Afterwards, a binary prediction regarding the questioned authorship of D U is obtained by comparing s ? against the decision boundary 0.5 (cf. Equation <ref type="formula" coords="12,469.80,119.31,3.60,8.64" target="#formula_6">5</ref>). In case that s ? &gt; 0.5 holds, c ? is classified as Y (D U and D A are assumed to be written by the same author), otherwise as N (both documents are probably written by different authors).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Evaluation</head><p>This section gives a brief description of our experimental evaluation. At the time we developed TAVeer, we had no access to the official test corpus and the respective ground truth of the underlying verification cases. To train and evaluate our approach, we therefore have split the official training <ref type="foot" coords="12,276.78,247.17,3.49,6.05" target="#foot_5">6</ref> data set provided by the PAN organizers into a training and validation corpus. In the following, we first explain how the initial training data set was partitioned, summarize its key statistics and mention several relevant observations we have made in regard to the verification cases in the corpus. Afterwards, we describe which alternative performance measure we have chosen to evaluate TAVeer on the validation corpus. Finally, we present the results on this corpus as well as on the official test corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Corpora</head><p>From the given official training data set, we reserved a fraction of 5,000 cases to train <ref type="foot" coords="12,476.61,370.72,3.49,6.05" target="#foot_6">7</ref>and 47,590 cases to evaluate TAVeer. Table <ref type="table" coords="12,315.27,384.35,4.98,8.64" target="#tab_1">3</ref> summarizes the statistics of both partitions. During our examination of the documents within the corpus, we made some observations worth mentioning. In a number of verification cases, the known and unknown are written in different languages. For example, within the verification cases:</p><formula xml:id="formula_7" coords="12,200.08,439.58,215.19,30.92">2225c14b-e691-5c6b-833f-0eea70a8be9c a5bf996f-0fd1-57c0-9953-5c99155e4a47 831efc2b-edab-56a6-8a38-a8b18273363f</formula><p>one document is written in English while the other is written in Spanish, Swedish and French, respectively. Within the case:</p><formula xml:id="formula_8" coords="12,200.08,512.32,215.19,7.01">33c96c88-acd5-503f-ac71-7397a277d144</formula><p>both the unknown and known document are identical and in the case:</p><formula xml:id="formula_9" coords="12,200.08,549.18,215.19,7.01">2a7758a1-1f08-503d-82b1-dfdf8e928560</formula><p>one document contains a valid natural language text, while the other one contains almost entirely repetitions of the same word. Besides these manual inspected verification cases, we further performed an automated analysis with regard to all documents contained in the training and validation corpora. Here, we noticed that a large fraction of the documents contain an excessive number of quotes. While trying to remove these quotes, we found that they made up about half of the texts and also, that apostrophes and quotation marks have been normalized by the same character ", which further complicated to remove the quotes. In view of these observations, we have left the documents in their original form, so that no cleaning has been carried out at all (this also applies to the test corpus). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance Measures</head><p>To assess the performance of our approach on the validation corpus, we have selected balanced accuracy (BAC) as an alternative performance measure. Despite its robustness and suitability especially for imbalanced corpora, BAC has not yet been considered in the field of AV, to the best of our knowledge. In contrast to F 1 and the newly proposed measure F 0.5u <ref type="bibr" coords="13,195.70,400.90,10.58,8.64" target="#b1">[2]</ref>, BAC considers all four confusion matrix outcomes: true positives (TP), false negatives (FN), false positives (FP) and true negatives (TN). This is preferable <ref type="foot" coords="13,151.36,423.14,3.49,6.05" target="#foot_7">8</ref> in realistic forensic cases where two opposing goals are faced:</p><p>1. verify that an alleged authorship is indeed correct, or 2. falsify an alleged authorship correctly so that both TP and TN can be measured reliably at the same time. BAC is defined by the arithmetic mean of sensitivity = true positive rate (TPR) and specificity = false positive rate (FPR):</p><formula xml:id="formula_10" coords="13,197.73,521.79,212.75,22.53">BAC = 1 2 TPR + FPR = 1 2 TP TP + FN + TN TN + FP</formula><p>When dealing with imbalanced corpora, we have observed that BAC is easier to interpret than other recommended measures such as Cohen's κ <ref type="bibr" coords="13,371.21,565.44,15.27,8.64" target="#b9">[10]</ref>. For balanced corpora, on the other hand, BAC offers another benefit making it a reliable performance measure as it is equal to ordinary accuracy. If we consider an AV method that (due to a weak calibration) predicts nothing but Y (same-author) or N (different-author), the resulting BAC value will always be 0.5. When using F 1 , which behaves asymmetric regarding one-sided Y-and N-predictions, the resulting score is either 2 3 ≈ 0.66 or 0, respectively.</p><p>In addition to BAC, we also report the confusion matrix outcomes to allow a better comparability regarding the results made by TAVeer, as well as the four measures (AUC, c@1, F 0.5u and F 1 ) considered by the PAN organizers for the official evaluation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results</head><p>After training TAVeer on the partition with the 5,000 verification cases, we applied the trained model to the imbalanced validation corpus comprising 47,590 cases. The results for the validation corpus are shown in Table <ref type="table" coords="14,312.47,227.11,3.74,8.64" target="#tab_2">4</ref>, while the official results <ref type="foot" coords="14,418.33,225.44,3.49,6.05" target="#foot_8">9</ref> with regard to the test corpus are listed in Table <ref type="table" coords="14,271.63,239.06,3.74,8.64" target="#tab_3">5</ref> Since we cannot make any statement regarding the test corpus, we have decided to use two self-compiled corpora C Reddit and C Amazon in order to get a better understanding regarding the cross-domain capability of TAVeer. C Reddit contains (partially very colloquial) comments from the well-known Reddit platform, while C Amazon contains product reviews from the Amazon platform. Both corpora, which differ in topic and genre, are described in detail in our paper <ref type="bibr" coords="14,258.36,501.41,16.60,8.64" target="#b11">[12]</ref> along with their respective corpus statistics. In what follows, we therefore only focus on the cross-domain experiment. The question we are seeking to answer is to what extent a model M X learned on a training corpus from a domain X can be applied to a test corpus from a domain Y (with X = Y) and vice versa.</p><p>Using the procedure described in Section 4.2, we first learn the two models M Reddit and M Amazon (cf. Table <ref type="table" coords="14,232.93,579.12,4.15,8.64">7</ref>) on the training partitions of the corpora C Reddit and C Amazon . Based on M Reddit , we then apply TAVeer to the test partition of C Amazon . Afterwards, we apply M Amazon to the test partition of C Reddit . The results are shown in Table <ref type="table" coords="14,463.95,603.03,3.74,8.64">6</ref>. If we focus on the performance deviations between the models applied to the original and cross-domain corpora, we can see in this table a slight loss of -0.005 in terms of BAC and a small gain of +0.002 in terms of AUC for the C Reddit test partition. Similarly, for the test partition of C Amazon , we can observe a slightly greater loss of -0.032 and -0.012 in terms of BAC and AUC, respectively.</p><p>The reason for the small deviations can be explained by the fact that the majority of the feature categories (more precisely, F 1 , F 2 , F 4 , F 6 and F 11 ) are present in both models M Reddit and M Amazon , as can be seen in Table <ref type="table" coords="15,352.36,406.11,3.74,8.64">7</ref>. Furthermore, their respective thresholds are very similar to each other. Consequently, both models are interchangeable without major performance losses, so that (at least on these corpora) TAVeer can be considered robust with respect to the different domains.  <ref type="table" coords="15,157.65,536.67,3.36,8.06">6</ref>. Cross-domain evaluation results for our two self-compiled corpora C Reddit and CAmazon. Note that since both corpora are balanced, the BAC and c@1 values are equal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>We have presented a simple but effective distance-based authorship verification (AV) approach called TAVeer to the AV 2020 shared task of the PAN competition, where the task was to determine for a pair of documents if both texts were written by the Corpus (F1, θF 1 ) (F2, θF 2 ) (F4, θF 4 ) (F6, θF 6 ) (F7, θF 7 ) (F8, θF 8 ) (F9, θF 9 ) (F10, θF 10 ) (F11, θF 11 ) CReddit (F1, 0.343) (F2, 0.757) (F4, 1.181) (F6, 0.641) (F8, 1.956) (F9, 1.996) (F10, 1.671) (F11, 1.869) CAmazon (F1, 0.349) (F2, 0.801) (F4, 1.108) (F6, 0.680) (F7, 1.622) (F11, 1.862) Table <ref type="table" coords="16,158.09,146.38,3.36,8.06">7</ref>. Model analysis: Each row (starting with column two) represents a model M learned on the respective training partition. Recall that Fi represents a feature category and θF i its corresponding threshold.</p><p>same author. Our approach, which we call TAVeer, relies solely on topic-agnostic feature categories based on punctuation marks, function words, contractions, transitional phrases as well as several subclasses of verbs and adverbs. By this, the method differs from many existing approaches that rely on implicitly defined feature categories such as character n-grams. Using such feature categories, in particular, in the context of AV is problematic, as one has no control over the features that are indeed captured. In the worst case, the prediction of an AV method may be based on topic-related words rather than on stylistic features, so that the method will miss its true purpose. The core of TAVeer is a distance function (Manhattan metric), which in combination with a thresholding procedure (based on equal error rate) acts as the underlying classifier.</p><p>To assess our approach, we have split the training data set into a training and validation set, where for the former only 5,000 verification cases were used (in other words, less than 10% of the entire data set). This model was submitted for the final evaluation on the official test set. From the official evaluation results and those obtained on our validation corpus, it can be concluded that TAVeer is able to generalize well across both corpora, with minimal losses on the test corpus. Besides the official train and test corpora, we have further performed a cross-domain experiment regarding two self-compiled corpora. In this context, we have demonstrated that TAVeer performs robustly even though the trained models and the test corpora come from two different domains.</p><p>Nevertheless, our AV method leaves room for further improvements. Currently, TAVeer does not take into account misspelled words, which can lead to a loss of potentially relevant features, especially in connection with informal texts. We therefore leave for future work the investigation of effective possibilities to semantically match misspelled words with respect to their common entity. One idea, for example, is to use back-translation services that can handle difficult spelling mistakes, which cannot be corrected by standard spell checkers. Another direction for future work is to investigate alternative feature categories not yet been considered in this paper. In this context, one idea is to experiment with interjections (e. g., "lol" or "aha") or topic-agnostic abbreviations (for example, "e.g." or "etc."), which represent important idiosyncratic stylistic markers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="10,134.77,367.60,345.82,8.64;10,134.77,379.23,345.83,9.65"><head>Figure 1 3 Figure 1 .</head><label>131</label><figDesc>Figure 1 illustrates the behavior of sim(•) with respect to the lower and upper bound of the Manhattan metric. Note that by considering d max as a variable parameter, we can</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,134.77,313.52,345.83,218.35"><head>Table 2 .</head><label>2</label><figDesc>Transitional phrases {of course, as a result, in addition, because of, in contrast, ... } Phrasal prepositions {as opposed to, in regard to, in relation to, inspite of, out of, ... } All categories of TA-based words and phrases. The list LTA is created by taking the union of all categories.</figDesc><table /><note coords="5,135.84,313.52,27.37,6.24;5,198.31,313.52,28.92,6.24;5,135.84,326.15,37.02,6.02;5,198.31,325.92,281.22,6.09;5,135.84,334.63,34.31,6.02;5,198.31,334.41,243.74,6.09;5,135.84,343.11,34.32,6.02;5,198.31,342.89,264.56,6.09;5,135.84,351.59,26.22,6.02;5,198.31,351.37,272.89,6.09;5,135.84,360.08,30.84,6.02;5,198.31,359.85,272.89,6.09;5,135.84,372.43,43.26,6.02;5,198.31,372.21,197.94,6.09;5,135.84,380.69,247.90,6.24;5,135.84,389.39,35.17,6.02;5,198.31,389.17,247.91,6.09;5,135.84,397.88,39.02,6.02;5,198.31,397.65,268.73,6.09;5,135.84,410.23,35.47,6.02;5,198.31,410.01,264.56,6.09;5,135.84,422.36,331.19,6.24;5,135.84,430.84,318.69,6.24;5,135.84,439.55,47.30,6.02;5,198.31,439.33,247.90,6.09;5,135.84,448.03,45.00,6.02;5,198.31,447.81,277.05,6.09;5,135.84,456.29,322.86,6.24;5,135.84,464.77,318.69,6.24;5,135.84,473.26,335.35,6.24;5,135.84,485.83,46.92,6.02;5,198.31,485.61,239.58,6.09"><p>Category Examples Conjunctions {and, as, because, but, either, for, hence, however, if, neither, ... } Determiners {a, an, both, each, either, every, no, other, our, some, ... } Prepositions {above, after, among, below, beside, between, beyond, inside, ... } Pronouns {all, another, any, anyone, anything, everything, few, he, her, ... } Quantifiers {any, certain, each, either, few, less, lots, many, more, most, ... } Auxiliary verbs {can, could, might, must, ought, shall, will, ... } Delexicalised verbs {get, go, take, make, do, have, give, set, ... } Empty verbs {do, did, does, got, have, had, had, gives, giving, gave, ... } Helping verbs {am, is, are, was, were, be, been, will, should, would, could, ... } Contractions {i'm, i'd, i'll, i've, he's, it's, we'd, she's, it'll, we're, ... } Adverbs of degree {almost, enough, hardly, just, nearly, quite, simply, so, too, ... } Adverbs of frequency {again, always, never, normally, rarely, seldom, sometimes, ... } Adverbs of place {below, everywhere, here, in, inside, into, nowhere, out, ... } Adverbs of time {already, during, immediately, just, recently, still, then, yet, ... } Pronominal adverbs {hereafter, hereby, thereafter, thereby, therefore, therein, ... } Focusing adverbs {especially, mainly, particularly, generally, only, simply, ... } Conjunctive adverbs {likewise, meanwhile, moreover, namely, nonetheless, otherwise, ... } Transition words {besides, furthermore, generally, hence, thus, however, ... }</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="13,134.77,203.52,345.83,81.66"><head>Table 3 .</head><label>3</label><figDesc>Key statistics for the training and validation partitions. Notation: |C| denotes the number of verification cases in each corpus C, while |DA| denotes the number of the known documents. The average character length of D U and DA (concatenation of all documents in DA) is denoted by avg|D U | and avg|DA|, respectively.</figDesc><table coords="13,161.89,203.52,291.58,35.04"><row><cell>Corpus C</cell><cell cols="5">|C| Distribution (Y/ N) |DA| avg|DA| avg|D U |</cell></row><row><cell>CPAN (train)</cell><cell>5,000</cell><cell>2,500 / 2,500</cell><cell>1</cell><cell>21,396</cell><cell>21,392</cell></row><row><cell cols="2">CPAN (validation) 47,590</cell><cell>25,323 / 22,267</cell><cell>1</cell><cell>21,452</cell><cell>21,439</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="14,134.77,239.06,345.83,159.03"><head>Table 4 .</head><label>4</label><figDesc>. A comparison of the results of the validation and the test corpora shows that TAVeer can generalize well, where only minimal losses can be observed for the test corpus. However, since the PAN organizers did not report the four confusion matrix outcomes for the test corpus, we cannot infer from the single number metrics more fine-grained information regarding the individual classification predictions of TAVeer or the other submitted AV approaches. Furthermore, we cannot provide any analysis regarding the test corpus, since at the time this paper was written we have no access to it. Evaluation results of TAVeer and the ten selected baseline methods. Bold and underlined values represent the best and second best results.</figDesc><table coords="14,173.40,354.96,268.56,20.70"><row><cell cols="2">BAC AUC c@1 F0.5u</cell><cell>F1</cell><cell>TP</cell><cell>FN</cell><cell>FP</cell><cell>TN</cell></row><row><cell>0.819 0.897 0.818</cell><cell cols="6">0.838 0.824 20,270 5,053 3,624 18,643</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="14,144.73,657.93,194.67,6.31"><head>Table 5 .</head><label>5</label><figDesc>Official evaluation results for the PAN 2020 test corpus with regard to the "large" and "small" training data sets. Bold and underlined values represent the best and second best results.</figDesc><table coords="14,144.73,657.93,194.67,6.31"><row><cell>pan20-web/author-identification.html</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,635.17,335.86,7.77;2,144.73,646.13,335.86,7.77;2,144.73,657.08,263.82,7.77"><p>Portions of this paper are based on our published work<ref type="bibr" coords="2,355.81,635.17,13.74,7.77" target="#b11">[12]</ref>. We therefore kindly ask the interested reader who would like to cite this article to use this reference. Note that a video presentation of our approach is available at http://bit.ly/TAVeer</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,144.73,645.77,319.29,7.93"><p>For this we used pattern<ref type="bibr" coords="5,234.01,645.94,10.45,7.77" target="#b7">[8]</ref> available at https://github.com/clips/pattern.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,144.73,657.08,248.04,7.77"><p>Homographs are words with the same spelling but different meaning.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="8,144.73,656.54,296.00,8.32"><p>TAVeer stands for "Topic-agnostic Authorship Verifier based on equal error rate".</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="9,144.73,646.13,335.86,7.77;9,144.73,657.08,177.57,7.77"><p>We refer the interested reader to our extended version of this paper<ref type="bibr" coords="9,388.19,646.13,13.74,7.77" target="#b10">[11]</ref>, in which we explain in detail how the interpretation can be performed.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="12,144.73,635.14,244.04,7.77"><p>Note that we used the "small" version of the official training corpus.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="12,144.73,646.13,335.86,7.77;12,144.73,656.54,243.46,8.32"><p>Note that the submitted version of our approach was only trained on this partition. In other words, we have not retrained TAVeer on the entire training data set.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="13,144.73,646.13,335.86,7.77;13,144.73,657.08,99.94,7.77"><p>This is at least true for the real-world forensic cases we have worked on in our research department at Fraunhofer SIT.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="14,144.73,646.13,335.86,7.77"><p>The results have been taken from the PAN website https://pan.webis.de/clef20/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7">Acknowledgments</head><p>This research work has been funded by the <rs type="funder">German Federal Ministry of Education and Research</rs> and the <rs type="funder">Hessen State Ministry for Higher Education, Research and the Arts</rs> within their joint support of the <rs type="funder">National Research Center for Applied Cybersecurity ATHENE</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="17,142.61,135.44,335.44,7.77;17,150.95,146.05,272.21,8.12" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="17,195.29,135.44,245.76,7.77">The Role of Linguistic Feature Categories in Authorship Verification</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ahmed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,446.68,135.44,31.37,7.77;17,150.95,146.40,65.99,7.77">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="page" from="214" to="221" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.61,157.06,337.73,7.77;17,150.95,168.02,324.47,7.77;17,150.95,178.98,326.71,7.77;17,150.95,189.94,324.89,7.77;17,150.95,200.90,38.60,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="17,332.43,157.06,144.34,7.77">Generalizing Unmasking for Short Texts</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,163.16,168.02,312.26,7.77;17,150.95,178.98,225.15,7.77">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">Jun 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="654" to="659" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="17,142.61,211.57,306.74,7.77;17,150.95,222.18,236.67,8.12" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="17,214.22,211.57,235.13,7.77;17,150.95,222.52,123.86,7.77">Who Wrote the 15th Book of Oz? An Application of Multivariate Analysis to Authorship Attribution</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">N G</forename><surname>Binongo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,280.55,222.52,36.86,7.77">CHANCE</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="9" to="17" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.61,233.19,311.82,7.77;17,150.95,244.15,323.14,7.77;17,150.95,255.11,222.27,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="17,335.64,233.19,118.80,7.77;17,150.95,244.15,99.04,7.77">Authorship Verification for Short Messages Using Stylometry</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Brocardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Traore</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Saad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Woungang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,268.26,244.15,205.83,7.77;17,150.95,255.11,144.35,7.77">2013 International Conference on Computer, Information and Telecommunication Systems (CITS)</title>
		<imprint>
			<date type="published" when="2013-05">May 2013</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.61,265.78,322.07,7.77;17,150.95,276.39,208.95,8.12" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="17,196.55,265.78,264.26,7.77">Delta: a Measure of Stylistic Difference and a Guide to Likely Authorship</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Burrows</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,150.95,276.74,125.28,7.77">Literary and Linguistic Computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="267" to="287" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.61,287.40,324.71,7.77;17,150.95,298.36,322.68,7.77;17,150.95,309.32,315.80,7.77;17,150.95,320.28,72.38,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="17,426.97,287.40,40.35,7.77;17,150.95,298.36,146.14,7.77">Authorship Verification, Average Similarity Analysis</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Castro Castro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Adame Arcia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pelaez Brioso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Muñoz Guillena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,315.27,298.36,158.36,7.77;17,150.95,309.32,177.82,7.77">Proceedings of the International Conference Recent Advances in Natural Language Processing</title>
		<meeting>the International Conference Recent Advances in Natural Language Processing<address><addrLine>BULGARIA</addrLine></address></meeting>
		<imprint>
			<publisher>INCOMA Ltd. Shoumen</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="84" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.61,330.95,329.08,7.77;17,150.95,341.56,301.17,8.12;17,150.95,352.86,54.03,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="17,291.15,330.95,180.55,7.77;17,150.95,341.90,81.01,7.77">Use of Generalized Regression Neural Network in Authorship Attribution</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Manimannan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,237.70,341.90,170.34,7.77">International Journal of Computer Applications</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="7" to="10" />
			<date type="published" when="2013-01">January 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.61,363.18,329.46,8.12;17,150.95,374.49,38.60,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="17,261.52,363.53,63.91,7.77">Pattern for Python</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>De Smedt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,331.62,363.53,73.95,7.77">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2063" to="2067" />
			<date type="published" when="2012-06">Jun 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.61,385.16,334.11,7.77;17,150.95,396.11,324.24,7.77;17,150.95,407.07,160.90,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="17,196.79,385.16,279.94,7.77;17,150.95,396.11,62.62,7.77">Linguistic Correlates of Style: Authorship Classification with Deep Linguistic Analysis Features</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,231.64,396.11,98.58,7.77;17,385.81,396.11,89.39,7.77;17,150.95,407.07,106.61,7.77">International Conference on Computational Linguistics</title>
		<imprint>
			<date type="published" when="2004-08">August 2004</date>
			<biblScope unit="page" from="611" to="617" />
		</imprint>
	</monogr>
	<note>Proceedings of Coling 2004</note>
</biblStruct>

<biblStruct coords="17,142.24,417.74,336.89,7.77;17,150.95,428.70,325.47,7.77;17,150.95,439.66,322.61,7.77;17,150.95,450.62,244.56,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="17,238.26,417.74,240.86,7.77;17,150.95,428.70,29.42,7.77">Rethinking the Evaluation Methodology of Authorship Verification Methods</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Halvani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Graner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,275.96,439.66,197.60,7.77;17,150.95,450.62,52.85,7.77">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Bellot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Trabelsi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mothe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Murtagh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="40" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.24,461.28,329.39,7.77;17,150.95,471.89,108.85,8.12" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="17,277.42,461.28,190.81,7.77">A Step Towards Interpretable Authorship Verification</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Halvani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Graner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Regev</surname></persName>
		</author>
		<idno>CoRR abs/2006.12418</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.24,482.91,325.66,7.77;17,150.95,493.87,305.80,7.77;17,150.95,504.83,317.78,7.77;17,150.95,515.79,180.96,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="17,277.42,482.91,190.47,7.77;17,150.95,493.87,69.91,7.77">TAVeer: An Interpretable Topic-Agnostic Authorship Verification Method</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Halvani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Graner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Regev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,376.80,493.87,79.95,7.77;17,150.95,504.83,232.02,7.77">ARES 2020: The 15th International Conference on Availability, Reliability and Security</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Volkamer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Wressnegger</surname></persName>
		</editor>
		<meeting><address><addrLine>Virtual Event, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">August 25-28, 2020. 2020</date>
			<biblScope unit="page" from="41" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.24,526.45,332.41,7.77;17,150.95,537.41,321.79,7.77;17,150.95,548.37,312.85,7.77;17,150.95,559.33,23.90,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="17,279.64,526.45,195.01,7.77;17,150.95,537.41,29.42,7.77">Assessing the Applicability of Authorship Verification Methods</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Halvani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Graner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,199.02,537.41,273.72,7.77;17,150.95,548.37,90.27,7.77">Proceedings of the 14th International Conference on Availability, Reliability and Security, ARES 2019</title>
		<meeting>the 14th International Conference on Availability, Reliability and Security, ARES 2019<address><addrLine>Canterbury, UK</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">August 26-29, 2019. 2019</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.24,570.00,315.09,7.77;17,150.95,580.96,327.23,7.77;17,150.95,591.92,304.43,7.77;17,150.95,602.87,256.52,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="17,296.45,570.00,160.88,7.77;17,150.95,580.96,96.04,7.77">Author Verification Using Common N-Gram Profiles of Text Documents</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jankowska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">E</forename><surname>Milios</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Keselj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,355.66,580.96,122.53,7.77;17,150.95,591.92,304.43,7.77;17,150.95,602.87,22.30,7.77">COLING 2014, 25th International Conference on Computational Linguistics, Proceedings of the Conference: Technical Papers</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Hajic</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</editor>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2014">August 23-29, 2014. 2014</date>
			<biblScope unit="page" from="387" to="397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.24,613.54,338.09,7.77;17,150.95,624.50,326.39,7.77;17,150.95,635.46,257.92,7.77" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="17,424.20,613.54,56.13,7.77;17,150.95,624.50,90.44,7.77">Towards Active Linguistic Authentication</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Noecker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Stolerman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Greenstadt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,369.38,624.50,107.97,7.77;17,150.95,635.46,7.80,7.77">Advances in Digital Forensics IX</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Peterson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Shenoi</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg, Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="385" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.24,646.13,316.38,7.77;17,150.95,657.08,329.64,7.77" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="17,241.37,646.13,201.01,7.77">Overview of the Author Identification Task at PAN 2013</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,150.95,657.08,153.16,7.77">Working Notes for CLEF 2013 Conference</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">September 23-26, 2013 (2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,119.96,332.13,7.77;18,150.95,130.92,309.35,7.77;18,150.95,141.88,118.80,7.77" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="18,228.74,119.96,245.63,7.77;18,150.95,130.92,38.30,7.77">A Slightly-Modified GI-Based Author-Verifier with Lots of Features (ASGALF)</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Khonji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Iraqi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,208.48,130.92,153.20,7.77">Working Notes for CLEF 2014 Conference</title>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">September 15-18, 2014. 2014</date>
			<biblScope unit="page" from="977" to="983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,151.94,320.48,7.77;18,150.95,162.90,297.00,7.77;18,150.95,173.86,80.53,7.77" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="18,232.18,151.94,230.54,7.77;18,150.95,162.90,21.92,7.77">Unine at CLEF 2015 author identification: Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kocher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="18,209.74,162.90,82.96,7.77">CLEF (Working Notes)</title>
		<title level="s" coord="18,298.68,162.90,107.26,7.77">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="volume">1391</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,183.92,313.36,7.77;18,150.95,194.53,325.09,8.12" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="18,232.18,183.92,220.03,7.77">A Simple and Efficient Algorithm for Authorship Verification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kocher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,150.95,194.88,241.42,7.77">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="259" to="269" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,204.95,324.22,7.77;18,150.95,215.56,98.08,8.12" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="18,283.56,204.95,179.40,7.77">Computational Methods in Authorship Attribution</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,150.95,215.91,27.86,7.77">JASIST</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="26" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,225.97,328.21,7.77;18,150.95,236.58,111.53,8.12" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="18,237.17,225.97,229.33,7.77">Determining if Two Documents are Written by the Same Author</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Winter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,150.95,236.93,27.86,7.77">JASIST</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="178" to="187" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,246.99,321.02,7.77;18,150.95,257.95,317.53,7.77;18,150.95,268.91,299.35,7.77" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="18,312.92,246.99,150.34,7.77;18,150.95,257.95,135.09,7.77">Exploiting Linguistic Style as a Cognitive Biometric for Continuous Verification</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">J</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Sundararajan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">L</forename><surname>Woodard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,303.88,257.95,164.61,7.77;18,150.95,268.91,33.33,7.77">2018 International Conference on Biometrics, ICB 2018</title>
		<meeting><address><addrLine>Gold Coast, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">February 20-23, 2018. 2018</date>
			<biblScope unit="page" from="270" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,278.98,326.89,7.77;18,150.95,289.59,205.57,8.12" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="18,354.46,278.98,114.67,7.77;18,150.95,289.93,77.49,7.77">Using conjunctions and adverbs for author verification</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Pavelec</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">S</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">J R</forename><surname>Justino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">V</forename><surname>Batista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,233.99,289.93,25.41,7.77">J. UCS</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="2967" to="2981" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,300.00,338.35,7.77;18,150.95,310.96,306.31,7.77;18,150.95,321.92,310.28,7.77;18,150.95,332.88,64.51,7.77" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="18,245.04,300.00,185.50,7.77">A Profile-Based Method for Authorship Verification</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Potha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,448.21,300.00,32.38,7.77;18,150.95,310.96,302.27,7.77">Artificial Intelligence: Methods and Applications: 8th Hellenic Conference on AI, SETN 2014</title>
		<meeting><address><addrLine>Ioannina, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014">May 15-17, 2014. 2014</date>
			<biblScope unit="page" from="313" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,342.94,332.95,7.77;18,150.95,353.90,317.45,7.77;18,150.95,364.86,329.64,7.77;18,150.95,375.82,329.64,7.77;18,150.95,386.77,318.34,7.77;18,150.95,397.73,57.03,7.77" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="18,245.35,342.94,214.25,7.77">An Improved Impostors Method for Authorship Verification</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Potha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,208.11,364.86,272.49,7.77;18,150.95,375.82,179.52,7.77">Experimental IR Meets Multilinguality, Multimodality, and Interaction -8th International Conference of the CLEF Association</title>
		<title level="s" coord="18,198.77,386.77,174.78,7.77">Proceedings. Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Lawless</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Kelly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Mandl</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>CLEF; Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017-09-11">2017. September 11-14, 2017. 2017</date>
			<biblScope unit="volume">10456</biblScope>
			<biblScope unit="page" from="138" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,407.80,302.07,7.77;18,150.95,418.76,174.84,7.77" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="18,245.35,407.80,195.57,7.77">Improved Algorithms for Extrinsic Author Verification</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Potha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,150.95,418.76,133.51,7.77">Knowledge and Information Systems</title>
		<imprint>
			<date type="published" when="2019-10">Oct 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,428.82,310.40,7.77;18,150.95,439.43,326.23,8.12" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="18,289.94,428.82,162.70,7.77;18,150.95,439.78,58.05,7.77">Authorship attribution on imbalanced english editorial corpora</title>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">V G</forename><surname>Raju</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,214.95,439.78,170.34,7.77">International Journal of Computer Applications</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="47" />
			<date type="published" when="2017-07">Jul 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,449.84,324.44,7.77;18,150.95,460.80,319.04,7.77;18,150.95,471.76,71.72,7.77" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="18,198.78,449.84,267.90,7.77;18,150.95,460.80,40.30,7.77">Authorship Verification Using the Impostors Method Notebook for PAN at CLEF 2013</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Seidman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,209.74,460.80,154.92,7.77">Working Notes for CLEF 2013 Conference</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">September 23-26, 2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,481.83,294.19,7.77;18,150.95,492.78,317.16,7.77;18,150.95,503.74,305.79,7.77;18,150.95,514.70,120.29,7.77" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="18,304.84,492.78,163.28,7.77;18,150.95,503.74,35.49,7.77">Overview of the Author Identification Task at PAN 2014</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Sánchez-Pérez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,204.92,503.74,153.20,7.77">Working Notes for CLEF 2014 Conference</title>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">September 15-18, 2014. 2014</date>
			<biblScope unit="page" from="877" to="897" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,524.77,331.25,7.77;18,150.95,535.73,17.93,7.77" xml:id="b29">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Stolerman</surname></persName>
		</author>
		<title level="m" coord="18,205.74,524.77,83.28,7.77">Authorship Verification</title>
		<imprint>
			<publisher>uMI Dissertations Publishing</publisher>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct coords="18,142.24,545.79,298.73,7.77;18,150.95,556.75,77.03,7.77" xml:id="b30">
	<monogr>
		<title level="m" type="main" coord="18,313.96,545.79,127.01,7.77;18,150.95,556.75,39.68,7.77">Verbs and Pronouns for Authorship Attribution</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Varela</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Justino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Soares De Oliveira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,566.81,322.55,7.77;18,150.95,577.77,300.08,7.77" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="18,232.14,566.81,183.41,7.77">Authorship Verification with Compression Features</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Veenman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,433.62,566.81,31.16,7.77;18,150.95,577.77,121.52,7.77">Working Notes for CLEF 2013 Conference</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">September 23-26, 2013 (2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,587.84,329.58,7.77;18,150.95,598.79,317.93,7.77;18,150.95,609.75,317.43,7.77;18,150.95,620.71,23.90,7.77" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="18,221.77,587.84,245.82,7.77">Effective and Scalable Authorship Attribution Using Function Words</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,345.28,598.79,119.62,7.77">Information Retrieval Technology</title>
		<title level="s" coord="18,150.95,609.75,126.47,7.77">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Yamada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Meng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Myaeng</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3689</biblScope>
			<biblScope unit="page" from="174" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.24,630.78,337.20,7.77;18,150.95,641.74,304.74,7.77;18,150.95,652.69,194.66,7.77" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="18,257.34,630.78,170.91,7.77">Using relative entropy for authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Vines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,287.26,641.74,119.61,7.77">Information Retrieval Technology</title>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Leong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Kan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Ji</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg, Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="92" to="105" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
