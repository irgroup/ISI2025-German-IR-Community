<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,176.84,115.96,261.68,12.62;1,186.72,133.89,241.92,12.62;1,147.84,151.82,319.68,12.62">Herbarium-Field Triplet Network for Cross-Domain Plant Identification NEUON Submission to LifeCLEF 2020 Plant</title>
				<funder>
					<orgName type="full">NEUON AI SDN. BHD.</orgName>
				</funder>
				<funder>
					<orgName type="full">Malaysia</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,224.73,189.49,59.22,8.74"><forename type="first">Sophia</forename><surname>Chulif</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Artificial Intelligence</orgName>
								<orgName type="institution">NEUON AIai</orgName>
								<address>
									<postCode>94300</postCode>
									<settlement>Sarawak</settlement>
									<country>Malaysia https</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,306.64,189.49,83.99,8.74"><forename type="first">Yang</forename><forename type="middle">Loong</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Artificial Intelligence</orgName>
								<orgName type="institution">NEUON AIai</orgName>
								<address>
									<postCode>94300</postCode>
									<settlement>Sarawak</settlement>
									<country>Malaysia https</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,176.84,115.96,261.68,12.62;1,186.72,133.89,241.92,12.62;1,147.84,151.82,319.68,12.62">Herbarium-Field Triplet Network for Cross-Domain Plant Identification NEUON Submission to LifeCLEF 2020 Plant</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CDEDCEA51407A5FDED3C1298851A4B4D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Cross-domain plant identification</term>
					<term>computer vision</term>
					<term>triplet loss</term>
					<term>convolutional neural networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the implementation and performance of a Herbarium-Field triplet loss network to evaluate the herbarium-field similarity of plants which corresponds to the cross-domain plant identification challenge in PlantCLEF 2020. A two-streamed triplet loss network is trained to maximize the embedding distance of different plant species and at the same time minimize the embedding distance of the same plant species given herbarium-field pairs. The team submitted seven runs which achieved a Mean Reciprocal Rank score of 0.121 and 0.111 for the whole test set and the sub-set of the test set respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Plant specimens in herbaria have been used by novices and experts alike to study and confirm plant species as well as many other useful applications as described in <ref type="bibr" coords="1,192.01,472.44,9.96,8.74" target="#b3">[4]</ref>. Many works are being carried out to improve the access and preservation of these specimens as they would be considerably less expensive to obtain rather than field images. Despite its large collection, the application of herbaria specimens on the identification of real-world plants require more research <ref type="bibr" coords="1,173.35,520.26,14.61,8.74" target="#b13">[14]</ref>.</p><p>The objective in PlantCLEF 2020 <ref type="bibr" coords="1,299.80,532.21,10.96,8.74" target="#b4">[5,</ref><ref type="bibr" coords="1,310.75,532.21,7.31,8.74" target="#b5">6]</ref> involves a task of cross-domain plant classification between herbarium specimens and field (real-world plant) images. In this paper, we present our approach using a two-streamed network, namely Herbarium-Field triplet loss network to evaluate the similarity of herbarium-field pairs corresponding to the aforementioned task.</p><p>We adopt triplet loss function to optimize the plant embeddings which regulates the measure of plant similarity. The implemented network is trained to maximize the embeddings of different herbarium-field species pairs and minimize The distances between herbarium-field pairs of the same species has to be less than the herbarium-pairs of different species (red and blue box denotes the class label).</p><p>the embeddings of same species pairs. It learns the similarity between herbarium sheets and field images instead of directly classifying plant species as conventional convolutional neural networks (CNN) <ref type="bibr" coords="2,329.70,384.18,9.96,8.74" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>FaceNet: A Unified Embedding for Face Recognition and Clustering The authors in <ref type="bibr" coords="2,203.01,479.13,15.50,8.74" target="#b11">[12]</ref> introduce triplet loss function that uses a CNN to optimize face embeddings which corresponds to a measure of face similarity. Instead of training an intermediate layer, the embeddings are directly optimized in an Euclidean space for face verification. Likewise, this triplet loss function is adopted in our networks to learn the optimized plant embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Plant Disease Recognition with Siamese Network</head><p>The authors in <ref type="bibr" coords="2,455.18,560.48,10.52,8.74" target="#b1">[2]</ref> introduce Few-Shot Learning algorithms that classify leaf images with deep learning. They employ Siamese Network with triplet loss that shows the possibility of achieving high accuracy with small datasets. In addition, the authors in <ref type="bibr" coords="2,470.07,596.34,10.52,8.74" target="#b2">[3]</ref> address the classification problem using real-world images. They also show that the image embeddings extracted from the employed Siamese Network are better than using transfer learning. In the same way, we employed a two-streamed triplet loss network which works similarly to classify plants utilising the herbarium and field embeddings. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>This section describes our approach in PlantCLEF 2020, the implemented network architecture and training stages involved. The training process is split into three stages: pre-trained herbarium network, pre-trained field network and two-stream triplet loss network. The Herbarium and Field networks are trained individually to construct networks that could model generalized herbarium and field features. A triplet network is then employed to model the triplets distance between herbarium and field features. The objective is to train the network to behave: (i) herbarium features (or embeddings) of a species should be closer to the field features of the same class (ii) herbarium features of a species should be further from field features of a different class. Fig. <ref type="figure" coords="3,361.98,465.17,4.98,8.74" target="#fig_0">1</ref> illustrates the concept of triplets learning for herbarium-field pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Network Architecture</head><p>The network architecture implemented in our approach is illustrated in Figure <ref type="figure" coords="3,472.85,536.57,3.87,8.74" target="#fig_1">2</ref>. This Herbarium-Field triplet loss network is constructed with two Inception-v4 CNNs <ref type="bibr" coords="3,163.94,560.48,14.61,8.74" target="#b12">[13]</ref>, namely Herbarium CNN and Field CNN which were initialized with weights pre-trained on PlantCLEF 2020 <ref type="bibr" coords="3,308.11,572.43,10.52,8.74" target="#b4">[5]</ref> and PlantCLEF 2017 <ref type="bibr" coords="3,414.70,572.43,10.52,8.74" target="#b6">[7]</ref> respectively. Both networks are formed to cater for the generalization of herbarium and field features. At the final embedding layer of each network, a batch normalization layer is added and the output is fed into a fully-connected layer. The output size of the fully-connected layer is then reduced from 1536 to 500. Subsequently, these outputs are L2 normalized in the L2 layer and concatenated to give an output size of (n * m) × 500 whereby n and m is the batch size of the Herbarium and Field networks respectively. This concatenated embedding is later passed into the triplet loss layer<ref type="foot" coords="4,246.96,117.42,3.97,6.12" target="#foot_0">1</ref> through which the network learns to compute the herbarium and field embeddings with respective to their optimum embedding space. The network is trained to maximize the embedding distance of different species in herbarium-field pairs and minimize the embedding distance of the same species. The classification of species is dependent on the computed embedding space by which a large embedding distance denotes different species and a small embedding distance indicates same species. There are two types of training methods investigated i.e., frozen front layers and non-frozen front layers.</p><p>Frozen Front Layers In this method, the front layers of the pre-trained Herbarium and Field network, or simply, the extractor layer of the network is frozen. This allows only the weights in the newly added layer (triplet loss layer) to be updated.</p><p>Non-Frozen Layers This method on the other hand trains all layers in the network. It allows the network to relearn and recompute the embeddings of herbarium and field images with respective to their optimized embedding space from the triplet loss. The new layers are set to have a higher learning rate than the migrated layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training stages</head><p>Herbarium Network As mentioned in 3.1, a Herbarium network based on the Inception-v4 model <ref type="bibr" coords="4,241.69,447.37,15.50,8.74" target="#b12">[13]</ref> is set up to make up the Herbarium-Field triplet loss network. The Herbarium network is initialized on weights pre-trained from ImageNet <ref type="bibr" coords="4,179.29,471.28,15.50,8.74" target="#b10">[11]</ref> and trained with PlantCLEF 2020 dataset (herbarium images) <ref type="bibr" coords="4,467.31,471.28,9.96,8.74" target="#b4">[5]</ref>.</p><p>Field Network Likewise, the Field network adopts the Inception-v4 <ref type="bibr" coords="4,444.16,497.17,15.50,8.74" target="#b12">[13]</ref> network architecture. It is also initialized with weights pre-trained from ImageNet <ref type="bibr" coords="4,134.77,521.08,15.50,8.74" target="#b10">[11]</ref> but trained with PlantCLEF 2017 dataset (field images) <ref type="bibr" coords="4,402.79,521.08,10.52,8.74" target="#b6">[7]</ref> instead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Herbarium-Field Triplet Loss Network</head><p>Once the Herbarium and Field networks are trained, the Herbarium-Field Triplet Loss network is set up. The network is trained with PlantCLEF 2020 dataset <ref type="bibr" coords="4,339.90,570.87,10.52,8.74" target="#b4">[5]</ref> consisting of both herbarium and field images. The network trained in the Non-Frozen Layers setup is set with a learning rate of 0.00001 in the migrated layers and 0.0001 in the newly added layers, whereas the Frozen Front Layers setup is set with a learning rate of zero in the migrated layers. 4 Training Setup</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Preparation</head><p>As mentioned in the task description, only a subset of species for field images were provided to allow learning a mapping between the herbarium and field domain. We separated the species which possess both herbarium and field images to be used for mapping. Out of 997 classes, 435 classes were identified having both herbarium and field images. These classes were then used for training.</p><p>Although the total number of classes was reduced from 997 to 435 species, the network was still trained to map the embedding space of 997 classes.</p><p>During the training of the Herbarium-Field triplet loss network, the images used for each batch were picked to be balanced for each class. For instance, in a batch of size 16, each class may not comprise more than 4 images, meanwhile the minimum number of images in each class is 2. This allows a balanced selection of anchors for the triplet loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data Augmentation</head><p>In order to increase the network generalization and increase training sample size, data augmentation was applied on the training images. Random cropping, horizontal flipping and colour distortion (brightness, saturation, hue, and contrast) of images were performed on the training dataset. As a result, features and various transforms that are invariant to their original locations can be learned by the network, consequently reducing the chance of overfitting <ref type="bibr" coords="5,400.85,516.18,14.61,8.74" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Training Dataset and Hyperparameters</head><p>The training dataset distributions and network setup parameters are summarized in Table <ref type="table" coords="5,173.78,583.16,4.98,8.74" target="#tab_0">1</ref> and Table <ref type="table" coords="5,228.86,583.16,4.98,8.74" target="#tab_1">2</ref> respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>The experiments were conducted using Tensorflow 1.13 <ref type="bibr" coords="5,379.00,644.16,10.52,8.74" target="#b0">[1]</ref> alongside slim packages. The codes are available at https://github.com/NeuonAI/plantclef2020 challenge  <ref type="table" coords="6,161.82,328.39,3.87,8.74" target="#tab_0">1</ref>. The number of images and classes present in the experimented training and testing dataset are summarized in Table <ref type="table" coords="6,341.47,340.34,3.87,8.74" target="#tab_2">3</ref>. Nevertheless, the class number for the Herbarium-Field triplet loss network remains 997 and 10,000 in the Herbarium and Field network stream respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Inference Procedure</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Herbarium dictionary</head><p>For inference, the embeddings from 997 herbarium classes were first extracted using the trained Herbarium-Field triplet loss network to form the reference embeddings served as a herbarium dictionary. Random samples from each class were picked and fed into the network to obtain the embeddings. The extracted embeddings were then averaged to get a single embedding representation for each class. The embedding for each class was subsequently saved as a dictionary. Note that the extraction was done with two different types of image cropping, namely, Center Crop and Center and Corner Crop. The Center Crop approach crops the centre region of the herbarium sample. Meanwhile, the Corner Crop approach on the other hand crops the top left, top right, bottom left, and bottom right region of the herbarium sample. Each region was cropped and resized then </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature similarity</head><p>After obtaining the single embedding representation of each class, the saved dictionary is then used to compare the embedding distance between the 997 herbarium representation and the test image. During validation, Center and Corner Crop were also applied together with horizontal flip in obtaining the test images' embeddings. This resulted in 10 different variations for each image which was then averaged to obtain their similarity probability. Cosine similarity was used as the distance metric in measuring the embedding similarity. Then, the cosine distance was obtained by subtracting the cosine similarity from 1. Finally, inverse distance weighting was performed on the cosine distance to obtain the probabilities of each class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Network and Results</head><p>The experimented results are tabulated in Table <ref type="table" coords="7,348.53,554.85,4.98,8.74" target="#tab_3">4</ref> and Table <ref type="table" coords="7,403.32,554.85,4.98,8.74" target="#tab_4">5</ref> for Center Crop and Center Crop and Corner Crop herbarium extraction methods respectively. The networks were tested on the same validation set of 1,219 images in which the Top 1 and Top 5 predictions were evaluated. Center Crop and Corner Crop were also applied on the field test set before validation. 5 different Herbarium-Field triplet loss networks were experimented, i.e.:</p><p>Network 1: Frozen Front Layers (FL) A network trained with frozen front layers.</p><p>Network 2: Non-Frozen Layers (NFL) A network trained with non-frozen layers, or to put simply, trained with all layers.</p><p>Network 3: Non-Frozen Layers Ensemble Model (NFL-ENS) A ensemble of 3 different models trained on all layers.</p><p>Network 4: Non-Frozen Layers Increased Augmentation (NFL-AUG) A network trained with all layers whereby the training images were pre-processed with more transformations and augmentation.</p><p>Network 5: Non-Frozen Layers Increased Augmentation Model Ensemble (NFL-AUG-ENS) An ensemble of Network 3 and Network 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Discussion</head><p>From the experiments, it can be seen that the NFL ensemble models performed the best among the networks. The ensemble of these networks increased the robustness of the system and returned better predictions. On the other hand, the FL network performed the worst among the networks. It can be suggested that the training of all layers does help the prediction model instead of freezing the front layers or extractor layers of the network. In can be seen that the ensemble models with increased augmentation performed equally as to the ensemble model without increased augmentation. It can be suggested that the increased augmentation may have not produced enough new significant information for the network to learn. Since a portion of field images were separated from the training set to serve as test set, some of the classes may miss some field information. In addition, the trained model does not represent the entire classes as some classes miss field images. Consequently, the networks did not performed as well as it was not fed with sufficient images to represent the field domain. An approach to increasing the prediction accuracy would be increasing the training samples of the field images that are not present in the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Submission</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Inference Procedure</head><p>The procedure adopted to produce the submitted results are as follow:</p><p>(i) Construct herbarium dictionary by extracting samples of herbarium embeddings for all 997 plant species using the trained Herbarium-Field triplet loss network. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Submitted Runs</head><p>The team submitted a total of seven runs based off the networks mentioned in Section 5.3.</p><p>Run 1 This model was based off (FL). Unlike the rest of the runs, this network was trained with frozen front layers and does not apply image flipping during validation. Moreover, the embedding distances were normalized, inversed then applied with softmax to obtain the probabilities. In addition, the probabilities were based off the averaged embedding instead of all embeddings for each observation ID.</p><p>Run 2 This model was based off (NFL). Similar to Run 1 however it was trained with all layers of the network, the embeddings of each observation IDs were averaged and then applied with Cosine Similarity and Inverse Distance Weighting to obtain the probabilities.</p><p>Run 3 This model was based off (NFL). Similar to Run 2 however by using Cosine Similariy and Inverse Weighting, the probabilities of each embeddings were first computed then averaged for each observation IDs .</p><p>Run 4 This model was based off (NFL). Similar to Run 3 however the probabilities take into account the total embeddings of each observation IDs multiplied by their croppings which consist of 10 variations.  <ref type="table" coords="10,413.62,269.58,3.87,8.74" target="#tab_0">1</ref>. It is also an ensemble of the predictions from 3 models of the same network.</p><p>Run 6 This model was based off (NFL-AUG). Similar to Run 5 which was trained with the full dataset however it is not an ensemble of models and trained with increased image processing transformations and augmentations.</p><p>Run 7 This model was based off (NFL-AUG-ENS). This run is the ensemble of the predictions from Run 5 and Run 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Submission Results</head><p>Our best submitted runs scored a Mean Reciprocal Rank (MRR) of 0.121 and 0.108 for the first and second metric respectively. Our results are tabulated in Table <ref type="table" coords="10,161.76,450.89,3.87,8.74" target="#tab_5">6</ref>. The results by all the participating teams are summarised in Fig. <ref type="figure" coords="10,456.64,450.89,4.98,8.74" target="#fig_3">3</ref> and Fig. <ref type="figure" coords="10,155.10,462.85,3.87,8.74" target="#fig_4">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Discussion</head><p>Similar to the experiment results, the ensemble models performed the best among the networks. The ensemble model with increased augmentation on the other hand performed best in the whole test set. In addition, the MRR score of the networks for the first and second metric are relatively close despite the few training photos in the sub-set species. It can be suggested that the number of training samples for each class does not directly influence the performance of the model. Other than filling the missing training samples of the field classes, the methods in obtaining the herbarium embedding representation can also be looked into to increase prediction accuracy. Such methods involve finding the best herbarium dictionary representation. Various image processing methods like flipping can be performed before extracting the herbarium embeddings. Meanwhile, finding the best model of the Herbarium-Field Triplet Loss Network and using it for the extraction of the herbarium embeddings would be significant as well.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Post-challenge Runs</head><p>In addition to the submitted results, the team trained another 3 runs which was based off the continuation of Run 6. However, the results did not performed better than the submitted runs. Since the runs were trained with the whole dataset, we believe the drop in performance is due to overfitting as there was no baseline to determine when to stop training the model. The MRR score of the runs are tabulated in Table <ref type="table" coords="12,257.47,486.84,3.87,8.74" target="#tab_6">7</ref>.</p><p>Run 8 This model was based off (NFL-AUG). This run was a continuation of the training from Run 6 which was trained with increased iterations.</p><p>Run 9 This model was based of (NFL-AUG-ENS). This run was an ensemble of Run 8 and Run 5 predictions.</p><p>Run 10 This model was based off (NFL-ENS). This run was an ensemble of 3 different models from Run 8.</p><p>We tested the post-challenge runs on our segregated test set as well and the results are tabulated in Table <ref type="table" coords="12,262.00,644.16,4.98,8.74" target="#tab_7">8</ref> and Table <ref type="table" coords="12,314.11,644.16,4.98,8.74" target="#tab_8">9</ref> for Center Crop and Center and Corner Crop herbarium dictionary construction methods respectively. In contrast with its MRR score, Run 8 shows the best performance in the experimental validation setup when in fact it performed the worst among the post-challenge runs. This is likely due to overfitting as mentioned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>In this paper we have presented our approach in PlantCLEF 2020 which focused on the cross-domain plant identification between herbarium sheets and in-field photos. We adopted a two-streamed Herbarium-Field triplet loss network which performed relatively equal regardless if few field training images were given. Based on the similar score between MRR metric 1 and 2, it is proven that the proposed network feature is not directly affected by the plant class but it learns to perceive the similarity between a given field image with herbarium images. It is shown that even with a minimal amount of field images for each species, crossdomain plant identification can be performed. The identification of real-world plants based on herbarium sheets alone is indeed a challenging task. Although our machines did not performed as well with missing field classes which is the case in real-world, it shows that with sufficient data, it offers a step in alleviating the tedious task of herbarium-field classification which requires high level expertise. For future work, the field images that are not present among the training dataset can be added to improve the predictions. This would allow the model to learn the whole representation of plant species with respect to their herbarium and field domain. Furthermore, the extraction of herbarium embeddings to form a more powerful dictionary can be investigated to find the best representation of herbarium embeddings for the herbarium-field similarity comparison.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,134.77,275.77,345.82,7.89;2,134.77,286.75,345.83,7.86;2,134.77,297.71,345.82,7.86;2,134.77,308.67,345.83,7.86;2,134.77,319.63,345.83,7.86;2,134.77,330.59,331.70,7.86;2,134.77,115.83,345.83,155.12"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The triplet loss concept mainly revolves around minimizing the distances between same class and maximizing the distances between different classes. (a) shows two classes with its herbarium counterpart, the image embedding is compared with its own herbarium and the herbarium from another class (as indicated by the arrows). (b)The distances between herbarium-field pairs of the same species has to be less than the herbarium-pairs of different species (red and blue box denotes the class label).</figDesc><graphic coords="2,134.77,115.83,345.83,155.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,155.24,293.19,304.87,7.89;3,134.77,115.83,345.83,162.59"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Network Architecture of the Herbarium-Field Triplet Loss Network.</figDesc><graphic coords="3,134.77,115.83,345.83,162.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,150.93,632.02,303.92,8.74;8,150.37,644.04,330.22,8.74;8,168.64,655.99,24.91,8.74;9,133.44,118.99,284.97,8.74;9,130.67,131.46,349.92,8.74;9,151.70,143.42,159.97,8.74;9,130.95,155.89,323.78,8.74;9,133.71,168.36,346.88,8.74;9,151.70,180.31,37.38,8.74;9,130.95,192.78,154.20,8.74;9,128.18,205.25,352.41,8.74;9,151.70,217.20,164.28,8.74;9,125.41,229.67,355.18,8.74;9,151.70,241.63,19.09,8.74;9,130.95,254.10,265.92,8.74;9,133.71,266.56,243.12,8.74;9,130.95,279.03,349.65,8.74;9,151.70,290.99,34.45,8.74;9,128.18,303.46,285.90,8.74;9,125.41,315.93,338.95,8.74"><head></head><label></label><figDesc>(a) Apply Center and Corner Crops on the images before extraction. (b) Average the cropped herbarium embeddings for each species and save them. (ii) Group the test images belonging to the same observation ID. (iii) For each image under the same observation ID, apply Center and Corner Crops which result in 5 images each. (iv) Subsequently flip the images horizontally resulting in 10 images each. (v) Average the 10 images and pass them to the Herbarium-Field triplet loss network. (vi) Obtain the image embeddings. (vii) Compute cosine similarity between each of the extracted embeddings with the saved 997 herbarium embeddings. (viii) Obtain cosine distance by subtracting the cosine similarity from the value of 1. (ix) Apply inverse distance weighting on the cosine distance. (x) Obtain the probabilities of the embedding distance. (xi) Average the probabilities over the total number of images for each observation ID. (xii) Repeat steps (iii) to (xii) for the remaining observation IDs. (xiii) Collect the predictions, probabilities and ranks for each observation ID.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="11,219.51,386.86,176.33,7.89;11,82.89,121.32,449.58,250.77"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Official Results of PlantCLEF 2020.</figDesc><graphic coords="11,82.89,121.32,449.58,250.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="11,162.35,649.04,290.66,7.89;11,82.89,413.70,449.57,220.58"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Official Results of PlantCLEF 2020 (Second Metric Evaluation).</figDesc><graphic coords="11,82.89,413.70,449.57,220.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,166.81,115.91,280.54,75.56"><head>Table 1 .</head><label>1</label><figDesc>Training dataset distribution for different networks</figDesc><table coords="5,166.81,129.11,280.54,62.36"><row><cell>Network</cell><cell cols="4">Number of images Number of classes Herbarium Field Herbarium Field</cell></row><row><cell>Herbarium</cell><cell>305,531</cell><cell>-</cell><cell>997</cell><cell>-</cell></row><row><cell>Field</cell><cell>-</cell><cell>1,187,484</cell><cell>-</cell><cell>10,000</cell></row><row><cell cols="2">Herbarium-Field Triplet Loss 197,552</cell><cell>6,257</cell><cell>435</cell><cell>435</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,115.91,368.33,221.21"><head>Table 2 .</head><label>2</label><figDesc>Network training parametersDue to the limited field training samples, prior to training, a sample of images from each of the "herbarium photo associations" and "photo" folders were randomly segregated for validation purposes. 1,219 field images were separated from the test set leaving 5,038 field images for training instead of 6,257 as stated in Table</figDesc><table coords="6,134.77,129.11,368.33,140.11"><row><cell>Parameter</cell><cell cols="2">Herbarium and Field Network Herbarium-Field Triplet Loss Network Value Value</cell></row><row><cell>Batch Size</cell><cell>256</cell><cell>16</cell></row><row><cell>Input Image Size</cell><cell>299 × 299 × 3</cell><cell>299 × 299 × 3</cell></row><row><cell>Optimizer</cell><cell>Adam Optimizer[8]</cell><cell>Adam Optimizer[8]</cell></row><row><cell>Initial Learning Rate</cell><cell>0.0001</cell><cell>0.0001</cell></row><row><cell>Weight Decay</cell><cell>0.00004</cell><cell>0.00004</cell></row><row><cell>Loss Function</cell><cell>Softmax Cross Entropy</cell><cell>Triplet Loss</cell></row><row><cell>5.1 Dataset</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,157.96,395.81,299.43,62.73"><head>Table 3 .</head><label>3</label><figDesc>Dataset of experimented Herbarium-Field Triplet Loss Network.</figDesc><table coords="6,200.59,416.61,214.18,41.94"><row><cell>Network</cell><cell cols="2">Herbarium</cell><cell>Field</cell></row><row><cell>Dataset</cell><cell cols="3">Train Test Train Test</cell></row><row><cell>Number of images</cell><cell cols="3">153,867 43,685 5,038 1,219</cell></row><row><cell cols="2">Number of classes present 435</cell><cell cols="2">434 435 345</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,161.90,115.91,291.56,103.08"><head>Table 4 .</head><label>4</label><figDesc>Validation Accuracy with Center Crop Herbarium Extraction.</figDesc><table coords="7,177.47,135.98,257.73,83.01"><row><cell></cell><cell></cell><cell>Top 1</cell><cell></cell><cell>Top 5</cell></row><row><cell>Networks</cell><cell>Top 1 Center Crop</cell><cell>Center Crop +</cell><cell>Top 5 Center Crop</cell><cell>Center Crop +</cell></row><row><cell></cell><cell></cell><cell>Corner Crop</cell><cell></cell><cell>Corner Crop</cell></row><row><cell>FL</cell><cell>27.48 %</cell><cell>28.63 %</cell><cell>50.78 %</cell><cell>52.42 %</cell></row><row><cell>NFL</cell><cell>32.65 %</cell><cell>32.73 %</cell><cell>59.97 %</cell><cell>58.98 %</cell></row><row><cell>NFL-ENS</cell><cell>36.42 %</cell><cell>37.33 %</cell><cell>65.14 %</cell><cell>67.51%</cell></row><row><cell>NFL-AUG</cell><cell>18.05 %</cell><cell>18.46 %</cell><cell>42.49 %</cell><cell>42.49 %</cell></row><row><cell cols="2">NFL-AUG-ENS 36.42 %</cell><cell>37.33 %</cell><cell>65.14 %</cell><cell>67.51 %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,134.77,232.28,343.51,138.73"><head>Table 5 .</head><label>5</label><figDesc>Validation Accuracy with Center and Corner Crop Herbarium Extraction.</figDesc><table coords="7,177.47,252.35,257.73,83.01"><row><cell></cell><cell></cell><cell>Top 1</cell><cell></cell><cell>Top 5</cell></row><row><cell>Networks</cell><cell>Top 1 Center Crop</cell><cell>Center Crop +</cell><cell>Top 5 Center Crop</cell><cell>Center Crop +</cell></row><row><cell></cell><cell></cell><cell>Corner Crop</cell><cell></cell><cell>Corner Crop</cell></row><row><cell>FL</cell><cell>27.40 %</cell><cell>29.20 %</cell><cell>50.78 %</cell><cell>52.17 %</cell></row><row><cell>NFL</cell><cell>33.06 %</cell><cell>34.29 %</cell><cell>59.80 %</cell><cell>58.98 %</cell></row><row><cell>NFL-ENS</cell><cell>36.10 %</cell><cell>37.57 %</cell><cell>63.82 %</cell><cell>66.45 %</cell></row><row><cell>NFL-AUG</cell><cell>18.29 %</cell><cell>18.79 %</cell><cell>41.84 %</cell><cell>42.74 %</cell></row><row><cell cols="2">NFL-AUG-ENS 36.10 %</cell><cell>37.57 %</cell><cell>63.82 %</cell><cell>66.45 %</cell></row></table><note coords="7,134.77,362.28,300.01,8.74"><p>passed into the network for the extraction of herbarium embeddings.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,134.77,115.91,345.83,162.41"><head>Table 6 .</head><label>6</label><figDesc>MRR Score of the Submitted Runs This model was based off (NFL-ENS). Unlike Run 1 to 4, the network was trained together with the full dataset as stated in Table</figDesc><table coords="10,134.77,138.15,271.91,128.21"><row><cell>Run</cell><cell>MRR Whole</cell><cell>MRR Sub-Set</cell></row><row><cell>7</cell><cell>0.121</cell><cell>0.107</cell></row><row><cell>5</cell><cell>0.111</cell><cell>0.108</cell></row><row><cell>3</cell><cell>0.103</cell><cell>0.094</cell></row><row><cell>2</cell><cell>0.099</cell><cell>0.076</cell></row><row><cell>6</cell><cell>0.093</cell><cell>0.066</cell></row><row><cell>4</cell><cell>0.088</cell><cell>0.073</cell></row><row><cell>1</cell><cell>0.081</cell><cell>0.061</cell></row><row><cell>Run 5</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="12,208.68,115.91,198.00,69.73"><head>Table 7 .</head><label>7</label><figDesc>MRR Score of Post-challenge Runs</figDesc><table coords="12,208.68,139.90,198.00,45.74"><row><cell>Run</cell><cell>MRR Whole</cell><cell>MRR Sub-Set</cell></row><row><cell>8</cell><cell>0.101</cell><cell>0.094</cell></row><row><cell>9</cell><cell>0.114</cell><cell>0.105</cell></row><row><cell>10</cell><cell>0.110</cell><cell>0.107</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="12,134.77,201.05,345.83,81.88"><head>Table 8 .</head><label>8</label><figDesc>Post-challenge Validation Accuracy with Center Crop Herbarium Dictionary.</figDesc><table coords="12,201.37,221.12,209.93,61.81"><row><cell></cell><cell></cell><cell>Top 1</cell><cell></cell><cell>Top 5</cell></row><row><cell>Run</cell><cell>Top 1 Center Crop</cell><cell>Center Crop +</cell><cell>Top 5 Center Crop</cell><cell>Center Crop +</cell></row><row><cell></cell><cell></cell><cell>Corner Crop</cell><cell></cell><cell>Corner Crop</cell></row><row><cell>8</cell><cell>44.71%</cell><cell>45.94%</cell><cell>75.80%</cell><cell>77.19%</cell></row><row><cell>9</cell><cell>36.42%</cell><cell>37.33%</cell><cell>65.14%</cell><cell>67.51%</cell></row><row><cell>10</cell><cell>36.42%</cell><cell>37.33%</cell><cell>65.14%</cell><cell>67.51%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="12,134.77,295.72,345.83,92.84"><head>Table 9 .</head><label>9</label><figDesc>Post-challenge Validation Accuracy with Center and Corner Crop Herbarium Dictionary.</figDesc><table coords="12,200.03,326.75,209.93,61.82"><row><cell></cell><cell></cell><cell>Top 1</cell><cell></cell><cell>Top 5</cell></row><row><cell>Run</cell><cell>Top 1 Center Crop</cell><cell>Center Crop +</cell><cell>Top 5 Center Crop</cell><cell>Center Crop +</cell></row><row><cell></cell><cell></cell><cell>Corner Crop</cell><cell></cell><cell>Corner Crop</cell></row><row><cell>8</cell><cell>46.02%</cell><cell>48.32%</cell><cell>74.98%</cell><cell>76.95%</cell></row><row><cell>9</cell><cell>36.10%</cell><cell>37.57%</cell><cell>63.82%</cell><cell>66.45%</cell></row><row><cell>10</cell><cell>36.10%</cell><cell>37.57%</cell><cell>63.82%</cell><cell>66.45%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,144.73,645.84,335.86,7.86;4,144.73,656.80,60.23,7.86"><p>The triplet loss is computed using triplet semihard loss function provided in Tensorflow 1.13<ref type="bibr" coords="4,195.23,656.80,9.73,7.86" target="#b0">[1]</ref> </p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p>The resources of this project is supported by <rs type="funder">NEUON AI SDN. BHD.</rs>, <rs type="funder">Malaysia</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="13,142.96,535.89,337.64,7.86;13,151.52,546.85,329.07,7.86;13,151.52,557.81,329.07,7.86;13,151.52,568.77,329.07,7.86;13,151.52,579.73,329.07,7.86;13,151.52,590.69,329.07,7.86;13,151.52,601.65,329.07,7.86;13,151.52,612.60,284.72,8.12" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mané</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/,softwareavailablefromtensorflow.org" />
		<title level="m" coord="13,167.61,601.65,280.76,7.86">TensorFlow: Large-scale machine learning on heterogeneous systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,623.92,337.63,7.86;13,151.52,634.88,329.07,7.86;13,151.52,645.84,329.07,7.86;13,151.52,656.80,56.31,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,240.72,634.88,239.87,7.86;13,151.52,645.84,127.75,7.86">Few-shot learning approach for plant disease classification using images taken in the field</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Argüeso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Picon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Irusta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Medela</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>San-Emeterio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bereciartua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Alvarez-Gila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,286.68,645.84,173.36,7.86">Computers and Electronics in Agriculture</title>
		<imprint>
			<biblScope unit="volume">175</biblScope>
			<biblScope unit="page">105542</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,119.67,337.63,7.86;14,151.52,130.63,162.85,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="14,344.05,119.67,136.53,7.86;14,151.52,130.63,134.18,7.86">Classification of various plant diseases using deep siamese network</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">S</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">S</forename><surname>Redkar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,141.59,337.64,7.86;14,151.52,152.55,125.36,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="14,201.44,141.59,167.31,7.86">100 uses for an herbarium: well at least 72</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">A</forename><surname>Funk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,375.42,141.59,105.17,7.86;14,151.52,152.55,96.69,7.86">American Society of Plant Taxonomists Newsletter</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,163.51,337.63,7.86;14,151.52,174.47,329.07,7.86;14,151.52,185.43,190.04,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="14,285.03,163.51,195.56,7.86;14,151.52,174.47,15.40,7.86">Overview of the lifeclef 2020 plant identification task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,186.97,174.47,293.63,7.86;14,151.52,185.43,24.01,7.86">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-09">Sep. 2020. 2020</date>
		</imprint>
	</monogr>
	<note>CLEF working notes 2020</note>
</biblStruct>

<biblStruct coords="14,142.96,196.39,337.64,7.86;14,151.52,207.34,329.07,7.86;14,151.52,218.30,329.07,7.86;14,151.52,229.26,329.07,7.86;14,151.52,240.22,329.07,7.86;14,151.52,251.18,25.60,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="14,376.51,218.30,104.08,7.86;14,151.52,229.26,159.72,7.86">Lifeclef 2020: Biodiversity identification and prediction challenges</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Deneu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ruiz De Castaneda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Champ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Eggel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dorso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lorieul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">R</forename><surname>Stöter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,334.81,229.26,145.78,7.86;14,151.52,240.22,188.77,7.86">Proceedings of CLEF 2020, CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting>CLEF 2020, CLEF: Conference and Labs of the Evaluation Forum<address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-09">Sep. 2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,262.14,337.63,7.86;14,151.52,273.10,329.07,7.86;14,151.52,284.06,329.07,7.86;14,151.52,295.02,329.07,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="14,348.80,273.10,131.79,7.86;14,151.52,284.06,152.70,7.86">Lifeclef 2017 lab overview: multimedia species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Planque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Palazzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,325.61,284.06,154.98,7.86;14,151.52,295.02,208.98,7.86">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="255" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,305.98,337.63,7.86;14,151.52,316.93,93.19,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="14,239.72,305.98,176.61,7.86">Adam: A method for stochastic optimization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="14,142.96,327.89,337.63,7.86;14,151.52,338.85,329.07,7.86;14,151.52,349.81,86.01,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="14,328.09,327.89,152.50,7.86;14,151.52,338.85,103.94,7.86">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,275.64,338.85,200.74,7.86">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,360.77,337.97,7.86;14,151.52,371.73,329.07,7.86;14,151.52,382.69,192.95,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="14,293.21,360.77,187.38,7.86;14,151.52,371.73,140.77,7.86">Data augmentation for improving deep learning in image classification problem</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Miko Lajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Grochowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,315.48,371.73,165.10,7.86;14,151.52,382.69,80.39,7.86">2018 international interdisciplinary PhD workshop (IIPhDW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="117" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,393.65,337.97,7.86;14,151.52,404.61,329.07,7.86;14,151.52,415.56,329.07,7.86;14,151.52,426.52,60.92,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="14,420.31,404.61,60.28,7.86;14,151.52,415.56,130.65,7.86">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,288.93,415.56,160.68,7.86">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,437.48,337.97,7.86;14,151.52,448.44,329.07,7.86;14,151.52,459.40,204.12,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="14,324.72,437.48,155.87,7.86;14,151.52,448.44,104.63,7.86">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,278.40,448.44,202.20,7.86;14,151.52,459.40,120.32,7.86">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,470.36,337.97,7.86;14,151.52,481.32,329.07,7.86;14,151.52,492.28,146.20,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="14,360.37,470.36,120.22,7.86;14,151.52,481.32,200.58,7.86">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,372.47,481.32,108.13,7.86;14,151.52,492.28,117.53,7.86">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,503.24,337.97,7.86;14,151.52,514.19,329.07,7.86;14,151.52,525.15,65.02,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="14,376.73,503.24,103.86,7.86;14,151.52,514.19,176.41,7.86">Automated plant species identification-trends and future directions</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wäldchen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rzanny</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Seeland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mäder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,335.91,514.19,116.93,7.86">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">1005993</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
