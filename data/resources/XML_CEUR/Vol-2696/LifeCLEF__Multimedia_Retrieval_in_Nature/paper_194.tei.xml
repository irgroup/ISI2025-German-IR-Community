<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,159.51,115.96,296.33,12.62;1,232.93,133.89,149.49,12.62">Impact of Pretrained Networks For Snake Species Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,243.67,177.68,72.32,8.74"><forename type="first">Moorthy</forename><surname>Gokula</surname></persName>
							<email>gokul@eloop.ai</email>
							<idno type="ORCID">0000-0003-3898-1302</idno>
							<affiliation key="aff0">
								<orgName type="department">Eloop Mobility Solutions</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,319.31,177.68,39.94,8.74;1,362.57,177.50,4.83,4.62"><forename type="first">Krishnan</forename><surname>Id</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Eloop Mobility Solutions</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,159.51,115.96,296.33,12.62;1,232.93,133.89,149.49,12.62">Impact of Pretrained Networks For Snake Species Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B2EB156154B1D46397860AD61AADD58E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Snake Species Classification</term>
					<term>Computer Vision</term>
					<term>Transfer Learning</term>
					<term>Convolutional Neural Networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A robust snake species classifier could aid in the treatment of snake bites. In this report, the technique of transfer learning is revisited to understand the significance of the underlying pre-trained network and the supervised datasets used for pre-training. In low data regime, the methodology of transfer learning has been instrumental in building reliable image classifiers. Comparisons are made between the pre-trained networks trained on datasets of different sizes and classes. Performance improves significantly when the pre-trained network is trained on a much larger supervised dataset. Using country metadata improves the performance considerably. In SnakeCLEF2020 challenge, an F1-score of 0.625 was achieved.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Snakebite is the second most deadly neglected tropical disease <ref type="bibr" coords="1,406.76,450.53,9.96,8.74" target="#b0">[1]</ref>, being responsible for a dramatic humanitarian crisis in global health. Snakebite envenoming (SBE) affects as many as 2.7 million people every year <ref type="bibr" coords="1,377.99,474.44,11.84,8.74" target="#b1">[3]</ref>, most of whom live in some of the world's remote, poorly developed, and politically marginalized tropical communities. With annual mortality of 81,000 to 138,000 and 400,000 surviving victims with permanent physical and psychological disabilities, SBE is a disease in urgent need of attention. Antivenoms can be life-saving when correctly administered but this often depends on the correct taxonomic identification (i.e. family, genus, and species) of the biting snake. But, snakes are never identified in nearly 50% of cases globally <ref type="bibr" coords="1,341.17,558.13,11.83,8.74" target="#b2">[4]</ref>. An automated system that suggests an identification to the healthcare provider from a low-quality photo can speed up the process of treatment. The participants of SnakeCLEF2020 <ref type="bibr" coords="1,465.09,582.04,15.50,8.74" target="#b9">[10]</ref> were challenged to build an accurate snake species classifier that works under diverse conditions.</p><p>With the goal of developing biodiversity monitoring systems, LifeCLEF <ref type="bibr" coords="2,470.07,142.50,10.52,8.74" target="#b4">[6]</ref> evaluation campaign aims at benchmarking the progress every year in the identification of plants and animals. SnakeCLEF challenge was introduced in 2020 to benchmark the progress in building a snake species classifier. In this challenge, 245,185 training images are provided split into 783 species. As shown in Figure <ref type="figure" coords="2,167.33,202.28,3.87,8.74" target="#fig_0">1</ref>, several aspects of snake morphology make this task challenging for computer vision. Evaluation is done using F1-score which ensures the need for better precision and recall over all the species. The trained model is used to infer labels on the test images that are hidden to participants on platform AICrowd<ref type="foot" coords="2,476.12,236.57,3.97,6.12" target="#foot_0">1</ref> directly. The dataset is extremely imbalanced as indicated in Figure <ref type="figure" coords="2,435.66,250.10,4.98,8.74" target="#fig_1">2</ref> with the minimum number of images per class being 17 and the highest class containing 12,201 images. Additional geographical metadata (country and continent) for the image is also provided. All ablation studies were done locally with the given validation set comprising of 14,029 images. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>With the renaissance of deep learning for building image classifiers since 2012 <ref type="bibr" coords="2,469.90,543.10,9.96,8.74" target="#b6">[8]</ref>, deep convolutional neural networks have become the standard for developing state of the art of image classifiers that work well under diverse conditions given that a large supervised dataset is available. In certain domain-specific cases, the availability of such large scale dataset comprising of millions of images might not be possible. The images might not be readily available, geographically constrained, or rare. In such cases, the technique of transfer learning is used. In this methodology, the network is trained on a different data distribution containing Recently, an extensive study has been performed <ref type="bibr" coords="3,355.60,406.74,10.52,8.74" target="#b5">[7]</ref> to understand the impact of these learned representations on the downstream task (fine-tuning to domainspecific image classifier). Corollary to popular belief, larger models trained on larger datasets do not always perform better on the downstream task. The size of the domain-specific dataset plays a crucial role in determining the training strategy and the size of the model. In the context of the SnakeCLEF2020 challenge, experiments were carried out to understand the differences between the models trained on both these datasets (ImageNet-1k and ImageNet-21k).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Implementation Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Pretrained Classifiers</head><p>Vanilla ResNet50-v2 <ref type="bibr" coords="3,229.02,584.39,10.52,8.74" target="#b3">[5]</ref> classifier is used for experimentation. Open-source models that were trained on both ImageNet-1k and ImageNet-21k were used. Both of the pre-trained classifiers were trained under the same conditions. Specifically, this involved keeping the hyperparameters, image resolution, and augmentations constant. The fully connected (FC) layer differs depending on the labels specific to the dataset. While fine-tuning, the FC layer is replaced with a domain-specific FC layer randomly initialized.</p><p>The following strategies were adopted during training:</p><p>-Trained for 10,000 steps.</p><p>-The batch size of each step was 512.</p><p>-Mixup augmentation was used.</p><p>-Staircase based Learning rate scheduler.</p><p>-Optimizer: Schocastic gradient descent with momentum 0.9.</p><p>-Cross Entropy Loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training Techniques</head><p>Preprocessing The given images are of varied sizes. During the training process, the images are first resized to 512x512x3 dimensions using bilinear interpolation method and a random crop of 456x456x3 was taken. The images were also horizontally flipped with a probability of 0.5. During the validation and the testing process, the images were only resized to 456x456x3 dimensions using bilinear interpolation. The images were also normalized with a standard deviation and mean of 0.5 and 0.5 respectively for training, validation, and testing process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Batch Accumulation</head><p>Training can be very inefficient if the mini-batch size is small due to noisy gradients. To accommodate large mini-batch size into GPU memory, batch accumulation is generally used. Gradients are accumulated over 16 steps without updating the model and then updated. Although the size of each mini-batch is 32, the effective mini-batch size is 512.</p><p>Learning Rate Learning rate is the crucial hyperparameter to the task of finetuning. After linear warmup, a stair-case based learning rate scheduler was used following the hyperrule provided by <ref type="bibr" coords="4,290.21,439.79,9.96,8.74" target="#b5">[7]</ref>. Base learning rate (lr b ) of 0.03 was used.</p><p>-Step 0-500: Linear warmup : lr b * i 500 where i = 0, 1, 2..., 500 -Step 500-10000: lr b decayed by a factor of 10 at 3000,6000 and 9000 steps Normalization Group normalization <ref type="bibr" coords="4,295.29,495.58,15.50,8.74" target="#b13">[14]</ref> technique along with weight standardization <ref type="bibr" coords="4,168.17,507.54,15.50,8.74" target="#b10">[11]</ref> was used. The accuracy of Group normalization is stable across a wide range of batch sizes. It is worth noting that other common techniques like weight decay and dropout were not used.</p><p>Augmentation Deep neural networks are prone to undesirable behaviors such as memorization, sensitivity to adversarial examples, and sampling bias. To combat the issues of overfitting, mixup augmentation <ref type="bibr" coords="4,344.32,579.27,15.50,8.74" target="#b14">[15]</ref> was used. Mixup strategy trains the network on convex combinations of pairs of examples and their labels. The combination can be controlled by a factor, α. With α = 0.1 , a sample training image is shown in Figure <ref type="figure" coords="4,288.20,615.13,3.87,8.74" target="#fig_2">3</ref>. This favours the network to discriminate between various classes better.  The network pre-trained on ImageNet-21k significantly outperforms its Image-Net-1k counterpart. Especially, classes with fewer data points are discriminated better reflected by the significant improvement in the F1-score.</p><p>Model-A disagrees with Model-B for 1,989 images, where Model-B is correct. Also, Model-B disagrees with Model-A for 433 images, where Model-A is correct. By analyzing images with the highest discrepancies (i.e) the images for which Model-B is correct and the probability of the correct species inferred from Model-A is very small, further insights could be gained. An attribution technique <ref type="bibr" coords="5,465.09,632.21,15.50,8.74" target="#b12">[13]</ref> to understand which pixels(features) are considered important by the model was performed. The generated saliency maps for top 3 images where models disagree the maximum was chosen. A single gradient step with respect to the target class for the given image was calculated. As shown in Figure <ref type="figure" coords="6,404.87,130.95,3.87,8.74" target="#fig_3">4</ref>, by ranking the pixels with respect to the gradients, the saliency maps generated from Model-B tend to be much more concentrated in the area of interest indicating better generalization. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Metadata Usage</head><p>Several snake species are constrained by their geographical location. Metadata about where the image was taken was given in the form of Country and Continent. The distribution of images per country follows a long tail distribution and is concentrated mostly in the United States Of America (61.42%). Images were taken from 187 countries. In the absence of such information, "UNKNOWN" is marked. The probability of a species given a country is precomputed from the training dataset distribution as follows:</p><formula xml:id="formula_0" coords="6,273.99,631.96,206.60,9.65">p(s | c) = t sc /t c<label>(1)</label></formula><p>where:</p><p>p(s | c) = probability of a species, given a country. t sc = total number of images belonging to the species, s found in the country, c. t c = total number of images found in the country, c.</p><p>The generated, p(s | c), is provided at<ref type="foot" coords="7,324.19,191.94,3.97,6.12" target="#foot_1">1</ref> along with the source code used for training. It is worth noting that the images marked with "UNKNOWN" data is considered as a country for the purposes of pre-computation. The final probabilities are then adjusted as follows:</p><formula xml:id="formula_1" coords="7,269.61,252.91,210.99,9.65">p s = p φs * p(s | c)<label>(2)</label></formula><p>where:</p><p>p s = probability of the species, given the image and country. p φs = probability of the species inferred from the model.</p><p>The probabilites are normalized to ensure a sum of 1. Using this technique on Model-B, the scores improved from 0.5813 to 0.6019.</p><p>The test dataset on which the final scores were calculated, follows a data distribution similar to validation dataset and the model achieves an F1-score of 0.625 when tested on AICrowd platform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>Although the models were trained with the same hyper-parameters, Model-B performs better than Model-A. These results signify the importance of having generalized visual representations before fine-tuning is done on a domain-specific dataset. Label smoothing <ref type="bibr" coords="7,241.61,512.70,13.92,8.74" target="#b8">[9]</ref> could improve the performance and can handle the noisy images found in the dataset. Bigger models and stronger augmentations such as rotation and jittering could make the model more resilient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgements</head><p>The compute resources required to perform the experiments was provided by hostkey.com<ref type="foot" coords="7,190.72,610.83,3.97,6.12" target="#foot_2">2</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,253.48,465.99,108.39,7.89;2,194.29,329.13,226.77,122.09"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Snakes diversity [2]</figDesc><graphic coords="2,194.29,329.13,226.77,122.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,257.16,256.90,101.04,7.89;3,137.60,115.83,340.16,126.29"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Data distribution</figDesc><graphic coords="3,137.60,115.83,340.16,126.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,241.64,312.08,132.09,7.89;5,194.29,115.84,226.77,181.47"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Augmentation Technique</figDesc><graphic coords="5,194.29,115.84,226.77,181.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,134.77,423.07,345.82,7.89;6,134.77,434.05,345.82,7.86;6,134.77,445.01,41.27,7.86;6,194.29,200.48,226.77,207.82"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Generated saliency maps. The first column denotes the images given, second column and third column denote the saliency maps from Model-A and Model-B respectively.</figDesc><graphic coords="6,194.29,200.48,226.77,207.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,187.78,425.75,239.80,64.23"><head>Table 1 .</head><label>1</label><figDesc>Performance comparisons of pre-trained networks</figDesc><table coords="5,204.62,425.75,206.11,53.32"><row><cell></cell><cell cols="2">Pretrained On</cell></row><row><cell>Metric</cell><cell cols="2">ImageNet-1k ImageNet-21k</cell></row><row><cell>Top-1 Accuracy</cell><cell>68.48 %</cell><cell>79.57 % +11.09%</cell></row><row><cell>Top-5 Accuracy</cell><cell>87.70%</cell><cell>93.58 % +5.88%</cell></row><row><cell>F1 score</cell><cell>0.27</cell><cell>0.5813 +0.3113</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,646.48,297.97,7.47;2,144.73,657.44,42.37,7.47"><p>https://www.aicrowd.com/challenges/snake-species-identificationchallenge</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1" coords="7,144.73,635.53,310.03,7.47;7,144.73,646.48,37.66,7.47"><p>https://github.com/GokulEpiphany/snakes-round-4-train/tree/master/ metadata</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2" coords="7,144.73,657.44,108.68,7.47"><p>https://www.hostkey.com/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,142.32,337.63,7.86;8,151.52,153.28,247.76,7.86;8,421.26,153.28,59.33,8.12;8,151.52,164.88,293.26,7.47;8,151.52,175.84,300.04,7.47;8,151.52,186.80,259.24,7.47" xml:id="b0">
	<monogr>
		<ptr target="https://www.unige.ch/medecine/isg/en/research/one-health/snapp-first-medical-decisionsupport-tool-for-snake-identification-based-on-artificial-intelligence-and-remote-collaborative-expe/" />
		<title level="m" coord="8,151.53,142.32,329.06,7.86;8,151.52,153.28,243.91,7.86">First medical decision support tool for snake identification based on artificial intelligence and remote collaborative expertise</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,229.88,337.64,8.11;8,151.52,241.49,130.15,7.47" xml:id="b1">
	<monogr>
		<ptr target="https://www.who.int/news-room/fact-sheets/detail/snakebite-envenoming" />
		<title level="m" coord="8,151.53,229.88,90.09,7.86">Snakebite envenoming</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,251.75,337.64,7.86;8,151.52,262.71,329.07,7.86;8,151.52,273.67,329.07,7.86;8,151.52,284.62,329.07,8.11;8,151.52,296.23,172.85,7.47" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,368.44,262.71,112.15,7.86;8,151.52,273.67,329.07,7.86;8,151.52,284.62,129.55,7.86">Identifying the snake: First scoping review on practices of communities and healthcare providers confronted with snakebite across the world</title>
		<author>
			<persName coords=""><forename type="first">Isabelle</forename><surname>Bolon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Durso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sara</forename><forename type="middle">Botero</forename><surname>Mesa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicolas</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gabriel</forename><surname>Alcoba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">François</forename><surname>Chappuis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rafael</forename><surname>Ruiz De Castañeda</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0229989</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0229989" />
	</analytic>
	<monogr>
		<title level="j" coord="8,292.43,284.62,45.53,7.86">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2020">03 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,306.49,337.64,7.86;8,151.52,317.45,329.07,7.86;8,151.52,328.41,329.07,7.86;8,151.52,339.37,137.45,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,406.27,306.49,74.32,7.86;8,151.52,317.45,104.56,7.86">Identity mappings in deep residual networks</title>
		<author>
			<persName coords=""><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,222.75,328.41,131.69,7.86">Computer Vision -ECCV 2016</title>
		<editor>
			<persName><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,350.27,337.64,7.86;8,151.52,361.23,329.07,7.86;8,151.52,372.19,329.07,7.86;8,151.52,383.15,329.07,7.86;8,151.52,394.11,329.07,7.86;8,151.52,405.07,329.07,7.86;8,151.52,416.02,329.07,7.86;8,151.52,426.98,55.50,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,183.00,394.11,297.59,7.86;8,151.52,405.07,195.87,7.86">Overview of lifeclef 2020: a system-oriented evaluation of automated species identification and species distribution prediction</title>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Kahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><surname>Deneu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maximilien</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Elijah</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lukáš</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rafael</forename><surname>Ruiz De Castañeda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Isabelle</forename><surname>Bolon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Titouan</forename><surname>Lorieul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christophe</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Champ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Willem-Pier</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fabian-Robert</forename><surname>Stöter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Dorso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ivan</forename><surname>Eggel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,369.36,405.07,111.24,7.86;8,151.52,416.02,220.40,7.86">Proceedings of CLEF 2020, CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting>CLEF 2020, CLEF: Conference and Labs of the Evaluation Forum<address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-09">Sep. 2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,437.89,337.63,7.86;8,151.52,448.85,329.07,7.86;8,151.52,459.81,138.71,8.12" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="8,286.74,448.85,193.86,7.86;8,151.52,459.81,30.97,7.86">Big transfer (bit): General visual representation learning</title>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joan</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jessica</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.11370</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,470.71,337.64,7.86;8,151.52,481.67,329.07,7.86;8,151.52,492.63,329.07,7.86;8,151.52,503.59,220.72,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,413.26,470.71,67.33,7.86;8,151.52,481.67,208.43,7.86">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,379.61,492.63,100.98,7.86;8,151.52,503.59,124.88,7.86">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,378.18,503.59,102.42,7.86;8,151.52,514.55,328.57,8.12;8,151.52,526.15,204.82,7.47" xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Curran Associates</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Inc</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,536.41,337.63,7.86;8,151.52,547.37,127.69,8.12" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="8,370.38,536.41,110.20,7.86;8,151.52,547.37,19.84,7.86">When does label smoothing help?</title>
		<author>
			<persName coords=""><forename type="first">Rafael</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02629</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,558.27,337.98,7.86;8,151.52,569.23,329.07,7.86;8,151.52,580.19,329.07,7.86;8,151.52,591.15,261.46,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,245.68,569.23,234.92,7.86;8,151.52,580.19,90.29,7.86">Overview of the snakeclef 2020: Automatic snake species identification challenge</title>
		<author>
			<persName coords=""><forename type="first">Lukáš</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rafael</forename><surname>Ruiz De Castañeda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Durso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Isabelle</forename><surname>Bolon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">Mohanty</forename><surname>Sharada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,259.99,580.19,220.60,7.86;8,151.52,591.15,96.66,7.86">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-09">Sep. 2020. 2020</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2020</note>
</biblStruct>

<biblStruct coords="8,142.62,602.06,337.97,7.86;8,151.52,613.02,152.02,8.12" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Siyuan</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Huiyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.10520</idno>
		<title level="m" coord="8,428.92,602.06,51.67,7.86;8,151.52,613.02,44.13,7.86">Weight standardization</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,623.92,337.98,7.86;8,151.52,634.88,329.07,7.86;8,151.52,645.84,329.07,7.86;8,151.52,657.44,71.02,7.47" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0575</idno>
		<title level="m" coord="8,262.54,645.84,190.75,7.86">Imagenet large scale visual recognition challenge</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,119.67,337.97,7.86;9,151.52,130.63,329.07,7.86;9,151.52,142.24,71.02,7.47" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="9,396.49,119.67,84.11,7.86;9,151.52,130.63,299.96,7.86">Deep inside convolutional networks: Visualising image classification models and saliency maps</title>
		<author>
			<persName coords=""><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6034</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,152.55,316.13,8.11" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="9,268.24,152.55,82.49,7.86">Group normalization</title>
		<author>
			<persName coords=""><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.08494</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,163.51,337.97,7.86;9,151.52,174.47,250.01,8.12" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m" coord="9,452.69,163.51,27.90,7.86;9,151.52,174.47,141.88,7.86">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
